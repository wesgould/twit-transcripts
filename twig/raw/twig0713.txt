;FFMETADATA1
title=Creased Cargo Shorts
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2023-04-27
track=713
language=English
genre=Podcast
comment=Alphabet earnings, teens and social media, blue check, Authenticator 2FA
encoded_by=Uniblab 5.3
date=2023
encoder=Lavf58.76.100

[00:00:00.000 --> 00:00:03.120]   It's time for Twig this week in Google.
[00:00:03.120 --> 00:00:05.520]   Jeff Jarvis is here. Stacey Higginbotham.
[00:00:05.520 --> 00:00:08.600]   Aunt Pruitt, and yes, I'm back in the saddle.
[00:00:08.600 --> 00:00:12.360]   As it were, we will talk about Google's quarterly results
[00:00:12.360 --> 00:00:15.680]   and how they compared to, let's say, I don't know, Microsoft.
[00:00:15.680 --> 00:00:21.520]   We also have a story about teens and social media.
[00:00:21.520 --> 00:00:27.240]   What is causing teens to be so anxious these days?
[00:00:27.240 --> 00:00:29.240]   Is it social media?
[00:00:29.240 --> 00:00:32.320]   And the blue check, that's making me anxious.
[00:00:32.320 --> 00:00:36.120]   All that and a lot more coming up next on This Week in Google.
[00:00:36.120 --> 00:00:38.800]   [MUSIC]
[00:00:38.800 --> 00:00:40.600]   Podcasts you love.
[00:00:40.600 --> 00:00:42.520]   From people you trust.
[00:00:42.520 --> 00:00:44.880]   This is Twig.
[00:00:44.880 --> 00:00:49.680]   [MUSIC]
[00:00:49.680 --> 00:00:54.520]   This is Twig. This Week in Google, episode 713,
[00:00:54.520 --> 00:00:58.600]   recorded Wednesday, April 26th, 2023.
[00:00:58.600 --> 00:01:01.040]   Christcargo Shorts.
[00:01:01.040 --> 00:01:05.200]   This episode of This Week in Google is brought to you by ZipRecruiter.
[00:01:05.200 --> 00:01:07.720]   Whether you're starting a new business or growing one,
[00:01:07.720 --> 00:01:09.720]   if you want it to be successful,
[00:01:09.720 --> 00:01:12.760]   you need the most talented people on your team.
[00:01:12.760 --> 00:01:14.640]   That's where ZipRecruiter comes in.
[00:01:14.640 --> 00:01:16.360]   Right now you can try it for free,
[00:01:16.360 --> 00:01:19.960]   ziprecruiter.com/twig.
[00:01:19.960 --> 00:01:26.440]   And by HPE GreenLake, orchestrated by the experts at CDW,
[00:01:26.440 --> 00:01:29.880]   who can help you consolidate and manage all your data in one
[00:01:29.880 --> 00:01:34.040]   flexible edge to cloud platform to scale and innovate.
[00:01:34.040 --> 00:01:39.320]   Learn more at CDW.com/HPE.
[00:01:39.320 --> 00:01:44.280]   And by Cisco Maraki, with employees working in different locations,
[00:01:44.280 --> 00:01:46.720]   providing a unified work experience,
[00:01:46.720 --> 00:01:49.320]   seems as bad as easy as perting cats.
[00:01:49.320 --> 00:01:52.040]   How do you rein in so many moving parts?
[00:01:52.040 --> 00:01:52.920]   I'll tell you how.
[00:01:52.920 --> 00:01:55.600]   The Maraki Cloud Managed Network.
[00:01:55.600 --> 00:01:58.560]   Learn how your organization can make hybrid work.
[00:01:58.560 --> 00:02:04.960]   Visit maraki.sisco.com/twig.
[00:02:04.960 --> 00:02:07.240]   It's time for Twig this week at Google.
[00:02:07.240 --> 00:02:10.080]   The show we cover the latest news from the Googleverse,
[00:02:10.080 --> 00:02:14.240]   the metaverse, the Twitterverse, such as it is.
[00:02:14.240 --> 00:02:15.800]   Stacey Higginbotham is here.
[00:02:15.800 --> 00:02:16.960]   Hello, Stacey.
[00:02:16.960 --> 00:02:20.160]   Wow, your hair changed since I've been gone.
[00:02:20.160 --> 00:02:20.880]   Oh, yeah.
[00:02:20.880 --> 00:02:21.400]   I got it.
[00:02:21.400 --> 00:02:21.840]   You color.
[00:02:21.840 --> 00:02:23.240]   It turned it pink.
[00:02:23.240 --> 00:02:24.520]   It's pretty.
[00:02:24.520 --> 00:02:25.160]   I like it.
[00:02:25.160 --> 00:02:25.680]   Thank you.
[00:02:25.680 --> 00:02:26.640]   Yes.
[00:02:26.640 --> 00:02:28.880]   You never know what we're going to get.
[00:02:28.880 --> 00:02:33.040]   My hair color, unfortunately, unchanged.
[00:02:33.040 --> 00:02:37.160]   Jeff Jarvis, let's see if he's still the silver fox he sure is.
[00:02:37.160 --> 00:02:38.440]   Hello, Jeff.
[00:02:38.440 --> 00:02:39.280]   Hello.
[00:02:39.280 --> 00:02:39.720]   How are you?
[00:02:39.720 --> 00:02:44.320]   Leonard Taap, Professor for journalistic innovation at Craig
[00:02:44.320 --> 00:02:47.760]   Newmark Graduate School of Journalism at the City University
[00:02:47.760 --> 00:02:48.160]   of New York.
[00:02:48.160 --> 00:02:48.760]   I like that.
[00:02:48.760 --> 00:02:50.480]   A choir from heaven.
[00:02:50.480 --> 00:02:53.320]   That was like a choir from heaven.
[00:02:53.320 --> 00:02:54.720]   Jeff, deepest condolences.
[00:02:54.720 --> 00:02:56.440]   I know your dad passed while we were gone.
[00:02:56.440 --> 00:02:57.360]   I'm so sorry.
[00:02:57.360 --> 00:02:58.360]   So sorry.
[00:02:58.360 --> 00:02:59.240]   Thank you so much.
[00:02:59.240 --> 00:03:01.120]   97?
[00:03:01.120 --> 00:03:02.360]   97.
[00:03:02.360 --> 00:03:03.840]   Holy cow.
[00:03:03.840 --> 00:03:06.760]   I wrote about him on Buzz machine folks.
[00:03:06.760 --> 00:03:07.680]   Oh, good.
[00:03:07.680 --> 00:03:08.040]   Yeah.
[00:03:08.040 --> 00:03:08.760]   Sorry, Jeff.
[00:03:08.760 --> 00:03:09.600]   Yeah.
[00:03:09.600 --> 00:03:10.040]   Thank you.
[00:03:10.040 --> 00:03:10.960]   And COVID.
[00:03:10.960 --> 00:03:11.400]   Sadness.
[00:03:11.400 --> 00:03:11.960]   COVID.
[00:03:11.960 --> 00:03:12.240]   Yeah.
[00:03:12.240 --> 00:03:12.960]   COVID.
[00:03:12.960 --> 00:03:14.160]   Was it?
[00:03:14.160 --> 00:03:15.320]   What do they call the new one?
[00:03:15.320 --> 00:03:16.200]   A Braxis?
[00:03:16.200 --> 00:03:17.480]   No, there's a name for it.
[00:03:17.480 --> 00:03:18.760]   No, I don't know.
[00:03:18.760 --> 00:03:19.400]   It wasn't.
[00:03:19.400 --> 00:03:21.600]   It wasn't for 30th and then was hospitalized three times.
[00:03:21.600 --> 00:03:22.680]   Oh, it was a long time.
[00:03:22.680 --> 00:03:24.040]   Successive thing happened.
[00:03:24.040 --> 00:03:28.200]   Oh, so he got it late last year and it just dragged out.
[00:03:28.200 --> 00:03:29.640]   He was fully vaccinated.
[00:03:29.640 --> 00:03:33.960]   He had internal bleeding first, got out of the hospital, went back in with post COVID
[00:03:33.960 --> 00:03:38.840]   pneumonia, which is a certain kind of pneumonia and got out of the hospital went to rehab, got
[00:03:38.840 --> 00:03:41.680]   home for 11 days, went back in with pneumonia again.
[00:03:41.680 --> 00:03:42.200]   And that was that.
[00:03:42.200 --> 00:03:43.160]   I'm so sorry.
[00:03:43.160 --> 00:03:46.320]   Oh, well, he's seven years condolences.
[00:03:46.320 --> 00:03:49.000]   I guess, you know, if there's any, we buried him.
[00:03:49.000 --> 00:03:52.760]   My sister, my sister is ashes, my sister is former church.
[00:03:52.760 --> 00:03:57.000]   She's being a minister and we put a bottle of gin in with him.
[00:03:57.000 --> 00:03:58.840]   What kind?
[00:03:58.840 --> 00:03:59.800]   Excellent choice.
[00:03:59.800 --> 00:04:00.240]   Yes.
[00:04:00.240 --> 00:04:00.920]   Outstanding.
[00:04:00.920 --> 00:04:03.880]   There was something on the Arc-Turus.
[00:04:03.880 --> 00:04:04.240]   That's it.
[00:04:04.240 --> 00:04:04.720]   Yeah.
[00:04:04.720 --> 00:04:05.920]   There was something Stacey.
[00:04:05.920 --> 00:04:07.280]   I really enjoyed on the trip.
[00:04:07.280 --> 00:04:11.000]   You know, when you're on a cruise ship, you have to establish a drink so that you get it
[00:04:11.000 --> 00:04:12.200]   automatically every day.
[00:04:12.200 --> 00:04:18.160]   And there was something called a Bramble, B-R-A-E-M-B-L-E, which is delicious.
[00:04:18.160 --> 00:04:18.840]   You've had them.
[00:04:18.840 --> 00:04:20.200]   She's been to that.
[00:04:20.200 --> 00:04:27.840]   I mean, well, you, there's now somebody who, Bramble.com that has taken gin and Blackberry
[00:04:27.840 --> 00:04:30.680]   Liqueur and married it together and you could buy a bottle of it.
[00:04:30.680 --> 00:04:33.200]   And it's, that's what we were drinking.
[00:04:33.200 --> 00:04:34.840]   It was fantastic.
[00:04:34.840 --> 00:04:39.360]   So that's an actual beverage that you make by hand.
[00:04:39.360 --> 00:04:40.760]   And so that's probably a good idea.
[00:04:40.760 --> 00:04:42.040]   Oh, you can choose the gin.
[00:04:42.040 --> 00:04:44.760]   But this way, the cocktail is a Bramble.
[00:04:44.760 --> 00:04:46.880]   But this is a liquor, which would be fun.
[00:04:46.880 --> 00:04:48.120]   Well, it's just like the cocktail.
[00:04:48.120 --> 00:04:50.200]   I mean, it's basically gin and Blackberry Liqueur.
[00:04:50.200 --> 00:04:52.720]   So yeah, I loved it.
[00:04:52.720 --> 00:04:54.040]   That was my beverage.
[00:04:54.040 --> 00:04:58.640]   I was shamed because a couple of years ago, I went on a riverboat trip,
[00:04:58.640 --> 00:05:00.880]   drank an apple or all spritz.
[00:05:00.880 --> 00:05:02.960]   Somebody said, yeah, a cruise drink.
[00:05:02.960 --> 00:05:04.280]   So I couldn't have that name.
[00:05:04.280 --> 00:05:06.720]   But then we get to Rome.
[00:05:06.720 --> 00:05:08.400]   That's all they drink in Rome.
[00:05:08.400 --> 00:05:12.440]   Every table, bright orange apple or all sprits or so.
[00:05:12.440 --> 00:05:15.360]   That's a great drink because you can have a lot of them.
[00:05:15.360 --> 00:05:16.520]   They're not a holly-aw-caw.
[00:05:16.520 --> 00:05:17.880]   I mean, yeah.
[00:05:17.880 --> 00:05:18.400]   Yeah.
[00:05:18.400 --> 00:05:19.320]   And they're tasty.
[00:05:19.320 --> 00:05:22.680]   It's basically alcoholic tang, basically.
[00:05:22.680 --> 00:05:26.920]   That is true, but not made by NASA.
[00:05:26.920 --> 00:05:30.400]   But maybe that's true.
[00:05:30.400 --> 00:05:31.160]   Yeah.
[00:05:31.160 --> 00:05:32.560]   Well, they say that.
[00:05:32.560 --> 00:05:34.280]   I don't know. That's OK.
[00:05:34.280 --> 00:05:36.080]   Hey, it's look at that.
[00:05:36.080 --> 00:05:39.600]   It's at Pruitt from Hands On Photography, patiently waiting for us to stop
[00:05:39.600 --> 00:05:44.560]   talking about silly beverages so that he can have another sip of his own.
[00:05:44.560 --> 00:05:46.560]   Abnebour, a Brenda.
[00:05:46.560 --> 00:05:49.120]   No, this was espresso.
[00:05:49.120 --> 00:05:50.320]   Oh, no.
[00:05:50.320 --> 00:05:50.960]   You liked it.
[00:05:50.960 --> 00:05:51.600]   You know what?
[00:05:51.600 --> 00:05:55.080]   I have to say this, you get a chance.
[00:05:55.080 --> 00:05:56.640]   The best coffee I've ever had.
[00:05:56.640 --> 00:06:02.360]   And we've had coffee all over the world in Arabia, where it came from in South
[00:06:02.360 --> 00:06:05.120]   America, in France.
[00:06:05.120 --> 00:06:07.440]   The best coffee I've ever had is Rome, ever.
[00:06:07.440 --> 00:06:08.200]   Consistent.
[00:06:08.200 --> 00:06:09.200]   I believe you.
[00:06:09.200 --> 00:06:11.240]   Unbelievable.
[00:06:11.240 --> 00:06:12.560]   They invented espresso.
[00:06:12.560 --> 00:06:15.440]   So right, I was going to say, well, what espresso comes from there?
[00:06:15.440 --> 00:06:17.120]   Yeah, they probably know what they're doing.
[00:06:17.120 --> 00:06:19.080]   We went to a legal desk for decaf.
[00:06:19.080 --> 00:06:21.920]   Oh, no, actually, you know what?
[00:06:21.920 --> 00:06:24.640]   I think you can't ask for a cappuccino after like noon.
[00:06:24.640 --> 00:06:26.120]   No, they won't know milk in it.
[00:06:26.120 --> 00:06:29.040]   But I found out what the order is because our guide who is Roman said,
[00:06:29.040 --> 00:06:35.680]   you get an espresso, con latte freo or cold day, if you want hot, but latte freo.
[00:06:35.680 --> 00:06:38.600]   She says, I like it and I put a little cold milk in my espresso.
[00:06:38.600 --> 00:06:39.800]   So you're allowed to do that.
[00:06:39.800 --> 00:06:41.400]   That's that's OK.
[00:06:41.400 --> 00:06:44.520]   So I was ordering espresso, con latte freo afternoon.
[00:06:44.520 --> 00:06:45.800]   You're exactly right, though, Stacey.
[00:06:45.800 --> 00:06:47.760]   They think you're American or something.
[00:06:47.760 --> 00:06:49.440]   You have a cappuccino.
[00:06:49.440 --> 00:06:50.440]   Crazy.
[00:06:50.440 --> 00:06:51.440]   Yeah.
[00:06:51.440 --> 00:06:52.600]   Best coffee ever.
[00:06:52.600 --> 00:06:53.240]   I miss it.
[00:06:53.240 --> 00:06:54.040]   I really miss it.
[00:06:54.040 --> 00:06:55.040]   We actually did it.
[00:06:55.040 --> 00:06:59.000]   It was so a lot of us Levatsa, which you can get.
[00:06:59.000 --> 00:07:00.360]   So I ordered some Levatsa beans.
[00:07:00.360 --> 00:07:01.920]   I'm just going to we'll bring them to work.
[00:07:01.920 --> 00:07:03.000]   You can try them.
[00:07:03.000 --> 00:07:03.840]   All right.
[00:07:03.840 --> 00:07:04.840]   But that's enough of that.
[00:07:04.840 --> 00:07:06.560]   We got so much to talk about.
[00:07:06.560 --> 00:07:07.840]   Oh, my God, it's crazy.
[00:07:07.840 --> 00:07:10.840]   I guess we should start with the alphabet's earnings.
[00:07:10.840 --> 00:07:14.360]   Because this week they announced their quarterly earnings.
[00:07:14.360 --> 00:07:17.240]   And there was good and bad.
[00:07:17.240 --> 00:07:19.000]   It beat for the first quarter.
[00:07:19.000 --> 00:07:22.960]   That means it beat the stock market's expectation.
[00:07:22.960 --> 00:07:26.400]   They're going to do a 70 billion.
[00:07:26.400 --> 00:07:29.320]   Bullion share buyback.
[00:07:29.320 --> 00:07:31.200]   That means they got some cash on hand.
[00:07:31.200 --> 00:07:35.000]   Revenue was 10 cents more share than expected.
[00:07:35.000 --> 00:07:36.800]   A hundred dollar, seventeen is share.
[00:07:38.240 --> 00:07:41.480]   That's 69.79 billion dollars.
[00:07:41.480 --> 00:07:43.480]   But there were some dark spots.
[00:07:43.480 --> 00:07:46.480]   YouTube advertising revenue went down.
[00:07:46.480 --> 00:07:48.800]   Not not didn't grow as fast.
[00:07:48.800 --> 00:07:50.000]   Actually went down.
[00:07:50.000 --> 00:07:52.600]   To six point six billion.
[00:07:52.600 --> 00:07:53.400]   A scotch.
[00:07:53.400 --> 00:07:54.720]   Just a scotch.
[00:07:54.720 --> 00:07:55.800]   A scotch.
[00:07:55.800 --> 00:07:56.800]   A scotch.
[00:07:56.800 --> 00:07:57.960]   Oh, bit.
[00:07:57.960 --> 00:07:59.680]   It went down a little bit.
[00:07:59.680 --> 00:08:02.480]   Google Cloud revenue went up a little bit.
[00:08:02.480 --> 00:08:03.560]   Just the same scotch.
[00:08:03.560 --> 00:08:04.800]   Just a scotch.
[00:08:04.800 --> 00:08:06.640]   Just just to offset it.
[00:08:07.880 --> 00:08:10.440]   But it's profitable.
[00:08:10.440 --> 00:08:12.120]   That's big.
[00:08:12.120 --> 00:08:13.800]   Yeah, six point seven billion.
[00:08:13.800 --> 00:08:15.600]   And Cloud for the first time is profitable.
[00:08:15.600 --> 00:08:16.120]   You're right.
[00:08:16.120 --> 00:08:18.040]   Yeah, that's a huge deal.
[00:08:18.040 --> 00:08:18.600]   First time.
[00:08:18.600 --> 00:08:19.400]   That's a big deal.
[00:08:19.400 --> 00:08:20.040]   Huge deal.
[00:08:20.040 --> 00:08:22.720]   They're they're sucking wind at the cloud.
[00:08:22.720 --> 00:08:25.160]   They've been an also ramp to Amazon and Microsoft.
[00:08:25.160 --> 00:08:25.440]   Right.
[00:08:25.440 --> 00:08:26.440]   Those are the two big ones.
[00:08:26.440 --> 00:08:27.440]   Yeah.
[00:08:27.440 --> 00:08:28.520]   Yep.
[00:08:28.520 --> 00:08:30.920]   And it's been hard going for Google.
[00:08:30.920 --> 00:08:32.840]   I don't Microsoft earnings came out.
[00:08:32.840 --> 00:08:34.240]   I don't I don't remember what their number was.
[00:08:34.240 --> 00:08:36.280]   But I think it was bigger than seven and a half billion.
[00:08:37.280 --> 00:08:38.280]   Yeah.
[00:08:38.280 --> 00:08:43.280]   I wonder what was the push that made it actually profitable for them finally.
[00:08:43.280 --> 00:08:44.480]   I'm going to guess AI.
[00:08:44.480 --> 00:08:45.480]   What do you think Stacey?
[00:08:45.480 --> 00:08:50.280]   Um, maybe I don't I truly don't know.
[00:08:50.280 --> 00:08:52.000]   I mean, their AI is internal.
[00:08:52.000 --> 00:08:54.800]   So I don't know their internal accounting policy towards that.
[00:08:54.800 --> 00:08:58.240]   It may just be that they finally they also cut.
[00:08:58.240 --> 00:09:00.760]   They cut some products.
[00:09:00.760 --> 00:09:02.480]   No, they cut some products out.
[00:09:02.480 --> 00:09:05.680]   So they're not supporting some IOT products and things that they were
[00:09:05.680 --> 00:09:08.360]   not as good at or didn't have customers in.
[00:09:08.360 --> 00:09:08.880]   Yeah.
[00:09:08.880 --> 00:09:12.760]   So it could also be that they took a write off for for layoffs.
[00:09:12.760 --> 00:09:14.840]   Oh, yes, billions leases and all that.
[00:09:14.840 --> 00:09:15.200]   Yeah.
[00:09:15.200 --> 00:09:20.480]   But 2.6 billion dollars late and charges related to layoffs and office space reduction.
[00:09:20.480 --> 00:09:24.680]   The journal has a story saying that Google is all about cost control now.
[00:09:24.680 --> 00:09:25.120]   Yeah.
[00:09:25.120 --> 00:09:29.240]   Well, we know that that's everything, which is, I mean, hey, it makes the market happy,
[00:09:29.240 --> 00:09:32.320]   but I prefer they also had some innovation in there too.
[00:09:32.800 --> 00:09:38.680]   So Google's revenue on cloud was 7.5 billion.
[00:09:38.680 --> 00:09:42.600]   Microsoft's revenue on cloud was 52.9 billion.
[00:09:42.600 --> 00:09:44.120]   Whoa, that'll give you an idea.
[00:09:44.120 --> 00:09:46.840]   Microsoft's not even the best, the biggest AWS.
[00:09:46.840 --> 00:09:48.040]   Do we know what Amazon says?
[00:09:48.040 --> 00:09:50.240]   Uh, they didn't do their earnings yet, right?
[00:09:50.240 --> 00:09:50.920]   I don't think their earnings.
[00:09:50.920 --> 00:09:51.800]   I haven't got them yet.
[00:09:51.800 --> 00:09:55.640]   Uh, and I should point out profit.
[00:09:55.640 --> 00:09:57.880]   62 billion in 2021.
[00:09:57.880 --> 00:09:59.320]   So they're not that much bigger.
[00:09:59.320 --> 00:10:00.120]   That's interesting.
[00:10:00.120 --> 00:10:00.480]   Huh?
[00:10:00.960 --> 00:10:02.840]   Microsoft's really gaining on them.
[00:10:02.840 --> 00:10:06.000]   Microsoft also, I'm sure did well because of AI.
[00:10:06.000 --> 00:10:11.240]   Both Microsoft and Google have what are the TPUs special processors designed?
[00:10:11.240 --> 00:10:17.520]   I think Microsoft said like 1% of their revenue in the cloud came from AI.
[00:10:17.520 --> 00:10:22.440]   Oh, maybe I'm wrong, then, which is, well, no, that's, that's not insignificant.
[00:10:22.440 --> 00:10:22.920]   Yeah.
[00:10:22.920 --> 00:10:26.880]   It's going to be big, big, big, big, small or how young it is.
[00:10:26.880 --> 00:10:27.200]   Yeah.
[00:10:27.200 --> 00:10:32.720]   That's the point we've made because Microsoft, of course, owns half of open AI.
[00:10:32.720 --> 00:10:37.160]   But better than that, if you're going to generate these massive large language
[00:10:37.160 --> 00:10:39.080]   models, you're going to do it in the cloud.
[00:10:39.080 --> 00:10:42.760]   And, you know, I think the competition is really between Microsoft and Google for that.
[00:10:42.760 --> 00:10:43.800]   Sorry, go ahead.
[00:10:43.800 --> 00:10:49.480]   Oh, no, no, I was just saying it's the AI side of it is brand new to them.
[00:10:49.480 --> 00:10:51.920]   So I wouldn't expect it to be a number.
[00:10:51.920 --> 00:10:52.640]   Exactly.
[00:10:52.640 --> 00:10:56.440]   But in future, uh, it would probably get bigger.
[00:10:56.840 --> 00:10:58.440]   Profit on cloud.
[00:10:58.440 --> 00:11:04.080]   So Google lost a year ago, $706 million in Google cloud.
[00:11:04.080 --> 00:11:09.640]   They finally made their first ever profit, $191 million, not billions, but
[00:11:09.640 --> 00:11:12.480]   Hey, hey, it's a part that I'm losing money.
[00:11:12.480 --> 00:11:15.160]   Uh, revenue in other bets.
[00:11:15.160 --> 00:11:17.280]   That's life sciences, barely.
[00:11:17.280 --> 00:11:18.480]   That's Waymo.
[00:11:18.480 --> 00:11:21.760]   Uh, it was next.
[00:11:21.760 --> 00:11:26.560]   Yeah, it was 440 million last year, 288 million this year.
[00:11:27.280 --> 00:11:30.960]   Well, but they also pulled out deep mind from other bets.
[00:11:30.960 --> 00:11:31.880]   It looks like, okay.
[00:11:31.880 --> 00:11:33.800]   Well, they didn't work deep mind.
[00:11:33.800 --> 00:11:37.200]   Yeah, I focus on other bets because of like Nest.
[00:11:37.200 --> 00:11:38.800]   So I can see how in seeing him.
[00:11:38.800 --> 00:11:39.280]   Oh, that's right.
[00:11:39.280 --> 00:11:39.800]   Home is.
[00:11:39.800 --> 00:11:40.240]   Yeah.
[00:11:40.240 --> 00:11:42.160]   Um, did they don't break it out?
[00:11:42.160 --> 00:11:42.760]   They merge.
[00:11:42.760 --> 00:11:45.160]   No, not, not the hardware.
[00:11:45.160 --> 00:11:45.400]   No.
[00:11:45.400 --> 00:11:45.800]   Yeah.
[00:11:45.800 --> 00:11:49.080]   But as you can see, this is why Google's like, yeah, I'm not going to support
[00:11:49.080 --> 00:11:51.640]   those other, those other smart displays and.
[00:11:51.640 --> 00:11:53.240]   Yeah, the heck with that.
[00:11:53.240 --> 00:11:53.760]   Yeah.
[00:11:54.640 --> 00:11:58.720]   Search and other revenue came in at $40 billion.
[00:11:58.720 --> 00:12:06.320]   That's up a scosh from 39.62 up a scosh.
[00:12:06.320 --> 00:12:11.040]   But ad sales, not so good.
[00:12:11.040 --> 00:12:11.800]   Right.
[00:12:11.800 --> 00:12:19.040]   Ad sales on YouTube and, uh, let me see if they have the ad sales for a search.
[00:12:19.040 --> 00:12:22.720]   I think search ad sales were not great either.
[00:12:23.080 --> 00:12:29.760]   Add revenue, be analyst expectations, but fell from year prior to 54.55 billion.
[00:12:29.760 --> 00:12:30.640]   Must be nice though.
[00:12:30.640 --> 00:12:32.200]   Oh, yeah, we did.
[00:12:32.200 --> 00:12:33.480]   We, it wasn't quite as big.
[00:12:33.480 --> 00:12:36.480]   It was only 54 billion and this is three months.
[00:12:36.480 --> 00:12:37.840]   This is not a year.
[00:12:37.840 --> 00:12:41.960]   Traffic acquisition costs went up as well.
[00:12:41.960 --> 00:12:45.960]   I have to say though, you know, look at Microsoft, which was also, you know,
[00:12:45.960 --> 00:12:47.480]   for the most part, very positive.
[00:12:47.480 --> 00:12:51.800]   Only Xbox and Bing didn't do that well.
[00:12:52.120 --> 00:12:55.240]   I have to say, I feel like Microsoft's starting to gain ground on Google.
[00:12:55.240 --> 00:12:58.640]   Uh, or am I wrong on that?
[00:12:58.640 --> 00:13:03.440]   Wait, Microsoft has gained ground on in what?
[00:13:03.440 --> 00:13:12.000]   Cloud revenue of 22% per share earnings up 10% quarterly revenue, 7%.
[00:13:12.000 --> 00:13:15.040]   LinkedIn revenue, 8%.
[00:13:15.040 --> 00:13:16.440]   They're firing on all.
[00:13:16.440 --> 00:13:18.400]   So I know.
[00:13:19.400 --> 00:13:22.360]   That's ads and LinkedIn is making money.
[00:13:22.360 --> 00:13:22.840]   Yeah.
[00:13:22.840 --> 00:13:24.120]   Well, they've got premium.
[00:13:24.120 --> 00:13:25.040]   They've got ads.
[00:13:25.040 --> 00:13:28.640]   They've got well, they've got resume services, I think.
[00:13:28.640 --> 00:13:29.000]   Yep.
[00:13:29.000 --> 00:13:34.600]   I'm, I've just not heard anything positive about LinkedIn in a long time.
[00:13:34.600 --> 00:13:36.360]   I love LinkedIn.
[00:13:36.360 --> 00:13:40.880]   I love it too, but there's definitely a lot of scamming and spamming happening
[00:13:40.880 --> 00:13:43.480]   over there on that platform way more than it used.
[00:13:43.480 --> 00:13:44.600]   That's on how you use it.
[00:13:44.600 --> 00:13:46.760]   If you're going for a job, that's useful.
[00:13:46.800 --> 00:13:49.960]   If you're looking up your colleagues and your competitors, that's useful.
[00:13:49.960 --> 00:13:52.000]   If you're wandering the feed, you're right.
[00:13:52.000 --> 00:13:58.720]   Then I actually get a lot of content, like good quality audience on my, my stories.
[00:13:58.720 --> 00:14:01.120]   I used to get a most, not business from there.
[00:14:01.120 --> 00:14:01.760]   Wow.
[00:14:01.760 --> 00:14:02.640]   How about Twitter?
[00:14:02.640 --> 00:14:03.760]   Do you guys like Twitter?
[00:14:03.760 --> 00:14:06.320]   I've heard this is a pretty exciting happening.
[00:14:06.320 --> 00:14:07.400]   Is it?
[00:14:07.400 --> 00:14:10.160]   Are we now calling it X or what are we doing here?
[00:14:10.160 --> 00:14:12.560]   Uh, the company is X, right?
[00:14:12.560 --> 00:14:13.560]   That cuts no longer.
[00:14:13.560 --> 00:14:17.120]   That was last week's news, but I don't know.
[00:14:17.120 --> 00:14:18.560]   I don't want to talk about Elon.
[00:14:18.560 --> 00:14:19.560]   I don't.
[00:14:19.560 --> 00:14:21.040]   OK, I don't.
[00:14:21.040 --> 00:14:21.800]   I'm OK with that.
[00:14:21.800 --> 00:14:22.200]   Sure.
[00:14:22.200 --> 00:14:23.680]   We have so much else we can talk about.
[00:14:23.680 --> 00:14:30.920]   We had to on Twitch on Sunday because Elon had such a bad week, but, uh, let me, let me put it this way.
[00:14:30.920 --> 00:14:33.280]   Have you guys noticed because of this blue check thing?
[00:14:33.280 --> 00:14:36.000]   Uh, is there any difference?
[00:14:36.000 --> 00:14:39.560]   Cause I know, say he loved the content you get on Twitter.
[00:14:39.560 --> 00:14:40.440]   Is there any difference?
[00:14:40.440 --> 00:14:42.600]   Has the blue check thing changed anything?
[00:14:43.600 --> 00:14:44.600]   Not for me.
[00:14:44.600 --> 00:14:53.800]   Um, yeah, some of the, like, some of the replies and things, like, I really, like Twitter has become less and less useful.
[00:14:53.800 --> 00:14:55.080]   So I'll just be honest.
[00:14:55.080 --> 00:14:56.520]   I don't spend much there.
[00:14:56.520 --> 00:14:58.360]   Hello, change for me.
[00:14:58.360 --> 00:15:02.040]   It's just again, it's more and more broadcast for me.
[00:15:02.040 --> 00:15:06.760]   I'm disappointed to see some people bought the check the eight bucks, Schmuck.
[00:15:06.760 --> 00:15:08.560]   Yeah, boy.
[00:15:08.560 --> 00:15:12.520]   And you really, yeah, you had a, there's a whole movement to block the check.
[00:15:12.520 --> 00:15:12.920]   Right?
[00:15:12.920 --> 00:15:23.640]   Uh, there are those who say anybody who is anybody who bought a check, uh, is probably a low value Twitter,
[00:15:23.640 --> 00:15:28.920]   person to fall because they had to buy basically promote their tweets.
[00:15:28.920 --> 00:15:42.280]   So the problem is, is people are looking at that as them buying a check versus it being someone that wants a add lists or, or lower ads in their Twitter experience.
[00:15:42.280 --> 00:15:48.920]   Or, or wanted to be able to edit, edit, but you know what, not, you know, for, for most people, it had squat to do.
[00:15:48.920 --> 00:15:49.880]   Well, check, Marty.
[00:15:49.880 --> 00:15:50.120]   Okay.
[00:15:50.120 --> 00:15:51.480]   Now we do have to wait into this.
[00:15:51.480 --> 00:15:53.720]   And I don't know if this number is valid, but I keep seeing it.
[00:15:53.720 --> 00:15:59.640]   The net gain when they took away the blue checks of people buying the blue checks was 28.
[00:15:59.640 --> 00:16:01.000]   Yeah, crazy.
[00:16:01.000 --> 00:16:01.400]   Low.
[00:16:01.400 --> 00:16:01.640]   Yeah.
[00:16:01.640 --> 00:16:03.400]   Little more than two dozen total.
[00:16:03.400 --> 00:16:06.040]   So it wasn't, it wasn't.
[00:16:06.040 --> 00:16:07.000]   Wait, wait, what?
[00:16:07.000 --> 00:16:08.280]   You didn't see this?
[00:16:08.280 --> 00:16:09.400]   The math on that.
[00:16:09.400 --> 00:16:17.960]   I know it's a little weird and it was a study and I don't know by some guy, but I've seen the number quoted again and again.
[00:16:17.960 --> 00:16:23.240]   This is, um, uh, I mean, everybody quoted it, but let me show you the original.
[00:16:23.240 --> 00:16:30.600]   Uh, this is from, um, uh, Ben Collins.
[00:16:30.600 --> 00:16:31.240]   Oh, okay.
[00:16:31.240 --> 00:16:32.200]   Who's really good.
[00:16:32.200 --> 00:16:32.760]   That's great.
[00:16:32.760 --> 00:16:34.360]   But baby, he got it from somebody else.
[00:16:34.360 --> 00:16:35.240]   Oh, yeah, he got it.
[00:16:35.240 --> 00:16:35.720]   Somebody else.
[00:16:35.720 --> 00:16:37.000]   From Travis Brown.
[00:16:38.040 --> 00:16:40.200]   Who, I don't know who he is when he's at home.
[00:16:40.200 --> 00:16:47.400]   Um, after, and this is in one day, but in other words, let's read it.
[00:16:47.400 --> 00:16:55.000]   Update for the day after just before the purge yesterday, 19,469 of the 407,000 legacy verified accounts.
[00:16:55.000 --> 00:16:57.640]   I had identified early in April had Twitter blue.
[00:16:57.640 --> 00:17:02.920]   So that's the first data point of almost half a million legacy accounts.
[00:17:02.920 --> 00:17:04.680]   They were all blown out.
[00:17:04.680 --> 00:17:05.640]   I lost my blue check.
[00:17:05.640 --> 00:17:06.200]   Everybody did.
[00:17:06.200 --> 00:17:07.480]   Only 20,000 left.
[00:17:07.480 --> 00:17:12.280]   Today, that number has only gone up by 28.
[00:17:12.280 --> 00:17:17.720]   That's in other words, 28 more people bought blue checks in one day.
[00:17:17.720 --> 00:17:17.720]   Mm.
[00:17:17.720 --> 00:17:21.560]   There is some question about whether it's a good thing to have a blue check.
[00:17:21.560 --> 00:17:21.960]   You're right.
[00:17:21.960 --> 00:17:24.280]   And, and Stacy could be for the edit button.
[00:17:24.280 --> 00:17:26.200]   It could be for the fewer ads.
[00:17:26.200 --> 00:17:30.680]   It's because your business needs you to put up, um, longer videos or longer posts.
[00:17:30.680 --> 00:17:32.520]   I mean, I'm empathetic to that.
[00:17:32.520 --> 00:17:35.160]   However, in general, unless you have a good excuse.
[00:17:35.800 --> 00:17:36.280]   Why?
[00:17:36.280 --> 00:17:41.480]   I've heard some people complain that when you look at replies now to any tweet,
[00:17:41.480 --> 00:17:44.600]   the blue checks are prior to just, oh, I know.
[00:17:44.600 --> 00:17:54.280]   And it can be a nightmare, like on things to try to figure out if it's accurate or if you're looking to see who's replying and people you know commenting.
[00:17:54.280 --> 00:17:55.720]   You can't.
[00:17:55.720 --> 00:17:56.200]   It's.
[00:17:56.200 --> 00:17:57.400]   That's my struggle now.
[00:17:57.400 --> 00:18:01.640]   It's just going through the notifications because I don't look at it as often,
[00:18:01.640 --> 00:18:05.560]   maybe more so in the weekends and it's, it could be pretty crap.
[00:18:05.560 --> 00:18:06.520]   Tastic in there.
[00:18:06.520 --> 00:18:07.720]   Sort of sifting through.
[00:18:07.720 --> 00:18:11.480]   So instead of talking about Elon, let me talk, let me do a little meta thing.
[00:18:11.480 --> 00:18:14.040]   Politico had a piece.
[00:18:14.040 --> 00:18:15.000]   I'm sure you all saw it.
[00:18:15.000 --> 00:18:22.040]   Your journalist, Jack Shafer writing, uh, in his fourth estate column, Elon Musk figured out the media's biggest weakness.
[00:18:22.040 --> 00:18:26.440]   The, the premise is Elon has always said, I'm not buying advertising.
[00:18:26.440 --> 00:18:33.560]   I don't need to because like, I guess Donald Trump, I figured out how to get coverage.
[00:18:34.280 --> 00:18:40.680]   Just from a tweet and the, and the complaint that Shafer has is we all fall for it.
[00:18:40.680 --> 00:18:42.280]   We actually buy into it.
[00:18:42.280 --> 00:18:45.400]   Well, yeah, we don't have to be talking about it.
[00:18:45.400 --> 00:18:49.640]   That's been an argument of mine for a little while.
[00:18:49.640 --> 00:18:53.800]   It's like, why do we continue to give people press time?
[00:18:53.800 --> 00:18:55.480]   Shafer writes, he'll do anything.
[00:18:55.480 --> 00:19:01.320]   Oh, he said, he said, he said, he calls what, but Musk is up to media stunt work.
[00:19:02.200 --> 00:19:06.680]   He says he'll do anything to keep it and him, Twitter and himself in the news.
[00:19:06.680 --> 00:19:12.920]   And every day, the news media rewards his show boating with an avalanche of running coverage and commentary.
[00:19:12.920 --> 00:19:13.960]   Sound familiar?
[00:19:13.960 --> 00:19:19.000]   But you've got to wonder, is Elon Musk the problem here or is it the press, which understands
[00:19:19.000 --> 00:19:22.680]   how it's being manipulated by Musk, but just can't quit him.
[00:19:22.680 --> 00:19:24.440]   It's good for traffic, right?
[00:19:24.440 --> 00:19:26.200]   It's good for the business.
[00:19:27.240 --> 00:19:32.840]   But I'm bringing this up as a journalism question for our journalists, Stacey and Jeff.
[00:19:32.840 --> 00:19:35.720]   Jeff, of course, teaches journalism, Stacey's a practicing journalist.
[00:19:35.720 --> 00:19:39.080]   What is the responsibility of the media?
[00:19:39.080 --> 00:19:43.080]   I mean, on the one hand, I understand an outlet, especially in this day and age,
[00:19:43.080 --> 00:19:47.960]   look at what just happened to BuzzFeed News wants to drive traffic.
[00:19:47.960 --> 00:19:54.760]   And if a president drives traffic, is we drive traffic or Elon's outrageous statements drive traffic,
[00:19:54.760 --> 00:20:00.840]   I understand the desire to put that on the TV or in the newspaper.
[00:20:00.840 --> 00:20:05.240]   But on the other hand, there are consequences to this as well.
[00:20:05.240 --> 00:20:08.440]   And we are allowing ourselves to be manipulated.
[00:20:08.440 --> 00:20:08.840]   Stacey?
[00:20:08.840 --> 00:20:15.000]   Well, the issue with journalism is that we don't have the right economic model for what we're
[00:20:15.000 --> 00:20:17.160]   trying to do, like for the quote unquote good.
[00:20:17.160 --> 00:20:24.440]   So if you want to drive traffic to benefit your advertisers, you have to cover a lot of this
[00:20:24.440 --> 00:20:31.720]   stuff. If you want to cover what is right, your readers, they'll still read it, some of it.
[00:20:31.720 --> 00:20:37.560]   They'll still read about like restaurant openings and sports pages and things like that.
[00:20:37.560 --> 00:20:44.760]   But they may not necessarily read your, I don't know, coverage that's good for you.
[00:20:44.760 --> 00:20:46.440]   The green coverage.
[00:20:46.440 --> 00:20:49.080]   By greens, I mean like broccoli.
[00:20:49.080 --> 00:20:49.320]   Yeah.
[00:20:49.320 --> 00:20:50.360]   You're broccoli coverage.
[00:20:50.360 --> 00:20:50.840]   No veg.
[00:20:50.840 --> 00:20:58.040]   And there are stories like Elon's tweets do become actual news when you look at things like
[00:20:58.040 --> 00:21:04.360]   the SpaceX rocket explosion, where he actually tweeted about not putting in the right safety
[00:21:04.360 --> 00:21:09.560]   protocols. So that's a way to talk. I'm like, oh, will this come back to Hontman lawsuits?
[00:21:09.560 --> 00:21:16.200]   Maybe. And there is actual news. I mean, the man is trying for big government contracts and has big
[00:21:17.640 --> 00:21:23.720]   government contracts, but maybe not the Twitter. And I don't know. I mean, some of the Twitter
[00:21:23.720 --> 00:21:30.520]   stuff is news because it does affect a site that people go to and like, but it's probably not to
[00:21:30.520 --> 00:21:35.800]   the level that we talk about it. But it's also our home. Twitter used to be our home.
[00:21:35.800 --> 00:21:42.600]   Yeah. There's a certain amount of lamentation, a morning for what happened to Twitter.
[00:21:43.800 --> 00:21:50.440]   But yeah, you could dial back that kind of coverage a lot and that would be more appropriate, I think.
[00:21:50.440 --> 00:21:57.320]   But amongst us, just us kids, we're all pretty sad that what was once something cool was gone.
[00:21:57.320 --> 00:22:04.040]   Yeah. But I also, I was talking to a reporter at DigiDay today. It was really about Buzzfeed
[00:22:04.040 --> 00:22:08.920]   and Buzzfeed News, which we'll get to. I'm sure later. But I think what we're seeing happen
[00:22:09.720 --> 00:22:20.840]   is with Buzzfeed, with Twitter, with Vice and on and on, is the dying breath of the mass media,
[00:22:20.840 --> 00:22:25.480]   business models. Stacey said, we don't have a business model yet. The business model we still borrow
[00:22:25.480 --> 00:22:31.400]   is that for mass media where you want maximum attention. And that's just not going to be
[00:22:31.400 --> 00:22:37.720]   competitive anymore because there's complete abundance of content, abundance of speech.
[00:22:38.760 --> 00:22:42.760]   It's going to be hard to get any attention. And I think we have to invent new models and new
[00:22:42.760 --> 00:22:50.840]   institutions to find quality. And we're not there yet. We had Paris Martyno on Twitter on Sunday.
[00:22:50.840 --> 00:22:56.280]   Oh, yeah. I love her. She works with the information. And the information doesn't do link bait stories
[00:22:56.280 --> 00:23:01.320]   because it's paid vault. You have to pay $100 a year. And so they don't need to. They get that
[00:23:01.320 --> 00:23:04.680]   they're not trying to drive traffic from links on Facebook.
[00:23:06.200 --> 00:23:11.720]   Right. So it's about service and value and not about reselling your audience. I mean,
[00:23:11.720 --> 00:23:15.800]   the internet gets, everything, the internet gets accused of mass media invented. Are you
[00:23:15.800 --> 00:23:20.920]   going to get attention? Well, that's what mass media did. You got to get engagement and sensationalism
[00:23:20.920 --> 00:23:25.320]   and click bait mass media did that. Why did they do that? Because they wanted to sell
[00:23:25.320 --> 00:23:31.800]   audio, the internet sells you to advertisers. Well, that's what mass media did. Right. And so,
[00:23:31.800 --> 00:23:39.800]   I think that we can shift to a view of value in here and a smaller scale more to the point.
[00:23:39.800 --> 00:23:44.280]   I mentioned in the show before the average circulation of a daily newspaper in the US before
[00:23:44.280 --> 00:23:51.080]   industrialization is 4000. If you have a sub stack newsletter at $10 a month, you got $200,000.
[00:23:51.080 --> 00:23:55.960]   You could make a living at that. Right. It's it brings the scale down. So the expectation
[00:23:55.960 --> 00:24:01.400]   that you've got to be huge. I tell you huge. You got to find all this stuff. I think, I think just
[00:24:01.400 --> 00:24:07.720]   people are going to are fed up with it. Now, Buzzfeed is kind of the
[00:24:07.720 --> 00:24:14.520]   poster child here. Buzzfeed announced that it was going to dissolve its news division. By the way,
[00:24:14.520 --> 00:24:20.040]   I know it's behind a paywall, but a puck news, Dylan Byers wrote, I thought a really good
[00:24:20.040 --> 00:24:25.480]   very good history of the whole thing. And it really doesn't blame Jonah Paredi. I mean,
[00:24:25.480 --> 00:24:32.920]   I think I was tempted to blame Jonah myself. But he says Jonah was a geek. Right.
[00:24:32.920 --> 00:24:41.000]   He came from Huffington Post. He was a co-founder there. He didn't he kind of was doing what his
[00:24:41.000 --> 00:24:48.760]   heart wanted to do, not necessarily thinking it out. Ben Smith, on the other hand, who had left
[00:24:48.760 --> 00:24:54.360]   pull. Oh, there we go. Traffic wrote a great book all about it. Had left Politico to go to Buzzfeed
[00:24:54.360 --> 00:24:58.200]   and then saw the writing on the wall. He's founded Semaphore since
[00:24:58.200 --> 00:25:04.520]   he knew a lot about what was going on. And he saw that the train coming to the end of the tunnel,
[00:25:04.520 --> 00:25:11.400]   which was essentially that Buzzfeed was living on Facebook clicks. Well, it's two things, Leo.
[00:25:11.400 --> 00:25:17.800]   It's yes, that's true. If you go back to about.com, which full disclosure I consulted for when
[00:25:17.800 --> 00:25:22.280]   the Times bought it, it was pretty wonderful. It would write things about all these topics.
[00:25:22.280 --> 00:25:28.280]   And then content farms came along and ruined it. Google had to diminish them all. Buzzfeed
[00:25:28.280 --> 00:25:33.800]   came along and did fun, neat quizzes and lists that everybody came along, all the content farms
[00:25:33.800 --> 00:25:37.080]   and ruined it because then the platform said, this is a rotten experience and we're going to
[00:25:37.080 --> 00:25:45.800]   degrade all of this. And so the problem then was that that happened to Buzzfeed's own
[00:25:46.760 --> 00:25:53.480]   business model. Buzzfeed News never had a business model. And Jonah talked in his memo about how
[00:25:53.480 --> 00:25:57.880]   he regretted overinvesting. That is to say he invested in something that had no business model.
[00:25:57.880 --> 00:26:03.720]   Ben Smith and the newsroom did great work, but it was a philanthropic act by Jonah to say,
[00:26:03.720 --> 00:26:09.480]   I'm going to subsidize news with the listicles. The news itself never fit into the Buzzfeed business
[00:26:09.480 --> 00:26:16.040]   model. It needed advertising, but news and advertising don't mix. And I said for years,
[00:26:16.040 --> 00:26:22.200]   I like Buzzfeed News, but it's doomed. It's doomed. Either the venture capitalists or the private
[00:26:22.200 --> 00:26:27.560]   equity or the public market would say, this is not making money, get rid of it. And that's what
[00:26:27.560 --> 00:26:35.240]   happened. Should I read traffic? I just started it. It's not out until next week. I actually have
[00:26:35.240 --> 00:26:41.720]   a copy on order. I told Ben, I always saved friends by friends books. But as I read the reviews,
[00:26:41.720 --> 00:26:45.480]   I said, I want this now. So I went to Ben and it's like, and I got a copy now copy soon.
[00:26:45.480 --> 00:26:50.600]   It just started as of course, it's been it's very well written. It's about, I mean,
[00:26:50.600 --> 00:26:58.840]   I think it's about that topic of traffic of that whole motif of ethos of media. It's about both Jonah
[00:26:58.840 --> 00:27:05.640]   and my friend, Nick Denton. So I'll be very eager to see what the contrast and comparisons are there.
[00:27:05.640 --> 00:27:10.280]   Nick Denton of Gawker Media. My favorite site.
[00:27:10.280 --> 00:27:17.880]   Gawker was a really good example of how if you follow that,
[00:27:17.880 --> 00:27:24.600]   you know, fall down that rabbit hole of of Linkbait, how bad it can get, right?
[00:27:24.600 --> 00:27:28.920]   Ben was one of the, I mean, Nick was one of the first ones to put the screen up in the newsroom
[00:27:28.920 --> 00:27:33.160]   with all the traffic stats. Talk about a rabbit hole. Yeah.
[00:27:33.160 --> 00:27:38.040]   Oh yeah. But he, he cynically knew what exactly what he was doing with that.
[00:27:38.040 --> 00:27:45.800]   Traffic subtitle is genius rivalry and delusion in the billion dollar race to go viral. You know,
[00:27:45.800 --> 00:27:49.400]   I've been, I don't, I don't know if you guys watch succession. It's my favorite TV show.
[00:27:49.400 --> 00:27:53.080]   And I mean, don't, don't, don't, because I'm two episodes behind.
[00:27:53.080 --> 00:27:56.840]   I won't know. I won't say anything except because this is actually from last season.
[00:27:56.840 --> 00:28:02.520]   But that was one of the new media ventures that Kendall Logan wanted to get. It was called Vulture.
[00:28:03.240 --> 00:28:06.040]   Kind of right. That's familiar sounding, isn't it?
[00:28:06.040 --> 00:28:11.240]   And it was the same idea and it failed for the same reason. And one of the things
[00:28:11.240 --> 00:28:15.640]   the writers, the succession of very good at doing is kind of plucking stories from today's
[00:28:15.640 --> 00:28:19.800]   headlines because you really change them just enough. So it's just enough. So you have to ask
[00:28:19.800 --> 00:28:24.280]   what that is and what it really means. And so Stacy, we are going to, I bet we're going to have
[00:28:24.280 --> 00:28:29.320]   in reference to the latest episode with no spoilers later because they mentioned Sundar.
[00:28:30.360 --> 00:28:32.040]   Okay. Yes. Yes.
[00:28:32.040 --> 00:28:32.840]   Responsed.
[00:28:32.840 --> 00:28:34.280]   Is not hysterical.
[00:28:34.280 --> 00:28:34.600]   Yeah.
[00:28:34.600 --> 00:28:36.760]   And our responded. I think we got to at least deal with.
[00:28:36.760 --> 00:28:39.880]   We'll mention this. It won't spoil it in any way. In fact, he'll just give you a heads up to
[00:28:39.880 --> 00:28:45.800]   listen for this line. So as Sundar Pachai, of course, getting excited about Google I/O.
[00:28:45.800 --> 00:28:50.520]   And he was on the analyst call. Here's a picture that they released, the press department released
[00:28:50.520 --> 00:28:58.040]   of Sundar meeting with the team to prepare for the analyst call. And he talked about the AI and
[00:28:58.040 --> 00:29:01.480]   picked. He didn't say anything that we didn't already know about Google I/O.
[00:29:01.480 --> 00:29:06.600]   But notice there's something about this picture that's a little bit odd. And it's hanging up here
[00:29:06.600 --> 00:29:13.880]   in the background. There's a pair of white cargo shorts that are creased. And this was a direct
[00:29:13.880 --> 00:29:19.000]   reference because he's mentioned in the last episode of succession. So, so, so, so, so,
[00:29:19.000 --> 00:29:27.480]   Tom sits. Oh, I can't say that. No, no, no, no, no. It's funny. Just look for the mention.
[00:29:27.480 --> 00:29:33.960]   Because it, my ears perked up as soon as he says Sundar Pachai. It's like what? And, and it's a very
[00:29:33.960 --> 00:29:41.720]   funny attempt to, to bond that fails miserably. But involves creased cargo shorts. And Sundar,
[00:29:41.720 --> 00:29:47.320]   who maybe he's a fan or maybe his press department, you know, is savvy enough to, to do it. This is a
[00:29:47.320 --> 00:29:54.840]   complete, funny thing is this is, this is an intentionally stock photo. We kind of, I mean,
[00:29:54.840 --> 00:30:01.400]   look at Sundar's smile. It's so fake and posed. Everybody's posture. Philip's talking to somebody
[00:30:01.400 --> 00:30:05.400]   like the, you know, just a friendly to cover. The whole point of it is clearly to.
[00:30:05.400 --> 00:30:07.320]   Yes, that's that the cargo shorts.
[00:30:07.320 --> 00:30:14.520]   Which is, I love it. That made me very happy. Actually, also Tom pronounced it Sundar.
[00:30:15.080 --> 00:30:19.160]   Yes. Yes. Was that intentional? Do you think? Or is that? Oh, I don't know.
[00:30:19.160 --> 00:30:23.640]   That is what all like white people say when they see. So that is intentional. Because Tom,
[00:30:23.640 --> 00:30:30.840]   as you know, Tom Womscam is Mr. Middle America, stuck in these, all the, with these Manhattan
[00:30:30.840 --> 00:30:39.560]   elites or so-called elites. Anyway, enough of that. But that was hysterical. I look forward to it.
[00:30:39.560 --> 00:30:45.960]   Finger on the pulse. Speaking on the, another, we should probably talk about another big media
[00:30:45.960 --> 00:30:56.280]   turnover, ABC Disney, which acquired 538. I did not know that 538 was Nate Silver's,
[00:30:56.280 --> 00:31:03.480]   at the time, amazing thing. Nate had started kind of in a, in a, in a form of baseball fandom
[00:31:03.480 --> 00:31:08.840]   called Sabre Metrics, which is, it's, it's like, there's a game going on. I don't know. I just see
[00:31:08.840 --> 00:31:14.360]   these stats here. He's like, it's spreadsheets, spreadsheets. But he was brilliant. He's really
[00:31:14.360 --> 00:31:18.760]   brilliant. And if you watch the movie Moneyball, you see how it's changed baseball is this
[00:31:18.760 --> 00:31:23.880]   under Sabre Metrics understanding of what stats matter. And he started applying this
[00:31:23.880 --> 00:31:27.720]   in his models to politics. When was that, Jeff? Was that 2008?
[00:31:27.720 --> 00:31:34.680]   Oh, yes. I think it was the first Obama election. Now, very famously, they got 2016.
[00:31:35.480 --> 00:31:41.800]   Very wrong. Very wrong. And I think the brand, and they led the New York Times down a bad path
[00:31:41.800 --> 00:31:46.520]   in saying, let's just predict the percentage chance of winning or losing, as opposed to the
[00:31:46.520 --> 00:31:51.800]   actual percentages. And, and that's the last time the Times has done that. The number 538,
[00:31:51.800 --> 00:31:56.680]   of course, comes from the number of members of Congress, right? Or no, it's the electoral,
[00:31:56.680 --> 00:32:03.640]   electoral college votes. And so it was always, it was this very nerdy kind of stats focused
[00:32:03.640 --> 00:32:08.280]   look at politics. Remember the times they had a meter. That's what I'm saying. The meter is what
[00:32:08.280 --> 00:32:13.400]   they got rid on after. This was all went. Did the Times own five? Did they buy 538?
[00:32:13.400 --> 00:32:19.240]   They had no, they had a deal with 538 for a few years, where he was kind of exclusive there.
[00:32:19.240 --> 00:32:24.120]   The Times was doing that at the time with blogs. They did it with Freakonomics too. They did it
[00:32:24.120 --> 00:32:32.680]   with various paths. Right. Yeah. And then ABC bought it for 538 for ESPN. And then it kind of split
[00:32:32.680 --> 00:32:38.440]   off from ESPN to do politics and stuff. And then Nate famously decided that he was an expert
[00:32:38.440 --> 00:32:42.200]   in epidemiology and COVID. Yeah, that was really well off the run.
[00:32:42.200 --> 00:32:48.040]   Yeah. And now he's gone. ABC is going to continue the brand.
[00:32:48.040 --> 00:32:56.680]   You'll see C stuff. When 538 started in 2008, I loved it. I read it. And you probably did too.
[00:32:56.680 --> 00:33:00.840]   I read it religiously. It was like, Oh, yeah, yeah, because it was a great, if you want horse race,
[00:33:01.400 --> 00:33:06.520]   coverage of politics. That's the ultimate horse race. I hate. I know. I know. It's
[00:33:06.520 --> 00:33:12.840]   terrible. But and I learned that after 2016, probably not to pay too much attention to it. But
[00:33:12.840 --> 00:33:18.760]   anyway, this is so you're not sad that Nate Silver has moved on.
[00:33:18.760 --> 00:33:28.280]   He's taking the interesting thing is Disney's keeping the brand. He's taking the formulas.
[00:33:29.800 --> 00:33:35.800]   He keeps the the maybe somebody wants it. He's keeping his math.
[00:33:35.800 --> 00:33:43.320]   All of the IP that he invented to do all of this. We got in trouble the last time because he favored
[00:33:43.320 --> 00:33:49.640]   too much. There were polls. I always quote the late James Kerry of Columbia about polls that they
[00:33:49.640 --> 00:33:54.680]   preempt the public discourse. They are meant to measure. They cut it off. And then
[00:33:55.880 --> 00:34:01.000]   that's a very good way to savvy. That's a very good point. You just you start focusing on
[00:34:01.000 --> 00:34:06.040]   who's winning and you stop thinking about what matters. And you put people into binary buckets.
[00:34:06.040 --> 00:34:10.680]   Right. You lose all nuance. That's a very good point. So thank you. James Kerry's brilliant.
[00:34:10.680 --> 00:34:16.280]   I write about it in the Gutenberg brothers. It's available for preorder now. But what happened in
[00:34:16.280 --> 00:34:22.120]   the last election or in the Trump victory was that the polls were being manipulated by the right
[00:34:22.120 --> 00:34:27.000]   way cleverly, smartly. Right. So the polls that Nate put into his average
[00:34:27.000 --> 00:34:33.880]   were kind of messed up. Plus people in the public like to screw with the pollsters. They gave no
[00:34:33.880 --> 00:34:40.600]   they have no credibility and nobody has land. Nobody except me as a landline phone. Right.
[00:34:40.600 --> 00:34:44.520]   Oh, that's not showing us your phone. Do you have a fax machine attached to that?
[00:34:45.320 --> 00:34:56.680]   I used to. So animals are pretty close. We need a new we instead of moral panic have a landline phone.
[00:34:56.680 --> 00:35:04.120]   How about that? So it works. What is what I hear when a dial tone sounds like a kid.
[00:35:04.120 --> 00:35:09.880]   My step mother she still has a landline and a fax machine. That's a dial tone.
[00:35:09.880 --> 00:35:19.880]   Kids. Kids. Do you know what it dial means? All right. I talked to a reporter today from San
[00:35:19.880 --> 00:35:25.240]   Francisco about the Skylab story because it's coming up on an anniversary, I guess. And I sent
[00:35:25.240 --> 00:35:29.000]   something about the composing room at the newspaper at the Chronicle in the examiner. He said,
[00:35:29.000 --> 00:35:35.000]   what's that? What's that? It's no idea. That's where you go either. If you're feeling lightheaded,
[00:35:35.000 --> 00:35:39.720]   AC, they have a little bounce a little lounge there and you can fall on that. You can
[00:35:39.720 --> 00:35:45.400]   pose yourself. Yeah. Oh, okay. No, it's not what it is. Oh, it's not what? Okay. Oh, it's like sure.
[00:35:45.400 --> 00:35:48.120]   I have those days all the time.
[00:35:48.120 --> 00:35:54.920]   Funny I'm going I'm off to the composing room. I haven't like prepared my fainting couch.
[00:35:54.920 --> 00:36:01.480]   No, it's where they don't want to let the lead type, right?
[00:36:02.280 --> 00:36:10.360]   Oh, okay. Yeah. Jeff, I have literally never worked at a publication that had in-house printing.
[00:36:10.360 --> 00:36:17.800]   No, I'm sure not. I was either by either. You're the only one. She also just say,
[00:36:17.800 --> 00:36:21.000]   Hey, dude, I'm not that old. That's what she said.
[00:36:21.000 --> 00:36:28.120]   Well, yeah. I'm like, like when I went to journalism school, I learned on like actual computer
[00:36:28.120 --> 00:36:36.680]   programs. So yeah, I'm a Jetson of the journey. Exactly. Now, was that computer program Quark?
[00:36:36.680 --> 00:36:43.400]   Yes, it was. Oh, wow. Old timer there. Hey, let's take a little break. There's more to talk about.
[00:36:43.400 --> 00:36:47.960]   I am so happy to be back. You guys, I missed you. We are happy to have missed you. You're
[00:36:47.960 --> 00:36:53.880]   your guys did a great, great job. So tell me, so did it was it Jason Howell last week?
[00:36:54.600 --> 00:36:58.520]   The last two weeks on Micah before that and Micah the first week. Okay. Thank you, Jason.
[00:36:58.520 --> 00:37:03.880]   Thank you, Micah. You know, it actually is great for me. It means that I can go on vacation and
[00:37:03.880 --> 00:37:08.440]   and they will hold down the fort. So I really do. I'm very grateful to them. Thank you.
[00:37:08.440 --> 00:37:13.720]   Our show today brought, but I did miss you guys and I'm glad to be back. I mean, if I could be
[00:37:13.720 --> 00:37:20.120]   in Rome right now, standing up and drinking espresso, I might be, but since I'm not,
[00:37:20.760 --> 00:37:26.760]   this is my second. I mean, you could be there and miss us at the same time. I did. I did. I thought
[00:37:26.760 --> 00:37:34.040]   Thursday afternoon, I thought, I wonder what the little people are doing. Our show today
[00:37:34.040 --> 00:37:42.520]   brought to you by, no, I didn't. Zip recruiter. Actually, we were, we, this is something that we
[00:37:42.520 --> 00:37:49.160]   always worry about. Lisa, of course, runs the company and she knows, we know anybody who has
[00:37:49.160 --> 00:37:55.560]   a company knows the company is the people. That's all that matters is the people. And if somebody leaves,
[00:37:55.560 --> 00:38:01.400]   I don't want to say it's disaster, but it's all hands on deck time. It means you've got to
[00:38:01.400 --> 00:38:05.800]   cover their duties and it means while you're doing that, you got to go out and find someone
[00:38:05.800 --> 00:38:10.120]   to replace them and you darn well better find somebody that's at least as good, if not better.
[00:38:10.120 --> 00:38:16.840]   Whether you're starting a new business, you're growing an existing business, if you want to be
[00:38:16.840 --> 00:38:21.240]   successful, you got to get the right people, right? The most talented people, the people who are going
[00:38:21.240 --> 00:38:27.400]   to fit your culture, the little fit in, that's where Zip recruiter comes in. And right now,
[00:38:27.400 --> 00:38:35.320]   you can try it for free zip recruiter.com/twig. Think about what new business you would start.
[00:38:35.320 --> 00:38:41.480]   I don't know. I'm thinking, you know, food truck might be kind of fun, get my son and
[00:38:41.480 --> 00:38:47.000]   we could make some salt hanks sandwiches drive around the country or maybe you'd want to give
[00:38:47.000 --> 00:38:53.640]   back, start a charity. Just don't start a podcast network, just a little word to the wise. Just
[00:38:53.640 --> 00:38:59.480]   maybe think of something else. However, no matter what you're doing, whatever your next business is,
[00:38:59.480 --> 00:39:03.400]   whatever your current business is, you got to let Zip recruiter help you hire. That's what we do.
[00:39:03.400 --> 00:39:08.440]   And it is such a relief. Somebody says, hey, here's my notice. We're going to, I'm moving.
[00:39:09.320 --> 00:39:14.440]   Lisa's, oh, okay. And we post on Zip recruiter, usually at breakfast, right? First thing in the
[00:39:14.440 --> 00:39:22.120]   morning, that's when we get the news. But what's so awesome about Zip recruiter is within a very
[00:39:22.120 --> 00:39:27.880]   quick period of time, we're going to get some really good qualified candidates. Now, how does it
[00:39:27.880 --> 00:39:32.440]   work? Well, first of all, you're posting a 100 plus job boards, you're posting all over the place.
[00:39:32.440 --> 00:39:36.600]   So you're casting the widest net. And by the way, sometimes people say, well, I don't know if I want
[00:39:36.600 --> 00:39:40.760]   that. What am I going to do with all those phone calls and emails and resume? No, don't worry. It
[00:39:40.760 --> 00:39:45.720]   all goes into the Zip recruiter interface. They reformat the resumes to make them uniform. So it's
[00:39:45.720 --> 00:39:51.720]   easy to scan them. You have a qualifying questions, true, false, yes, no, even essay questions that
[00:39:51.720 --> 00:39:58.920]   can eliminate people who just don't fit. You also, of course, have this amazing Zip recruiter matching
[00:39:58.920 --> 00:40:04.920]   technology. So cool. This really is the secret sauce. They will look through their million plus
[00:40:04.920 --> 00:40:10.440]   resumes, current resumes on file and find people whose qualifications fit what you're looking for.
[00:40:10.440 --> 00:40:16.360]   Then suggest them to you, you can look at them and say, I think we should invite these three people.
[00:40:16.360 --> 00:40:22.120]   Those people now, because you've invited them personally, are they're already thrilled. They're
[00:40:22.120 --> 00:40:27.320]   going to follow through. They're going to give you a great interview. They're more likely to apply
[00:40:27.320 --> 00:40:32.200]   because you asked them. Zip recruiter also has some nice little features because there's people
[00:40:32.200 --> 00:40:38.520]   going through Zip recruiter postings all the time. They let you add labels. Nowadays, some of the
[00:40:38.520 --> 00:40:43.720]   labels that are really good are, for instance, remote. You can remote work. A lot of people are
[00:40:43.720 --> 00:40:49.880]   looking for that. Training provided be a good one. They have these little stickers and people who
[00:40:49.880 --> 00:40:53.480]   are looking for jobs might be looking for that right on entry level. Oh, they're going to train
[00:40:53.480 --> 00:40:59.800]   me. That's good. Urgent. We'll put that in all of them. It's always urgent. Let your jobs stand
[00:40:59.800 --> 00:41:05.960]   out among all the other listings. Let Zip recruiter fill all your roles with the right candidates.
[00:41:05.960 --> 00:41:10.760]   We're not alone, by the way. Four out of five employers who post a Zip recruiter get a quality
[00:41:10.760 --> 00:41:16.760]   candidate within the first day on day one. I would say for us, it's almost always within an hour or
[00:41:16.760 --> 00:41:21.720]   two. It's just like Lisa does it at breakfast before lunch. She's going, "Oh, I got one. Oh,
[00:41:21.720 --> 00:41:26.360]   I got another one." For her, it's such a relief to know, "Oh, I'm going to be able to fill this position.
[00:41:27.000 --> 00:41:34.520]   See for yourself. Go to our special web address, Zip recruiter, and try it for free, zipprecruiter.com/twig."
[00:41:34.520 --> 00:41:44.680]   Again, zipprecruiter.com/twigz. Zip recruiter. The smartest way to hire. We are very grateful
[00:41:44.680 --> 00:41:49.240]   for Zip recruiter. Thank you. Thank you for sponsoring the show too. We appreciate that.
[00:41:49.240 --> 00:42:04.680]   Zip recruiter.com/twigz. I saw something I thought, "Oh, this will be a good one."
[00:42:04.680 --> 00:42:09.320]   What do you want, Jeff? What do you like? What are you thinking? I know you're used to a democracy.
[00:42:09.320 --> 00:42:11.960]   I don't want to pull the rug out from under you too fast.
[00:42:14.840 --> 00:42:22.680]   How about the dead people subscribing to Twitter blue? Elon was so shocked that nobody had the
[00:42:22.680 --> 00:42:28.520]   checkmark that he gave it. Well, he says, "I paid," which he obviously didn't. I mean,
[00:42:28.520 --> 00:42:34.680]   I guess it's okay to lie now and just like blatantly, "Oh, yeah, I paid eight bucks for LeBron."
[00:42:34.680 --> 00:42:39.800]   Even King has an actionable libel case against Elon. Well, that's an interesting one because
[00:42:39.800 --> 00:42:46.040]   when you go to Twitter, it says, "This person paid for Twitter blue and gave their phone number."
[00:42:46.040 --> 00:42:51.480]   And Stephen King said, "Well, I absolutely did not." So that's an implied endorsement. FDC, hello.
[00:42:51.480 --> 00:42:57.000]   Right. It's eight bucks. No, I'm not that idiotic. I didn't do that. No.
[00:42:57.000 --> 00:43:01.800]   We can be pretty sure, however, that Anthony Bourdain did not pay for his.
[00:43:01.800 --> 00:43:07.720]   Nor did Kobe Bryant. Shogi. He also put on. Nor Chadwick Boseman, your friend,
[00:43:08.200 --> 00:43:15.000]   and these people passed, but they all got blue checks. Thank you, Elon.
[00:43:15.000 --> 00:43:21.800]   Well, that may be just good PR because you really don't want someone impersonating someone
[00:43:21.800 --> 00:43:27.080]   who's dead. Well, that's a good point, actually. That's the right thing to do, I guess, huh? Yeah.
[00:43:27.080 --> 00:43:33.080]   But the blue check is me and listening. Chrissy Teigen, who is actually a very talented Twitter,
[00:43:33.720 --> 00:43:40.440]   she can stir out the pot like nobody says, "You still tweeting?" Yeah. Wait, I'm trying. I'm crying.
[00:43:40.440 --> 00:43:42.840]   They're giving them for punishment now.
[00:43:42.840 --> 00:43:53.960]   When John Favreau, Boomone getting a blue check, Teigen advised him that changing his account
[00:43:53.960 --> 00:43:58.840]   handle would make it disappear. This, by the way, from the Washington Post, Michael Jackson,
[00:44:00.200 --> 00:44:06.520]   Mac Miller, John McCain, Kirstie Allie, Barbara Walters, all got blue checks. But
[00:44:06.520 --> 00:44:10.600]   I think you raised a good point. I think it's reasonable for them to say, "Hey,
[00:44:10.600 --> 00:44:15.400]   these people aren't going to pay for it." Those people, it's appropriate, really. It's the people
[00:44:15.400 --> 00:44:21.240]   who are alive. Oh, Jamal Khashoggi, that's kind of not so. That's a little queasy making.
[00:44:22.840 --> 00:44:29.240]   The people who are alive who were forced to have it with the implied endorsement,
[00:44:29.240 --> 00:44:32.360]   I think that's problematic. I really do.
[00:44:32.360 --> 00:44:41.240]   Enough. You said you were going to do more Twitter. You did it. I didn't make you. I had my
[00:44:41.240 --> 00:44:52.200]   two non-extently. You just did it. Okay, I like this one. This is kind of interesting,
[00:44:52.200 --> 00:44:56.520]   and I think we might get a little conversation going. Do you remember? I think we interviewed her,
[00:44:56.520 --> 00:45:03.560]   and I did not like it. A woman named, what was it, Twengie? How do you pronounce it? Oh, no.
[00:45:03.560 --> 00:45:10.280]   I didn't like her. Jean Tweng. I don't either. She wrote a book that said,
[00:45:10.280 --> 00:45:17.320]   this is back in 2017. She wrote I-Gen. I-Gen, and we interviewed her. She basically said,
[00:45:17.320 --> 00:45:21.560]   "This whole generation's lost because of social media and screens."
[00:45:21.560 --> 00:45:30.120]   This has been a continued conversation. I think Dana Boyd probably debunked it, I would guess.
[00:45:32.440 --> 00:45:38.600]   When Twengie looked at, she studies generational trends at San Diego State,
[00:45:38.600 --> 00:45:42.760]   when she looked at mental health metrics for teenagers, and this is back in 2012,
[00:45:42.760 --> 00:45:50.520]   according to NPR, what she saw, shocked her. In all my analyses of generational data,
[00:45:50.520 --> 00:45:57.000]   some reaching back to the 1930s, I had never seen anything like it. She warned of a mental health
[00:45:57.000 --> 00:46:03.800]   crisis on the horizon. Fast forward 10 years, and we're seeing now, people say,
[00:46:03.800 --> 00:46:10.440]   the young people today, especially young women today, are more depressed, more detached,
[00:46:10.440 --> 00:46:21.160]   lonelier, more anxious than ever before. You've got a teenager, Stacey. What are your thoughts?
[00:46:23.160 --> 00:46:30.120]   I think it's silly to ascribe all of this to social media. I will say that my team's social
[00:46:30.120 --> 00:46:38.760]   life is so different from mine. Part of that is COVID. For over a year, they were isolated.
[00:46:38.760 --> 00:46:44.840]   But even before that, this generation of kids has historically been so over-scheduled
[00:46:44.840 --> 00:46:50.600]   that they never hang out in person. Even now, they don't really hang out in person.
[00:46:52.360 --> 00:46:59.080]   It's probably once a month, maybe twice a month, that my child actually meets in real life outside
[00:46:59.080 --> 00:47:08.920]   of school with friends. I think that probably has a lot. I'm not saying social media is part of
[00:47:08.920 --> 00:47:15.160]   that. At least they're having connections with people, I guess. There are implications of pile
[00:47:15.160 --> 00:47:20.360]   on bullying and things like that. I also think a lot of it's like, if you try to make plans with
[00:47:20.360 --> 00:47:27.640]   somebody, they're in club sports, so they're never available, or they're part of some team or
[00:47:27.640 --> 00:47:32.040]   theater or some part of school, then they're at least hanging out possibly in person with other
[00:47:32.040 --> 00:47:39.480]   people. But it is high drama to try to get your kids together with other kids.
[00:47:39.480 --> 00:47:46.520]   I don't think anybody denies that it's hard right now to be a teenager.
[00:47:46.520 --> 00:47:52.840]   But I think to say it's social media or screen time is over simplistic. There are other things
[00:47:52.840 --> 00:47:56.680]   that you say over scheduling. But you could trace that back to stranger danger too.
[00:47:56.680 --> 00:48:04.120]   This bogus promotional thing that, "Oh God, don't let your kids out of the house. They're going to
[00:48:04.120 --> 00:48:11.320]   get assaulted." Really cold. People are all latchkey kids. I feel like, yeah, at the same time,
[00:48:11.320 --> 00:48:14.920]   I was stranger-danger'd. I was also like, no one was watching me.
[00:48:14.920 --> 00:48:22.920]   When I was a kid, you went out to the street and you played. We did that.
[00:48:22.920 --> 00:48:28.440]   What I was like, we just went to the mall and played. But I think even that was constrained over time.
[00:48:28.440 --> 00:48:33.640]   Exactly. No, that seemed to be evil too. Yeah, you just said, no, don't go out. We don't know.
[00:48:33.640 --> 00:48:39.640]   Some stranger's going to abduct you. I'm not saying it's all of it. I'm not saying social
[00:48:39.640 --> 00:48:45.800]   media is not part of it. But there are so many possible root causes. Society's changed a lot.
[00:48:45.800 --> 00:48:49.560]   And then the other thing, and Jeff and I will always, I know, bring this up, which is,
[00:48:49.560 --> 00:48:55.080]   when we were kids, it was rock and roll and Rolling Stone magazine. I mean, there's always
[00:48:55.080 --> 00:49:00.200]   something when the old generation- I like Rolling Stone. Oh, I know. But I'm just saying,
[00:49:00.200 --> 00:49:04.840]   when the younger generation is disconnected from the older generation, that we called it the
[00:49:04.840 --> 00:49:11.240]   generation gap. Well, that's Twingy's new book now. It's called Generations.
[00:49:11.240 --> 00:49:17.240]   Yeah. She's doing all that, all that, that, that generation stuff. So I, so before my father died,
[00:49:17.240 --> 00:49:26.760]   Joe Scarborough was praising the Utah bill or law now taking kids off of social media entirely
[00:49:26.760 --> 00:49:30.600]   and getting to raise it. And so I went on Twitter and I said, oh no, now Joe and me
[00:49:30.600 --> 00:49:35.320]   are praising this. And Joe came on and said, you know, damn it, Jarvis, there's proven science
[00:49:35.320 --> 00:49:40.040]   and you're, you know, just chilling for the technology companies are.
[00:49:40.040 --> 00:49:44.680]   So I said, I'm going to come back and give you some data. So I have a long thread in there,
[00:49:44.680 --> 00:49:51.320]   line 60, which I did for Joe, but I'll do for here now, which has a lot of data and many studies
[00:49:51.320 --> 00:49:58.280]   that directly respond to both Twingy and her partner in crime, Jonathan Haidt from the Atlantic.
[00:49:58.280 --> 00:50:03.240]   Do you think she cherry picked a little bit? Oh yeah. And everybody does. I can't do it.
[00:50:03.240 --> 00:50:09.640]   I'm doing it right here. Yeah. But Amy Orbin, who's, who's the best, I think, at, at arguing back,
[00:50:09.640 --> 00:50:15.000]   did some important research down a few, you'll find it. Oh, that's the wrong one. I don't know
[00:50:15.000 --> 00:50:20.440]   where you went. If you go to my, like, we'll see it. Should I go to his reply to you?
[00:50:20.440 --> 00:50:26.840]   No, just go back to line 60 and click there. That's what I did. No, now go back. Okay, now,
[00:50:27.560 --> 00:50:32.840]   scroll down now. Oh, don't show this thread. See, I don't understand how this Twitter thing works.
[00:50:32.840 --> 00:50:37.240]   This is the thread. So the thread. Oh, this is the thread. You're probably on an apple,
[00:50:37.240 --> 00:50:41.160]   so you're screwling the wrong way. Get confused every time you scroll. Oh, because I went, this is
[00:50:41.160 --> 00:50:47.480]   the link. It's this tweet. Hold down. But this tweet refers to this tweet, which has a show this
[00:50:47.480 --> 00:50:52.440]   thread. This is the thread. But why does it say show this thread on this tweet? Well, because that's
[00:50:52.440 --> 00:50:58.200]   Twitter. Don't blame me. All right. One more. One more. One more. Keep going. Keep going. There.
[00:50:58.200 --> 00:51:04.920]   Amy Orban, a leading researcher in the field, studied large social data sets with 355,000
[00:51:04.920 --> 00:51:09.960]   subjects found, quote, the association of well-being with regularly eating potatoes
[00:51:09.960 --> 00:51:16.920]   was nearly as negative as the association technology use. And by the way, wary glasses is
[00:51:16.920 --> 00:51:21.160]   worse the technology use because don't we know all of us who were called for eyes at school and
[00:51:21.160 --> 00:51:28.680]   traumatized. This is in nature.com, which is a fairly reliable or urban leading person. She
[00:51:28.680 --> 00:51:35.480]   also found in the next one that that social media use is not in itself a strong predictor of life
[00:51:35.480 --> 00:51:45.400]   science. So when 20, so let's let's go back to the NPR thing because 20 has got a lot of data.
[00:51:46.840 --> 00:51:53.960]   For instance, 22% of 10th grade girls spend seven or more hours a day on social media,
[00:51:53.960 --> 00:51:59.480]   which means they're doing little else and sleeping going to school and engaging with social media.
[00:51:59.480 --> 00:52:06.920]   Screen time is cutting the kids sleep. The percentage of 10th and 12th graders who slept
[00:52:06.920 --> 00:52:11.720]   seven or fewer hours each night rose from a third to nearly one half. But again, is that social
[00:52:11.720 --> 00:52:17.320]   media or the fact that got zero period so that they can take their crew classes so they can get
[00:52:17.320 --> 00:52:22.840]   into college, which they can ill afford. Right. Right. Right. And if they're if they're depressed
[00:52:22.840 --> 00:52:27.800]   and under stress and anxiety, talk about the social stress of the lunchroom, talk about the
[00:52:27.800 --> 00:52:31.960]   fact that their control over young women's bodies has been taken away from them, talk about the
[00:52:31.960 --> 00:52:36.760]   fear that they're going to be shot at school, talk about the environment of falling down in their
[00:52:36.760 --> 00:52:42.440]   future generation. There's plenty of cause for them to be anxious. Hundreds of thousands more
[00:52:42.440 --> 00:52:51.480]   college students depressed. Yeah. I think actually, I mean, there are obviously all levels of maturity,
[00:52:51.480 --> 00:52:59.880]   but the kids that I see through my child's school and my child, they're thoughtful
[00:53:00.440 --> 00:53:08.920]   individuals. And they are, they, I mean, many of them are anxious, but I honestly, I can't
[00:53:08.920 --> 00:53:16.040]   say to them, well, that's crazy. I mean, this is a generation that is going to be worse off than
[00:53:16.040 --> 00:53:21.640]   their parents mostly crying out loud there. They know the climate change is going to clobber them
[00:53:21.640 --> 00:53:28.440]   and their kids. I'd be anxious too. I'm glad I'm going to be dead before 2050 because it's not going
[00:53:28.440 --> 00:53:34.040]   to be good. Neil Lisa, and I'd like to ask a generational question here. I'm curious about this.
[00:53:34.040 --> 00:53:42.440]   When I grew up, no one I knew would, if they did, would say out loud that they went to a shrink,
[00:53:42.440 --> 00:53:50.680]   we didn't talk about medicine. We didn't talk about leading therapy. We didn't have any discussion
[00:53:50.680 --> 00:53:55.240]   of that. Especially in the black community. Yes, that's right. That people are more
[00:53:55.240 --> 00:54:00.840]   willing and morphiosis to talk about it. Yeah. Because Tony Soprano, it really, it was a hard
[00:54:00.840 --> 00:54:09.640]   thing for him to admit. Yeah. Yeah. You could have lost his gig from that. Yeah. No, I think you're
[00:54:09.640 --> 00:54:15.640]   right, but now it's okay, right? Yeah, no, our kids. I go to two shrinks. I'm thinking about a third.
[00:54:18.040 --> 00:54:26.920]   It doesn't help. I still, I agree with you, Miss LePorte, that is not the only thing. It is a
[00:54:26.920 --> 00:54:36.280]   combination of things. For me, I think it's a combination of word of parents. I know this country,
[00:54:36.280 --> 00:54:43.000]   in particular, is full of really, really, craptastic parents. That puts the children at a disadvantage
[00:54:43.000 --> 00:54:49.880]   right out the gate. Then you throw in these different platforms, be it Instagram, TikTok,
[00:54:49.880 --> 00:54:56.200]   Facebook, what have you, that has a lot of things that are sensationalized and are false. I can get
[00:54:56.200 --> 00:55:01.480]   why children or teenagers or what have you can go through depression because they feel like they're
[00:55:01.480 --> 00:55:08.360]   missing out or should be living up to that standard that they see on this screen. But again, that
[00:55:08.360 --> 00:55:16.200]   stuff could, you could fight that a little bit with some decent parenting or mentors. A lot of
[00:55:16.200 --> 00:55:22.280]   times, I just speaking from my own experience, I see stuff happen in the communities back in Carolina.
[00:55:22.280 --> 00:55:27.160]   The very first thing that popped out of my mouth was, "Where is mom and dad?"
[00:55:27.160 --> 00:55:35.160]   Some of the stuff could be taught at home. I don't think the parents are getting enough credit for
[00:55:35.160 --> 00:55:38.760]   some of the things that our kids are going through these days.
[00:55:38.760 --> 00:55:47.480]   Let me ask you this. Jeff, in your tweet, thread, and Stacy, in your experience, and your experience,
[00:55:47.480 --> 00:55:52.440]   are we going to stipulate that your kids are more troubled now than before?
[00:55:57.080 --> 00:56:08.280]   Y'all going to go ahead? Because I have thoughts. Again, I think kids today are more troubled than
[00:56:08.280 --> 00:56:13.000]   before because of... Well, I'm not asking because. No, no, I'm not saying because. That's the next
[00:56:13.000 --> 00:56:20.680]   part of the question. First part is, though, do we agree that there is a problem? Yes. I agree.
[00:56:21.400 --> 00:56:29.160]   I think the kids are struggling, but I think the kids are actually... My kid and their friend group
[00:56:29.160 --> 00:56:35.800]   is so much better and more ambitious and more considerate and empathetic than my friends and I
[00:56:35.800 --> 00:56:42.840]   ever were. I guess what I'm asking is, what's the dispute? Is the dispute the kids are in
[00:56:42.840 --> 00:56:50.200]   trouble or is it a dispute? What caused it? It's clear that it's foolish to say, "Oh, this is what
[00:56:50.200 --> 00:56:54.520]   did it?" They used to say it was violent video games and violent movies. I mean, there are many,
[00:56:54.520 --> 00:56:59.400]   many, many possible causes. Maybe all of them involved. Well, that's why I asked my question.
[00:56:59.400 --> 00:57:03.000]   If people are more willing to talk about mental health today, does that mean mental health is worse?
[00:57:03.000 --> 00:57:07.160]   Right, exactly. That's legit. That's legit. Healthier at dealing with it.
[00:57:07.160 --> 00:57:12.520]   And autism is to cause these diagnoses in company. Autism today is diagnosed at a much higher rate.
[00:57:12.520 --> 00:57:16.680]   Is that because autism suddenly has appeared? No, it's because of Tylenol.
[00:57:17.640 --> 00:57:23.800]   Or is it because of an environmental factor? Or is it much more likely not Tylenol? Although,
[00:57:23.800 --> 00:57:31.080]   who knows? There was just a study that blamed autism on Tylenol. I know. And you don't hug your
[00:57:31.080 --> 00:57:35.880]   kids enough and blah, blah, blah. But really, probably the case is that we just didn't have the term
[00:57:35.880 --> 00:57:41.560]   and we didn't die. I do think that the pressure on kids today, I mean, how many schools did you
[00:57:41.560 --> 00:57:47.160]   and I apply to and you got into Yale versus seven schools kids apply? I got in all of them, but one,
[00:57:47.160 --> 00:57:55.560]   Harvard, I hate those sons of bitches. The social pressure, the political pressure,
[00:57:55.560 --> 00:57:59.480]   I think that there is worse pressure on kids. I think there is more cause. And the economic
[00:57:59.480 --> 00:58:08.600]   unwinding. Yeah, I don't blame them. I look at my kids, 28 and 30. The economic, they couldn't buy a
[00:58:08.600 --> 00:58:15.160]   house. They can't, they don't have a job they're going to have for life. It's completely changed.
[00:58:16.040 --> 00:58:22.440]   And the internet actually shares a lot of that. You want to feel anxious, like scroll through
[00:58:22.440 --> 00:58:30.680]   your kids Twitter or Twitter, TikTok feed. They're like, I have $500,000 in student debt. I didn't
[00:58:30.680 --> 00:58:34.520]   get into any of my colleges that I wanted to. I can't buy a house. I'm not going to have any
[00:58:34.520 --> 00:58:39.000]   children, even though I want them. Because I mean, I just got a hospital bill for $80,000.
[00:58:39.000 --> 00:58:42.520]   Well, there's another one. Yeah, medical bankruptcy. There's another one.
[00:58:44.120 --> 00:58:51.720]   I would be terrified if I were 18. I completely understand that. There's a lot of stuff.
[00:58:51.720 --> 00:58:59.880]   Kids can be depressed about that stuff because of the situations that we put them in as parents,
[00:58:59.880 --> 00:59:08.120]   in my opinion. I know I've never shied away, excuse me, about finances and things like that in this
[00:59:08.120 --> 00:59:14.840]   household. Because I don't want my children to think that things just come for free or you just get
[00:59:14.840 --> 00:59:21.160]   handouts and things like that. Everything has a consequence. Everything has a price. There's,
[00:59:21.160 --> 00:59:29.640]   yeah, we have free lunches in school. But I tried to explain to them that free lunch is
[00:59:29.640 --> 00:59:37.480]   costing somebody else somewhere else. And I need them to understand that. And so, yeah, every now
[00:59:37.480 --> 00:59:42.200]   and then, they can be quite anxious about, man, I don't want to have all of this debt for college
[00:59:42.200 --> 00:59:46.840]   because college is going to cost a quarter of a million dollars at some point. And I don't want
[00:59:46.840 --> 00:59:51.160]   that hanging over my head. So yeah, I should probably think about getting myself in a better
[00:59:51.160 --> 00:59:58.520]   position. And yeah, that can be quite anxious. But that's unfortunately, that is life right now.
[00:59:58.520 --> 01:00:01.640]   And I've also respected greatly how you talk about mental health.
[01:00:03.720 --> 01:00:09.320]   And use this platform to do so. Yeah, I don't shy away from it, you know, because again,
[01:00:09.320 --> 01:00:15.560]   a few minutes ago, as you were saying from a generational standpoint, you didn't talk about it.
[01:00:15.560 --> 01:00:23.480]   And then I can tell you for a fact, black folks did not talk about depression. And when depression
[01:00:23.480 --> 01:00:30.760]   or anxiety or anything like that came up, you were called, quote, crazy, or you were told, go
[01:00:30.760 --> 01:00:37.480]   especially in the South, go and pray it away or something like that. And that's not cool.
[01:00:37.480 --> 01:00:44.520]   You know, people can have chemical imbalances that can lead to, you know, mental health concerns.
[01:00:44.520 --> 01:00:49.640]   So I always done a great job with your boys. You've parented them very well. But I think
[01:00:49.640 --> 01:00:53.560]   I'm trying. You've fallen to it. You've fallen a little bit of a trap that a lot of parents
[01:00:53.560 --> 01:01:00.520]   whose kids have done well fall into. And I don't know if it's just your parenting. I think you
[01:01:00.520 --> 01:01:05.160]   kind of lucked out. I think there are plenty of very good parents whose kids are very troubled,
[01:01:05.160 --> 01:01:09.080]   very concerned. I'm including myself in this. I'm sure Jeff, you probably include yourself.
[01:01:09.080 --> 01:01:13.560]   It's not that we were bad parents. You lucked out. You did well. But I don't think that's good.
[01:01:13.560 --> 01:01:20.120]   No, no, no, no, no. Good parent isn't the only problem by any means. No, no, it's not. It's not.
[01:01:20.120 --> 01:01:27.320]   But I do believe that. Well, a couple of things. I do believe that parenting helps. And this is
[01:01:27.320 --> 01:01:33.320]   going to sound very selfish. But I also believe having daddy in the picture helps.
[01:01:33.320 --> 01:01:37.960]   I hate that there are so many single mothers out there.
[01:01:37.960 --> 01:01:46.760]   And just look at statistics from the black side of things. Black news, we had to do better.
[01:01:46.760 --> 01:01:51.560]   We got to stay in the picture. There's a, I mean, yes. Yes. And this is a big conversation,
[01:01:51.560 --> 01:01:55.800]   I know, in the black community. But you could also say, and what happened to religion,
[01:01:56.360 --> 01:02:00.200]   you know, we'll look at the divorce rate. I mean, there, we're in a different world.
[01:02:00.200 --> 01:02:04.680]   And there are many, many things. I love Taylor Lawrence's response. You quote this in your tweet,
[01:02:04.680 --> 01:02:11.240]   thread. Taylor says, people are like, why are kids so depressed? It must be their phones.
[01:02:11.240 --> 01:02:15.640]   But never mentioned the fact that we're living in late stage capitalist hellscape during an
[01:02:15.640 --> 01:02:21.240]   ongoing deadly pandemic with no social safety net as climate change cooks the world. Yeah,
[01:02:21.240 --> 01:02:27.400]   there are a few things to worry about. Just a few right below that, the Rust-Outfit column in the
[01:02:27.400 --> 01:02:34.280]   New York Times, you know, blames secularization, blames cancel culture. It's a pure political agenda
[01:02:34.280 --> 01:02:40.280]   right to find the things that are screwing up kids. And on the left, I'm going to blame
[01:02:40.280 --> 01:02:46.680]   billionaires. It's billionaires fault. That's who it is. Much succession. So I mean, look,
[01:02:46.680 --> 01:02:53.800]   fair share. There's a lot of reasons. So that's why I asked the question. Do we agree that there's a
[01:02:53.800 --> 01:02:59.560]   mental health crisis among young people? I agree. Oh, hardly. And then the next question is, well,
[01:02:59.560 --> 01:03:02.360]   what caused it? I don't know, Stacy, Stacy, do you agree with the promise?
[01:03:02.360 --> 01:03:07.000]   I do agree that there's a mental health crisis among young people. I would even say that mental
[01:03:07.000 --> 01:03:12.840]   crisis extends up to even millennials. Yeah, like it's not just teenagers. Oh, my kids are
[01:03:12.840 --> 01:03:21.400]   millennials. I'll vouch for that. The lack of the economic precariousness.
[01:03:21.400 --> 01:03:27.000]   I mean, we've known that was stressful for a long time looking at, you know, I'll say
[01:03:27.000 --> 01:03:31.960]   black communities or other communities that have historically been unable to access economic
[01:03:31.960 --> 01:03:39.240]   privilege, right? Now everyone's kind of getting into that place. And that's
[01:03:42.200 --> 01:03:45.720]   we're all going to be there. And it's scary. Yeah.
[01:03:45.720 --> 01:03:54.520]   Well, anyway, so Leo, when I saw that gene twangy,
[01:03:54.520 --> 01:03:59.320]   Leo, because when I saw the rundown, I thought, Oh God, get my blood pressure. No, that's what
[01:03:59.320 --> 01:04:04.280]   that's why I put in the rundown. I am looking for things to surprise me to get your blood pressure.
[01:04:04.280 --> 01:04:08.520]   No, no, I was this was a great conversation. I think this is an important conversation.
[01:04:09.400 --> 01:04:14.600]   And you're right. It's easy for I understand why Joe Scarborough said, you know, hey, you technology
[01:04:14.600 --> 01:04:20.920]   guys, you're defending technology. I understand why they say that. But honestly, it's not just
[01:04:20.920 --> 01:04:24.840]   defend technology is to point out there are a lot of new ones. Yeah, there's a lot of new ones to
[01:04:24.840 --> 01:04:29.960]   it. And then all of this is to say there is more that the platform should be doing
[01:04:29.960 --> 01:04:36.360]   for young people for for content for lots of things. But to well, I'm no and you know me. I'm
[01:04:36.360 --> 01:04:40.440]   no fan of any of these social media platforms, by the way, except the mass.
[01:04:40.440 --> 01:04:44.200]   But the Utah laws ridiculous today, we don't have the rundown because I didn't bother because I
[01:04:44.200 --> 01:04:49.160]   saw this. I thought I was going to be an overdose. But today, bipartisan group just this afternoon
[01:04:49.160 --> 01:04:54.840]   announced in legislation to legally forbid children under 13 from being anywhere on
[01:04:54.840 --> 01:05:01.080]   social media and to forbid the use of this is what's ridiculous of any algorithm because
[01:05:01.080 --> 01:05:09.560]   algorithms are bad on on anybody up to 18. And our friend near Weiss Blatt put up a really good piece
[01:05:09.560 --> 01:05:15.160]   on on tech meme, which I don't think I put in the rundown where she said everything that Tristan
[01:05:15.160 --> 01:05:20.520]   Harris did against social media is all this evil. Just like like fear for fear is now transferring
[01:05:20.520 --> 01:05:27.160]   that to AI. So from social media to algorithms to AI, it's a continuum of ant ant get ready,
[01:05:27.160 --> 01:05:31.240]   get ready. I'm going to say it. I'm going to say it. Moral panic about this.
[01:05:31.240 --> 01:05:36.040]   Ah, yeah, in dealing with the underlying problems.
[01:05:36.040 --> 01:05:40.600]   Well, that's because if we dealt with the underlying problems, we'd have to like
[01:05:40.600 --> 01:05:45.960]   fix the world higher society. No, I was going to say, I mean,
[01:05:45.960 --> 01:05:57.000]   I don't know. I'm like, I don't know how we do this because we've enabled, we've put corporate
[01:05:57.560 --> 01:06:03.480]   well being above societal well being put individual well being above societal well being.
[01:06:03.480 --> 01:06:10.680]   And we've basically, we're going to just ride that train to the very end and we're kind of getting
[01:06:10.680 --> 01:06:15.720]   close, I feel it'll be interesting. Yeah, by the way, runs make an interesting opportunity to
[01:06:15.720 --> 01:06:25.400]   change things. But I mean, honestly, I think you could add politicians to the cause as well. I
[01:06:25.400 --> 01:06:32.120]   mean, if I were young and I were looking at the disarray of our national polity, I would not have
[01:06:32.120 --> 01:06:38.920]   high hopes. And then what's it look like the 20, 24 elections going to be between two people in
[01:06:38.920 --> 01:06:48.200]   their eighties? Oh, great. That's wonderful. That'll solve it. Those old folks knew. So the bill
[01:06:48.200 --> 01:06:53.800]   you were talking about unveiled today, the protecting kids on social media act is bipartisan,
[01:06:54.680 --> 01:07:04.360]   created by Hawaii, Senator Brian Schatz, a Democrat, Tom Cotton, a wonderful Republican, Chris Murphy
[01:07:04.360 --> 01:07:12.520]   of Connecticut, Katie Britt, these are these is left and right. This is these, you know,
[01:07:12.520 --> 01:07:17.160]   down their cause they can agree on all the internet. Common cause, it's all the internet.
[01:07:17.160 --> 01:07:20.760]   This, by the way, speaking of parent, basically up to the parent to decide.
[01:07:22.520 --> 01:07:28.120]   You know, I go back to Dana Boyd, she grew up in some small Pennsylvania town feeling like a
[01:07:28.120 --> 01:07:31.720]   freak and weirdo. And it was because of the internet, a connector that she could find out that she
[01:07:31.720 --> 01:07:38.600]   wasn't alone. She was freaked. She was brilliant. And it's up to parents to decide how their children
[01:07:38.600 --> 01:07:44.280]   should be doing this. But it's like, it's like decreeing that no kid can be outside alone in your
[01:07:44.280 --> 01:07:52.440]   backyard anymore. Men as men as quarterly results came out at market close,
[01:07:52.600 --> 01:08:01.720]   which was a little while ago, third Q one revenue up 3%, revenue up 3%, how income? Well, okay,
[01:08:01.720 --> 01:08:10.120]   revenue up income down. Get ready for this. Stand back. 24%. That's a big drop in.
[01:08:10.120 --> 01:08:15.480]   Right now it's for firings or? Yeah, I have to look at the details. Year over year,
[01:08:16.200 --> 01:08:24.040]   the reality labs unit, the metaverse unit, Q one revenue down. 51% year over year.
[01:08:24.040 --> 01:08:29.160]   Are they going to change the name of the company again? Operating loss, get ready. 35% year over
[01:08:29.160 --> 01:08:36.760]   year. Last year, remember, they lost $13.7 billion. And they're on track to lose even more this year.
[01:08:36.760 --> 01:08:41.240]   But they're destroying the world, Leo. They're all powerful. There's nothing that can stop them.
[01:08:44.360 --> 01:08:52.760]   I'm on themselves. I read a German essay because I'm working on my book, the next one. And
[01:08:52.760 --> 01:08:59.720]   it was going on about about toxic genius and the myth of genius in Silicon Valley and how that is
[01:08:59.720 --> 01:09:06.120]   toxic. And it went through Mark Zuckerberg and I had this great line in there that said that
[01:09:06.120 --> 01:09:15.320]   he's neither a genius nor a villain. He was just a ill-prepared, rather incompetent guy who got lucky.
[01:09:15.320 --> 01:09:20.760]   And I think that that's a lot of this too is we put these guys up on these pedestals as if they're
[01:09:20.760 --> 01:09:26.760]   amazing. Some of them are very smart. But Elon Musk shows that not just the emperor has no clothes,
[01:09:26.760 --> 01:09:34.440]   the closet's empty. That's the media's fault. Exactly. Exactly. Stacey agreed. We pump them up
[01:09:34.440 --> 01:09:38.600]   and so we can knock them down. That's our sport. It's like bowling, genius.
[01:09:38.600 --> 01:09:46.920]   It's because people like people. And if you're going to tell a narrative, you need a person. And
[01:09:46.920 --> 01:09:54.280]   these companies were big. So then we put these. So maybe we chose bad people to exemplify or we
[01:09:54.280 --> 01:10:02.920]   focus too much on the CEO as a person. Instead of like the like in TikTok, maybe we should have
[01:10:02.920 --> 01:10:07.880]   been focusing on some of the awesome users. And I see that people are doing things like that. But
[01:10:07.880 --> 01:10:12.520]   I don't know. Well, I said, yeah, I should have had more focus.
[01:10:12.520 --> 01:10:20.360]   Or just the people like the school system, the guy who bought MacIntoshes for schools
[01:10:20.360 --> 01:10:26.440]   initially and why. We should be talking more to we should not just be sitting around calling the
[01:10:26.440 --> 01:10:33.320]   CEOs of these companies. We should try to build our narratives not around some guy genius.
[01:10:33.320 --> 01:10:42.280]   But Lord, that's that's almost impossible. And then there's Dr. Carlson, but we'll save that
[01:10:42.280 --> 01:10:47.640]   for another day. Oh, yeah. Let's not talk about him. I only have one question. There's a journalism
[01:10:47.640 --> 01:10:55.240]   question about the Wall Street Journal's story today. So it's completely kind of a meta story
[01:10:55.240 --> 01:11:00.920]   about this, but I'll save that because I want to do an ad. Again, thrilled to be back. Thank you,
[01:11:00.920 --> 01:11:06.680]   and prove it. It's been great. Great. I missed you. You did a great bunch of hands on photography.
[01:11:06.680 --> 01:11:12.040]   He's been doing great stuff in the club. Thank you for that. You've got a bunch more club events
[01:11:12.040 --> 01:11:18.280]   coming up. If you're not yet a member of club to it, man, this guy is doing is rocking it. Go to
[01:11:18.280 --> 01:11:25.080]   twit.tv/clubtwit for ad free versions of all of our shows. The fabulous special shows that we
[01:11:25.080 --> 01:11:28.440]   put out only for club twit members. Of course, our discord,
[01:11:28.440 --> 01:11:35.000]   which is a great hang. I think it's my social media. No kid ever went crazy in our discord. I
[01:11:35.000 --> 01:11:41.560]   could tell you that right now. Nothing but happy, go lucky folks in there. And it's a
[01:11:41.560 --> 01:11:48.120]   prue and approved. Now that's legit. That's the greatest stamp ever. I love that. Shout out to
[01:11:48.120 --> 01:11:55.960]   Joe Esposito. Joe's great. He fixed my traps. Oh, he did. There you go. That's a little
[01:11:55.960 --> 01:12:01.160]   greeting. You can put that up. That's a little greetings from the nerds in the club twit discard.
[01:12:01.160 --> 01:12:08.520]   Seven bucks a month. Buck less than a blue check and you get so much more for it. Go to twit.tv/clubtwit.
[01:12:08.520 --> 01:12:13.320]   There's now family plans. There's corporate membership. There's an annual membership. I think
[01:12:13.320 --> 01:12:19.480]   it's the best thing ever. And we thank our members. We love you. Twit.tv/clubtwit.
[01:12:19.480 --> 01:12:27.560]   Your rocket at four us are shown today brought to you by HPE GreenLake orchestrated by the experts
[01:12:27.560 --> 01:12:35.240]   at CDW. The helpful people at CDW understand that your organization needs simple management
[01:12:35.240 --> 01:12:41.480]   over its big data, but some need to keep their workloads on prem for organizational and compliance
[01:12:41.480 --> 01:12:47.160]   requirements. It can feel challenging to organize and optimize your data. That's where CDW can help
[01:12:47.160 --> 01:12:53.720]   your organization by consolidating and managing all your data in one flexible unified experience
[01:12:53.720 --> 01:12:59.240]   with the HPE GreenLake Edge to Cloud platform. The experience you're going to get with HPE
[01:12:59.240 --> 01:13:03.960]   GreenLake is unique because no matter where your data or applications live, you can free up energy,
[01:13:03.960 --> 01:13:09.880]   free up resources, automated processes, streamlined management. I mean, who doesn't want more streamlined,
[01:13:09.880 --> 01:13:16.200]   right? But only that HPE GreenLake creates a seamless cloud experience among multiple data environments.
[01:13:16.200 --> 01:13:22.120]   So it kind of solves this problem thanks to the as-a-service model that meets your remote workforce
[01:13:22.120 --> 01:13:27.560]   at the edge. And with unrivaled scalability, you'll see instant increase in capacity,
[01:13:27.560 --> 01:13:33.000]   allowing for greater flexibility and accelerated business growth. So your team can tackle bigger
[01:13:33.000 --> 01:13:37.320]   priorities. I'm sure there's other things on your plate like, I don't know, innovation. Sure,
[01:13:37.320 --> 01:13:45.480]   when you need to get more out of your technology, HPE makes data transformation possible. CDW
[01:13:45.480 --> 01:13:55.720]   makes it powerful. Learn more at CDW.com/HPE. We thank you so much for their support of this week
[01:13:55.720 --> 01:14:11.080]   in Google CDW.com/HPE. What else is going on? Oh, I guess we can mention this. So
[01:14:11.080 --> 01:14:18.200]   not talking about Tuggle Carlson, getting laid off at blah, blah, blah. But there was always
[01:14:18.200 --> 01:14:23.800]   this question, well, what happened? Nobody knows. In the Wall Street Journal, who should know
[01:14:24.440 --> 01:14:31.400]   because they're owned by the same family says, oh, is those memos. So those memos, that's what did it.
[01:14:31.400 --> 01:14:38.040]   Now, I just, when I saw this, I thought, I'm going to ask you media watchers, in particular, you,
[01:14:38.040 --> 01:14:43.720]   Jeff, how, at first I thought, well, that's credible. It's a Wall Street Journal. They know,
[01:14:43.720 --> 01:14:49.000]   and they say unnamed sources, probably to Lachlan called them and said, could you print this?
[01:14:49.000 --> 01:14:57.080]   But now having watched succession, I'm wondering if there's some deep, dark thing that they're
[01:14:57.080 --> 01:15:02.920]   kind of this is, oh, no, no, pay no attention. It's just this. It's the memos. And I think there's
[01:15:02.920 --> 01:15:08.040]   some people made a fairly credible case that, hey, they've known about this for months. Why would
[01:15:08.040 --> 01:15:13.480]   that suddenly do this, right? Abbey Grossberg was interviewed on Nicole Wallace last night.
[01:15:13.480 --> 01:15:17.880]   It was a fascinating interview talking about this kind of bad behavior, the behavior had been
[01:15:17.880 --> 01:15:29.640]   there forever. My theory is a little bit different. I think that Tucker and his toasted testicles
[01:15:29.640 --> 01:15:36.040]   got too big for his britches. Yeah. And was, that's the Dylan buyer's take on it.
[01:15:36.040 --> 01:15:42.520]   Yeah, the he controlled. Yeah. And he was working out of his house in Maine. He wasn't even,
[01:15:43.080 --> 01:15:49.560]   by the way, I wonder who owns that studio and who gets to keep the stuff. So, you know,
[01:15:49.560 --> 01:15:54.360]   he was trouble. They couldn't fire him before the Dominion settlement because that would have
[01:15:54.360 --> 01:16:00.840]   hurt their case. So it's, ah, so that's the timing. Timing is that I think. Yeah. I think,
[01:16:00.840 --> 01:16:05.160]   but I think that they were looking for an excuse. Abbey Grossberg gave them a great excuse.
[01:16:05.160 --> 01:16:10.760]   You know, he used the C word to bosses. He did horrible things. I said somebody else say
[01:16:10.760 --> 01:16:17.240]   well that he was an Australian company. They don't line that word. He said all the time.
[01:16:17.240 --> 01:16:25.720]   I don't know. I guess it really comes to a much broader question, which is, is the Wall Street
[01:16:25.720 --> 01:16:31.160]   Journal, you know, I think for a long time, I've thought that Apple has used them, for instance,
[01:16:31.160 --> 01:16:39.960]   as kind of a house organ. Is the wall, how much? I guess you could ask this now about the New
[01:16:39.960 --> 01:16:44.040]   York Times too though. How much of a journalistic entity is it? How trustworthy is it?
[01:16:44.040 --> 01:16:48.120]   You know, I'm not talking about the opinion of age. I'm talking about the reporting.
[01:16:48.120 --> 01:16:53.320]   The reporting is still trust. So good. I think you do find a certain
[01:16:53.320 --> 01:16:59.640]   a certain type of person will
[01:16:59.640 --> 01:17:08.600]   their turn to the Wall Street Journal for leaks. For example, a FCC commissioner, a Republican FCC
[01:17:08.600 --> 01:17:16.840]   commissioner, used the Wall Street Journal extensively for leaks. And the reporter knew that,
[01:17:16.840 --> 01:17:22.600]   but also the fact that they could get these sorts of scoops was important. Access journalism,
[01:17:22.600 --> 01:17:27.880]   which is problematic. It is access journalism. But it's also, I mean, the New York Times does
[01:17:27.880 --> 01:17:32.680]   that too. It's just different people leak to the New York Times. You got a chicken egg there. I
[01:17:32.680 --> 01:17:39.240]   agree with you, but I'll see your bid and up you. Okay. Where I think that the reporter,
[01:17:39.240 --> 01:17:48.280]   without ever being told, also sees that an FCC car leak happens to fit the C-A-R-R, not a gas leak.
[01:17:48.280 --> 01:17:56.840]   Yes, I got you. Car leak. It wasn't car. Oh, it was. With, I think so, fits in with the agenda
[01:17:57.480 --> 01:18:03.320]   of Murdoch and the company. It goes in both directions. I think that makes sense. I mean,
[01:18:03.320 --> 01:18:07.800]   you're going to leak to somewhere where that leak will be welcome.
[01:18:07.800 --> 01:18:15.320]   Check it in. Yeah. So, and I also, so I will say, I once, you all know my bias,
[01:18:15.320 --> 01:18:19.320]   which is towards consumers. And if you've ever read my broadband coverage when I was covering
[01:18:19.320 --> 01:18:24.440]   that beat, I was like, I mean, I talked to the telecoms and I knew how their stuff worked. And
[01:18:24.440 --> 01:18:29.720]   I respected the technical limitations, but I was also pretty skeptical of a lot of their arguments,
[01:18:29.720 --> 01:18:40.040]   rightly so. As it turns out. Well, no, I mean, again, I understand the tech behind it.
[01:18:40.040 --> 01:18:47.320]   But when I went to Fortune after being at Gigo, and Gigo was always happy when I was like,
[01:18:47.320 --> 01:18:53.080]   when I'd be like, oh, look, it's another effort by our duopoly to squash competition in broadband.
[01:18:53.800 --> 01:18:58.680]   That could be my headline and no one blink an eye. And it was true. It wasn't crazy.
[01:18:58.680 --> 01:19:06.120]   But when I write the same headline, I think I wrote something about Comcast goes with evil plan for
[01:19:06.120 --> 01:19:11.000]   dating apps. Stacey, go get them. Stacey.
[01:19:11.000 --> 01:19:18.680]   So I put that in Fortune and it did like, it was there for maybe an hour before I got an email.
[01:19:18.680 --> 01:19:23.320]   That was like, hey, maybe we don't want to call Comcast evil on our front page. And I was like,
[01:19:24.200 --> 01:19:26.440]   what about calling? I'm just saying it's their evil plan.
[01:19:26.440 --> 01:19:29.640]   They may not say, but they're planning. Maybe.
[01:19:29.640 --> 01:19:34.680]   It's like, maybe we could just go Comcast and introduce his data caps. I was like, yeah,
[01:19:34.680 --> 01:19:39.000]   the data caps are real bad. They're like, yeah, maybe we just put that in the story. And I was like,
[01:19:39.000 --> 01:19:47.800]   so it's subtle. I get it. Yes, probably there. Yeah. But I don't think it's just like,
[01:19:49.320 --> 01:19:54.520]   I don't think that's how I got the scoop or like, like, we're actually that is kind of how this
[01:19:54.520 --> 01:20:01.960]   is. Um, there, but there does come to be a, an agenda for a publication that people put into.
[01:20:01.960 --> 01:20:05.800]   Yeah. And I love the Guardian dearly. I've worked with the Guardian. I think the Guardian is brilliant,
[01:20:05.800 --> 01:20:11.160]   but the Guardian's tech coverage has been pure. Get ready and pure moral panic.
[01:20:11.160 --> 01:20:14.520]   Oh, you're ready. Oh, you're married. You're just low on the uptake.
[01:20:15.800 --> 01:20:21.480]   Oh, it's a new one. Oh, that was so fancy.
[01:20:21.480 --> 01:20:29.160]   The Atlantic and the Wall Street Journal have all been of a single voice.
[01:20:29.160 --> 01:20:35.720]   And others haven't been. And so does it come from the top? Rarely. You know, when I worked for
[01:20:35.720 --> 01:20:40.280]   the TV God, I never once did. Rupert Bird dot com or did everybody come and say to me,
[01:20:40.280 --> 01:20:46.920]   you can't do this. Now, when I worked at Time Inc, to your point, Stacy, oh, yes. When I wrote
[01:20:46.920 --> 01:20:59.320]   a favorable review of a PBS series about Algier hiss, they, I had to quit and my editor almost
[01:20:59.320 --> 01:21:06.280]   quit until they took away their edits. Wow. Yeah. They because because because Whitaker Chambers
[01:21:07.160 --> 01:21:12.520]   was a time editor and Henry Grunwald found Whitaker Chambers to be his mentor. And when I said that
[01:21:12.520 --> 01:21:16.840]   the thing was credible about Whitaker Chambers, he went slashing through my piece and I said,
[01:21:16.840 --> 01:21:21.720]   that's not going to my name. No, I'm, I'm, and we had to fight and God bless my editor,
[01:21:21.720 --> 01:21:24.920]   Pat Ryan, may she rest in peace fought for me. So I saw direct
[01:21:24.920 --> 01:21:31.560]   interference from Time Inc more than I did at News Corp. Well, here we go. The New York Times
[01:21:31.560 --> 01:21:36.680]   just published an article very much like the journal article with pretty much the same
[01:21:36.680 --> 01:21:44.200]   suppositions. Again, you know, unnamed sources. And here's another one, the Rolling Stone. Now,
[01:21:44.200 --> 01:21:50.680]   who leaks to the Rolling Stone these days? They say you are the Rolling Stone. Is it Rolling Stone?
[01:21:50.680 --> 01:21:54.920]   Just Rolling Stone, not the Rolling Stone. It's like the Facebook. Yeah. Lost the thoughts.
[01:21:54.920 --> 01:22:03.560]   I think it's the Rolling Stone magazine. Is that what we're talking about?
[01:22:03.560 --> 01:22:08.040]   Yeah. But I'm wondering because it used to be rock the roll magazine. I think it's changed.
[01:22:08.040 --> 01:22:14.840]   It seems like it's a lot of coverage, right? And stuff. They used to do a lot of investigative
[01:22:14.840 --> 01:22:19.560]   journalism even when I was in high school. They came out. They were the one that they had the
[01:22:19.560 --> 01:22:24.600]   Petraeus scoop and stuff. So yeah, you're right. They've got anyway, eight people. This just came out
[01:22:24.600 --> 01:22:30.600]   too. Eight people familiar with the situation. Eight tell Rolling Stone that Fox News in its
[01:22:30.600 --> 01:22:38.520]   communications department has assembled a damaging dossier about Tucker Carlson that they will release
[01:22:38.520 --> 01:22:44.280]   should he attack the network. So wow, this is a story. I love this story. It has nothing to do with
[01:22:44.280 --> 01:22:48.200]   tech. That totally tracks. Yeah. It has nothing to do with tech. But it's very much
[01:22:48.200 --> 01:22:55.800]   that is exciting. You may run for president. What? You should not let people, if you have the
[01:22:55.800 --> 01:23:02.600]   ability to gather a damaging dossier on someone, you should not put them in a position of power.
[01:23:02.600 --> 01:23:10.120]   I have to prove that all you guys said don't. Mine is like my dog is upset because I forgot to
[01:23:10.120 --> 01:23:15.160]   walk her the other day. So you make a good point. You make a good point. If your number one anchor
[01:23:15.160 --> 01:23:20.120]   has a dossier damaging enough. Really good points, Stacy. That's an excellent point.
[01:23:20.120 --> 01:23:28.760]   Really good point. When I was just like Don Lemon, everybody, I'm like, Oh, you know what? Just add
[01:23:28.760 --> 01:23:35.880]   24 hour news channels to the pile of things wrong with this world. You know what's right with this
[01:23:35.880 --> 01:23:41.960]   world men in charge of these places. Men. I mean, I was well, I don't know. I mean, like,
[01:23:41.960 --> 01:23:48.440]   I have to, I'm not hanging out with like Soledad or Brian or other people. She's cool. She's very cool.
[01:23:48.440 --> 01:23:55.080]   But like do I'm just trying to. She would never do that. Most of the professional women
[01:23:55.080 --> 01:24:00.360]   I know about all this stuff actually. Oh, yeah. Oh, she's like, she's a strong voice for ethics
[01:24:00.360 --> 01:24:07.160]   and journals. Yeah. Our damaging dossies, I feel like most women we we would never like.
[01:24:07.160 --> 01:24:13.320]   That is my slogan when like I I'm around my editors who are like, Oh, yeah, I totally got
[01:24:13.320 --> 01:24:16.760]   trashed and then I was late for my interview and I missed my plane and I didn't get away.
[01:24:16.760 --> 01:24:21.160]   Little women are more women are in power. And then you tell me that. I think some of this
[01:24:21.160 --> 01:24:25.800]   maybe because there's a predominance of men acting badly because there's a predominance of men in
[01:24:25.800 --> 01:24:30.440]   power. It's really a power dynamic. And I think it's human. Yeah. And maybe if more
[01:24:30.440 --> 01:24:34.840]   we were a predominance of women in power, we'd see more of those stories. I don't give me power.
[01:24:34.840 --> 01:24:39.960]   And I will think we should try it. Lisa always says that she says, put women in charge. We
[01:24:39.960 --> 01:24:44.760]   wouldn't have all these wars would you? And she's got a she's got a point. We just haven't tried it yet.
[01:24:44.760 --> 01:24:54.120]   When I was back out there in the real world, aka Europe, I saw a lot of small cars,
[01:24:54.840 --> 01:24:59.480]   especially in Rome. Great story in the journal this week about this car.
[01:24:59.480 --> 01:25:05.880]   A really tiny car that is number one in Brazil. Wow.
[01:25:05.880 --> 01:25:15.320]   It's the size of a golf cart car. Yeah, it's an EV doesn't have a trunk.
[01:25:15.320 --> 01:25:21.240]   They talked to one of the owners who said he's driven 6,000 miles in it and it can squeeze in
[01:25:21.240 --> 01:25:27.880]   three people quote, but they can't be very fat. And quote. Thanks for putting that in quotes.
[01:25:27.880 --> 01:25:35.160]   He also says, you got to be careful driving it around because people don't respect you at all.
[01:25:35.160 --> 01:25:41.960]   Oh, no, let's drivers call his car El Estorbito or the little nuisance.
[01:25:41.960 --> 01:25:50.360]   That's the name of it. Look at it. But it's very popular in Bolivia. It's Maine Bolivia.
[01:25:50.360 --> 01:25:57.400]   It can be plugged into any outlet costs for this person that they're quoting about $8 a month
[01:25:57.400 --> 01:26:03.560]   to get around. What is your miles per hour? 35 miles per hour. It'll only go about 60 miles
[01:26:03.560 --> 01:26:08.840]   per charge. But if you just drive it around town, perfect, by the way, for Chihuahuas, Micah.
[01:26:08.840 --> 01:26:13.640]   I'm going to start you. I would totally drive this around Bay Bridge.
[01:26:13.640 --> 01:26:18.040]   Yeah, it's for it's for our our speed limits top out. It's a getting around town.
[01:26:18.040 --> 01:26:25.240]   That makes sense around the island. Yeah. Anyway, I saw a lot of Chinese cars.
[01:26:25.240 --> 01:26:30.760]   There was a there's a brand called Yo-Yo, which is how many more brands you see in your
[01:26:30.760 --> 01:26:33.800]   Yeah, and they're small because there's no parking.
[01:26:33.800 --> 01:26:40.760]   You know, I mean, you got to fit in. It's so cute because you're walking along and people aren't
[01:26:40.760 --> 01:26:45.000]   allowed to have cars in the center of Roman, unless they live there and they're trying to park
[01:26:46.440 --> 01:26:51.400]   watch. And if you have a if you have a normal size car, the streets are this wide.
[01:26:51.400 --> 01:26:57.880]   And there are no sidewalks. You're walking down the street and it's it's dodging cars all the time.
[01:26:57.880 --> 01:27:01.560]   And I said, well, I'm sure they never hit anybody. So Lisa looks it up and it's like there's thousands
[01:27:01.560 --> 01:27:09.000]   of casualties a year of cars hitting people. This is the this was very popular.
[01:27:09.000 --> 01:27:13.720]   Casualties are just in injuries. Casualties is injuries. There's deaths.
[01:27:13.720 --> 01:27:18.440]   I don't know. Yeah, casualty was death. No, I think casualties. I don't know. Well, I meant
[01:27:18.440 --> 01:27:22.840]   engine. I don't know. Okay, let's look it up. So they're not death. Let me ask there.
[01:27:22.840 --> 01:27:23.960]   They're just being chat.
[01:27:23.960 --> 01:27:29.560]   Oh, many getting hit by a small car versus like a curve.
[01:27:29.560 --> 01:27:38.600]   F one, 50 in Rome, probably due to pedestrian pedestrian deaths. You just say pedestrian deaths
[01:27:38.600 --> 01:27:45.720]   with that with that, that would be pedestrian deaths. Occurgeal bikes each year.
[01:27:45.720 --> 01:27:51.000]   You said I was seeing a lot of e-bikes, which is very oh, it's not too bad.
[01:27:51.000 --> 01:27:57.640]   59 a year. That's not so bad. Oh, dude, we get like that in Seattle in like two months.
[01:27:57.640 --> 01:28:03.720]   Yeah. Here's an article from China. Roman roads are becoming like the wild west for pedestrians.
[01:28:07.640 --> 01:28:15.800]   59. Come on. That's nothing. On the other hand, on the road, 2395 people died in road accidents.
[01:28:15.800 --> 01:28:20.360]   Lisa looked that one up when we were in a cab going 90 miles an hour to the airport.
[01:28:20.360 --> 01:28:28.920]   She literally, she looked up. How many people died on the highway in Italy?
[01:28:28.920 --> 01:28:35.640]   Rolle volcano went off and Iceland. Yeah. I made it to the last flight out of Europe
[01:28:35.640 --> 01:28:41.400]   from Berlin to Munich. A guy who convinced these two women that I was a long time friend of his,
[01:28:41.400 --> 01:28:45.640]   I've never met him before, but I didn't get to Munich. They let me into their car. Their last
[01:28:45.640 --> 01:28:51.400]   rental car, they get to Berlin. And I'm sitting there in the back calculating kilometers to miles.
[01:28:51.400 --> 01:28:57.240]   Oh, yeah. You were going 120 miles an hour miles an hour miles an hour. Oh, that's awesome.
[01:28:57.240 --> 01:29:03.480]   On Zalto Bon. Yeah, I did the same thing. We're going 131 kilometers an hour and I found out.
[01:29:03.480 --> 01:29:11.400]   Oh, that's only 80 miles an hour. That's not, that's not. US Supreme Court will not review a decision
[01:29:11.400 --> 01:29:22.840]   that says AI can patent inventions. Got to be a human. Got to be a human. Computer scientist,
[01:29:22.840 --> 01:29:28.360]   Stephen Thawler, challenged the US Patent and Trademark Office. You remember they refused to
[01:29:28.360 --> 01:29:35.320]   issue a patent for inventions his AI system had created. The justices said, no, we don't even,
[01:29:35.320 --> 01:29:41.640]   we don't even want to talk to you. They just, they declined to hear the challenge. So I think
[01:29:41.640 --> 01:29:48.120]   that means officially, right? The AI cannot patent anything. Human has to copyright and they
[01:29:48.120 --> 01:29:53.160]   can't patent, which is really interesting. Then when you turn back around and say, well, then,
[01:29:53.720 --> 01:29:57.640]   am I really stealing your content? If I can't patent it, copyright it, right?
[01:29:57.640 --> 01:30:03.400]   You know, there was a really good article in the New Yorker by a guy named Jaren Lanier, who was a,
[01:30:03.400 --> 01:30:12.760]   I've mixed feelings about Jaren was a very early pioneer of AI. I'm sorry, VR, literally 20 years
[01:30:12.760 --> 01:30:17.000]   ago, looks like this. Yeah, and he wrote a really terrible book called You Are Not A Gadget. What's
[01:30:17.000 --> 01:30:20.680]   his, what's that one? And 10 arguments for the leading your social media accounts right now.
[01:30:20.680 --> 01:30:25.240]   Okay, because you know, he was kind of anti technology, but he did write, I thought, a very
[01:30:25.240 --> 01:30:31.720]   good article that was published this week in the Yorker about AI. And his argument is that,
[01:30:31.720 --> 01:30:36.120]   first of all, you shouldn't call it artificial intelligence names are important. And you know,
[01:30:36.120 --> 01:30:41.640]   because we've grown up in this milieu, where AI, you know, smart machines kill humans and stuff
[01:30:41.640 --> 01:30:47.320]   like that, it's called there is no AI is the name of the article. And what he really says is,
[01:30:47.320 --> 01:30:55.320]   this is an AI, this is a new way of collaborating. This is about social collaboration, because no
[01:30:55.320 --> 01:31:01.080]   AI makes something from whole cloth. It's all from previous human creations.
[01:31:01.080 --> 01:31:02.920]   I could agree with him about something.
[01:31:02.920 --> 01:31:07.160]   He says, if the new tech isn't too artificial intelligence, what is it? In my view, the most
[01:31:07.160 --> 01:31:13.160]   accurate way to understand what we're building today is an innovative form of social collaboration.
[01:31:13.160 --> 01:31:20.680]   And I thought, that's fascinating. That's an interesting angle similar to what Stalman said,
[01:31:20.680 --> 01:31:27.000]   right? Well, Stalman said, you should never trust an AI because it's not, it's never designed
[01:31:27.000 --> 01:31:34.360]   to be factual, you know, but what he was saying, how the AI is not necessarily quote unquote,
[01:31:34.360 --> 01:31:37.920]   intelligent, right, because it doesn't exactly. Yeah, it's just a
[01:31:37.920 --> 01:31:41.560]   doesn't know correct. Yeah, and that's what we've been saying for a while. But I think this is
[01:31:41.560 --> 01:31:44.520]   an interesting way of thinking and it goes back to this patent thing, because
[01:31:44.520 --> 01:31:50.920]   it is, it is generative, but it's generative from stuff humans made
[01:31:50.920 --> 01:31:56.120]   previously, right? So think of it more of as that.
[01:31:56.120 --> 01:32:04.280]   He says, think of people, people are the answer to problems of bits. That goes back to his kind of
[01:32:04.280 --> 01:32:08.920]   overarching thing that he's writing about in that book, and you are not a gadget and all of that
[01:32:08.920 --> 01:32:15.160]   stuff. He's become kind of a well known anti technology guy. But I, but he started writing about
[01:32:15.160 --> 01:32:19.320]   VR. Is that what you said? He created early VR. No, he was the guy.
[01:32:19.320 --> 01:32:29.000]   Yeah, very famous. Okay. What's the word? He coined. But yet he's against tech these days.
[01:32:29.000 --> 01:32:34.840]   There's a lot of folks, I think, Christian Harris is an example of others,
[01:32:34.840 --> 01:32:37.800]   where they've seen the burning bush after they've cashed their checks.
[01:32:38.520 --> 01:32:43.640]   They've made their, there it is. Okay. They say, Oh my God, it's terrible. And I'm going to save
[01:32:43.640 --> 01:32:49.000]   you all from what I helped create. Right. What if they're not cashing their checks? What if they
[01:32:49.000 --> 01:32:55.160]   just are like, they simply, they were naive, they believed in what they were doing. They created it.
[01:32:55.160 --> 01:32:59.400]   They thought it would be used for good things. It wasn't. They thought it would get better.
[01:32:59.400 --> 01:33:03.160]   It didn't. And now they're like, Oh, screw it. It's awesome. And I feel like that's where I
[01:33:03.160 --> 01:33:09.960]   are. He's coming with an informed point of view because he's in, you know, he created stuff.
[01:33:09.960 --> 01:33:16.760]   Or he's exploiting this to just to get more attention. I don't think he made a pocket of money
[01:33:16.760 --> 01:33:33.120]   on all of this, frankly. Well, he's making money on these books like Perfic
[01:33:33.120 --> 01:33:38.160]   Read This Peace with an open line because I would like you to. I'm sorry that, but next week we could
[01:33:38.160 --> 01:33:42.240]   talk about it. But I think it was really good. You know, it's New Yorker. It's not, you know,
[01:33:42.240 --> 01:33:48.400]   the Daily Mail. Who can be? Yeah. Okay. I thought I thought I had already used up my free articles
[01:33:48.400 --> 01:33:53.680]   this month. So I didn't. I'm putting it out right now. You know what? I'm painting it out.
[01:33:53.680 --> 01:33:59.600]   Yeah. Well, for things to be the book that I underlined. I pay for the New Yorker. But Connie
[01:33:59.600 --> 01:34:06.160]   Nast is so screwed up that I can never log in. The only way I can actually do it is in my Apple,
[01:34:06.160 --> 01:34:11.600]   you know, news thing I can read it or with the New Yorker app I can read it, but I can never
[01:34:11.600 --> 01:34:17.600]   read it on the web. They think they think I'm not a member, even though I am and I log in and
[01:34:17.600 --> 01:34:20.960]   it says, Oh, good. Welcome. Your account is good. You're in and then I go to a lot.
[01:34:20.960 --> 01:34:23.440]   Article says, No, you got to buy the got to subscribe.
[01:34:23.440 --> 01:34:27.760]   You have to would you please talk to your friends over there? It's the worst system.
[01:34:27.760 --> 01:34:32.000]   It happens to me with Wired too. It's and Vanity Fair. I subscribed to Wired,
[01:34:32.000 --> 01:34:39.200]   Vanity Fair and New York. Oh, and none of them work right. It's terrible. Anyway, sorry.
[01:34:39.200 --> 01:34:46.080]   Diatry Bober, U.S. Supreme Court has taken a case that may interest you.
[01:34:46.080 --> 01:34:53.600]   They agreed on Monday to consider whether the First Amendment does indeed bar government
[01:34:53.600 --> 01:35:00.080]   officials from blocking their critics. Now you may remember there have been a couple of cases
[01:35:00.080 --> 01:35:10.720]   around this. Donald Trump was told that he could not block people on Twitter as president, right?
[01:35:10.720 --> 01:35:14.880]   Actually, oh, I take it back. It's an official. They agreed to review it, but then he left office
[01:35:14.880 --> 01:35:21.680]   and they decided it was moot. Right. They dodged that bullet. Oh, interesting.
[01:35:22.400 --> 01:35:26.560]   So we don't know how they're going to rule on this. The justices took up an appeal by two members
[01:35:26.560 --> 01:35:31.280]   of a public school board from Pawe which is a doubt in Southern California.
[01:35:31.280 --> 01:35:36.800]   Lower court ruled in favor of school parents who sued after being blocked from Facebook pages
[01:35:36.800 --> 01:35:42.240]   in a Twitter account that the officials maintain. Now this isn't a private account. This is their
[01:35:42.240 --> 01:35:49.280]   official school board account. And the parents, I think quite rightly said, no, if you're going to
[01:35:49.280 --> 01:35:55.760]   have a official school board account, you can't block us because you don't like our responses to
[01:35:55.760 --> 01:36:01.840]   this. I agree with the parents. They also took up an appeal by a Michigan man of a lower courts
[01:36:01.840 --> 01:36:07.040]   ruling against him after he sued his city official in Port Huron who blocked him on Facebook.
[01:36:07.040 --> 01:36:13.200]   So they've got cases can go in in both ways. So the issue is whether a public official's social
[01:36:13.200 --> 01:36:17.600]   media account can amount to governmental action bound by the First Amendment.
[01:36:17.600 --> 01:36:28.560]   And I didn't realize that they they they they've mooted the Trump case. I forgot that.
[01:36:28.560 --> 01:36:34.320]   Completely forgot that. Yeah. He's not he lost in the lower court though and did have to unblock
[01:36:34.320 --> 01:36:37.840]   those people. And that's why I thought he lost in the Supreme Court. They just never did decide
[01:36:37.840 --> 01:36:45.600]   that. So this will finally decide that. I don't what's what's a credible argument saying a public
[01:36:45.600 --> 01:36:52.560]   official on Twitter, that's public pronouncements, right? You shouldn't be able to block people.
[01:36:52.560 --> 01:36:58.480]   I guess let's let's let's let's play a state doubles advocate here is that if if if
[01:36:58.480 --> 01:37:04.880]   trolls and bots and opponents come in and do nothing but attack and attack and attack to make it
[01:37:04.880 --> 01:37:10.160]   useless, well, you can block a non human affecting the speech. Let's say it's a human.
[01:37:10.160 --> 01:37:16.960]   Even so you then you have to the platform doesn't have a way to prove humanity or it doesn't force
[01:37:16.960 --> 01:37:22.080]   proving humanity. So then you've got then you've just created a digital like system of proving
[01:37:22.080 --> 01:37:29.360]   you're a person. Well, don't they were not the Supreme Court because we can't decide.
[01:37:30.400 --> 01:37:36.000]   It's a good thing we're not Congress. Actually, it's a good thing. I think we don't know.
[01:37:36.000 --> 01:37:41.680]   Are the best heard of the last couple of the best thing in the world, which is podcast hosts.
[01:37:41.680 --> 01:37:49.600]   God bless them. We're pundits. The pundits and the podcast hosts were around the world.
[01:37:49.600 --> 01:37:53.840]   If only built. That's what George Bird's one said. He says, it's a shame that all the people know how
[01:37:53.840 --> 01:38:03.520]   to run the government are working as barbers or taxi drivers. Schools bought millions of
[01:38:03.520 --> 01:38:09.280]   Chromebooks three years ago. And now they're starting to break, which is causing the US public
[01:38:09.280 --> 01:38:15.680]   interest research group education fund to complain saying that cheap Chromebooks through their short
[01:38:15.680 --> 01:38:21.440]   life spans and lack of repairability are less sustainable and more expensive for schools than
[01:38:21.440 --> 01:38:24.240]   pricier devices might be. I don't know what they're talking about.
[01:38:24.240 --> 01:38:25.440]   Windows Windows.
[01:38:25.440 --> 01:38:27.600]   Windows. You agree with that? No.
[01:38:27.600 --> 01:38:34.400]   They're upset because they are having eight year lifespan. Like Google's like, well,
[01:38:34.400 --> 01:38:39.200]   we'll promote like the we're not promote. We'll keep updating Chromebooks eight years.
[01:38:39.200 --> 01:38:43.120]   That's kind of a long time.
[01:38:43.120 --> 01:38:47.280]   They're saying these things are crap. They call it the report was called Chromebook churn.
[01:38:47.920 --> 01:38:53.040]   Was the problem the update or the problem the hardware problem was they also they have two
[01:38:53.040 --> 01:38:57.200]   problems. They have one is the update and the other is the fact that the keyboards keep breaking.
[01:38:57.200 --> 01:39:01.040]   But you know, that's also a fraction of two and it's hard to get repair parts. But yeah,
[01:39:01.040 --> 01:39:07.120]   you give a K through 12 student. Yeah. What do you think? Give me my back books.
[01:39:07.120 --> 01:39:08.480]   I ain't gonna lie to you.
[01:39:08.480 --> 01:39:11.840]   I'm a computer distancing. She's gonna beat it to death within months.
[01:39:11.840 --> 01:39:15.520]   I will have you know that my computers last at least five years.
[01:39:15.520 --> 01:39:20.080]   How about the keyboards? How long the keyboard is lasted for?
[01:39:20.080 --> 01:39:26.160]   I've had this keyboard for like a decade or more. Actually, I think two decades.
[01:39:26.160 --> 01:39:30.320]   It must be masochistic. It's a masochistic.
[01:39:30.320 --> 01:39:30.720]   It's letters.
[01:39:30.720 --> 01:39:36.160]   Wow. You have had a long time with it. The letters are wearing off.
[01:39:36.160 --> 01:39:38.080]   The A the S. Wow.
[01:39:38.080 --> 01:39:40.080]   The M they're all going.
[01:39:40.080 --> 01:39:41.920]   The M that's interesting.
[01:39:41.920 --> 01:39:49.040]   You would expect the ETA ION S H R D L U the most used letters.
[01:39:49.040 --> 01:39:49.840]   The one shrewd Lou.
[01:39:49.840 --> 01:39:52.400]   Yeah, that's an old one.
[01:39:52.400 --> 01:39:54.960]   Oh, wow. That's not a computer. That's a keyboard.
[01:39:54.960 --> 01:39:56.160]   Yeah. Well, that's what I was asked for.
[01:39:56.160 --> 01:39:58.320]   Oh, here's my missing letters.
[01:39:58.320 --> 01:39:59.040]   See, no.
[01:39:59.040 --> 01:40:01.040]   A laugh would not be able to stand your abuse.
[01:40:01.040 --> 01:40:03.680]   Oh, no. She doesn't have a laptop. She's got a desktop.
[01:40:03.680 --> 01:40:08.560]   No, no, I have a laptop. I have a docking station.
[01:40:08.560 --> 01:40:08.960]   Yeah.
[01:40:08.960 --> 01:40:09.360]   Smart.
[01:40:09.360 --> 01:40:10.240]   This is a better keyboard.
[01:40:10.240 --> 01:40:10.880]   You're smart.
[01:40:10.880 --> 01:40:11.360]   Yeah, yeah, yeah.
[01:40:11.360 --> 01:40:15.520]   Perg says, well, you should double the lifespan.
[01:40:15.520 --> 01:40:19.120]   If you did, you could cut emissions by 4.6 million tons of CO2.
[01:40:19.120 --> 01:40:20.800]   Blah, blah, blah.
[01:40:20.800 --> 01:40:25.680]   They say Google should make it easier to unenroll Chromebooks from remote management
[01:40:25.680 --> 01:40:27.600]   and should install remote operating systems.
[01:40:27.600 --> 01:40:28.640]   Linux.
[01:40:28.640 --> 01:40:31.600]   This is so uninformed.
[01:40:31.600 --> 01:40:34.160]   It would make a host.
[01:40:34.160 --> 01:40:35.120]   It's greater in Linux.
[01:40:35.120 --> 01:40:35.600]   Yeah.
[01:40:35.600 --> 01:40:36.720]   This is moronic.
[01:40:38.000 --> 01:40:42.080]   Google's response is, we work diligently with our hardware partners to increase the years
[01:40:42.080 --> 01:40:45.600]   of guaranteed support Chromebooks received since 2020.
[01:40:45.600 --> 01:40:50.720]   We provide eight years of automatic updates, which was up from five even.
[01:40:50.720 --> 01:40:52.000]   Look it.
[01:40:52.000 --> 01:40:54.880]   You give a kid a laptop five years.
[01:40:54.880 --> 01:40:57.920]   I mean, look at the book's last five years.
[01:40:57.920 --> 01:41:01.040]   Up five, five years in 2016.
[01:41:01.040 --> 01:41:04.400]   We're always working with our device manufacturing partners to increasingly build a device.
[01:41:04.400 --> 01:41:04.960]   You know what?
[01:41:04.960 --> 01:41:05.600]   Yes, it's true.
[01:41:05.600 --> 01:41:09.440]   If you buy a $200 Chromebook, it's not going to wear out very well.
[01:41:09.440 --> 01:41:11.520]   But you're saying, what are you going to get?
[01:41:11.520 --> 01:41:12.560]   A $200 iPad?
[01:41:12.560 --> 01:41:12.880]   Nope.
[01:41:12.880 --> 01:41:15.440]   You're going to get a $200 Windows machine?
[01:41:15.440 --> 01:41:15.680]   Nope.
[01:41:15.680 --> 01:41:19.200]   I don't understand what their proposition is.
[01:41:19.200 --> 01:41:19.600]   No.
[01:41:19.600 --> 01:41:20.960]   Give them a wooden block.
[01:41:20.960 --> 01:41:22.720]   It'll last longer.
[01:41:22.720 --> 01:41:26.560]   How about a slate with a piece of chalk?
[01:41:26.560 --> 01:41:27.040]   Chalk.
[01:41:27.040 --> 01:41:28.960]   I said I'm going to tadlet for you.
[01:41:28.960 --> 01:41:29.440]   All right.
[01:41:29.440 --> 01:41:30.800]   Yeah, I got your tablet.
[01:41:30.800 --> 01:41:34.240]   All right.
[01:41:34.240 --> 01:41:35.040]   What were those books?
[01:41:35.040 --> 01:41:38.640]   The writing books from the colonial times, like a primer or primer?
[01:41:38.640 --> 01:41:40.080]   A horn book.
[01:41:40.080 --> 01:41:40.640]   Horn book.
[01:41:40.640 --> 01:41:41.040]   There you go.
[01:41:41.040 --> 01:41:41.520]   Horn book.
[01:41:41.520 --> 01:41:42.160]   That's it.
[01:41:42.160 --> 01:41:42.560]   Yeah.
[01:41:42.560 --> 01:41:43.920]   I knew you guys would know that.
[01:41:43.920 --> 01:41:44.720]   Because we're that old.
[01:41:44.720 --> 01:41:45.120]   Because we're that old.
[01:41:45.120 --> 01:41:45.600]   Can you remember?
[01:41:45.600 --> 01:41:46.320]   Yes.
[01:41:46.320 --> 01:41:47.120]   He actually remembers.
[01:41:47.120 --> 01:41:48.240]   Over the flons school.
[01:41:48.240 --> 01:41:48.480]   Yeah.
[01:41:48.480 --> 01:41:53.760]   That when he and Hester Prynne were in fourth grade and he dipped her pigtails into the inkwell.
[01:41:53.760 --> 01:41:57.440]   Got hers.
[01:41:57.440 --> 01:41:58.240]   She got hers.
[01:41:58.240 --> 01:41:59.280]   That's right.
[01:41:59.280 --> 01:41:59.920]   That's right.
[01:42:03.040 --> 01:42:04.800]   Tesla has one of the good news.
[01:42:04.800 --> 01:42:07.280]   There is some good news for Elon in the weeks.
[01:42:07.280 --> 01:42:08.640]   Rendezvous.
[01:42:08.640 --> 01:42:09.200]   I don't like that.
[01:42:09.200 --> 01:42:09.840]   Tesla one along.
[01:42:09.840 --> 01:42:12.400]   Well, there's some bias.
[01:42:12.400 --> 01:42:13.760]   I think we've just uncovered some bias.
[01:42:13.760 --> 01:42:14.320]   There is a D.
[01:42:14.320 --> 01:42:16.080]   There's some bias.
[01:42:16.080 --> 01:42:21.920]   Tesla wins a lawsuit over autopilot model S crash 2019 accident.
[01:42:21.920 --> 01:42:30.320]   Justine shoe sued Tesla after EV swerved into a center median on LA City Street
[01:42:30.320 --> 01:42:31.920]   while autopilot was engaged.
[01:42:31.920 --> 01:42:34.320]   She's just going down the road and all this happened to me.
[01:42:34.320 --> 01:42:36.320]   Used to happen to me all the time with my model X.
[01:42:36.320 --> 01:42:37.840]   It would just decide some days.
[01:42:37.840 --> 01:42:39.040]   I think I'll drive that way.
[01:42:39.040 --> 01:42:46.480]   She saw more than $3 million alleging defects in the software and the design of Tesla's airbags.
[01:42:46.480 --> 01:42:50.880]   She suffered a fractured jaw missing teeth and nerve damage.
[01:42:50.880 --> 01:42:55.840]   The jury said not not Tesla's fault.
[01:42:55.840 --> 01:43:01.280]   Tesla's defense was, hey, we told you you shouldn't use it on city streets.
[01:43:01.920 --> 01:43:07.280]   The jury awarded her no damages said the automaker did not intentionally fail
[01:43:07.280 --> 01:43:08.960]   disclosed facts about autopilot.
[01:43:08.960 --> 01:43:12.960]   Not not Tesla's fault.
[01:43:12.960 --> 01:43:16.400]   Jury did not maybe the jury likes Elon.
[01:43:16.400 --> 01:43:22.080]   Meanwhile, Elon the self driving rocket made a lot of damage.
[01:43:22.080 --> 01:43:23.600]   Now this is this new video.
[01:43:23.600 --> 01:43:26.000]   I know, but there's new video you might want to just look at.
[01:43:26.000 --> 01:43:26.800]   Oh, where is that?
[01:43:26.800 --> 01:43:28.480]   A down at line.
[01:43:28.480 --> 01:43:29.920]   Give me the line.
[01:43:30.560 --> 01:43:32.000]   Oh, you want the line?
[01:43:32.000 --> 01:43:32.960]   Line 76.
[01:43:32.960 --> 01:43:34.800]   76.
[01:43:34.800 --> 01:43:39.040]   This is a tick tock of the SpaceX.
[01:43:39.040 --> 01:43:42.160]   Oh, well, this is just the damage done on the ground.
[01:43:42.160 --> 01:43:46.960]   I know, I know, but that's not because the rocket blew up.
[01:43:46.960 --> 01:43:49.280]   That's just what happens when you're near a rock.
[01:43:49.280 --> 01:43:50.480]   He doesn't have a flame divergent.
[01:43:50.480 --> 01:43:52.960]   No, that's because he didn't build the appropriate safe.
[01:43:52.960 --> 01:43:53.920]   Oh, ronk.
[01:43:53.920 --> 01:43:56.880]   Rambling the thrust of the many engines.
[01:43:56.880 --> 01:44:00.000]   Oh, yeah, because we've seen he admitted today, right?
[01:44:00.000 --> 01:44:00.880]   Remote cameras.
[01:44:00.880 --> 01:44:03.200]   He tweeted about not wanting to put one.
[01:44:03.200 --> 01:44:07.360]   Hey, if you go all the way down to Boca Chica, Texas,
[01:44:07.360 --> 01:44:13.120]   however, the fact that the thing blew up
[01:44:13.120 --> 01:44:18.080]   is widely considered not to be a bad thing.
[01:44:18.080 --> 01:44:19.840]   It was the first time they launched it,
[01:44:19.840 --> 01:44:22.800]   and it got very high and they learned a lot and blah, blah, blah.
[01:44:22.800 --> 01:44:23.840]   It was a terrible.
[01:44:23.840 --> 01:44:26.720]   But the big issue was it blew up.
[01:44:26.720 --> 01:44:29.280]   They believe one of the reasons it blew up
[01:44:29.280 --> 01:44:32.880]   was because they had insufficient ground protection.
[01:44:32.880 --> 01:44:33.760]   Oh.
[01:44:33.760 --> 01:44:35.600]   And so when they had something,
[01:44:35.600 --> 01:44:37.920]   he kind of caused his own problems.
[01:44:37.920 --> 01:44:43.280]   I get not wanting to, if that feels like a safety regulation
[01:44:43.280 --> 01:44:44.320]   that you could ignore.
[01:44:44.320 --> 01:44:45.120]   And I mean--
[01:44:45.120 --> 01:44:47.680]   So there was damage caused in the launch,
[01:44:47.680 --> 01:44:49.680]   which is why the rocket went off course,
[01:44:49.680 --> 01:44:51.120]   which is why they had to blow it off.
[01:44:51.120 --> 01:44:53.440]   But it's a test.
[01:44:53.440 --> 01:44:56.640]   So he's learned a lesson and bad in the lawn.
[01:44:56.640 --> 01:44:57.920]   You've learned your lesson.
[01:44:57.920 --> 01:44:59.520]   We already knew this was--
[01:44:59.520 --> 01:45:00.320]   I know.
[01:45:00.320 --> 01:45:01.360]   I know.
[01:45:01.360 --> 01:45:02.320]   I know.
[01:45:02.320 --> 01:45:05.200]   I'm like, we don't have to reinvent this wheel.
[01:45:05.200 --> 01:45:07.200]   It does wheel at the cost of--
[01:45:07.200 --> 01:45:10.560]   Anyway, sorry.
[01:45:10.560 --> 01:45:11.360]   All right.
[01:45:11.360 --> 01:45:12.800]   The space guys,
[01:45:12.800 --> 01:45:14.720]   you know, we have space experts at the network.
[01:45:14.720 --> 01:45:18.960]   Rod Pyle and Terrick Malek of this week in space,
[01:45:18.960 --> 01:45:20.960]   they said it was looking forward to this time.
[01:45:20.960 --> 01:45:22.160]   I wonder what Rod will say.
[01:45:22.160 --> 01:45:25.200]   We're going to have him on the Ask the Tech guys on Sunday
[01:45:25.200 --> 01:45:27.600]   before he does this week in space.
[01:45:27.600 --> 01:45:30.080]   I wonder what he'll say with this new knowledge,
[01:45:30.080 --> 01:45:31.760]   because I don't think they knew about the shield.
[01:45:31.760 --> 01:45:32.800]   They didn't know about the shield.
[01:45:32.800 --> 01:45:34.800]   Did they know all about the shield?
[01:45:34.800 --> 01:45:35.440]   Okay.
[01:45:35.440 --> 01:45:36.480]   And they still say it was--
[01:45:36.480 --> 01:45:37.280]   They still think it.
[01:45:37.280 --> 01:45:39.360]   I mean, people--
[01:45:39.360 --> 01:45:40.320]   I will take it to them.
[01:45:40.320 --> 01:45:43.120]   I will say, my friend rocket scientist,
[01:45:43.120 --> 01:45:44.880]   Stacey Higginbotham.
[01:45:44.880 --> 01:45:46.160]   Not a rocket scientist.
[01:45:46.160 --> 01:45:48.400]   I'm sorry, brain surgeon.
[01:45:48.400 --> 01:45:50.400]   Stacey Higginbotham says--
[01:45:50.400 --> 01:45:50.960]   Babers.
[01:45:50.960 --> 01:45:52.000]   --epidibiologist.
[01:45:52.000 --> 01:45:53.920]   I stayed in a holiday unless night.
[01:45:53.920 --> 01:45:56.400]   Right.
[01:45:57.200 --> 01:45:58.400]   Humble.
[01:45:58.400 --> 01:45:58.960]   Humble.
[01:45:58.960 --> 01:45:59.440]   Humble.
[01:45:59.440 --> 01:45:59.920]   Humble.
[01:45:59.920 --> 01:46:00.480]   Humble.
[01:46:00.480 --> 01:46:01.600]   Rocket scientist.
[01:46:01.600 --> 01:46:04.080]   Inurious humble rocket scientist.
[01:46:04.080 --> 01:46:05.040]   Stacey Higginbotham.
[01:46:05.040 --> 01:46:05.760]   So this is--
[01:46:05.760 --> 01:46:07.360]   Are we now in the TikTok segment?
[01:46:07.360 --> 01:46:08.160]   Is that--
[01:46:08.160 --> 01:46:09.760]   Was that your secret plan?
[01:46:09.760 --> 01:46:11.200]   I had no TikTok quarter today.
[01:46:11.200 --> 01:46:12.160]   Oh, all right.
[01:46:12.160 --> 01:46:13.360]   I tried, but I found nothing.
[01:46:13.360 --> 01:46:15.280]   I watched a lot for you.
[01:46:15.280 --> 01:46:18.640]   Well, in your vast TikTok experience,
[01:46:18.640 --> 01:46:21.520]   what is your take on talk this day?
[01:46:21.520 --> 01:46:22.560]   Is it--
[01:46:22.560 --> 01:46:25.280]   It feels to me like it's kind of--
[01:46:25.280 --> 01:46:27.280]   Like the content is kind of going downhill.
[01:46:27.280 --> 01:46:29.280]   Maybe that's because my son no longer posts her.
[01:46:29.280 --> 01:46:30.640]   He posts her Instagram.
[01:46:30.640 --> 01:46:31.440]   But I just--
[01:46:31.440 --> 01:46:34.240]   It feels like it's not as satisfying as it used to be.
[01:46:34.240 --> 01:46:35.600]   No, I still enjoy it.
[01:46:35.600 --> 01:46:35.840]   You still--
[01:46:35.840 --> 01:46:37.280]   It's--
[01:46:37.280 --> 01:46:38.880]   For me, it varies day to day.
[01:46:38.880 --> 01:46:41.760]   The algorithm's kind of having a bad day sometimes.
[01:46:41.760 --> 01:46:42.480]   Maybe that's it.
[01:46:42.480 --> 01:46:43.040]   What's weird?
[01:46:43.040 --> 01:46:43.280]   Yeah.
[01:46:43.280 --> 01:46:45.440]   Some days better than others.
[01:46:45.440 --> 01:46:46.480]   There was--
[01:46:46.480 --> 01:46:47.440]   We mentioned the--
[01:46:47.440 --> 01:46:47.760]   Go ahead.
[01:46:47.760 --> 01:46:48.240]   I'm sorry.
[01:46:48.240 --> 01:46:50.960]   When I'm in there, it seems to be all right.
[01:46:50.960 --> 01:46:53.360]   Far is showing me things that I would like.
[01:46:53.360 --> 01:46:53.680]   Is it--
[01:46:53.680 --> 01:46:55.440]   You get a lot of musical theater?
[01:46:55.440 --> 01:46:56.640]   No, I--
[01:46:56.640 --> 01:46:57.440]   Oh, gosh.
[01:46:57.440 --> 01:46:58.400]   Thank goodness.
[01:46:58.400 --> 01:47:00.000]   I'd like to tease you.
[01:47:00.000 --> 01:47:00.480]   Oh.
[01:47:00.480 --> 01:47:01.840]   It's doing so much better for me.
[01:47:01.840 --> 01:47:02.880]   I will say that.
[01:47:02.880 --> 01:47:05.360]   There was--
[01:47:05.360 --> 01:47:06.160]   There's a business model.
[01:47:06.160 --> 01:47:10.160]   We would pay TikTok to show and musical theater.
[01:47:10.160 --> 01:47:10.800]   Stop it.
[01:47:10.800 --> 01:47:13.520]   Just stop.
[01:47:13.520 --> 01:47:19.680]   There was apparently one thing you might be interested in
[01:47:19.680 --> 01:47:23.280]   in this completely posed picture of Sundar Pichai
[01:47:23.280 --> 01:47:24.240]   and his cargo pants.
[01:47:24.240 --> 01:47:27.760]   Some have hypothesized--
[01:47:27.760 --> 01:47:30.240]   Note that a little bit of this picture
[01:47:30.240 --> 01:47:33.680]   down there in the lower left is kind of blurred out.
[01:47:33.680 --> 01:47:39.280]   Some have hypothesized that that maybe was a fold,
[01:47:39.280 --> 01:47:41.680]   a Google fold.
[01:47:41.680 --> 01:47:44.480]   Uh--
[01:47:44.480 --> 01:47:46.800]   Oh, like a little fold Easter egg?
[01:47:46.800 --> 01:47:48.880]   A little fold Easter egg, perhaps.
[01:47:48.880 --> 01:47:50.320]   Doesn't look like one to me, but--
[01:47:51.520 --> 01:47:52.560]   Remember, it was blurred.
[01:47:52.560 --> 01:47:54.080]   It modified, perhaps.
[01:47:54.080 --> 01:47:56.720]   On 47, we have video of--
[01:47:56.720 --> 01:48:00.160]   You want to see the TikTok video of the full--
[01:48:00.160 --> 01:48:02.000]   Or I'm sorry, Twitter video.
[01:48:02.000 --> 01:48:05.360]   This is from Zarekshi, whoever that--
[01:48:05.360 --> 01:48:06.640]   Oh, it's Polish.
[01:48:06.640 --> 01:48:07.600]   So there's the fold.
[01:48:07.600 --> 01:48:08.640]   Is that--
[01:48:08.640 --> 01:48:09.440]   Do you think that's--
[01:48:09.440 --> 01:48:10.960]   It looks a lot like a galaxy fold.
[01:48:10.960 --> 01:48:12.640]   I don't know.
[01:48:12.640 --> 01:48:13.360]   Maybe a little bit--
[01:48:13.360 --> 01:48:15.040]   No, the aspect ratio is more like--
[01:48:15.040 --> 01:48:18.000]   More like 3x2, don't you?
[01:48:18.000 --> 01:48:18.880]   It's interesting.
[01:48:18.880 --> 01:48:19.680]   It's more square.
[01:48:20.880 --> 01:48:21.680]   Hmm.
[01:48:21.680 --> 01:48:24.400]   Hmm.
[01:48:24.400 --> 01:48:24.880]   Hinge on it.
[01:48:24.880 --> 01:48:26.960]   Open it folds close.
[01:48:26.960 --> 01:48:27.920]   It folds open.
[01:48:27.920 --> 01:48:30.240]   Stacey, how's your flip hang--
[01:48:30.240 --> 01:48:30.720]   Hold up.
[01:48:30.720 --> 01:48:31.760]   Is it still--
[01:48:31.760 --> 01:48:33.600]   Do you have any weird creases or anything?
[01:48:33.600 --> 01:48:35.520]   On the--
[01:48:35.520 --> 01:48:36.320]   On the stamps.
[01:48:36.320 --> 01:48:37.120]   You don't use it, though.
[01:48:37.120 --> 01:48:38.720]   I do.
[01:48:38.720 --> 01:48:40.480]   Time.
[01:48:40.480 --> 01:48:41.520]   We have this covered.
[01:48:41.520 --> 01:48:42.080]   I know.
[01:48:42.080 --> 01:48:42.480]   I know.
[01:48:42.480 --> 01:48:43.920]   I don't use the computer.
[01:48:43.920 --> 01:48:45.520]   I'm trying to get you to tell the truth.
[01:48:45.520 --> 01:48:46.880]   So you do use it.
[01:48:46.880 --> 01:48:50.800]   [laughter]
[01:48:50.800 --> 01:48:52.800]   [laughter]
[01:48:52.800 --> 01:48:54.000]   The galaxy flip.
[01:48:54.000 --> 01:48:55.680]   I sent it to Stacey.
[01:48:55.680 --> 01:48:57.280]   I know she doesn't use the kobo,
[01:48:57.280 --> 01:48:57.760]   and I'm just--
[01:48:57.760 --> 01:48:59.280]   I'm waiting for it to tell the truth about it.
[01:48:59.280 --> 01:49:00.240]   Well, the kobo she--
[01:49:00.240 --> 01:49:00.880]   [laughter]
[01:49:00.880 --> 01:49:01.040]   Yeah.
[01:49:01.040 --> 01:49:02.560]   She found my boggling.
[01:49:02.560 --> 01:49:03.040]   Unusable.
[01:49:03.040 --> 01:49:04.000]   Like, it was like--
[01:49:04.000 --> 01:49:05.040]   Well, I didn't know what it was.
[01:49:05.040 --> 01:49:06.240]   It-- I was like, what?
[01:49:06.240 --> 01:49:06.720]   Huh?
[01:49:06.720 --> 01:49:08.320]   I found the bop.
[01:49:08.320 --> 01:49:09.600]   Everybody loves Raymond's parents.
[01:49:09.600 --> 01:49:09.760]   What's--
[01:49:09.760 --> 01:49:11.600]   Why are you saying it is a fruit every month?
[01:49:11.600 --> 01:49:12.080]   I--
[01:49:12.080 --> 01:49:13.360]   Why did you send me the kobo?
[01:49:13.360 --> 01:49:13.760]   Terrible.
[01:49:13.760 --> 01:49:16.560]   I found the box,
[01:49:16.560 --> 01:49:17.760]   and if I'd known,
[01:49:17.760 --> 01:49:18.800]   I would have said it in the box,
[01:49:18.800 --> 01:49:20.000]   and then you would have had a better idea
[01:49:20.000 --> 01:49:21.120]   of what the hell that was.
[01:49:21.120 --> 01:49:21.920]   But anyway,
[01:49:21.920 --> 01:49:23.280]   but the flip you knew what it was,
[01:49:23.280 --> 01:49:24.640]   because I told you I was sending that.
[01:49:24.640 --> 01:49:25.520]   And you do use it,
[01:49:25.520 --> 01:49:27.440]   and you flip it all the time,
[01:49:27.440 --> 01:49:28.000]   and it hasn't--
[01:49:28.000 --> 01:49:28.320]   I flip it.
[01:49:28.320 --> 01:49:28.960]   And it's held up?
[01:49:28.960 --> 01:49:30.800]   It's held up.
[01:49:30.800 --> 01:49:31.680]   I don't flip it.
[01:49:31.680 --> 01:49:34.400]   Certainly, I don't--
[01:49:34.400 --> 01:49:37.920]   It's not a bad function.
[01:49:37.920 --> 01:49:39.120]   It's more just like a--
[01:49:39.120 --> 01:49:40.400]   But yeah, in order to use it,
[01:49:40.400 --> 01:49:41.280]   you have to open it.
[01:49:41.280 --> 01:49:43.360]   Yeah, I think--
[01:49:43.360 --> 01:49:46.240]   I leave it open sometimes.
[01:49:46.240 --> 01:49:47.520]   So that's--
[01:49:47.520 --> 01:49:48.000]   That's--
[01:49:48.000 --> 01:49:49.840]   I'm not great about always losing--
[01:49:49.840 --> 01:49:50.720]   To keep the flipping.
[01:49:50.720 --> 01:49:52.640]   Well, no, just like--
[01:49:52.640 --> 01:49:54.720]   Because if I'm like on the couch,
[01:49:54.720 --> 01:49:55.920]   and someone asks me something,
[01:49:55.920 --> 01:49:56.880]   and I'm like, oh, hold on.
[01:49:56.880 --> 01:49:58.000]   And then I just put it down.
[01:49:58.000 --> 01:49:59.360]   I don't always close it.
[01:49:59.360 --> 01:49:59.680]   Yeah.
[01:49:59.680 --> 01:50:04.800]   So I also throw my phones around a lot,
[01:50:04.800 --> 01:50:05.920]   I'll be honest.
[01:50:05.920 --> 01:50:07.440]   And it survived,
[01:50:07.440 --> 01:50:08.160]   which is good.
[01:50:08.160 --> 01:50:09.360]   It survived.
[01:50:09.360 --> 01:50:11.520]   So the whole reason I ask this is,
[01:50:11.520 --> 01:50:12.880]   I've kind of, of the opinion,
[01:50:12.880 --> 01:50:14.240]   these folding screens.
[01:50:14.240 --> 01:50:15.680]   I haven't had great results
[01:50:15.680 --> 01:50:17.440]   with their longevity,
[01:50:17.440 --> 01:50:19.360]   but you are, and that's good.
[01:50:19.360 --> 01:50:21.440]   So maybe Google should do a fold.
[01:50:21.440 --> 01:50:22.560]   What do you guys think?
[01:50:22.560 --> 01:50:24.800]   The rumor is they'll announce it in June.
[01:50:24.800 --> 01:50:25.040]   Right.
[01:50:25.040 --> 01:50:28.160]   I would not pay what their rumored prices,
[01:50:28.160 --> 01:50:28.960]   but we'll see.
[01:50:28.960 --> 01:50:30.480]   Yeah, almost 2000.
[01:50:30.480 --> 01:50:32.000]   But again, that's just--
[01:50:32.000 --> 01:50:33.120]   That's just too expensive.
[01:50:33.120 --> 01:50:33.680]   Yeah.
[01:50:33.680 --> 01:50:35.280]   You're not going to announce it at I/O?
[01:50:35.280 --> 01:50:37.840]   Oh, I'm sorry.
[01:50:37.840 --> 01:50:38.720]   When is I/O May?
[01:50:38.720 --> 01:50:40.400]   May.
[01:50:40.400 --> 01:50:41.200]   I meant to say May.
[01:50:41.200 --> 01:50:41.680]   I'm not saying May.
[01:50:41.680 --> 01:50:42.240]   I'm coming up.
[01:50:42.240 --> 01:50:42.880]   Yeah.
[01:50:42.880 --> 01:50:44.400]   In fact, actually, good news.
[01:50:44.400 --> 01:50:47.520]   We will be sending people down
[01:50:47.520 --> 01:50:49.760]   to Google for I/O.
[01:50:49.760 --> 01:50:51.120]   Jason Howell will be down there.
[01:50:51.120 --> 01:50:54.400]   And Jason Ron and Flo will be doing a special--
[01:50:54.400 --> 01:50:56.080]   Or is it a win?
[01:50:56.080 --> 01:50:56.960]   Win to it down.
[01:50:56.960 --> 01:50:57.280]   It's a win.
[01:50:57.280 --> 01:51:00.240]   We'll be doing a win to down.
[01:51:00.240 --> 01:51:01.840]   We'll be doing--
[01:51:01.840 --> 01:51:03.120]   I've been told it's win.
[01:51:03.120 --> 01:51:05.120]   Win to it.
[01:51:05.120 --> 01:51:06.320]   Win to it.
[01:51:06.320 --> 01:51:07.280]   Win to it down.
[01:51:07.280 --> 01:51:08.080]   Now.
[01:51:08.080 --> 01:51:09.120]   I can't say it right.
[01:51:09.120 --> 01:51:09.760]   It's Vietnamese.
[01:51:09.760 --> 01:51:10.560]   It's very hard.
[01:51:10.560 --> 01:51:11.680]   You're getting close, though.
[01:51:11.680 --> 01:51:12.560]   Keep trying.
[01:51:12.560 --> 01:51:14.240]   Anyway, you know who I'm talking about.
[01:51:14.240 --> 01:51:15.440]   The wonderful win to down.
[01:51:16.480 --> 01:51:19.120]   And those other people will be down there.
[01:51:19.120 --> 01:51:25.920]   They're going to do all about Android that day.
[01:51:25.920 --> 01:51:29.520]   You and I, Jeff, and if actually I want to invite you to Stacy,
[01:51:29.520 --> 01:51:32.160]   if you want, we will be doing the keynote with Sundar.
[01:51:32.160 --> 01:51:33.040]   But we'll do it from here.
[01:51:33.040 --> 01:51:34.480]   Our respective locales.
[01:51:34.480 --> 01:51:37.280]   I had to say no.
[01:51:37.280 --> 01:51:37.760]   I'm sorry.
[01:51:37.760 --> 01:51:39.200]   It's because I record my show.
[01:51:39.200 --> 01:51:40.240]   Yeah, no, no, no.
[01:51:40.240 --> 01:51:41.760]   I was just an offer.
[01:51:41.760 --> 01:51:43.040]   Wasn't a demand.
[01:51:43.040 --> 01:51:43.840]   Here's the question.
[01:51:43.840 --> 01:51:45.520]   Will he be wearing shorts?
[01:51:45.520 --> 01:51:47.680]   I think he'll be wearing creased.
[01:51:47.680 --> 01:51:48.640]   Wouldn't that be hysterical?
[01:51:48.640 --> 01:51:49.840]   Be wearing creased cargo shorts?
[01:51:49.840 --> 01:51:50.480]   It would be great.
[01:51:50.480 --> 01:51:51.040]   Love that.
[01:51:51.040 --> 01:51:51.440]   Great.
[01:51:51.440 --> 01:51:53.920]   Anyway, so you and I, Jeff, will be doing the keynote.
[01:51:53.920 --> 01:51:54.400]   I'm looking forward to it.
[01:51:54.400 --> 01:51:55.120]   All about Android.
[01:51:55.120 --> 01:51:56.320]   They'll be doing the show from down there.
[01:51:56.320 --> 01:51:57.520]   And then they're going to do a second show,
[01:51:57.520 --> 01:51:59.440]   which will be, I think, the following week.
[01:51:59.440 --> 01:52:01.600]   They've got four people from Google.
[01:52:01.600 --> 01:52:02.560]   They're going to have on.
[01:52:02.560 --> 01:52:04.240]   They've done this before.
[01:52:04.240 --> 01:52:07.520]   So they're going to have some great information from Google I/O.
[01:52:07.520 --> 01:52:14.960]   Make sure you watch all about Android during the Google I/O 2023.
[01:52:14.960 --> 01:52:18.000]   I'm going to find out whether Google still does book talks.
[01:52:18.000 --> 01:52:18.800]   Like I used to.
[01:52:18.800 --> 01:52:23.520]   If so, I've watched many of those on YouTube, and they're really great.
[01:52:23.520 --> 01:52:25.520]   Yeah, because you should, there you go.
[01:52:25.520 --> 01:52:27.920]   That's one more thing you could do out here.
[01:52:27.920 --> 01:52:28.880]   Yeah, what about here?
[01:52:28.880 --> 01:52:30.000]   Put that on the list, man.
[01:52:30.000 --> 01:52:32.800]   We'll give you about 50.
[01:52:32.800 --> 01:52:34.560]   Anybody who's still on?
[01:52:34.560 --> 01:52:36.240]   Let me know if you still do book talks.
[01:52:36.240 --> 01:52:37.920]   Yeah, usually Jeff's available.
[01:52:37.920 --> 01:52:40.000]   What's the date of that commonwealth talk?
[01:52:40.000 --> 01:52:41.360]   I'll cover the talk.
[01:52:41.360 --> 01:52:42.800]   I found these results on search.
[01:52:43.760 --> 01:52:47.680]   I said, I knew somebody who actually worked with Google.
[01:52:47.680 --> 01:52:49.360]   They've rejected you.
[01:52:49.360 --> 01:52:51.120]   They've cut off all support for you.
[01:52:51.120 --> 01:52:53.120]   You're nothing at all.
[01:52:53.120 --> 01:52:56.400]   You're ex-Google, sympathetic.
[01:52:56.400 --> 01:52:58.400]   Did you just say you're nothing anymore?
[01:52:58.400 --> 01:53:00.000]   You still mean to Google?
[01:53:00.000 --> 01:53:00.640]   That's the word.
[01:53:00.640 --> 01:53:03.920]   No, it's, I mean to the device that thinks it's still a Google.
[01:53:03.920 --> 01:53:07.520]   It's just an employee who's now been laid off and doesn't know it, right?
[01:53:07.520 --> 01:53:08.480]   Uh, gosh.
[01:53:10.480 --> 01:53:16.240]   Where were we? Oh, the 25th of July at the Commonwealth Club in San Francisco
[01:53:16.240 --> 01:53:17.600]   and the 26th all come up.
[01:53:17.600 --> 01:53:20.240]   I'm already, I'm already having sweaty problems about the bridge.
[01:53:20.240 --> 01:53:20.800]   Honest to God.
[01:53:20.800 --> 01:53:23.600]   Do you...
[01:53:23.600 --> 01:53:26.800]   Okay.
[01:53:26.800 --> 01:53:34.160]   In my personal opinion, the fact that an AI could do a credible Drake song is not that exciting.
[01:53:34.160 --> 01:53:35.680]   No.
[01:53:35.680 --> 01:53:36.400]   No.
[01:53:36.400 --> 01:53:39.440]   Because Drake sucks.
[01:53:39.440 --> 01:53:41.520]   About the weekend.
[01:53:41.520 --> 01:53:42.400]   What do you think of the weekend?
[01:53:42.400 --> 01:53:43.360]   Oh, even worse.
[01:53:43.360 --> 01:53:44.160]   Okay.
[01:53:44.160 --> 01:53:45.120]   Oh, well.
[01:53:45.120 --> 01:53:45.360]   So...
[01:53:45.360 --> 01:53:46.160]   Oh.
[01:53:46.160 --> 01:53:47.040]   Okay.
[01:53:47.040 --> 01:53:51.200]   AC needs some spell of assaults.
[01:53:51.200 --> 01:53:52.560]   He just pissed off Stacy.
[01:53:52.560 --> 01:53:54.640]   He didn't piss off our fan base, I'm sure.
[01:53:54.640 --> 01:53:54.960]   So...
[01:53:54.960 --> 01:53:55.760]   One, two.
[01:53:55.760 --> 01:53:59.040]   I'm a Kendrick Lamar fan.
[01:53:59.040 --> 01:54:00.880]   I think Drake is a little, anyway.
[01:54:00.880 --> 01:54:01.760]   Now you're talking.
[01:54:01.760 --> 01:54:02.800]   Yeah, that's...
[01:54:02.800 --> 01:54:05.040]   I like Kendrick LeC'mart as well, but...
[01:54:05.760 --> 01:54:07.440]   Drake, I mean, I grew up on--
[01:54:07.440 --> 01:54:08.400]   No, Drake's fine.
[01:54:08.400 --> 01:54:08.800]   And yeah.
[01:54:08.800 --> 01:54:09.280]   Just teasing.
[01:54:09.280 --> 01:54:09.680]   He's...
[01:54:09.680 --> 01:54:13.280]   Drake is the nickel back of rappers.
[01:54:13.280 --> 01:54:13.920]   Is that fair?
[01:54:13.920 --> 01:54:14.880]   That is fair.
[01:54:14.880 --> 01:54:15.280]   That...
[01:54:15.280 --> 01:54:15.840]   Okay, yes.
[01:54:15.840 --> 01:54:16.320]   Okay, okay.
[01:54:16.320 --> 01:54:17.280]   I'm just saying...
[01:54:17.280 --> 01:54:18.480]   Oh, jeez.
[01:54:18.480 --> 01:54:19.600]   Oh.
[01:54:19.600 --> 01:54:20.480]   Is he Canadian?
[01:54:20.480 --> 01:54:20.960]   That's a...
[01:54:20.960 --> 01:54:21.360]   Yes.
[01:54:21.360 --> 01:54:22.240]   Yes, Canadian.
[01:54:22.240 --> 01:54:22.960]   Yes, Canadian.
[01:54:22.960 --> 01:54:24.640]   Yes, he was on the grassy.
[01:54:24.640 --> 01:54:27.360]   He was a child star under grassy.
[01:54:27.360 --> 01:54:28.800]   He grew up in the hood.
[01:54:28.800 --> 01:54:31.280]   If the hood is upper West Side Journal.
[01:54:31.280 --> 01:54:32.960]   He grew up in the sixth.
[01:54:32.960 --> 01:54:35.920]   [laughter]
[01:54:35.920 --> 01:54:40.000]   Anyway, the reason I bring this up is a TikTok user named
[01:54:40.000 --> 01:54:41.680]   Ghostwriter977.
[01:54:41.680 --> 01:54:48.160]   Created a AI-generated song with Drake in the weekend,
[01:54:48.160 --> 01:54:49.600]   but it wasn't Drake in the weekend.
[01:54:49.600 --> 01:54:55.280]   There's a Kendrick Lamar version of Off the Grid.
[01:54:55.280 --> 01:54:56.880]   There's Rihanna singing "Cuffet."
[01:54:56.880 --> 01:55:02.000]   And these are all fake AI-generated.
[01:55:02.000 --> 01:55:06.000]   Now, I listened to it, but since I think Drake is a nickel back of rap,
[01:55:06.000 --> 01:55:08.000]   I was underwhelmed.
[01:55:08.000 --> 01:55:12.240]   But apparently, the song, according to the Washington Post,
[01:55:12.240 --> 01:55:16.800]   sparked a panic in the music industry because it got...
[01:55:16.800 --> 01:55:17.520]   And they should be.
[01:55:17.520 --> 01:55:18.080]   And they should be.
[01:55:18.080 --> 01:55:18.640]   Right?
[01:55:18.640 --> 01:55:19.280]   They should be.
[01:55:19.280 --> 01:55:19.920]   Well, it's interesting.
[01:55:19.920 --> 01:55:21.840]   The artist responses a little different, but anyway,
[01:55:21.840 --> 01:55:26.480]   15 million views on TikTok, 600,000 streams on Spotify.
[01:55:26.480 --> 01:55:30.480]   It has now hearted my sleeve.
[01:55:30.480 --> 01:55:32.560]   I can't play it for you because it's gone.
[01:55:32.560 --> 01:55:34.240]   It's been removed from all digital surveys.
[01:55:34.240 --> 01:55:35.680]   Here's the question.
[01:55:35.680 --> 01:55:36.800]   Here's the question.
[01:55:36.800 --> 01:55:39.040]   Given the copyright discussion and trademark discussion
[01:55:39.040 --> 01:55:41.360]   we had earlier, not very bad, but patent discussion made earlier,
[01:55:41.360 --> 01:55:45.200]   was it taken down because it was a copyright violation
[01:55:45.200 --> 01:55:46.960]   when in fact you can't cut it right?
[01:55:46.960 --> 01:55:47.760]   They were made up.
[01:55:47.760 --> 01:55:48.320]   Is it?
[01:55:48.320 --> 01:55:52.480]   Or was it just because they didn't want to pieve the publishing house?
[01:55:52.480 --> 01:55:53.840]   Or...
[01:55:53.840 --> 01:55:56.320]   We talked about this a little last week too.
[01:55:56.320 --> 01:55:57.280]   Oh, of course.
[01:55:57.280 --> 01:55:57.760]   I'm sorry.
[01:55:57.760 --> 01:55:58.640]   Is this an older...
[01:55:58.640 --> 01:55:59.520]   This is kind of an older story.
[01:55:59.520 --> 01:56:00.000]   It's okay.
[01:56:00.000 --> 01:56:01.440]   So if we talked about this last week.
[01:56:01.440 --> 01:56:02.240]   I did kind of want to...
[01:56:02.240 --> 01:56:04.240]   Well, I just wanted to just Drake mainly.
[01:56:04.240 --> 01:56:06.640]   How rude.
[01:56:06.640 --> 01:56:07.360]   Mission accomplished.
[01:56:07.360 --> 01:56:08.320]   Oh, so rude.
[01:56:08.320 --> 01:56:08.800]   So rude.
[01:56:08.800 --> 01:56:09.200]   That would.
[01:56:09.200 --> 01:56:12.480]   But it goes back to this whole thing about it.
[01:56:12.480 --> 01:56:16.000]   You can't copyright or patent something that AI created.
[01:56:16.000 --> 01:56:17.280]   So why is it a threat?
[01:56:17.280 --> 01:56:18.720]   Because it sold a lot of songs.
[01:56:18.720 --> 01:56:20.480]   Got a lot of spins.
[01:56:20.480 --> 01:56:23.520]   I don't know.
[01:56:23.520 --> 01:56:24.720]   This is really interesting.
[01:56:26.320 --> 01:56:30.320]   And actually the post quote it's a law journal,
[01:56:30.320 --> 01:56:31.760]   a law professor, rather K.G.
[01:56:31.760 --> 01:56:33.440]   Agreein who said the history...
[01:56:33.440 --> 01:56:36.400]   And this is true of black artists within USIP law
[01:56:36.400 --> 01:56:39.840]   has been one of appropriation, degradation, and devaluation.
[01:56:39.840 --> 01:56:43.040]   And that's absolutely true, right?
[01:56:43.040 --> 01:56:45.120]   You know that it took Elvis to take
[01:56:45.120 --> 01:56:47.040]   Little Richard's music and make it popular.
[01:56:47.040 --> 01:56:48.480]   Pat Boone.
[01:56:48.480 --> 01:56:51.040]   Sorry.
[01:56:51.040 --> 01:56:52.480]   Boone.
[01:56:52.480 --> 01:56:53.520]   Oh my god.
[01:56:53.520 --> 01:56:53.840]   Yeah.
[01:56:55.040 --> 01:56:59.280]   Pat Boone singing Little Richard is something.
[01:56:59.280 --> 01:56:59.600]   Boy.
[01:56:59.600 --> 01:57:01.920]   There's a new movie about Little Richard.
[01:57:01.920 --> 01:57:02.960]   I can't, I heard a new documentary.
[01:57:02.960 --> 01:57:04.080]   I can't wait to see.
[01:57:04.080 --> 01:57:04.720]   Love.
[01:57:04.720 --> 01:57:05.520]   Oh, Richard.
[01:57:05.520 --> 01:57:06.160]   Nice.
[01:57:06.160 --> 01:57:06.400]   Yeah.
[01:57:06.400 --> 01:57:08.160]   Anyway, okay.
[01:57:08.160 --> 01:57:09.200]   So you already talked about this.
[01:57:09.200 --> 01:57:10.960]   We don't have to bring it back.
[01:57:10.960 --> 01:57:17.920]   Grimes has tweeted that I will be glad to collab with any AI,
[01:57:17.920 --> 01:57:20.960]   as long as and I will share the profits 50/50.
[01:57:20.960 --> 01:57:22.640]   So she's addressed this and said,
[01:57:22.640 --> 01:57:26.080]   "Look, that's fine, but let's share in the profits."
[01:57:26.080 --> 01:57:29.520]   But if you can't...
[01:57:29.520 --> 01:57:30.800]   Well, how did you share profits with...
[01:57:30.800 --> 01:57:31.360]   Yeah, I was about to...
[01:57:31.360 --> 01:57:31.920]   How do you know?
[01:57:31.920 --> 01:57:33.760]   Well, you know...
[01:57:33.760 --> 01:57:35.280]   Well, there's profits when you send...
[01:57:35.280 --> 01:57:36.800]   Do you send the transfer?
[01:57:36.800 --> 01:57:39.040]   If you have 600,000 streams on Spotify,
[01:57:39.040 --> 01:57:41.200]   you're getting something for those streams, right?
[01:57:41.200 --> 01:57:42.880]   TikTok, no.
[01:57:42.880 --> 01:57:46.320]   Yeah, where are they sending that transfer though?
[01:57:46.320 --> 01:57:48.320]   Oh, who do you count?
[01:57:48.320 --> 01:57:50.640]   Well, whoever did the AI goes the entity...
[01:57:50.640 --> 01:57:53.600]   Ghost Rider 977, I guess, right?
[01:57:53.600 --> 01:57:54.000]   Right.
[01:57:54.000 --> 01:57:57.440]   Ghost Rider shouldn't make any money on it,
[01:57:57.440 --> 01:58:02.480]   because he's basically piggybacking on previous works by Drake in the weekend.
[01:58:02.480 --> 01:58:03.200]   So I don't...
[01:58:03.200 --> 01:58:04.560]   I apologize.
[01:58:04.560 --> 01:58:06.080]   I forgot this is an older story.
[01:58:06.080 --> 01:58:06.880]   I just...
[01:58:06.880 --> 01:58:08.400]   I was all week of...
[01:58:08.400 --> 01:58:09.600]   Where are you being, man?
[01:58:09.600 --> 01:58:10.080]   Come on.
[01:58:10.080 --> 01:58:11.840]   Ah, but then nobody was talking about...
[01:58:11.840 --> 01:58:13.360]   I was caught chewing Pepe every time.
[01:58:13.360 --> 01:58:14.880]   By the way, the food is great and rum.
[01:58:14.880 --> 01:58:15.440]   The music...
[01:58:15.440 --> 01:58:17.360]   Well, it's weird.
[01:58:18.640 --> 01:58:23.040]   Italian pop music is very, very strange.
[01:58:23.040 --> 01:58:27.360]   She's not dare to listen to music though.
[01:58:27.360 --> 01:58:29.280]   Anyway.
[01:58:29.280 --> 01:58:30.480]   Well, but no, I enjoyed it.
[01:58:30.480 --> 01:58:32.640]   But it's just weird.
[01:58:32.640 --> 01:58:33.920]   It's just...
[01:58:33.920 --> 01:58:34.720]   I think Lisa...
[01:58:34.720 --> 01:58:39.920]   Let me see if she posted a clip from one of these
[01:58:39.920 --> 01:58:43.040]   restaurants that we were in.
[01:58:43.040 --> 01:58:45.920]   Maybe not.
[01:58:45.920 --> 01:58:48.480]   There is a... I have a video clip of us enjoying some...
[01:58:48.480 --> 01:58:52.000]   some fine pop music in a Italian restaurant.
[01:58:52.000 --> 01:58:55.440]   But I don't have a clue.
[01:58:55.440 --> 01:58:56.720]   I have anywhere to show you.
[01:58:56.720 --> 01:58:57.520]   Okay, that's that.
[01:58:57.520 --> 01:58:59.200]   I don't have the more to say about that.
[01:58:59.200 --> 01:59:01.760]   Bad Bunny and Rihanna, AI do it now.
[01:59:01.760 --> 01:59:05.680]   Sure.
[01:59:05.680 --> 01:59:09.360]   The fake Drake and the weekend creator seems to be behind it.
[01:59:09.360 --> 01:59:11.120]   Fake Drake is actually a pretty good name.
[01:59:11.120 --> 01:59:12.240]   I'd copyright that.
[01:59:12.240 --> 01:59:12.800]   Oh, yeah?
[01:59:14.480 --> 01:59:19.440]   Heart of my sleeve is the Drake tune.
[01:59:19.440 --> 01:59:21.280]   Now...
[01:59:21.280 --> 01:59:24.320]   Well, that was last Tuesday.
[01:59:24.320 --> 01:59:24.880]   Never mind.
[01:59:24.880 --> 01:59:26.320]   This is all old names.
[01:59:26.320 --> 01:59:27.120]   Forget it.
[01:59:27.120 --> 01:59:28.000]   I didn't put it in there.
[01:59:28.000 --> 01:59:28.720]   You put it in there.
[01:59:28.720 --> 01:59:29.600]   So I don't blame me.
[01:59:29.600 --> 01:59:31.360]   No, I did because I thought it was good.
[01:59:31.360 --> 01:59:32.160]   Let me make clear.
[01:59:32.160 --> 01:59:33.040]   That was important.
[01:59:33.040 --> 01:59:34.640]   The stale.
[01:59:34.640 --> 01:59:35.040]   That's all.
[01:59:35.040 --> 01:59:40.960]   Does it show, as Reason Magazine said,
[01:59:40.960 --> 01:59:42.960]   the potential for AI's future?
[01:59:43.840 --> 01:59:47.600]   Do you want to see some certain artists
[01:59:47.600 --> 01:59:50.240]   are going to be quiet all right when it comes to AI?
[01:59:50.240 --> 01:59:54.640]   Because some artists are really talented
[01:59:54.640 --> 01:59:57.520]   and can put something out there that's going to be catchy
[01:59:57.520 --> 02:00:00.080]   and AI is just not going to be that good.
[02:00:00.080 --> 02:00:00.480]   That's right.
[02:00:00.480 --> 02:00:03.680]   I think we don't have to worry about AI creations.
[02:00:03.680 --> 02:00:04.960]   Yeah, I don't think so.
[02:00:04.960 --> 02:00:06.080]   Well, and you don't have to worry...
[02:00:06.080 --> 02:00:08.080]   I mean, should you worry about it in pop music?
[02:00:08.080 --> 02:00:10.640]   Where familiarity is what we're usually looking for?
[02:00:10.640 --> 02:00:11.120]   You got to get...
[02:00:11.120 --> 02:00:11.680]   Yeah, maybe.
[02:00:11.680 --> 02:00:12.080]   But...
[02:00:12.080 --> 02:00:14.880]   You got to get on the AM radio if you really want to make it hit.
[02:00:14.880 --> 02:00:16.080]   At least that's what I'm told.
[02:00:16.080 --> 02:00:18.240]   I don't think it's...
[02:00:18.240 --> 02:00:22.480]   AI could have played AM as kids here.
[02:00:22.480 --> 02:00:25.120]   5,000 watts of power, huh?
[02:00:25.120 --> 02:00:31.360]   It's time for the Google Change Log.
[02:00:31.360 --> 02:00:37.760]   Google Authenticator has finally, well,
[02:00:37.760 --> 02:00:40.080]   but not so fast added syncing.
[02:00:40.080 --> 02:00:42.480]   You were just playing this to me for two-factor codes.
[02:00:42.480 --> 02:00:43.360]   So when you...
[02:00:43.360 --> 02:00:46.160]   I long ago abandoned Google Authenticator
[02:00:46.160 --> 02:00:48.480]   because I get a lot of phones, new phones.
[02:00:48.480 --> 02:00:50.320]   I'm always setting authenticators up.
[02:00:50.320 --> 02:00:55.120]   I don't want to have to go out and get all new two-factor QR codes.
[02:00:55.120 --> 02:01:00.400]   Actually, our security guy, Steve Gibson solves that
[02:01:00.400 --> 02:01:05.920]   screenshotting the QR codes, printing them out and putting them in a notebook.
[02:01:05.920 --> 02:01:07.840]   Then he has them when he gets a new phone.
[02:01:07.840 --> 02:01:08.320]   Wow.
[02:01:09.760 --> 02:01:11.040]   I'm not sure I'd recommend that.
[02:01:11.040 --> 02:01:12.800]   I, for a long time, have been using...
[02:01:12.800 --> 02:01:17.680]   We mentioned Authy, which would automatically sync to the cloud,
[02:01:17.680 --> 02:01:19.760]   you know, do what this thing that Google's now doing.
[02:01:19.760 --> 02:01:21.200]   Or...
[02:01:21.200 --> 02:01:24.560]   And now I've got one that's, I think, better, which is two FAS.
[02:01:24.560 --> 02:01:25.760]   That's the one I used.
[02:01:25.760 --> 02:01:26.400]   It's free.
[02:01:26.400 --> 02:01:27.360]   It's open source.
[02:01:27.360 --> 02:01:28.720]   So, you know, you can look at the code.
[02:01:28.720 --> 02:01:30.400]   You know, it's not doing anything weird.
[02:01:30.400 --> 02:01:33.360]   And it backs up either to Google Drive or iCloud.
[02:01:33.360 --> 02:01:34.320]   But you encrypt it.
[02:01:34.320 --> 02:01:35.360]   It's end-to-end encrypted.
[02:01:35.360 --> 02:01:36.480]   So you encrypt it.
[02:01:36.480 --> 02:01:37.520]   And then it backs it up.
[02:01:37.520 --> 02:01:39.040]   So only you can look at it.
[02:01:39.040 --> 02:01:41.040]   So that has worked out very well for me.
[02:01:41.040 --> 02:01:43.440]   Some have said, and I have to look into this,
[02:01:43.440 --> 02:01:49.040]   that this Google Authenticator backup is not end-to-end encrypted.
[02:01:49.040 --> 02:01:56.560]   Which would be problematic because, well, it means that if somebody could get into your
[02:01:56.560 --> 02:02:01.600]   Google account, they could just, you know, back and restore your Authenticator.
[02:02:01.600 --> 02:02:07.920]   So I don't, you know, I haven't very independently verified this.
[02:02:08.560 --> 02:02:09.520]   So...
[02:02:09.520 --> 02:02:15.920]   Wouldn't this be a part of Google's strategy to make sure that it's encrypted into end?
[02:02:15.920 --> 02:02:16.480]   Yeah.
[02:02:16.480 --> 02:02:18.000]   You know, I trust Google.
[02:02:18.000 --> 02:02:18.480]   I do.
[02:02:18.480 --> 02:02:22.400]   I totally trust Google's security.
[02:02:22.400 --> 02:02:26.000]   But they mention nothing about this.
[02:02:26.000 --> 02:02:31.600]   Well, when they, when they talk about this, they mention nothing about encryption.
[02:02:31.600 --> 02:02:33.040]   And I've seen some articles.
[02:02:33.040 --> 02:02:35.280]   Again, I haven't independently verified it.
[02:02:35.280 --> 02:02:36.320]   Let's say it's not.
[02:02:37.120 --> 02:02:38.800]   So you'll know if it is or isn't.
[02:02:38.800 --> 02:02:40.320]   If you, well, you maybe won't.
[02:02:40.320 --> 02:02:42.080]   You'll still have to provide a password.
[02:02:42.080 --> 02:02:44.560]   But does Google keep that password as a question?
[02:02:44.560 --> 02:02:51.840]   So I'm not going to recommend it, but this is a feature that's been long needed on Google Authenticator.
[02:02:51.840 --> 02:02:55.440]   Here's, oh, wait a minute.
[02:02:55.440 --> 02:02:56.640]   Here's nine to five Google.
[02:02:56.640 --> 02:03:01.680]   I trust this Google on why Authenticator Sync isn't end-to-end encrypted.
[02:03:01.680 --> 02:03:02.960]   They said that's coming later.
[02:03:04.640 --> 02:03:06.640]   So MISC discovered this.
[02:03:06.640 --> 02:03:09.760]   And I think it's very valid.
[02:03:09.760 --> 02:03:15.040]   Google today explained, it says nine to five Google that they want to offer features
[02:03:15.040 --> 02:03:17.920]   to protect users but are useful and convenient.
[02:03:17.920 --> 02:03:21.520]   But are useful and convenient.
[02:03:21.520 --> 02:03:23.120]   Useful and convenient.
[02:03:23.120 --> 02:03:28.000]   Acknowledging that E2EE is a powerful feature that provides extra protections,
[02:03:28.000 --> 02:03:32.160]   the downside is users might get locked out of their own data without recovery if they forget
[02:03:32.160 --> 02:03:36.240]   their Google account password or whatever extra password you use.
[02:03:36.240 --> 02:03:37.600]   That happens.
[02:03:37.600 --> 02:03:37.920]   Yeah.
[02:03:37.920 --> 02:03:40.720]   That's why you print them out and you leave them somewhere.
[02:03:40.720 --> 02:03:44.400]   And I'm serious.
[02:03:44.400 --> 02:03:45.760]   If you lose like two refactors.
[02:03:45.760 --> 02:03:48.400]   If you lose two factors, not the end of the world.
[02:03:48.400 --> 02:03:56.000]   I think this is just expensive for Google because they have those to invalidate you.
[02:03:56.000 --> 02:03:57.280]   Yeah, or okay.
[02:03:57.280 --> 02:03:57.280]   Okay.
[02:03:57.280 --> 02:04:01.280]   So you know, you always have recovery codes whenever you set up two factor.
[02:04:01.280 --> 02:04:03.040]   So you should always have those.
[02:04:03.040 --> 02:04:08.320]   And in most cases, you can turn off two factor and then re-do it.
[02:04:08.320 --> 02:04:13.040]   Because in effect, it's the same thing as when I get a new phone with Google
[02:04:13.040 --> 02:04:15.280]   up that I get her, I have to go out and redo it.
[02:04:15.280 --> 02:04:15.600]   Right.
[02:04:15.600 --> 02:04:16.800]   Anyway.
[02:04:16.800 --> 02:04:18.320]   Wait a minute.
[02:04:18.320 --> 02:04:18.800]   Hold on.
[02:04:18.800 --> 02:04:19.360]   Hold on.
[02:04:19.360 --> 02:04:25.040]   So you're saying if I'm locked out, I have a way of...
[02:04:25.040 --> 02:04:29.360]   In most cases, going in and turning off the two FA if I'm locked out so I can get in.
[02:04:29.360 --> 02:04:30.160]   I don't...
[02:04:30.160 --> 02:04:31.760]   Actually, that doesn't sound secure either, does it?
[02:04:31.760 --> 02:04:33.680]   No.
[02:04:33.680 --> 02:04:34.240]   Never mind.
[02:04:34.240 --> 02:04:37.040]   Can't end encryption.
[02:04:37.040 --> 02:04:38.400]   I don't think this is right.
[02:04:38.400 --> 02:04:44.240]   They are adding end-to-end encryption, however, for RCS group chats.
[02:04:44.240 --> 02:04:46.000]   This was in beta for a while.
[02:04:46.000 --> 02:04:50.080]   Google messages start showing end-to-end encryption for group chats.
[02:04:50.080 --> 02:04:52.160]   So it's useful.
[02:04:52.160 --> 02:04:52.960]   Yeah, it is good.
[02:04:52.960 --> 02:04:53.600]   See?
[02:04:53.600 --> 02:04:55.840]   They like end-to-end encryption here, but not there.
[02:04:57.680 --> 02:05:03.920]   Google's making it much easier to search for tools in Docs, Sheets, and Slides.
[02:05:03.920 --> 02:05:06.640]   You think as a search engine, they'd probably be good at this.
[02:05:06.640 --> 02:05:12.080]   They now have a search bar that allows users to locate tools and features using their own words.
[02:05:12.080 --> 02:05:14.880]   Whose words would you be using?
[02:05:14.880 --> 02:05:16.880]   Using Ants words.
[02:05:16.880 --> 02:05:19.280]   Or rather than a paperclip.
[02:05:19.280 --> 02:05:22.640]   Make it easy for me to search email and Gmail.
[02:05:25.040 --> 02:05:27.920]   You don't need to remember the specific name of the tool you need is description of the
[02:05:27.920 --> 02:05:29.040]   feature of the device.
[02:05:29.040 --> 02:05:33.520]   So it's just the natural language, something Google said for 15 years on their search.
[02:05:33.520 --> 02:05:35.920]   Okay, fine.
[02:05:35.920 --> 02:05:37.760]   Google Apps Chromebook privacy.
[02:05:37.760 --> 02:05:41.200]   They're now adding a new camera and mic switch.
[02:05:41.200 --> 02:05:46.560]   So you can turn off the camera and microphone system-wide.
[02:05:46.560 --> 02:05:51.520]   You know, yeah, the best thing, of course, would be to get a device that has a physical
[02:05:51.520 --> 02:05:54.720]   shutter, but microphone's a little harder.
[02:05:55.120 --> 02:05:56.240]   My friends are a little harder.
[02:05:56.240 --> 02:05:57.600]   So nice.
[02:05:57.600 --> 02:05:58.640]   You can toggle it off.
[02:05:58.640 --> 02:06:02.480]   It'll be in the privacy control panel in Chrome OS.
[02:06:02.480 --> 02:06:03.840]   You can toggle it back on then?
[02:06:03.840 --> 02:06:04.080]   Yeah.
[02:06:04.080 --> 02:06:05.440]   Okay.
[02:06:05.440 --> 02:06:06.800]   See this?
[02:06:06.800 --> 02:06:07.280]   Toggle.
[02:06:07.280 --> 02:06:09.520]   Toggle means on and off.
[02:06:09.520 --> 02:06:13.200]   Well, no, but if you turned it off for all applications, did you have to turn it on
[02:06:13.200 --> 02:06:14.320]   application by application again?
[02:06:14.320 --> 02:06:15.360]   No, no, no, no, no, no, no, no.
[02:06:15.360 --> 02:06:17.120]   It's all for previously approved.
[02:06:17.120 --> 02:06:19.120]   It's allow access-
[02:06:19.120 --> 02:06:21.280]   It overrides it.
[02:06:21.280 --> 02:06:22.320]   That's right.
[02:06:22.320 --> 02:06:22.560]   Okay, God.
[02:06:22.560 --> 02:06:23.360]   I see what you're saying.
[02:06:23.360 --> 02:06:26.160]   No, that's reasonable because normally you do that one by one.
[02:06:26.160 --> 02:06:27.280]   That's completely reasonable.
[02:06:27.280 --> 02:06:32.400]   Google Bard, which I don't know if about you, but I've been less than impressed with Google Bard.
[02:06:32.400 --> 02:06:35.760]   I've not opened it up.
[02:06:35.760 --> 02:06:36.000]   Yeah.
[02:06:36.000 --> 02:06:38.080]   I did open it up.
[02:06:38.080 --> 02:06:42.640]   Wait, I did open it up when I got the little invitation, but I haven't opened it up since then.
[02:06:42.640 --> 02:06:46.400]   Frankly, I pay for chat GPT and I haven't opened it up that much either.
[02:06:46.400 --> 02:06:47.200]   I see.
[02:06:47.200 --> 02:06:49.120]   I think flash of the pan, man.
[02:06:49.120 --> 02:06:49.600]   Yeah.
[02:06:50.160 --> 02:06:54.800]   You know what I did do though, when we had an unscheduled stop in Genoa,
[02:06:54.800 --> 02:06:58.160]   we were supposed to go to Portofina, but the waves were too high,
[02:06:58.160 --> 02:06:58.960]   went to Genoa.
[02:06:58.960 --> 02:07:01.280]   So I asked chat GPT to recommend.
[02:07:01.280 --> 02:07:05.200]   I said, "Give me a three-hour tour of starting here."
[02:07:05.200 --> 02:07:06.480]   And it actually-
[02:07:06.480 --> 02:07:07.520]   Three-hour tour.
[02:07:07.520 --> 02:07:13.520]   It gave me a pretty good suggestion of things to do, and it knew,
[02:07:13.520 --> 02:07:16.960]   you know, that's 15 steps and you'll be able to do this and you should be done in three hours.
[02:07:16.960 --> 02:07:17.760]   It was pretty good.
[02:07:17.760 --> 02:07:18.560]   And it gave me everything.
[02:07:18.560 --> 02:07:20.320]   A bunch of Christopher Columbus stuff.
[02:07:20.320 --> 02:07:20.800]   Yeah.
[02:07:20.800 --> 02:07:22.000]   Christopher Columbus' house.
[02:07:22.000 --> 02:07:22.640]   Very good.
[02:07:22.640 --> 02:07:23.280]   That's good, eh?
[02:07:23.280 --> 02:07:27.280]   Google Bard now can do one more thing.
[02:07:27.280 --> 02:07:31.440]   It's something Microsoft's co-pilot, GitHub co-pilot can do,
[02:07:31.440 --> 02:07:34.960]   which is write, debug, and explain codes.
[02:07:34.960 --> 02:07:40.400]   They've added coding capabilities for C++ Go, Java, JavaScript, Python, and TypeScript.
[02:07:40.400 --> 02:07:48.480]   And you can, even with Python, export the code to Google Colab without copying and pasting.
[02:07:49.360 --> 02:07:55.200]   It's actually a very handy feature of these to paste in some code and say,
[02:07:55.200 --> 02:07:55.840]   "What does this do?"
[02:07:55.840 --> 02:07:56.800]   Or, "What does this mean?"
[02:07:56.800 --> 02:08:01.440]   Especially with regular expressions, things like that are a little bit obscure.
[02:08:01.440 --> 02:08:03.600]   I'm pretty curious to see that.
[02:08:03.600 --> 02:08:08.640]   Because it was hard for me to understand a human trying to explain
[02:08:08.640 --> 02:08:14.400]   code to me, you know, explaining classes and inheritance and stuff like that.
[02:08:14.400 --> 02:08:17.120]   So I'd like to see how I could do it.
[02:08:17.120 --> 02:08:24.080]   I've seen people claim that one of the advantages of this AI chat stuff is going to be as a teacher.
[02:08:24.080 --> 02:08:28.720]   And I have seen that in the past where you could say, "Well, explain monads to me,"
[02:08:28.720 --> 02:08:30.080]   and would do very well.
[02:08:30.080 --> 02:08:34.400]   Somebody I just saw from somebody well-known who said, "What was this?"
[02:08:34.400 --> 02:08:38.160]   That in a few years, your kid will learn to read from chat GPT.
[02:08:38.160 --> 02:08:39.920]   That that will be...
[02:08:39.920 --> 02:08:42.960]   Your kid can already learn to read from an AI.
[02:08:42.960 --> 02:08:44.080]   I mean, there are apps on your...
[02:08:44.720 --> 02:08:49.040]   That you put on your iPad or your phone that will run them through the alphabet
[02:08:49.040 --> 02:08:50.480]   and letters and all that.
[02:08:50.480 --> 02:08:51.120]   Yeah.
[02:08:51.120 --> 02:08:51.520]   Yeah.
[02:08:51.520 --> 02:08:56.720]   Somebody well-known, I can't remember who it was.
[02:08:56.720 --> 02:08:57.600]   Google Assistant.
[02:08:57.600 --> 02:09:01.200]   Maybe they don't have a kid and they're not aware of all that's happening and reading technical...
[02:09:01.200 --> 02:09:01.760]   Maybe.
[02:09:01.760 --> 02:09:02.080]   Yeah.
[02:09:02.080 --> 02:09:06.640]   But a human taught your child to read, right?
[02:09:06.640 --> 02:09:07.040]   Or no?
[02:09:07.040 --> 02:09:09.440]   A human antennae.
[02:09:09.440 --> 02:09:10.240]   Really?
[02:09:10.240 --> 02:09:10.720]   A neat.
[02:09:10.720 --> 02:09:12.400]   Well, we weren't...
[02:09:12.400 --> 02:09:13.440]   That's really cool.
[02:09:14.240 --> 02:09:15.360]   Yeah. My kid had...
[02:09:15.360 --> 02:09:18.640]   They were dual language, so it took a longer to learn to read.
[02:09:18.640 --> 02:09:21.520]   So we...
[02:09:21.520 --> 02:09:22.320]   What do they speak?
[02:09:22.320 --> 02:09:24.880]   Spanish and English?
[02:09:24.880 --> 02:09:26.080]   Oh, how did that happen?
[02:09:26.080 --> 02:09:28.400]   Did you send them to a Spanish school?
[02:09:28.400 --> 02:09:28.560]   Spanish school?
[02:09:28.560 --> 02:09:29.040]   Spanish school?
[02:09:29.040 --> 02:09:29.600]   Oh, you did.
[02:09:29.600 --> 02:09:30.320]   Oh, that's cool.
[02:09:30.320 --> 02:09:31.120]   That was in Austin.
[02:09:31.120 --> 02:09:32.480]   That's so freaking awesome.
[02:09:32.480 --> 02:09:33.200]   I love that.
[02:09:33.200 --> 02:09:36.240]   I regret not doing that, actually.
[02:09:36.240 --> 02:09:36.960]   That's a great...
[02:09:36.960 --> 02:09:37.440]   That's a great...
[02:09:37.440 --> 02:09:39.840]   Yeah, that was my argument for my husband and I won that.
[02:09:39.840 --> 02:09:41.120]   Yeah.
[02:09:41.120 --> 02:09:44.080]   I got to spend a lot of money on school tuition.
[02:09:44.080 --> 02:09:46.960]   Yeah, well, are they fluent in both still?
[02:09:46.960 --> 02:09:48.640]   Oh, yeah.
[02:09:48.640 --> 02:09:48.960]   Yeah.
[02:09:48.960 --> 02:09:49.520]   They...
[02:09:49.520 --> 02:09:52.000]   Yeah, they...
[02:09:52.000 --> 02:09:54.560]   They are amazing.
[02:09:54.560 --> 02:09:55.040]   That's amazing.
[02:09:55.040 --> 02:09:59.040]   They ever complain about it, or recognize the value of it early.
[02:09:59.040 --> 02:09:59.440]   Oh, no.
[02:09:59.440 --> 02:10:00.800]   They love knowing Spanish.
[02:10:00.800 --> 02:10:01.040]   Yeah.
[02:10:01.040 --> 02:10:03.840]   They actually love that they also know...
[02:10:03.840 --> 02:10:06.720]   They're not fluent in Mandarin,
[02:10:06.720 --> 02:10:09.120]   but they've learned Mandarin starting in Thursday.
[02:10:09.120 --> 02:10:10.320]   That's awesome, buddy.
[02:10:10.320 --> 02:10:11.360]   Stacey.
[02:10:11.360 --> 02:10:11.920]   You see that?
[02:10:11.920 --> 02:10:13.280]   That's good parenting.
[02:10:13.280 --> 02:10:14.080]   Dang.
[02:10:14.080 --> 02:10:14.480]   Dang.
[02:10:14.480 --> 02:10:14.880]   Dang.
[02:10:14.880 --> 02:10:16.880]   That's what's up.
[02:10:16.880 --> 02:10:19.600]   This I've noticed already on my smart devices.
[02:10:19.600 --> 02:10:21.760]   Google Assistant shuts the hell up.
[02:10:21.760 --> 02:10:22.640]   I'm sorry.
[02:10:22.640 --> 02:10:23.520]   Stop speaking.
[02:10:23.520 --> 02:10:27.760]   After turning on smart home devices,
[02:10:27.760 --> 02:10:30.160]   in the past, I'd go,
[02:10:30.160 --> 02:10:32.080]   "Hey, Google, turn off the lights and go...
[02:10:32.080 --> 02:10:36.000]   And then sometimes Amazon does this too.
[02:10:36.000 --> 02:10:39.520]   They go, "Hey, did you know I can also close the garage door?"
[02:10:39.520 --> 02:10:43.200]   And it's like, "No, just turn the dingy dang lights off.
[02:10:43.600 --> 02:10:44.320]   Anyway, they...
[02:10:44.320 --> 02:10:45.520]   One job. Do it."
[02:10:45.520 --> 02:10:45.760]   Yeah.
[02:10:45.760 --> 02:10:47.840]   By the way, they're...
[02:10:47.840 --> 02:10:50.320]   I hope nobody's home because they just turned off the lights.
[02:10:50.320 --> 02:10:53.760]   Whoopsies.
[02:10:53.760 --> 02:10:55.840]   Sammy the cat.
[02:10:55.840 --> 02:10:57.920]   Cats are not going to be happy, you know.
[02:10:57.920 --> 02:11:02.480]   I think that they got a little too chatty,
[02:11:02.480 --> 02:11:04.160]   both Amazon and Google.
[02:11:04.160 --> 02:11:10.000]   I'm glad to hear they're getting a little bit less.
[02:11:10.000 --> 02:11:11.360]   You probably covered this, Stacey,
[02:11:11.360 --> 02:11:13.680]   on your fabulous podcast with Kevin Dofel.
[02:11:13.680 --> 02:11:15.040]   Stacey, I know T.C.
[02:11:15.040 --> 02:11:16.880]   Thank you.
[02:11:16.880 --> 02:11:19.840]   Yeah, Andrew, my husband, hates Google,
[02:11:19.840 --> 02:11:22.160]   and Madam A has had it forever.
[02:11:22.160 --> 02:11:24.400]   And he was like, "I hate you, Google.
[02:11:24.400 --> 02:11:25.200]   I hate you."
[02:11:25.200 --> 02:11:26.400]   And I get it.
[02:11:26.400 --> 02:11:27.440]   It is annoying.
[02:11:27.440 --> 02:11:28.560]   Okay.
[02:11:28.560 --> 02:11:29.760]   Turning on fan.
[02:11:29.760 --> 02:11:31.200]   Yeah.
[02:11:31.200 --> 02:11:32.480]   Okay.
[02:11:32.480 --> 02:11:33.120]   Turning off...
[02:11:33.120 --> 02:11:35.440]   Actually, my birthday cake this year had,
[02:11:35.440 --> 02:11:37.600]   "Sorry, I can't help with that."
[02:11:37.600 --> 02:11:39.040]   Because that was glitching.
[02:11:40.000 --> 02:11:41.760]   Andrew has a sense of humor.
[02:11:41.760 --> 02:11:44.080]   The birthday cake said, "Sorry, I can't help with that."
[02:11:44.080 --> 02:11:45.200]   And he's all right.
[02:11:45.200 --> 02:11:48.000]   Yeah, I think, is that whatever Google says,
[02:11:48.000 --> 02:11:49.280]   my birthday cake is written on.
[02:11:49.280 --> 02:11:49.680]   Here's what I found on the web.
[02:11:49.680 --> 02:11:50.000]   Because we...
[02:11:50.000 --> 02:11:51.600]   Yeah.
[02:11:51.600 --> 02:11:52.000]   Yeah.
[02:11:52.000 --> 02:11:52.960]   We eliminated...
[02:11:52.960 --> 02:11:56.480]   My birthday present was to eliminate my Nest audios
[02:11:56.480 --> 02:11:57.760]   in Sonos speaker.
[02:11:57.760 --> 02:11:59.920]   That's just like a little theme.
[02:11:59.920 --> 02:12:01.280]   That's hysterical.
[02:12:01.280 --> 02:12:05.520]   You see that now, sometimes by the way, on Twitter replies,
[02:12:06.960 --> 02:12:10.640]   that somebody's got an AI hooked up to their account.
[02:12:10.640 --> 02:12:13.440]   And we'll say, "I'm not allowed to talk on that."
[02:12:13.440 --> 02:12:14.240]   Stuff like that.
[02:12:14.240 --> 02:12:14.800]   That's terrible.
[02:12:14.800 --> 02:12:16.560]   Anyway, now you'll get it.
[02:12:16.560 --> 02:12:18.640]   Oh, it says, "Sorry, something went wrong."
[02:12:18.640 --> 02:12:19.120]   Sorry.
[02:12:19.120 --> 02:12:19.840]   That was your cake?
[02:12:19.840 --> 02:12:20.800]   Something went wrong.
[02:12:20.800 --> 02:12:21.840]   That was your cake?
[02:12:21.840 --> 02:12:22.880]   Do you like to see a picture?
[02:12:22.880 --> 02:12:23.120]   Here.
[02:12:23.120 --> 02:12:23.440]   Yes.
[02:12:23.440 --> 02:12:25.360]   That's awesome.
[02:12:25.360 --> 02:12:26.480]   Oh, share.
[02:12:26.480 --> 02:12:27.840]   See.
[02:12:27.840 --> 02:12:29.440]   What do I have to do?
[02:12:29.440 --> 02:12:30.560]   Do I have to do something?
[02:12:30.560 --> 02:12:31.760]   I'm going to create a link.
[02:12:31.760 --> 02:12:32.960]   Do I have to click something?
[02:12:32.960 --> 02:12:36.480]   You're going to have to click it in a few hours.
[02:12:36.480 --> 02:12:37.920]   That's the question.
[02:12:37.920 --> 02:12:42.080]   I'm going to stick it at the on top of the change log.
[02:12:42.080 --> 02:12:42.800]   So, line.
[02:12:42.800 --> 02:12:45.200]   Well, I'm already there, so that's good.
[02:12:45.200 --> 02:12:46.320]   That should make it easy.
[02:12:46.320 --> 02:12:46.720]   Here we go.
[02:12:46.720 --> 02:12:48.640]   Boom.
[02:12:48.640 --> 02:12:49.040]   Oh, wait.
[02:12:49.040 --> 02:12:49.760]   Nope, that's the wrong.
[02:12:49.760 --> 02:12:50.240]   Nope, don't.
[02:12:50.240 --> 02:12:50.800]   Nope, don't.
[02:12:50.800 --> 02:12:52.240]   Nope, that's a...
[02:12:52.240 --> 02:12:52.560]   That will...
[02:12:52.560 --> 02:12:56.800]   That's going to be an edit link to the Marvel podcast.
[02:12:56.800 --> 02:12:57.920]   Can't be found.
[02:12:57.920 --> 02:12:59.040]   Nope, nothing there.
[02:12:59.040 --> 02:13:01.680]   Nope.
[02:13:01.680 --> 02:13:04.720]   You know, sometimes cutting and pasting is so hard.
[02:13:04.720 --> 02:13:05.360]   This is not ideal.
[02:13:05.360 --> 02:13:05.920]   There you go.
[02:13:05.920 --> 02:13:07.200]   I remember the old thing.
[02:13:07.200 --> 02:13:11.760]   Here is Stacy's crazy birthday cake.
[02:13:11.760 --> 02:13:13.520]   Sorry, something went wrong.
[02:13:13.520 --> 02:13:14.400]   [laughter]
[02:13:14.400 --> 02:13:15.360]   You had the goods.
[02:13:15.360 --> 02:13:16.560]   That's a humor.
[02:13:16.560 --> 02:13:17.760]   That is so funny.
[02:13:17.760 --> 02:13:19.360]   S-brilliant.
[02:13:19.360 --> 02:13:20.480]   That is awesome.
[02:13:20.480 --> 02:13:22.720]   I love that.
[02:13:22.720 --> 02:13:25.440]   Yeah, he gives me great cakes.
[02:13:25.440 --> 02:13:26.640]   Really?
[02:13:26.640 --> 02:13:27.280]   Is that his thing?
[02:13:27.280 --> 02:13:29.040]   Is he famous for that?
[02:13:29.040 --> 02:13:33.040]   I mean, we never put happy birthday on our cakes.
[02:13:33.040 --> 02:13:35.040]   That always comes off to some fun.
[02:13:35.040 --> 02:13:36.000]   Oh, that's great.
[02:13:36.000 --> 02:13:36.480]   Thanks.
[02:13:36.480 --> 02:13:38.560]   You should do a retrospective of cakes.
[02:13:38.560 --> 02:13:40.800]   Yeah, I want to see a gallery.
[02:13:40.800 --> 02:13:41.280]   Yeah.
[02:13:41.280 --> 02:13:42.400]   I should.
[02:13:42.400 --> 02:13:43.680]   I'll get right on that.
[02:13:43.680 --> 02:13:48.160]   Yeah, that's the Google change song.
[02:13:48.160 --> 02:13:52.480]   Final thoughts and picks of the week.
[02:13:52.480 --> 02:13:54.080]   Next, ladies and gentlemen,
[02:13:54.080 --> 02:13:56.480]   as we wrap up this thrilling gripping
[02:13:56.480 --> 02:13:58.560]   and only two and a half hour long show.
[02:13:58.560 --> 02:14:03.040]   I showed it they brought to you by Cisco Moraki,
[02:14:03.040 --> 02:14:07.360]   the experts in cloud-based networking for hybrid work.
[02:14:07.360 --> 02:14:08.880]   I'll tell you, it's really interesting,
[02:14:08.880 --> 02:14:11.680]   as much as some of these companies have fought hybrid work,
[02:14:11.680 --> 02:14:14.320]   employees love it.
[02:14:14.320 --> 02:14:18.320]   And I think now a lot of leaders are saying,
[02:14:18.320 --> 02:14:19.920]   "This isn't so bad."
[02:14:19.920 --> 02:14:23.520]   Whether your employees are working at home or at a cabin in the mountains,
[02:14:23.520 --> 02:14:26.080]   at a lounge chair on the beach,
[02:14:26.080 --> 02:14:29.840]   a cloud-managed network provides the same exceptional work experience,
[02:14:29.840 --> 02:14:31.120]   no matter where they are.
[02:14:31.920 --> 02:14:34.800]   And I got to tell you, you might as well roll out the welcome mat,
[02:14:34.800 --> 02:14:36.720]   because hybrid work is here to stay.
[02:14:36.720 --> 02:14:40.640]   Hybrid work works best in the cloud.
[02:14:40.640 --> 02:14:43.680]   And yes, obviously your employees love it.
[02:14:43.680 --> 02:14:45.120]   But it's got perks for leaders too.
[02:14:45.120 --> 02:14:47.120]   Workers can move faster,
[02:14:47.120 --> 02:14:50.000]   deliver better results with a cloud-managed network.
[02:14:50.000 --> 02:14:52.640]   Leaders can automate distributed operations,
[02:14:52.640 --> 02:14:54.720]   build more sustainable workspaces,
[02:14:54.720 --> 02:14:56.240]   proactively protect the network.
[02:14:56.240 --> 02:14:58.720]   An IDG market pulse research report
[02:14:58.720 --> 02:15:00.960]   conducted for Cisco Moraki highlights
[02:15:00.960 --> 02:15:05.360]   the top tier opportunities for you in supporting hybrid work.
[02:15:05.360 --> 02:15:09.840]   Hybrid work is a priority for 78% of C-suite executives.
[02:15:09.840 --> 02:15:10.880]   Why?
[02:15:10.880 --> 02:15:13.680]   Well, leaders want to derive collaboration forward
[02:15:13.680 --> 02:15:17.840]   while staying on top of or even boosting productivity and security.
[02:15:17.840 --> 02:15:19.760]   Security, of course,
[02:15:19.760 --> 02:15:21.360]   one of the challenges of hybrid work,
[02:15:21.360 --> 02:15:23.120]   the IDG report says,
[02:15:23.120 --> 02:15:26.160]   "48% of leaders report cybersecurity threats
[02:15:26.160 --> 02:15:30.000]   is a primary obstacle to improving workforce experiences."
[02:15:30.720 --> 02:15:32.480]   One of the things that's going to make a difference here,
[02:15:32.480 --> 02:15:35.440]   thanks to Cisco Moraki always on security monitoring.
[02:15:35.440 --> 02:15:37.920]   Makes the cloud-managed network so awesome.
[02:15:37.920 --> 02:15:41.760]   IT can use apps from Moraki's vast ecosystem of partners.
[02:15:41.760 --> 02:15:44.640]   Turnkey solutions built to work seamlessly
[02:15:44.640 --> 02:15:48.720]   with the Moraki Cloud platform for asset tracking,
[02:15:48.720 --> 02:15:50.480]   location analytics, and more.
[02:15:50.480 --> 02:15:52.960]   You can gather insights on how people use their workspaces.
[02:15:52.960 --> 02:15:53.840]   It's actually great,
[02:15:53.840 --> 02:15:55.600]   because if you have a hybrid workspace,
[02:15:55.600 --> 02:15:58.160]   you can actually have it smart,
[02:15:58.160 --> 02:16:01.760]   you can be smart, so environmental sensors can track activity,
[02:16:01.760 --> 02:16:04.000]   they can track occupancy levels,
[02:16:04.000 --> 02:16:05.600]   they can stay on top of cleanliness,
[02:16:05.600 --> 02:16:07.920]   you can implement hot desking,
[02:16:07.920 --> 02:16:10.320]   but not sacrifice security,
[02:16:10.320 --> 02:16:13.040]   so that employees can reserve workspaces,
[02:16:13.040 --> 02:16:16.400]   and then you can have time-based door access,
[02:16:16.400 --> 02:16:18.640]   so people can't just wander in.
[02:16:18.640 --> 02:16:22.240]   You've got all sorts of power to do this,
[02:16:22.240 --> 02:16:23.600]   which is fantastic.
[02:16:23.600 --> 02:16:26.560]   And it lets employees quickly scout out a place to work,
[02:16:26.560 --> 02:16:29.680]   have access to it without compromising your security.
[02:16:29.680 --> 02:16:31.520]   Mobile device management is very important
[02:16:31.520 --> 02:16:34.320]   to these days, integrating devices and systems.
[02:16:34.320 --> 02:16:38.800]   Let IT manage, update, and troubleshoot company-owned devices,
[02:16:38.800 --> 02:16:44.320]   even when that device and that employee are in a remote location.
[02:16:44.320 --> 02:16:47.920]   Turn anywhere into a place of productivity,
[02:16:47.920 --> 02:16:50.960]   empower your organization with the same exceptional experience,
[02:16:50.960 --> 02:16:53.840]   no matter where they work with Moraki
[02:16:53.840 --> 02:16:56.640]   and the Cisco suite of technology.
[02:16:56.640 --> 02:16:59.040]   Learn how your organization can make hybrid work,
[02:16:59.040 --> 02:17:03.600]   visit moraki.cisco.com/twitm-er,
[02:17:03.600 --> 02:17:10.480]   aka moraki.cisco.com/twitm-er,
[02:17:10.480 --> 02:17:13.360]   we really thank Cisco Moraki for supporting the show.
[02:17:13.360 --> 02:17:15.920]   You support it when you go to that address,
[02:17:15.920 --> 02:17:19.600]   so make sure you do that exactly as I specify.
[02:17:19.600 --> 02:17:25.120]   moraki.cisco.com/twitm-er,
[02:17:25.120 --> 02:17:26.880]   that really makes a difference.
[02:17:26.880 --> 02:17:30.880]   And we thank them so much for their support, Stacey Higginbotham.
[02:17:30.880 --> 02:17:32.960]   Did you bring a thing?
[02:17:32.960 --> 02:17:36.320]   Oh, muted.
[02:17:36.320 --> 02:17:36.400]   Muted.
[02:17:36.400 --> 02:17:37.840]   Oh, unmute.
[02:17:37.840 --> 02:17:38.960]   I did.
[02:17:38.960 --> 02:17:40.880]   I have the most exciting thing for you all today.
[02:17:40.880 --> 02:17:41.360]   Oh, wow.
[02:17:41.360 --> 02:17:44.000]   Do you know what this is?
[02:17:44.000 --> 02:17:46.880]   Oh, is it a, is it an electric compact?
[02:17:48.400 --> 02:17:53.600]   No, it is the Aquara FP2 millimeter wave sensor.
[02:17:53.600 --> 02:17:53.760]   Oh.
[02:17:53.760 --> 02:17:55.920]   This is, according to Stacey,
[02:17:55.920 --> 02:17:59.040]   the hottest sensor coming on the market in 2023.
[02:17:59.040 --> 02:18:00.720]   So millimeter wave I'm aware of,
[02:18:00.720 --> 02:18:03.920]   because that's what they use at the airport when they go whoop whoop,
[02:18:03.920 --> 02:18:07.200]   and they scan you for arms and stuff, right?
[02:18:07.200 --> 02:18:08.400]   That's millimeter wave.
[02:18:08.400 --> 02:18:08.480]   Right.
[02:18:08.480 --> 02:18:09.840]   It is.
[02:18:09.840 --> 02:18:11.280]   So they're actually using radar.
[02:18:11.280 --> 02:18:13.760]   They're not using the same frequency.
[02:18:13.760 --> 02:18:14.720]   Oh, it's not the same frequency.
[02:18:14.720 --> 02:18:15.600]   It's a game over the--
[02:18:15.600 --> 02:18:18.080]   And what would you use this cool little thing anymore?
[02:18:18.080 --> 02:18:18.560]   For--
[02:18:18.560 --> 02:18:18.720]   Yeah.
[02:18:18.720 --> 02:18:19.680]   Let me tell you.
[02:18:19.680 --> 02:18:20.240]   All right.
[02:18:20.240 --> 02:18:21.920]   That was like, don't worry.
[02:18:21.920 --> 02:18:22.960]   I won't leave you hanging.
[02:18:22.960 --> 02:18:24.480]   So they showed this off at CES.
[02:18:24.480 --> 02:18:28.000]   This is a presence detection sensor.
[02:18:28.000 --> 02:18:31.360]   What's cool about it is instead of like a traditional PIR sensor,
[02:18:31.360 --> 02:18:33.600]   what it has with the radar,
[02:18:33.600 --> 02:18:36.880]   you get a little bit more granularity.
[02:18:36.880 --> 02:18:40.480]   So this will actually detect the number of people in a room.
[02:18:40.480 --> 02:18:44.800]   It also can be placed on the ceiling and used as a fall detection model.
[02:18:44.800 --> 02:18:45.520]   Oh.
[02:18:45.520 --> 02:18:48.320]   And just for fun, it measures luxe.
[02:18:48.320 --> 02:18:50.480]   So the amount of light you've got in a room.
[02:18:50.480 --> 02:18:52.000]   So PIR is infrared.
[02:18:52.000 --> 02:18:55.200]   So when I have friends on my hugh lights have a motion sensors,
[02:18:55.200 --> 02:18:57.120]   that's just an infrared beam.
[02:18:57.120 --> 02:19:00.080]   And if I break it, then they know I'm here and they turn the lights on, right?
[02:19:00.080 --> 02:19:01.120]   Yes.
[02:19:01.120 --> 02:19:02.800]   This is like radar.
[02:19:02.800 --> 02:19:05.280]   Yeah, this is radar.
[02:19:05.280 --> 02:19:06.560]   And so they--
[02:19:06.560 --> 02:19:09.600]   What it allows you to do, like I said, multiple people,
[02:19:09.600 --> 02:19:10.800]   so that's pretty cool.
[02:19:10.800 --> 02:19:14.480]   It also allows you to finally kind of block off an area,
[02:19:15.120 --> 02:19:16.320]   and create different zones.
[02:19:16.320 --> 02:19:17.040]   Oh, I'd like that.
[02:19:17.040 --> 02:19:19.600]   Because sometimes the lights turn on when I don't want them to,
[02:19:19.600 --> 02:19:20.720]   because it's just because I'm in the room.
[02:19:20.720 --> 02:19:21.120]   Yeah.
[02:19:21.120 --> 02:19:21.760]   Yeah.
[02:19:21.760 --> 02:19:25.360]   Or you could have your lights turn on when you hit a specific zone.
[02:19:25.360 --> 02:19:25.920]   Yes.
[02:19:25.920 --> 02:19:28.960]   Like if you're bed, if it's in your bedroom and your bed is the zone,
[02:19:28.960 --> 02:19:32.480]   you could be like, when two people hit this zone lights out.
[02:19:32.480 --> 02:19:34.400]   The other thing is--
[02:19:34.400 --> 02:19:35.360]   That sounds romantic.
[02:19:35.360 --> 02:19:38.320]   Where are we?
[02:19:38.320 --> 02:19:38.960]   What happened?
[02:19:38.960 --> 02:19:39.440]   I'm fascinated.
[02:19:39.440 --> 02:19:43.600]   You could also do two people hit this bed,
[02:19:44.160 --> 02:19:46.160]   play romantic music, whatever.
[02:19:46.160 --> 02:19:49.440]   Oh, so it can town how many people are in the room.
[02:19:49.440 --> 02:19:50.480]   Right.
[02:19:50.480 --> 02:19:51.520]   Oh, that's really neat.
[02:19:51.520 --> 02:19:54.080]   It does best with three, but it is up to five.
[02:19:54.080 --> 02:19:55.600]   The downside is here, the downside.
[02:19:55.600 --> 02:19:58.000]   Three, if you have five people in your bed,
[02:19:58.000 --> 02:19:59.440]   maybe you should consider--
[02:19:59.440 --> 02:20:01.440]   Maybe a scared living room.
[02:20:01.440 --> 02:20:02.880]   Like if everyone's sitting down,
[02:20:02.880 --> 02:20:06.000]   if one person's at the dining room table,
[02:20:06.000 --> 02:20:07.360]   maybe it's your kid's studying,
[02:20:07.360 --> 02:20:09.440]   and you know that, so then you have brighter lights.
[02:20:09.440 --> 02:20:11.200]   I do like the fall detection idea,
[02:20:11.200 --> 02:20:11.920]   because I don't--
[02:20:12.400 --> 02:20:16.160]   My mom, 90, I'm worried, very worried about her falling.
[02:20:16.160 --> 02:20:17.680]   I'm not going to put a camera.
[02:20:17.680 --> 02:20:19.200]   She wouldn't want a camera in there.
[02:20:19.200 --> 02:20:20.160]   So this is--
[02:20:20.160 --> 02:20:21.200]   I can't see her, but I wish--
[02:20:21.200 --> 02:20:22.400]   Like your own business.
[02:20:22.400 --> 02:20:22.880]   Yeah, exactly.
[02:20:22.880 --> 02:20:23.360]   Oh.
[02:20:23.360 --> 02:20:26.560]   So here comes a couple caveats so far,
[02:20:26.560 --> 02:20:30.000]   and I've been playing with this only for like 24 or 48 hours,
[02:20:30.000 --> 02:20:32.000]   so I have not gone through all of them.
[02:20:32.000 --> 02:20:34.160]   I'll have a review up soon though, like next week.
[02:20:34.160 --> 02:20:37.200]   Okay, caveat one, it's wired.
[02:20:37.200 --> 02:20:40.640]   And caveat two is for fall detection,
[02:20:40.640 --> 02:20:42.560]   it will only be used for fall detection.
[02:20:42.560 --> 02:20:44.720]   You can't use anything else if you're using it for that.
[02:20:44.720 --> 02:20:45.360]   No.
[02:20:45.360 --> 02:20:48.560]   Because the best placement for fall detection
[02:20:48.560 --> 02:20:49.520]   is on your ceiling.
[02:20:49.520 --> 02:20:52.720]   Provided your ceiling is only nine feet tall.
[02:20:52.720 --> 02:20:54.960]   A caveat.
[02:20:54.960 --> 02:20:57.200]   That's an old house, is right?
[02:20:57.200 --> 02:20:58.880]   Yeah, these are--
[02:20:58.880 --> 02:21:01.520]   I mean, it won't work in my living room,
[02:21:01.520 --> 02:21:02.880]   because it's a cathedral ceiling.
[02:21:02.880 --> 02:21:05.840]   But for my study, we could have fall detection in here.
[02:21:05.840 --> 02:21:08.480]   So those are some of--
[02:21:08.480 --> 02:21:09.280]   Those are some of--
[02:21:09.280 --> 02:21:10.320]   Bit or laugh so hard.
[02:21:10.320 --> 02:21:11.360]   Yeah.
[02:21:11.360 --> 02:21:12.080]   We'll go off.
[02:21:12.080 --> 02:21:13.040]   Or I just swooned.
[02:21:13.040 --> 02:21:17.040]   This is like literally--
[02:21:17.040 --> 02:21:18.240]   like it's sold out already.
[02:21:18.240 --> 02:21:20.640]   It is an $83.
[02:21:20.640 --> 02:21:22.560]   It's $8299 over at Amazon,
[02:21:22.560 --> 02:21:25.040]   where I believe it is still sold out.
[02:21:25.040 --> 02:21:28.800]   But it's a really interesting device,
[02:21:28.800 --> 02:21:30.160]   and I'm really excited to play with it,
[02:21:30.160 --> 02:21:33.280]   because it's going to allow way more complicated
[02:21:33.280 --> 02:21:36.480]   smart home integrations and fall detection.
[02:21:37.440 --> 02:21:39.760]   And we have established that there is nothing to fear
[02:21:39.760 --> 02:21:44.640]   from millimeter wave radar.
[02:21:44.640 --> 02:21:48.000]   What do you mean nothing?
[02:21:48.000 --> 02:21:48.960]   Like what kind of fear--
[02:21:48.960 --> 02:21:49.680]   I don't know.
[02:21:49.680 --> 02:21:50.960]   Pretty Asian.
[02:21:50.960 --> 02:21:53.760]   It's like a scramble on eggs or anything, is it?
[02:21:53.760 --> 02:21:55.280]   Oh, no, no, no.
[02:21:55.280 --> 02:21:56.560]   Millimeter wave's pretty--
[02:21:56.560 --> 02:22:00.160]   This isn't even as strong as the airport machines,
[02:22:00.160 --> 02:22:01.200]   but also--
[02:22:01.200 --> 02:22:02.560]   Okay, it's a scramble, my eggs.
[02:22:02.560 --> 02:22:05.520]   There is something like--
[02:22:06.400 --> 02:22:08.000]   It's worth thinking about this.
[02:22:08.000 --> 02:22:10.000]   Breakfast is ready, and I didn't do anything.
[02:22:10.000 --> 02:22:14.960]   Oh, yes, that's thanks to the present sensor FP2X,
[02:22:14.960 --> 02:22:15.600]   Strangler.
[02:22:15.600 --> 02:22:18.160]   When it sees people in the room,
[02:22:18.160 --> 02:22:19.520]   it scumbles their eggs.
[02:22:19.520 --> 02:22:22.400]   I'm sorry, it's not the power.
[02:22:22.400 --> 02:22:23.280]   With the sort of--
[02:22:23.280 --> 02:22:26.080]   Like when it's detecting falls,
[02:22:26.080 --> 02:22:29.760]   it's detecting a specific type of disruptive pattern
[02:22:29.760 --> 02:22:31.440]   in the millimeter waves, right?
[02:22:31.440 --> 02:22:32.400]   So shooting out the waves,
[02:22:32.400 --> 02:22:34.240]   it's like, oh, a fall looks like this.
[02:22:34.240 --> 02:22:37.120]   It is possible because these are high precision
[02:22:37.120 --> 02:22:41.200]   to detect things like people doing things,
[02:22:41.200 --> 02:22:42.240]   or people--
[02:22:42.240 --> 02:22:44.560]   I always use the example of if they wanted to,
[02:22:44.560 --> 02:22:46.000]   they could create an algorithm to measure
[02:22:46.000 --> 02:22:47.280]   if you kick your dog or not.
[02:22:47.280 --> 02:22:47.600]   Yeah.
[02:22:47.600 --> 02:22:50.640]   So just because it's not a camera
[02:22:50.640 --> 02:22:52.640]   doesn't mean it can't share information
[02:22:52.640 --> 02:22:54.560]   that you still wouldn't like having out in the world.
[02:22:54.560 --> 02:22:54.960]   Interesting.
[02:22:54.960 --> 02:22:55.440]   Yeah.
[02:22:55.440 --> 02:22:57.280]   But they do have to build it in algorithm four.
[02:22:57.280 --> 02:23:00.400]   It's got a USB-C port.
[02:23:00.400 --> 02:23:01.840]   Is that where it gets its power from?
[02:23:02.640 --> 02:23:03.280]   Yeah.
[02:23:03.280 --> 02:23:05.680]   And I mean, if you got them out this on a ceiling,
[02:23:05.680 --> 02:23:06.640]   you're going to have to--
[02:23:06.640 --> 02:23:08.000]   Like when I'm going to test that,
[02:23:08.000 --> 02:23:10.080]   I'm going to have to put an extension cord in
[02:23:10.080 --> 02:23:11.760]   because the cord is probably--
[02:23:11.760 --> 02:23:14.720]   I have PoE in my ceiling, I guess.
[02:23:14.720 --> 02:23:15.760]   I could get--
[02:23:15.760 --> 02:23:16.240]   It does not.
[02:23:16.240 --> 02:23:18.800]   There must be something that will take ethernet
[02:23:18.800 --> 02:23:20.320]   and turn it into regular electricity.
[02:23:20.320 --> 02:23:22.000]   It only needs five watts.
[02:23:22.000 --> 02:23:23.040]   So that would probably be--
[02:23:23.040 --> 02:23:23.360]   Yeah.
[02:23:23.360 --> 02:23:25.520]   And it's got a micro-USB--
[02:23:25.520 --> 02:23:27.680]   Oh, I guess--
[02:23:27.680 --> 02:23:30.080]   Hold on, that was terrible.
[02:23:31.840 --> 02:23:33.200]   USB-C, it says.
[02:23:33.200 --> 02:23:33.760]   Yeah.
[02:23:33.760 --> 02:23:34.240]   Yeah.
[02:23:34.240 --> 02:23:35.680]   Sorry, USB-C.
[02:23:35.680 --> 02:23:38.640]   And then it doesn't have matter.
[02:23:38.640 --> 02:23:40.720]   It does support HomeKit.
[02:23:40.720 --> 02:23:42.720]   And then--
[02:23:42.720 --> 02:23:43.520]   So HomeKit,
[02:23:43.520 --> 02:23:46.240]   the acquire app--
[02:23:46.240 --> 02:23:47.280]   If you want fault detection,
[02:23:47.280 --> 02:23:49.520]   you have to do it only through the acquire app.
[02:23:49.520 --> 02:23:50.720]   If you want--
[02:23:50.720 --> 02:23:53.520]   If you put it through Google and Amazon,
[02:23:53.520 --> 02:23:56.560]   it supports only presence, not lux.
[02:23:56.560 --> 02:23:59.920]   And if you do it through if and HomeKit,
[02:23:59.920 --> 02:24:02.240]   it supports presence and lux.
[02:24:02.240 --> 02:24:03.040]   Here's a question.
[02:24:03.040 --> 02:24:05.920]   You think we'll see more of these kinds of things.
[02:24:05.920 --> 02:24:08.560]   I mean, this is the first I've seen,
[02:24:08.560 --> 02:24:11.600]   but I presume it must be doable.
[02:24:11.600 --> 02:24:13.440]   I've been talking about this for years.
[02:24:13.440 --> 02:24:16.480]   RF sensing is the new hotness in smart home.
[02:24:16.480 --> 02:24:18.880]   And actually, the latest Ecobee,
[02:24:18.880 --> 02:24:20.160]   the presence detection,
[02:24:20.160 --> 02:24:20.960]   the people detection,
[02:24:20.960 --> 02:24:23.200]   the latest Ecobee thermostat is radar.
[02:24:23.200 --> 02:24:24.320]   It is millimeter-bar.
[02:24:24.320 --> 02:24:25.040]   Ah, nice.
[02:24:25.040 --> 02:24:27.760]   Because it's more precise.
[02:24:28.480 --> 02:24:30.080]   It--
[02:24:30.080 --> 02:24:31.840]   I mean, PIR works in the dark,
[02:24:31.840 --> 02:24:33.360]   but it really works in the dark.
[02:24:33.360 --> 02:24:37.360]   So it has a lot going for it.
[02:24:37.360 --> 02:24:39.200]   It's very interesting.
[02:24:39.200 --> 02:24:39.600]   How much?
[02:24:39.600 --> 02:24:42.800]   This one's $8299.
[02:24:42.800 --> 02:24:43.840]   Oh, it's a little pricey.
[02:24:43.840 --> 02:24:46.240]   But I guess you wouldn't get more than one per--
[02:24:46.240 --> 02:24:48.480]   Well, if you wanted to do a fault detection,
[02:24:48.480 --> 02:24:49.440]   you have to put one in each room
[02:24:49.440 --> 02:24:50.480]   that you care about falling in.
[02:24:50.480 --> 02:24:51.600]   Yeah, you care about it.
[02:24:51.600 --> 02:24:53.040]   You can fall in the kitchen, mom,
[02:24:53.040 --> 02:24:55.520]   but don't fall in the living room,
[02:24:55.520 --> 02:24:57.440]   because I couldn't afford to have a sensor there.
[02:24:58.080 --> 02:25:02.320]   My pick of the week is a mouth pad for your mouse.
[02:25:02.320 --> 02:25:03.680]   So it's like a mouth-mouth pad.
[02:25:03.680 --> 02:25:04.560]   Wait, what?
[02:25:04.560 --> 02:25:05.120]   A mouth--
[02:25:05.120 --> 02:25:05.760]   What?
[02:25:05.760 --> 02:25:06.720]   So you put--
[02:25:06.720 --> 02:25:11.440]   I'm not going to actually pick this.
[02:25:11.440 --> 02:25:12.800]   I thought it was kind of interesting.
[02:25:12.800 --> 02:25:14.640]   I mean, it's not available, or you'd be buying it.
[02:25:14.640 --> 02:25:15.440]   It would actually--
[02:25:15.440 --> 02:25:18.960]   Actually, this is really for people with injuries
[02:25:18.960 --> 02:25:20.960]   that affect their mobility.
[02:25:20.960 --> 02:25:21.520]   Yeah, which does.
[02:25:21.520 --> 02:25:22.720]   But, okay.
[02:25:22.720 --> 02:25:23.360]   You could--
[02:25:23.360 --> 02:25:24.960]   I mean, you couldn't through reuse it.
[02:25:24.960 --> 02:25:26.800]   It's a tongue-driven interface.
[02:25:27.680 --> 02:25:29.680]   That basically acts like a track pad.
[02:25:29.680 --> 02:25:30.800]   So you could do your computer,
[02:25:30.800 --> 02:25:32.160]   your smartphone, your tablet.
[02:25:32.160 --> 02:25:32.800]   Oh!
[02:25:32.800 --> 02:25:33.680]   It uses Bluetooth.
[02:25:33.680 --> 02:25:34.480]   It's invisible.
[02:25:34.480 --> 02:25:35.840]   You run--
[02:25:35.840 --> 02:25:36.800]   This goes in your--
[02:25:36.800 --> 02:25:38.080]   You know, on your palate,
[02:25:38.080 --> 02:25:39.120]   your upper mouth, and then--
[02:25:39.120 --> 02:25:41.120]   I don't know what Peter butter to handle in the time.
[02:25:41.120 --> 02:25:42.400]   Don't take it out before--
[02:25:42.400 --> 02:25:44.000]   It only goes for five hours, too.
[02:25:44.000 --> 02:25:45.360]   So you probably want to take it out
[02:25:45.360 --> 02:25:47.440]   before you have a peanut butter sandwich.
[02:25:47.440 --> 02:25:50.800]   But it's kind of an interesting idea.
[02:25:50.800 --> 02:25:54.560]   It absolutely could be an accessibility thing,
[02:25:54.560 --> 02:25:56.720]   but I don't think they're pushing it that way.
[02:25:56.720 --> 02:25:58.000]   I think they're promoting--
[02:25:58.000 --> 02:26:00.080]   I think we'll be using this before you know it.
[02:26:00.080 --> 02:26:00.320]   Yeah.
[02:26:00.320 --> 02:26:02.160]   Yeah, scoble walk around.
[02:26:02.160 --> 02:26:03.360]   You can use it to scroll--
[02:26:03.360 --> 02:26:05.120]   TikTok when your hands are busy.
[02:26:05.120 --> 02:26:06.320]   Well, or better yet,
[02:26:06.320 --> 02:26:08.720]   surreptitiously with you--
[02:26:08.720 --> 02:26:10.000]   Now that you're wearing your specs
[02:26:10.000 --> 02:26:12.000]   and you need something to control them,
[02:26:12.000 --> 02:26:14.080]   I think we're going to see some surreptitious ways
[02:26:14.080 --> 02:26:15.680]   to control stuff like that, right?
[02:26:15.680 --> 02:26:17.040]   [MUMBLING]
[02:26:17.040 --> 02:26:19.600]   Okay, Jeff.
[02:26:19.600 --> 02:26:20.320]   Great.
[02:26:20.320 --> 02:26:21.280]   Never mind.
[02:26:21.280 --> 02:26:22.960]   This is the mouth pad.
[02:26:22.960 --> 02:26:23.920]   It's not going to be very subtle.
[02:26:23.920 --> 02:26:25.600]   From Augmental.com.
[02:26:25.600 --> 02:26:27.280]   How do you click, Tech?
[02:26:27.280 --> 02:26:28.080]   There's a click.
[02:26:28.080 --> 02:26:29.120]   You can tap your tongue.
[02:26:29.120 --> 02:26:29.680]   Like--
[02:26:29.680 --> 02:26:30.160]   Yeah.
[02:26:30.160 --> 02:26:32.320]   And Jeff--
[02:26:32.320 --> 02:26:32.320]   Jeff--
[02:26:32.320 --> 02:26:33.280]   Really pushed that.
[02:26:33.280 --> 02:26:34.240]   Give us another one.
[02:26:34.240 --> 02:26:39.360]   Okay, I was going to do creased cargo pants,
[02:26:39.360 --> 02:26:40.880]   but I feel like that that's probably--
[02:26:40.880 --> 02:26:41.280]   Oh, sorry.
[02:26:41.280 --> 02:26:42.000]   We took that away from you.
[02:26:42.000 --> 02:26:44.240]   Let me let you stall enough for me over the years.
[02:26:44.240 --> 02:26:46.320]   So I'm actually going to give a book--
[02:26:46.320 --> 02:26:49.360]   I had Ben Spitt's book in there
[02:26:49.360 --> 02:26:51.120]   because it's coming out in New Daddy.
[02:26:51.120 --> 02:26:52.400]   I pre-ordered it, thanks to you.
[02:26:52.400 --> 02:26:52.640]   Thank you.
[02:26:52.640 --> 02:26:55.360]   Halo Lorenz has her book coming out.
[02:26:55.360 --> 02:26:55.840]   Oh.
[02:26:55.840 --> 02:26:56.800]   Imminently.
[02:26:56.800 --> 02:26:58.240]   Maybe we get her on the show.
[02:26:58.240 --> 02:26:59.760]   Oh, what's your book about?
[02:26:59.760 --> 02:27:00.880]   A book about a book about a book about a book about a book
[02:27:00.880 --> 02:27:02.000]   that's extremely online.
[02:27:02.000 --> 02:27:03.920]   The untold story of famed influence
[02:27:03.920 --> 02:27:05.040]   and power on the internet.
[02:27:05.040 --> 02:27:06.160]   That's not for our alley.
[02:27:06.160 --> 02:27:08.720]   Is it a biocrossee or is it about other people?
[02:27:08.720 --> 02:27:10.080]   I think it kind of is, probably.
[02:27:10.080 --> 02:27:10.480]   I don't know.
[02:27:10.480 --> 02:27:11.200]   It's coming out later.
[02:27:11.200 --> 02:27:13.520]   And then I, of course, then I just saw a book
[02:27:13.520 --> 02:27:18.560]   that we might all like called Keith Houston's Empire of the Sum,
[02:27:18.560 --> 02:27:21.360]   The Rise and Rain of the Pocket Calculator.
[02:27:21.360 --> 02:27:23.360]   I mean, oh, I got to read that.
[02:27:23.360 --> 02:27:26.640]   And then, of course, I have a book coming out in June
[02:27:26.640 --> 02:27:28.080]   called The Gutenberg Prethices.
[02:27:28.080 --> 02:27:29.680]   So two tricks here.
[02:27:29.680 --> 02:27:32.000]   One, you can go to Barnes & Noble
[02:27:32.000 --> 02:27:34.720]   between today and the 28th of this month.
[02:27:34.720 --> 02:27:36.880]   And you use the code pre-order25
[02:27:36.880 --> 02:27:38.720]   in any book that's not out yet.
[02:27:38.720 --> 02:27:40.000]   You can get 25% off.
[02:27:40.000 --> 02:27:40.320]   Oh.
[02:27:40.320 --> 02:27:43.520]   It's including your book.
[02:27:43.520 --> 02:27:45.120]   My book.
[02:27:45.120 --> 02:27:45.840]   You bet.
[02:27:45.840 --> 02:27:46.400]   Now the other thing.
[02:27:46.400 --> 02:27:47.120]   Your cut, though.
[02:27:47.120 --> 02:27:48.800]   I don't care.
[02:27:48.800 --> 02:27:49.360]   I don't care.
[02:27:49.360 --> 02:27:50.000]   I don't care.
[02:27:50.000 --> 02:27:50.560]   All others don't care.
[02:27:50.560 --> 02:27:50.960]   You know what?
[02:27:50.960 --> 02:27:52.960]   You can, if you don't want to do that,
[02:27:52.960 --> 02:27:54.560]   if you go to Bloomsbury directly.
[02:27:54.560 --> 02:27:55.040]   That's right.
[02:27:55.040 --> 02:27:56.320]   They'll give you 10% off.
[02:27:56.320 --> 02:27:56.720]   So you--
[02:27:56.720 --> 02:27:57.760]   They give you 10% off.
[02:27:57.760 --> 02:27:57.920]   Yeah.
[02:27:57.920 --> 02:27:59.600]   But now the other thing is,
[02:27:59.600 --> 02:28:01.200]   the other trick that I have out there
[02:28:01.200 --> 02:28:07.040]   is I've come to love the British book company Blackwells.
[02:28:07.040 --> 02:28:10.000]   I love going to their store in Oxford.
[02:28:10.000 --> 02:28:10.960]   I loved it.
[02:28:10.960 --> 02:28:13.600]   Turns out you can buy most any book from Blackwells.
[02:28:13.600 --> 02:28:16.240]   And they give you a good discount and free shipping.
[02:28:16.240 --> 02:28:18.800]   You can buy American books and British books.
[02:28:18.800 --> 02:28:23.280]   So if you buy the Gutenberg parenthesis, $27 MSRP,
[02:28:23.280 --> 02:28:25.440]   they take $3 off, but free shipping.
[02:28:25.440 --> 02:28:28.880]   Versus Barnes and Noble, they take 25% off,
[02:28:28.880 --> 02:28:31.040]   but they charge for shipping unless you hit a certain amount.
[02:28:31.040 --> 02:28:33.600]   So shop around, figure it out.
[02:28:33.600 --> 02:28:35.440]   But in any case, all of us folks,
[02:28:35.440 --> 02:28:37.680]   we're going to be pushing our books to you.
[02:28:37.680 --> 02:28:38.560]   Here's Ben's book.
[02:28:38.560 --> 02:28:39.440]   Taylor's coming out.
[02:28:39.440 --> 02:28:40.240]   Keith's coming out.
[02:28:40.240 --> 02:28:44.560]   And mine coming out the Gutenberg parenthesis today to--
[02:28:44.560 --> 02:28:45.680]   What's today?
[02:28:45.680 --> 02:28:50.000]   Friday, I guess, is a good time to pre-order anything you want out there,
[02:28:50.000 --> 02:28:51.200]   including mine.
[02:28:51.200 --> 02:28:53.440]   Barnes and Noble, 25% off with the code.
[02:28:53.440 --> 02:28:56.480]   Pre-order 25.
[02:28:56.480 --> 02:28:57.760]   Pre-order 25.
[02:28:57.760 --> 02:29:00.080]   And Blackwells, just because we want to support Blackwells,
[02:29:00.080 --> 02:29:00.720]   because they're great.
[02:29:00.720 --> 02:29:02.320]   Because they're really great.
[02:29:02.320 --> 02:29:02.560]   Yeah.
[02:29:02.560 --> 02:29:04.000]   And they will--
[02:29:04.000 --> 02:29:06.880]   By the way, the other number I was going to have is in the story about
[02:29:06.880 --> 02:29:10.960]   Sundar's income of $266 million, which is kind of ridiculous,
[02:29:10.960 --> 02:29:12.720]   because it's a whole bunch of stock who cares.
[02:29:12.720 --> 02:29:15.280]   But they calculated the--
[02:29:15.280 --> 02:29:16.960]   It's 800-- was it 800?
[02:29:16.960 --> 02:29:21.760]   The calculation of what it is to the median income in the company.
[02:29:21.760 --> 02:29:24.080]   It's an 808 to one ratio.
[02:29:24.080 --> 02:29:24.800]   Oh boy.
[02:29:24.800 --> 02:29:29.200]   And the company used as their median for all employees.
[02:29:29.200 --> 02:29:30.560]   You guys want to guess what that is?
[02:29:30.560 --> 02:29:33.840]   Oh, $183,072.
[02:29:33.840 --> 02:29:36.240]   $279.
[02:29:36.240 --> 02:29:40.000]   $239,800.
[02:29:40.000 --> 02:29:42.400]   That's a good median salary.
[02:29:43.040 --> 02:29:43.840]   Yeah, for those of those--
[02:29:43.840 --> 02:29:46.560]   I mean, half of Googlers make more half of Googlers make less.
[02:29:46.560 --> 02:29:47.120]   Right.
[02:29:47.120 --> 02:29:49.200]   There's one guy right in the middle.
[02:29:49.200 --> 02:29:50.560]   He's the Mr. Median.
[02:29:50.560 --> 02:29:55.200]   By the way, I want to clarify Taylor's book is not about her.
[02:29:55.200 --> 02:29:58.480]   I'm just reading the summary.
[02:29:58.480 --> 02:29:59.360]   It's a history.
[02:29:59.360 --> 02:30:00.960]   It's a history.
[02:30:00.960 --> 02:30:03.920]   The untold story of fame, influence, and power on the internet,
[02:30:03.920 --> 02:30:04.880]   but not of her.
[02:30:04.880 --> 02:30:06.960]   It's a history of--
[02:30:06.960 --> 02:30:08.880]   But she's certainly his perspective.
[02:30:08.880 --> 02:30:09.440]   Yeah, oh yeah.
[02:30:10.960 --> 02:30:13.120]   That's why I asked because she's been a--
[02:30:13.120 --> 02:30:13.920]   That's great.
[02:30:13.920 --> 02:30:16.000]   Yeah, a target.
[02:30:16.000 --> 02:30:23.440]   But yeah, she certainly has an experience of what unwanted fame on the internet can lead to too.
[02:30:23.440 --> 02:30:25.360]   Extremely online.
[02:30:25.360 --> 02:30:25.760]   All right.
[02:30:25.760 --> 02:30:28.240]   And what was the other one that Keith's book?
[02:30:28.240 --> 02:30:29.360]   Keith Houston's book.
[02:30:29.360 --> 02:30:33.280]   Keith wrote the book, The Book, which is a really well produced book about
[02:30:33.280 --> 02:30:35.120]   the object of the book.
[02:30:35.120 --> 02:30:36.560]   He does good stuff.
[02:30:36.560 --> 02:30:37.920]   Empire of the Sum.
[02:30:37.920 --> 02:30:40.800]   Rise and reign of the pocket calculate.
[02:30:40.800 --> 02:30:41.520]   I love that.
[02:30:41.520 --> 02:30:42.240]   That's a very--
[02:30:42.240 --> 02:30:43.840]   I just saw that two minutes ago,
[02:30:43.840 --> 02:30:46.080]   because all the authors are out there on Twitter right now saying,
[02:30:46.080 --> 02:30:47.280]   "You can pre-order me!"
[02:30:47.280 --> 02:30:50.720]   All this stuff comes out in May for some reason,
[02:30:50.720 --> 02:30:51.920]   like it's the magic month.
[02:30:51.920 --> 02:30:53.520]   I don't know why.
[02:30:53.520 --> 02:30:54.480]   Well, this is all--
[02:30:54.480 --> 02:30:56.080]   They're all putting it out there because part of the novel,
[02:30:56.080 --> 02:30:57.280]   do you offer for any--
[02:30:57.280 --> 02:30:58.080]   Oh, I see.
[02:30:58.080 --> 02:30:59.680]   I think it's any pre-order.
[02:30:59.680 --> 02:31:00.000]   Right.
[02:31:00.000 --> 02:31:01.760]   There's another book you will--
[02:31:01.760 --> 02:31:04.240]   A lot of books coming out in May for some reason.
[02:31:04.240 --> 02:31:06.400]   It's ahead of summer travel.
[02:31:06.400 --> 02:31:07.120]   I guess.
[02:31:07.120 --> 02:31:07.440]   Yeah.
[02:31:08.160 --> 02:31:10.960]   Those be treats like the sum of all history or--
[02:31:10.960 --> 02:31:11.200]   Right.
[02:31:11.200 --> 02:31:12.800]   The Gutenberg.
[02:31:12.800 --> 02:31:13.440]   [LAUGHTER]
[02:31:13.440 --> 02:31:13.840]   Sum--
[02:31:13.840 --> 02:31:15.120]   Sum does a couple of things.
[02:31:15.120 --> 02:31:16.880]   Oh, sum's out in September.
[02:31:16.880 --> 02:31:17.680]   This is--
[02:31:17.680 --> 02:31:18.320]   Oh, OK.
[02:31:18.320 --> 02:31:19.120]   --for the beach.
[02:31:19.120 --> 02:31:20.080]   This is a fascinating--
[02:31:20.080 --> 02:31:22.640]   I know a little bit about the story of the pocket calculator.
[02:31:22.640 --> 02:31:23.200]   It's fascinating.
[02:31:23.200 --> 02:31:25.200]   So I will absolutely read this.
[02:31:25.200 --> 02:31:28.880]   And Pruitt, what you got for us?
[02:31:28.880 --> 02:31:31.600]   Well, since he was talking about books,
[02:31:31.600 --> 02:31:37.760]   I just added one real quickly from Sean Powers, co-host on Floss Week.
[02:31:37.760 --> 02:31:38.240]   Oh, yeah.
[02:31:38.240 --> 02:31:41.520]   And he's coming up to do a special AMA with you, right?
[02:31:41.520 --> 02:31:42.400]   On the club to it?
[02:31:42.400 --> 02:31:43.680]   That is correct, sir.
[02:31:43.680 --> 02:31:44.400]   That is correct.
[02:31:44.400 --> 02:31:45.440]   He wrote a kid's book.
[02:31:45.440 --> 02:31:45.440]   He's this book.
[02:31:45.440 --> 02:31:46.640]   It looks like--
[02:31:46.640 --> 02:31:47.360]   He wrote--
[02:31:47.360 --> 02:31:50.800]   He started writing comments back when the pandemic kicked off.
[02:31:50.800 --> 02:31:54.080]   You know, it was part of his own mental exercise.
[02:31:54.080 --> 02:31:56.240]   And for his own mental health,
[02:31:56.240 --> 02:31:58.240]   and it was a lot of fun for him.
[02:31:58.240 --> 02:31:59.440]   So he turned it into a book,
[02:31:59.440 --> 02:32:02.160]   and it's out for pre-order today.
[02:32:02.160 --> 02:32:03.520]   And I believe, just like you said,
[02:32:03.520 --> 02:32:07.120]   the whole bar is a noble discount.
[02:32:07.120 --> 02:32:08.400]   It's effective on it, too.
[02:32:08.400 --> 02:32:11.040]   And it's called My Big Round World.
[02:32:11.040 --> 02:32:12.640]   And it's pretty good stuff.
[02:32:12.640 --> 02:32:14.480]   So shout out to Mr. Sean Powers.
[02:32:14.480 --> 02:32:16.560]   He's a good dude.
[02:32:16.560 --> 02:32:18.400]   It started out because he couldn't draw arms.
[02:32:18.400 --> 02:32:19.680]   Right.
[02:32:19.680 --> 02:32:25.680]   Getting a square personality into a round world,
[02:32:25.680 --> 02:32:27.040]   not just for kids, for everybody.
[02:32:27.040 --> 02:32:28.080]   Yeah.
[02:32:28.080 --> 02:32:28.560]   What else?
[02:32:28.560 --> 02:32:28.960]   Good stuff.
[02:32:28.960 --> 02:32:29.200]   I'm--
[02:32:29.200 --> 02:32:33.280]   Next, I want to just give a shout out to Mr. Sharp.
[02:32:33.280 --> 02:32:34.000]   I know most--
[02:32:34.880 --> 02:32:36.960]   Twit listeners don't know who he is or care,
[02:32:36.960 --> 02:32:41.520]   but Mr. Shannon Sharp is a Hall of Fame NFL tight end.
[02:32:41.520 --> 02:32:44.560]   And I love his story, and he's got his own show,
[02:32:44.560 --> 02:32:49.520]   but I've been just watching his journey as a Hall of Fame athlete.
[02:32:49.520 --> 02:32:52.400]   Then he's getting into the tech--
[02:32:52.400 --> 02:32:54.960]   not tech commentary, sports commentary side of things.
[02:32:54.960 --> 02:32:57.600]   And he just does so much work, so much research,
[02:32:57.600 --> 02:32:59.440]   and it really shows.
[02:32:59.440 --> 02:33:01.280]   And this latest episode on there,
[02:33:01.280 --> 02:33:02.960]   he's speaking with Steve Harvey.
[02:33:03.600 --> 02:33:07.360]   And that conversation between them just resonated with me personally,
[02:33:07.360 --> 02:33:08.880]   just because of how they came up.
[02:33:08.880 --> 02:33:11.280]   Growing up in the South,
[02:33:11.280 --> 02:33:15.360]   and just the hard work that they did as just regular everyday life,
[02:33:15.360 --> 02:33:22.800]   Sharp talks about being like 19, 20 years old before he used the bathroom inside.
[02:33:22.800 --> 02:33:23.280]   Wow.
[02:33:23.280 --> 02:33:26.160]   And that was in the '80s.
[02:33:26.160 --> 02:33:26.640]   Yeah.
[02:33:26.640 --> 02:33:28.320]   You know, because they grew up poor.
[02:33:28.320 --> 02:33:29.760]   That's like living in New Jersey.
[02:33:29.760 --> 02:33:31.200]   I mean, it's just tough.
[02:33:31.200 --> 02:33:32.480]   Right.
[02:33:32.480 --> 02:33:33.280]   I'm kidding.
[02:33:33.280 --> 02:33:37.040]   But it's just-- I love the stories because he said a lot of things
[02:33:37.040 --> 02:33:39.680]   that made me think about my grandparents.
[02:33:39.680 --> 02:33:44.480]   And I was like, yeah, I remember going to the farm and having to slaughter the hogs.
[02:33:44.480 --> 02:33:45.040]   Wow.
[02:33:45.040 --> 02:33:46.800]   It was a whole process.
[02:33:46.800 --> 02:33:48.640]   And I was like, yeah, these guys get it.
[02:33:48.640 --> 02:33:50.320]   And just seeing where they are now.
[02:33:50.320 --> 02:33:53.920]   Going through all of that hard work and all that struggle,
[02:33:53.920 --> 02:33:57.200]   nothing but respect for him and his journey.
[02:33:57.200 --> 02:34:00.640]   And lastly, I just want to say share hard-heads videos
[02:34:00.640 --> 02:34:04.640]   with everyone you know, please, because that is part of my campaigning
[02:34:04.640 --> 02:34:07.280]   for said hard-head because dad does not want to pay for college.
[02:34:07.280 --> 02:34:08.720]   How's it going very much?
[02:34:08.720 --> 02:34:09.280]   How's it going?
[02:34:09.280 --> 02:34:09.920]   You got any--
[02:34:09.920 --> 02:34:10.560]   Bikes?
[02:34:10.560 --> 02:34:11.680]   Lots of phone calls.
[02:34:11.680 --> 02:34:13.120]   Lots of phone calls.
[02:34:13.120 --> 02:34:15.440]   But hey, ain't nobody showing me the money yet.
[02:34:15.440 --> 02:34:18.240]   But you're a tough negotiator.
[02:34:18.240 --> 02:34:21.440]   I bet I could just see that coach sitting on your couch in your living room.
[02:34:21.440 --> 02:34:24.560]   And you go, well, yeah, what are you going to do for the Mercedes?
[02:34:24.560 --> 02:34:28.400]   You know, and the thing is, hard-heads had it best himself.
[02:34:28.400 --> 02:34:31.840]   He's like, man, it's like everybody's trying to take me out on a date
[02:34:31.840 --> 02:34:33.840]   just to make someone else jealous.
[02:34:33.840 --> 02:34:35.280]   Oh, that's not good.
[02:34:35.280 --> 02:34:36.640]   That's not totally good.
[02:34:36.640 --> 02:34:38.080]   Poor Jacob.
[02:34:38.080 --> 02:34:39.520]   So this is his huddle.
[02:34:39.520 --> 02:34:44.560]   And I've just got a hughgl.com and search for Jacob Pruitt.
[02:34:44.560 --> 02:34:46.000]   And then he shared a video.
[02:34:46.000 --> 02:34:47.840]   Take those videos, send them to every coach you know.
[02:34:47.840 --> 02:34:49.280]   Lots of good.
[02:34:49.280 --> 02:34:49.680]   You know what?
[02:34:49.680 --> 02:34:50.880]   They're fun to watch.
[02:34:50.880 --> 02:34:52.000]   This kid's good.
[02:34:52.000 --> 02:34:53.520]   He's good.
[02:34:53.520 --> 02:34:54.320]   He's good.
[02:34:54.320 --> 02:34:55.520]   He's a good citizen.
[02:34:55.520 --> 02:34:56.560]   He's a nice kid.
[02:34:56.560 --> 02:34:57.040]   Citizen.
[02:34:57.040 --> 02:34:57.920]   All vouch for him.
[02:34:57.920 --> 02:34:59.440]   I remember Jacob very well.
[02:34:59.440 --> 02:35:03.680]   Loved hanging with him when you first moved out here.
[02:35:03.680 --> 02:35:05.680]   He came over to dinner with a family.
[02:35:05.680 --> 02:35:06.880]   Just the nicest boy.
[02:35:06.880 --> 02:35:10.640]   Brown has reached out recently and called.
[02:35:10.640 --> 02:35:11.840]   He called to Drown.
[02:35:11.840 --> 02:35:13.120]   Couldn't be a better one.
[02:35:13.120 --> 02:35:13.840]   Send him to Brad.
[02:35:13.840 --> 02:35:14.080]   Oh!
[02:35:14.080 --> 02:35:15.760]   I know some people in Providence.
[02:35:15.760 --> 02:35:17.120]   That would be a great school.
[02:35:17.120 --> 02:35:17.680]   Columbia.
[02:35:17.680 --> 02:35:18.720]   He'd be a New York City.
[02:35:18.720 --> 02:35:19.680]   I'd be here in New York at Columbia.
[02:35:19.680 --> 02:35:20.960]   He knows somebody there.
[02:35:20.960 --> 02:35:23.120]   Ivy Leagues have been phone calling him.
[02:35:23.120 --> 02:35:25.680]   Dartmouth is all the couple of times.
[02:35:25.680 --> 02:35:26.320]   Does he have?
[02:35:26.320 --> 02:35:27.440]   He must have good grades.
[02:35:27.440 --> 02:35:29.200]   He's got great grades.
[02:35:29.200 --> 02:35:29.680]   Yeah.
[02:35:29.680 --> 02:35:30.240]   You know, so that's--
[02:35:30.240 --> 02:35:32.000]   Because they're looking at all show-care money.
[02:35:32.000 --> 02:35:33.520]   I don't know if y'all show-care money.
[02:35:33.520 --> 02:35:36.000]   You know, the football programs aren't as important at these ivies.
[02:35:36.000 --> 02:35:38.800]   But they're important, but they're not as important.
[02:35:38.800 --> 02:35:40.000]   They want a scholar athlete.
[02:35:40.000 --> 02:35:40.640]   So that's a good--
[02:35:40.640 --> 02:35:41.840]   That's high praise.
[02:35:41.840 --> 02:35:43.600]   Well, that could be life-changing.
[02:35:43.600 --> 02:35:47.360]   Brown, Columbia, Dartmouth, and--
[02:35:47.360 --> 02:35:48.400]   Well, he's smarter than you.
[02:35:48.400 --> 02:35:51.680]   It depends.
[02:35:51.680 --> 02:35:52.560]   Depends on the question.
[02:35:52.560 --> 02:35:53.360]   I'll just say that.
[02:35:53.360 --> 02:35:54.320]   Depends on the question.
[02:35:55.040 --> 02:35:56.720]   Hey, have you done the dishes a day?
[02:35:56.720 --> 02:35:57.920]   You can't answer what do you mean.
[02:35:57.920 --> 02:35:59.680]   So what does this--
[02:35:59.680 --> 02:36:00.720]   Is this what is that?
[02:36:00.720 --> 02:36:03.520]   Jacob.
[02:36:03.520 --> 02:36:04.720]   Yeah, go Jacob.
[02:36:04.720 --> 02:36:05.760]   Yeah, Jacob.
[02:36:05.760 --> 02:36:06.560]   Go Jacob.
[02:36:06.560 --> 02:36:07.760]   Huddle Doc.
[02:36:07.760 --> 02:36:08.240]   Dang, calm.
[02:36:08.240 --> 02:36:09.200]   Quit family.
[02:36:09.200 --> 02:36:09.600]   Nice.
[02:36:09.600 --> 02:36:11.440]   So one more quick mention if I may.
[02:36:11.440 --> 02:36:12.080]   Yes.
[02:36:12.080 --> 02:36:14.720]   So I had a guest appearance on, and this is going to be--
[02:36:14.720 --> 02:36:16.240]   You're going to know what, and I didn't know the Dan
[02:36:16.240 --> 02:36:18.720]   Loubataran show.
[02:36:18.720 --> 02:36:21.040]   You ever heard of him?
[02:36:21.040 --> 02:36:21.600]   Sure.
[02:36:21.600 --> 02:36:22.400]   I have.
[02:36:22.400 --> 02:36:22.640]   Yeah.
[02:36:23.520 --> 02:36:25.200]   So he's a jock, right?
[02:36:25.200 --> 02:36:26.560]   It's a sports podcast.
[02:36:26.560 --> 02:36:27.440]   They want me to--
[02:36:27.440 --> 02:36:28.240]   I said, I don't know--
[02:36:28.240 --> 02:36:30.400]   SHIT about sports.
[02:36:30.400 --> 02:36:30.800]   I don't know.
[02:36:30.800 --> 02:36:31.680]   I want to talk about Tucker.
[02:36:31.680 --> 02:36:32.160]   It's fine.
[02:36:32.160 --> 02:36:33.120]   So I go on.
[02:36:33.120 --> 02:36:35.520]   I do my, you know, spiel.
[02:36:35.520 --> 02:36:36.880]   Like four or five people came and said,
[02:36:36.880 --> 02:36:39.440]   "My podcast stream is crossed."
[02:36:39.440 --> 02:36:41.040]   Yeah.
[02:36:41.040 --> 02:36:42.480]   You're on this one.
[02:36:42.480 --> 02:36:45.040]   Yes, we should know who Dan Loubataran is.
[02:36:45.040 --> 02:36:45.840]   Yes.
[02:36:45.840 --> 02:36:46.240]   Yeah.
[02:36:46.240 --> 02:36:47.440]   Dan Loubataran.
[02:36:47.440 --> 02:36:49.120]   String fans are everywhere.
[02:36:49.120 --> 02:36:49.520]   Nice.
[02:36:49.520 --> 02:36:50.560]   That's awesome, man.
[02:36:50.560 --> 02:36:51.040]   Nice.
[02:36:51.040 --> 02:36:53.040]   And we should catch up with that.
[02:36:53.840 --> 02:36:56.960]   Show so we can hear about you talking about sports.
[02:36:56.960 --> 02:36:58.000]   That'll be fun.
[02:36:58.000 --> 02:36:59.600]   Oh, no, you never hear me talking about sports.
[02:36:59.600 --> 02:36:59.920]   OK.
[02:36:59.920 --> 02:37:03.920]   I listened before I went on,
[02:37:03.920 --> 02:37:07.520]   and I had this flashback to why I hated going to the barbers.
[02:37:07.520 --> 02:37:09.520]   Oh, it's like going to a barber.
[02:37:09.520 --> 02:37:10.560]   Oh, he's a boy.
[02:37:10.560 --> 02:37:12.160]   How about those fillies?
[02:37:12.160 --> 02:37:12.640]   Yeah.
[02:37:12.640 --> 02:37:14.720]   You know, I was scared to death.
[02:37:14.720 --> 02:37:16.080]   I'm on the chess club.
[02:37:16.080 --> 02:37:16.960]   I don't know that.
[02:37:16.960 --> 02:37:17.360]   Exactly.
[02:37:17.360 --> 02:37:21.440]   I could do AV for you, Mr. Barber.
[02:37:21.440 --> 02:37:22.800]   Ask me about film scripts.
[02:37:22.800 --> 02:37:24.720]   I could tell you everything there is now.
[02:37:24.720 --> 02:37:27.920]   Hey, Mr. Jarvis, that's awesome that you're on there.
[02:37:27.920 --> 02:37:29.520]   You know who he is.
[02:37:29.520 --> 02:37:32.560]   He's a big famous, big famous sports podcast.
[02:37:32.560 --> 02:37:33.440]   Nice.
[02:37:33.440 --> 02:37:34.720]   Yeah, it's cool.
[02:37:34.720 --> 02:37:35.920]   Thank you.
[02:37:35.920 --> 02:37:37.360]   Pro it hands-on photography.
[02:37:37.360 --> 02:37:38.720]   Twit.tv/hop.
[02:37:38.720 --> 02:37:41.120]   I will be watching the Rick Salmon interview
[02:37:41.120 --> 02:37:43.520]   about travel photography.
[02:37:43.520 --> 02:37:45.040]   Now that it's too late.
[02:37:45.040 --> 02:37:46.240]   Well, but you got to come in on.
[02:37:46.240 --> 02:37:50.720]   Well, again, we're going to continue to talk about
[02:37:51.440 --> 02:37:55.440]   smartphone photography and videography
[02:37:55.440 --> 02:37:56.880]   and just getting some use out of that.
[02:37:56.880 --> 02:38:00.240]   I have a special guest joining me this week, Miss Susie Batello.
[02:38:00.240 --> 02:38:01.600]   Just great.
[02:38:01.600 --> 02:38:03.120]   Just about the mobile film fest.
[02:38:03.120 --> 02:38:05.280]   It's going to be a good show.
[02:38:05.280 --> 02:38:09.120]   I have to say, cameras, phones have gotten so good.
[02:38:09.120 --> 02:38:14.400]   Whether it's the Pixel 7 or the S23 Ultra or the iPhone 14,
[02:38:14.400 --> 02:38:17.120]   I felt like I got every shot I wanted.
[02:38:17.120 --> 02:38:18.560]   Yeah.
[02:38:18.560 --> 02:38:20.480]   It's I can't knock them.
[02:38:20.480 --> 02:38:23.360]   There are some things that I wanted full-frame sensor for.
[02:38:23.360 --> 02:38:23.840]   Sure.
[02:38:23.840 --> 02:38:27.840]   But most people, phone will do just fine.
[02:38:27.840 --> 02:38:28.320]   Low-light.
[02:38:28.320 --> 02:38:31.440]   Low-light, see, you know, if it was dark out,
[02:38:31.440 --> 02:38:32.960]   I wasn't able to get great shots.
[02:38:32.960 --> 02:38:35.280]   And zoom, Ultra zoom.
[02:38:35.280 --> 02:38:37.680]   And fortunately, Sabra brought her OM1,
[02:38:37.680 --> 02:38:40.080]   which is a very nice micro four-thirds camera.
[02:38:40.080 --> 02:38:41.360]   So she was able to get that full.
[02:38:41.360 --> 02:38:43.760]   She kills me how humble she is.
[02:38:43.760 --> 02:38:44.800]   She's really good.
[02:38:44.800 --> 02:38:45.760]   She's a good photographer, isn't she?
[02:38:45.760 --> 02:38:47.520]   She's so diagrammed now.
[02:38:47.520 --> 02:38:48.880]   I'm just hobbyist.
[02:38:48.880 --> 02:38:49.360]   Oh, whatever.
[02:38:49.360 --> 02:38:50.080]   You could shoot.
[02:38:50.080 --> 02:38:51.680]   She could shoot.
[02:38:51.680 --> 02:38:53.360]   Thank you, Aunt.
[02:38:53.360 --> 02:38:55.040]   Bye, Stacey.
[02:38:55.040 --> 02:38:57.920]   Stacey on IOT.com is her website.
[02:38:57.920 --> 02:39:00.080]   The IOT podcast with Kevin Tofel.
[02:39:00.080 --> 02:39:01.520]   Thank you.
[02:39:01.520 --> 02:39:02.720]   Have a wonderful week.
[02:39:02.720 --> 02:39:04.800]   Will you, you're not going to be here next week, I think, right?
[02:39:04.800 --> 02:39:06.320]   Or you are.
[02:39:06.320 --> 02:39:06.720]   I am.
[02:39:06.720 --> 02:39:07.520]   Oh, good.
[02:39:07.520 --> 02:39:08.080]   Thank goodness.
[02:39:08.080 --> 02:39:08.880]   Thank you for your next week.
[02:39:08.880 --> 02:39:09.440]   Okay, good.
[02:39:09.440 --> 02:39:09.840]   Okay.
[02:39:09.840 --> 02:39:10.320]   All right.
[02:39:10.320 --> 02:39:10.480]   All right.
[02:39:10.480 --> 02:39:11.440]   Sometimes I forget.
[02:39:11.440 --> 02:39:11.760]   Bye.
[02:39:11.760 --> 02:39:12.480]   She wants to go.
[02:39:12.480 --> 02:39:13.280]   Bye.
[02:39:13.280 --> 02:39:14.640]   And Jeff Jarvis, what?
[02:39:14.640 --> 02:39:15.280]   Oh, dude.
[02:39:15.280 --> 02:39:16.400]   He's just watched the times.
[02:39:16.400 --> 02:39:18.640]   He's he's the director of the townite.
[02:39:18.640 --> 02:39:18.960]   Oh, yeah.
[02:39:18.960 --> 02:39:20.880]   She's got to go do that phone call.
[02:39:20.880 --> 02:39:21.680]   Yeah.
[02:39:21.680 --> 02:39:21.840]   Yeah.
[02:39:21.840 --> 02:39:22.800]   I get so late.
[02:39:22.800 --> 02:39:24.880]   I have no idea.
[02:39:24.880 --> 02:39:25.440]   What we do.
[02:39:25.440 --> 02:39:29.600]   Cash, he's the director of the townite center for entrepreneurial
[02:39:29.600 --> 02:39:30.000]   journalism.
[02:39:30.000 --> 02:39:31.520]   We don't have too much fun.
[02:39:31.520 --> 02:39:32.080]   At the.
[02:39:32.080 --> 02:39:37.680]   Craig Newmark Graduate School of Joy-Nalism.
[02:39:37.680 --> 02:39:40.320]   It's a city university in New York.
[02:39:40.320 --> 02:39:44.480]   They made you a new card because you have so many additional titles.
[02:39:44.480 --> 02:39:45.520]   I was not.
[02:39:45.520 --> 02:39:46.000]   Last boy.
[02:39:46.000 --> 02:39:48.000]   I was kitchen manager at Ponderosa Statehouse.
[02:39:48.000 --> 02:39:48.960]   I just wanted that corrected.
[02:39:48.960 --> 02:39:49.760]   Oh, well.
[02:39:49.760 --> 02:39:50.640]   Got to make a new one.
[02:39:50.640 --> 02:39:51.040]   Wow.
[02:39:51.040 --> 02:39:51.440]   New card.
[02:39:51.440 --> 02:39:51.680]   Yeah.
[02:39:51.680 --> 02:39:52.080]   There you go.
[02:39:52.080 --> 02:39:52.720]   New card.
[02:39:52.720 --> 02:39:54.720]   Thank you, Mr. J.J.
[02:39:54.720 --> 02:39:56.240]   Good to see you.
[02:39:56.240 --> 02:39:57.280]   It's Jeff Rose.
[02:39:57.280 --> 02:39:58.960]   Just text Jeff Rose.
[02:39:58.960 --> 02:40:02.560]   That's his superhero name.
[02:40:02.560 --> 02:40:07.360]   We do a twit of a Wednesday afternoon about 2 p.m.
[02:40:07.360 --> 02:40:09.440]   Civic 5 p.m. Eastern.
[02:40:09.440 --> 02:40:11.040]   That'd be 2100 UTC.
[02:40:11.040 --> 02:40:12.400]   If you want to watch us live,
[02:40:13.280 --> 02:40:16.080]   there are live streams at twit.tv/live.
[02:40:16.080 --> 02:40:18.800]   You could chat with us live at IRC.twit.tv.
[02:40:18.800 --> 02:40:20.240]   Of course, if you're in the club,
[02:40:20.240 --> 02:40:23.440]   you can always chat with us in our club twit discord.
[02:40:23.440 --> 02:40:24.880]   A wonderful place to hang.
[02:40:24.880 --> 02:40:29.520]   After the fact on demand versions of the show available at twit.tv/twig.
[02:40:29.520 --> 02:40:33.600]   There's also a YouTube channel.
[02:40:33.600 --> 02:40:36.640]   In fact, there's a link there at twit.tv/twig.
[02:40:36.640 --> 02:40:39.360]   That'll take you to the YouTube channel if you want to share the video
[02:40:39.360 --> 02:40:40.720]   or you want to just watch it on YouTube.
[02:40:41.360 --> 02:40:44.160]   I think the easiest thing to do is subscribe in your favorite podcast player.
[02:40:44.160 --> 02:40:46.240]   That way you'll get it automatically as soon as it's done.
[02:40:46.240 --> 02:40:51.760]   Thanks to our producers and our staff and our team,
[02:40:51.760 --> 02:40:53.840]   all of who held down the fort.
[02:40:53.840 --> 02:40:58.480]   While Elis and I were jaunting about, they did a great job.
[02:40:58.480 --> 02:40:59.840]   Thanks to all of you for that.
[02:40:59.840 --> 02:41:01.440]   Jason Howell and Michael Sargent,
[02:41:01.440 --> 02:41:04.640]   of course, our studio manager, John Slanina.
[02:41:04.640 --> 02:41:06.400]   Benito, thank you.
[02:41:06.400 --> 02:41:07.040]   Jamer Bee.
[02:41:07.040 --> 02:41:08.080]   Jamer Bee.
[02:41:08.080 --> 02:41:10.800]   Benito, thank you for doing a great job on the board.
[02:41:11.440 --> 02:41:15.360]   Burke McQuinn for bringing a dog to work.
[02:41:15.360 --> 02:41:19.760]   And doing all the things that Mr. Burke does.
[02:41:19.760 --> 02:41:20.960]   Did I call the show Twit?
[02:41:20.960 --> 02:41:21.920]   You know, it's not Twit.
[02:41:21.920 --> 02:41:24.720]   It's twig, T-W-I-G.
[02:41:24.720 --> 02:41:26.400]   And I hope you will be here next week.
[02:41:26.400 --> 02:41:28.080]   Bye-bye.
[02:41:28.080 --> 02:41:32.320]   If you love all things, Android,
[02:41:32.320 --> 02:41:34.080]   well, I'm going to show for you to check out.
[02:41:34.080 --> 02:41:35.520]   It's called All About Android.
[02:41:35.520 --> 02:41:37.600]   And I'll give you three guesses what we talk about.
[02:41:37.600 --> 02:41:41.440]   We talk about Android, the latest news, hardware, apps.
[02:41:41.440 --> 02:41:42.400]   We answer feedback.
[02:41:42.400 --> 02:41:44.560]   It's me, Jason Howell, Ron Richards,
[02:41:44.560 --> 02:41:48.400]   Winswood Dow, and a whole cast of awesome characters
[02:41:48.400 --> 02:41:50.960]   talking about the operating system that we love.
[02:41:50.960 --> 02:41:54.640]   You can find All About Android at twit.tv/AA.
[02:41:54.640 --> 02:42:04.640]   [MUSIC]
[02:42:04.640 --> 02:42:08.000]   [MUSIC PLAYING]

