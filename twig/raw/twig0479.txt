;FFMETADATA1
title=It's a Sugar Speedball!
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=479
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.000]   It's time for Twig this week in Google Stacey Yegenbothoms here filling in for Jeff Jarvis.
[00:00:05.000 --> 00:00:09.000]   Matthew Ingram will talk about the new Google Home Hub.
[00:00:09.000 --> 00:00:11.000]   I've got a little pocket review for you.
[00:00:11.000 --> 00:00:13.000]   Just got it today.
[00:00:13.000 --> 00:00:18.000]   Three more problems with the Pixel 3 XL and Tim Cook's Mad as heck.
[00:00:18.000 --> 00:00:20.000]   It's all coming up next on Twig.
[00:00:20.000 --> 00:00:25.000]   Netcast you love.
[00:00:25.000 --> 00:00:27.000]   From people you trust.
[00:00:28.000 --> 00:00:31.000]   This is Twig.
[00:00:31.000 --> 00:00:38.000]   This is Twig.
[00:00:38.000 --> 00:00:44.000]   This week in Google, Episode 479, recorded Wednesday, October 24th, 2018.
[00:00:44.000 --> 00:00:46.000]   It's a sugar speedball.
[00:00:46.000 --> 00:00:51.000]   This week in Google is brought to you by Rocket Mortgage by Quick-It-Lones.
[00:00:51.000 --> 00:00:53.000]   Introducing Ray Shield Approval.
[00:00:53.000 --> 00:00:59.000]   If you're in the market to buy a home, Ray Shield Approval locks up your rate for up to 90 days while you shop.
[00:00:59.000 --> 00:01:01.000]   It's a real game changer.
[00:01:01.000 --> 00:01:05.000]   Learn more and get started at rocketmortgage.com/twig.
[00:01:05.000 --> 00:01:11.000]   And by DigitalOcean, the easiest cloud platform to deploy, manage and scale applications.
[00:01:11.000 --> 00:01:19.000]   Over 150,000 businesses rely on DigitalOcean to remove infrastructure friction and deliver industry-leading price performance.
[00:01:19.000 --> 00:01:25.000]   Sign up today and receive a free $100 credit at dio.co/twig.
[00:01:25.000 --> 00:01:28.000]   It's time for Twig this week in Google.
[00:01:28.000 --> 00:01:31.000]   The show where we talk about the latest news from the Googleverse.
[00:01:31.000 --> 00:01:35.000]   Stacey Higginbotham is here from Stacey on IoT.
[00:01:35.000 --> 00:01:36.000]   Hello Stacey.
[00:01:36.000 --> 00:01:40.000]   She's got one of those little calls that are doads.
[00:01:40.000 --> 00:01:42.000]   But you sound fine actually.
[00:01:42.000 --> 00:01:43.000]   Oh, well good.
[00:01:43.000 --> 00:01:45.000]   I'm making fun of you.
[00:01:45.000 --> 00:01:46.000]   It's okay.
[00:01:46.000 --> 00:01:47.000]   I expect that.
[00:01:47.000 --> 00:01:48.000]   I expect nothing less.
[00:01:48.000 --> 00:01:53.000]   Until you get that fist to come out of the back of the thing, to punch me.
[00:01:53.000 --> 00:01:56.000]   I'm safe.
[00:01:56.000 --> 00:01:59.000]   Also with this, your erstwhile cohort at giga-ome.
[00:01:59.000 --> 00:02:04.000]   Matthew Ingram, now Chief Digital Writer at the Columbia Journalism Review, cjr.org.
[00:02:04.000 --> 00:02:06.000]   Great to have you, Matthew.
[00:02:06.000 --> 00:02:08.000]   Thank you, Chris, to be here.
[00:02:08.000 --> 00:02:15.000]   I'm glad you both are here and I would love to have had Jeff here, but he's traveling still.
[00:02:15.000 --> 00:02:16.000]   He's a traveling.
[00:02:16.000 --> 00:02:18.000]   This is time of year to travel.
[00:02:18.000 --> 00:02:26.680]   But I saw with some disappointment that Jimmy Wales citizen journalist Enterprise maybe
[00:02:26.680 --> 00:02:28.000]   isn't doing all that well.
[00:02:28.000 --> 00:02:35.720]   They've let all the journalists go and now it's all going to be community driven, like
[00:02:35.720 --> 00:02:37.560]   a wiki.
[00:02:37.560 --> 00:02:43.640]   So it sounds like I've actually been doing some research on this and it sounds like they
[00:02:43.640 --> 00:02:46.800]   are going to hire new journalists.
[00:02:46.800 --> 00:02:50.440]   So it's not that they're not going to have any, but they want to...
[00:02:50.440 --> 00:02:52.800]   What happened to the 12 original guys?
[00:02:52.800 --> 00:03:00.960]   Well, the story is that they want the journalist that they hire to be more community friendly
[00:03:00.960 --> 00:03:03.080]   or to interact with the community better.
[00:03:03.080 --> 00:03:09.360]   So the suggestion or the implication is that the ones they had were two sort of "I'm a
[00:03:09.360 --> 00:03:16.960]   journalist" and I say what goes and I get content from you, the user, and then I turn
[00:03:16.960 --> 00:03:23.160]   it into journalism as opposed to helping, at least that's the way it was phrased anyway.
[00:03:23.160 --> 00:03:28.240]   It's wiki Tribune and the last line of the Verge article says, "Wiki Tribune plans to
[00:03:28.240 --> 00:03:32.080]   hire more journalists in the future in a capacity that's more community driven and less about
[00:03:32.080 --> 00:03:34.880]   supervising the work of outside computers."
[00:03:34.880 --> 00:03:41.520]   That makes... I remember at Tech TV that was always... and even before then, any television
[00:03:41.520 --> 00:03:48.280]   show in the '90s that had a website and a TV part as Tech TV did, as the site did before
[00:03:48.280 --> 00:03:54.560]   it, there was just an impermeable wall between the television people and the web people at
[00:03:54.560 --> 00:03:56.360]   that time.
[00:03:56.360 --> 00:03:58.320]   I think that's changed over time.
[00:03:58.320 --> 00:04:07.120]   So Jimmy wrote something on the site about the changes and he said that a lot of journalists...
[00:04:07.120 --> 00:04:13.280]   and I can agree with him on this, a lot of journalists see themselves as sort of above
[00:04:13.280 --> 00:04:18.320]   regular people because they have certain skills and they've done certain things and so that
[00:04:18.320 --> 00:04:24.240]   that's not a great mindset to go into collaborating with users on.
[00:04:24.240 --> 00:04:28.280]   And I would go along with that.
[00:04:28.280 --> 00:04:30.320]   Well I know that's how Stacey feels.
[00:04:30.320 --> 00:04:31.320]   I do.
[00:04:31.320 --> 00:04:33.320]   I hate collaborating with Norma's.
[00:04:33.320 --> 00:04:34.320]   God.
[00:04:34.320 --> 00:04:36.320]   But you are better than another.
[00:04:36.320 --> 00:04:37.320]   It was not just a real...
[00:04:37.320 --> 00:04:39.920]   I mean, it was actual reality.
[00:04:39.920 --> 00:04:41.160]   Well, good.
[00:04:41.160 --> 00:04:42.800]   I'm actually glad that it's doing all right.
[00:04:42.800 --> 00:04:47.000]   That's actually... it sounds to me like a reasonable course correction and it is inevitable
[00:04:47.000 --> 00:04:50.320]   in this kind of thing that you have people who train in this who went to graduate school
[00:04:50.320 --> 00:04:51.320]   like Stacey did.
[00:04:51.320 --> 00:04:52.320]   I don't know about...
[00:04:52.320 --> 00:04:54.320]   I actually did not go to graduate school.
[00:04:54.320 --> 00:04:55.320]   That's important to know.
[00:04:55.320 --> 00:04:57.080]   Like, like that you did.
[00:04:57.080 --> 00:04:58.080]   I did.
[00:04:58.080 --> 00:04:59.080]   What do you did?
[00:04:59.080 --> 00:05:00.080]   I know.
[00:05:00.080 --> 00:05:01.080]   I wonder...
[00:05:01.080 --> 00:05:04.400]   Well, graduate school was a waste of brain cells for me because mine was all about like
[00:05:04.400 --> 00:05:06.760]   content analysis as opposed to practical journalism.
[00:05:06.760 --> 00:05:09.720]   I was like, get me on the streets.
[00:05:09.720 --> 00:05:11.920]   I went right after typewriters were invented.
[00:05:11.920 --> 00:05:14.800]   So most of my kids used this.
[00:05:14.800 --> 00:05:19.760]   And Jeff who teaches graduate school in journalism and isn't with us today, the lobby of his
[00:05:19.760 --> 00:05:23.880]   graduate school is actually has a display of antique typewriters.
[00:05:23.880 --> 00:05:26.000]   So it's all coming full circle.
[00:05:26.000 --> 00:05:31.480]   So I tell the kids when I go to the 20 year olds, the kids, when I talk to them at journalism
[00:05:31.480 --> 00:05:34.720]   schools about our journalism school, which was typewriters.
[00:05:34.720 --> 00:05:39.920]   And we type things out and then we had to print them on a giant Gestetner machine.
[00:05:39.920 --> 00:05:40.920]   Oh, geez.
[00:05:40.920 --> 00:05:42.440]   This is like it sounds like the Middle Ages.
[00:05:42.440 --> 00:05:45.840]   Did you shout copy?
[00:05:45.840 --> 00:05:50.080]   And then this huge roll of paper would come off and you'd cut it with an exact knife and
[00:05:50.080 --> 00:05:53.200]   then try and trim it and glue it on to a paper.
[00:05:53.200 --> 00:05:54.200]   Oh, wow.
[00:05:54.200 --> 00:05:59.040]   Yeah, I remember many years ago, 25, 30 years ago going to see, going to the Chronicle where
[00:05:59.040 --> 00:06:03.400]   they were laying out the comics and they still were using wax and exacto knives.
[00:06:03.400 --> 00:06:08.720]   And the guy said, he said, this is, this is, by next year, nobody will do this in the
[00:06:08.720 --> 00:06:09.720]   world.
[00:06:09.720 --> 00:06:11.400]   I think they were when the last holdouts.
[00:06:11.400 --> 00:06:16.960]   I remember using Dreamweaver to actually code the magazine that I was putting on the
[00:06:16.960 --> 00:06:17.960]   web in college.
[00:06:17.960 --> 00:06:20.680]   You know, when we did the first time, it's not that old Stacy.
[00:06:20.680 --> 00:06:21.680]   That does not.
[00:06:21.680 --> 00:06:22.680]   I remember.
[00:06:22.680 --> 00:06:23.680]   I remember.
[00:06:23.680 --> 00:06:24.680]   Yeah.
[00:06:24.680 --> 00:06:25.680]   Yeah.
[00:06:25.680 --> 00:06:26.680]   HTML hot metal.
[00:06:26.680 --> 00:06:34.560]   There was one that it had spider in it or something.
[00:06:34.560 --> 00:06:35.560]   Spiders.
[00:06:35.560 --> 00:06:36.560]   Yeah.
[00:06:36.560 --> 00:06:37.560]   Web spider.
[00:06:37.560 --> 00:06:38.560]   Yeah.
[00:06:38.560 --> 00:06:39.560]   Yeah.
[00:06:39.560 --> 00:06:40.560]   Yeah.
[00:06:40.560 --> 00:06:41.560]   I have received.
[00:06:41.560 --> 00:06:42.560]   Am I?
[00:06:42.560 --> 00:06:43.560]   Oh, go ahead.
[00:06:43.560 --> 00:06:44.560]   Do you stay, see anything else you want to say about?
[00:06:44.560 --> 00:06:47.400]   Oh, I was going to segue us off of old journalism to go new, exciting things.
[00:06:47.400 --> 00:06:50.080]   The newest, latest gizmo has arrived.
[00:06:50.080 --> 00:06:51.080]   Okay.
[00:06:51.080 --> 00:06:55.160]   Just to give you a sense, for those of you watching at home, if you're listening, I'll
[00:06:55.160 --> 00:06:57.760]   describe this, this is the Google Home Hub.
[00:06:57.760 --> 00:07:01.040]   The thing Google announced at Google I/O finally came today.
[00:07:01.040 --> 00:07:04.480]   This is a Pixel 3 phone also announced at the same time.
[00:07:04.480 --> 00:07:07.480]   These are almost exactly the same size.
[00:07:07.480 --> 00:07:11.560]   So it was hard to tell in the announcement how big this Home Hub was.
[00:07:11.560 --> 00:07:12.560]   It ain't big.
[00:07:12.560 --> 00:07:17.040]   It's, it's actually a little bit function, a little bit smaller than the Pixel 7 7 inch
[00:07:17.040 --> 00:07:20.880]   tab or the Nexus 7 7 inch tablet that Google used to sell.
[00:07:20.880 --> 00:07:22.540]   They sold out for $127.
[00:07:22.540 --> 00:07:24.280]   This is $149.
[00:07:24.280 --> 00:07:25.280]   No camera.
[00:07:25.280 --> 00:07:26.280]   That's a light sensor.
[00:07:26.280 --> 00:07:27.280]   It's an ambient light sensor.
[00:07:27.280 --> 00:07:32.680]   If I cover it up, you'll see at night the pictures get darker and darker.
[00:07:32.680 --> 00:07:34.880]   So it won't keep you up at night.
[00:07:34.880 --> 00:07:38.360]   I have to say the excellent camera.
[00:07:38.360 --> 00:07:40.320]   This is a nice photo frame.
[00:07:40.320 --> 00:07:42.600]   It integrates really well with Google photos.
[00:07:42.600 --> 00:07:45.400]   What I did for this is I picked people.
[00:07:45.400 --> 00:07:49.520]   You could choose people that you want to have in your pictures.
[00:07:49.520 --> 00:07:54.600]   So I chose my family and every one of these pictures has somebody, sometimes in a tiny,
[00:07:54.600 --> 00:07:58.440]   tiny picture of my family.
[00:07:58.440 --> 00:08:02.440]   And it's really fun because it goes back 20 years ever since I started taking digital
[00:08:02.440 --> 00:08:04.000]   photos.
[00:08:04.000 --> 00:08:05.280]   So it's a really fun photo frame.
[00:08:05.280 --> 00:08:07.040]   Now I've sent it for every 10 seconds.
[00:08:07.040 --> 00:08:09.200]   You can make it every minute, every five minutes, every hour.
[00:08:09.200 --> 00:08:13.480]   You don't have to change it that frequently, but just for purposes of display.
[00:08:13.480 --> 00:08:16.200]   And it has also got Google Assistant.
[00:08:16.200 --> 00:08:24.200]   Let me turn the microphone on and say, I don't know, listen to this week in Google.
[00:08:24.200 --> 00:08:27.440]   Oh, I have to say something first.
[00:08:27.440 --> 00:08:28.440]   Pardon me.
[00:08:28.440 --> 00:08:31.680]   Hey, play this week in Google.
[00:08:31.680 --> 00:08:33.880]   I don't know if it'll work.
[00:08:33.880 --> 00:08:34.880]   Sure.
[00:08:34.880 --> 00:08:40.160]   Here's the latest episode of this week in Google MP3, Twig 478, when a doorbell rings,
[00:08:40.160 --> 00:08:41.680]   a roadie gets its wings.
[00:08:41.680 --> 00:08:43.680]   It's time for Twig.
[00:08:43.680 --> 00:08:45.320]   This week in Google.
[00:08:45.320 --> 00:08:46.600]   Kevin Tofel and Stacy.
[00:08:46.600 --> 00:08:48.080]   Hey, stop.
[00:08:48.080 --> 00:08:49.440]   So the sound is, I think, pretty good.
[00:08:49.440 --> 00:08:54.720]   It's coming out of these fabric covered speakers on the back, which is pretty good.
[00:08:54.720 --> 00:08:57.160]   I'm sad to say I thought, oh, it'll have a type C connector.
[00:08:57.160 --> 00:08:58.160]   It does it.
[00:08:58.160 --> 00:09:01.320]   It has one of those barrel plugs, proprietary barrel plugs.
[00:09:01.320 --> 00:09:06.560]   So, and it has, and I can't show you because it's plugged in, the poorest design for a
[00:09:06.560 --> 00:09:07.960]   plug I've ever seen.
[00:09:07.960 --> 00:09:09.360]   It's so round.
[00:09:09.360 --> 00:09:13.120]   When people have already started complaining, it doesn't work very well in a power strip,
[00:09:13.120 --> 00:09:14.800]   to just be prepared for that.
[00:09:14.800 --> 00:09:17.000]   Yeah, Google did that with the home.
[00:09:17.000 --> 00:09:18.440]   Is it the minis, I think?
[00:09:18.440 --> 00:09:19.440]   Yeah.
[00:09:19.440 --> 00:09:20.440]   It did that.
[00:09:20.440 --> 00:09:21.840]   Yeah, I was really disappointed in that.
[00:09:21.840 --> 00:09:23.480]   It's like, please, come on.
[00:09:23.480 --> 00:09:25.120]   So you know what we're doing with this?
[00:09:25.120 --> 00:09:27.600]   The default display is a photo.
[00:09:27.600 --> 00:09:29.080]   You see, it's still showing the Twig.
[00:09:29.080 --> 00:09:30.080]   It's the default display.
[00:09:30.080 --> 00:09:33.800]   Oh, let me turn it down a little bit because it's a little bright for us to see that you
[00:09:33.800 --> 00:09:36.440]   swipe up to get controls from the bottom.
[00:09:36.440 --> 00:09:39.760]   Here's the Google Home app to control it.
[00:09:39.760 --> 00:09:45.000]   I can't see anything.
[00:09:45.000 --> 00:09:50.680]   I love the photo slideshow, and I think that the screen is very good for that.
[00:09:50.680 --> 00:09:53.560]   It's more than adequate for the slideshow.
[00:09:53.560 --> 00:09:56.080]   It also has, as you can see, a clock display.
[00:09:56.080 --> 00:09:59.680]   It has a variety of digital and analog clocks you can use, but I think everybody's going
[00:09:59.680 --> 00:10:01.320]   to use this as a photo frame.
[00:10:01.320 --> 00:10:02.320]   No video calling.
[00:10:02.320 --> 00:10:03.320]   No video calling.
[00:10:03.320 --> 00:10:04.960]   You can do audio calling.
[00:10:04.960 --> 00:10:06.480]   You can do duo on it, though.
[00:10:06.480 --> 00:10:07.480]   Kevin and I just come in.
[00:10:07.480 --> 00:10:09.480]   You can, but no video.
[00:10:09.480 --> 00:10:10.480]   Yes.
[00:10:10.480 --> 00:10:13.760]   I like this at, I think, at $149.
[00:10:13.760 --> 00:10:17.600]   This makes a lot of sense putting this in the kitchen, in the bedroom.
[00:10:17.600 --> 00:10:18.600]   No camera, right?
[00:10:18.600 --> 00:10:19.600]   In the bathroom.
[00:10:19.600 --> 00:10:20.600]   I don't think it looks good in the kitchen.
[00:10:20.600 --> 00:10:22.240]   I'd say bedroom, maybe bathroom.
[00:10:22.240 --> 00:10:26.440]   Kitchen, I feel like I would want the larger, maybe that JBL you've got there, or maybe
[00:10:26.440 --> 00:10:28.360]   the Lenovo Smart Display that I've got.
[00:10:28.360 --> 00:10:29.920]   You have the Lenovo.
[00:10:29.920 --> 00:10:30.920]   It's just came out.
[00:10:30.920 --> 00:10:32.920]   That's a little small.
[00:10:32.920 --> 00:10:38.560]   I would like the Ten inch Lenovo, which I've got with me, is great for watching YouTube.
[00:10:38.560 --> 00:10:39.800]   You can watch YouTube on it.
[00:10:39.800 --> 00:10:44.640]   You can't watch Netflix yet on the larger ones, although you are supposed to eventually.
[00:10:44.640 --> 00:10:45.640]   Yeah.
[00:10:45.640 --> 00:10:47.640]   How much is the Lenovo?
[00:10:47.640 --> 00:10:49.640]   The bigger Lenovo is 250.
[00:10:49.640 --> 00:10:51.280]   The smaller Lenovo is 200.
[00:10:51.280 --> 00:10:52.680]   The smaller is 8 inches.
[00:10:52.680 --> 00:10:54.240]   The big one is 10 inches.
[00:10:54.240 --> 00:10:55.240]   You like this?
[00:10:55.240 --> 00:10:59.720]   I can slide down from the top and see my home automation stuff.
[00:10:59.720 --> 00:11:01.960]   Yes, and you can control the lights.
[00:11:01.960 --> 00:11:02.960]   I'm very excited.
[00:11:02.960 --> 00:11:03.960]   Isn't that nice?
[00:11:03.960 --> 00:11:04.960]   Yeah.
[00:11:04.960 --> 00:11:07.360]   So these are the lights, media, broadcast.
[00:11:07.360 --> 00:11:09.920]   I could view the rooms.
[00:11:09.920 --> 00:11:12.360]   This one's in the shed.
[00:11:12.360 --> 00:11:15.720]   I thought that was funny.
[00:11:15.720 --> 00:11:21.880]   Anyway, I think this is actually a very nice device, especially at that price.
[00:11:21.880 --> 00:11:25.400]   I would say I'm going to get a couple more.
[00:11:25.400 --> 00:11:28.040]   I'm really pretty happy with it.
[00:11:28.040 --> 00:11:31.400]   I really love the photo frame.
[00:11:31.400 --> 00:11:32.600]   That's for me.
[00:11:32.600 --> 00:11:36.120]   This makes more sense if you've stored a lot of photos in Google Photos.
[00:11:36.120 --> 00:11:41.840]   If you've been using the face recognition, it really is fun because it goes back in time
[00:11:41.840 --> 00:11:45.800]   here's a picture from Hawaii from four or five years ago.
[00:11:45.800 --> 00:11:47.000]   It's just completely random.
[00:11:47.000 --> 00:11:48.000]   So I like that.
[00:11:48.000 --> 00:11:49.240]   It doesn't sound bad.
[00:11:49.240 --> 00:11:50.720]   We played some music.
[00:11:50.720 --> 00:11:53.760]   It's not horrible.
[00:11:53.760 --> 00:11:55.800]   It's better than one would expect for something this size.
[00:11:55.800 --> 00:11:58.200]   But of course, yeah, I'm sure the JBL will sound better.
[00:11:58.200 --> 00:11:59.440]   The Lenovo sounds pretty good too.
[00:11:59.440 --> 00:12:04.640]   I would say the Lenovo is not hugely better than this.
[00:12:04.640 --> 00:12:05.800]   I think the Lido was sounds bad.
[00:12:05.800 --> 00:12:07.400]   Of course, I'm not in the same room.
[00:12:07.400 --> 00:12:09.560]   Here's Henry at the prom.
[00:12:09.560 --> 00:12:11.720]   I would like it definitely bigger.
[00:12:11.720 --> 00:12:17.440]   I've been trying to actually have a computer dedicated server that just plays photos.
[00:12:17.440 --> 00:12:23.320]   I like them to be big so I can see example stuff.
[00:12:23.320 --> 00:12:26.760]   If you want really big, of course, if you've got a TV that's cast enabled, you can always
[00:12:26.760 --> 00:12:29.680]   just put it on TV, right?
[00:12:29.680 --> 00:12:32.200]   Let's get 70 inches of photos.
[00:12:32.200 --> 00:12:37.360]   Now before you rush out and buy one, Matthew, I will say I would be looking in a month.
[00:12:37.360 --> 00:12:40.760]   We're going to be actually less than a month now is going to be Black Friday.
[00:12:40.760 --> 00:12:44.560]   And if I don't see lots of hot Google deals, I'm going to be shocked.
[00:12:44.560 --> 00:12:51.440]   They already sold this Google home at a hundred bucks for eight hours online.
[00:12:51.440 --> 00:12:53.440]   So I wouldn't be surprised.
[00:12:53.440 --> 00:12:58.120]   I'll have a full review for you Saturday on the screen savers, but I got it this morning.
[00:12:58.120 --> 00:13:01.560]   But initially, my initial reaction is I'm pretty happy with this.
[00:13:01.560 --> 00:13:02.560]   I like it.
[00:13:02.560 --> 00:13:04.960]   But I like the Echo Show too.
[00:13:04.960 --> 00:13:05.960]   The new one?
[00:13:05.960 --> 00:13:07.600]   Well, I don't have the new one.
[00:13:07.600 --> 00:13:09.400]   I have the original one, which a lot of people need.
[00:13:09.400 --> 00:13:12.080]   The new one is very beautiful.
[00:13:12.080 --> 00:13:18.360]   And now that I've got the old one, but once I saw the new one, I was like, "Ooh, ooh."
[00:13:18.360 --> 00:13:20.800]   Old one, you're so dated and yucky.
[00:13:20.800 --> 00:13:22.880]   It already looks old, doesn't it?
[00:13:22.880 --> 00:13:23.880]   So gross.
[00:13:23.880 --> 00:13:24.880]   Now we come to the new one.
[00:13:24.880 --> 00:13:33.240]   Now we come to the Pixel 3.
[00:13:33.240 --> 00:13:38.120]   And I can't figure out if people are just being really nitpicky or if there are actually
[00:13:38.120 --> 00:13:41.680]   some significant issues of the Pixel 3.
[00:13:41.680 --> 00:13:43.800]   There's one that I have certainly experienced.
[00:13:43.800 --> 00:13:46.040]   And I think pretty much everyone's experiencing.
[00:13:46.040 --> 00:13:50.600]   If you're listening to music on the Pixel 3 and you launch the camera, the music stops,
[00:13:50.600 --> 00:13:56.920]   it has very aggressive background process killing.
[00:13:56.920 --> 00:13:59.160]   Some say it's because they only put 4GB of RAM in here.
[00:13:59.160 --> 00:14:00.160]   I don't believe that.
[00:14:00.160 --> 00:14:05.560]   I think it's either a bug or Google tuned it a little too aggressively.
[00:14:05.560 --> 00:14:08.480]   Remember in the early days of the iPhone, you couldn't run anything in the background
[00:14:08.480 --> 00:14:10.000]   except Apple's approved stuff.
[00:14:10.000 --> 00:14:12.560]   That was to improve battery life.
[00:14:12.560 --> 00:14:15.160]   Later Apple added background.
[00:14:15.160 --> 00:14:18.440]   Google's had it, Android's had it for some time.
[00:14:18.440 --> 00:14:22.520]   So it could very well just be an aggressive memory management technique.
[00:14:22.520 --> 00:14:27.400]   However, I was trying to play Pokemon Go the other day and every time I took a picture
[00:14:27.400 --> 00:14:30.840]   it restarted Pokemon Go, which was no good.
[00:14:30.840 --> 00:14:33.480]   And it's certainly no good if you're listening to a book or music and you want the music to
[00:14:33.480 --> 00:14:35.880]   continue while you take a picture or do something else.
[00:14:35.880 --> 00:14:40.400]   You can multitask, but it looks like two or three apps is the limit and some apps like
[00:14:40.400 --> 00:14:44.360]   the camera are so demanding that nothing can run in the background.
[00:14:44.360 --> 00:14:48.120]   Is that all the fancy computational tech or maybe?
[00:14:48.120 --> 00:14:49.120]   Sorry, Matthew?
[00:14:49.120 --> 00:14:52.640]   Sorry, so it literally shuts the app down like if there's something running.
[00:14:52.640 --> 00:14:53.800]   Yeah, I could show you.
[00:14:53.800 --> 00:14:54.800]   I can do it.
[00:14:54.800 --> 00:14:56.280]   I'll play some.
[00:14:56.280 --> 00:14:57.720]   This is from Google's own app.
[00:14:57.720 --> 00:14:59.240]   This is Google Play Music.
[00:14:59.240 --> 00:15:01.680]   Let me turn it up.
[00:15:01.680 --> 00:15:03.480]   That seems suboptimal.
[00:15:03.480 --> 00:15:04.480]   Yes.
[00:15:04.480 --> 00:15:05.480]   Okay.
[00:15:05.480 --> 00:15:08.600]   So I'm listening to some music on here.
[00:15:08.600 --> 00:15:11.480]   And as soon as I launch the camera.
[00:15:11.480 --> 00:15:15.480]   I did it just the other.
[00:15:15.480 --> 00:15:16.480]   So this is part of the promise.
[00:15:16.480 --> 00:15:17.480]   It doesn't do it all the time.
[00:15:17.480 --> 00:15:18.480]   It didn't do it this time.
[00:15:18.480 --> 00:15:19.480]   Oh, I see.
[00:15:19.480 --> 00:15:21.760]   Oh, but now it's gone.
[00:15:21.760 --> 00:15:23.800]   So runs out of RAM.
[00:15:23.800 --> 00:15:29.480]   Yeah, maybe a RAM issue for gigs is a lot, but maybe this to me, this feels like something
[00:15:29.480 --> 00:15:32.760]   they could fix pretty quickly and I imagine will.
[00:15:32.760 --> 00:15:33.760]   There's also issues.
[00:15:33.760 --> 00:15:36.360]   Some people have complained of the camera losing photos.
[00:15:36.360 --> 00:15:37.800]   You take a picture.
[00:15:37.800 --> 00:15:40.440]   It records it, but it doesn't save it.
[00:15:40.440 --> 00:15:41.440]   What?
[00:15:41.440 --> 00:15:42.880]   Yeah, that would be pretty bad.
[00:15:42.880 --> 00:15:45.720]   It has not happened to me.
[00:15:45.720 --> 00:15:49.480]   But that could be pretty upsetting.
[00:15:49.480 --> 00:15:55.760]   People complaining about the sound that the two speakers, and everybody hates this.
[00:15:55.760 --> 00:15:59.440]   Everybody, I don't hate it, but a lot of people hate this notch.
[00:15:59.440 --> 00:16:04.720]   But at least the excuse for the large notch is that you've got a speaker here.
[00:16:04.720 --> 00:16:10.360]   But the thing is it's a smaller speaker here than on the chin, which people also hate.
[00:16:10.360 --> 00:16:15.360]   And even though these are left-light-right speakers, one is louder than the other.
[00:16:15.360 --> 00:16:19.440]   And then somebody, I can't remember who maybe it was, Neelite Patel, put rice on his back
[00:16:19.440 --> 00:16:21.960]   of his pixel while it was playing music.
[00:16:21.960 --> 00:16:22.960]   There it is.
[00:16:22.960 --> 00:16:25.760]   Oh, Russell Holly did this.
[00:16:25.760 --> 00:16:28.240]   And there's so much bass that the rice is vibrating.
[00:16:28.240 --> 00:16:30.880]   Now, is that being nitpicky?
[00:16:30.880 --> 00:16:31.880]   A little bit.
[00:16:31.880 --> 00:16:32.880]   I think so.
[00:16:32.880 --> 00:16:35.960]   Hey, who's going to be eating rice off the back of their pixel?
[00:16:35.960 --> 00:16:40.480]   Well, no, that's just to illustrate the heavy bass phenomenon.
[00:16:40.480 --> 00:16:42.680]   Well, I want heavy bass.
[00:16:42.680 --> 00:16:44.680]   Got to have the bass.
[00:16:44.680 --> 00:16:49.320]   Well, I don't enjoy super overweighted bass, I'll be honest.
[00:16:49.320 --> 00:16:50.320]   It doesn't.
[00:16:50.320 --> 00:17:00.560]   And a lot of people boost their bass because their overall sound quality isn't great.
[00:17:00.560 --> 00:17:02.200]   And then you've got, I mean...
[00:17:02.200 --> 00:17:06.760]   I would agree, the sound, while the sound is very loud and Google made a lot of noise
[00:17:06.760 --> 00:17:10.920]   about that, so to speak.
[00:17:10.920 --> 00:17:16.600]   It's not great, it's not great sound, but I don't expect a phone to have great sound.
[00:17:16.600 --> 00:17:22.040]   Paul Throck says he was unhappy with it, it's not as good even as his Pixel 2 XL, so...
[00:17:22.040 --> 00:17:23.560]   Another thing to be aware of.
[00:17:23.560 --> 00:17:28.160]   Hey, but if the bass is strong enough to move the rice, then the haptic feedback on that
[00:17:28.160 --> 00:17:29.320]   thing must be awesome.
[00:17:29.320 --> 00:17:30.920]   Actually, it's surprising.
[00:17:30.920 --> 00:17:31.920]   It's not.
[00:17:31.920 --> 00:17:32.920]   It is fantastic.
[00:17:32.920 --> 00:17:35.880]   And that is the one thing everybody's very happy about.
[00:17:35.880 --> 00:17:36.880]   Hmm.
[00:17:36.880 --> 00:17:37.880]   There you go.
[00:17:37.880 --> 00:17:42.200]   Puses and minuses.
[00:17:42.200 --> 00:17:43.200]   I like it.
[00:17:43.200 --> 00:17:46.680]   The screen is great and the camera is amazing.
[00:17:46.680 --> 00:17:49.080]   We're just now getting an updated camera app.
[00:17:49.080 --> 00:17:53.200]   Doesn't yet have the night shot capability, but that seems to be just around the corner.
[00:17:53.200 --> 00:17:59.000]   Actually, the new version of the Google camera app was decompiled and people have found the
[00:17:59.000 --> 00:18:00.640]   night shot in there.
[00:18:00.640 --> 00:18:03.240]   There are APKs floating around with it on there.
[00:18:03.240 --> 00:18:04.240]   So it's...
[00:18:04.240 --> 00:18:06.080]   I'm very excited about that.
[00:18:06.080 --> 00:18:09.840]   It's a feature Google said will come out soon.
[00:18:09.840 --> 00:18:10.840]   It's an excellent camera.
[00:18:10.840 --> 00:18:14.040]   I'm very happy with the images.
[00:18:14.040 --> 00:18:15.040]   So...
[00:18:15.040 --> 00:18:16.040]   I don't know.
[00:18:16.040 --> 00:18:17.400]   I don't know what to say about this.
[00:18:17.400 --> 00:18:20.160]   I think those are definitely problems.
[00:18:20.160 --> 00:18:21.320]   There's no fun this perfect.
[00:18:21.320 --> 00:18:22.840]   Every phone has problems.
[00:18:22.840 --> 00:18:25.160]   I've been very happy with the Pixel 3.
[00:18:25.160 --> 00:18:27.920]   And I can live with the fact that it's closing out apps in the background.
[00:18:27.920 --> 00:18:29.080]   Presumably that'll be fixed.
[00:18:29.080 --> 00:18:31.400]   If it's not fixed, then it's an issue.
[00:18:31.400 --> 00:18:32.400]   Then I would agree with you.
[00:18:32.400 --> 00:18:33.680]   I thought I saw somebody...
[00:18:33.680 --> 00:18:36.400]   I was at an event and I saw it and it looked great.
[00:18:36.400 --> 00:18:37.400]   I mean, the screen looked amazing.
[00:18:37.400 --> 00:18:38.880]   It's very nice.
[00:18:38.880 --> 00:18:40.760]   Last year's screen was not so nice.
[00:18:40.760 --> 00:18:42.840]   That was a terrible OLED screen.
[00:18:42.840 --> 00:18:45.720]   Apparently, they're getting these from Samsung and Kriam Kevin Tofol.
[00:18:45.720 --> 00:18:46.720]   So that's good.
[00:18:46.720 --> 00:18:47.720]   Sorry?
[00:18:47.720 --> 00:18:54.120]   I thought I was looking for a new phone and I saw something that said the 2XL had a different
[00:18:54.120 --> 00:18:55.120]   screen.
[00:18:55.120 --> 00:18:56.120]   It did.
[00:18:56.120 --> 00:18:57.120]   It had the LG OLED screen.
[00:18:57.120 --> 00:18:58.120]   It was terrible.
[00:18:58.120 --> 00:19:00.040]   And it was not recommended.
[00:19:00.040 --> 00:19:01.040]   Not recommended.
[00:19:01.040 --> 00:19:02.360]   But the 3 is as good.
[00:19:02.360 --> 00:19:07.880]   It's a Samsung panel reportedly and I would say is as good as the iPhone or the Samsung
[00:19:07.880 --> 00:19:08.880]   phones.
[00:19:08.880 --> 00:19:10.880]   Very crisp, great color.
[00:19:10.880 --> 00:19:13.240]   I got a wild way in 20.
[00:19:13.240 --> 00:19:14.760]   The P20 is great.
[00:19:14.760 --> 00:19:16.480]   Are you happy?
[00:19:16.480 --> 00:19:17.480]   Very happy.
[00:19:17.480 --> 00:19:19.520]   The camera is amazing.
[00:19:19.520 --> 00:19:22.320]   It has not one, not two, but three cameras.
[00:19:22.320 --> 00:19:23.320]   Yeah.
[00:19:23.320 --> 00:19:30.040]   And it's the two big ones on the back are designed for low light and zoom.
[00:19:30.040 --> 00:19:32.320]   I mean, performance is incredible.
[00:19:32.320 --> 00:19:35.240]   I mean, it's really amazing.
[00:19:35.240 --> 00:19:37.680]   I have a copy of, I bought one too.
[00:19:37.680 --> 00:19:41.000]   And the thing that sent me off a little bit.
[00:19:41.000 --> 00:19:47.000]   Do you remember that when you set it up, Huawei asked for permission to look at everything
[00:19:47.000 --> 00:19:50.080]   on your phone and send it back to China?
[00:19:50.080 --> 00:19:51.080]   Yeah.
[00:19:51.080 --> 00:19:52.080]   Yeah.
[00:19:52.080 --> 00:19:54.280]   So I just said sure.
[00:19:54.280 --> 00:19:56.680]   Look about how you're wrong.
[00:19:56.680 --> 00:19:58.680]   You're not a Chinese dissident.
[00:19:58.680 --> 00:20:01.560]   That's like hello Chinese dissidents trying to contact it.
[00:20:01.560 --> 00:20:04.720]   That put me off a little bit.
[00:20:04.720 --> 00:20:07.320]   But other than that, it's a really nice phone.
[00:20:07.320 --> 00:20:09.560]   Yeah, it's a great phone.
[00:20:09.560 --> 00:20:13.560]   I'm really happy with it.
[00:20:13.560 --> 00:20:14.560]   Yeah.
[00:20:14.560 --> 00:20:19.760]   This sort of ties to this Pixel 3 charging story, which opened me into this crazy world
[00:20:19.760 --> 00:20:21.680]   of insider baseball on.
[00:20:21.680 --> 00:20:24.440]   She will wait.
[00:20:24.440 --> 00:20:27.920]   So did you read the update at the bottom?
[00:20:27.920 --> 00:20:34.640]   So it starts with Ars Technica saying DRM for chargers, Google Pixel 3 locks fast Qi
[00:20:34.640 --> 00:20:36.360]   charging to certified chargers.
[00:20:36.360 --> 00:20:41.320]   And in chiefly, their claim was that the fast 10 watt charging is only available if you
[00:20:41.320 --> 00:20:42.760]   have a Pixel stand.
[00:20:42.760 --> 00:20:49.240]   Google's response, the Pixel 3 does not support 10 watt Qi charging at all.
[00:20:49.240 --> 00:20:53.120]   It supports 10 watt wireless charging.
[00:20:53.120 --> 00:20:55.320]   And it supports the Qi wireless charging standard.
[00:20:55.320 --> 00:20:56.920]   But these are two different things.
[00:20:56.920 --> 00:20:59.720]   Qi is capped at five watts.
[00:20:59.720 --> 00:21:03.800]   For 10 watt wireless charging, you need to charge her with what Belkin calls Google's
[00:21:03.800 --> 00:21:08.000]   10 watt proprietary wireless charging technology.
[00:21:08.000 --> 00:21:12.640]   So that does make kind of make sense that, yeah, this is what I mean.
[00:21:12.640 --> 00:21:15.880]   Sometimes I think the fan boys jump on these things.
[00:21:15.880 --> 00:21:17.960]   At all I rate, I blame Twitter.
[00:21:17.960 --> 00:21:19.480]   A few minutes of conspiracy.
[00:21:19.480 --> 00:21:20.480]   Yeah.
[00:21:20.480 --> 00:21:25.760]   The facts come out that actually you can't get a 10 watt Qi charger.
[00:21:25.760 --> 00:21:27.920]   It wouldn't be Qi.
[00:21:27.920 --> 00:21:28.920]   Exactly.
[00:21:28.920 --> 00:21:36.240]   Well, and I do think Qualcomm has pushed this with its whole rapid something, something
[00:21:36.240 --> 00:21:37.440]   charging.
[00:21:37.440 --> 00:21:43.360]   So chip vendors are constantly doing this to differentiate with their products, right?
[00:21:43.360 --> 00:21:49.600]   And the idea that Google or Apple or any like you would do this to boost your own product,
[00:21:49.600 --> 00:21:50.800]   that totally makes sense.
[00:21:50.800 --> 00:21:52.320]   But it is kind of frustrating for a user.
[00:21:52.320 --> 00:21:55.920]   Well, but they do allow, for instance, the Belkin charger to do 10 watts.
[00:21:55.920 --> 00:21:57.280]   So it's not just Google.
[00:21:57.280 --> 00:22:03.120]   Well, it's more the idea that now if I'm buying a phone and I want rapid charging, I
[00:22:03.120 --> 00:22:04.880]   don't buy Qi.
[00:22:04.880 --> 00:22:05.880]   That's not the one.
[00:22:05.880 --> 00:22:06.880]   Right.
[00:22:06.880 --> 00:22:08.320]   So all of my standardized stuff doesn't work.
[00:22:08.320 --> 00:22:10.000]   I have to go buy something different.
[00:22:10.000 --> 00:22:12.040]   That's a failing of the Qi standard though, right?
[00:22:12.040 --> 00:22:13.040]   Yeah.
[00:22:13.040 --> 00:22:14.040]   Or give it.
[00:22:14.040 --> 00:22:18.800]   I mean, yes, they are working on higher wattage standards.
[00:22:18.800 --> 00:22:19.800]   But yes.
[00:22:19.800 --> 00:22:27.360]   So I have the Samsung fast charger for my note nine and it does charge fast.
[00:22:27.360 --> 00:22:28.680]   And it works with everything else.
[00:22:28.680 --> 00:22:32.880]   It works with the iPhone and it seems to charge pretty quickly both the iPhone and the Pixel
[00:22:32.880 --> 00:22:34.920]   three.
[00:22:34.920 --> 00:22:39.120]   That's a 15 watt charger, but obviously it's not a Qi charger.
[00:22:39.120 --> 00:22:43.440]   So she is the she is like the lowest common.
[00:22:43.440 --> 00:22:46.840]   The lowest common denominator exactly.
[00:22:46.840 --> 00:22:49.880]   Well, and she has several denominators.
[00:22:49.880 --> 00:22:51.080]   It's worth noting their work.
[00:22:51.080 --> 00:22:52.360]   They've got the phone stuff.
[00:22:52.360 --> 00:22:56.360]   They've got a big massive wattage for charging electric vehicles.
[00:22:56.360 --> 00:23:01.280]   And then they've got another group working on like kitchen standards and that would charge
[00:23:01.280 --> 00:23:03.000]   my phone pretty fast.
[00:23:03.000 --> 00:23:06.800]   Yeah, that would blow your phone out of the water.
[00:23:06.800 --> 00:23:12.320]   It would make rice dance on the back of it.
[00:23:12.320 --> 00:23:13.320]   That's for sure.
[00:23:13.320 --> 00:23:14.840]   I was going to say, have you ever put your phone in a microwave?
[00:23:14.840 --> 00:23:18.800]   Because that's what it would be like.
[00:23:18.800 --> 00:23:24.880]   Article and Wired about the secure enclave, the hardware chip in the Pixel three, the
[00:23:24.880 --> 00:23:31.320]   Titan M, which I didn't realize is based on the big, big boy Titan that is in Google
[00:23:31.320 --> 00:23:32.800]   servers.
[00:23:32.800 --> 00:23:34.720]   And it is a secure enclave.
[00:23:34.720 --> 00:23:36.400]   There it is right there.
[00:23:36.400 --> 00:23:40.240]   Physically separated from the chip, which is actually a little different from the way
[00:23:40.240 --> 00:23:46.160]   where the secure enclave works on Apple's iOS devices, their secure enclave is on the
[00:23:46.160 --> 00:23:49.600]   die for the CPU.
[00:23:49.600 --> 00:23:56.840]   And Google says by isolating the Titan M completely, moving it off the dip.
[00:23:56.840 --> 00:23:57.840]   That's smart.
[00:23:57.840 --> 00:24:02.360]   You get, you get, he says everything that lives in the main processor, including Apple's
[00:24:02.360 --> 00:24:08.320]   Enclave is sharing cash and RAM for the most part in order to use it to protect keys.
[00:24:08.320 --> 00:24:11.160]   It's a reasonable thing to do, but you know, there's still going to be the risks of things
[00:24:11.160 --> 00:24:14.440]   like Spectre, Meltdown, and Rohammer.
[00:24:14.440 --> 00:24:17.760]   This is Will Dury, who's a principal software engineer at Google.
[00:24:17.760 --> 00:24:20.000]   Yeah, if they're combined, it's easier to...
[00:24:20.000 --> 00:24:23.920]   So we move the key matter to tamper resistant hardware that has its own private storage,
[00:24:23.920 --> 00:24:26.760]   its own private RAM, its own private processing.
[00:24:26.760 --> 00:24:27.760]   Yes.
[00:24:27.760 --> 00:24:32.880]   So that's a super common design, but I will say when you integrate it on chip, one of
[00:24:32.880 --> 00:24:36.720]   the reasons you do it is to save space, it also to save on costs.
[00:24:36.720 --> 00:24:37.720]   Yes.
[00:24:37.720 --> 00:24:42.080]   I just want to point out that because a lot of times we don't discuss the trade-offs
[00:24:42.080 --> 00:24:43.760]   there and it's worth discussing.
[00:24:43.760 --> 00:24:45.840]   Everything's a trade-off, yeah.
[00:24:45.840 --> 00:24:52.760]   My phone has a secure enclave, but it's located in Shanghai.
[00:24:52.760 --> 00:24:57.400]   We'll take good care of your data here at Huawei in Shanghai.
[00:24:57.400 --> 00:25:02.440]   It's a secure, I can't get it.
[00:25:02.440 --> 00:25:06.160]   We actually had a long and I thought a fruitful conversation on Windows Weekly today about
[00:25:06.160 --> 00:25:13.120]   exactly that because Tim Cook, the CEO of Apple, spoke yesterday in front of a European
[00:25:13.120 --> 00:25:14.120]   privacy commission.
[00:25:14.120 --> 00:25:17.440]   He was quite heated.
[00:25:17.440 --> 00:25:21.040]   He was clearly targeting Google and Facebook.
[00:25:21.040 --> 00:25:24.720]   No question in my mind, he didn't mention them by name, but saying...
[00:25:24.720 --> 00:25:26.880]   Yeah, I don't think he was talking about them.
[00:25:26.880 --> 00:25:27.880]   No.
[00:25:27.880 --> 00:25:29.640]   I think he was talking about two other large...
[00:25:29.640 --> 00:25:32.640]   Okay, so wait, wait, y'all, because I...
[00:25:32.640 --> 00:25:33.640]   Strong feelings on this.
[00:25:33.640 --> 00:25:35.600]   I think it's actually really good that he did this.
[00:25:35.600 --> 00:25:37.800]   Yes, he's talking about Google and Facebook.
[00:25:37.800 --> 00:25:41.640]   He calls him the Data Industrial Complex.
[00:25:41.640 --> 00:25:45.240]   But actually, everyone wants to be like them.
[00:25:45.240 --> 00:25:48.680]   So he's also making a really important point.
[00:25:48.680 --> 00:25:53.560]   We talk about it on this week's show, but I don't know if you saw the story about GM
[00:25:53.560 --> 00:25:59.400]   listening in on the radio signals from their cars last year.
[00:25:59.400 --> 00:26:02.560]   So this came out and if you Google like GM...
[00:26:02.560 --> 00:26:03.560]   I don't know.
[00:26:03.560 --> 00:26:06.360]   Is there on-star technology to do that probably?
[00:26:06.360 --> 00:26:07.360]   They did.
[00:26:07.360 --> 00:26:11.520]   And they pulled this data and there was a quote from one of their executives.
[00:26:11.520 --> 00:26:15.400]   And he's like, he talks about why they were doing this and playing this.
[00:26:15.400 --> 00:26:17.400]   He's like, because we could.
[00:26:17.400 --> 00:26:20.920]   Which I don't know about you, but hey, that's freaky as all get out.
[00:26:20.920 --> 00:26:22.920]   We know TVs do it.
[00:26:22.920 --> 00:26:25.960]   We know this is not unusual.
[00:26:25.960 --> 00:26:27.560]   In fact, that's what Cook said.
[00:26:27.560 --> 00:26:31.800]   He said, basically we're in a surveillance state.
[00:26:31.800 --> 00:26:39.640]   But I guess the question I would ask you and this question I asked Paul is, where do you
[00:26:39.640 --> 00:26:40.640]   draw the line?
[00:26:40.640 --> 00:26:42.680]   I mean, Google is a free server.
[00:26:42.680 --> 00:26:45.440]   GAPL does not give it stuff away.
[00:26:45.440 --> 00:26:48.440]   But Google and Facebook and others are free services.
[00:26:48.440 --> 00:26:52.800]   Not GM either, but let's stick with Google and Facebook then.
[00:26:52.800 --> 00:26:57.240]   And the way they monetize their services by selling advertising, the way they make money
[00:26:57.240 --> 00:27:02.440]   and advertising is by selling targeted advertising using information.
[00:27:02.440 --> 00:27:03.680]   They claim is anonymized.
[00:27:03.680 --> 00:27:05.720]   Actually Google, I think, does anonymize it.
[00:27:05.720 --> 00:27:08.120]   Facebook pretty obviously doesn't.
[00:27:08.120 --> 00:27:10.880]   Well, and let's be clear, users buy into that, right?
[00:27:10.880 --> 00:27:13.320]   Users effectively know that that's occurring.
[00:27:13.320 --> 00:27:15.080]   Well, that's the question.
[00:27:15.080 --> 00:27:17.920]   How much do users know, right?
[00:27:17.920 --> 00:27:18.920]   That is a good question.
[00:27:18.920 --> 00:27:20.720]   And how much do they care?
[00:27:20.720 --> 00:27:23.400]   I don't think it's how much do they know and how much do they care.
[00:27:23.400 --> 00:27:31.200]   I think it is a, we have to come to a consensus as a society on what data should be protected
[00:27:31.200 --> 00:27:32.480]   and how we should use it.
[00:27:32.480 --> 00:27:36.960]   So I know that Facebook is using my data and I don't get enough value from Facebook.
[00:27:36.960 --> 00:27:37.960]   So I'm like, screw it.
[00:27:37.960 --> 00:27:38.960]   I'm just not going to be on there.
[00:27:38.960 --> 00:27:42.000]   But there are plenty of people who get lots of value from Facebook.
[00:27:42.000 --> 00:27:48.040]   And if they had the option to have better controls over what data went where, I think
[00:27:48.040 --> 00:27:50.720]   some of them, not all of them, but some of them would take it.
[00:27:50.720 --> 00:27:54.960]   And I think denying people that and just shrugging it off and saying it's because they don't
[00:27:54.960 --> 00:27:58.840]   care, I don't think that's a really nuanced conversation.
[00:27:58.840 --> 00:28:02.280]   It doesn't further better privacy than all of them.
[00:28:02.280 --> 00:28:07.560]   No, I completely agree that there should be, in particular, Facebook and Google should
[00:28:07.560 --> 00:28:13.760]   make Facebook in particular, should make it easier to control your data in a more granular
[00:28:13.760 --> 00:28:17.480]   way and even to take it with you if you want or to.
[00:28:17.480 --> 00:28:23.040]   And I think if there is one place that legislation could look at, it would be that.
[00:28:23.040 --> 00:28:25.200]   It would be transparency around that.
[00:28:25.200 --> 00:28:30.720]   And it would be more information and more sort of ability users could have around that.
[00:28:30.720 --> 00:28:35.560]   But I just wanted to ask this one question.
[00:28:35.560 --> 00:28:37.440]   Is it okay with you?
[00:28:37.440 --> 00:28:43.960]   And as long as it's explicit and everybody knows, to get free services like Facebook
[00:28:43.960 --> 00:28:52.640]   or Google or Twitter, because the way it's paid for is with targeted ads, if they stopped
[00:28:52.640 --> 00:28:57.400]   at that, in other words, they use the information they gather about you to target ads, which
[00:28:57.400 --> 00:28:59.880]   is highly lucrative for them.
[00:28:59.880 --> 00:29:01.840]   Would that be okay?
[00:29:01.840 --> 00:29:02.840]   As long as you-
[00:29:02.840 --> 00:29:04.080]   It's fine with me.
[00:29:04.080 --> 00:29:05.080]   Stacey?
[00:29:05.080 --> 00:29:07.480]   I mean, that's the deal I've got into.
[00:29:07.480 --> 00:29:09.080]   Yeah, I doesn't bother me either.
[00:29:09.080 --> 00:29:10.440]   In fact, I'd prefer targeted ads.
[00:29:10.440 --> 00:29:12.040]   I know what I'm doing.
[00:29:12.040 --> 00:29:14.360]   Yes, but here's the deal.
[00:29:14.360 --> 00:29:19.160]   As we move the computing to everything else, it becomes really interesting to see.
[00:29:19.160 --> 00:29:22.080]   It's one thing to get a targeted ad when I'm surfing the internet.
[00:29:22.080 --> 00:29:28.040]   It's another thing to get a targeted ad in my home on my, I don't know, television that
[00:29:28.040 --> 00:29:35.120]   I'm watching with my new boyfriend or on a billboard because I'm walking by.
[00:29:35.120 --> 00:29:36.560]   This is all theoretical.
[00:29:36.560 --> 00:29:39.240]   I make them silly so you can see that it's theoretical.
[00:29:39.240 --> 00:29:43.680]   I agree with you, GM snooping on what radio stations I'm listening to and selling that
[00:29:43.680 --> 00:29:47.760]   date off without my knowledge, maybe with my permission in the fine print, but without
[00:29:47.760 --> 00:29:49.440]   my knowledge, is wrong.
[00:29:49.440 --> 00:29:50.440]   That's wrong.
[00:29:50.440 --> 00:29:51.440]   Right.
[00:29:51.440 --> 00:29:52.440]   I'm not-
[00:29:52.440 --> 00:29:53.960]   Because they're making money on the car.
[00:29:53.960 --> 00:29:57.040]   Similarly, Apple's making money on the hardware.
[00:29:57.040 --> 00:30:01.240]   But if I'm getting a free service, ad supported service, I don't know if that's wrong.
[00:30:01.240 --> 00:30:02.240]   Okay, I don't see one deal.
[00:30:02.240 --> 00:30:03.240]   But listen to this.
[00:30:03.240 --> 00:30:04.920]   It's being such a big deal.
[00:30:04.920 --> 00:30:05.920]   Maybe I'm totally-
[00:30:05.920 --> 00:30:06.920]   I think it's-
[00:30:06.920 --> 00:30:09.000]   I don't care if they're looking for it.
[00:30:09.000 --> 00:30:12.760]   They look at what radio stations I'm listening to or songs I'm listening to.
[00:30:12.760 --> 00:30:16.080]   You clearly do not have the All-Britain E Spears channel.
[00:30:16.080 --> 00:30:17.080]   What the heck, Matthew?
[00:30:17.080 --> 00:30:18.080]   What's going to-
[00:30:18.080 --> 00:30:19.080]   No.
[00:30:19.080 --> 00:30:20.080]   So why?
[00:30:20.080 --> 00:30:21.080]   It's-
[00:30:21.080 --> 00:30:22.080]   Something-
[00:30:22.080 --> 00:30:23.080]   Something-
[00:30:23.080 --> 00:30:24.080]   I don't care about it.
[00:30:24.080 --> 00:30:25.080]   I don't-
[00:30:25.080 --> 00:30:26.080]   It doesn't bother me.
[00:30:26.080 --> 00:30:27.080]   So that's it.
[00:30:27.080 --> 00:30:29.000]   You're going a little farther than I was willing to go.
[00:30:29.000 --> 00:30:31.240]   And they were looking at where you were listening to it.
[00:30:31.240 --> 00:30:33.600]   They were looking at what vehicle you drove.
[00:30:33.600 --> 00:30:35.400]   All of that would freak me out.
[00:30:35.400 --> 00:30:36.400]   Totally.
[00:30:36.400 --> 00:30:38.560]   And I would say a couple things.
[00:30:38.560 --> 00:30:43.240]   Then in a few years, you're not going to be able to buy an unconnected product, for
[00:30:43.240 --> 00:30:46.480]   example, in your appliances.
[00:30:46.480 --> 00:30:54.560]   So GM, GM, sorry, Ken Moore and GE appliances, they've both said that they're not going to
[00:30:54.560 --> 00:30:57.400]   make non-connected products.
[00:30:57.400 --> 00:31:00.640]   So when you start thinking about these things are going to come, connectivity is going to
[00:31:00.640 --> 00:31:06.920]   be coming by default to a lot of these, then you realize you can't opt out of this world.
[00:31:06.920 --> 00:31:11.120]   So we have to start making these rules and having these conversations now.
[00:31:11.120 --> 00:31:12.120]   And-
[00:31:12.120 --> 00:31:13.120]   I don't know.
[00:31:13.120 --> 00:31:15.120]   Matthew, you may be like, "Yeah, I don't care if you know-
[00:31:15.120 --> 00:31:16.120]   Yeah, I know you're right.
[00:31:16.120 --> 00:31:17.120]   I'm so slippery.
[00:31:17.120 --> 00:31:18.120]   I'm so slippery.
[00:31:18.120 --> 00:31:19.120]   I'm so slippery.
[00:31:19.120 --> 00:31:20.120]   And I'm so slippery.
[00:31:20.120 --> 00:31:20.720]   And maybe I don't care about the songs on my radio, but you're right.
[00:31:20.720 --> 00:31:23.720]   Everything is going to include sort of data harvesting-
[00:31:23.720 --> 00:31:25.320]   And some people do care.
[00:31:25.320 --> 00:31:26.320]   There's a-
[00:31:26.320 --> 00:31:28.200]   So there's clearly a spectrum of care.
[00:31:28.200 --> 00:31:29.200]   Right.
[00:31:29.200 --> 00:31:32.240]   Some people, for instance, somebody in the chat was saying, "Well Leo, you have ads.
[00:31:32.240 --> 00:31:36.640]   Yeah, but we don't collect information about you before those ads."
[00:31:36.640 --> 00:31:39.160]   So there are some people who say, "No ad is okay.
[00:31:39.160 --> 00:31:42.360]   I want a free service and I don't want you to monetize it."
[00:31:42.360 --> 00:31:43.360]   That's one extreme.
[00:31:43.360 --> 00:31:48.360]   There's some people that say, "No data collection is okay at all."
[00:31:48.360 --> 00:31:49.440]   That's another extreme.
[00:31:49.440 --> 00:31:53.280]   And people generally fall between those in some way.
[00:31:53.280 --> 00:31:56.280]   Like, "Well, you could collect data, but you can only use it exactly this way."
[00:31:56.280 --> 00:31:59.720]   I'm of the opinion, for instance, as long as you're explicit-
[00:31:59.720 --> 00:32:01.280]   This is what GM did wrong.
[00:32:01.280 --> 00:32:04.200]   They didn't tell people and as long as they have an opt out-
[00:32:04.200 --> 00:32:05.200]   Right.
[00:32:05.200 --> 00:32:06.200]   And maybe the opt out has a trade out.
[00:32:06.200 --> 00:32:08.960]   Maybe, well, if you don't want to see ads, you can't use Facebook.
[00:32:08.960 --> 00:32:10.720]   That's the trade off.
[00:32:10.720 --> 00:32:13.000]   But that's got to be explicit and you have to have the choice.
[00:32:13.000 --> 00:32:14.560]   I have to be informed.
[00:32:14.560 --> 00:32:20.080]   It has to be informed and sent, which is what GM didn't do.
[00:32:20.080 --> 00:32:21.920]   And I should have the right to say no to that.
[00:32:21.920 --> 00:32:23.320]   And as long as I have that-
[00:32:23.320 --> 00:32:27.840]   And I will say yes, in my case, too, "Yeah, you can collect data about me to target ads.
[00:32:27.840 --> 00:32:29.120]   You can't sell it to the government.
[00:32:29.120 --> 00:32:32.280]   You can't sell individual information about me to anybody.
[00:32:32.280 --> 00:32:38.360]   If somebody says, "Hey, I want to know what Leo's blood type is, you can't give them that."
[00:32:38.360 --> 00:32:39.840]   That's what I mean about granularity.
[00:32:39.840 --> 00:32:45.080]   It'd be easier to be better to have a bit more control rather than just sign here to give
[00:32:45.080 --> 00:32:48.040]   away all your data so that we can do whatever we want with it.
[00:32:48.040 --> 00:32:50.600]   And we're not going to let you know what that is.
[00:32:50.600 --> 00:32:56.440]   And it may be the Kenmore sales refrigerators that must be connected to work.
[00:32:56.440 --> 00:32:58.920]   If that's the case, wow.
[00:32:58.920 --> 00:33:04.360]   I mean, if you get a benefit from connecting a refrigerator, but you don't have to for
[00:33:04.360 --> 00:33:08.960]   it to cool food, then that may be a fair trade-off, right?
[00:33:08.960 --> 00:33:12.960]   And I should point out that I don't care.
[00:33:12.960 --> 00:33:16.200]   I don't care about lots of things that I probably should care about.
[00:33:16.200 --> 00:33:17.200]   So taking my life-
[00:33:17.200 --> 00:33:19.040]   He's pretty apathetic, folks.
[00:33:19.040 --> 00:33:21.040]   He's just completely scared of life.
[00:33:21.040 --> 00:33:24.280]   He's Canadian enough of the fear.
[00:33:24.280 --> 00:33:27.880]   I'm reminded by my wife all the time that there are things I should care about and I
[00:33:27.880 --> 00:33:29.200]   don't care about.
[00:33:29.200 --> 00:33:32.440]   And I realize there's a problem.
[00:33:32.440 --> 00:33:34.000]   I'm kind of like you, Matthew.
[00:33:34.000 --> 00:33:37.520]   I don't give a damn about anything at all.
[00:33:37.520 --> 00:33:39.280]   It comes with age, I think.
[00:33:39.280 --> 00:33:40.280]   Here's what-
[00:33:40.280 --> 00:33:43.320]   I think it comes with privilege, you guys.
[00:33:43.320 --> 00:33:44.320]   Oh, privilege.
[00:33:44.320 --> 00:33:45.320]   We're white guys.
[00:33:45.320 --> 00:33:46.320]   You're right.
[00:33:46.320 --> 00:33:47.320]   That's fair.
[00:33:47.320 --> 00:33:48.320]   That's totally fair.
[00:33:48.320 --> 00:33:49.320]   That's strictly true.
[00:33:49.320 --> 00:33:50.320]   That's exactly right.
[00:33:50.320 --> 00:33:51.320]   It comes with privilege.
[00:33:51.320 --> 00:33:52.320]   It was a new city.
[00:33:52.320 --> 00:33:54.320]   You don't have any privacy and you should probably get used to it.
[00:33:54.320 --> 00:33:56.320]   That was like 12 years ago.
[00:33:56.320 --> 00:33:57.320]   It's got me dealing.
[00:33:57.320 --> 00:33:58.320]   Yeah, it's got me dealing.
[00:33:58.320 --> 00:33:59.320]   Speaking of privilege.
[00:33:59.320 --> 00:34:02.600]   Well, he's pretty privileged.
[00:34:02.600 --> 00:34:03.600]   Here's what Cook said.
[00:34:03.600 --> 00:34:05.000]   He's also privileged.
[00:34:05.000 --> 00:34:09.240]   Our own information from the everyday to the deeply personal is being weaponized against
[00:34:09.240 --> 00:34:11.800]   us with military efficiency.
[00:34:11.800 --> 00:34:17.080]   These scraps of data, each one harmless enough on its own, are carefully assembled, synthesized,
[00:34:17.080 --> 00:34:18.880]   traded, and sold.
[00:34:18.880 --> 00:34:23.960]   Taken to this extreme, this process creates an enduring digital profile and lets companies
[00:34:23.960 --> 00:34:25.920]   know you better than you may know yourself.
[00:34:25.920 --> 00:34:30.760]   The profile is a bunch of algorithms that serve up increasingly extreme content.
[00:34:30.760 --> 00:34:33.360]   That's something I'd worry about and we see that at YouTube.
[00:34:33.360 --> 00:34:35.360]   That's what he's talking about, obviously.
[00:34:35.360 --> 00:34:38.600]   Pounding our harmless preferences into harm.
[00:34:38.600 --> 00:34:40.640]   We shouldn't sugarcoat the consequences.
[00:34:40.640 --> 00:34:43.000]   This is surveillance.
[00:34:43.000 --> 00:34:46.080]   He's calling for federal regulation.
[00:34:46.080 --> 00:34:47.560]   But by the way, so is Google.
[00:34:47.560 --> 00:34:52.720]   So is Mark Zuckerberg at Facebook because I think these tech giants all realize, well,
[00:34:52.720 --> 00:34:53.720]   we need a national law because-
[00:34:53.720 --> 00:34:54.720]   I know it's going to happen.
[00:34:54.720 --> 00:34:55.960]   Sure, it's going to happen.
[00:34:55.960 --> 00:34:56.960]   So they have to do it.
[00:34:56.960 --> 00:34:57.960]   And they'd rather do it.
[00:34:57.960 --> 00:34:58.960]   And they'd rather do it.
[00:34:58.960 --> 00:35:00.800]   And they'd rather get out of front of it.
[00:35:00.800 --> 00:35:01.800]   Yeah.
[00:35:01.800 --> 00:35:02.800]   To the extent possible.
[00:35:02.800 --> 00:35:05.920]   I would say he's also probably talking a little bit about the data brokers.
[00:35:05.920 --> 00:35:08.360]   I mean, he's not a dumb man.
[00:35:08.360 --> 00:35:12.920]   And those guys are- I think they're actually worse.
[00:35:12.920 --> 00:35:15.520]   I think they- I think in some cases- They- They- They- They sometimes are.
[00:35:15.520 --> 00:35:18.160]   Because they're less transparent if that's possible.
[00:35:18.160 --> 00:35:22.440]   And they merge all kinds of databases that people don't even realize exists.
[00:35:22.440 --> 00:35:23.440]   Right.
[00:35:23.440 --> 00:35:28.080]   Well, that's- I think that's- Tim does nail it there where he's saying each piece by itself
[00:35:28.080 --> 00:35:29.080]   is innocuous enough.
[00:35:29.080 --> 00:35:33.600]   But when you aggregate them, you can create something that is pretty dangerous.
[00:35:33.600 --> 00:35:38.280]   He also says AI is going to make this worse.
[00:35:38.280 --> 00:35:42.720]   He says for artificial intelligence to be truly smart, it must respect human values,
[00:35:42.720 --> 00:35:43.720]   including privacy.
[00:35:43.720 --> 00:35:46.800]   If we get this wrong, the dangers are profound.
[00:35:46.800 --> 00:35:52.920]   We can achieve both great artificial intelligence and great privacy standards.
[00:35:52.920 --> 00:35:57.440]   But it's not only a possibility, it's a responsibility.
[00:35:57.440 --> 00:35:58.440]   I- I- You know what?
[00:35:58.440 --> 00:35:59.440]   I agree with him.
[00:35:59.440 --> 00:36:01.680]   It- Of course, is directly aimed at Google.
[00:36:01.680 --> 00:36:04.680]   And I guess you could be a cynic and say, "Well, yes, since Apple doesn't have that
[00:36:04.680 --> 00:36:09.080]   information, they don't want AI to be- to be able to use that information because that
[00:36:09.080 --> 00:36:12.440]   would give Google an unassailable advantage."
[00:36:12.440 --> 00:36:17.040]   I was going to say it's easy in some ways for Apple to make that argument because-
[00:36:17.040 --> 00:36:18.640]   They don't do it.
[00:36:18.640 --> 00:36:19.640]   They don't do it.
[00:36:19.640 --> 00:36:20.640]   And they don't really need it.
[00:36:20.640 --> 00:36:21.640]   They can sell phones for-
[00:36:21.640 --> 00:36:22.640]   Right.
[00:36:22.640 --> 00:36:25.160]   And make billions of dollars.
[00:36:25.160 --> 00:36:32.080]   So- And they don't provide- Like Apple fans are going to get mad, but I think Apple is
[00:36:32.080 --> 00:36:34.840]   terrible at most services.
[00:36:34.840 --> 00:36:40.920]   And that a little bit of user data would probably help things get better.
[00:36:40.920 --> 00:36:43.640]   At least data about the way people use their stuff and-
[00:36:43.640 --> 00:36:44.640]   Yeah.
[00:36:44.640 --> 00:36:45.640]   Or don't.
[00:36:45.640 --> 00:36:46.640]   Or don't.
[00:36:46.640 --> 00:36:47.640]   Yeah.
[00:36:47.640 --> 00:36:53.360]   Well, clearly Apple- I mean, GM makes plenty of money selling cars, but they wanted to
[00:36:53.360 --> 00:36:55.120]   make a little more money.
[00:36:55.120 --> 00:36:57.880]   And clearly Apple could do the same thing.
[00:36:57.880 --> 00:37:01.440]   You know, there is strong incentive on every company to make more money, even if you're
[00:37:01.440 --> 00:37:03.240]   making a lot of money.
[00:37:03.240 --> 00:37:05.880]   But I like hearing him say no.
[00:37:05.880 --> 00:37:11.640]   He says GDPR has shown us all that good policy and political will can come together to protect
[00:37:11.640 --> 00:37:13.880]   the rights of everyone.
[00:37:13.880 --> 00:37:17.600]   He tweeted this- Well, early this morning, we believe privacy is a fundamental human
[00:37:17.600 --> 00:37:18.600]   right.
[00:37:18.600 --> 00:37:23.640]   No matter what country you live in, that right should be protected and keeping with four
[00:37:23.640 --> 00:37:26.480]   essential principles data minimum.
[00:37:26.480 --> 00:37:30.000]   This is, by the way, cribs straight from GDPR.
[00:37:30.000 --> 00:37:34.400]   Data minimization, transparency, the right to access and the right to security.
[00:37:34.400 --> 00:37:36.400]   GDPR is hugely problematic.
[00:37:36.400 --> 00:37:41.680]   I mean, it's not like it's the best privacy legislation ever devised.
[00:37:41.680 --> 00:37:45.560]   It has all kinds of unanticipated consequences, I think.
[00:37:45.560 --> 00:37:47.560]   I'm not sure we should- It has.
[00:37:47.560 --> 00:37:49.800]   That's the gold standard we should be.
[00:37:49.800 --> 00:37:52.400]   I would say it has a potential for harm.
[00:37:52.400 --> 00:37:58.640]   And what the EU commissioner said is, but we won't go there.
[00:37:58.640 --> 00:38:00.840]   We'll use it with a light touch.
[00:38:00.840 --> 00:38:01.840]   We'll use it appropriately.
[00:38:01.840 --> 00:38:08.800]   But anytime a law gives lawmakers a tool that could be harmful, that's to me harmful
[00:38:08.800 --> 00:38:10.440]   in and of itself.
[00:38:10.440 --> 00:38:13.520]   However, it hasn't been misused to this point.
[00:38:13.520 --> 00:38:14.520]   I don't think.
[00:38:14.520 --> 00:38:17.240]   It's only a few months old.
[00:38:17.240 --> 00:38:20.680]   Yeah, it's going to take us a year or two.
[00:38:20.680 --> 00:38:24.760]   And it leads us to the trend is toward things like the right to be forgotten, which is a
[00:38:24.760 --> 00:38:25.760]   huge minefield.
[00:38:25.760 --> 00:38:26.760]   Yeah.
[00:38:26.760 --> 00:38:27.760]   Yeah, it's terrible.
[00:38:27.760 --> 00:38:28.760]   Yeah.
[00:38:28.760 --> 00:38:29.760]   Go ahead.
[00:38:29.760 --> 00:38:30.760]   Sorry, Stacy.
[00:38:30.760 --> 00:38:32.760]   Oh, that's okay.
[00:38:32.760 --> 00:38:35.960]   I like, I like, dumped over my microphone.
[00:38:35.960 --> 00:38:40.480]   So I'm like sitting here going, "Oh, hey, you may have already talked about this."
[00:38:40.480 --> 00:38:47.120]   Which is, look, I think we're going to have to find a balance between- It is possible
[00:38:47.120 --> 00:38:53.240]   for us, given compute power, given social media and everything that we have to know
[00:38:53.240 --> 00:38:59.080]   just about everything about everyone and how it's tracked forever or somewhere, right?
[00:38:59.080 --> 00:39:02.440]   And that is historically something that we really haven't had.
[00:39:02.440 --> 00:39:06.800]   I mean, I guess we've had it in small towns back in the day where, you know, your family
[00:39:06.800 --> 00:39:12.760]   was- You could have that kind of tamed from your family forever.
[00:39:12.760 --> 00:39:14.720]   Or in East Germany.
[00:39:14.720 --> 00:39:15.720]   Or in East Germany.
[00:39:15.720 --> 00:39:20.760]   But, you know, you could always move, which is a big deal, but still possible.
[00:39:20.760 --> 00:39:22.560]   Now you're not going to be able to ever escape that.
[00:39:22.560 --> 00:39:27.560]   And so we're coming from this era of, "Ah, it's really impossible to know anything about
[00:39:27.560 --> 00:39:28.560]   anybody, too.
[00:39:28.560 --> 00:39:30.720]   It's possible to know everything about everybody."
[00:39:30.720 --> 00:39:35.560]   And we've got to figure out the median between like how we want to handle that.
[00:39:35.560 --> 00:39:36.560]   I just think it's weird.
[00:39:36.560 --> 00:39:39.400]   And Matthew's going to be a little different than maybe me.
[00:39:39.400 --> 00:39:44.720]   I just think it's a lot more complex than- And I think we've talked about this before.
[00:39:44.720 --> 00:39:51.080]   If I own, you know, my data, quote unquote, on Facebook, what does that consist of?
[00:39:51.080 --> 00:39:53.120]   Does it consist of my address book?
[00:39:53.120 --> 00:39:55.600]   Because those are the phone numbers of other people.
[00:39:55.600 --> 00:39:56.600]   Do I own those?
[00:39:56.600 --> 00:39:58.160]   Or do they own those?
[00:39:58.160 --> 00:40:00.400]   And if I want to take them somewhere, right?
[00:40:00.400 --> 00:40:04.640]   So if I want to take them somewhere, I have to get permission from all of those people,
[00:40:04.640 --> 00:40:05.640]   right?
[00:40:05.640 --> 00:40:12.240]   If it's data portability or Facebook giving me control over, quote unquote, my data.
[00:40:12.240 --> 00:40:15.560]   I think it's fine if it's my photos or content I imported.
[00:40:15.560 --> 00:40:22.160]   But as soon as it involves other people, you get sort of- It becomes exponentially more
[00:40:22.160 --> 00:40:23.160]   difficult.
[00:40:23.160 --> 00:40:26.960]   And I think we're developing mores around that, right?
[00:40:26.960 --> 00:40:33.880]   So I know at school, I would never take a picture of someone's child and post it without
[00:40:33.880 --> 00:40:35.360]   them knowing.
[00:40:35.360 --> 00:40:39.480]   And I think beforehand, like 10 years ago, I might have done that or someone else might
[00:40:39.480 --> 00:40:40.480]   have done that.
[00:40:40.480 --> 00:40:41.480]   But now no one does that.
[00:40:41.480 --> 00:40:42.480]   Really?
[00:40:42.480 --> 00:40:43.480]   That's interesting.
[00:40:43.480 --> 00:40:46.120]   So that's become the more a nobody will do that.
[00:40:46.120 --> 00:40:47.760]   In my child's school.
[00:40:47.760 --> 00:40:48.760]   Yeah.
[00:40:48.760 --> 00:40:52.760]   Well, because I posted a photo of you, I tagged you, I think.
[00:40:52.760 --> 00:40:56.000]   I posted a photo on- I think it was- She's a grown up.
[00:40:56.000 --> 00:40:57.520]   But I'm a grown up.
[00:40:57.520 --> 00:41:01.560]   No, but I tagged you and you said, I wish you wouldn't do that.
[00:41:01.560 --> 00:41:02.560]   Oh, yes.
[00:41:02.560 --> 00:41:03.560]   And I do.
[00:41:03.560 --> 00:41:05.480]   I tell my friends that- It had literally not occurred to me.
[00:41:05.480 --> 00:41:07.400]   And so I thought, oh, that's odd.
[00:41:07.400 --> 00:41:10.000]   You wish you wouldn't post photos of you or tag them?
[00:41:10.000 --> 00:41:11.000]   Yes.
[00:41:11.000 --> 00:41:15.560]   And I don't like people post mostly tagging because that makes it much easier to find
[00:41:15.560 --> 00:41:16.560]   it.
[00:41:16.560 --> 00:41:17.560]   Right.
[00:41:17.560 --> 00:41:21.760]   But- Oh, we know that Facebook's face recognition algorithms are so good that it doesn't matter
[00:41:21.760 --> 00:41:22.760]   anymore, right?
[00:41:22.760 --> 00:41:24.760]   If there's a picture of you on Facebook.
[00:41:24.760 --> 00:41:25.760]   Well, this was probably earlier.
[00:41:25.760 --> 00:41:26.760]   Yeah.
[00:41:26.760 --> 00:41:29.760]   So would your preference now be that people not post photos of you at all?
[00:41:29.760 --> 00:41:32.040]   I don't like people posting photos of me.
[00:41:32.040 --> 00:41:33.800]   It really depends on context.
[00:41:33.800 --> 00:41:35.880]   If you post a photo of me at an event, that's fine.
[00:41:35.880 --> 00:41:38.360]   If you're at my house and post a photo of me, that's not fine.
[00:41:38.360 --> 00:41:39.360]   Oh, yeah.
[00:41:39.360 --> 00:41:40.360]   I agree with you on that.
[00:41:40.360 --> 00:41:42.520]   I'll post a photo of me in front of my kids' school.
[00:41:42.520 --> 00:41:43.520]   Also not fine.
[00:41:43.520 --> 00:41:44.520]   Yeah.
[00:41:44.520 --> 00:41:45.520]   But I think you're right.
[00:41:45.520 --> 00:41:46.520]   That's a good point.
[00:41:46.520 --> 00:41:52.520]   I think you're developing a kind of morality or- Morality is etiquette/morality.
[00:41:52.520 --> 00:41:54.640]   I mean, these things are so new.
[00:41:54.640 --> 00:42:00.920]   You know, it's really- It's early days in terms of determining how you behave when two
[00:42:00.920 --> 00:42:04.640]   billion people could possibly see the thing that you're posting.
[00:42:04.640 --> 00:42:08.800]   I mean, we just don't know what that's like, really.
[00:42:08.800 --> 00:42:15.200]   And there was some backlash recently about the people who took a video of maybe a homeless
[00:42:15.200 --> 00:42:17.200]   man shaving on a train.
[00:42:17.200 --> 00:42:18.200]   It's a good idea.
[00:42:18.200 --> 00:42:19.200]   Yeah.
[00:42:19.200 --> 00:42:21.800]   I remember that because I'm thinking about it just today.
[00:42:21.800 --> 00:42:26.760]   He was shaving the guy sort of made fun of him because he was making a God off a mess.
[00:42:26.760 --> 00:42:30.800]   He didn't have anywhere to put the cream, so he was just flicking it on the floor.
[00:42:30.800 --> 00:42:34.200]   And he was shaving repeatedly, and there was a lot of shaving cream.
[00:42:34.200 --> 00:42:35.600]   I mean, it was hilarious.
[00:42:35.600 --> 00:42:39.800]   And you were thinking, "Why would this person be doing this on the train?"
[00:42:39.800 --> 00:42:45.240]   And then within about an hour or two, it turned out that he was homeless and had just gotten
[00:42:45.240 --> 00:42:47.440]   out of a homeless shelter.
[00:42:47.440 --> 00:42:51.160]   And he was going to meet, I think, his brother, and he wanted to look nice.
[00:42:51.160 --> 00:42:54.720]   And so he was shaving the only place he could.
[00:42:54.720 --> 00:42:59.720]   And it just completely changed the entire perspective you had on the train.
[00:42:59.720 --> 00:43:08.120]   Some of this is because social media is allowed bad, people with bad intent to act out so
[00:43:08.120 --> 00:43:10.840]   horrifically that we are now all much more sensitive.
[00:43:10.840 --> 00:43:16.080]   Any picture that's posted is the potential for being misused.
[00:43:16.080 --> 00:43:18.840]   And all of a sudden, we have to be aware of this.
[00:43:18.840 --> 00:43:23.880]   And partly it's because I think because the Twitter and Instagram and Facebook make it
[00:43:23.880 --> 00:43:24.880]   so easy to--
[00:43:24.880 --> 00:43:25.880]   Oh.
[00:43:25.880 --> 00:43:27.920]   So this is how we learn, right?
[00:43:27.920 --> 00:43:35.480]   If there's a-- so now I think it's become pretty commonplace to be irritated or to--
[00:43:35.480 --> 00:43:37.840]   Yeah, we're all outraged all the time.
[00:43:37.840 --> 00:43:38.840]   No, no, no.
[00:43:38.840 --> 00:43:43.600]   To see it as bad when, say, somebody is in public and they overhear someone having a
[00:43:43.600 --> 00:43:47.720]   conversation, and then they live to eat the conversation or they take pictures of them.
[00:43:47.720 --> 00:43:51.640]   There was one, I think, on a plane where it seemed like these two people were getting
[00:43:51.640 --> 00:43:52.640]   together.
[00:43:52.640 --> 00:43:54.720]   Like, that's an invasion of privacy.
[00:43:54.720 --> 00:44:01.240]   But if you see the purpose of social media as being to make fun of people who you don't
[00:44:01.240 --> 00:44:03.680]   know, you probably think it's great.
[00:44:03.680 --> 00:44:09.080]   But as soon as you start to think of them as real people who have lives, then you maybe
[00:44:09.080 --> 00:44:10.080]   reconsider.
[00:44:10.080 --> 00:44:16.600]   And I think it is interesting to see the shifting of kind of the way we look at those things.
[00:44:16.600 --> 00:44:19.160]   Life is so complicated now.
[00:44:19.160 --> 00:44:26.440]   And by the way, I thought Alex Stamos, the former Facebook security chiefs, responds
[00:44:26.440 --> 00:44:29.080]   to Tim Cook on Twitter, should be taken.
[00:44:29.080 --> 00:44:30.080]   Go ahead and sit.
[00:44:30.080 --> 00:44:35.880]   Yeah, he says the Apple needs to come clean about how it blocks ways to provide a more
[00:44:35.880 --> 00:44:40.560]   secure and private way to access apps in China.
[00:44:40.560 --> 00:44:45.440]   Apple absolutely supports the Chinese government in surveilling its citizens.
[00:44:45.440 --> 00:44:46.680]   Here's the quote.
[00:44:46.680 --> 00:44:51.320]   You don't want the media to create an incentive structure that ignores treating Chinese citizens
[00:44:51.320 --> 00:44:57.160]   as less deserving of privacy protections because a CEO is willing to badmouth the business
[00:44:57.160 --> 00:45:02.480]   model of their primary competitor who uses advertising to subsidize cheaper devices.
[00:45:02.480 --> 00:45:04.400]   Great point.
[00:45:04.400 --> 00:45:06.760]   Wait, cheaper devices, my buttocks?
[00:45:06.760 --> 00:45:13.040]   Well, Google's devices aren't cheaper, but there are free and cheap Android phones that
[00:45:13.040 --> 00:45:16.920]   are effectively subsidized by the fact that Google gives away Android.
[00:45:16.920 --> 00:45:21.080]   So he cares about our privacy, but he doesn't care about the privacy of the Chinese.
[00:45:21.080 --> 00:45:22.080]   Since you're not Chinese.
[00:45:22.080 --> 00:45:23.080]   Right.
[00:45:23.080 --> 00:45:24.080]   So how is that?
[00:45:24.080 --> 00:45:28.680]   How are we supposed to see that as some shining moral compass?
[00:45:28.680 --> 00:45:35.720]   I always am suspicious when people are very sanctimonious because often the most sanctimonious
[00:45:35.720 --> 00:45:38.520]   people are the ones who are the biggest sinners.
[00:45:38.520 --> 00:45:39.520]   And we've seen this.
[00:45:39.520 --> 00:45:42.320]   I'm very sanctimonious and I am not a big sinner.
[00:45:42.320 --> 00:45:43.320]   Well, there are exceptions.
[00:45:43.320 --> 00:45:48.240]   My biggest sin is eating an entire package of sour patch kids.
[00:45:48.240 --> 00:45:49.240]   Oh, that's bad.
[00:45:49.240 --> 00:45:51.240]   You're a bad person.
[00:45:51.240 --> 00:45:52.240]   I am.
[00:45:52.240 --> 00:45:55.680]   Actually, the only person you're hurting is yourself.
[00:45:55.680 --> 00:45:56.680]   Oh, that's right.
[00:45:56.680 --> 00:45:57.680]   You're going to do.
[00:45:57.680 --> 00:45:59.840]   And my family who I'm taking the sour patch kids away from.
[00:45:59.840 --> 00:46:00.840]   Oh, well, that's.
[00:46:00.840 --> 00:46:04.680]   And also act to deal with me when I'm in the sugar high.
[00:46:04.680 --> 00:46:07.120]   But doesn't the isn't it like a speedball for sugar?
[00:46:07.120 --> 00:46:08.520]   Like it's sour and sweet.
[00:46:08.520 --> 00:46:10.920]   So it's like counteracting the sugar.
[00:46:10.920 --> 00:46:14.840]   I don't think that's how it works.
[00:46:14.840 --> 00:46:15.840]   It's not how it works.
[00:46:15.840 --> 00:46:17.800]   It's a sugar speedball.
[00:46:17.800 --> 00:46:18.800]   Okay.
[00:46:18.800 --> 00:46:26.960]   Let's take a break.
[00:46:26.960 --> 00:46:28.040]   Matthew Ingram is here.
[00:46:28.040 --> 00:46:33.960]   He is in charge of digital writing, whatever that might be at the Columbia journalism review
[00:46:33.960 --> 00:46:36.920]   at CJR.org chief digital writer.
[00:46:36.920 --> 00:46:40.000]   Does that mean you don't write with ink?
[00:46:40.000 --> 00:46:42.840]   No exclusively with pixels and ones.
[00:46:42.840 --> 00:46:44.360]   You're only allowed.
[00:46:44.360 --> 00:46:46.800]   I think it means you're covered digital technologies.
[00:46:46.800 --> 00:46:47.800]   Yes.
[00:46:47.800 --> 00:46:48.800]   That'd be my case.
[00:46:48.800 --> 00:46:49.800]   Yes.
[00:46:49.800 --> 00:46:55.440]   And Stacey Higginbotham, who only covers Internet of Things, little tiny Internet of Things
[00:46:55.440 --> 00:46:56.440]   Things.
[00:46:56.440 --> 00:46:58.640]   That's actually our big ones.
[00:46:58.640 --> 00:47:00.920]   Stacey, like your GM vehicle.
[00:47:00.920 --> 00:47:01.920]   Stacey on IOT.
[00:47:01.920 --> 00:47:03.480]   That's an Internet of Thing devices, isn't it?
[00:47:03.480 --> 00:47:05.120]   If it's phone at home.
[00:47:05.120 --> 00:47:06.320]   Yes, sure is.
[00:47:06.320 --> 00:47:09.320]   Stacey on IOT.com.
[00:47:09.320 --> 00:47:12.960]   Our show today brought to you by Rocket Mortgage.
[00:47:12.960 --> 00:47:17.880]   When it comes time to buy a home, you have, of course, many choices.
[00:47:17.880 --> 00:47:19.920]   Lots of people want to lend you that money to buy the house.
[00:47:19.920 --> 00:47:20.920]   That's nice.
[00:47:20.920 --> 00:47:21.920]   That's a good feeling.
[00:47:21.920 --> 00:47:24.880]   But there's different experiences involved.
[00:47:24.880 --> 00:47:28.120]   For instance, the Big Bank, where we got our loan.
[00:47:28.120 --> 00:47:31.640]   Lisa and I got our home loan five years ago for the house we live in today.
[00:47:31.640 --> 00:47:35.000]   And first of all, you got to go to the Big Bank, right?
[00:47:35.000 --> 00:47:36.560]   And you probably should dress up a little bit.
[00:47:36.560 --> 00:47:37.560]   You look prosperous.
[00:47:37.560 --> 00:47:38.560]   I don't need a loan.
[00:47:38.560 --> 00:47:41.480]   You're just going to do you a favor and borrow some money.
[00:47:41.480 --> 00:47:46.600]   And then they go, boom, here's a stack.
[00:47:46.600 --> 00:47:48.160]   Here's the application.
[00:47:48.160 --> 00:47:49.160]   Go home.
[00:47:49.160 --> 00:47:50.160]   Do some homework.
[00:47:50.160 --> 00:47:51.160]   And we did.
[00:47:51.160 --> 00:47:52.160]   We were good.
[00:47:52.160 --> 00:47:56.440]   We went, you know, we got all the paperwork, got the old pay stubs, got the bank statements
[00:47:56.440 --> 00:47:59.920]   from years gone by, filed it all.
[00:47:59.920 --> 00:48:02.440]   We thought, well, this will be done soon.
[00:48:02.440 --> 00:48:04.680]   Let's go on vacation.
[00:48:04.680 --> 00:48:08.440]   Two months, two months later, we're still getting requests from the Big Bank for more
[00:48:08.440 --> 00:48:09.440]   information.
[00:48:09.440 --> 00:48:15.040]   We're on a cruise ship faxing them, like pay stubs and stuff.
[00:48:15.040 --> 00:48:16.040]   It's crazy.
[00:48:16.040 --> 00:48:19.040]   We finally got the house, but it was not a good experience.
[00:48:19.040 --> 00:48:22.400]   Fast forward to the 21st century and quick and loans.
[00:48:22.400 --> 00:48:26.080]   The number one lender in the country for the last eight years, according to JD Power
[00:48:26.080 --> 00:48:28.680]   and their customer satisfaction survey.
[00:48:28.680 --> 00:48:31.240]   Number one, that's made them number one in volume.
[00:48:31.240 --> 00:48:33.680]   They've actually surpassed the Big Bank as of December.
[00:48:33.680 --> 00:48:34.680]   That's really good news.
[00:48:34.680 --> 00:48:39.800]   These more people are getting the great customer experience of quick and loans and rocket mortgage.
[00:48:39.800 --> 00:48:42.720]   Rocket mortgage is their entirely online mortgage approval process.
[00:48:42.720 --> 00:48:44.520]   You don't have to go to a bank.
[00:48:44.520 --> 00:48:46.160]   You don't have to go to the attic to get paperwork.
[00:48:46.160 --> 00:48:49.320]   You just go to rocketmortgage.com/twig.
[00:48:49.320 --> 00:48:52.600]   Answer a few simple questions within a few minutes.
[00:48:52.600 --> 00:48:55.160]   They'll check your credit and give you pre-qualified approval.
[00:48:55.160 --> 00:48:56.160]   Boom, just like that.
[00:48:56.160 --> 00:49:00.480]   You choose the loan you want, the term, the rate, the down payment.
[00:49:00.480 --> 00:49:06.320]   Then within 24 hours, step two, they'll verify your income assets and credit and give you
[00:49:06.320 --> 00:49:07.320]   verified approval.
[00:49:07.320 --> 00:49:09.640]   Now you're as good as a cash buyer.
[00:49:09.640 --> 00:49:11.880]   You go right to the front of the line when you're buying the house.
[00:49:11.880 --> 00:49:15.680]   Sellers says, "Oh good," because you have the letters that say that we got the money.
[00:49:15.680 --> 00:49:16.680]   That's a nice feeling.
[00:49:16.680 --> 00:49:23.400]   There's still a little anxiety though because rates are going up and there's some pressure
[00:49:23.400 --> 00:49:27.400]   on you when you're looking at a house to buy now before the rates go up and it costs you
[00:49:27.400 --> 00:49:28.960]   lots more.
[00:49:28.960 --> 00:49:31.640]   That's where rocket mortgage really kicks into gear.
[00:49:31.640 --> 00:49:36.360]   Once you're verified, you qualify for their all new exclusive rate shield approval.
[00:49:36.360 --> 00:49:40.680]   They'll lock that rate for up to three months while you shop up to 90 days.
[00:49:40.680 --> 00:49:41.840]   It can't go up.
[00:49:41.840 --> 00:49:47.000]   Rates can go down and your rate will go down, but if the rates go up, yours stays the same.
[00:49:47.000 --> 00:49:50.160]   Either way you'll win and win and that's exactly what makes rocket mortgage and quick
[00:49:50.160 --> 00:49:53.320]   and loans the best lender in the country.
[00:49:53.320 --> 00:49:54.320]   To get started, it's easy.
[00:49:54.320 --> 00:49:57.320]   Go to rocketmortgage.com/twig.
[00:49:57.320 --> 00:50:00.480]   Rate shield approval is only valid on certain 30-year purchase transactions.
[00:50:00.480 --> 00:50:03.120]   Additional conditions or exclusions may apply.
[00:50:03.120 --> 00:50:07.120]   Based on quick and loans data and comparison to public data records, equal housing lender,
[00:50:07.120 --> 00:50:14.280]   licensed in all 50 states, NMLS, consumeraccess.org number, 30, 30.
[00:50:14.280 --> 00:50:15.280]   You don't have to remember all that.
[00:50:15.280 --> 00:50:16.280]   Just remember this.
[00:50:16.280 --> 00:50:17.280]   rocketmortgage.com/twig.
[00:50:17.280 --> 00:50:24.200]   It really transformed the lending process.
[00:50:24.200 --> 00:50:25.200]   Check them out today.
[00:50:25.200 --> 00:50:28.000]   Are you ready?
[00:50:28.000 --> 00:50:29.000]   You want to do a little...
[00:50:29.000 --> 00:50:34.160]   Actually, before we do the change log, I had mentioned a few weeks ago was the 10th anniversary
[00:50:34.160 --> 00:50:36.360]   of Android.
[00:50:36.360 --> 00:50:45.280]   Actually the HTC One, the Google phone, came out the G1 on October 22nd, so 2008.
[00:50:45.280 --> 00:50:48.000]   So there were a number of posts.
[00:50:48.000 --> 00:50:49.080]   I have that G1.
[00:50:49.080 --> 00:50:50.080]   I bought it.
[00:50:50.080 --> 00:50:51.080]   I was very excited.
[00:50:51.080 --> 00:50:56.800]   As everyone else was, very disappointed by that first Android device.
[00:50:56.800 --> 00:50:58.840]   Can you still use it?
[00:50:58.840 --> 00:51:01.280]   I guess it has a proprietary charging port.
[00:51:01.280 --> 00:51:04.240]   I'd have to find the weird...
[00:51:04.240 --> 00:51:07.080]   All those days all those phones were weird.
[00:51:07.080 --> 00:51:07.920]   You know, there's weird not-
[00:51:07.920 --> 00:51:08.920]   Yeah.
[00:51:08.920 --> 00:51:09.920]   Yeah.
[00:51:09.920 --> 00:51:10.920]   Things you plugged in.
[00:51:10.920 --> 00:51:12.560]   It didn't have a headphone jack.
[00:51:12.560 --> 00:51:16.400]   The main reason it wasn't any good is not Android.
[00:51:16.400 --> 00:51:17.560]   The phone was very underpowered.
[00:51:17.560 --> 00:51:18.560]   It was very slow.
[00:51:18.560 --> 00:51:20.480]   Maybe it was Android.
[00:51:20.480 --> 00:51:22.360]   They had an on-screen keyboard and a multitouch.
[00:51:22.360 --> 00:51:24.440]   They had a physical keyboard.
[00:51:24.440 --> 00:51:25.440]   They had apps.
[00:51:25.440 --> 00:51:27.920]   No, they didn't have apps.
[00:51:27.920 --> 00:51:30.320]   No, they didn't have an on-screen keyboard.
[00:51:30.320 --> 00:51:31.800]   No, they didn't have an multitouch.
[00:51:31.800 --> 00:51:32.800]   You know what else they didn't have?
[00:51:32.800 --> 00:51:34.720]   They didn't have a headphone jack.
[00:51:34.720 --> 00:51:35.720]   Wow.
[00:51:35.720 --> 00:51:36.720]   Wow.
[00:51:36.720 --> 00:51:37.720]   That's very poor.
[00:51:37.720 --> 00:51:38.720]   Yeah, right.
[00:51:38.720 --> 00:51:39.720]   Yeah.
[00:51:39.720 --> 00:51:42.280]   And they were way ahead of the times there.
[00:51:42.280 --> 00:51:44.480]   But over time, Android got better and better.
[00:51:44.480 --> 00:51:46.200]   Here's Cupcake 1.5.
[00:51:46.200 --> 00:51:51.480]   This is a fun walk-down memory lane from the Verge.
[00:51:51.480 --> 00:51:56.720]   Cupcake added the ability to cut and paste.
[00:51:56.720 --> 00:51:59.880]   That turns out to be a hard thing to do on a mobile device, I guess.
[00:51:59.880 --> 00:52:02.800]   Windows Phone didn't have it for a long time.
[00:52:02.800 --> 00:52:10.080]   The on-screen keyboard that arrived in 1.5, the extensible widgets, video capture and
[00:52:10.080 --> 00:52:12.120]   playback.
[00:52:12.120 --> 00:52:16.160]   Android 1.6 donut.
[00:52:16.160 --> 00:52:18.160]   After that, then Eclair 2.0.
[00:52:18.160 --> 00:52:25.440]   Eclair was a complete redesign of how it looked and had had, according to the Verge,
[00:52:25.440 --> 00:52:30.280]   an unheard of 854 by 480 display.
[00:52:30.280 --> 00:52:31.280]   Wow.
[00:52:31.280 --> 00:52:32.280]   Wow.
[00:52:32.280 --> 00:52:36.400]   That was the Motorola droid.
[00:52:36.400 --> 00:52:39.200]   I did not like the droids.
[00:52:39.200 --> 00:52:40.200]   Multiple account support.
[00:52:40.200 --> 00:52:43.120]   Wow, I didn't realize it had been around that long since 2.0.
[00:52:43.120 --> 00:52:44.120]   Wow.
[00:52:44.120 --> 00:52:48.240]   Multiple Maps navigation came out in 2.0.
[00:52:48.240 --> 00:52:51.640]   Live wallpapers, speech to text.
[00:52:51.640 --> 00:52:58.600]   Then there was FroYo, because remember, they're all desserts, 2.2.
[00:52:58.600 --> 00:53:00.680]   Gingerbread, 2.3.
[00:53:00.680 --> 00:53:05.640]   An improved keyboard, better battery and app management.
[00:53:05.640 --> 00:53:06.640]   Front-facing controls.
[00:53:06.640 --> 00:53:08.920]   Android, give us the battery indicator.
[00:53:08.920 --> 00:53:09.920]   Yes.
[00:53:09.920 --> 00:53:10.920]   I just imagined we did go to the internet.
[00:53:10.920 --> 00:53:11.920]   Oh, you're good.
[00:53:11.920 --> 00:53:12.920]   That's exactly right.
[00:53:12.920 --> 00:53:13.920]   That was in gingerbread.
[00:53:13.920 --> 00:53:15.640]   Was that in gingerbread or was that earlier?
[00:53:15.640 --> 00:53:17.800]   I think it was earlier, right?
[00:53:17.800 --> 00:53:21.240]   Let's go back up through those pictures.
[00:53:21.240 --> 00:53:26.400]   Gingerbread helped make that a little easier to fix with a new bundled utility for graphically
[00:53:26.400 --> 00:53:30.200]   viewing battery drain over time.
[00:53:30.200 --> 00:53:34.440]   That was in gingerbread 2.3.
[00:53:34.440 --> 00:53:36.240]   Honeycomb.
[00:53:36.240 --> 00:53:43.520]   Honeycomb was designed for tablets, I remember, and did not work very well.
[00:53:43.520 --> 00:53:45.240]   That came out with that Nexus 7.
[00:53:45.240 --> 00:53:48.640]   That was the 7-inch tablet I was talking about.
[00:53:48.640 --> 00:53:51.640]   $127.
[00:53:51.640 --> 00:53:55.520]   Honeycomb was an interim ice cream sandwich, was the real deal 4.0.
[00:53:55.520 --> 00:54:00.040]   Now we're getting to kind of something that looks like the real Android that we're used
[00:54:00.040 --> 00:54:01.760]   to.
[00:54:01.760 --> 00:54:03.720]   Face unlock.
[00:54:03.720 --> 00:54:07.160]   Android Beam.
[00:54:07.160 --> 00:54:10.160]   Here's the to go with the battery drain indicators.
[00:54:10.160 --> 00:54:12.600]   Here's data usage analysis.
[00:54:12.600 --> 00:54:16.480]   It's funny if you look at this because a lot of the stuff Apple's added recently.
[00:54:16.480 --> 00:54:17.480]   Yeah.
[00:54:17.480 --> 00:54:18.480]   And touts.
[00:54:18.480 --> 00:54:19.480]   It's like face unlock.
[00:54:19.480 --> 00:54:25.640]   Yeah, face unlock was not that it worked, but it, but you could do it.
[00:54:25.640 --> 00:54:27.520]   Eoretically, it was possible.
[00:54:27.520 --> 00:54:29.080]   It was in, it was in there.
[00:54:29.080 --> 00:54:30.520]   It's the spots that counts.
[00:54:30.520 --> 00:54:40.800]   Jelly Bean 4.1, 4.2 Jelly Bean, 4.3 Jelly Bean, then there was KitKat.
[00:54:40.800 --> 00:54:41.800]   Jelly.
[00:54:41.800 --> 00:54:42.800]   October 2013.
[00:54:42.800 --> 00:54:43.800]   Has it been that long?
[00:54:43.800 --> 00:54:44.800]   Wow.
[00:54:44.800 --> 00:54:47.800]   KitKat 4.4.
[00:54:47.800 --> 00:54:55.360]   Well, I can go on, but there's a very nice if you, if you want to go down the Android
[00:54:55.360 --> 00:55:00.040]   memory lane, they even have little videos from Google I/O.
[00:55:00.040 --> 00:55:02.440]   Look at the first Android Wear watch.
[00:55:02.440 --> 00:55:05.640]   I think it's huge.
[00:55:05.640 --> 00:55:09.160]   That's big on a big wrist.
[00:55:09.160 --> 00:55:11.160]   I can't even imagine it.
[00:55:11.160 --> 00:55:18.760]   That's a huge, it's Android the giant marshmallow.
[00:55:18.760 --> 00:55:21.120]   Happy, happy 10th.
[00:55:21.120 --> 00:55:28.360]   To Google Android, a sweet decade of Android and Google's own blog had, had its little
[00:55:28.360 --> 00:55:29.360]   memory.
[00:55:29.360 --> 00:55:30.840]   Oh, you know what?
[00:55:30.840 --> 00:55:35.440]   It looks like that most of that Verge article was taken straight from Google's blog.
[00:55:35.440 --> 00:55:38.800]   Well, I'll be diggity danged.
[00:55:38.800 --> 00:55:41.120]   Here's the Nexus 7 tablet.
[00:55:41.120 --> 00:55:43.120]   I still use my Nexus 7.
[00:55:43.120 --> 00:55:44.120]   I have two of them.
[00:55:44.120 --> 00:55:45.120]   It's quite useful.
[00:55:45.120 --> 00:55:47.360]   I only run one program on it.
[00:55:47.360 --> 00:55:49.920]   Oh, they had boarding passes in Jelly Bean.
[00:55:49.920 --> 00:55:51.240]   What's the program?
[00:55:51.240 --> 00:55:52.800]   That must be Google now, right?
[00:55:52.800 --> 00:55:54.160]   Is that, yeah.
[00:55:54.160 --> 00:55:56.840]   Google now started in Jelly Bean.
[00:55:56.840 --> 00:56:01.960]   So now we know it takes how many 4 Android versions to kill something.
[00:56:01.960 --> 00:56:05.000]   Ah, sigh.
[00:56:05.000 --> 00:56:10.000]   What's the program you run on your tablet?
[00:56:10.000 --> 00:56:11.720]   The one in front of me?
[00:56:11.720 --> 00:56:12.720]   It's just--
[00:56:12.720 --> 00:56:14.720]   You said you have two and you only run one--
[00:56:14.720 --> 00:56:16.560]   Oh, I wrote a little Android.
[00:56:16.560 --> 00:56:18.240]   What do they call the--
[00:56:18.240 --> 00:56:19.240]   The Android.
[00:56:19.240 --> 00:56:20.240]   An APK?
[00:56:20.240 --> 00:56:26.880]   Yeah, it's an APK, but I made it with a very simplified Android programming environment.
[00:56:26.880 --> 00:56:30.800]   And it does one thing only, which is time my radio shows.
[00:56:30.800 --> 00:56:35.760]   So as the time goes by, it counts me down to the next ad.
[00:56:35.760 --> 00:56:39.960]   And it turns out the Nexus 7 is a perfect size for it.
[00:56:39.960 --> 00:56:40.960]   So it just--
[00:56:40.960 --> 00:56:41.960]   There it is.
[00:56:41.960 --> 00:56:45.040]   It's just-- because it's big, it's big numbers, and it's just counting me down.
[00:56:45.040 --> 00:56:48.600]   And when I get to zero, then it's time to do a commercial.
[00:56:48.600 --> 00:56:53.120]   Oh, I just thought you went by feel.
[00:56:53.120 --> 00:56:54.680]   Well, not here.
[00:56:54.680 --> 00:56:57.200]   By here, it's feel is exactly right.
[00:56:57.200 --> 00:56:58.200]   OK.
[00:56:58.200 --> 00:56:59.200]   Radio shows network.
[00:56:59.200 --> 00:57:00.200]   Oh, right.
[00:57:00.200 --> 00:57:01.200]   Right.
[00:57:01.200 --> 00:57:02.200]   Right.
[00:57:02.200 --> 00:57:03.440]   So actually, I was doing a-- I was in a commercial.
[00:57:03.440 --> 00:57:05.080]   Now I'm green, which means I can talk.
[00:57:05.080 --> 00:57:07.320]   I have 547 seconds.
[00:57:07.320 --> 00:57:08.320]   And then--
[00:57:08.320 --> 00:57:09.320]   I didn't see--
[00:57:09.320 --> 00:57:10.320]   I know.
[00:57:10.320 --> 00:57:11.920]   It's--
[00:57:11.920 --> 00:57:13.320]   Commercial radio.
[00:57:13.320 --> 00:57:14.320]   Yeah.
[00:57:14.320 --> 00:57:20.000]   In fact, if anybody wonders why our shows go on so damn long, why I talk about the same
[00:57:20.000 --> 00:57:25.000]   thing over and over again is because I never was allowed to for 40 years in broadcasting.
[00:57:25.000 --> 00:57:26.000]   So I'm a--
[00:57:26.000 --> 00:57:27.000]   Did all of these thoughts just--
[00:57:27.000 --> 00:57:28.000]   Stored up to this break.
[00:57:28.000 --> 00:57:30.280]   I just want to talk.
[00:57:30.280 --> 00:57:32.920]   How long did it take you to write that?
[00:57:32.920 --> 00:57:33.920]   Not very long.
[00:57:33.920 --> 00:57:36.720]   What was the name of the-- it was MIT took it over.
[00:57:36.720 --> 00:57:37.720]   Six months.
[00:57:37.720 --> 00:57:38.720]   Oh, god.
[00:57:38.720 --> 00:57:39.720]   No.
[00:57:39.720 --> 00:57:43.400]   If you saw the code-- here, I'll show you the code.
[00:57:43.400 --> 00:57:46.200]   I'm sure it was like an afternoon or something.
[00:57:46.200 --> 00:57:47.360]   Barely.
[00:57:47.360 --> 00:57:52.280]   Because it's mostly one big if then-- if then else thing, you know.
[00:57:52.280 --> 00:57:53.280]   And--
[00:57:53.280 --> 00:57:54.960]   That's the only programming I do now.
[00:57:54.960 --> 00:57:56.600]   App builder, it's called.
[00:57:56.600 --> 00:58:01.000]   Actually, I still do some-- I do some coding.
[00:58:01.000 --> 00:58:02.000]   I love coding.
[00:58:02.000 --> 00:58:04.640]   It's always been a good hobby.
[00:58:04.640 --> 00:58:05.640]   Is this it?
[00:58:05.640 --> 00:58:06.640]   No.
[00:58:06.640 --> 00:58:09.720]   That's a dumb-- that's the base.
[00:58:09.720 --> 00:58:11.520]   That's the base.
[00:58:11.520 --> 00:58:16.240]   Maybe-- this can't be it because this is like demo code.
[00:58:16.240 --> 00:58:17.960]   But it's what it looks like.
[00:58:17.960 --> 00:58:19.240]   But you don't usually write it in that.
[00:58:19.240 --> 00:58:22.200]   You write it with the app builder app.
[00:58:22.200 --> 00:58:23.920]   MIT took this over.
[00:58:23.920 --> 00:58:25.960]   And then so this is the APK. It's a megabyte.
[00:58:25.960 --> 00:58:26.960]   It's pretty small.
[00:58:26.960 --> 00:58:30.800]   I put it-- it's nice and small and easy to run on a 10-year-old,
[00:58:30.800 --> 00:58:32.800]   whatever that is, tablet.
[00:58:32.800 --> 00:58:34.360]   But it's very useful.
[00:58:34.360 --> 00:58:38.600]   And the thing is, it goes all the time.
[00:58:38.600 --> 00:58:40.480]   The radio shows only on Saturday and Sunday.
[00:58:40.480 --> 00:58:41.880]   But this goes all the time.
[00:58:41.880 --> 00:58:42.480]   It's always--
[00:58:42.480 --> 00:58:43.480]   It never stops.
[00:58:43.480 --> 00:58:45.880]   Never stops counting down the minutes.
[00:58:45.880 --> 00:58:46.360]   Yeah.
[00:58:46.360 --> 00:58:48.200]   Well, at least you can count on something.
[00:58:48.200 --> 00:58:49.720]   There's something you can count on.
[00:58:49.720 --> 00:58:51.280]   Let's just leave this right here.
[00:58:51.280 --> 00:58:55.720]   Ironically, this is actually bigger and maybe even more
[00:58:55.720 --> 00:58:57.920]   useful than the Home Hub.
[00:58:57.920 --> 00:58:59.240]   Oh, there you go.
[00:58:59.240 --> 00:59:02.240]   That'll give you some idea.
[00:59:02.240 --> 00:59:04.120]   But there's me and my wife.
[00:59:04.120 --> 00:59:05.800]   Does it have a counter feature?
[00:59:05.800 --> 00:59:06.160]   No.
[00:59:06.160 --> 00:59:06.600]   Home Hub.
[00:59:06.600 --> 00:59:06.960]   You know what?
[00:59:06.960 --> 00:59:10.360]   If I could get this-- that app on this, then I'd be happy.
[00:59:10.360 --> 00:59:15.080]   I smell a challenge.
[00:59:15.080 --> 00:59:17.240]   [GROANING]
[00:59:17.240 --> 00:59:20.000]   Someone else.
[00:59:20.000 --> 00:59:22.080]   Can you run apps on the Home Hub?
[00:59:22.080 --> 00:59:24.240]   I don't think you can.
[00:59:24.240 --> 00:59:25.840]   I wonder.
[00:59:25.840 --> 00:59:28.280]   No, it's running cat--
[00:59:28.280 --> 00:59:29.280]   It's from cats, right?
[00:59:29.280 --> 00:59:29.800]   Yeah.
[00:59:29.800 --> 00:59:30.800]   Yeah.
[00:59:30.800 --> 00:59:33.000]   I guess you could do it now.
[00:59:33.000 --> 00:59:33.440]   Somehow.
[00:59:33.440 --> 00:59:34.560]   Let me off the look at it.
[00:59:34.560 --> 00:59:36.760]   That'd be interesting.
[00:59:36.760 --> 00:59:43.440]   So Google has made some changes, which we will start talking
[00:59:43.440 --> 00:59:45.640]   about right now.
[00:59:45.640 --> 00:59:46.640]   In the middle.
[00:59:46.640 --> 00:59:48.160]   [MUSIC PLAYING]
[00:59:48.160 --> 00:59:50.560]   The Google change log.
[00:59:50.560 --> 00:59:54.400]   Boom, boom, boom, boom, boom.
[00:59:54.400 --> 00:59:56.640]   Not quite 2001, a space odyssey.
[00:59:56.640 --> 00:59:59.080]   But here it is.
[00:59:59.080 --> 01:00:00.200]   What's new from Google?
[01:00:00.200 --> 01:00:01.960]   And this is a big one.
[01:00:01.960 --> 01:00:03.720]   And it's not in response to Tim Cook,
[01:00:03.720 --> 01:00:07.240]   but it is a-- if somebody brings up Tim Cook,
[01:00:07.240 --> 01:00:08.840]   it's a good thing to mention.
[01:00:08.840 --> 01:00:11.880]   This is in the keyword blog, Ed Moralia writing,
[01:00:11.880 --> 01:00:14.160]   Director of Product Management, Privacy and Data Protection
[01:00:14.160 --> 01:00:15.360]   Office.
[01:00:15.360 --> 01:00:17.920]   They are going to make it easier for you
[01:00:17.920 --> 01:00:20.400]   to-- they say this is part of an overall plan
[01:00:20.400 --> 01:00:23.760]   to make it easier for you to make decisions about your data
[01:00:23.760 --> 01:00:25.880]   directly within the Google products you use every day.
[01:00:25.880 --> 01:00:28.800]   But it's starting with search.
[01:00:28.800 --> 01:00:33.000]   You see in this animation, you go to the settings of search,
[01:00:33.000 --> 01:00:34.640]   and there is a new entry.
[01:00:34.640 --> 01:00:36.520]   I don't see it yet, but presumably it
[01:00:36.520 --> 01:00:39.920]   will be coming to all Google devices called your data
[01:00:39.920 --> 01:00:44.800]   in search in which you can then go down and delete your data,
[01:00:44.800 --> 01:00:47.520]   control your data, see what Google
[01:00:47.520 --> 01:00:50.280]   knows about you.
[01:00:50.280 --> 01:00:52.840]   See, this is-- to me, as long as Google is transiting,
[01:00:52.840 --> 01:00:54.360]   you're heard about what they collect
[01:00:54.360 --> 01:00:55.680]   and gives you these kinds of things.
[01:00:55.680 --> 01:00:57.800]   Now you might be cynical and say, well, they're only doing it
[01:00:57.800 --> 01:00:58.640]   because of GDPR.
[01:00:58.640 --> 01:01:01.040]   Well, fine, if that's the case.
[01:01:01.040 --> 01:01:01.560]   Fine.
[01:01:01.560 --> 01:01:03.040]   Regular should works.
[01:01:03.040 --> 01:01:04.800]   Yeah, they're doing it.
[01:01:04.800 --> 01:01:06.280]   The threat of regulation works.
[01:01:06.280 --> 01:01:07.960]   Yeah.
[01:01:07.960 --> 01:01:11.120]   So you can see what searches you made.
[01:01:11.120 --> 01:01:13.600]   You can delete search activity.
[01:01:13.600 --> 01:01:18.640]   You can decide what search activity is saved.
[01:01:18.640 --> 01:01:20.320]   Coming to maps, too.
[01:01:20.320 --> 01:01:22.240]   Yes, eventually it sounds like they
[01:01:22.240 --> 01:01:24.840]   plan to put it in every Google application.
[01:01:24.840 --> 01:01:26.400]   We're always working on making it easier for you
[01:01:26.400 --> 01:01:27.840]   to understand and control your data
[01:01:27.840 --> 01:01:31.240]   so you can make privacy choices that are right for you.
[01:01:31.240 --> 01:01:33.320]   Earlier this year, we launched a new Google account
[01:01:33.320 --> 01:01:36.480]   experience that puts your privacy in security front and center.
[01:01:36.480 --> 01:01:38.560]   We updated our privacy policy with videos
[01:01:38.560 --> 01:01:40.080]   and clearer language.
[01:01:40.080 --> 01:01:41.320]   Today, we're making it easier for you
[01:01:41.320 --> 01:01:45.360]   to make decisions about your data directly within search.
[01:01:45.360 --> 01:01:50.080]   So I don't think it was in response to Tim Cook.
[01:01:50.080 --> 01:01:50.440]   But--
[01:01:50.440 --> 01:01:52.200]   I imagine they've been working on it for a while.
[01:01:52.200 --> 01:01:54.160]   Yes, I think you probably have been.
[01:01:54.160 --> 01:01:59.960]   More 4K, I'm grateful to Google.
[01:01:59.960 --> 01:02:04.000]   Apple did this when they released the 4K Apple TV.
[01:02:04.000 --> 01:02:06.760]   Google is now upgrading your movies
[01:02:06.760 --> 01:02:11.680]   that you've purchased on Google Play to 4K for free.
[01:02:11.680 --> 01:02:14.120]   Even if you originally bought it in SD or HD,
[01:02:14.120 --> 01:02:16.760]   of course, the movie has to be available in 4K.
[01:02:16.760 --> 01:02:22.200]   They're also lowering the prices on 4K titles.
[01:02:22.200 --> 01:02:24.840]   Is that because nobody cares enough to update their 4K
[01:02:24.840 --> 01:02:26.160]   on their own?
[01:02:26.160 --> 01:02:29.600]   I think that would be the cynical interpretation.
[01:02:29.600 --> 01:02:31.920]   But I think the real interpretation
[01:02:31.920 --> 01:02:33.800]   is that more people have 4K TVs.
[01:02:33.800 --> 01:02:36.280]   In fact, if you'd be hard pressed to buy a new TV,
[01:02:36.280 --> 01:02:38.760]   even a cheap TV that isn't 4K.
[01:02:38.760 --> 01:02:40.240]   So it just makes sense.
[01:02:40.240 --> 01:02:44.280]   They updated the app on Samsung, LG, and Visio TVs.
[01:02:44.280 --> 01:02:48.280]   They will automatically support 4K if those are 4K TVs.
[01:02:48.280 --> 01:02:48.920]   And you can use--
[01:02:48.920 --> 01:02:51.640]   What if you bought it in SD when there was an HD alternative?
[01:02:51.640 --> 01:02:54.200]   Because sometimes when I buy--
[01:02:54.200 --> 01:02:55.560]   Well, that's interesting.
[01:02:55.560 --> 01:02:57.160]   They say--
[01:02:57.160 --> 01:02:57.680]   OK.
[01:02:57.680 --> 01:03:01.000]   --even if you originally bought the movie in SD.
[01:03:01.000 --> 01:03:02.160]   Huh.
[01:03:02.160 --> 01:03:03.160]   All right.
[01:03:05.520 --> 01:03:06.960]   That's pretty good.
[01:03:06.960 --> 01:03:08.600]   Yeah, because sometimes you're like,
[01:03:08.600 --> 01:03:11.160]   I'm really only buying this to watch on my tablet.
[01:03:11.160 --> 01:03:12.160]   So then--
[01:03:12.160 --> 01:03:12.640]   OK.
[01:03:12.640 --> 01:03:14.000]   Better.
[01:03:14.000 --> 01:03:17.360]   I bet you that's so unusual.
[01:03:17.360 --> 01:03:18.040]   Really?
[01:03:18.040 --> 01:03:18.640]   They don't care.
[01:03:18.640 --> 01:03:20.760]   Am I the only cheap person in the universe?
[01:03:20.760 --> 01:03:22.920]   You save a buck.
[01:03:22.920 --> 01:03:26.920]   Hey, it is so worth it.
[01:03:26.920 --> 01:03:30.000]   How about a new course to teach people
[01:03:30.000 --> 01:03:33.680]   about fairness in machine learning?
[01:03:33.680 --> 01:03:36.880]   My daughter actually has been doing her thesis on this.
[01:03:36.880 --> 01:03:40.280]   And we all know that machine learning can be highly biased
[01:03:40.280 --> 01:03:44.600]   if it's trained with limited samples, right?
[01:03:44.600 --> 01:03:48.000]   If you only train face recognition with Caucasians,
[01:03:48.000 --> 01:03:51.800]   it's going to be a terrible job with African-Americans.
[01:03:51.800 --> 01:03:53.360]   So here's the question.
[01:03:53.360 --> 01:03:54.920]   What do you see?
[01:03:54.920 --> 01:04:01.320]   Bananas, stickers, or bananas on shelves?
[01:04:01.320 --> 01:04:03.320]   Stickers.
[01:04:03.320 --> 01:04:05.920]   There are stickers on all the bananas, maybe.
[01:04:05.920 --> 01:04:07.080]   So--
[01:04:07.080 --> 01:04:07.720]   OK.
[01:04:07.720 --> 01:04:09.600]   Students who complete this training will learn
[01:04:09.600 --> 01:04:11.520]   how biases might affect this.
[01:04:11.520 --> 01:04:13.640]   People ask to describe a photo of bananas.
[01:04:13.640 --> 01:04:18.600]   May not say yellow bananas, because those of us
[01:04:18.600 --> 01:04:19.600]   are in the US.
[01:04:19.600 --> 01:04:22.240]   And I bet in Australia, too, that's all we see, right?
[01:04:22.240 --> 01:04:22.760]   Fair point.
[01:04:22.760 --> 01:04:25.040]   But in many parts of the world, yellow
[01:04:25.040 --> 01:04:27.880]   is not a common color for banana.
[01:04:27.880 --> 01:04:28.160]   They're--
[01:04:28.160 --> 01:04:28.640]   Green.
[01:04:28.640 --> 01:04:29.880]   Pink.
[01:04:29.880 --> 01:04:30.440]   What?
[01:04:30.440 --> 01:04:31.440]   They're green.
[01:04:31.440 --> 01:04:32.280]   They're green.
[01:04:32.280 --> 01:04:33.280]   Green.
[01:04:33.280 --> 01:04:34.280]   Orange.
[01:04:34.280 --> 01:04:35.240]   I was like, what?
[01:04:35.240 --> 01:04:37.040]   I have never, ever heard of this.
[01:04:37.040 --> 01:04:40.760]   That's like how I felt when I heard that Wombats booth cubes.
[01:04:40.760 --> 01:04:41.880]   I was like, what?
[01:04:41.880 --> 01:04:41.880]   What?
[01:04:41.880 --> 01:04:44.080]   Perfect cubes.
[01:04:44.080 --> 01:04:45.320]   Wombats booth cubes.
[01:04:45.320 --> 01:04:47.200]   Now we're going down a whole different road.
[01:04:47.200 --> 01:04:47.840]   Sorry.
[01:04:47.840 --> 01:04:51.280]   Non sequitur, keep going.
[01:04:51.280 --> 01:04:51.800]   They do.
[01:04:51.800 --> 01:04:53.480]   But then there's a lot of designers, too,
[01:04:53.480 --> 01:04:53.960]   and other companies.
[01:04:53.960 --> 01:04:56.440]   If you want to recognize bananas,
[01:04:56.440 --> 01:04:59.400]   and you don't make distinctions about the colors,
[01:04:59.400 --> 01:05:01.400]   you might not ever recognize those bananas
[01:05:01.400 --> 01:05:02.480]   or the red or the green.
[01:05:02.480 --> 01:05:03.680]   Those are plantains.
[01:05:03.680 --> 01:05:05.520]   You might not recognize those because you go, no, no, no.
[01:05:05.520 --> 01:05:07.880]   Every banana I've ever seen is yellow.
[01:05:07.880 --> 01:05:08.120]   Every--
[01:05:08.120 --> 01:05:10.760]   Plantains different the bananas?
[01:05:10.760 --> 01:05:12.200]   They're related.
[01:05:12.200 --> 01:05:13.120]   I know they're related.
[01:05:13.120 --> 01:05:15.360]   They're both banana-y.
[01:05:15.360 --> 01:05:17.240]   Here.
[01:05:17.240 --> 01:05:18.920]   OK.
[01:05:18.920 --> 01:05:20.960]   I have no faith in this discussion anymore.
[01:05:20.960 --> 01:05:21.520]   That's all it's--
[01:05:21.520 --> 01:05:22.480]   I'm trying to though.
[01:05:22.480 --> 01:05:23.640]   I do know that's for a fact.
[01:05:23.640 --> 01:05:24.120]   Look at that.
[01:05:24.120 --> 01:05:24.800]   Red.
[01:05:24.800 --> 01:05:27.160]   There's a pink banana.
[01:05:27.160 --> 01:05:30.600]   The variety of banana that we get in North America
[01:05:30.600 --> 01:05:31.600]   is a model culture.
[01:05:31.600 --> 01:05:32.360]   It's a particular strain.
[01:05:32.360 --> 01:05:32.840]   Yeah.
[01:05:32.840 --> 01:05:33.840]   It's a model culture.
[01:05:33.840 --> 01:05:34.320]   Yes.
[01:05:34.320 --> 01:05:38.120]   They are clones, and they're dying.
[01:05:38.120 --> 01:05:39.720]   Yes.
[01:05:39.720 --> 01:05:43.880]   And they're politically incorrect.
[01:05:43.880 --> 01:05:45.680]   We need new bananas.
[01:05:45.680 --> 01:05:48.760]   Their history and the dual corporations history is horrific.
[01:05:48.760 --> 01:05:49.760]   So--
[01:05:49.760 --> 01:05:50.760]   OK.
[01:05:50.760 --> 01:05:53.560]   That company sometime.
[01:05:53.560 --> 01:05:56.400]   Google has told its employees in an internal memo
[01:05:56.400 --> 01:05:58.480]   that references to sex acts are no longer
[01:05:58.480 --> 01:06:03.360]   allowed in workplace documents or short URLs.
[01:06:03.360 --> 01:06:05.520]   And was that a big problem?
[01:06:05.520 --> 01:06:07.960]   I'm thinking if they had to make a policy,
[01:06:07.960 --> 01:06:10.040]   it might have been.
[01:06:10.040 --> 01:06:10.920]   I guess maybe it was.
[01:06:10.920 --> 01:06:15.720]   By the way, what--
[01:06:15.720 --> 01:06:17.960]   --was a file out of other things you shouldn't have to say.
[01:06:17.960 --> 01:06:19.280]   Shouldn't have to say.
[01:06:19.280 --> 01:06:27.160]   Cavendish, yes.
[01:06:27.160 --> 01:06:28.160]   Yes.
[01:06:28.160 --> 01:06:29.680]   Catrin said Cavendish.
[01:06:29.680 --> 01:06:31.160]   Cavendish.
[01:06:31.160 --> 01:06:32.400]   Should never have to say that.
[01:06:32.400 --> 01:06:38.280]   Did you want to talk about Bloomberg at all?
[01:06:38.280 --> 01:06:39.160]   Oh, God no.
[01:06:39.160 --> 01:06:42.920]   Yes, yes.
[01:06:42.920 --> 01:06:44.280]   But let's finish the change log.
[01:06:44.280 --> 01:06:45.400]   I'm just looking in--
[01:06:45.400 --> 01:06:45.920]   Sorry.
[01:06:45.920 --> 01:06:46.280]   I'm sorry.
[01:06:46.280 --> 01:06:49.160]   --all Kiwis.
[01:06:49.160 --> 01:06:52.760]   All Kiwis schools get a license to Chrome.
[01:06:52.760 --> 01:06:54.040]   And you get a license to Chrome.
[01:06:54.040 --> 01:06:55.600]   And you get a license to Chrome.
[01:06:55.600 --> 01:06:57.360]   I thought we were still talking about fruit.
[01:06:57.360 --> 01:06:59.360]   Yes, we could be.
[01:06:59.360 --> 01:07:01.440]   Why do the Kiwis--
[01:07:01.440 --> 01:07:03.600]   As part of an agreement with the New Zealand Ministry
[01:07:03.600 --> 01:07:05.720]   of Education, all state and state-integrated schools
[01:07:05.720 --> 01:07:08.840]   across New Zealand can claim ministry-funded Chrome
[01:07:08.840 --> 01:07:11.080]   education licenses to manage and use--
[01:07:11.080 --> 01:07:13.080]   I don't know-- Google.
[01:07:13.080 --> 01:07:13.600]   Google.
[01:07:13.600 --> 01:07:15.360]   Oh, it sounds like the Google or the--
[01:07:15.360 --> 01:07:16.360]   They made a deal.
[01:07:16.360 --> 01:07:19.080]   Yeah, they made a deal with the federal department
[01:07:19.080 --> 01:07:19.720]   of education.
[01:07:19.720 --> 01:07:20.560]   Yeah, they made a deal.
[01:07:20.560 --> 01:07:23.280]   Free to you, maybe not to Kiwis.
[01:07:23.280 --> 01:07:24.520]   I have nothing against the Kiwis.
[01:07:24.520 --> 01:07:24.960]   Nothing.
[01:07:25.840 --> 01:07:27.280]   Mm.
[01:07:27.280 --> 01:07:31.040]   How about a better way to share your ETA with Google Maps?
[01:07:31.040 --> 01:07:35.200]   I'm down for that voluntarily.
[01:07:35.200 --> 01:07:36.360]   You drew my text?
[01:07:36.360 --> 01:07:37.360]   Yeah.
[01:07:37.360 --> 01:07:39.360]   How do you do that already?
[01:07:39.360 --> 01:07:41.360]   You can do it.
[01:07:41.360 --> 01:07:43.360]   After you've started navigating to a destination,
[01:07:43.360 --> 01:07:44.920]   tap the up arrow button.
[01:07:44.920 --> 01:07:47.120]   And then on the share trip progress,
[01:07:47.120 --> 01:07:49.960]   you'll be able to share your live location, root an ETA
[01:07:49.960 --> 01:07:51.760]   with all your favorite contacts.
[01:07:51.760 --> 01:07:53.960]   This is Android and iOS.
[01:07:53.960 --> 01:07:57.040]   Today's update also allows for sharing across third party apps
[01:07:57.040 --> 01:07:59.960]   like Facebook, Messenger, Line, WhatsApp, and more.
[01:07:59.960 --> 01:08:00.960]   So they can--
[01:08:00.960 --> 01:08:05.120]   You don't have to just give them maps.
[01:08:05.120 --> 01:08:06.880]   I've always liked that feature.
[01:08:06.880 --> 01:08:09.520]   We've watched people who are late to the show.
[01:08:09.520 --> 01:08:12.680]   We've watched them thrive up here.
[01:08:12.680 --> 01:08:14.720]   I think it was Robert Scobel who was the first to discover
[01:08:14.720 --> 01:08:16.200]   that feature in iOS.
[01:08:16.200 --> 01:08:20.080]   And we watched him speed the whole way.
[01:08:20.080 --> 01:08:20.920]   Did he make it?
[01:08:20.920 --> 01:08:23.240]   Yes.
[01:08:23.240 --> 01:08:25.400]   But not so quickly that we weren't
[01:08:25.400 --> 01:08:30.920]   able to, on the air, live, watch him come here and park
[01:08:30.920 --> 01:08:34.520]   and drive way above the speed.
[01:08:34.520 --> 01:08:36.560]   He must have been driving one of them GM cars.
[01:08:36.560 --> 01:08:38.880]   And that's your Google change log.
[01:08:38.880 --> 01:08:46.200]   [SINGING]
[01:08:46.200 --> 01:08:49.960]   First, the Kiwi was originally known as the Chinese gooseberry.
[01:08:49.960 --> 01:08:50.800]   Yes.
[01:08:50.800 --> 01:08:51.640]   The Kiwi fruit.
[01:08:51.640 --> 01:08:52.480]   But what's that?
[01:08:52.480 --> 01:08:53.480]   Yeah.
[01:08:53.480 --> 01:08:54.560]   It is a gooseberry.
[01:08:54.560 --> 01:08:55.640]   Not the Kiwi people.
[01:08:55.640 --> 01:08:56.760]   [LAUGHTER]
[01:08:56.760 --> 01:08:57.240]   Yes.
[01:08:57.240 --> 01:08:58.280]   No, they were not known.
[01:08:58.280 --> 01:09:02.200]   Those Chinese gooseberries down under.
[01:09:02.200 --> 01:09:04.840]   Like, I really want to call people Chinese gooseberries.
[01:09:04.840 --> 01:09:06.520]   Oh, that's kind of like a love thing.
[01:09:06.520 --> 01:09:08.640]   Kiwi fruit is a gooseberry.
[01:09:08.640 --> 01:09:13.120]   But much like rapeseed oil, they realize no one would buy it
[01:09:13.120 --> 01:09:15.520]   if they didn't rename it.
[01:09:15.520 --> 01:09:18.720]   And I use this often as an example with my kids,
[01:09:18.720 --> 01:09:21.400]   the importance of marketing and particularly
[01:09:21.400 --> 01:09:24.680]   naming, I think the Vikings did that with Greenland
[01:09:24.680 --> 01:09:26.800]   because they were trying to get people to go there.
[01:09:26.800 --> 01:09:28.000]   Well, and you know that--
[01:09:28.000 --> 01:09:29.000]   [INAUDIBLE]
[01:09:29.000 --> 01:09:29.560]   It's green.
[01:09:29.560 --> 01:09:31.920]   Well, they made the mistake of calling Iceland Iceland
[01:09:31.920 --> 01:09:32.920]   and no one went there.
[01:09:32.920 --> 01:09:34.480]   No one went there, exactly.
[01:09:34.480 --> 01:09:35.000]   I wrote my question.
[01:09:35.000 --> 01:09:36.160]   Yeah, that's why no one went there.
[01:09:36.160 --> 01:09:37.400]   Here's another example.
[01:09:37.400 --> 01:09:41.640]   This, the Patagonian toothfish.
[01:09:41.640 --> 01:09:48.080]   No one would really want that unless you named it Chilean sea bass.
[01:09:48.080 --> 01:09:49.080]   Mm-hmm.
[01:09:49.080 --> 01:09:50.960]   And which is delicious.
[01:09:50.960 --> 01:09:56.160]   Delicious Patagonian toothfish to go with your Chinese gooseberry.
[01:09:56.160 --> 01:09:58.520]   Mahima, he was originally--
[01:09:58.520 --> 01:10:01.360]   it's a type of dolphin, but it's not the cute kind.
[01:10:01.360 --> 01:10:02.680]   The good dolphin.
[01:10:02.680 --> 01:10:03.680]   But they didn't want to use--
[01:10:03.680 --> 01:10:04.680]   No, dolphin.
[01:10:04.680 --> 01:10:05.680]   --the word dolphin.
[01:10:05.680 --> 01:10:06.680]   No.
[01:10:06.680 --> 01:10:07.200]   No.
[01:10:07.200 --> 01:10:12.600]   Probably Mahima means bad dolphin in Hawaiian.
[01:10:12.600 --> 01:10:13.600]   Other dolphin.
[01:10:13.600 --> 01:10:15.960]   Other dolphin, the one you can eat.
[01:10:15.960 --> 01:10:16.920]   The edible dolphin.
[01:10:16.920 --> 01:10:20.720]   What makes Mahima he OK to eat then?
[01:10:20.720 --> 01:10:22.760]   It sounds good.
[01:10:22.760 --> 01:10:24.240]   It's not-- they're not under threat.
[01:10:24.240 --> 01:10:26.720]   Like, it's a type of-- it's not even a dolphin, really.
[01:10:26.720 --> 01:10:30.560]   I don't even know why it's called this.
[01:10:30.560 --> 01:10:31.360]   I don't name--
[01:10:31.360 --> 01:10:33.720]   Well, now I'm not going to want to every Mahima again.
[01:10:33.720 --> 01:10:34.240]   Let's look here.
[01:10:34.240 --> 01:10:35.320]   No, it's not a dolphin.
[01:10:35.320 --> 01:10:36.000]   It's a fish.
[01:10:36.000 --> 01:10:36.760]   No, it's a fish.
[01:10:36.760 --> 01:10:37.280]   There you go.
[01:10:37.280 --> 01:10:40.040]   It's the pompano dolphin fish.
[01:10:40.040 --> 01:10:42.240]   Yeah, so there's-- it has a dolphin in it.
[01:10:42.240 --> 01:10:44.160]   Yeah, or Dorado.
[01:10:44.160 --> 01:10:45.360]   Actually, I've seen this in Dorado.
[01:10:45.360 --> 01:10:46.440]   Oh, comes from the Hawaiian language.
[01:10:46.440 --> 01:10:47.560]   Very strong.
[01:10:47.560 --> 01:10:48.080]   Yeah.
[01:10:48.080 --> 01:10:48.640]   It means very strong.
[01:10:48.640 --> 01:10:50.440]   Very strong.
[01:10:50.440 --> 01:10:51.440]   Very strong.
[01:10:51.440 --> 01:10:52.440]   I don't know.
[01:10:52.440 --> 01:10:53.840]   That's strong, though, really.
[01:10:53.840 --> 01:10:56.360]   It isn't closely related to dolphins.
[01:10:56.360 --> 01:11:00.080]   It's just called the dolphin fish, but it's not related.
[01:11:00.080 --> 01:11:01.520]   They're fugly looking fish.
[01:11:01.520 --> 01:11:02.880]   Yeah.
[01:11:02.880 --> 01:11:07.520]   In Malta, they call them the lampuka.
[01:11:07.520 --> 01:11:08.040]   Nice.
[01:11:08.040 --> 01:11:09.440]   Also a bad name.
[01:11:09.440 --> 01:11:10.400]   Put that on the menu.
[01:11:10.400 --> 01:11:18.800]   Have lampuka for dinner, everyone.
[01:11:18.800 --> 01:11:19.800]   Let's take a break.
[01:11:19.800 --> 01:11:20.300]   You know what?
[01:11:20.300 --> 01:11:23.840]   I'm going to get you out of here fast, because Stacy is faint.
[01:11:23.840 --> 01:11:24.520]   Oh, I'm sorry.
[01:11:24.520 --> 01:11:25.320]   I'm focused.
[01:11:25.320 --> 01:11:27.040]   Well, I'm reading now about Mahi Mahi.
[01:11:27.040 --> 01:11:30.080]   Oh, you see the rat holes we get into.
[01:11:30.080 --> 01:11:31.680]   Are you getting one of them roadiimatics?
[01:11:31.680 --> 01:11:33.440]   We still haven't really decided who's
[01:11:33.440 --> 01:11:34.720]   getting the roadiimatic.
[01:11:34.720 --> 01:11:35.520]   Oh, you know what?
[01:11:35.520 --> 01:11:37.960]   They've offered me a review unit, so I can take one.
[01:11:37.960 --> 01:11:38.120]   What?
[01:11:38.120 --> 01:11:41.840]   If you really want me to do a tortilla analysis.
[01:11:41.840 --> 01:11:42.960]   What's a roadiim--
[01:11:42.960 --> 01:11:45.600]   It's an automated roadi maker.
[01:11:45.600 --> 01:11:46.600]   What?
[01:11:46.600 --> 01:11:51.080]   Now, I would buy an automated Montreal bagel maker.
[01:11:51.080 --> 01:11:51.600]   But--
[01:11:51.600 --> 01:11:52.280]   Yeah.
[01:11:52.280 --> 01:11:53.360]   Montreal bagels?
[01:11:53.360 --> 01:11:54.600]   What?
[01:11:54.600 --> 01:11:55.600]   Oh, she's a rat.
[01:11:55.600 --> 01:11:57.000]   Tuck it into the bagel bag.
[01:11:57.000 --> 01:11:58.000]   Oh.
[01:11:58.000 --> 01:11:58.840]   Oh.
[01:11:58.840 --> 01:12:00.840]   She doesn't know from bagels.
[01:12:00.840 --> 01:12:02.160]   She's in Austin.
[01:12:02.160 --> 01:12:04.200]   When do you move to Seattle?
[01:12:04.200 --> 01:12:05.520]   June.
[01:12:05.520 --> 01:12:08.600]   You'll hear a lot more coming in, because I've got a whole thing.
[01:12:08.600 --> 01:12:08.840]   What?
[01:12:08.840 --> 01:12:09.840]   Whoa.
[01:12:09.840 --> 01:12:11.040]   What?
[01:12:11.040 --> 01:12:14.160]   OK, Matthew, I tweeted this, and I told people--
[01:12:14.160 --> 01:12:15.760]   Don't you read Twitter religiously,
[01:12:15.760 --> 01:12:18.560]   and if you miss something, go back and look at it.
[01:12:18.560 --> 01:12:20.480]   I think I blocked Stacy at one point.
[01:12:20.480 --> 01:12:21.480]   No, this is why--
[01:12:21.480 --> 01:12:23.120]   Is it my insults to Canadians?
[01:12:23.120 --> 01:12:23.760]   No, no, no.
[01:12:23.760 --> 01:12:28.040]   I feel so righteous when I say what I don't read Twitter.
[01:12:28.040 --> 01:12:29.200]   What is going on?
[01:12:29.200 --> 01:12:30.680]   What's the deal?
[01:12:30.680 --> 01:12:33.040]   I move into Seattle in June, because I've
[01:12:33.040 --> 01:12:34.880]   wanted to live there for a while.
[01:12:34.880 --> 01:12:37.560]   And because I've lived in Austin for 20 years,
[01:12:37.560 --> 01:12:39.160]   and it's time to get out of here.
[01:12:39.160 --> 01:12:41.080]   But you have that great house.
[01:12:41.080 --> 01:12:42.120]   I do.
[01:12:42.120 --> 01:12:44.320]   I'll have a great house elsewhere.
[01:12:44.320 --> 01:12:47.640]   So have you started house hunting?
[01:12:47.640 --> 01:12:49.440]   We're going to rent for a year.
[01:12:49.440 --> 01:12:51.280]   We're going to rent on Bainbridge Island.
[01:12:51.280 --> 01:12:53.560]   Oh, I love Bainbridge Island.
[01:12:53.560 --> 01:12:55.200]   We're going to see if we're island people.
[01:12:55.200 --> 01:12:57.480]   I have family there.
[01:12:57.480 --> 01:12:58.000]   Excellent.
[01:12:58.000 --> 01:13:00.080]   Bainbridge is an ice island, because it has a bridge.
[01:13:00.080 --> 01:13:04.000]   We've been looking at an island that doesn't have a bridge.
[01:13:04.000 --> 01:13:04.840]   It's risky, man.
[01:13:04.840 --> 01:13:05.880]   Well--
[01:13:05.880 --> 01:13:06.440]   Good for you.
[01:13:06.440 --> 01:13:07.320]   Yeah, that was great.
[01:13:07.320 --> 01:13:07.840]   Good for you.
[01:13:07.840 --> 01:13:08.720]   That's beautiful area.
[01:13:08.720 --> 01:13:11.040]   We may end up up there with you.
[01:13:11.040 --> 01:13:13.920]   Ah, the Twig Studio could move.
[01:13:13.920 --> 01:13:16.760]   Oh, no, you'd be retired.
[01:13:16.760 --> 01:13:22.280]   You know, I think this is not exactly a job one retires from.
[01:13:22.280 --> 01:13:25.040]   Because basically it involves sitting in a chair and talking.
[01:13:25.040 --> 01:13:26.760]   I was like, are you going to keel over in your chair?
[01:13:26.760 --> 01:13:28.600]   Because I do not want to be on the air for that.
[01:13:28.600 --> 01:13:30.560]   I'm going to feel terrible.
[01:13:30.560 --> 01:13:31.520]   That would be great.
[01:13:31.520 --> 01:13:33.880]   I want to die in the saddle, so to speak.
[01:13:33.880 --> 01:13:34.840]   Prior to--
[01:13:34.840 --> 01:13:38.080]   He was a comfortable chair, as it were.
[01:13:38.080 --> 01:13:41.120]   He retired.
[01:13:41.120 --> 01:13:43.160]   What am I going to retire to?
[01:13:43.160 --> 01:13:44.680]   Sitting in a chair and talking.
[01:13:44.680 --> 01:13:49.560]   Sitting in a chair and not talking on the TV.
[01:13:49.560 --> 01:13:50.720]   Just talking to nobody.
[01:13:50.720 --> 01:13:52.160]   Just talking to nobody.
[01:13:52.160 --> 01:13:54.400]   Does that sound like fun?
[01:13:54.400 --> 01:13:55.200]   No, all right.
[01:13:55.200 --> 01:13:56.880]   Yeah, you're going to have a Facebook livestream.
[01:13:56.880 --> 01:13:58.040]   People's doing it at 7.
[01:13:58.040 --> 01:14:00.360]   I told Stacey, get the road, hematic.
[01:14:00.360 --> 01:14:10.200]   By the way, Heston Q used once hanging on the rack.
[01:14:10.200 --> 01:14:12.440]   Looks pretty.
[01:14:12.440 --> 01:14:14.640]   You could probably sell it on eBay.
[01:14:14.640 --> 01:14:18.480]   The problem with it is, A, just as you said,
[01:14:18.480 --> 01:14:20.200]   who doesn't know how to use a pan?
[01:14:20.200 --> 01:14:27.760]   B, it's all designed around videos and recipes
[01:14:27.760 --> 01:14:31.200]   on the iPad or the tablet.
[01:14:31.200 --> 01:14:33.920]   So you say, oh, I want to make--
[01:14:33.920 --> 01:14:34.280]   Right.
[01:14:34.280 --> 01:14:35.480]   Stu.
[01:14:35.480 --> 01:14:38.920]   Now you have to watch a whole video and the thing.
[01:14:38.920 --> 01:14:43.280]   And then because you can manually control that burner,
[01:14:43.280 --> 01:14:44.200]   but it does things.
[01:14:44.200 --> 01:14:47.600]   It's got a mind of its own.
[01:14:47.600 --> 01:14:50.320]   Give it to both of your kids know how to cook?
[01:14:50.320 --> 01:14:51.640]   Because that's who you should give it to.
[01:14:51.640 --> 01:14:53.720]   Someone who doesn't know how to cook.
[01:14:53.720 --> 01:14:54.800]   Yeah, actually.
[01:14:54.800 --> 01:14:58.000]   It would be like a hot plate without being a hot plate,
[01:14:58.000 --> 01:14:59.760]   because it's an induction burner.
[01:14:59.760 --> 01:15:01.720]   And $800 hot plate.
[01:15:01.720 --> 01:15:04.600]   [LAUGHTER]
[01:15:04.600 --> 01:15:06.240]   Yes.
[01:15:06.240 --> 01:15:08.240]   And well, to add insult to injury,
[01:15:08.240 --> 01:15:10.520]   that pretty much the same time frame I bought the Facebook
[01:15:10.520 --> 01:15:12.080]   portals.
[01:15:12.080 --> 01:15:13.080]   Oh.
[01:15:13.080 --> 01:15:14.120]   Oh, you did?
[01:15:14.120 --> 01:15:15.640]   Yeah, oh, yeah.
[01:15:15.640 --> 01:15:17.880]   Matthew will test him out with you.
[01:15:17.880 --> 01:15:18.880]   That he will.
[01:15:18.880 --> 01:15:19.720]   See?
[01:15:19.720 --> 01:15:21.080]   He doesn't care about privacy.
[01:15:21.080 --> 01:15:23.960]   Yeah, he's like, gee, I'm listening to my radio.
[01:15:23.960 --> 01:15:26.160]   Facebook, come to my house.
[01:15:26.160 --> 01:15:28.160]   I'm going to get a Huawei portal.
[01:15:28.160 --> 01:15:29.800]   He's got the P20.
[01:15:29.800 --> 01:15:31.160]   Get the Huawei portal.
[01:15:31.160 --> 01:15:33.400]   You already have it, my friend.
[01:15:33.400 --> 01:15:35.560]   I showed it--
[01:15:35.560 --> 01:15:37.120]   Oh.
[01:15:37.120 --> 01:15:39.400]   Our show today brought to you by Digital Ocean.
[01:15:39.400 --> 01:15:40.720]   I am a Digital Ocean fan.
[01:15:40.720 --> 01:15:43.000]   Digital Ocean is one of those companies
[01:15:43.000 --> 01:15:44.080]   you may not have heard of.
[01:15:44.080 --> 01:15:48.760]   I guess if you're a developer, or you're a startup, you have.
[01:15:48.760 --> 01:15:51.080]   But I think a lot of people don't know about Digital Ocean,
[01:15:51.080 --> 01:15:53.600]   because it's one of those things that
[01:15:53.600 --> 01:15:57.360]   is really making a huge difference.
[01:15:57.360 --> 01:16:02.560]   It is an innovation engine for the modern times.
[01:16:02.560 --> 01:16:03.600]   And here's why I say that.
[01:16:03.600 --> 01:16:06.800]   Went back when my friend Kevin Rose started Dig.
[01:16:06.800 --> 01:16:10.040]   The long, late, lamented Dig.
[01:16:10.040 --> 01:16:10.680]   I remember him.
[01:16:10.680 --> 01:16:15.720]   He had to buy a colos server and then buy a server.
[01:16:15.720 --> 01:16:19.000]   He had to go to the colo, put the server in.
[01:16:19.000 --> 01:16:20.320]   He had a configurate.
[01:16:20.320 --> 01:16:21.200]   He had to set it up.
[01:16:21.200 --> 01:16:25.520]   And then he had one server that could run Dig.
[01:16:25.520 --> 01:16:28.200]   Fast forward to 2018.
[01:16:28.200 --> 01:16:32.360]   If you've got an idea for a technology to change the world,
[01:16:32.360 --> 01:16:36.120]   if you've got an app that you want to put online,
[01:16:36.120 --> 01:16:37.600]   a website you want to put online,
[01:16:37.600 --> 01:16:40.520]   if you want to learn how to make apps or websites,
[01:16:40.520 --> 01:16:44.880]   if you want to play with ideas, do what we call nowadays,
[01:16:44.880 --> 01:16:47.520]   a minimum viable product.
[01:16:47.520 --> 01:16:50.600]   Digital Ocean makes it-- not only makes it easy,
[01:16:50.600 --> 01:16:52.960]   makes it very affordable.
[01:16:52.960 --> 01:17:00.200]   It is powering the transformation of the world, I think.
[01:17:00.200 --> 01:17:00.880]   And I love it.
[01:17:00.880 --> 01:17:02.000]   So what is Digital Ocean?
[01:17:02.000 --> 01:17:06.120]   It's the industry leader in cloud platforms.
[01:17:06.120 --> 01:17:10.360]   Makes it easy to deploy, manage, and scale applications.
[01:17:10.360 --> 01:17:12.720]   What you do is you create a droplet.
[01:17:12.720 --> 01:17:15.720]   See, you get a droplet in the ocean.
[01:17:15.720 --> 01:17:17.400]   You create a droplet.
[01:17:17.400 --> 01:17:20.680]   And that droplet is basically a provision server
[01:17:20.680 --> 01:17:25.400]   that'll be ready for you to use in a minute in any way you
[01:17:25.400 --> 01:17:26.200]   want.
[01:17:26.200 --> 01:17:29.680]   With 99.99% uptime, and they've got an SLA
[01:17:29.680 --> 01:17:31.920]   for that cloud firewalls, you get
[01:17:31.920 --> 01:17:36.480]   monitoring, you get alerting, you get a full DNS management,
[01:17:36.480 --> 01:17:39.400]   you get a public IP address that you can then
[01:17:39.400 --> 01:17:41.920]   use with your domain name if you want.
[01:17:41.920 --> 01:17:44.680]   You get enterprise SSDs.
[01:17:44.680 --> 01:17:46.560]   Very easy to use API.
[01:17:46.560 --> 01:17:50.440]   So 150,000 businesses, including some of the world's
[01:17:50.440 --> 01:17:55.200]   fastest growing startups, have been using Digital Ocean
[01:17:55.200 --> 01:18:00.080]   to get their first minimum viable product up
[01:18:00.080 --> 01:18:06.360]   to create a product without a whole lot of costs.
[01:18:06.360 --> 01:18:08.720]   And I mean, when I mean affordable,
[01:18:08.720 --> 01:18:11.720]   it starts at $5 a month.
[01:18:11.720 --> 01:18:14.560]   So in fact, I'll show you real quickly.
[01:18:14.560 --> 01:18:16.120]   I like to do this on the show.
[01:18:16.120 --> 01:18:17.560]   I'm going to set up a droplet.
[01:18:17.560 --> 01:18:20.360]   I have three droplets running right now.
[01:18:20.360 --> 01:18:23.720]   Total of $7.90.
[01:18:23.720 --> 01:18:25.280]   I mean, that's what we're talking about.
[01:18:25.280 --> 01:18:27.720]   Let me show you how easy it is to create a droplet.
[01:18:27.720 --> 01:18:28.800]   You could choose an image.
[01:18:28.800 --> 01:18:31.080]   So if you just say, look, I want an Ubuntu running,
[01:18:31.080 --> 01:18:35.240]   or a free BSD running ZFS, or Fedora or Debian or CentOS,
[01:18:35.240 --> 01:18:39.120]   you can even select the version, which is really pretty amazing.
[01:18:39.120 --> 01:18:42.560]   I like to run a really stable Debian 8.1, right?
[01:18:42.560 --> 01:18:45.840]   So that could be it, but you could also use containers.
[01:18:45.840 --> 01:18:50.280]   Or let's say you know, no, I want to do some node programming.
[01:18:50.280 --> 01:18:51.960]   I want node JS.
[01:18:51.960 --> 01:18:53.920]   I'm going to write a node application.
[01:18:53.920 --> 01:18:57.600]   So all I do is I say, OK, I'm going to create a node JS.
[01:18:57.600 --> 01:19:00.840]   It'll be running on Ubuntu 18.04.
[01:19:00.840 --> 01:19:05.000]   I want-- I'm going to do it cheap-- $5 a month, or 0.007
[01:19:05.000 --> 01:19:06.200]   cents an hour.
[01:19:06.200 --> 01:19:09.520]   That gives me a virtual CPU, 25 gigs of storage, a terabyte
[01:19:09.520 --> 01:19:12.600]   of transfer, plenty for an MVP.
[01:19:12.600 --> 01:19:15.520]   I always enable backups in case I do something good.
[01:19:15.520 --> 01:19:18.240]   Choose your server all over the world, Frankfurt, London,
[01:19:18.240 --> 01:19:20.840]   Singapore, Amsterdam, Toronto, Bangalore, New York.
[01:19:20.840 --> 01:19:23.720]   I always choose San Francisco, because it's nearby.
[01:19:23.720 --> 01:19:25.240]   I like it with the SSH key.
[01:19:25.240 --> 01:19:27.200]   See, I can use my SSH key to log in.
[01:19:27.200 --> 01:19:28.240]   That's very handy.
[01:19:28.240 --> 01:19:31.440]   They got IPv6 private networking, lots more stuff.
[01:19:31.440 --> 01:19:34.920]   Name it, Leo's node.
[01:19:34.920 --> 01:19:35.440]   Watch this.
[01:19:35.440 --> 01:19:37.800]   I am going to create my droplet.
[01:19:37.800 --> 01:19:41.000]   This is literally provisioning a server that's
[01:19:41.000 --> 01:19:47.000]   going to be very inexpensive and ready to use in about a minute.
[01:19:47.000 --> 01:19:50.480]   It's a great way to create your first website,
[01:19:50.480 --> 01:19:54.880]   to learn how to write code, to create a minimum viable application
[01:19:54.880 --> 01:19:56.520]   for your new startup.
[01:19:56.520 --> 01:19:58.680]   This is what's transforming the world, in my opinion.
[01:19:58.680 --> 01:20:00.200]   I love the jolotian.
[01:20:00.200 --> 01:20:03.120]   I love what this means for entrepreneurs.
[01:20:03.120 --> 01:20:05.800]   You could choose from standard or CPU's optimized droplets,
[01:20:05.800 --> 01:20:06.720]   customized from there.
[01:20:06.720 --> 01:20:08.320]   They now have volumes.
[01:20:08.320 --> 01:20:10.080]   It's easy to add volumes.
[01:20:10.080 --> 01:20:13.560]   So if you need more storage, it's easy to get-- oh, it's done.
[01:20:13.560 --> 01:20:17.320]   I now have a node server running at this address.
[01:20:17.320 --> 01:20:18.720]   It's really awesome.
[01:20:18.720 --> 01:20:21.480]   I can log into it via SSH.
[01:20:21.480 --> 01:20:24.760]   I can start writing my node code right now.
[01:20:24.760 --> 01:20:26.160]   Fantastic.
[01:20:26.160 --> 01:20:30.400]   Say hi to 138.68 to 17.123.
[01:20:30.400 --> 01:20:32.040]   dio.co/twit.
[01:20:32.040 --> 01:20:33.680]   It's going to get even more affordable right now.
[01:20:33.680 --> 01:20:35.560]   If you go to dio.co/twit, we're going
[01:20:35.560 --> 01:20:38.040]   to give you a free $100 credit.
[01:20:38.040 --> 01:20:41.360]   That's going to give you quite a lot of time
[01:20:41.360 --> 01:20:43.800]   to play with this for free.
[01:20:43.800 --> 01:20:45.960]   And it integrates with everything you're already using.
[01:20:45.960 --> 01:20:49.800]   dio.co/twit, a $300 credit.
[01:20:49.800 --> 01:20:53.280]   I always tell students, get an account of digital ocean,
[01:20:53.280 --> 01:20:55.400]   so that when you start learning how to code,
[01:20:55.400 --> 01:20:56.960]   you can do it in a real world environment.
[01:20:56.960 --> 01:20:59.640]   You can even invite your friends to use your new site.
[01:20:59.640 --> 01:21:01.320]   And for businesses, too, it's a great way
[01:21:01.320 --> 01:21:04.200]   to get started without having to buy server hardware
[01:21:04.200 --> 01:21:06.400]   or wait for provisioning days at a time.
[01:21:06.400 --> 01:21:12.120]   dio.co/twit, $100 credit right now at digital ocean.
[01:21:12.120 --> 01:21:13.720]   Love digital ocean.
[01:21:13.720 --> 01:21:19.320]   I'm going to give you a few.
[01:21:19.320 --> 01:21:22.440]   I want to read an item from the Bainbridge Island police
[01:21:22.440 --> 01:21:23.040]   blotter.
[01:21:23.040 --> 01:21:23.560]   Can I do this?
[01:21:23.560 --> 01:21:25.320]   Yes, please.
[01:21:25.320 --> 01:21:26.360]   OK.
[01:21:26.360 --> 01:21:27.840]   Random selection.
[01:21:27.840 --> 01:21:30.880]   A person or persons yet unknown forced their way
[01:21:30.880 --> 01:21:33.800]   into a pasture on Island Center Road
[01:21:33.800 --> 01:21:37.520]   and stole a horse exercise ball while several of the animals
[01:21:37.520 --> 01:21:38.040]   were present.
[01:21:38.040 --> 01:21:41.960]   Yes.
[01:21:41.960 --> 01:21:43.240]   We read the local paper.
[01:21:43.240 --> 01:21:44.840]   It is awesome.
[01:21:44.840 --> 01:21:46.400]   There are no suspects.
[01:21:46.400 --> 01:21:48.000]   Of course not.
[01:21:48.000 --> 01:21:50.520]   But somebody's got an illicit horse exercise
[01:21:50.520 --> 01:21:52.240]   ball in their living room.
[01:21:52.240 --> 01:21:55.040]   Is that like a normal exercise ball?
[01:21:55.040 --> 01:21:57.160]   I think so, but larger problems.
[01:21:57.160 --> 01:22:00.440]   OK, I was like, wait, what is a horse?
[01:22:00.440 --> 01:22:02.280]   Maybe somebody just needed a really big one.
[01:22:02.280 --> 01:22:05.560]   And that's they couldn't think of how it was to get them.
[01:22:05.560 --> 01:22:06.000]   Yeah.
[01:22:06.000 --> 01:22:06.520]   It's very--
[01:22:06.520 --> 01:22:06.520]   It's very--
[01:22:06.520 --> 01:22:07.280]   It is an island.
[01:22:07.280 --> 01:22:09.200]   You wouldn't want to have to drive off to order something.
[01:22:09.200 --> 01:22:11.160]   And there is no prime now.
[01:22:11.160 --> 01:22:12.120]   There's no prime?
[01:22:12.120 --> 01:22:13.120]   Oh, there's no prime now.
[01:22:13.120 --> 01:22:13.960]   There's no prime now.
[01:22:13.960 --> 01:22:14.400]   No.
[01:22:14.400 --> 01:22:15.360]   Because there is a bridge.
[01:22:15.360 --> 01:22:17.360]   So you do get deliveries and stuff.
[01:22:17.360 --> 01:22:18.320]   Yes, yes.
[01:22:18.320 --> 01:22:20.600]   My-- like I said, my aunt and uncle live there.
[01:22:20.600 --> 01:22:22.920]   And they love it.
[01:22:22.920 --> 01:22:25.560]   Well, ScooterX says his business partner lives there.
[01:22:25.560 --> 01:22:26.280]   Nice.
[01:22:26.280 --> 01:22:28.680]   My late uncle also lived there.
[01:22:28.680 --> 01:22:29.760]   He built one of those--
[01:22:29.760 --> 01:22:30.600]   you might as well do this.
[01:22:30.600 --> 01:22:32.840]   He got a Lindelceder home, one of those log homes
[01:22:32.840 --> 01:22:34.920]   that they've ever built it himself.
[01:22:34.920 --> 01:22:38.320]   Oh, there's the exercise ball.
[01:22:38.320 --> 01:22:39.440]   I think that's art.
[01:22:39.440 --> 01:22:40.160]   Oh, is that art?
[01:22:40.160 --> 01:22:40.960]   OK.
[01:22:40.960 --> 01:22:42.520]   Thanks, I guess.
[01:22:42.520 --> 01:22:48.480]   And he was in the CIA, and he retired to Bainbridge Island.
[01:22:48.480 --> 01:22:49.480]   There's a complaint.
[01:22:49.480 --> 01:22:49.960]   I feel safer already.
[01:22:49.960 --> 01:22:50.800]   Yeah.
[01:22:50.800 --> 01:22:53.880]   I'm the councilman in proper conduct
[01:22:53.880 --> 01:22:57.840]   because he called a hotel owner a liar, seven times during--
[01:22:57.840 --> 01:23:00.440]   You saw a liar.
[01:23:00.440 --> 01:23:02.400]   --televised counseling.
[01:23:02.400 --> 01:23:05.440]   Did he challenge him to a duel afterwards?
[01:23:05.440 --> 01:23:08.800]   This is where you want to live, I swear.
[01:23:08.800 --> 01:23:09.720]   Yeah, I don't.
[01:23:09.720 --> 01:23:10.880]   But my family really does.
[01:23:10.880 --> 01:23:12.440]   And it gets me closer to the Pacific Northwest.
[01:23:12.440 --> 01:23:15.160]   Yeah, they'll get tired of it pretty quick.
[01:23:15.160 --> 01:23:17.320]   You don't want to live there?
[01:23:17.320 --> 01:23:19.320]   I don't-- you want to live in Seattle, don't you?
[01:23:19.320 --> 01:23:20.520]   You want to live in Seattle?
[01:23:20.520 --> 01:23:22.520]   I'm a little more urban than the rest of my family.
[01:23:22.520 --> 01:23:23.520]   Oh, OK.
[01:23:23.520 --> 01:23:24.720]   Yeah.
[01:23:24.720 --> 01:23:26.240]   I'll go live in there with him.
[01:23:26.240 --> 01:23:27.800]   There's good kayaking.
[01:23:27.800 --> 01:23:29.360]   There is good kayaking.
[01:23:29.360 --> 01:23:32.040]   But it's only during certain months of the year.
[01:23:32.040 --> 01:23:33.040]   It's like Canada, actually.
[01:23:33.040 --> 01:23:33.800]   What am I saying?
[01:23:33.800 --> 01:23:34.240]   OK.
[01:23:34.240 --> 01:23:36.200]   It's just Canada.
[01:23:36.200 --> 01:23:38.840]   Do they get ice?
[01:23:38.840 --> 01:23:40.920]   I don't know.
[01:23:40.920 --> 01:23:41.840]   I don't know.
[01:23:41.840 --> 01:23:42.680]   I mean, I'm sure they do.
[01:23:42.680 --> 01:23:44.800]   I think they like that ice.
[01:23:44.800 --> 01:23:45.880]   But not like--
[01:23:45.880 --> 01:23:47.840]   It doesn't stick.
[01:23:47.840 --> 01:23:49.200]   OK, then it doesn't matter.
[01:23:49.200 --> 01:23:49.960]   Yeah.
[01:23:49.960 --> 01:23:52.480]   It's not like you get a week of ice or anything.
[01:23:52.480 --> 01:23:53.520]   No, no, no.
[01:23:53.520 --> 01:23:55.320]   It is an island where you search.
[01:23:55.320 --> 01:24:01.080]   So you do get a lot of power outages and internet outages.
[01:24:01.080 --> 01:24:03.440]   So I'm going to have two internet service providers,
[01:24:03.440 --> 01:24:05.480]   both Comcast, who serves the area,
[01:24:05.480 --> 01:24:08.440]   and a local DSL provider.
[01:24:08.440 --> 01:24:10.240]   And a windmill?
[01:24:10.240 --> 01:24:11.640]   And also a windmill.
[01:24:11.640 --> 01:24:12.560]   And a little hamster.
[01:24:12.560 --> 01:24:15.240]   I don't wheel.
[01:24:15.240 --> 01:24:17.360]   So I am going to give you a chance.
[01:24:17.360 --> 01:24:19.840]   We have talked a lot about the Bloomberg Supermaker story.
[01:24:19.840 --> 01:24:21.760]   We've gone back and forth.
[01:24:21.760 --> 01:24:23.720]   Each of our hosts--
[01:24:23.720 --> 01:24:25.520]   well, no, but I would actually love your take on this.
[01:24:25.520 --> 01:24:29.160]   Each of our hosts has widely differing opinions.
[01:24:29.160 --> 01:24:34.000]   Steve Gibson and I feel like Bloomberg didn't make this up.
[01:24:34.000 --> 01:24:37.160]   But we've had people like Andy Inako and Greg Farrow on Twitter,
[01:24:37.160 --> 01:24:39.920]   just as recently as Sunday, say it's bollocks,
[01:24:39.920 --> 01:24:45.080]   and that Tim Cook and Amazon's demands for retractions
[01:24:45.080 --> 01:24:51.760]   are right, and Bloomberg should retract the story.
[01:24:51.760 --> 01:24:52.040]   Matt?
[01:24:52.040 --> 01:24:57.920]   So I mean, Bloomberg-- it's not like this just showed up
[01:24:57.920 --> 01:24:59.200]   on some guy's blog.
[01:24:59.200 --> 01:25:02.080]   I mean, Bloomberg has been around for a while,
[01:25:02.080 --> 01:25:05.000]   and they know what they're doing.
[01:25:05.000 --> 01:25:07.760]   So that's my first starting point.
[01:25:07.760 --> 01:25:12.080]   So obviously, there's something going on.
[01:25:12.080 --> 01:25:15.040]   And they claim they have 17 different sources.
[01:25:15.040 --> 01:25:17.880]   But the denials that we've seen--
[01:25:17.880 --> 01:25:21.440]   like typically, you get denials that are super vague.
[01:25:21.440 --> 01:25:26.400]   These are extremely detailed and explicit denials.
[01:25:26.400 --> 01:25:31.000]   Denials of every single alleged fact-- denials
[01:25:31.000 --> 01:25:33.440]   that any company is under a gag order,
[01:25:33.440 --> 01:25:36.200]   so even if it was a top secret investigation--
[01:25:36.200 --> 01:25:40.480]   denials that are so specific, writing letters to Congress,
[01:25:40.480 --> 01:25:41.480]   saying it's not true.
[01:25:41.480 --> 01:25:46.960]   Like, that's not something you do if there's any truth to it.
[01:25:46.960 --> 01:25:49.640]   So then you have a source.
[01:25:49.640 --> 01:25:52.240]   One of the only named sources says,
[01:25:52.240 --> 01:25:55.200]   well, I sketched out a hypothetical way
[01:25:55.200 --> 01:25:58.640]   that this could happen in the facts all match identically
[01:25:58.640 --> 01:26:00.680]   with my hypothetical.
[01:26:00.680 --> 01:26:02.840]   So that makes me nervous.
[01:26:02.840 --> 01:26:07.600]   And then there's a guy who writes a blog all about network
[01:26:07.600 --> 01:26:09.280]   architecture and servers.
[01:26:09.280 --> 01:26:13.160]   I don't know him, but he did a five page analysis
[01:26:13.160 --> 01:26:16.360]   of the description that Bloomberg gave
[01:26:16.360 --> 01:26:20.880]   and said it's not only not plausible, in some cases,
[01:26:20.880 --> 01:26:25.760]   it's functionally impossible for the things they describe
[01:26:25.760 --> 01:26:28.320]   doing things to do those things.
[01:26:28.320 --> 01:26:29.920]   And even if you wanted to do those things,
[01:26:29.920 --> 01:26:31.880]   you wouldn't do them in that way.
[01:26:31.880 --> 01:26:33.880]   You would do them through software
[01:26:33.880 --> 01:26:35.880]   or through different types of chips.
[01:26:35.880 --> 01:26:38.520]   And so I just have this huge--
[01:26:38.520 --> 01:26:41.240]   it's not that I don't trust Bloomberg.
[01:26:41.240 --> 01:26:46.680]   I do, but it just feels wrong in some way.
[01:26:46.680 --> 01:26:48.760]   So that's the question is if it is--
[01:26:48.760 --> 01:26:51.120]   and you've got John Mecklethwaite, their editor in chief.
[01:26:51.120 --> 01:26:52.560]   And by the way, I talked to Mark Millian,
[01:26:52.560 --> 01:26:54.520]   who writes at Bloomberg Business Week
[01:26:54.520 --> 01:26:56.120]   a couple of tweets ago.
[01:26:56.120 --> 01:26:58.760]   He said Mecklethwaite was involved in this story
[01:26:58.760 --> 01:27:01.080]   from its inception two years ago.
[01:27:01.080 --> 01:27:05.480]   This goes back to Obama administration sources,
[01:27:05.480 --> 01:27:09.760]   as well as Trump administration sources, two years ago.
[01:27:09.760 --> 01:27:13.640]   And Mecklethwaite is highly respected in the industry.
[01:27:13.640 --> 01:27:15.080]   He said he was very much involved
[01:27:15.080 --> 01:27:18.120]   in vetting these sources and vetting this story.
[01:27:18.120 --> 01:27:20.320]   So to me, it's a great puzzlement.
[01:27:20.320 --> 01:27:22.080]   Now, somebody told me--
[01:27:22.080 --> 01:27:25.000]   I think we need more-- so Eric Wempel at the Washington Post
[01:27:25.000 --> 01:27:28.400]   wrote up something about it in which he said,
[01:27:28.400 --> 01:27:30.840]   "Bloomberg has to come up with more.
[01:27:30.840 --> 01:27:31.680]   They have to--"
[01:27:31.680 --> 01:27:33.280]   Well, one would think that if it's a true story,
[01:27:33.280 --> 01:27:35.200]   others will come up with more as well, right?
[01:27:35.200 --> 01:27:37.440]   They'll say that you'll have one of these motherboards.
[01:27:37.440 --> 01:27:38.920]   Theoretically.
[01:27:38.920 --> 01:27:43.040]   Well, yeah, because I mean, the second we saw that Bloomberg
[01:27:43.040 --> 01:27:45.040]   story, everybody called everybody they knew
[01:27:45.040 --> 01:27:46.560]   to try to follow this.
[01:27:46.560 --> 01:27:51.880]   I mean, and while there are very few hardcore enterprise
[01:27:51.880 --> 01:27:55.800]   server type reporters out there, they still do exist.
[01:27:55.800 --> 01:27:59.160]   And I even called some people I know and talked to them
[01:27:59.160 --> 01:28:01.040]   about it.
[01:28:01.040 --> 01:28:02.480]   I guess on the other hand, I would
[01:28:02.480 --> 01:28:05.960]   expect none of these companies to admit it.
[01:28:05.960 --> 01:28:07.400]   Not only is it bad for businesses,
[01:28:07.400 --> 01:28:09.360]   probably they're under gag order.
[01:28:09.360 --> 01:28:14.840]   And so, you know, it's very likely that the intelligence
[01:28:14.840 --> 01:28:17.800]   community has told everybody under no circumstances
[01:28:17.800 --> 01:28:19.840]   are you to tell anybody this happened.
[01:28:19.840 --> 01:28:22.120]   But that's why I would have expected that it has to be
[01:28:22.120 --> 01:28:24.000]   a lot more general.
[01:28:24.000 --> 01:28:26.000]   And we would have followed up on it.
[01:28:26.000 --> 01:28:31.200]   Like, I just-- I was reading Seymour Hershey's biography,
[01:28:31.200 --> 01:28:33.640]   right, just actually two weeks ago.
[01:28:33.640 --> 01:28:37.280]   And one of the astonishing things that still remains true
[01:28:37.280 --> 01:28:39.920]   to this day is once you pull--
[01:28:39.920 --> 01:28:42.440]   once you pull the thread, the sweater unravels,
[01:28:42.440 --> 01:28:45.720]   once someone starts talking, even when people are trying
[01:28:45.720 --> 01:28:46.840]   to shut that person up--
[01:28:46.840 --> 01:28:48.840]   Usually, the more it comes out, right?
[01:28:48.840 --> 01:28:49.400]   Yeah.
[01:28:49.400 --> 01:28:50.560]   And that's not happening here.
[01:28:50.560 --> 01:28:51.060]   Yeah.
[01:28:51.060 --> 01:28:55.200]   Yeah, it's just--
[01:28:55.200 --> 01:28:58.080]   And yeah, I don't-- I do not believe that Micklethwaite
[01:28:58.080 --> 01:29:00.480]   and the two reporters involved are lying.
[01:29:00.480 --> 01:29:01.280]   No, of course not.
[01:29:01.280 --> 01:29:02.760]   No, of course not.
[01:29:02.760 --> 01:29:07.800]   But I'm wondering whether they talk to guys like this source
[01:29:07.800 --> 01:29:09.720]   who gave them hypotheticals.
[01:29:09.720 --> 01:29:13.720]   And they built a story around things
[01:29:13.720 --> 01:29:17.280]   that their sources have not actually seen.
[01:29:17.280 --> 01:29:20.680]   But they have heard about.
[01:29:20.680 --> 01:29:21.480]   And that's what we've--
[01:29:21.480 --> 01:29:22.360]   Yeah, I'm sticking--
[01:29:22.360 --> 01:29:23.040]   It's hearsay.
[01:29:23.040 --> 01:29:25.120]   And so less reliable.
[01:29:25.120 --> 01:29:26.280]   Right.
[01:29:26.280 --> 01:29:26.880]   Yeah.
[01:29:26.880 --> 01:29:29.880]   I'm sticking with my-- they're touching the back
[01:29:29.880 --> 01:29:30.920]   at the right and the ossers.
[01:29:30.920 --> 01:29:32.960]   They think it's right and ossers, but it's really an elephant.
[01:29:32.960 --> 01:29:34.280]   Or however I said that.
[01:29:34.280 --> 01:29:35.120]   That's exactly.
[01:29:35.120 --> 01:29:35.600]   Yeah.
[01:29:35.600 --> 01:29:38.800]   And the other thing which I've always said,
[01:29:38.800 --> 01:29:41.560]   whoever you believe is that it is an issue.
[01:29:41.560 --> 01:29:42.520]   These things do happen.
[01:29:42.520 --> 01:29:45.440]   Every security expert says, however it happens,
[01:29:45.440 --> 01:29:49.840]   whether in software, at the factory, in transit, it happens.
[01:29:49.840 --> 01:29:50.520]   We do it.
[01:29:50.520 --> 01:29:51.800]   They do it.
[01:29:51.800 --> 01:29:55.280]   And it's a big problem because you can't ever be assured that--
[01:29:55.280 --> 01:29:57.560]   trust is a huge part of modern life.
[01:29:57.560 --> 01:29:59.600]   And as these machines that we use every day
[01:29:59.600 --> 01:30:01.720]   in every context are more and more complex.
[01:30:01.720 --> 01:30:03.800]   We have to trust them more and more.
[01:30:03.800 --> 01:30:07.240]   And that's why this article is important
[01:30:07.240 --> 01:30:09.280]   and why this debate is important.
[01:30:09.280 --> 01:30:11.360]   Because it sounds like whether you believe
[01:30:11.360 --> 01:30:13.640]   the facts about Super Micro-- these are not.
[01:30:13.640 --> 01:30:15.480]   These devices are no longer trustworthy.
[01:30:15.480 --> 01:30:17.680]   And they are everywhere.
[01:30:17.680 --> 01:30:20.240]   And I think that's why we need more detail.
[01:30:20.240 --> 01:30:20.840]   We need--
[01:30:20.840 --> 01:30:21.800]   We do.
[01:30:21.800 --> 01:30:22.840]   Yeah.
[01:30:22.840 --> 01:30:23.280]   Yeah.
[01:30:23.280 --> 01:30:24.040]   OK.
[01:30:24.040 --> 01:30:25.520]   I'm glad-- no, hey.
[01:30:25.520 --> 01:30:28.120]   Columbia Journalism Review, Long Standing Journalists.
[01:30:28.120 --> 01:30:30.720]   You actually went to J School when they were typewriters.
[01:30:30.720 --> 01:30:33.680]   I wanted to hear what Matthew Ingram had to say about this.
[01:30:33.680 --> 01:30:35.320]   So I'm glad you brought it up.
[01:30:35.320 --> 01:30:37.520]   Yeah, the typewriters, Matthew, that really
[01:30:37.520 --> 01:30:40.680]   changes how I use journalism.
[01:30:40.680 --> 01:30:42.960]   Hey, that's when journalism was hard.
[01:30:42.960 --> 01:30:44.480]   Oh, Pishtosh.
[01:30:44.480 --> 01:30:45.480]   [LAUGHTER]
[01:30:45.480 --> 01:30:48.160]   I was confused that it was hard.
[01:30:48.160 --> 01:30:50.040]   Matthew, do you have a pick of the week, anything
[01:30:50.040 --> 01:30:54.240]   you want to share with us before we wrap this puppy up?
[01:30:54.240 --> 01:30:58.640]   I found something-- it's in the rundown.
[01:30:58.640 --> 01:31:04.600]   It's the-- you can watch PowerPoint presentation
[01:31:04.600 --> 01:31:07.880]   about how the white walkers use their Chromebooks
[01:31:07.880 --> 01:31:09.200]   to communicate.
[01:31:09.200 --> 01:31:11.040]   Wait, the white walkers?
[01:31:11.040 --> 01:31:13.160]   You mean from Game of Thrones?
[01:31:13.160 --> 01:31:13.840]   Yeah.
[01:31:13.840 --> 01:31:17.600]   So there's a presentation about how they do recruiting
[01:31:17.600 --> 01:31:20.480]   for the white walkers, yeah.
[01:31:20.480 --> 01:31:23.160]   And this is actually an ad from Google.
[01:31:23.160 --> 01:31:24.880]   It's very persuasive.
[01:31:24.880 --> 01:31:26.360]   White walkers make a slide.
[01:31:26.360 --> 01:31:28.960]   The Night King is making a slide presentation.
[01:31:28.960 --> 01:31:29.720]   Not PowerPoint.
[01:31:29.720 --> 01:31:31.480]   You said PowerPoint, but let's be fair.
[01:31:31.480 --> 01:31:31.960]   Oh, sorry.
[01:31:31.960 --> 01:31:34.040]   This is Google Slides, yeah.
[01:31:34.040 --> 01:31:35.160]   You don't need PowerPoint.
[01:31:35.160 --> 01:31:36.800]   You can use the iceberg font.
[01:31:36.800 --> 01:31:38.720]   Winter is year.
[01:31:38.720 --> 01:31:40.400]   [LAUGHTER]
[01:31:40.400 --> 01:31:43.960]   [MUSIC PLAYING]
[01:31:43.960 --> 01:31:45.040]   The cold is ice.
[01:31:45.040 --> 01:31:46.480]   [LAUGHTER]
[01:31:46.480 --> 01:31:49.960]   Yours cold as ice!
[01:31:49.960 --> 01:31:50.720]   Oh, wait a minute.
[01:31:50.720 --> 01:31:52.760]   He's using Lightroom on a Chromebook.
[01:31:52.760 --> 01:31:54.760]   Ah, really?
[01:31:54.760 --> 01:31:57.400]   [LAUGHTER]
[01:31:57.400 --> 01:31:59.800]   This is pretty funny.
[01:31:59.800 --> 01:32:03.640]   We need this today, says the Night King White Walker.
[01:32:03.640 --> 01:32:05.160]   I'm on it.
[01:32:05.160 --> 01:32:07.240]   Night King, are you?
[01:32:07.240 --> 01:32:10.120]   If you want to work together, build armies,
[01:32:10.120 --> 01:32:13.000]   collaborate destroy walls, manage teams, conquer Westeros.
[01:32:13.000 --> 01:32:14.040]   Or what, bro?
[01:32:14.040 --> 01:32:15.840]   Your Chromebook.
[01:32:15.840 --> 01:32:17.960]   But I missed that how they did Lightroom.
[01:32:17.960 --> 01:32:19.360]   Maybe that was Lightroom and Android.
[01:32:19.360 --> 01:32:21.360]   Chromebook.com/whitewalkers.
[01:32:21.360 --> 01:32:23.360]   [LAUGHTER]
[01:32:23.360 --> 01:32:24.320]   There you go.
[01:32:24.320 --> 01:32:25.400]   Very good.
[01:32:25.400 --> 01:32:26.520]   I like it.
[01:32:26.520 --> 01:32:27.040]   That was fun.
[01:32:27.040 --> 01:32:28.440]   Nice.
[01:32:28.440 --> 01:32:30.800]   Stacy, what's your pick of the week?
[01:32:30.800 --> 01:32:32.160]   Um, OK.
[01:32:32.160 --> 01:32:34.240]   Well, I can show you Whisper Mode if you want to hear--
[01:32:34.240 --> 01:32:35.840]   if you want it, it's a little creepy.
[01:32:35.840 --> 01:32:37.840]   Or I can show you--
[01:32:37.840 --> 01:32:40.400]   I went to an event.
[01:32:40.400 --> 01:32:42.200]   It was a speaker at an event.
[01:32:42.200 --> 01:32:44.560]   And it was for JBL, actually.
[01:32:44.560 --> 01:32:47.000]   But as part of that, Chris Turkstra,
[01:32:47.000 --> 01:32:49.920]   who is the head of Google Assistant, was there.
[01:32:49.920 --> 01:32:53.680]   And I asked him, because this has long bothered me,
[01:32:53.680 --> 01:32:56.680]   why all the different Google Assistant voices
[01:32:56.680 --> 01:33:01.600]   were called things like cyan and scarlet, or not scarlet, red?
[01:33:01.600 --> 01:33:03.360]   They're not called by names.
[01:33:03.360 --> 01:33:04.240]   They're not called by names.
[01:33:04.240 --> 01:33:05.560]   They're called by colors.
[01:33:05.560 --> 01:33:09.240]   And I currently use cyan, which is a male voice.
[01:33:09.240 --> 01:33:12.440]   And so I was like, hey, what's up with that?
[01:33:12.440 --> 01:33:18.360]   And he said that they did not want to offend anyone.
[01:33:18.360 --> 01:33:21.480]   It's a fraught topic for gender identification,
[01:33:21.480 --> 01:33:24.200]   for nationalities and ethnicities.
[01:33:24.200 --> 01:33:27.280]   So they just went with colors.
[01:33:27.280 --> 01:33:28.520]   And I was like, huh.
[01:33:28.520 --> 01:33:30.920]   And the reason I stopped myself saying scarlet
[01:33:30.920 --> 01:33:34.000]   is he said some colors have names, or have gender.
[01:33:34.000 --> 01:33:35.680]   So they don't use that either.
[01:33:35.680 --> 01:33:38.000]   So they don't use that either.
[01:33:38.000 --> 01:33:42.360]   Which I was like, hey, that's actually kind of nice to know.
[01:33:42.360 --> 01:33:43.480]   Smart.
[01:33:43.480 --> 01:33:45.760]   And that's not a pick.
[01:33:45.760 --> 01:33:48.520]   It's just information I picked up talking to someone.
[01:33:48.520 --> 01:33:48.960]   And I thought--
[01:33:48.960 --> 01:33:51.600]   That's why I don't mind a space spy on me,
[01:33:51.600 --> 01:33:55.280]   because they're good people.
[01:33:55.280 --> 01:33:56.520]   For now.
[01:33:56.520 --> 01:33:57.360]   For now.
[01:33:57.360 --> 01:34:00.080]   I think some people there are really awesome,
[01:34:00.080 --> 01:34:03.760]   just like the whole spectrum of humanity.
[01:34:03.760 --> 01:34:06.160]   So where do I choose the--
[01:34:06.160 --> 01:34:07.480]   Where can I see the colors?
[01:34:07.480 --> 01:34:10.760]   Yeah, I'm in the voice.
[01:34:10.760 --> 01:34:12.240]   I don't know.
[01:34:12.240 --> 01:34:14.400]   You can hear mine, if you want.
[01:34:14.400 --> 01:34:16.560]   Let's just spray over.
[01:34:16.560 --> 01:34:18.800]   I want to hear whisper, too.
[01:34:18.800 --> 01:34:19.600]   Oh, well, OK.
[01:34:19.600 --> 01:34:20.480]   What do you want first?
[01:34:20.480 --> 01:34:21.960]   You want to hear cyan or whisper?
[01:34:21.960 --> 01:34:22.560]   Whisper first.
[01:34:22.560 --> 01:34:24.320]   Whisper, point of whisper.
[01:34:24.320 --> 01:34:25.760]   I'll tell you why.
[01:34:25.760 --> 01:34:30.920]   Because if you have a child and you want your Amazon Echo
[01:34:30.920 --> 01:34:34.560]   to sing a lullaby as she goes to sleep,
[01:34:34.560 --> 01:34:36.160]   you don't want the-- and I actually
[01:34:36.160 --> 01:34:37.800]   have had this problem with the Google Home,
[01:34:37.800 --> 01:34:40.360]   because I use it to set alarms.
[01:34:40.360 --> 01:34:42.600]   OK, you're about to spoil my thunder, Leo.
[01:34:42.600 --> 01:34:44.320]   Like at 6 in the morning?
[01:34:44.320 --> 01:34:46.880]   You know, I want to say, don't forget to wake me up at 8.30.
[01:34:46.880 --> 01:34:47.360]   Right.
[01:34:47.360 --> 01:34:49.520]   So I say, hey, wake me up at 8.30.
[01:34:49.520 --> 01:34:53.560]   And it goes, OK, I'm setting alarms for 8.30 in the morning.
[01:34:53.560 --> 01:34:54.920]   Arr.
[01:34:54.920 --> 01:34:57.080]   It's like, I don't know.
[01:34:57.080 --> 01:34:57.720]   Thank you.
[01:34:57.720 --> 01:34:58.680]   All right, ready?
[01:34:58.680 --> 01:34:59.760]   Yes.
[01:34:59.760 --> 01:35:03.120]   Oh, forgive me, everyone who has a matame.
[01:35:03.120 --> 01:35:06.920]   I'll let you set alarm for 10 AM.
[01:35:06.920 --> 01:35:13.000]   She's so quiet, we can't hear her.
[01:35:13.000 --> 01:35:13.840]   You couldn't hear that?
[01:35:13.840 --> 01:35:14.600]   My mic was right there.
[01:35:14.600 --> 01:35:15.280]   OK.
[01:35:15.280 --> 01:35:16.840]   Oh, did she say it?
[01:35:16.840 --> 01:35:21.320]   I'll let you cancel alarm.
[01:35:21.320 --> 01:35:24.480]   10 AM alarm cancel.
[01:35:24.480 --> 01:35:25.080]   Did you hear it?
[01:35:25.080 --> 01:35:26.120]   Yeah, it's creepy.
[01:35:26.120 --> 01:35:27.720]   Why I don't know how I heard it's very--
[01:35:27.720 --> 01:35:28.440]   It is really quiet.
[01:35:28.440 --> 01:35:29.680]   Well, and I was trying to--
[01:35:29.680 --> 01:35:31.760]   and I was trying to turn it up, and then I realized, oh,
[01:35:31.760 --> 01:35:32.760]   that doesn't actually work.
[01:35:32.760 --> 01:35:33.560]   It's whisper enough.
[01:35:33.560 --> 01:35:34.560]   Yeah.
[01:35:34.560 --> 01:35:35.560]   [LAUGHTER]
[01:35:35.560 --> 01:35:38.720]   So if you whisper to her, she will whisper to you.
[01:35:38.720 --> 01:35:39.240]   Cool.
[01:35:39.240 --> 01:35:42.520]   And the way you turn that on is you just say what?
[01:35:42.520 --> 01:35:43.880]   You say echo, whisk, go--
[01:35:43.880 --> 01:35:43.880]   Oh.
[01:35:43.880 --> 01:35:45.200]   --use whisper mode.
[01:35:45.200 --> 01:35:47.800]   Yes, this is the most important thing I can't believe I forgot it.
[01:35:47.800 --> 01:35:48.440]   You guys--
[01:35:48.440 --> 01:35:49.520]   Oh!
[01:35:49.520 --> 01:35:50.560]   OK.
[01:35:50.560 --> 01:35:53.400]   Can I get a Stacy mode in my echo?
[01:35:53.400 --> 01:35:56.920]   Yeah, I don't think everyone's prepared for that.
[01:35:56.920 --> 01:35:58.040]   OK.
[01:35:58.040 --> 01:36:02.600]   This, to enable it, all you have to do is whisper at her.
[01:36:02.600 --> 01:36:03.120]   Oh.
[01:36:03.120 --> 01:36:04.080]   That's it.
[01:36:04.080 --> 01:36:04.960]   You don't have to say--
[01:36:04.960 --> 01:36:07.640]   She's going to say she's going to say she's going to say, hey,
[01:36:07.640 --> 01:36:08.720]   I think you're whispering at me.
[01:36:08.720 --> 01:36:10.840]   Do you want to enable whisper mode?
[01:36:10.840 --> 01:36:12.200]   Oh, yeah.
[01:36:12.200 --> 01:36:13.200]   Yes.
[01:36:13.200 --> 01:36:15.360]   And this is one of the first--
[01:36:15.360 --> 01:36:18.280]   and you guys, you're going to hear me talk about this a lot
[01:36:18.280 --> 01:36:21.880]   in the near future, because Amazon is actually
[01:36:21.880 --> 01:36:25.600]   putting as part of re-invent coming up a session
[01:36:25.600 --> 01:36:28.080]   on voice-based programming.
[01:36:28.080 --> 01:36:29.640]   It's for serverless, so kind of nerdy.
[01:36:29.640 --> 01:36:35.200]   But the point is we are going to be soon in a world of voice-based
[01:36:35.200 --> 01:36:35.680]   programming.
[01:36:35.680 --> 01:36:36.360]   And we're implementing--
[01:36:36.360 --> 01:36:37.920]   Like, if you look at Amazon, they
[01:36:37.920 --> 01:36:40.400]   are implementing all the infrastructure needed for that.
[01:36:40.400 --> 01:36:41.800]   Not all, but some of it.
[01:36:41.800 --> 01:36:44.560]   That seems like a really nice way to implement these things
[01:36:44.560 --> 01:36:47.080]   instead of having to know what it is and all that stuff.
[01:36:47.080 --> 01:36:47.560]   Yeah.
[01:36:47.560 --> 01:36:48.360]   Well, and they did it.
[01:36:48.360 --> 01:36:51.560]   They showed it off at the Amazon event.
[01:36:51.560 --> 01:36:53.440]   They showed off a smart plug.
[01:36:53.440 --> 01:36:54.200]   It was the Amazon.
[01:36:54.200 --> 01:37:00.000]   And that's part of why the ACH, the Madam A Connect Kit--
[01:37:00.000 --> 01:37:01.080]   I can't say her name.
[01:37:01.080 --> 01:37:01.760]   I'm sorry.
[01:37:01.760 --> 01:37:03.080]   The A Connect Kit module was--
[01:37:03.080 --> 01:37:03.920]   Say, Echo Connect.
[01:37:03.920 --> 01:37:04.280]   Echo.
[01:37:04.280 --> 01:37:06.520]   Just use Echo instead of A.
[01:37:06.520 --> 01:37:07.560]   But--
[01:37:07.560 --> 01:37:08.520]   I know what to say.
[01:37:08.520 --> 01:37:12.360]   Because if you use it and you put it in your product
[01:37:12.360 --> 01:37:16.560]   and you use Amazon's wireless connectivity,
[01:37:16.560 --> 01:37:17.480]   they have a word for it.
[01:37:17.480 --> 01:37:19.240]   And I can't think of what it's called.
[01:37:19.240 --> 01:37:21.440]   You basically plug it in.
[01:37:21.440 --> 01:37:26.200]   And Madam A says, hey, I see a new smart plug.
[01:37:26.200 --> 01:37:27.080]   Do you want to--
[01:37:27.080 --> 01:37:29.840]   Oh, that's how it should be.
[01:37:29.840 --> 01:37:30.800]   And then you say--
[01:37:30.800 --> 01:37:31.880]   And then you say--
[01:37:31.880 --> 01:37:32.640]   Yes.
[01:37:32.640 --> 01:37:33.960]   And she's like, hey, what room is it?
[01:37:33.960 --> 01:37:34.800]   And you're like kitchen.
[01:37:34.800 --> 01:37:36.960]   And she's like, yes.
[01:37:36.960 --> 01:37:38.720]   Like a real assistant.
[01:37:38.720 --> 01:37:39.720]   Yes.
[01:37:39.720 --> 01:37:40.560]   Like a dumb robot.
[01:37:40.560 --> 01:37:41.480]   Oh, awesome.
[01:37:41.480 --> 01:37:44.200]   By the way, I have video of the Whisper Mode being recorded.
[01:37:44.200 --> 01:37:46.760]   I don't know if you saw this.
[01:37:46.760 --> 01:37:47.720]   Do you have my sound?
[01:37:47.720 --> 01:37:49.880]   [INAUDIBLE]
[01:37:49.880 --> 01:37:51.000]   Oh.
[01:37:51.000 --> 01:37:55.000]   She's saying quiet whispery things.
[01:37:55.000 --> 01:37:56.440]   Is this an ASMR video?
[01:37:56.440 --> 01:37:57.800]   Is this Cardi B does ASMR?
[01:37:57.800 --> 01:37:58.640]   Yes.
[01:37:58.640 --> 01:37:59.480]   Yes, it is.
[01:37:59.480 --> 01:38:00.480]   Fingo.
[01:38:00.480 --> 01:38:02.240]   You win.
[01:38:02.240 --> 01:38:04.480]   Well, I'm so sad that you can't hear it, though.
[01:38:04.480 --> 01:38:05.480]   That's--
[01:38:05.480 --> 01:38:06.480]   That's ASMR.
[01:38:06.480 --> 01:38:08.920]   Why does she have two different legs?
[01:38:08.920 --> 01:38:11.840]   Well, you've got left, and you've got right.
[01:38:11.840 --> 01:38:12.360]   OK.
[01:38:12.360 --> 01:38:15.760]   And she's not afraid to use it.
[01:38:15.760 --> 01:38:17.240]   So this is so weird.
[01:38:17.240 --> 01:38:20.480]   And I think I introduced you guys all about ASMR way back
[01:38:20.480 --> 01:38:21.080]   in the day.
[01:38:21.080 --> 01:38:22.080]   Are you into it?
[01:38:22.080 --> 01:38:22.920]   Thank you, Deb.
[01:38:22.920 --> 01:38:25.560]   My daughter is-- she actually listens to it.
[01:38:25.560 --> 01:38:26.520]   I picked up her headphones.
[01:38:26.520 --> 01:38:28.080]   And I was like, hey, what you listening to?
[01:38:28.080 --> 01:38:29.080]   And she's like--
[01:38:29.080 --> 01:38:30.400]   And I'm like, what is it?
[01:38:30.400 --> 01:38:32.280]   So she's like, oh, it's my ASMR noise.
[01:38:32.280 --> 01:38:33.080]   And I was like--
[01:38:33.080 --> 01:38:34.560]   Wow.
[01:38:34.560 --> 01:38:36.560]   So what does it do for her?
[01:38:36.560 --> 01:38:37.800]   But she finally relaxed.
[01:38:37.800 --> 01:38:39.440]   She's like, she's super anxious.
[01:38:39.440 --> 01:38:43.560]   So it makes her feel like while she does her homework.
[01:38:43.560 --> 01:38:44.080]   And stuff.
[01:38:44.080 --> 01:38:48.600]   I used to when I was young, some people, when they talked,
[01:38:48.600 --> 01:38:51.840]   would put me in a kind of altered state.
[01:38:51.840 --> 01:38:54.920]   And I think that's what ASMR was originally kind of about,
[01:38:54.920 --> 01:38:59.040]   is that there is a almost hypnotic mode of talking.
[01:38:59.040 --> 01:39:00.520]   And it doesn't have to be whisper.
[01:39:00.520 --> 01:39:02.880]   This is where I think they've gone wrong with the shit.
[01:39:02.880 --> 01:39:03.400]   No.
[01:39:03.400 --> 01:39:06.440]   No, it's supposed to enable this sensory chill.
[01:39:06.440 --> 01:39:06.960]   This sensory--
[01:39:06.960 --> 01:39:08.200]   Yeah, it was a weird feeling.
[01:39:08.200 --> 01:39:11.880]   It was like-- yeah, it was like that.
[01:39:11.880 --> 01:39:13.800]   And it felt good.
[01:39:13.800 --> 01:39:15.840]   But I've never been able to recapture that.
[01:39:15.840 --> 01:39:17.560]   Maybe I should listen to the small card you be.
[01:39:17.560 --> 01:39:18.960]   Bob Ross does that for me.
[01:39:18.960 --> 01:39:20.440]   Bob Ross is very much that.
[01:39:20.440 --> 01:39:21.840]   See, he's not whispering with--
[01:39:21.840 --> 01:39:22.040]   Yeah.
[01:39:22.040 --> 01:39:22.960]   Very gentle.
[01:39:22.960 --> 01:39:23.760]   Very relaxing.
[01:39:23.760 --> 01:39:25.600]   Very relaxing.
[01:39:25.600 --> 01:39:28.920]   Did you ever read about why he talks like that?
[01:39:28.920 --> 01:39:29.880]   No.
[01:39:29.880 --> 01:39:30.280]   What?
[01:39:30.280 --> 01:39:32.400]   So he was in the army.
[01:39:32.400 --> 01:39:35.840]   And he got yelled at a lot.
[01:39:35.840 --> 01:39:39.360]   So when he got out, he decided that he would never, ever
[01:39:39.360 --> 01:39:40.560]   raise his voice ever.
[01:39:40.560 --> 01:39:42.040]   Never.
[01:39:42.040 --> 01:39:42.880]   Wow.
[01:39:42.880 --> 01:39:46.440]   I am going to do the same thing for someone.
[01:39:46.440 --> 01:39:48.440]   It would be terrible at that.
[01:39:48.440 --> 01:39:49.600]   What?
[01:39:49.600 --> 01:39:52.360]   I'd be like, oh, guys.
[01:39:52.360 --> 01:39:54.800]   Oh, guys.
[01:39:54.800 --> 01:39:57.440]   It'll be so great.
[01:39:57.440 --> 01:39:59.040]   Yeah, it's a little weird.
[01:39:59.040 --> 01:40:01.000]   Yeah.
[01:40:01.000 --> 01:40:04.720]   Ladies and gentlemen, I am going to release the staff
[01:40:04.720 --> 01:40:06.880]   and crew of the Good Ship Twig.
[01:40:06.880 --> 01:40:09.440]   Thanks, Bob.
[01:40:09.440 --> 01:40:13.080]   And let them fly free.
[01:40:13.080 --> 01:40:15.400]   According to Proposition 12.
[01:40:15.400 --> 01:40:18.280]   What if I just limp off with my broken toe?
[01:40:18.280 --> 01:40:20.000]   Do you have a broken toe, too?
[01:40:20.000 --> 01:40:21.120]   Oh, yeah.
[01:40:21.120 --> 01:40:22.000]   What'd you do?
[01:40:22.000 --> 01:40:23.560]   Oh, no, anything.
[01:40:23.560 --> 01:40:25.920]   Oh, I break my toe all the time.
[01:40:25.920 --> 01:40:27.560]   Once every year or two, I break my toe.
[01:40:27.560 --> 01:40:29.040]   You stub it on something?
[01:40:29.040 --> 01:40:30.400]   It was for fun, there.
[01:40:30.400 --> 01:40:34.000]   No, it gets caught on something, and then it just snaps.
[01:40:34.000 --> 01:40:35.040]   Oh, my God.
[01:40:35.040 --> 01:40:36.800]   It's usually when I'm putting in my--
[01:40:36.800 --> 01:40:38.520]   it's usually when I'm stepping into my pants.
[01:40:38.520 --> 01:40:39.400]   I'll just be honest.
[01:40:39.400 --> 01:40:41.320]   It's really terrifying.
[01:40:41.320 --> 01:40:41.840]   Wow.
[01:40:41.840 --> 01:40:43.120]   It's so stupid.
[01:40:43.120 --> 01:40:45.320]   Wow.
[01:40:45.320 --> 01:40:48.320]   I tore my toe up.
[01:40:48.320 --> 01:40:49.400]   Oh, I'm sorry.
[01:40:49.400 --> 01:40:50.360]   But it's still fun.
[01:40:50.360 --> 01:40:57.120]   And now, just so that you don't think we're lying,
[01:40:57.120 --> 01:41:00.920]   here is a wombat.
[01:41:00.920 --> 01:41:05.240]   And here is wombat poop.
[01:41:05.240 --> 01:41:07.600]   It's cubic.
[01:41:07.600 --> 01:41:10.840]   What is cut around the cubes?
[01:41:10.840 --> 01:41:12.880]   I don't know if it's a cube, exactly.
[01:41:12.880 --> 01:41:14.280]   Not a cube.
[01:41:14.280 --> 01:41:15.800]   It's not-- yeah, it's not exactly.
[01:41:15.800 --> 01:41:20.240]   By describing it as a cube, you gave it some--
[01:41:20.240 --> 01:41:21.040]   Fake news.
[01:41:21.040 --> 01:41:22.240]   Fake news.
[01:41:22.240 --> 01:41:22.960]   Wombats are adorable.
[01:41:22.960 --> 01:41:24.000]   Look at the wombat.
[01:41:24.000 --> 01:41:25.120]   I love how it's pretty.
[01:41:25.120 --> 01:41:28.120]   I had a wombat encounter in Tasmania.
[01:41:28.120 --> 01:41:28.800]   Yes, you did.
[01:41:28.800 --> 01:41:29.320]   That's right.
[01:41:29.320 --> 01:41:31.120]   Last time I was on, we showed you.
[01:41:31.120 --> 01:41:32.560]   I love my wombat.
[01:41:32.560 --> 01:41:34.320]   And a Tasmanian devil, too, didn't it?
[01:41:34.320 --> 01:41:35.560]   Yes, I showed them both.
[01:41:35.560 --> 01:41:36.080]   Yes.
[01:41:36.080 --> 01:41:37.200]   Those are not cute.
[01:41:37.200 --> 01:41:38.120]   Those look like--
[01:41:38.120 --> 01:41:39.520]   No, those aren't cute, but wombat's.
[01:41:39.520 --> 01:41:41.240]   Although, wombat's get rid of your flair.
[01:41:41.240 --> 01:41:41.680]   Put on that?
[01:41:41.680 --> 01:41:42.680]   Actually.
[01:41:42.680 --> 01:41:43.560]   He's grooming, I think.
[01:41:43.560 --> 01:41:45.400]   Well, an interesting point that--
[01:41:45.400 --> 01:41:47.480]   but it has a bone.
[01:41:47.480 --> 01:41:49.160]   It's almost like a helmet.
[01:41:49.160 --> 01:41:52.080]   And to avoid being eaten alive,
[01:41:52.080 --> 01:41:54.720]   wombat's will dive into their hole,
[01:41:54.720 --> 01:41:58.240]   only their butt will protrude, and it's armored.
[01:41:58.240 --> 01:41:59.480]   And they can't be eaten.
[01:41:59.480 --> 01:42:02.880]   However, I've been told by Australians,
[01:42:02.880 --> 01:42:05.760]   that makes them a very poor form of roadkill,
[01:42:05.760 --> 01:42:08.520]   because it feels like you just hit a bowling ball.
[01:42:08.520 --> 01:42:09.040]   What?
[01:42:09.040 --> 01:42:10.240]   We can probably damage--
[01:42:10.240 --> 01:42:12.240]   I thought that there was a video.
[01:42:12.240 --> 01:42:12.880]   This is a weird thing.
[01:42:12.880 --> 01:42:15.240]   Some sort of wombat ASMR.
[01:42:15.240 --> 01:42:18.120]   I don't think we need to investigate any further.
[01:42:18.120 --> 01:42:19.840]   And then there was a funnel or something.
[01:42:19.840 --> 01:42:20.360]   What is that?
[01:42:20.360 --> 01:42:25.320]   She's demonstrating why--
[01:42:25.320 --> 01:42:26.680]   They're poop.
[01:42:26.680 --> 01:42:27.160]   Yes.
[01:42:27.160 --> 01:42:28.040]   Why they poop.
[01:42:28.040 --> 01:42:28.560]   Yes.
[01:42:28.560 --> 01:42:29.880]   Is it their accessible shape?
[01:42:29.880 --> 01:42:30.720]   That's why I'm isolated.
[01:42:30.720 --> 01:42:31.320]   That's why I'm isolated.
[01:42:31.320 --> 01:42:33.720]   There is a physical physics reason for it.
[01:42:33.720 --> 01:42:34.680]   Got you.
[01:42:34.680 --> 01:42:35.120]   Got it.
[01:42:35.120 --> 01:42:36.320]   I really love this show.
[01:42:36.320 --> 01:42:36.840]   OK.
[01:42:36.840 --> 01:42:38.920]   You learn so much in this show.
[01:42:38.920 --> 01:42:40.880]   I can check that out later.
[01:42:40.880 --> 01:42:42.840]   Check it out.
[01:42:42.840 --> 01:42:45.720]   Learn more about wombat's Visit Your Local Public Library,
[01:42:45.720 --> 01:42:47.120]   Matthew.
[01:42:47.120 --> 01:42:48.800]   Google Play the Wombat poop.
[01:42:48.800 --> 01:42:51.840]   Isn't it sad that people no longer have to go to the library
[01:42:51.840 --> 01:42:52.920]   to learn anything?
[01:42:52.920 --> 01:42:55.040]   They could just Google it?
[01:42:55.040 --> 01:42:57.640]   You know, my daughter's teacher gives her--
[01:42:57.640 --> 01:43:01.040]   they have to have X number of print sources
[01:43:01.040 --> 01:43:01.880]   for their papers.
[01:43:01.880 --> 01:43:03.320]   That's crazy talk.
[01:43:03.320 --> 01:43:07.200]   Well, what is really crazy to me is we get the New Yorker.
[01:43:07.200 --> 01:43:10.320]   So I'm like, oh, let me go.
[01:43:10.320 --> 01:43:11.840]   But I don't keep the issues.
[01:43:11.840 --> 01:43:15.600]   So she doesn't count unless it's in paper format.
[01:43:15.600 --> 01:43:17.720]   So when she goes to the New Yorker website,
[01:43:17.720 --> 01:43:18.800]   which I'm like--
[01:43:18.800 --> 01:43:20.480]   That's the same text.
[01:43:20.480 --> 01:43:23.160]   Yeah, I'm like, that's a little iffy.
[01:43:23.160 --> 01:43:25.080]   How old is this teacher?
[01:43:25.080 --> 01:43:26.080]   Could do that.
[01:43:26.080 --> 01:43:26.840]   Is that my age?
[01:43:26.840 --> 01:43:28.600]   Is it typing class?
[01:43:28.600 --> 01:43:29.920]   No, it's science.
[01:43:29.920 --> 01:43:31.240]   Science.
[01:43:31.240 --> 01:43:32.240]   Yeah, it is.
[01:43:32.240 --> 01:43:33.760]   That's what library--
[01:43:33.760 --> 01:43:36.600]   I went to the library when I was in Calgary,
[01:43:36.600 --> 01:43:39.360]   because I was looking for somewhere to work that looked
[01:43:39.360 --> 01:43:41.240]   nice, so I like old libraries.
[01:43:41.240 --> 01:43:42.320]   Well, thanks to WeWork.
[01:43:42.320 --> 01:43:43.880]   We don't even have that anymore.
[01:43:43.880 --> 01:43:45.160]   And they have Wi-Fi.
[01:43:45.160 --> 01:43:45.680]   And they were--
[01:43:45.680 --> 01:43:46.720]   Come to Austin.
[01:43:46.720 --> 01:43:50.760]   Our brand new library is on one of Time Magazine's top 100
[01:43:50.760 --> 01:43:52.400]   beautiful places in the world.
[01:43:52.400 --> 01:43:53.520]   Oh, that's nice.
[01:43:53.520 --> 01:43:54.400]   But it's not beautiful.
[01:43:54.400 --> 01:43:56.920]   Like, new beautiful or beautiful old beautiful?
[01:43:56.920 --> 01:44:00.360]   It's new beautiful, but it's a totally green building.
[01:44:00.360 --> 01:44:01.640]   It's very cool looking.
[01:44:01.640 --> 01:44:03.160]   It's got a lot of--
[01:44:03.160 --> 01:44:03.680]   It's very nice.
[01:44:03.680 --> 01:44:05.040]   It's pretty.
[01:44:05.040 --> 01:44:05.540]   See?
[01:44:05.540 --> 01:44:06.440]   Because the New York--
[01:44:06.440 --> 01:44:07.040]   It's pretty.
[01:44:07.040 --> 01:44:09.080]   The New York Public Library in private--
[01:44:09.080 --> 01:44:09.600]   OK, that's old.
[01:44:09.600 --> 01:44:10.920]   --for your favorite.
[01:44:10.920 --> 01:44:12.120]   Yeah, I love that.
[01:44:12.120 --> 01:44:12.720]   Yeah.
[01:44:12.720 --> 01:44:18.120]   I used to go and work in the old documents for him.
[01:44:18.120 --> 01:44:19.600]   That looks OK, I guess.
[01:44:19.600 --> 01:44:21.400]   Wow.
[01:44:21.400 --> 01:44:22.440]   Where?
[01:44:22.440 --> 01:44:23.720]   I just say one thing.
[01:44:23.720 --> 01:44:26.280]   Where the hell are the books?
[01:44:26.280 --> 01:44:27.880]   This is the atrium area.
[01:44:27.880 --> 01:44:29.480]   They're all on the side shelves.
[01:44:29.480 --> 01:44:31.480]   Nice library you got there.
[01:44:31.480 --> 01:44:31.960]   Be ashamed of it.
[01:44:31.960 --> 01:44:34.000]   If you had any books in it--
[01:44:34.000 --> 01:44:35.840]   Libraries are about social events now.
[01:44:35.840 --> 01:44:39.120]   It's not just about--
[01:44:39.120 --> 01:44:40.720]   Oh, and I see some books.
[01:44:40.720 --> 01:44:42.160]   See, they're over on the side.
[01:44:42.160 --> 01:44:43.000]   Don't worry, they're there.
[01:44:43.000 --> 01:44:44.800]   They're over on the side.
[01:44:44.800 --> 01:44:48.120]   My child and husband came back and they came back with 30 books.
[01:44:48.120 --> 01:44:49.160]   So I know that they're--
[01:44:49.160 --> 01:44:50.680]   Oh, that's nice.
[01:44:50.680 --> 01:44:52.360]   The new central library.
[01:44:52.360 --> 01:44:54.200]   That's pretty.
[01:44:54.200 --> 01:44:57.080]   Stacey Higginbotham talks about internet of things
[01:44:57.080 --> 01:44:58.040]   at her website.
[01:44:58.040 --> 01:45:00.840]   That's her newsletter, StaceyAnIOT.com.
[01:45:00.840 --> 01:45:03.560]   She also does an IOT podcast, the internet of things
[01:45:03.560 --> 01:45:06.760]   podcast with Kevin Tofel every Wednesday morning.
[01:45:06.760 --> 01:45:10.000]   And you can subscribe to that at StaceyAnIOT.com as well.
[01:45:10.000 --> 01:45:12.000]   She's at Gigastacey on Twitter.
[01:45:12.000 --> 01:45:13.360]   And I hope your call gets better.
[01:45:13.360 --> 01:45:14.360]   We'll see you next week, Stacey.
[01:45:14.360 --> 01:45:15.360]   Thank you.
[01:45:15.360 --> 01:45:16.280]   Thanks for--
[01:45:16.280 --> 01:45:19.640]   Matthew Ingram, Stacey's longtime colleague at Gig Oames.
[01:45:19.640 --> 01:45:22.080]   Now at the Columbia Journalism Review,
[01:45:22.080 --> 01:45:24.600]   CJR.org, where he's chief digital writer.
[01:45:24.600 --> 01:45:29.800]   You can also follow him on the Twitter, M-A-T-H-E-W-I.
[01:45:29.800 --> 01:45:30.480]   1T.
[01:45:30.480 --> 01:45:32.280]   1T.
[01:45:32.280 --> 01:45:34.200]   Like it's supposed to be.
[01:45:34.200 --> 01:45:37.160]   It's forever ruined my spelling of anybody named Matthew.
[01:45:37.160 --> 01:45:38.120]   I swear.
[01:45:38.120 --> 01:45:39.000]   I don't think 1.
[01:45:39.000 --> 01:45:39.960]   Some people need 2.
[01:45:39.960 --> 01:45:40.920]   Some people need 2.
[01:45:40.920 --> 01:45:42.280]   They're maybe overachievers.
[01:45:42.280 --> 01:45:44.200]   I don't know.
[01:45:44.200 --> 01:45:47.920]   We do a twig every Wednesday, 130 Pacific, 430 Eastern.
[01:45:47.920 --> 01:45:49.440]   That's 20, 30 UTC.
[01:45:49.440 --> 01:45:51.960]   Join us, won't you?
[01:45:51.960 --> 01:45:52.560]   Watch the show.
[01:45:52.560 --> 01:45:54.800]   You can stream it live at Twit.tv/live,
[01:45:54.800 --> 01:45:57.120]   or you could be in the studio with us live.
[01:45:57.120 --> 01:45:57.960]   We like that, too.
[01:45:57.960 --> 01:45:58.800]   We had a--
[01:45:58.800 --> 01:45:59.880]   Very nice.
[01:45:59.880 --> 01:46:03.920]   Couple of people visiting from Adelaide today, Australia.
[01:46:03.920 --> 01:46:04.800]   Jesse and Michael.
[01:46:04.800 --> 01:46:06.040]   Yeah, thanks for joining us.
[01:46:06.040 --> 01:46:07.040]   Thanks for joining us.
[01:46:07.040 --> 01:46:08.920]   Adelaide is Austin's sister city.
[01:46:08.920 --> 01:46:11.200]   Hello.
[01:46:11.200 --> 01:46:12.600]   I'm so excited for that.
[01:46:12.600 --> 01:46:13.040]   OK.
[01:46:13.040 --> 01:46:15.360]   Sister cities.
[01:46:15.360 --> 01:46:15.720]   I'm--
[01:46:15.720 --> 01:46:16.720]   OK.
[01:46:16.720 --> 01:46:16.880]   Sister.
[01:46:16.880 --> 01:46:21.000]   My cold medicine is totally kicking in you guys.
[01:46:21.000 --> 01:46:21.880]   Don't stop now.
[01:46:21.880 --> 01:46:24.480]   If you want to be in studio email tickets at Twit.tv,
[01:46:24.480 --> 01:46:27.640]   you can also get on to man versions of the show at twig,
[01:46:27.640 --> 01:46:31.480]   twit.tv/twig, or subscribe in your favorite podcast.
[01:46:31.480 --> 01:46:32.720]   Oh, look.
[01:46:32.720 --> 01:46:35.000]   That's a nice picture of Stacy.
[01:46:35.000 --> 01:46:37.000]   Wow.
[01:46:37.000 --> 01:46:38.000]   Well, we'll work on that.
[01:46:38.000 --> 01:46:38.760]   No, thanks you guys.
[01:46:38.760 --> 01:46:40.880]   We'll work on that.
[01:46:40.880 --> 01:46:45.040]   Twit.tv/twig, or subscribe in your favorite podcast appliance.
[01:46:45.040 --> 01:46:46.240]   Thank you so much for being here.
[01:46:46.240 --> 01:46:48.320]   We'll see you next time on This Week in Google.
[01:46:48.320 --> 01:46:51.240]   [MUSIC PLAYING]
[01:46:51.240 --> 01:46:54.600]   [MUSIC PLAYING]
[01:46:54.600 --> 01:46:57.180]   (upbeat music)
[01:46:57.180 --> 01:47:00.660]   [MUSIC PLAYING]

