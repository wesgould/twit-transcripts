;FFMETADATA1
album=This Week In Google 2011
artist=Leo Laporte, Jeff Jarvis, And Gina Trapani
comment=http://twit.tv/twig83
encoded_by=iTunes v7.0
genre=Podcast
title=TWiG 83: The Uncanny Valley
date=2011
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.880]   [MUSIC PLAYING]
[00:00:03.880 --> 00:00:05.920]   Netcast you love.
[00:00:05.920 --> 00:00:07.280]   From people you trust.
[00:00:07.280 --> 00:00:11.080]   [MUSIC PLAYING]
[00:00:11.080 --> 00:00:13.840]   This is Twig.
[00:00:13.840 --> 00:00:17.600]   Bandwidth for this week in Google is provided by cash fly,
[00:00:17.600 --> 00:00:20.680]   C-A-C-H-E-F-L-Y.com.
[00:00:20.680 --> 00:00:24.600]   [MUSIC PLAYING]
[00:00:24.600 --> 00:00:26.080]   This is Twig.
[00:00:26.080 --> 00:00:31.680]   This week in Google, episode 83, recorded February 23, 2011.
[00:00:31.680 --> 00:00:34.640]   The Uncanny Valley.
[00:00:34.640 --> 00:00:37.720]   This week in Google is brought to you by hover.com.
[00:00:37.720 --> 00:00:40.120]   Hover is domain name, registration, and management
[00:00:40.120 --> 00:00:40.880]   that's simple.
[00:00:40.880 --> 00:00:47.760]   For 10% off your new domain, go to twig.hovr.com
[00:00:47.760 --> 00:00:50.000]   and buy squarespace.com.
[00:00:50.000 --> 00:00:52.600]   The fast and easy way to publish a high quality website
[00:00:52.600 --> 00:00:55.280]   or blog for a free 14-day trial,
[00:00:55.280 --> 00:00:59.720]   go to squarespace.com/twig.
[00:00:59.720 --> 00:01:00.680]   It's time for Twig.
[00:01:00.680 --> 00:01:03.160]   This week in Google and the cloud, joining us
[00:01:03.160 --> 00:01:05.680]   are Google Clouders, starting with the course Gina
[00:01:05.680 --> 00:01:08.840]   Trapani from Life Hacker and her own site now,
[00:01:08.840 --> 00:01:10.120]   SmarterWeird.org.
[00:01:10.120 --> 00:01:13.480]   And the great Think Up, right?
[00:01:13.480 --> 00:01:14.000]   Think Up.
[00:01:14.000 --> 00:01:14.500]   Think Up.
[00:01:14.500 --> 00:01:16.440]   Hey, it's so great to have you back, Leo.
[00:01:16.440 --> 00:01:16.920]   Thank you, Jim.
[00:01:16.920 --> 00:01:19.520]   Looking very tan and thin and refreshed.
[00:01:19.520 --> 00:01:20.560]   I had so much fun.
[00:01:20.560 --> 00:01:22.440]   It was really nice to get a little vacation.
[00:01:22.440 --> 00:01:24.640]   Thanks to Becky and Tom for filling in while I was gone.
[00:01:24.640 --> 00:01:25.200]   I appreciate it.
[00:01:25.200 --> 00:01:26.200]   We're fantastic.
[00:01:26.200 --> 00:01:28.240]   I said to them, I want all of you at the same time,
[00:01:28.240 --> 00:01:30.640]   not just, you know, piecemeal.
[00:01:30.640 --> 00:01:31.560]   Well, that's a good idea.
[00:01:31.560 --> 00:01:33.760]   In fact, I believe-- well, I'll tell you about that in a second.
[00:01:33.760 --> 00:01:36.360]   I believe we will all be together again.
[00:01:36.360 --> 00:01:38.240]   And it won't be in rock and roll heaven.
[00:01:38.240 --> 00:01:39.600]   It'll be sooner than that.
[00:01:39.600 --> 00:01:43.360]   But first, let me say hi to Jeff Jarvis of Buzzmachine.com.
[00:01:43.360 --> 00:01:45.440]   He's a professor of journalism at the City University of New
[00:01:45.440 --> 00:01:52.400]   York and the author of a fine book called What Would Google Do?
[00:01:52.400 --> 00:01:55.160]   Hey, how's private-- I mean, public parts come in.
[00:01:55.160 --> 00:01:57.960]   I'm one-third of the way throughout it in the manuscript.
[00:01:57.960 --> 00:02:00.640]   We're fighting over the subtitle now.
[00:02:00.640 --> 00:02:01.760]   I'll ask you about it later.
[00:02:01.760 --> 00:02:02.240]   Oh, good.
[00:02:02.240 --> 00:02:04.000]   We can do a poll.
[00:02:04.000 --> 00:02:04.920]   We could, yes.
[00:02:04.920 --> 00:02:05.400]   You know why?
[00:02:05.400 --> 00:02:08.160]   Because I met when I was in the Buenos Aires,
[00:02:08.160 --> 00:02:09.720]   I had a lunch after that event.
[00:02:09.720 --> 00:02:12.600]   I had another lunch with a bunch of people.
[00:02:12.600 --> 00:02:16.560]   And one of them, Mariano Wexler, was an entrepreneur
[00:02:16.560 --> 00:02:21.520]   who created a Twitter thing called Pollowers at P-O-L-L-Pole
[00:02:21.520 --> 00:02:22.200]   Ours.
[00:02:22.200 --> 00:02:23.640]   And I use it yesterday.
[00:02:23.640 --> 00:02:24.520]   It's in closed beta.
[00:02:24.520 --> 00:02:25.680]   It's so cool.
[00:02:25.680 --> 00:02:27.960]   It lets you do polls on Twitter.
[00:02:27.960 --> 00:02:28.640]   Very cool.
[00:02:28.640 --> 00:02:30.440]   So if you want help, we can do a poll.
[00:02:30.440 --> 00:02:32.320]   I'll do a real quick reading, OK?
[00:02:32.320 --> 00:02:33.080]   We'll get the chat room.
[00:02:33.080 --> 00:02:33.440]   OK.
[00:02:33.440 --> 00:02:37.000]   So public parts of the title, subtitle, candidates.
[00:02:37.000 --> 00:02:41.440]   One, public parts and expose.
[00:02:41.440 --> 00:02:42.880]   Two, if we're slightly dirty.
[00:02:42.880 --> 00:02:43.800]   Slightly dirty.
[00:02:43.800 --> 00:02:45.520]   Why do we share a billion times a day?
[00:02:45.520 --> 00:02:46.920]   Ooh, OK.
[00:02:46.920 --> 00:02:50.560]   Three, privacy and fear, openness and opportunity.
[00:02:50.560 --> 00:02:52.600]   Four, what happens when companies, governments,
[00:02:52.600 --> 00:02:55.680]   and individuals let it all hang out?
[00:02:55.680 --> 00:02:56.160]   Like that.
[00:02:56.160 --> 00:02:58.960]   And five, the private self, the public sphere,
[00:02:58.960 --> 00:03:02.800]   and principles for a new society.
[00:03:02.800 --> 00:03:03.720]   Chat--
[00:03:03.720 --> 00:03:06.040]   I-- well, I won't say anything.
[00:03:06.040 --> 00:03:06.520]   No, do.
[00:03:06.520 --> 00:03:07.520]   No, what do you say?
[00:03:07.520 --> 00:03:07.880]   What?
[00:03:07.880 --> 00:03:09.800]   I have a strong opinion.
[00:03:09.800 --> 00:03:10.880]   Which one?
[00:03:10.880 --> 00:03:12.920]   That-- what happens when governments and--
[00:03:12.920 --> 00:03:13.920]   let it all hang out?
[00:03:13.920 --> 00:03:14.280]   I like that.
[00:03:14.280 --> 00:03:16.880]   You agree with the publisher, Gina?
[00:03:16.880 --> 00:03:18.840]   Yeah, that one is pretty provocative.
[00:03:18.840 --> 00:03:24.080]   I like the one, privacy and fears and publicness
[00:03:24.080 --> 00:03:25.720]   and opportunity.
[00:03:25.720 --> 00:03:26.080]   OK.
[00:03:26.080 --> 00:03:28.520]   Yesterday, the editor and I were going for the billion times
[00:03:28.520 --> 00:03:28.800]   a day.
[00:03:28.800 --> 00:03:29.880]   But OK, all right, good.
[00:03:29.880 --> 00:03:31.080]   We thought it was--
[00:03:31.080 --> 00:03:35.000]   private parts and expose was a Twitter title.
[00:03:35.000 --> 00:03:35.520]   It's probably--
[00:03:35.520 --> 00:03:36.480]   clever, probably doesn't--
[00:03:36.480 --> 00:03:37.000]   Too short.
[00:03:37.000 --> 00:03:38.960]   --very clever, yes.
[00:03:38.960 --> 00:03:40.080]   So all right.
[00:03:40.080 --> 00:03:42.840]   Yeah, the billion times a day, why do we share a billion times
[00:03:42.840 --> 00:03:44.400]   a day, that one's pretty provocative, too.
[00:03:44.400 --> 00:03:46.080]   I like that one.
[00:03:46.080 --> 00:03:48.760]   Yeah, but remember, this is all about selling books.
[00:03:48.760 --> 00:03:50.480]   Yeah, yeah.
[00:03:50.480 --> 00:03:52.880]   And you agree with the publisher, the boss man
[00:03:52.880 --> 00:03:54.520]   at Simon & Schuster, like the one you likely owe.
[00:03:54.520 --> 00:03:56.520]   And I was pissy about it last night.
[00:03:56.520 --> 00:03:57.720]   Well, I mean, it doesn't--
[00:03:57.720 --> 00:03:59.840]   No, I think you're-- no, that's what I'm saying.
[00:03:59.840 --> 00:04:04.000]   My first book, Gina Smith and I, who wrote it,
[00:04:04.000 --> 00:04:06.120]   wanted to call it-- how do I get the dog here out
[00:04:06.120 --> 00:04:07.840]   of the disk drive?
[00:04:07.840 --> 00:04:12.920]   And the publisher chose the completely mundane 101 computer
[00:04:12.920 --> 00:04:15.280]   answers you need to know.
[00:04:15.280 --> 00:04:15.800]   Yep.
[00:04:15.800 --> 00:04:16.800]   The publisher--
[00:04:16.800 --> 00:04:18.240]   that'll kill a book.
[00:04:18.240 --> 00:04:20.560]   [LAUGHTER]
[00:04:20.560 --> 00:04:22.480]   But, you know, and somebody once told me
[00:04:22.480 --> 00:04:26.400]   with our former program director at Tech TV,
[00:04:26.400 --> 00:04:28.760]   he said, you can be clever in a title,
[00:04:28.760 --> 00:04:30.280]   or you can communicate what it's about.
[00:04:30.280 --> 00:04:33.640]   But, you know, I think it's nice in a book
[00:04:33.640 --> 00:04:36.080]   to know what it's about.
[00:04:36.080 --> 00:04:38.560]   I kind of already have a joke with public parts.
[00:04:38.560 --> 00:04:40.120]   Yeah, public parts is great.
[00:04:40.120 --> 00:04:43.080]   And then the subtitle says really what it's about,
[00:04:43.080 --> 00:04:46.280]   which is how-- what does it say it again?
[00:04:46.280 --> 00:04:50.080]   Uh, that one is--
[00:04:50.080 --> 00:04:51.440]   oops, oops, where'd it go?
[00:04:51.440 --> 00:04:51.880]   Where'd it go?
[00:04:51.880 --> 00:04:53.200]   Where'd it go?
[00:04:53.200 --> 00:04:56.080]   [GRUNTS]
[00:04:56.080 --> 00:04:59.040]   Sorry, it was something like how governments and the public--
[00:04:59.040 --> 00:05:01.280]   it's what happens when companies, governments,
[00:05:01.280 --> 00:05:03.120]   and people let it all hang out.
[00:05:03.120 --> 00:05:04.240]   I love that.
[00:05:04.240 --> 00:05:05.400]   Yeah, that is good.
[00:05:05.400 --> 00:05:07.040]   That says-- that's what the book is about.
[00:05:07.040 --> 00:05:08.880]   You're bringing me around, all right.
[00:05:08.880 --> 00:05:09.280]   All right.
[00:05:09.280 --> 00:05:11.680]   We could do a-- actually, it's too long for--
[00:05:11.680 --> 00:05:12.400]   poll on Twitter.
[00:05:12.400 --> 00:05:13.680]   I don't think I can get that on.
[00:05:13.680 --> 00:05:14.480]   I don't know how to read.
[00:05:14.480 --> 00:05:17.160]   But it's free consultation here, yes.
[00:05:17.160 --> 00:05:19.640]   Twitter polls really have to be fairly succinct.
[00:05:19.640 --> 00:05:20.800]   Anyway, I miss you guys.
[00:05:20.800 --> 00:05:21.720]   It's great to see you again.
[00:05:21.720 --> 00:05:23.560]   It's so good to be back.
[00:05:23.560 --> 00:05:26.080]   Tom, by the way, have you heard this before?
[00:05:26.080 --> 00:05:26.760]   I never heard before.
[00:05:26.760 --> 00:05:28.720]   He does a mean Leo imitation.
[00:05:28.720 --> 00:05:29.640]   No.
[00:05:29.640 --> 00:05:30.560]   He does.
[00:05:30.560 --> 00:05:31.720]   No.
[00:05:31.720 --> 00:05:33.200]   I think we have to have--
[00:05:33.200 --> 00:05:34.200]   it's not by Southwest.
[00:05:34.200 --> 00:05:37.040]   I think we have to have a Leo off.
[00:05:37.040 --> 00:05:40.160]   You're kidding me.
[00:05:40.160 --> 00:05:41.160]   What group will I test?
[00:05:41.160 --> 00:05:42.080]   Two plus one.
[00:05:42.080 --> 00:05:42.880]   Who's Theo?
[00:05:42.880 --> 00:05:46.200]   Well, Eileen, you knew about this and didn't tell me.
[00:05:46.200 --> 00:05:47.200]   I want to hear it.
[00:05:47.200 --> 00:05:48.320]   I'm going back in time.
[00:05:48.320 --> 00:05:50.400]   And it's all recorded.
[00:05:50.400 --> 00:05:51.080]   That's good.
[00:05:51.080 --> 00:05:52.120]   Well, he should.
[00:05:52.120 --> 00:05:53.160]   He's a talented guy.
[00:05:53.160 --> 00:05:54.560]   I really think Tom is so great.
[00:05:54.560 --> 00:05:58.120]   What a stellar addition to the network he has been.
[00:05:58.120 --> 00:05:58.640]   He's a natural.
[00:05:58.640 --> 00:06:00.760]   The guy never says, um, it's amazing.
[00:06:00.760 --> 00:06:01.400]   Yeah, he's really talented.
[00:06:01.400 --> 00:06:02.120]   I've never heard him say--
[00:06:02.120 --> 00:06:02.480]   He's really talented.
[00:06:02.480 --> 00:06:03.080]   --that he's really talented.
[00:06:03.080 --> 00:06:04.080]   Yeah.
[00:06:04.080 --> 00:06:05.360]   Well, thank you, Tom, for filling in.
[00:06:05.360 --> 00:06:07.880]   I really appreciate it.
[00:06:07.880 --> 00:06:09.320]   And you mentioned South by Southwest.
[00:06:09.320 --> 00:06:11.800]   That's where we will all be together again.
[00:06:11.800 --> 00:06:13.320]   I think Becky's going to be there.
[00:06:13.320 --> 00:06:16.600]   We're doing a Twit at Momos.
[00:06:16.600 --> 00:06:22.600]   If you go to Inside.Twit.TV, that's our company blog.
[00:06:22.600 --> 00:06:24.840]   Eileen's put up all the information
[00:06:24.840 --> 00:06:27.400]   you need to know about South by Southwest.
[00:06:27.400 --> 00:06:30.800]   We did Twit there last year with you two and a bunch of others.
[00:06:30.800 --> 00:06:32.600]   And I think we're going to have a very--
[00:06:32.600 --> 00:06:35.160]   Well, how big is the current cast?
[00:06:35.160 --> 00:06:39.440]   It's fairly large, I believe.
[00:06:39.440 --> 00:06:40.920]   But we're going to do it from Momos, which
[00:06:40.920 --> 00:06:44.120]   is a nice little club in Austin.
[00:06:44.120 --> 00:06:45.680]   Not right on 6th.
[00:06:45.680 --> 00:06:47.640]   How far off of 6th is it?
[00:06:47.640 --> 00:06:50.240]   It's like a mile?
[00:06:50.240 --> 00:06:52.320]   Cabot, probably.
[00:06:52.320 --> 00:06:54.640]   We're going to be Sunday, March 13.
[00:06:54.640 --> 00:06:56.920]   I'm going to do the radio show at 1.
[00:06:56.920 --> 00:07:00.000]   Tom will do his show TNT at 4.
[00:07:00.000 --> 00:07:03.960]   And then we're doing Twit at 5.
[00:07:03.960 --> 00:07:05.760]   And we'll do a meetup after Twit.
[00:07:05.760 --> 00:07:07.480]   And I'll be there.
[00:07:07.480 --> 00:07:08.120]   Tom will be there.
[00:07:08.120 --> 00:07:09.440]   Sarah, Brian, Brushwood.
[00:07:09.440 --> 00:07:11.840]   And we hope you two will also be part of it.
[00:07:11.840 --> 00:07:12.560]   That wouldn't miss it.
[00:07:12.560 --> 00:07:13.000]   Highlight.
[00:07:13.000 --> 00:07:13.560]   Absolutely.
[00:07:13.560 --> 00:07:14.080]   Good.
[00:07:14.080 --> 00:07:15.000]   And I'll be--
[00:07:15.000 --> 00:07:15.480]   Yay.
[00:07:15.480 --> 00:07:17.200]   You'll have to kick us off stage.
[00:07:17.200 --> 00:07:19.400]   You'll have to shove us off.
[00:07:19.400 --> 00:07:21.320]   Well, I don't think there'll be a large enough crowd for me
[00:07:21.320 --> 00:07:23.480]   to throw you into the crowd for crowd surfing.
[00:07:23.480 --> 00:07:25.080]   Crowd surfing.
[00:07:25.080 --> 00:07:29.440]   If there is, the challenge will be on.
[00:07:29.440 --> 00:07:34.760]   See if you can do a longer live crowd surf than I did last year.
[00:07:34.760 --> 00:07:37.040]   I think that just goes down in the Hall of Fame.
[00:07:37.040 --> 00:07:38.560]   Yeah, I think that will never be doing it.
[00:07:38.560 --> 00:07:40.600]   I was so happy I was there for that moment.
[00:07:40.600 --> 00:07:42.000]   It was the greatest moment ever.
[00:07:42.000 --> 00:07:43.000]   It's not my self-help.
[00:07:43.000 --> 00:07:43.920]   It was a lot of--
[00:07:43.920 --> 00:07:45.400]   It was a lot.
[00:07:45.400 --> 00:07:51.120]   When you went down, did you at that moment kind of say, oh, crap.
[00:07:51.120 --> 00:07:52.280]   What have I just done?
[00:07:52.280 --> 00:07:53.200]   No, I was ignorant.
[00:07:53.200 --> 00:07:55.400]   I found out later that it's actually dangerous
[00:07:55.400 --> 00:07:59.200]   that the crowd dropped meatloaf once.
[00:07:59.200 --> 00:08:01.480]   And he broke his elbow.
[00:08:01.480 --> 00:08:04.360]   And there are a couple of instances of performers
[00:08:04.360 --> 00:08:07.440]   jumping into the crowd and being dropped.
[00:08:07.440 --> 00:08:09.680]   But I don't know if I said this on the air.
[00:08:09.680 --> 00:08:10.840]   I hope I'm not repeating myself.
[00:08:10.840 --> 00:08:12.520]   But as I get older, I find I do often.
[00:08:12.520 --> 00:08:15.440]   But for me, there was a great metaphor there
[00:08:15.440 --> 00:08:18.080]   because my whole career has been
[00:08:18.080 --> 00:08:22.440]   buoyed, supported by this great community that we have around us.
[00:08:22.440 --> 00:08:29.720]   And this was a very visceral, real experience of me jumping
[00:08:29.720 --> 00:08:34.360]   leap of faith out into this crowd and then carrying me gently along.
[00:08:34.360 --> 00:08:34.360]   Wow.
[00:08:34.360 --> 00:08:36.120]   That's really amazing.
[00:08:36.120 --> 00:08:36.920]   See?
[00:08:36.920 --> 00:08:38.520]   I'm not such a--
[00:08:38.520 --> 00:08:40.040]   I hadn't thought about the D-Fellow South.
[00:08:40.040 --> 00:08:41.040]   Oh, I did.
[00:08:41.040 --> 00:08:42.320]   That is something.
[00:08:42.320 --> 00:08:42.840]   OK.
[00:08:42.840 --> 00:08:45.040]   Oh, I was thinking as I'm going, I'm thinking, wow,
[00:08:45.040 --> 00:08:47.840]   this is a metaphor for my entire career.
[00:08:47.840 --> 00:08:50.680]   It was really wonderful.
[00:08:50.680 --> 00:08:54.600]   Hey, quickly, I didn't see it because I was on a boat.
[00:08:54.600 --> 00:08:58.880]   But a couple of things happened while I was on a boat.
[00:08:58.880 --> 00:09:01.440]   Egypt, revolution.
[00:09:01.440 --> 00:09:02.880]   Big, you know.
[00:09:02.880 --> 00:09:03.760]   Facebook started.
[00:09:03.760 --> 00:09:04.920]   Google started it, I guess.
[00:09:04.920 --> 00:09:08.120]   Google executive started it on Facebook.
[00:09:08.120 --> 00:09:10.880]   Twitter powered it.
[00:09:10.880 --> 00:09:13.880]   And IBM beat Ken Jennings on Jeopardy.
[00:09:13.880 --> 00:09:16.800]   I'm not sure which is more important, to be honest with you.
[00:09:16.800 --> 00:09:20.320]   No, I do know which is more important.
[00:09:20.320 --> 00:09:22.560]   But we've talked a lot about the amazing--
[00:09:22.560 --> 00:09:24.920]   I'm sure you did last week and the week before about the amazing
[00:09:24.920 --> 00:09:28.640]   role of social media and Google specifically in the Egyptian
[00:09:28.640 --> 00:09:30.600]   revolution.
[00:09:30.600 --> 00:09:31.120]   We did.
[00:09:31.120 --> 00:09:33.520]   But we have not talked yet about Watson.
[00:09:33.520 --> 00:09:42.600]   I didn't see it, but boy, that's a pretty amazing thing.
[00:09:42.600 --> 00:09:44.960]   Let's play a little bit of Jeopardy, shall we?
[00:09:44.960 --> 00:09:47.280]   The quotation marks.
[00:09:47.280 --> 00:09:48.920]   What to wear?
[00:09:48.920 --> 00:09:50.600]   US geographic nicknames.
[00:09:50.600 --> 00:09:51.760]   This is a double Jeopardy, right?
[00:09:51.760 --> 00:09:54.360]   Magical, mousery tour.
[00:09:54.360 --> 00:09:54.960]   And finally, the name.
[00:09:54.960 --> 00:09:57.440]   So Watson is a computer created by IBM.
[00:09:57.440 --> 00:09:59.920]   Let's do familiar sayings for 1,200.
[00:09:59.920 --> 00:10:01.800]   If you're one of these capable fellows,
[00:10:01.800 --> 00:10:04.440]   you're unfortunately master of none.
[00:10:04.440 --> 00:10:04.840]   Brad.
[00:10:04.840 --> 00:10:05.960]   What is a jack of all trades?
[00:10:05.960 --> 00:10:06.520]   Yeah.
[00:10:06.520 --> 00:10:07.240]   1,600 for William.
[00:10:07.240 --> 00:10:07.720]   He beat Watson.
[00:10:07.720 --> 00:10:09.080]   Watson's kind of stoic.
[00:10:09.080 --> 00:10:11.280]   He's a horse designed by this.
[00:10:11.280 --> 00:10:11.640]   Ken.
[00:10:11.640 --> 00:10:12.400]   What's a committee?
[00:10:12.400 --> 00:10:12.880]   Good.
[00:10:12.880 --> 00:10:14.480]   Fennelier sayings for 2,000.
[00:10:14.480 --> 00:10:15.480]   It's a poor work--
[00:10:15.480 --> 00:10:18.280]   It's kind of fun because you're showing Watson thinking.
[00:10:18.280 --> 00:10:19.360]   Watson, what are tools?
[00:10:19.360 --> 00:10:20.720]   You are right for 2,000.
[00:10:20.720 --> 00:10:21.880]   That's creepy!
[00:10:21.880 --> 00:10:23.280]   For 1,600.
[00:10:23.280 --> 00:10:24.920]   Some would say it sounds like Zuckerberg.
[00:10:24.920 --> 00:10:27.600]   So I'm honestly titled his memoir, A Heartbreaking--
[00:10:27.600 --> 00:10:28.560]   No, he's more eloquent.
[00:10:28.560 --> 00:10:29.560]   And fluid.
[00:10:29.560 --> 00:10:30.360]   Oh.
[00:10:30.360 --> 00:10:31.960]   What is staggering genius?
[00:10:31.960 --> 00:10:33.440]   That's right.
[00:10:33.440 --> 00:10:35.480]   Same category, 1,200.
[00:10:35.480 --> 00:10:37.240]   Answer, A-A-W-O.
[00:10:37.240 --> 00:10:40.280]   Oh, do you not think this is creepy?
[00:10:40.280 --> 00:10:42.280]   I mean, it's awe-inspiring and creepy.
[00:10:42.280 --> 00:10:46.160]   I'll wager $2,127.
[00:10:46.160 --> 00:10:49.640]   By the way, you know that's exactly the right amount to wager,
[00:10:49.640 --> 00:10:51.080]   right?
[00:10:51.080 --> 00:10:52.240]   Who would even come up with that?
[00:10:52.240 --> 00:10:53.720]   New Yorkers, 1959.
[00:10:53.720 --> 00:10:55.440]   Actually, they didn't talk about his algorithm
[00:10:55.440 --> 00:10:56.520]   for coming up with Daily Double.
[00:10:56.520 --> 00:10:57.840]   I did not want the two.
[00:10:57.840 --> 00:11:00.000]   OK, the New Yorkers, 1959 review.
[00:11:00.000 --> 00:11:03.640]   Let's play Jeopardy.
[00:11:03.640 --> 00:11:05.920]   I'd like to remind you you need to state your answer
[00:11:05.920 --> 00:11:07.520]   as a question.
[00:11:07.520 --> 00:11:10.520]   The New Yorkers, 1959 review of this,
[00:11:10.520 --> 00:11:12.400]   said in its brevity and clarity,
[00:11:12.400 --> 00:11:19.400]   it is unlike most such manuals, a book, as well as a tool.
[00:11:19.400 --> 00:11:22.400]   Jeff Jarvis.
[00:11:22.400 --> 00:11:23.240]   Strunk and white.
[00:11:23.240 --> 00:11:24.560]   That's what I would have said.
[00:11:24.560 --> 00:11:25.320]   You agree, Gina?
[00:11:25.320 --> 00:11:25.760]   What is this one?
[00:11:25.760 --> 00:11:26.240]   What is--
[00:11:26.240 --> 00:11:26.740]   What is--
[00:11:26.740 --> 00:11:30.640]   Oh, by the way, Watson would not forget to do that.
[00:11:30.640 --> 00:11:33.640]   So we're going to say, what is Elements of Style?
[00:11:33.640 --> 00:11:34.140]   Let's see.
[00:11:34.140 --> 00:11:36.840]   He said, in its brevity and clarity,
[00:11:36.840 --> 00:11:41.640]   it is unlike most such manuals, a book, as well as a tool.
[00:11:41.640 --> 00:11:42.680]   Let's try.
[00:11:42.680 --> 00:11:44.480]   What is Dorothy Parker?
[00:11:44.480 --> 00:11:45.480]   Oh!
[00:11:45.480 --> 00:11:46.760]   Oh, no.
[00:11:46.760 --> 00:11:49.120]   The work was the Elements of Style.
[00:11:49.120 --> 00:11:49.600]   Only 10%--
[00:11:49.600 --> 00:11:51.200]   That's 10% confidence.
[00:11:51.200 --> 00:11:52.560]   Yeah, isn't that interesting?
[00:11:52.560 --> 00:11:54.400]   Yeah, I love the confidence readings.
[00:11:54.400 --> 00:11:55.440]   I love the buzzer threshold.
[00:11:55.440 --> 00:11:57.600]   You know, you had a certain threshold where you'd only buzz
[00:11:57.600 --> 00:11:58.420]   if you had an answer.
[00:11:58.420 --> 00:12:00.140]   I mean, not on that one because it was a daily double,
[00:12:00.140 --> 00:12:01.620]   but I loved it.
[00:12:01.620 --> 00:12:02.180]   It was fascinating.
[00:12:02.180 --> 00:12:04.420]   The first five minutes I was kind of creeped out.
[00:12:04.420 --> 00:12:07.380]   But then I was just cool to see and to kind of think
[00:12:07.380 --> 00:12:08.460]   about the different circumstances.
[00:12:08.460 --> 00:12:11.980]   Like, Watson got all the answers in text, right?
[00:12:11.980 --> 00:12:13.380]   But Trebek was reading them aloud.
[00:12:13.380 --> 00:12:15.820]   So that made me wonder, at what point does Watson
[00:12:15.820 --> 00:12:16.540]   get the text, right?
[00:12:16.540 --> 00:12:18.860]   Because you listen-- listening is to speech
[00:12:18.860 --> 00:12:21.620]   is slower than reading text, especially for a computer.
[00:12:21.620 --> 00:12:23.180]   So I kept thinking about things like that.
[00:12:23.180 --> 00:12:27.160]   Because there was actually a buzzer that Watson pressed.
[00:12:27.160 --> 00:12:27.680]   Physically?
[00:12:27.680 --> 00:12:28.180]   There was a mechanism.
[00:12:28.180 --> 00:12:28.840]   Physically, yeah.
[00:12:28.840 --> 00:12:30.840]   There was a physical mechanism that matched down
[00:12:30.840 --> 00:12:32.400]   on a buzzer, just like the humans.
[00:12:32.400 --> 00:12:34.040]   And it wasn't connected to the internet, right?
[00:12:34.040 --> 00:12:35.040]   Because a human played--
[00:12:35.040 --> 00:12:35.540]   Right.
[00:12:35.540 --> 00:12:36.540]   It had a database.
[00:12:36.540 --> 00:12:37.040]   --has a set of--
[00:12:37.040 --> 00:12:37.540]   Right.
[00:12:37.540 --> 00:12:38.640]   It had a huge database.
[00:12:38.640 --> 00:12:42.000]   And actually, the room where the Watson system was
[00:12:42.000 --> 00:12:44.520]   was filled with really loud refrigerators.
[00:12:44.520 --> 00:12:48.840]   I think it was like 50 blade servers connected
[00:12:48.840 --> 00:12:49.360]   to Ethernet.
[00:12:49.360 --> 00:12:52.040]   And then it's just like this really loud cooling system.
[00:12:52.040 --> 00:12:53.920]   But I love that it was really, really cool.
[00:12:53.920 --> 00:12:56.920]   Like Ken Jennings said that he welcomes our new computer
[00:12:56.920 --> 00:12:57.420]   overlords.
[00:12:57.420 --> 00:12:58.520]   I kind of feel the same way.
[00:12:58.520 --> 00:13:00.320]   I love you, Ken.
[00:13:00.320 --> 00:13:01.320]   That's a really good--
[00:13:01.320 --> 00:13:01.760]   He goes back to--
[00:13:01.760 --> 00:13:02.680]   --do he answer.
[00:13:02.680 --> 00:13:03.200]   Yes.
[00:13:03.200 --> 00:13:07.520]   If we saw Google-- if we'd never seen search engines,
[00:13:07.520 --> 00:13:08.560]   we'd never seen the internet.
[00:13:08.560 --> 00:13:11.200]   And suddenly you saw Google fully birthed.
[00:13:11.200 --> 00:13:13.200]   You'd take us creepy.
[00:13:13.200 --> 00:13:14.200]   Yeah.
[00:13:14.200 --> 00:13:14.700]   Right?
[00:13:14.700 --> 00:13:15.760]   Raker's wild.
[00:13:15.760 --> 00:13:16.600]   Raker's wild.
[00:13:16.600 --> 00:13:19.960]   We wrote an article last month in PC Magazine,
[00:13:19.960 --> 00:13:23.160]   why IBM's Jeopardy Victory Matters.
[00:13:23.160 --> 00:13:26.880]   He said when he wrote his book, The Age of Intelligent
[00:13:26.880 --> 00:13:28.560]   Machines in the 1980s, he predicted
[00:13:28.560 --> 00:13:30.440]   that a computer would win the World Chess
[00:13:30.440 --> 00:13:34.760]   Championship by 1998.
[00:13:34.760 --> 00:13:35.800]   He said that was a year off.
[00:13:35.800 --> 00:13:39.960]   It was 1997 that IBM's computer, Deep Blue, Gary
[00:13:39.960 --> 00:13:41.440]   Cusparov.
[00:13:41.440 --> 00:13:43.520]   He said what happened immediately was, of course,
[00:13:43.520 --> 00:13:45.200]   people, humans started rationalizing.
[00:13:45.200 --> 00:13:46.840]   Well, the computer was--
[00:13:46.840 --> 00:13:49.560]   Chess is a completely analytical game.
[00:13:49.560 --> 00:13:51.880]   There's a correct answer at all points.
[00:13:51.880 --> 00:13:55.360]   Blah, blah, blah, blah.
[00:13:55.360 --> 00:13:56.000]   He says no.
[00:13:56.000 --> 00:13:57.960]   This is-- look it.
[00:13:57.960 --> 00:13:59.680]   This is significant.
[00:13:59.680 --> 00:14:01.600]   And he said what was most significant
[00:14:01.600 --> 00:14:04.680]   was that Watson had a sense of humor, or at least appeared to.
[00:14:04.680 --> 00:14:06.440]   Did you notice that?
[00:14:06.440 --> 00:14:07.920]   Gina, did you notice a little sense of humor?
[00:14:07.920 --> 00:14:13.160]   For instance, Ken Jennings selects the chicks dig me category.
[00:14:13.160 --> 00:14:16.080]   He's making a joke, because he says, I've never
[00:14:16.080 --> 00:14:18.160]   said this on TV, chicks dig me.
[00:14:18.160 --> 00:14:18.660]   Ken Jennings.
[00:14:18.660 --> 00:14:19.160]   He's a human.
[00:14:19.160 --> 00:14:19.920]   He made a joke.
[00:14:19.920 --> 00:14:26.560]   Later on, Watson says, let's finish chicks dig me and gets a laugh.
[00:14:26.560 --> 00:14:28.360]   Now, probably inadvertent, right?
[00:14:28.360 --> 00:14:29.480]   Yeah, yeah.
[00:14:29.480 --> 00:14:30.800]   Because there was no speech recognition,
[00:14:30.800 --> 00:14:32.160]   like Watson couldn't hear.
[00:14:32.160 --> 00:14:34.200]   Right.
[00:14:34.200 --> 00:14:36.000]   Here's a question, dumb question.
[00:14:36.000 --> 00:14:37.360]   That's the kind I always ask you to.
[00:14:37.360 --> 00:14:39.640]   Ask the dumb one, because believe me.
[00:14:39.640 --> 00:14:42.000]   Is Watson AI-- is it artificial intelligence,
[00:14:42.000 --> 00:14:43.200]   or is it just--
[00:14:43.200 --> 00:14:43.880]   what is--
[00:14:43.880 --> 00:14:46.160]   Well, AI is kind of a deprecated term these days.
[00:14:46.160 --> 00:14:46.560]   People who--
[00:14:46.560 --> 00:14:48.560]   I know it is, right.
[00:14:48.560 --> 00:14:51.040]   I mean, it's probably a big decision tree.
[00:14:51.040 --> 00:14:51.600]   You know what?
[00:14:51.600 --> 00:14:52.800]   Looking at those conference readings,
[00:14:52.800 --> 00:14:54.960]   that's exactly what a chess computer is doing.
[00:14:54.960 --> 00:14:58.480]   As it's an analog.
[00:14:58.480 --> 00:14:58.840]   I don't know.
[00:14:58.840 --> 00:15:00.400]   Gina, is it AI?
[00:15:00.400 --> 00:15:02.280]   I mean, it's natural language processing, right?
[00:15:02.280 --> 00:15:04.200]   So it's just this giant terabyte of data.
[00:15:04.200 --> 00:15:06.920]   And you just look at things like word frequency.
[00:15:06.920 --> 00:15:08.600]   And I think that some of the scientists
[00:15:08.600 --> 00:15:12.840]   talked about how they tried to identify the nouns and the adjectives
[00:15:12.840 --> 00:15:14.160]   and the verbs inside the answer.
[00:15:14.160 --> 00:15:18.600]   And then, I don't know that it's AI.
[00:15:18.600 --> 00:15:20.360]   It's a more natural language processing.
[00:15:20.360 --> 00:15:21.920]   But it really had to-- because it's jeopardy,
[00:15:21.920 --> 00:15:25.080]   it really had to understand things like references and jokes.
[00:15:25.080 --> 00:15:27.200]   I mean, that was what was so cool about it.
[00:15:27.200 --> 00:15:28.920]   A lot of geeks I saw were kind of felt
[00:15:28.920 --> 00:15:35.280]   like this was this unnecessary display for regular people.
[00:15:35.280 --> 00:15:38.160]   I thought it was such a great PR for IBM.
[00:15:38.160 --> 00:15:41.040]   And I think it was an awesome display of what you can do
[00:15:41.040 --> 00:15:42.880]   when you have the data, what computers can do
[00:15:42.880 --> 00:15:44.040]   when you have the data.
[00:15:44.040 --> 00:15:47.120]   If a computer's going to help me diagnose symptoms
[00:15:47.120 --> 00:15:50.960]   over a course of years that doctors can't, then hey,
[00:15:50.960 --> 00:15:53.720]   yeah, I want to go to Watson for my diagnosis.
[00:15:53.720 --> 00:15:56.680]   Well, it would have been better than my--
[00:15:56.680 --> 00:15:57.280]   exactly.
[00:15:57.280 --> 00:16:01.600]   I was feeding doctors when I had an arterial thing,
[00:16:01.600 --> 00:16:04.120]   my falling apart body.
[00:16:04.120 --> 00:16:05.400]   And I would feed them symptoms.
[00:16:05.400 --> 00:16:07.080]   And they wouldn't listen to the symptoms.
[00:16:07.080 --> 00:16:08.720]   They would just jump to their own conclusion.
[00:16:08.720 --> 00:16:12.800]   And I wanted Gregory House MD as an algorithm.
[00:16:12.800 --> 00:16:15.320]   I wanted Watson as a doctor.
[00:16:15.320 --> 00:16:16.040]   Yeah.
[00:16:16.040 --> 00:16:16.760]   Yep.
[00:16:16.760 --> 00:16:17.800]   Yep.
[00:16:17.800 --> 00:16:19.920]   By the way, I really want to plug my good friend,
[00:16:19.920 --> 00:16:22.720]   Stephen Baker, who is the author of Final Jeopardy,
[00:16:22.720 --> 00:16:25.760]   the full story of Watson and Jeopardy, now on sale.
[00:16:25.760 --> 00:16:27.560]   And he's a business week writer.
[00:16:27.560 --> 00:16:29.000]   And he did a really interesting thing
[00:16:29.000 --> 00:16:31.440]   where he wrote the whole book up to the last chapter.
[00:16:31.440 --> 00:16:32.800]   He could find it without it.
[00:16:32.800 --> 00:16:33.800]   Yeah.
[00:16:33.800 --> 00:16:35.720]   And then get the last chapter immediately.
[00:16:35.720 --> 00:16:37.120]   And Stephen is great.
[00:16:37.120 --> 00:16:38.320]   And I look forward to seeing his book.
[00:16:38.320 --> 00:16:40.480]   So Stephen Baker, Final Jeopardy.
[00:16:40.480 --> 00:16:42.720]   I also apologize to everybody who's listening,
[00:16:42.720 --> 00:16:44.680]   who hasn't yet seen the show, although I don't know why
[00:16:44.680 --> 00:16:46.880]   you wouldn't have seen the show more than a week ago.
[00:16:46.880 --> 00:16:49.920]   But apparently-- and I've learned this, by the way--
[00:16:49.920 --> 00:16:52.880]   after talking about this before the show, on the radio show,
[00:16:52.880 --> 00:16:58.560]   that Jeopardy fans take this game very, very, very seriously.
[00:16:58.560 --> 00:17:02.000]   And I got a lot of people saying, Leo, I hate you.
[00:17:02.000 --> 00:17:03.600]   I was looking forward to this.
[00:17:03.600 --> 00:17:07.720]   You spoiled it by talking about the result.
[00:17:07.720 --> 00:17:08.600]   I had no idea.
[00:17:08.600 --> 00:17:10.600]   I thought it was a TV game show.
[00:17:10.600 --> 00:17:12.560]   Not for Jeopardy crews.
[00:17:12.560 --> 00:17:14.760]   Nobody complains that you was, oh, wheel of fortune.
[00:17:14.760 --> 00:17:16.760]   You said who was going to win.
[00:17:16.760 --> 00:17:19.200]   But Jeopardy is a little different, I guess.
[00:17:19.200 --> 00:17:22.520]   What Ray comes down to is he says,
[00:17:22.520 --> 00:17:26.200]   he has a bet with Mitch Capor that a computer will
[00:17:26.200 --> 00:17:31.160]   pass the Turing test, the very famous test of--
[00:17:31.160 --> 00:17:32.560]   it's complicated, but I could boil it down.
[00:17:32.560 --> 00:17:36.320]   It simply is a computer indistinguishable from a human
[00:17:36.320 --> 00:17:39.680]   to a third party who's not in the know.
[00:17:39.680 --> 00:17:43.600]   And Ray Kurzweil said, 2029, absolutely.
[00:17:43.600 --> 00:17:45.040]   And bet 10 grand.
[00:17:45.040 --> 00:17:46.360]   Capor said, no way.
[00:17:46.360 --> 00:17:48.320]   Capor, of course, the creator of Lotus 123
[00:17:48.320 --> 00:17:50.520]   knows a little bit about computer software.
[00:17:50.520 --> 00:17:52.840]   As does Ray Kurzweil, who is one of the premier artificial
[00:17:52.840 --> 00:17:55.120]   intelligence researchers in the world.
[00:17:55.120 --> 00:17:56.120]   What do you guys think?
[00:17:56.120 --> 00:18:00.760]   Well, I just will say that Ray considers this victory
[00:18:00.760 --> 00:18:02.920]   by Watson absolute proof that it's going to happen.
[00:18:02.920 --> 00:18:04.800]   And it probably happens sooner than 2029.
[00:18:04.800 --> 00:18:07.640]   Because, come on, after all, it might have been hard to tell
[00:18:07.640 --> 00:18:10.080]   that I was a computer.
[00:18:10.080 --> 00:18:11.600]   Yeah, I mean, of course, it helped
[00:18:11.600 --> 00:18:12.960]   that he would change color.
[00:18:12.960 --> 00:18:15.040]   He would go orange when he got things wrong.
[00:18:15.040 --> 00:18:16.400]   So it looked like he was embarrassed.
[00:18:16.400 --> 00:18:19.240]   And the fact that he had a male voice, and that Trebek
[00:18:19.240 --> 00:18:22.680]   kind of referred to him as a he, that part creeped me out
[00:18:22.680 --> 00:18:23.160]   at first.
[00:18:23.160 --> 00:18:25.240]   I mean, I know we call boats she and that kind of thing.
[00:18:25.240 --> 00:18:26.640]   But I was kind of like, it's a computer.
[00:18:26.640 --> 00:18:28.440]   Let's refer to it as an it.
[00:18:28.440 --> 00:18:30.240]   But that's the key in the Turing test
[00:18:30.240 --> 00:18:33.000]   is that you anthropomorphize, right?
[00:18:33.000 --> 00:18:34.000]   Right.
[00:18:34.000 --> 00:18:37.240]   And the Turing test is, can you do it successfully?
[00:18:37.240 --> 00:18:38.920]   No, it doesn't have any rules like,
[00:18:38.920 --> 00:18:42.280]   oh, you're not allowed to turn color or call it a he.
[00:18:42.280 --> 00:18:45.240]   You know, interestingly, if you go to Gina's point about data,
[00:18:45.240 --> 00:18:48.360]   the problem in trying to create the Turing algorithm before
[00:18:48.360 --> 00:18:49.400]   was you didn't have enough data.
[00:18:49.400 --> 00:18:52.840]   Now the web is filled with conversations.
[00:18:52.840 --> 00:18:55.880]   And if the Turing test is to have a conversation
[00:18:55.880 --> 00:18:58.400]   and believe that it's a human being,
[00:18:58.400 --> 00:19:01.160]   the data set of conversations now is incredible.
[00:19:01.160 --> 00:19:02.880]   Yeah, huge.
[00:19:02.880 --> 00:19:06.480]   Yeah, it'll speak like Twitter.
[00:19:06.480 --> 00:19:08.920]   It'll say, well, man, but.
[00:19:08.920 --> 00:19:10.920]   [LAUGHTER]
[00:19:10.920 --> 00:19:12.280]   That's not so bad.
[00:19:12.280 --> 00:19:14.000]   No.
[00:19:14.000 --> 00:19:19.480]   The conclusion of the article, Raker's Wiles says,
[00:19:19.480 --> 00:19:21.280]   what will be the significance of a computer
[00:19:21.280 --> 00:19:24.240]   passing the Turing test if it is really a properly designed
[00:19:24.240 --> 00:19:29.200]   test, it will mean that this AI is truly operating at human
[00:19:29.200 --> 00:19:29.720]   levels.
[00:19:29.720 --> 00:19:31.880]   Now I had a debate with Ray saying,
[00:19:31.880 --> 00:19:32.960]   but it's not human, right?
[00:19:32.960 --> 00:19:34.480]   I mean, it's not.
[00:19:34.480 --> 00:19:36.560]   So what, that it can fool you into thinking human,
[00:19:36.560 --> 00:19:37.760]   that's not the same as human.
[00:19:37.760 --> 00:19:40.080]   And Ray said, but does it matter?
[00:19:40.080 --> 00:19:41.720]   No, it's not human, but does it matter
[00:19:41.720 --> 00:19:44.240]   if it's indistinguishable from human?
[00:19:44.240 --> 00:19:48.560]   He says, I for one would then regard it as human.
[00:19:48.560 --> 00:19:50.720]   I'm expecting this to happen within two decades.
[00:19:50.720 --> 00:19:53.000]   And I also expect when it does, observers
[00:19:53.000 --> 00:19:55.600]   will continue to find things wrong with it.
[00:19:55.600 --> 00:19:57.480]   By the time the controversy dies down
[00:19:57.480 --> 00:20:00.280]   and it becomes unambiguous, as it is now, by the way,
[00:20:00.280 --> 00:20:02.240]   that computers play better chess.
[00:20:02.240 --> 00:20:04.080]   It's going to be pretty unambiguous pretty soon
[00:20:04.080 --> 00:20:05.680]   that computers will beat everybody at Chevy.
[00:20:05.680 --> 00:20:08.320]   If it beats Ken Jennings, who's never been beaten,
[00:20:08.320 --> 00:20:11.720]   OK, it beat the world champion at jeopardy, right?
[00:20:11.720 --> 00:20:13.520]   He says, by the time the controversy dies down,
[00:20:13.520 --> 00:20:16.160]   it becomes unambiguous that non-biological intelligence
[00:20:16.160 --> 00:20:19.040]   is equal to biological human intelligence,
[00:20:19.040 --> 00:20:26.320]   then AI's will already be thousands of times smarter than us.
[00:20:26.320 --> 00:20:29.400]   But keep in mind, this is not an alien invasion from Mars.
[00:20:29.400 --> 00:20:33.080]   Weerk-- this is another argument I had with Ray.
[00:20:33.080 --> 00:20:34.560]   Well, that's the Terminator.
[00:20:34.560 --> 00:20:37.400]   I mean, they're just going to wipe us out.
[00:20:37.400 --> 00:20:37.900]   Yeah.
[00:20:37.900 --> 00:20:39.400]   He says, we're inferior.
[00:20:39.400 --> 00:20:39.880]   Right.
[00:20:39.880 --> 00:20:40.920]   He says, no.
[00:20:40.920 --> 00:20:43.160]   We're creating these technologies to extend our reach.
[00:20:43.160 --> 00:20:46.040]   The fact that farmers in China can access all of human knowledge
[00:20:46.040 --> 00:20:47.640]   with devices they carry in their pockets
[00:20:47.640 --> 00:20:51.240]   is a testament to the fact that we are doing this already.
[00:20:51.240 --> 00:20:53.440]   Ultimately, we will vastly extend and expand
[00:20:53.440 --> 00:20:55.560]   our own intelligence by merging with these tools
[00:20:55.560 --> 00:20:56.560]   of our own creation.
[00:20:56.560 --> 00:21:00.120]   He told me, they won't kill us.
[00:21:00.120 --> 00:21:02.720]   We're their daddy.
[00:21:02.720 --> 00:21:05.960]   They will revere us.
[00:21:05.960 --> 00:21:08.960]   That worked really well on bad historical actica.
[00:21:08.960 --> 00:21:10.480]   Yeah.
[00:21:10.480 --> 00:21:12.200]   Hey, I created you.
[00:21:12.200 --> 00:21:14.680]   Stop it.
[00:21:14.680 --> 00:21:17.560]   What do you think?
[00:21:17.560 --> 00:21:19.960]   Ray believes we're nearing very near what
[00:21:19.960 --> 00:21:21.240]   he calls a singularity.
[00:21:21.240 --> 00:21:23.680]   By the way, we're going to talk to Ray Kurzweil in two weeks.
[00:21:23.680 --> 00:21:25.800]   And that would absolutely be one of the topics on our--
[00:21:25.800 --> 00:21:26.800]   A lot.
[00:21:26.800 --> 00:21:27.800]   --is a pleasure.
[00:21:27.800 --> 00:21:28.800]   I will be tuning into that.
[00:21:28.800 --> 00:21:30.520]   It sounds very interesting.
[00:21:30.520 --> 00:21:33.960]   And if you read his book, The Singularity is Near,
[00:21:33.960 --> 00:21:35.440]   or The Age of Intelligent Machines,
[00:21:35.440 --> 00:21:38.160]   or The Age of Spiritual Machines, all of which
[00:21:38.160 --> 00:21:40.800]   kind of in one way or another deal with this,
[00:21:40.800 --> 00:21:44.040]   it's pretty convincing.
[00:21:44.040 --> 00:21:45.560]   He's the guy who also said, I just
[00:21:45.560 --> 00:21:48.240]   want to live long enough to live forever.
[00:21:48.240 --> 00:21:51.600]   Because he believes if he can survive 20 years,
[00:21:51.600 --> 00:21:53.240]   he'll be able to pour his brain into a machine,
[00:21:53.240 --> 00:21:54.320]   and he never die.
[00:21:55.320 --> 00:21:57.880]   That's kind of a simplification of it.
[00:21:57.880 --> 00:22:00.600]   So do you fear this, Gina?
[00:22:00.600 --> 00:22:01.800]   I don't.
[00:22:01.800 --> 00:22:02.960]   I look forward to this.
[00:22:02.960 --> 00:22:04.520]   You're a programmer.
[00:22:04.520 --> 00:22:05.720]   I guess so.
[00:22:05.720 --> 00:22:07.200]   So what in the chat room is asking,
[00:22:07.200 --> 00:22:09.600]   would you hire Watson as a lawyer or maybe an accountant?
[00:22:09.600 --> 00:22:10.160]   You bet.
[00:22:10.160 --> 00:22:11.160]   You bet.
[00:22:11.160 --> 00:22:11.160]   Absolutely.
[00:22:11.160 --> 00:22:12.760]   Definitely is an accountant.
[00:22:12.760 --> 00:22:13.280]   Definitely.
[00:22:13.280 --> 00:22:14.560]   Definitely is an accountant.
[00:22:14.560 --> 00:22:17.200]   If the goal is make me pay the fewest amount of taxes
[00:22:17.200 --> 00:22:20.440]   possible, definitely Watson would do better than my accountant.
[00:22:20.440 --> 00:22:23.920]   Sorry to my accountant.
[00:22:23.920 --> 00:22:28.240]   But this kind of thing just makes me really happy to be alive
[00:22:28.240 --> 00:22:29.840]   at this point in the world.
[00:22:29.840 --> 00:22:33.200]   We may see an amazing thing.
[00:22:33.200 --> 00:22:34.720]   You will see it in your lifetime, Gina.
[00:22:34.720 --> 00:22:36.320]   I don't know if Jeff and I will make it.
[00:22:36.320 --> 00:22:37.360]   It's really touch and go.
[00:22:37.360 --> 00:22:38.760]   Especially me.
[00:22:38.760 --> 00:22:40.320]   Are you falling apart, Jeff?
[00:22:40.320 --> 00:22:41.320]   I'm falling apart.
[00:22:41.320 --> 00:22:42.000]   I'm a mess.
[00:22:42.000 --> 00:22:42.720]   Is this something new?
[00:22:42.720 --> 00:22:43.480]   This is--
[00:22:43.480 --> 00:22:44.760]   No, no, nothing new this time.
[00:22:44.760 --> 00:22:45.880]   But it's every few.
[00:22:45.880 --> 00:22:47.640]   I'm going for a hat trick, so--
[00:22:47.640 --> 00:22:48.840]   Jeez.
[00:22:48.840 --> 00:22:50.480]   No, hang in there, Jeff.
[00:22:50.480 --> 00:22:50.960]   Yeah.
[00:22:50.960 --> 00:22:53.280]   You just have to live long enough to live forever.
[00:22:53.280 --> 00:22:56.360]   I will pour me into the computer now.
[00:22:56.360 --> 00:22:57.040]   I figure--
[00:22:57.040 --> 00:22:58.720]   You just need to make Jeff a note on the network.
[00:22:58.720 --> 00:22:59.640]   That's all.
[00:22:59.640 --> 00:23:02.040]   That's what we do that way.
[00:23:02.040 --> 00:23:06.360]   We could be doing this show well into the 30th century.
[00:23:06.360 --> 00:23:07.720]   Wouldn't that be funny?
[00:23:07.720 --> 00:23:08.920]   It's time for Twig.
[00:23:08.920 --> 00:23:09.440]   Hello.
[00:23:09.440 --> 00:23:12.080]   Number 4,676.
[00:23:12.080 --> 00:23:13.560]   What is elements of style?
[00:23:13.560 --> 00:23:16.400]   See, I knew that.
[00:23:16.400 --> 00:23:18.360]   I hope this doesn't come off as a flip because I
[00:23:18.360 --> 00:23:18.840]   mean it.
[00:23:18.840 --> 00:23:20.320]   The first person in the board of the computer
[00:23:20.320 --> 00:23:21.800]   are Steve Jobs.
[00:23:21.800 --> 00:23:22.400]   No kidding.
[00:23:22.400 --> 00:23:24.320]   And I hope it won't be too late.
[00:23:24.320 --> 00:23:25.640]   But yeah.
[00:23:25.640 --> 00:23:26.160]   You're right.
[00:23:26.160 --> 00:23:27.680]   He will--
[00:23:27.680 --> 00:23:29.720]   God, I'm praying for him because he's
[00:23:29.720 --> 00:23:33.920]   so important to this revolution that we're in the middle of.
[00:23:33.920 --> 00:23:35.440]   Yes.
[00:23:35.440 --> 00:23:37.880]   But you know who will be the first person, by the way,
[00:23:37.880 --> 00:23:38.800]   just so you know.
[00:23:38.800 --> 00:23:40.120]   Mark Zuckerberg.
[00:23:40.120 --> 00:23:41.200]   Mark Zuckerberg.
[00:23:41.200 --> 00:23:41.720]   Just so you know.
[00:23:41.720 --> 00:23:43.760]   He didn't-- everybody at that dinner with Obama last week,
[00:23:43.760 --> 00:23:44.400]   right?
[00:23:44.400 --> 00:23:45.720]   We'll want in the jar.
[00:23:45.720 --> 00:23:46.160]   Yeah.
[00:23:46.160 --> 00:23:49.840]   Larry, Sergey, Mark, and Steve.
[00:23:49.840 --> 00:23:50.840]   Yeah.
[00:23:50.840 --> 00:23:52.960]   Sounds like a rock group.
[00:23:52.960 --> 00:23:54.400]   It's not a bad world.
[00:23:54.400 --> 00:23:56.120]   It's not a bad.
[00:23:56.120 --> 00:23:59.880]   Now absolutely, Mark Zuckerberg is right on track.
[00:23:59.880 --> 00:24:00.560]   You know what?
[00:24:00.560 --> 00:24:00.960]   I'm going to interview--
[00:24:00.960 --> 00:24:02.320]   he's rich enough.
[00:24:02.320 --> 00:24:03.880]   And gosh darn it, people like him.
[00:24:03.880 --> 00:24:09.160]   When I interviewed Zuckerberg, my editor hated this line.
[00:24:09.160 --> 00:24:11.440]   But I argued with him when I keep it in.
[00:24:11.440 --> 00:24:13.400]   He said, we're not in the technology business so much
[00:24:13.400 --> 00:24:14.920]   as we're in the sociology business.
[00:24:14.920 --> 00:24:15.920]   Well, he's right.
[00:24:15.920 --> 00:24:16.480]   And he is.
[00:24:16.480 --> 00:24:18.120]   I mean, he's human engineering.
[00:24:18.120 --> 00:24:19.960]   He's engineering society.
[00:24:19.960 --> 00:24:21.400]   And that's what's fascinating.
[00:24:21.400 --> 00:24:25.040]   I actually said that on this show a year ago, I said,
[00:24:25.040 --> 00:24:27.360]   what Google needs to do is hire more sociologists
[00:24:27.360 --> 00:24:29.640]   and fewer computer scientists.
[00:24:29.640 --> 00:24:32.400]   Because the computer science problems are not intractable.
[00:24:32.400 --> 00:24:33.560]   They're not difficult.
[00:24:33.560 --> 00:24:39.400]   But the user interface is a way of taking complexity
[00:24:39.400 --> 00:24:40.040]   and making it simple.
[00:24:40.040 --> 00:24:41.920]   All of that is very hard.
[00:24:41.920 --> 00:24:44.560]   Well, it goes back to Facebook again.
[00:24:44.560 --> 00:24:48.480]   Yuri Milner, who's a major investor in Facebook now,
[00:24:48.480 --> 00:24:52.960]   has told me that his entire investment strategy is AI.
[00:24:52.960 --> 00:24:55.160]   That he believes that if you take data that
[00:24:55.160 --> 00:24:57.600]   exists in a Facebook or one of the prosumes, I guess,
[00:24:57.600 --> 00:25:00.520]   Zynga as well, and you add AI to it,
[00:25:00.520 --> 00:25:05.640]   he says there's this giant leap that occurs.
[00:25:05.640 --> 00:25:06.640]   Yeah, that makes sense.
[00:25:06.640 --> 00:25:07.840]   It's that data set thing.
[00:25:07.840 --> 00:25:08.800]   The bigger--
[00:25:08.800 --> 00:25:09.880]   It's the bigger the data set.
[00:25:09.880 --> 00:25:10.560]   Yeah.
[00:25:10.560 --> 00:25:11.760]   The more you can do with it.
[00:25:11.760 --> 00:25:15.440]   Well, OK, who has the biggest data set right now?
[00:25:15.440 --> 00:25:16.120]   Google.
[00:25:16.120 --> 00:25:17.120]   Google.
[00:25:17.120 --> 00:25:20.840]   But Google's data set is about data.
[00:25:20.840 --> 00:25:23.080]   Facebook's data set is about people.
[00:25:23.080 --> 00:25:24.400]   Well, that's true.
[00:25:24.400 --> 00:25:27.800]   If you look at it another way and say, the way I ask it in the book
[00:25:27.800 --> 00:25:31.160]   is who's the best signal generator of human--
[00:25:31.160 --> 00:25:33.720]   OK, that's a probably better measurement, huh?
[00:25:33.720 --> 00:25:34.080]   Right?
[00:25:34.080 --> 00:25:34.440]   And so--
[00:25:34.440 --> 00:25:35.760]   Yeah, things because more structured data
[00:25:35.760 --> 00:25:37.480]   and people-centric data, right?
[00:25:37.480 --> 00:25:38.160]   Yeah, for now.
[00:25:38.160 --> 00:25:39.000]   I think it could change.
[00:25:39.000 --> 00:25:42.320]   Google, that's why-- to my mind, that's why Android.
[00:25:42.320 --> 00:25:44.240]   And with Android, Google knows where we are,
[00:25:44.240 --> 00:25:46.920]   what we're looking for, what we want, where we're going,
[00:25:46.920 --> 00:25:48.200]   where we've been.
[00:25:48.200 --> 00:25:50.400]   Those are very, very important signals.
[00:25:50.400 --> 00:25:54.840]   Facebook knows who we know, what we like, what we talk about,
[00:25:54.840 --> 00:25:59.000]   and how you become the best signal generator,
[00:25:59.000 --> 00:26:02.120]   and then the best analyst of those signals
[00:26:02.120 --> 00:26:04.120]   to become the best exploiter of those signals
[00:26:04.120 --> 00:26:06.520]   to give us relevance.
[00:26:06.520 --> 00:26:11.360]   And relevance-- I saw the Guardian some time ago
[00:26:11.360 --> 00:26:15.120]   did some kind of random story generator.
[00:26:15.120 --> 00:26:16.440]   It was an effort to get the serendipity.
[00:26:16.440 --> 00:26:18.040]   And I said, no, serendipity is not that.
[00:26:18.040 --> 00:26:19.640]   Serendipity is not randomness.
[00:26:19.640 --> 00:26:21.520]   It's relevance we didn't expect.
[00:26:21.520 --> 00:26:22.840]   Ah.
[00:26:22.840 --> 00:26:23.560]   Right?
[00:26:23.560 --> 00:26:26.800]   And so that's what both Google and Facebook
[00:26:26.800 --> 00:26:29.800]   want to be able to do is finally get the real terrain
[00:26:29.800 --> 00:26:32.320]   test is when they're a step ahead of us.
[00:26:32.320 --> 00:26:34.080]   That's what Eric was saying when he said,
[00:26:34.080 --> 00:26:35.720]   we'll know what you want before you will.
[00:26:35.720 --> 00:26:36.800]   Exactly.
[00:26:36.800 --> 00:26:37.320]   Exactly.
[00:26:37.320 --> 00:26:41.080]   It is-- it is-- the next book I should do is Eric Schmitz
[00:26:41.080 --> 00:26:44.040]   quotes the get me in trouble.
[00:26:44.040 --> 00:26:45.160]   It's a long book.
[00:26:45.160 --> 00:26:46.160]   It's a long book.
[00:26:46.160 --> 00:26:47.160]   It's a good one.
[00:26:47.160 --> 00:26:48.160]   It's the right to sell.
[00:26:48.160 --> 00:26:49.160]   It's wonderful.
[00:26:49.160 --> 00:26:52.160]   On the official Google blog last week,
[00:26:52.160 --> 00:26:56.680]   this post, an update to Google Social Search,
[00:26:56.680 --> 00:26:58.040]   today we're doing a little bit more
[00:26:58.040 --> 00:26:59.640]   to bring you all the goodness of Google,
[00:26:59.640 --> 00:27:02.120]   plus the opinions of people you care about.
[00:27:02.120 --> 00:27:05.520]   They're incorporating more information
[00:27:05.520 --> 00:27:06.760]   from the people that matter to you,
[00:27:06.760 --> 00:27:08.600]   whether they're publishing on YouTube, Flickr,
[00:27:08.600 --> 00:27:10.160]   on their own blog or website.
[00:27:10.160 --> 00:27:13.760]   So social search results are getting mixed in.
[00:27:13.760 --> 00:27:16.440]   Now, of course, they're presenting those to us.
[00:27:16.440 --> 00:27:18.080]   But if they're presenting this to us,
[00:27:18.080 --> 00:27:19.600]   it's kind of like the tip of the iceberg.
[00:27:19.600 --> 00:27:21.440]   You've got to think that two thirds of this data
[00:27:21.440 --> 00:27:25.800]   is being mined within Google.
[00:27:25.800 --> 00:27:27.160]   Yeah, that's fine.
[00:27:27.160 --> 00:27:30.960]   I was at a privacy conference in Victoria,
[00:27:30.960 --> 00:27:33.400]   BC last week, which is where I did the show from,
[00:27:33.400 --> 00:27:35.920]   with bad Wi-Fi in the hotel room.
[00:27:35.920 --> 00:27:39.400]   And I gave a talk the next morning.
[00:27:39.400 --> 00:27:41.960]   And I got into a tussle with the head of privacy
[00:27:41.960 --> 00:27:45.240]   for Victoria, for BC when she said that Eric Spitz said
[00:27:45.240 --> 00:27:47.520]   that privacy isn't relevant.
[00:27:47.520 --> 00:27:49.040]   I said, he never said that.
[00:27:49.040 --> 00:27:51.160]   But the thing that I asked everyone there to do was,
[00:27:51.160 --> 00:27:52.920]   I said, the next time you hear the word creepy,
[00:27:52.920 --> 00:27:54.560]   which conferences like that, you hear it all the time,
[00:27:54.560 --> 00:27:56.680]   just stop and say, define that, please.
[00:27:56.680 --> 00:27:58.560]   Right?
[00:27:58.560 --> 00:28:00.280]   You know, there's a time we would have thought Google was creepy.
[00:28:00.280 --> 00:28:02.280]   There's a time when all kinds of things seem creepy.
[00:28:02.280 --> 00:28:03.280]   TV seem creepy.
[00:28:03.280 --> 00:28:04.120]   What's creepy?
[00:28:04.120 --> 00:28:04.960]   It means unknown.
[00:28:04.960 --> 00:28:07.600]   So what's in being creepy, AI being creepy,
[00:28:07.600 --> 00:28:08.600]   Turing test being creepy.
[00:28:08.600 --> 00:28:10.000]   It's because we don't know if,
[00:28:10.000 --> 00:28:11.240]   we don't know what can be done with it.
[00:28:11.240 --> 00:28:13.600]   If we instead make it ours and control it,
[00:28:13.600 --> 00:28:14.680]   magnificent things can happen.
[00:28:14.680 --> 00:28:18.320]   - I'll define creepy in a way that maybe doesn't fit that.
[00:28:18.320 --> 00:28:19.720]   It's the uncanny valley.
[00:28:19.720 --> 00:28:22.720]   You know, the animators have this phrase
[00:28:22.720 --> 00:28:26.160]   they use, the uncanny valley where there's a,
[00:28:26.160 --> 00:28:30.080]   human mind is so adept at seeing a human face or hands
[00:28:30.080 --> 00:28:34.280]   or body that if you draw a cartoon, Elmer Fudd
[00:28:34.280 --> 00:28:35.120]   doesn't bother anybody.
[00:28:35.120 --> 00:28:35.960]   They know it's a cartoon.
[00:28:35.960 --> 00:28:38.040]   The brain says, yeah, yes, it's a drawing.
[00:28:38.040 --> 00:28:41.360]   But as you move closer and closer to real humans,
[00:28:41.360 --> 00:28:44.200]   animated humans, there gets this place where you go,
[00:28:44.200 --> 00:28:47.760]   called the uncanny valley where it looks to every,
[00:28:47.760 --> 00:28:50.720]   in every way real, but the brain knows it's not
[00:28:50.720 --> 00:28:54.040]   and it's creepy, real creepy.
[00:28:54.040 --> 00:28:54.880]   That's when I'm--
[00:28:54.880 --> 00:28:56.120]   - Until it starts to look real.
[00:28:56.120 --> 00:28:57.200]   - Right, until we understand--
[00:28:57.200 --> 00:28:58.600]   - Well, it's just a temporary valley, I guess.
[00:28:58.600 --> 00:29:00.240]   - It's temporary, right, it's temporary.
[00:29:00.240 --> 00:29:01.680]   It's temporary until we take control of it.
[00:29:01.680 --> 00:29:02.760]   - So you can cross the valley.
[00:29:02.760 --> 00:29:03.600]   - We can cross the valley.
[00:29:03.600 --> 00:29:04.680]   - We can roll over to stop creepy anymore.
[00:29:04.680 --> 00:29:07.040]   - Right, I mean, I think that's what creepy is for me, right?
[00:29:07.040 --> 00:29:09.920]   Like, I didn't know you that you knew this about me
[00:29:09.920 --> 00:29:10.960]   and then suddenly--
[00:29:10.960 --> 00:29:12.320]   - That's creepy. - You did.
[00:29:12.320 --> 00:29:13.360]   And that creeped me out, right?
[00:29:13.360 --> 00:29:15.320]   Because my perception was that you were this far away,
[00:29:15.320 --> 00:29:17.400]   but it turns out you're standing right over my shoulder
[00:29:17.400 --> 00:29:18.640]   and I didn't know.
[00:29:18.640 --> 00:29:19.520]   So that creeps me out, right?
[00:29:19.520 --> 00:29:20.840]   If someone sneaks up behind me.
[00:29:20.840 --> 00:29:23.720]   So like with the social search that Google just launched,
[00:29:23.720 --> 00:29:24.960]   it's great, I love it.
[00:29:24.960 --> 00:29:27.000]   But the first time, you know, it rolled out,
[00:29:27.000 --> 00:29:28.360]   I hadn't read the news story.
[00:29:28.360 --> 00:29:30.400]   I did a search for something that Adam Pash
[00:29:30.400 --> 00:29:32.040]   at Life Hacker, who I follow on Twitter
[00:29:32.040 --> 00:29:33.800]   and who I email with all the time,
[00:29:33.800 --> 00:29:34.920]   had written about on Life Hacker.
[00:29:34.920 --> 00:29:36.960]   So I do this search and at the top
[00:29:36.960 --> 00:29:38.800]   of this search it says, you know, here's the result
[00:29:38.800 --> 00:29:41.960]   and Adam recommends this or Adam shared this.
[00:29:41.960 --> 00:29:45.160]   And I was like, oh, okay.
[00:29:45.160 --> 00:29:47.240]   And which was great because--
[00:29:47.240 --> 00:29:48.240]   - I can get over that.
[00:29:48.240 --> 00:29:49.240]   I can get over that.
[00:29:49.240 --> 00:29:50.400]   That's not-- - But the first time,
[00:29:50.400 --> 00:29:51.240]   it surprised me.
[00:29:51.240 --> 00:29:52.920]   So I kind of hovered over Adam and said,
[00:29:52.920 --> 00:29:55.840]   oh, you're connected to Adam on Twitter and in Gmail.
[00:29:55.840 --> 00:29:57.080]   Okay, I knew that.
[00:29:57.080 --> 00:29:59.160]   But it's that initial jarring like,
[00:29:59.160 --> 00:30:01.280]   oh, I didn't know that you knew everybody
[00:30:01.280 --> 00:30:02.240]   that I followed on Twitter,
[00:30:02.240 --> 00:30:03.760]   even though that that's public data.
[00:30:03.760 --> 00:30:06.280]   I just, that's something I did over on Twitter.
[00:30:06.280 --> 00:30:11.040]   I think that that's a little tiny example of a little creepy.
[00:30:11.040 --> 00:30:13.400]   That said, the social search results now that I understand
[00:30:13.400 --> 00:30:14.960]   that Google has been crawling all, you know,
[00:30:14.960 --> 00:30:18.080]   knows all my sort of my social graph is fantastic.
[00:30:18.080 --> 00:30:20.800]   Like I love seeing names and faces next to links.
[00:30:20.800 --> 00:30:23.120]   Like, oh yes, this is what I wanna click on.
[00:30:23.120 --> 00:30:24.840]   - Here's a graph from Wikipedia.
[00:30:24.840 --> 00:30:29.280]   Across the X axis is human likeness.
[00:30:29.280 --> 00:30:31.280]   Across the Y axis is familiarity.
[00:30:31.280 --> 00:30:33.720]   And there's the uncanny valley.
[00:30:33.720 --> 00:30:38.720]   So stuffed animal, fine humanoid robot, fine zombie, corpse.
[00:30:38.720 --> 00:30:40.640]   (laughing)
[00:30:40.640 --> 00:30:41.480]   Creepy!
[00:30:41.480 --> 00:30:45.000]   But I would submit there, so we have two kinds of creepy.
[00:30:45.000 --> 00:30:45.960]   Two definitions of creepy.
[00:30:45.960 --> 00:30:48.000]   One, which you and Gina embrace is that,
[00:30:48.000 --> 00:30:49.720]   well, it's technologically sophisticated.
[00:30:49.720 --> 00:30:51.440]   So it surprises us.
[00:30:51.440 --> 00:30:52.680]   But we can get used to that,
[00:30:52.680 --> 00:30:54.880]   technological sophistication you can get used to.
[00:30:54.880 --> 00:30:55.720]   - Yes.
[00:30:55.720 --> 00:30:57.720]   - But I don't think you get used to a zombie.
[00:30:57.720 --> 00:31:03.000]   It's permanently creepy, isn't it?
[00:31:03.000 --> 00:31:05.080]   - Well, I never get used to David Copperfield.
[00:31:05.080 --> 00:31:06.960]   (laughing)
[00:31:06.960 --> 00:31:09.440]   - Or who's that other magician who always goes like this?
[00:31:09.440 --> 00:31:10.280]   - Uh, hmm.
[00:31:10.280 --> 00:31:15.600]   - So I think there's genuine creepiness.
[00:31:15.600 --> 00:31:19.200]   It's not merely that we're technologically, you know,
[00:31:19.200 --> 00:31:20.080]   surprised.
[00:31:20.080 --> 00:31:21.560]   - I don't want this to get misquoted
[00:31:21.560 --> 00:31:22.880]   because I like the guy I respect him
[00:31:22.880 --> 00:31:24.280]   and I'm saying good things about the book.
[00:31:24.280 --> 00:31:27.200]   But I think that's part of why people don't get Zuckerberg.
[00:31:27.200 --> 00:31:28.920]   - He's genuinely creepy.
[00:31:28.920 --> 00:31:29.760]   (laughing)
[00:31:29.760 --> 00:31:31.200]   - Here's why, here's why.
[00:31:31.200 --> 00:31:32.320]   And don't pull folks.
[00:31:32.320 --> 00:31:33.640]   - He's a zombie.
[00:31:33.640 --> 00:31:34.880]   I don't think he has to pull.
[00:31:34.880 --> 00:31:38.360]   - Oh, it's because you would think that he would be,
[00:31:38.360 --> 00:31:39.960]   of course, the most open person on earth.
[00:31:39.960 --> 00:31:42.040]   But in fact, the mystique of Mark Zuckerberg
[00:31:42.040 --> 00:31:43.040]   is that he's mysterious.
[00:31:43.040 --> 00:31:44.040]   - Right.
[00:31:44.040 --> 00:31:47.560]   - And the fact that he needed to be,
[00:31:47.560 --> 00:31:49.960]   and Aaron Sorkin and company tried to interpret him
[00:31:49.960 --> 00:31:51.880]   and I would say badly still.
[00:31:51.880 --> 00:31:53.720]   I know I'm about the only one who says that.
[00:31:53.720 --> 00:31:57.360]   You know, that's where the creepiness comes from
[00:31:57.360 --> 00:31:58.840]   is we don't get him, we don't understand him.
[00:31:58.840 --> 00:32:00.240]   He's not like us.
[00:32:00.240 --> 00:32:02.760]   - Well, certainly as Jesse Eisenberg portrayed him
[00:32:02.760 --> 00:32:05.320]   in the soon to be Academy Award winning movie,
[00:32:05.320 --> 00:32:06.560]   The Social Network,
[00:32:06.560 --> 00:32:10.040]   Eisenberg clearly went for creepy, right?
[00:32:10.040 --> 00:32:10.960]   Kind of subhuman.
[00:32:10.960 --> 00:32:12.320]   - Yes, yes.
[00:32:12.320 --> 00:32:13.680]   - I don't know, you've been with Mark,
[00:32:13.680 --> 00:32:15.400]   is he really that creepy?
[00:32:15.400 --> 00:32:16.720]   - No, I mean, he smiles.
[00:32:16.720 --> 00:32:17.560]   - He's human.
[00:32:17.560 --> 00:32:18.280]   - He smiles, he blinks.
[00:32:18.280 --> 00:32:19.440]   He actually blinks.
[00:32:19.440 --> 00:32:23.520]   You know, I was remembering this
[00:32:23.520 --> 00:32:24.800]   as I was rewriting the chapter, right?
[00:32:24.800 --> 00:32:28.000]   My editor, who's by the way is very happy
[00:32:28.000 --> 00:32:29.920]   to see what you guys were saying about the title
[00:32:29.920 --> 00:32:31.440]   because his boss likes it so.
[00:32:31.440 --> 00:32:32.760]   - We win, we win.
[00:32:32.760 --> 00:32:36.440]   - I'm sorry, Jeff, you should have sent me an email saying,
[00:32:36.440 --> 00:32:37.280]   would you please?
[00:32:37.280 --> 00:32:38.800]   - No, no, no, this is good feedback.
[00:32:38.800 --> 00:32:40.800]   By the way, Gina, are you offended by it, hang out?
[00:32:40.800 --> 00:32:42.160]   Let it all hang out?
[00:32:42.160 --> 00:32:43.480]   - No, not at all.
[00:32:43.480 --> 00:32:46.360]   - To pure all penile or you should be now.
[00:32:46.360 --> 00:32:49.040]   - And that's the publisher's contention.
[00:32:49.040 --> 00:32:49.880]   - Yeah, it's okay.
[00:32:49.880 --> 00:32:51.160]   - Then it's probably the right choice
[00:32:51.160 --> 00:32:54.360]   'cause you can never be to penile or pureile.
[00:32:54.360 --> 00:32:55.200]   - Be it.
[00:32:55.200 --> 00:32:57.200]   - Ah, so.
[00:32:57.200 --> 00:33:00.040]   In fact, if you have the choice between penile, pureile,
[00:33:00.040 --> 00:33:03.240]   or both, I'd go for both.
[00:33:03.240 --> 00:33:05.320]   - Or what's the name of the hand thing?
[00:33:05.320 --> 00:33:07.400]   Purell, penile, purell.
[00:33:07.400 --> 00:33:08.240]   - Oh, yes.
[00:33:08.240 --> 00:33:09.400]   - Well, safe to speak.
[00:33:09.400 --> 00:33:10.240]   - Safe to speak.
[00:33:10.240 --> 00:33:11.080]   - Safe to speak.
[00:33:11.080 --> 00:33:11.920]   - Purell, purell.
[00:33:11.920 --> 00:33:12.760]   - You mean that?
[00:33:12.760 --> 00:33:13.600]   - Geez, little windy.
[00:33:13.600 --> 00:33:15.600]   - That's why I'm safe, I'm sorry.
[00:33:15.600 --> 00:33:18.120]   - Maybe you shouldn't use that as some title.
[00:33:18.120 --> 00:33:19.800]   - Stop, stop, stop.
[00:33:19.800 --> 00:33:23.680]   - So, I remember, I thought back to what I saw Zuckermank
[00:33:23.680 --> 00:33:26.640]   at various events, at pardon me from place dropping Davos
[00:33:26.640 --> 00:33:29.600]   or the Quadraigal Conference or this Murdoch event
[00:33:29.600 --> 00:33:30.960]   where I was brought in to,
[00:33:30.960 --> 00:33:32.440]   and in every one of those cases,
[00:33:32.440 --> 00:33:36.080]   he absolutely threw the business moguls.
[00:33:36.080 --> 00:33:37.280]   Pardon me, light.
[00:33:37.280 --> 00:33:38.120]   - I'm not dead.
[00:33:38.120 --> 00:33:41.640]   Is your soul lighting your computer screen?
[00:33:41.640 --> 00:33:44.160]   Is that why it keeps getting dark?
[00:33:44.160 --> 00:33:46.360]   - Ooh, 'cause I'm actually a zombie.
[00:33:46.360 --> 00:33:47.280]   - Oh geez.
[00:33:47.280 --> 00:33:48.640]   By the way, Nightingale said,
[00:33:48.640 --> 00:33:50.680]   Leo, hang out with a zombie, have a beer with one.
[00:33:50.680 --> 00:33:52.840]   You'd find them not creepy after a while.
[00:33:52.840 --> 00:33:54.400]   So maybe I'm wrong.
[00:33:54.400 --> 00:33:57.640]   So Zuckerberg, what I loved about him on panels and stuff
[00:33:57.640 --> 00:34:01.480]   was that he never said a word more than he had to say.
[00:34:01.480 --> 00:34:05.480]   And he was blunt, politely blunt.
[00:34:05.480 --> 00:34:07.880]   Somebody would ask a question, he would say,
[00:34:07.880 --> 00:34:10.360]   and it was like that one scene in the movie where he said,
[00:34:10.360 --> 00:34:11.440]   you know, why do you say that?
[00:34:11.440 --> 00:34:12.600]   That's just what he was.
[00:34:12.600 --> 00:34:14.520]   He would just answer the question, that's it, no more.
[00:34:14.520 --> 00:34:17.640]   And I loved the fact that he didn't add flowers
[00:34:17.640 --> 00:34:19.360]   and buzzwords and all that,
[00:34:19.360 --> 00:34:20.440]   that he just said what he thought
[00:34:20.440 --> 00:34:21.840]   that was it, bummed on now what.
[00:34:21.840 --> 00:34:23.680]   And it threw everybody for such a loop.
[00:34:23.680 --> 00:34:25.240]   - It's interesting, 'cause that was something
[00:34:25.240 --> 00:34:27.000]   that apparently Aaron Sorkin picked up on,
[00:34:27.000 --> 00:34:29.280]   'cause it's exactly how Aaron Sorkin wrote it.
[00:34:29.280 --> 00:34:32.200]   - So now he's either had media training
[00:34:32.200 --> 00:34:35.600]   or I think more likely he is simply become more-
[00:34:35.600 --> 00:34:36.440]   - He's relaxed.
[00:34:36.440 --> 00:34:37.280]   - He was scared.
[00:34:37.280 --> 00:34:38.240]   - Yeah, he's relaxed.
[00:34:38.240 --> 00:34:41.240]   So we get to see a little more of him now.
[00:34:41.240 --> 00:34:44.560]   And we, you know, what's the real Zuckerberg, the zombie?
[00:34:44.560 --> 00:34:45.720]   Or this?
[00:34:45.720 --> 00:34:47.680]   And so no, I think that he's not like that.
[00:34:47.680 --> 00:34:49.120]   I think that that's why he was like that,
[00:34:49.120 --> 00:34:50.160]   'cause he was scared.
[00:34:50.160 --> 00:34:51.600]   He was 19 years old.
[00:34:51.600 --> 00:34:52.440]   So why do I have mobile?
[00:34:52.440 --> 00:34:53.280]   - He was kid.
[00:34:53.280 --> 00:34:54.440]   - I didn't know what to do.
[00:34:54.440 --> 00:34:56.440]   His father's a dentist who works alone.
[00:34:56.440 --> 00:34:59.200]   You know, that's what it was.
[00:34:59.200 --> 00:35:01.800]   - Sounds like a line at a CSI.
[00:35:01.800 --> 00:35:04.480]   His father was a dentist who works alone.
[00:35:04.480 --> 00:35:05.640]   (laughing)
[00:35:05.640 --> 00:35:08.040]   By the way, the Urban Dictionary has two interesting,
[00:35:08.040 --> 00:35:10.840]   two germane, as long as we're gonna use big words,
[00:35:10.840 --> 00:35:15.240]   germane definitions of creepy, not Jackson.
[00:35:15.240 --> 00:35:21.160]   Someone, somewhat scary because of strangeness,
[00:35:21.160 --> 00:35:23.000]   which is kind of what you guys are saying.
[00:35:23.000 --> 00:35:24.480]   - I'm familiar, strange.
[00:35:24.480 --> 00:35:27.120]   - I'm familiar, but we'll become familiar.
[00:35:27.120 --> 00:35:29.480]   And then the third definition is,
[00:35:29.480 --> 00:35:32.400]   by far the most common adjective predicated
[00:35:32.400 --> 00:35:34.680]   to quiet people who don't smile.
[00:35:34.680 --> 00:35:37.200]   Isn't that interesting?
[00:35:37.200 --> 00:35:40.360]   AKA the old Mark Zuckerberg.
[00:35:40.360 --> 00:35:41.320]   - Yeah.
[00:35:41.320 --> 00:35:42.160]   - All right, let's take a break.
[00:35:42.160 --> 00:35:43.040]   This is interesting.
[00:35:43.040 --> 00:35:43.880]   I think it's interesting.
[00:35:43.880 --> 00:35:44.880]   What is creepy?
[00:35:44.880 --> 00:35:50.000]   And is, you know, is it merely just technologically new?
[00:35:50.920 --> 00:35:52.440]   And strangeness.
[00:35:52.440 --> 00:35:54.520]   - Well, the cloud is creepy.
[00:35:54.520 --> 00:35:56.640]   - Oh yeah, a lot of people are creeped out by the cloud.
[00:35:56.640 --> 00:35:57.640]   - The fact that the cloud,
[00:35:57.640 --> 00:35:59.680]   I don't know what it is, people just draw this cloud thing.
[00:35:59.680 --> 00:36:00.800]   I would say that, where is it?
[00:36:00.800 --> 00:36:01.640]   Where's your earth?
[00:36:01.640 --> 00:36:02.640]   That's creepy.
[00:36:02.640 --> 00:36:03.640]   - Where's my data go?
[00:36:03.640 --> 00:36:05.800]   - I came up with a news, I can't remember who said it
[00:36:05.800 --> 00:36:07.560]   to me first and I would give him credit if I could,
[00:36:07.560 --> 00:36:10.040]   but a great way to respond to people who say,
[00:36:10.040 --> 00:36:11.680]   I'm not gonna trust my data to the cloud
[00:36:11.680 --> 00:36:13.680]   and I include John C. Devorah to this.
[00:36:13.680 --> 00:36:14.520]   - Yeah.
[00:36:14.520 --> 00:36:17.080]   - Is, well, okay, where's your money?
[00:36:17.080 --> 00:36:18.960]   - Right.
[00:36:18.960 --> 00:36:19.800]   - Is it in your mattress?
[00:36:19.800 --> 00:36:21.520]   - No, does it exist?
[00:36:21.520 --> 00:36:23.440]   No, it's in the cloud.
[00:36:23.440 --> 00:36:26.520]   You've been trusting your entire financial world
[00:36:26.520 --> 00:36:29.880]   to the cloud for your whole life.
[00:36:29.880 --> 00:36:32.640]   There's no vault with your money in it.
[00:36:32.640 --> 00:36:35.720]   - I have this vision now of Devorahak
[00:36:35.720 --> 00:36:37.080]   with a razor and a mattress.
[00:36:37.080 --> 00:36:38.200]   (laughing)
[00:36:38.200 --> 00:36:41.600]   If anybody would put his money in a mattress, it's John C.
[00:36:41.600 --> 00:36:43.320]   You might wish that, you know, he was in Madrid
[00:36:43.320 --> 00:36:45.520]   in his passport and wallet got pickpocketed.
[00:36:45.520 --> 00:36:46.520]   - Ah, no.
[00:36:46.520 --> 00:36:47.840]   - Ow.
[00:36:47.840 --> 00:36:49.400]   - Oh, the pumpiest man on--
[00:36:49.400 --> 00:36:50.440]   - Oh, on earth.
[00:36:50.440 --> 00:36:52.360]   Oh, my lord, he must have been--
[00:36:52.360 --> 00:36:55.480]   - You know, it was karma because I think he was like
[00:36:55.480 --> 00:36:56.520]   lording it over people.
[00:36:56.520 --> 00:36:57.520]   You've never been to Europe.
[00:36:57.520 --> 00:36:59.800]   Well, I've been to Europe many times.
[00:36:59.800 --> 00:37:00.640]   (laughing)
[00:37:00.640 --> 00:37:03.560]   Then he's the one who got pickpocketed.
[00:37:03.560 --> 00:37:04.400]   Anyway, we would make sure--
[00:37:04.400 --> 00:37:05.680]   - I have no spam.
[00:37:05.680 --> 00:37:07.520]   I have no passport.
[00:37:07.520 --> 00:37:08.360]   - We'll make sure.
[00:37:08.360 --> 00:37:10.000]   John and I believe is back now.
[00:37:10.000 --> 00:37:11.200]   And actually, we have a great video
[00:37:11.200 --> 00:37:13.440]   that John and I lean shot in Madrid
[00:37:13.440 --> 00:37:17.480]   at the afford focus event, so we'll get that out soon.
[00:37:17.480 --> 00:37:18.880]   Meanwhile, let me take a little break
[00:37:18.880 --> 00:37:21.320]   and mention our friends at hover.com.
[00:37:21.320 --> 00:37:24.440]   Hover is domain name registration done right.
[00:37:24.440 --> 00:37:26.160]   Simply clean.
[00:37:26.160 --> 00:37:27.040]   They don't upsell you.
[00:37:27.040 --> 00:37:28.360]   In fact, you know, a lot of times
[00:37:28.360 --> 00:37:30.360]   on these other registrars, you say,
[00:37:30.360 --> 00:37:32.480]   "All right, I'll buy that domain."
[00:37:32.480 --> 00:37:33.320]   Oh, it's cheap.
[00:37:33.320 --> 00:37:34.480]   995, what a great deal.
[00:37:34.480 --> 00:37:37.000]   Oh, by the way, you probably want privacy on this.
[00:37:37.000 --> 00:37:38.040]   You'd probably like this and that.
[00:37:38.040 --> 00:37:41.120]   And they tried to upsell you on 1500 different things.
[00:37:41.120 --> 00:37:41.960]   By the time you're done,
[00:37:41.960 --> 00:37:45.400]   it's the most expensive domain name you've ever seen.
[00:37:45.400 --> 00:37:46.680]   Hover doesn't do that.
[00:37:46.680 --> 00:37:49.080]   Their domain name registration made simple.
[00:37:49.080 --> 00:37:51.160]   In fact, I'll give you an example.
[00:37:51.160 --> 00:37:52.720]   They build privacy right in.
[00:37:52.720 --> 00:37:53.960]   They know you want privacy.
[00:37:53.960 --> 00:37:55.800]   So they don't charge you for it.
[00:37:55.800 --> 00:37:58.600]   It comes with the territory.
[00:37:58.600 --> 00:38:02.520]   H-O-V-E-R as in cover.
[00:38:02.520 --> 00:38:03.720]   Hover.com.
[00:38:03.720 --> 00:38:05.880]   And actually, if you go to twig.hover.com,
[00:38:05.880 --> 00:38:08.880]   you can check it out and get a little deal.
[00:38:08.880 --> 00:38:14.560]   10% off your domain registration.
[00:38:14.560 --> 00:38:15.760]   Couldn't be easier.
[00:38:15.760 --> 00:38:17.360]   Transfers are great too.
[00:38:17.360 --> 00:38:18.720]   Now, some people say, "Well, wait a minute.
[00:38:18.720 --> 00:38:19.520]   The transfer's not free."
[00:38:19.520 --> 00:38:21.320]   Yeah, it's $10.
[00:38:21.320 --> 00:38:23.600]   But what the $10 does is gets you an additional year
[00:38:23.600 --> 00:38:25.960]   on your existing domain registration.
[00:38:25.960 --> 00:38:28.480]   So it's actually a good deal.
[00:38:28.480 --> 00:38:30.800]   And they'll even do all the transfers for you.
[00:38:30.800 --> 00:38:32.360]   I transferred a bunch of domains
[00:38:32.360 --> 00:38:34.400]   and I wish I'd taken advantage of this.
[00:38:34.400 --> 00:38:37.240]   If you click the transfer your domain for $25,
[00:38:37.240 --> 00:38:39.880]   no matter how many domains, one to a thousand,
[00:38:39.880 --> 00:38:41.120]   they will do it all for you.
[00:38:41.120 --> 00:38:46.120]   You call them 8667316556 and they'll do the entire thing
[00:38:46.120 --> 00:38:52.160]   for you all the niggly technical details of a transfer,
[00:38:52.160 --> 00:38:54.280]   which is a pain and a butt.
[00:38:54.280 --> 00:38:55.880]   'Cause I know that's the thing that's perhaps
[00:38:55.880 --> 00:38:57.120]   keeping you from moving to Hover,
[00:38:57.120 --> 00:38:58.880]   but you'll be glad you did.
[00:38:58.880 --> 00:38:59.960]   By the way, when you call that number
[00:38:59.960 --> 00:39:03.000]   and you get a representative, you will not be put on hold.
[00:39:03.000 --> 00:39:05.120]   They have a no hold policy for customer service calls
[00:39:05.120 --> 00:39:06.280]   during business hours.
[00:39:06.280 --> 00:39:08.240]   And I like that too.
[00:39:08.240 --> 00:39:09.760]   I can't tell you how much time I've spent on hold
[00:39:09.760 --> 00:39:10.880]   of those other guys.
[00:39:10.880 --> 00:39:14.360]   Hover.com for your new domain or transfer your old domain.
[00:39:14.360 --> 00:39:16.000]   It's the easiest, the best, the fastest,
[00:39:16.000 --> 00:39:17.320]   the cleanest, the most straightforward.
[00:39:17.320 --> 00:39:19.840]   Of course, it's their Canadian.
[00:39:19.840 --> 00:39:20.980]   It has to be good.
[00:39:20.980 --> 00:39:24.200]   Did you notice that when you were in Victoria?
[00:39:24.200 --> 00:39:26.520]   They're just, they're nice people.
[00:39:26.520 --> 00:39:27.360]   - They are.
[00:39:27.360 --> 00:39:29.720]   - You run into a Canadian, he apologizes.
[00:39:29.720 --> 00:39:33.480]   - Well, I got into the fight with the speech writer
[00:39:33.480 --> 00:39:38.000]   for the commissioner or governor general
[00:39:38.000 --> 00:39:41.520]   or whatever, a privacy in British Columbia
[00:39:41.520 --> 00:39:43.520]   and saying, you misquoted, Eric Schmidt,
[00:39:43.520 --> 00:39:45.720]   you cited a blog and she said,
[00:39:45.720 --> 00:39:46.560]   - No, no, no, she said,
[00:39:46.560 --> 00:39:47.720]   I said, not your full of crap.
[00:39:47.720 --> 00:39:48.720]   It's your rude.
[00:39:48.720 --> 00:39:49.960]   And I said, I'm American.
[00:39:49.960 --> 00:39:51.280]   (laughing)
[00:39:51.280 --> 00:39:52.120]   - Your rude.
[00:39:52.120 --> 00:39:55.280]   - That's the worst it gets.
[00:39:55.280 --> 00:40:00.000]   No, I have to say, this is a division of two cows.
[00:40:00.000 --> 00:40:01.680]   It was called Domains Direct for a long time.
[00:40:01.680 --> 00:40:03.440]   It really is just a great service.
[00:40:03.440 --> 00:40:04.440]   And I love these guys.
[00:40:04.440 --> 00:40:05.280]   - That was nice people.
[00:40:05.280 --> 00:40:06.720]   - Well, you know, this came out of South by Southwest
[00:40:06.720 --> 00:40:09.960]   last year because Elliot, who's the CEO, came over
[00:40:09.960 --> 00:40:11.240]   and we were, we were, we were,
[00:40:11.240 --> 00:40:13.480]   remember we had that great meat dinner?
[00:40:13.480 --> 00:40:14.320]   - Yes.
[00:40:14.320 --> 00:40:15.160]   - Oh, so good.
[00:40:15.160 --> 00:40:16.000]   We're gonna do that again.
[00:40:16.000 --> 00:40:16.840]   By the way, Eileen.
[00:40:16.840 --> 00:40:19.240]   - Our partyologist still hates you.
[00:40:19.240 --> 00:40:20.080]   - No, it's good.
[00:40:20.080 --> 00:40:20.920]   You should eat more meat.
[00:40:20.920 --> 00:40:21.920]   (thunder rumbling)
[00:40:21.920 --> 00:40:23.160]   - After your South American bedroom,
[00:40:23.160 --> 00:40:24.480]   I'll bet you're full of.
[00:40:24.480 --> 00:40:26.960]   - I lost six pounds on the cruise.
[00:40:26.960 --> 00:40:27.800]   - Really?
[00:40:27.800 --> 00:40:29.120]   - Eating meat.
[00:40:29.120 --> 00:40:29.960]   - Good for you, Leo.
[00:40:29.960 --> 00:40:30.800]   - It's at carbs.
[00:40:30.800 --> 00:40:31.800]   It was not eating carbs, it did for me.
[00:40:31.800 --> 00:40:33.280]   Anyway, I don't want to get into that.
[00:40:33.280 --> 00:40:34.880]   'Cause you're, I don't want to kill you, Jeff.
[00:40:34.880 --> 00:40:37.240]   (laughing)
[00:40:37.240 --> 00:40:39.120]   I'm not gonna, I just want you to go to twig
[00:40:39.120 --> 00:40:40.440]   and have a laugh.
[00:40:40.440 --> 00:40:41.280]   - It'll blow me over.
[00:40:41.280 --> 00:40:42.520]   - It would be so bad.
[00:40:42.520 --> 00:40:44.480]   It'd be like, oh yeah, I got this great diet.
[00:40:44.480 --> 00:40:46.880]   You just eat a lot of meat and Jeff goes, ah!
[00:40:46.880 --> 00:40:48.040]   And then.
[00:40:48.040 --> 00:40:49.080]   - I know we gotta get his brain,
[00:40:49.080 --> 00:40:50.280]   poor his brain in the jar first.
[00:40:50.280 --> 00:40:51.440]   - Yeah, yeah, before we, yeah.
[00:40:51.440 --> 00:40:54.880]   We gotta get the jar then, I'll tell you about the meat diet.
[00:40:54.880 --> 00:40:56.680]   Yeah, I ate a lot of good meat.
[00:40:56.680 --> 00:40:58.080]   Oh man, Buenos Aires.
[00:40:58.080 --> 00:41:01.040]   Oh, they got this thing called provolato,
[00:41:01.040 --> 00:41:03.600]   which is like fried cheese.
[00:41:03.600 --> 00:41:05.200]   It's so good.
[00:41:05.200 --> 00:41:06.040]   - Oh man.
[00:41:06.040 --> 00:41:07.400]   - It becomes a little skillet.
[00:41:07.400 --> 00:41:10.200]   And then I had the blue-to-verse blood sausage
[00:41:10.200 --> 00:41:12.040]   and chorizo, now I've had Mexican chorizo.
[00:41:12.040 --> 00:41:15.000]   This is not Mexican, this is incredible sausage.
[00:41:15.000 --> 00:41:15.880]   (gasps)
[00:41:15.880 --> 00:41:19.040]   The food and the steaks, oh my God, anyway.
[00:41:19.040 --> 00:41:19.880]   Where were we talking about?
[00:41:19.880 --> 00:41:20.720]   Oh yeah, hover.
[00:41:20.720 --> 00:41:21.560]   (laughing)
[00:41:21.560 --> 00:41:23.240]   - You know what to self eat lunch before.
[00:41:23.240 --> 00:41:25.400]   - Lunch, or a twig.
[00:41:25.400 --> 00:41:27.440]   We made a chipotle run, I should've asked you.
[00:41:27.440 --> 00:41:31.280]   Oh, grads, I can't, Skype doesn't support chipotle transfer.
[00:41:31.280 --> 00:41:33.000]   - Seriously, we need the burrito shoot.
[00:41:33.000 --> 00:41:34.800]   (laughing)
[00:41:34.800 --> 00:41:36.720]   - From Petaluma's great down at the San Diego.
[00:41:36.720 --> 00:41:38.160]   - Burrito shoot.
[00:41:38.160 --> 00:41:39.000]   - That's a great idea.
[00:41:39.000 --> 00:41:41.000]   You know what they should do at chipotle
[00:41:41.000 --> 00:41:43.320]   is they should have pneumatic delivery.
[00:41:43.320 --> 00:41:45.200]   It's the product made for pneumatic delivery.
[00:41:45.200 --> 00:41:46.720]   (whooshing)
[00:41:46.720 --> 00:41:49.040]   - It's a toilet, it's the bullet burrito, come on.
[00:41:49.040 --> 00:41:51.600]   (laughing)
[00:41:51.600 --> 00:41:52.800]   - Twig.hubber.com.
[00:41:52.800 --> 00:41:54.640]   - We are headed off on every tangent possible.
[00:41:54.640 --> 00:41:56.280]   - I love the tangents.
[00:41:56.280 --> 00:41:58.520]   If you listen to the Twit Network,
[00:41:58.520 --> 00:42:00.080]   not when Jeff, not when,
[00:42:00.080 --> 00:42:01.520]   we're not when Tom and Becky,
[00:42:01.520 --> 00:42:04.360]   you know, these guys are professionals.
[00:42:04.360 --> 00:42:05.200]   - On topic.
[00:42:05.200 --> 00:42:07.440]   - They keep it on track, they know what they're doing,
[00:42:07.440 --> 00:42:09.240]   they hit the clock, they're everything,
[00:42:09.240 --> 00:42:11.400]   they're perfect, they're wonderful people.
[00:42:11.400 --> 00:42:13.200]   - And we are on topic, and it's like,
[00:42:13.200 --> 00:42:14.280]   squirrels.
[00:42:14.280 --> 00:42:16.540]   (laughing)
[00:42:16.540 --> 00:42:22.440]   - So gingerbread, I'm keep looking at my next assess.
[00:42:22.440 --> 00:42:25.200]   Now, Gina, you were bemoaning the next one.
[00:42:25.200 --> 00:42:27.760]   - During the commercial, I was checking my phone
[00:42:27.760 --> 00:42:30.880]   to see if the OTA on gingerbread had come through.
[00:42:30.880 --> 00:42:32.080]   - I knew you were doing that.
[00:42:32.080 --> 00:42:33.080]   - Not yet.
[00:42:33.080 --> 00:42:33.920]   - Not yet.
[00:42:33.920 --> 00:42:36.280]   - 2.3.3.
[00:42:36.280 --> 00:42:39.800]   And even the next assess, which is using 2.2,
[00:42:39.800 --> 00:42:41.120]   should get an update.
[00:42:41.120 --> 00:42:43.960]   - Yep, and they said that it could take a few weeks
[00:42:43.960 --> 00:42:45.640]   to do the rollout, but someone in the forum said,
[00:42:45.640 --> 00:42:46.920]   it's not really gonna take a few weeks,
[00:42:46.920 --> 00:42:48.200]   it'll be in the next few days.
[00:42:48.200 --> 00:42:49.360]   We just, we do it incrementally,
[00:42:49.360 --> 00:42:50.680]   just in case there are problems.
[00:42:50.680 --> 00:42:54.280]   So as far as I know, no one's released an update.zip
[00:42:54.280 --> 00:42:55.200]   that you can just grab,
[00:42:55.200 --> 00:42:58.120]   although someone in the chat room can correct me.
[00:42:58.120 --> 00:43:00.400]   I'm trying to be a regular user
[00:43:00.400 --> 00:43:02.240]   and just waiting for the OTA update.
[00:43:02.240 --> 00:43:03.520]   But it also means that I am the loser
[00:43:03.520 --> 00:43:06.120]   checking my phone every five minutes to see if I have--
[00:43:06.120 --> 00:43:07.240]   - But Gina, the reward,
[00:43:07.240 --> 00:43:10.000]   it's like the hamster with the button and the pellet.
[00:43:10.000 --> 00:43:11.600]   - Exactly, give me the pellet.
[00:43:11.600 --> 00:43:13.440]   - Oh, it's just a great,
[00:43:13.440 --> 00:43:16.480]   there is perhaps for an Android user, no better feeling
[00:43:16.480 --> 00:43:18.200]   than that little announcement that comes on the screen
[00:43:18.200 --> 00:43:19.760]   that says you have an update.
[00:43:19.760 --> 00:43:22.040]   - Yes, the little teen robot guy.
[00:43:22.040 --> 00:43:24.640]   But you know, the honeycomb emulator or SDK is out.
[00:43:24.640 --> 00:43:28.160]   So I was temporarily distracted by that.
[00:43:28.160 --> 00:43:29.280]   I downloaded that this morning,
[00:43:29.280 --> 00:43:30.120]   it took some screenshots.
[00:43:30.120 --> 00:43:31.560]   - So what do you think?
[00:43:31.560 --> 00:43:34.480]   - You know, the emulator is kind of slow,
[00:43:34.480 --> 00:43:35.400]   but that's just the emulator
[00:43:35.400 --> 00:43:38.080]   and I had to fiddle with some settings and sped it up.
[00:43:38.080 --> 00:43:40.200]   Otherwise, really beautiful.
[00:43:40.200 --> 00:43:43.840]   I mean, the emulator, there are no apps installed at all.
[00:43:43.840 --> 00:43:44.960]   I mean, they have a few demos,
[00:43:44.960 --> 00:43:46.960]   but like Gmail and all the regular apps aren't installed.
[00:43:46.960 --> 00:43:48.320]   It's just kind of bare bones.
[00:43:48.320 --> 00:43:49.840]   But it's really cool.
[00:43:49.840 --> 00:43:50.920]   It's just a huge screen.
[00:43:50.920 --> 00:43:52.680]   It makes such a big difference.
[00:43:52.680 --> 00:43:53.520]   - Okay, don't list.
[00:43:53.520 --> 00:43:55.440]   Besides seeing the video wall.
[00:43:55.440 --> 00:43:56.440]   (mumbles)
[00:43:56.440 --> 00:43:57.920]   - Yeah, 'cause there's some real jealous--
[00:43:57.920 --> 00:43:58.760]   - I don't wanna jump us.
[00:43:58.760 --> 00:43:59.600]   - No. - They're not gonna
[00:43:59.600 --> 00:44:00.440]   like yell at us.
[00:44:00.440 --> 00:44:01.280]   - No, no, no, no, I'm with you though,
[00:44:01.280 --> 00:44:02.120]   'cause that's eye candy.
[00:44:02.120 --> 00:44:02.960]   I wanna know, is it--
[00:44:02.960 --> 00:44:03.960]   - It is like-- - Yeah.
[00:44:03.960 --> 00:44:07.360]   - What is it, Gina, that you think is the most
[00:44:07.360 --> 00:44:08.720]   actually valuable thing?
[00:44:08.720 --> 00:44:12.240]   - It's interesting that all the buttons are on
[00:44:12.240 --> 00:44:13.080]   the device itself.
[00:44:13.080 --> 00:44:15.600]   There's no key, you know, the back button
[00:44:15.600 --> 00:44:17.440]   and the home button are all there.
[00:44:17.440 --> 00:44:19.400]   You know, the time, you can tap on the time
[00:44:19.400 --> 00:44:21.920]   and we'll pop up sort of a larger,
[00:44:21.920 --> 00:44:24.120]   kind of like, not that I wanna say this,
[00:44:24.120 --> 00:44:26.280]   but kind of like windows.
[00:44:26.280 --> 00:44:27.360]   And you just have a lot more space
[00:44:27.360 --> 00:44:28.360]   and you can flip between things.
[00:44:28.360 --> 00:44:30.400]   I mean, it's just, it's the bigger screen, stupid.
[00:44:30.400 --> 00:44:33.520]   It just makes a huge, huge difference.
[00:44:33.520 --> 00:44:35.280]   But like I said, the emulator,
[00:44:35.280 --> 00:44:37.440]   there are no apps installed really.
[00:44:37.440 --> 00:44:39.360]   So I couldn't, I didn't get a chance to try Gmail,
[00:44:39.360 --> 00:44:40.520]   the Gmail app, that's closed source,
[00:44:40.520 --> 00:44:42.720]   that doesn't come out with the SDK.
[00:44:42.720 --> 00:44:45.280]   So I really didn't get a good chance to really experience
[00:44:45.280 --> 00:44:46.120]   what it's like.
[00:44:46.120 --> 00:44:47.520]   I really like the different panels,
[00:44:47.520 --> 00:44:49.400]   though the action bar and the panel on the side.
[00:44:49.400 --> 00:44:53.040]   And I ran my own app and have lots of really exciting ideas
[00:44:53.040 --> 00:44:55.640]   about how to make it kind of more tablet friendly.
[00:44:55.640 --> 00:44:58.200]   So, initial-- - So one thing,
[00:44:58.200 --> 00:44:59.720]   this means that the manufacturers
[00:44:59.720 --> 00:45:01.520]   will do the damn buttons around.
[00:45:01.520 --> 00:45:04.040]   - Right. - Yeah, but then we'll have
[00:45:04.040 --> 00:45:05.560]   duplicate buttons 'cause we'll have hardware.
[00:45:05.560 --> 00:45:08.240]   I mean, I know the zoom doesn't have buttons.
[00:45:08.240 --> 00:45:09.440]   - Right, and we'll others have buttons.
[00:45:09.440 --> 00:45:12.560]   I mean, it looks like all the buttons are on the screen.
[00:45:12.560 --> 00:45:15.720]   Like the emulator itself doesn't have the extra buttons,
[00:45:15.720 --> 00:45:17.240]   even the circuit button.
[00:45:17.240 --> 00:45:18.080]   - Really?
[00:45:18.080 --> 00:45:19.960]   - Well, though, I imagine that maybe some of the other
[00:45:19.960 --> 00:45:23.040]   tablets will have the, you know, maybe search and home.
[00:45:23.040 --> 00:45:27.000]   But menu and back or op-
[00:45:27.000 --> 00:45:29.600]   - The advantage is zoom is it's never upside down.
[00:45:29.600 --> 00:45:30.440]   - Right.
[00:45:30.440 --> 00:45:31.800]   Oh, that's probably a lot of it, isn't it?
[00:45:31.800 --> 00:45:36.480]   The orientation is independent of the hardware.
[00:45:36.480 --> 00:45:37.760]   - Which makes a lot of sense.
[00:45:37.760 --> 00:45:39.720]   It drives me nutty line.
[00:45:39.720 --> 00:45:41.440]   - Yeah, no, that actually is, that's, yeah,
[00:45:41.440 --> 00:45:42.840]   you're right on the Samsung 'cause it's just
[00:45:42.840 --> 00:45:45.600]   once you turn around, it's kind of, oh, dear.
[00:45:45.600 --> 00:45:46.440]   - Right.
[00:45:46.440 --> 00:45:47.720]   - And this isn't a problem on the iPad so much
[00:45:47.720 --> 00:45:49.240]   'cause there's only one button.
[00:45:49.240 --> 00:45:51.640]   - Yeah, good point.
[00:45:51.640 --> 00:45:53.160]   Right, so that can be anywhere.
[00:45:53.160 --> 00:45:54.000]   - Right.
[00:45:54.000 --> 00:45:56.280]   I mean, you can't, you know, you can't hit the wrong button
[00:45:56.280 --> 00:45:58.320]   if there's only one button.
[00:45:58.320 --> 00:46:00.200]   - I installed my app, it looked great.
[00:46:00.200 --> 00:46:02.120]   There's tons of white space, obviously,
[00:46:02.120 --> 00:46:03.240]   but it completely works.
[00:46:03.240 --> 00:46:05.720]   - Oh, so it scales, you don't have to do anything special.
[00:46:05.720 --> 00:46:07.080]   - Nope, I didn't do anything special.
[00:46:07.080 --> 00:46:08.160]   - Oh, that's the beautiful thing.
[00:46:08.160 --> 00:46:10.800]   - It scaled it up, there's just a lot of white space.
[00:46:10.800 --> 00:46:13.720]   - Would there be a way kind of an elastic,
[00:46:13.720 --> 00:46:18.720]   some sort of elastic layout that would kind of handle that better?
[00:46:18.720 --> 00:46:20.680]   - I think that way you can do is, as a developer,
[00:46:20.680 --> 00:46:23.240]   is that you can create panels and if you're on the widescreen,
[00:46:23.240 --> 00:46:25.440]   both panels show on the screen at the same time,
[00:46:25.440 --> 00:46:27.760]   but if you're on the small screen,
[00:46:27.760 --> 00:46:30.640]   you would have to tap an object to move over to the other panel.
[00:46:30.640 --> 00:46:31.480]   - Okay, okay.
[00:46:31.480 --> 00:46:32.320]   - Yeah.
[00:46:32.320 --> 00:46:33.320]   - They gotta make it easy for developers
[00:46:33.320 --> 00:46:36.600]   to make it something that looks universal at some time.
[00:46:36.600 --> 00:46:38.560]   - Yes, yep, yep.
[00:46:38.560 --> 00:46:41.080]   - Boy, Gina, you shouldn't have turned down that movie offer
[00:46:41.080 --> 00:46:42.800]   that you got last year,
[00:46:42.800 --> 00:46:46.120]   'cause if you were, if you're going to the Oscars,
[00:46:46.120 --> 00:46:50.520]   as a nominee, you would have received a gold zoom.
[00:46:50.520 --> 00:46:52.320]   And by the way, I gotta be clear about this,
[00:46:52.320 --> 00:46:55.360]   'cause zoom is so generic.
[00:46:55.360 --> 00:46:58.560]   Maybe, can we agree to say zoom, or something like that?
[00:46:58.560 --> 00:46:59.800]   (laughing)
[00:46:59.800 --> 00:47:01.680]   - Oom, oom.
[00:47:01.680 --> 00:47:04.040]   - It's the Motorola XOOM.
[00:47:04.040 --> 00:47:05.880]   It's a basic black for the general public,
[00:47:05.880 --> 00:47:09.760]   but they've got a gold one for Oscar hosts and nominees.
[00:47:09.760 --> 00:47:12.640]   This part of the, you know, you get a bag of stuff.
[00:47:12.640 --> 00:47:13.960]   - Oh, it's a tax bill.
[00:47:13.960 --> 00:47:16.040]   - Well, that's right, I was talking to Waz.
[00:47:16.040 --> 00:47:18.360]   When he did "Dancing with the Stars,"
[00:47:18.360 --> 00:47:21.280]   they gave him a basket of goodies,
[00:47:21.280 --> 00:47:23.800]   worth 70, I hope I'm not betraying a confidence,
[00:47:23.800 --> 00:47:27.000]   worth 75, I don't know, he didn't make me sign an NDA,
[00:47:27.000 --> 00:47:29.240]   $75,000.
[00:47:29.240 --> 00:47:32.720]   And he took it 'cause he said we didn't know any better,
[00:47:32.720 --> 00:47:34.040]   so, oh, thanks.
[00:47:34.040 --> 00:47:36.760]   And then they had to pay, you know, like half of its taxes.
[00:47:36.760 --> 00:47:41.120]   You have to pay $30,000 for this $75,000 basket of goodies.
[00:47:41.120 --> 00:47:43.560]   And he said, it's a bunch of crap I didn't want, you know,
[00:47:43.560 --> 00:47:45.920]   bulgari perfume and stuff.
[00:47:45.920 --> 00:47:47.480]   And it's all retail.
[00:47:47.480 --> 00:47:50.360]   - Oom, Waz, you smell so elegant.
[00:47:50.360 --> 00:47:52.520]   He said there were three good things in the whole bag.
[00:47:52.520 --> 00:47:53.680]   It was very expensive.
[00:47:53.680 --> 00:47:56.240]   - Just to clarify, chatroom,
[00:47:56.240 --> 00:47:58.160]   I did not get a movie offer, I...
[00:47:58.160 --> 00:48:00.040]   (laughing)
[00:48:00.040 --> 00:48:01.560]   - It says so in Wikipedia,
[00:48:01.560 --> 00:48:03.480]   if it doesn't, I'll make sure it doesn't.
[00:48:03.480 --> 00:48:05.640]   - I thought you were gonna be the lawyer in social networks.
[00:48:05.640 --> 00:48:08.120]   - Yeah, oh, she would've been good.
[00:48:08.120 --> 00:48:10.440]   She's so much more believable.
[00:48:10.440 --> 00:48:11.280]   - Yeah, right.
[00:48:11.280 --> 00:48:13.320]   - Oh, you would've been so good.
[00:48:13.320 --> 00:48:15.720]   - Oh, you guys be my agent, seriously.
[00:48:15.720 --> 00:48:18.040]   - Well, you know, hey Snoop Dogg got that, Kamer.
[00:48:18.040 --> 00:48:22.120]   Have you seen the Snoop Dogg for the 4G indulge?
[00:48:22.120 --> 00:48:22.960]   - I haven't seen it yet.
[00:48:22.960 --> 00:48:24.960]   - All right, let's watch a commercial.
[00:48:24.960 --> 00:48:25.800]   I don't think they could sue us
[00:48:25.800 --> 00:48:27.920]   for playing their stupid commercial, can they?
[00:48:27.920 --> 00:48:29.080]   - They should pay you for playing this.
[00:48:29.080 --> 00:48:30.560]   - Yeah.
[00:48:30.560 --> 00:48:32.120]   I know we're gonna get it from Jeopardy, though.
[00:48:32.120 --> 00:48:33.880]   I know Alex Trebek's gonna say,
[00:48:33.880 --> 00:48:36.720]   oh, Leo, you made a horrible error.
[00:48:36.720 --> 00:48:38.400]   This is a little bit from that.
[00:48:38.400 --> 00:48:39.800]   - Yeah, sure.
[00:48:39.800 --> 00:48:41.520]   - A little bit from that ad.
[00:48:41.520 --> 00:48:42.520]   It's kind of like a dating day.
[00:48:42.520 --> 00:48:46.480]   - Last up is Snoop, D-O-G-G-G.
[00:48:46.480 --> 00:48:48.040]   (audience applauding)
[00:48:48.040 --> 00:48:52.520]   I'm a rapper, an actor, a director,
[00:48:52.520 --> 00:48:54.040]   little league football coach,
[00:48:54.040 --> 00:48:56.120]   and a relationship therapist.
[00:48:56.120 --> 00:48:59.080]   - And the 4G, lately the speed of my hustle
[00:48:59.080 --> 00:49:00.720]   is increased exceptionally.
[00:49:00.720 --> 00:49:03.880]   And I've had to amp up my Gs to facilitate my needs.
[00:49:03.880 --> 00:49:04.720]   - Oh.
[00:49:04.720 --> 00:49:05.560]   (audience cheering)
[00:49:05.560 --> 00:49:06.920]   - Settle down now, girl.
[00:49:06.920 --> 00:49:09.120]   - All right, home girl.
[00:49:09.120 --> 00:49:11.880]   - When we come back, the lovely Brittany
[00:49:11.880 --> 00:49:14.040]   will be grilling each of our contestants,
[00:49:14.040 --> 00:49:16.040]   who she's gonna pick, stay tuned.
[00:49:16.040 --> 00:49:16.880]   (audience applauding)
[00:49:16.880 --> 00:49:17.700]   - I did it.
[00:49:17.700 --> 00:49:18.840]   - So this is an ad that's done, kinda like the dating.
[00:49:18.840 --> 00:49:22.080]   - The whole consideration brought to you by Central PCS,
[00:49:22.080 --> 00:49:23.840]   and the Samsung Galaxy.
[00:49:23.840 --> 00:49:25.560]   - That, you know what that is?
[00:49:25.560 --> 00:49:26.800]   That's homeless announcer.
[00:49:26.800 --> 00:49:28.040]   - Or is that him, yeah.
[00:49:28.040 --> 00:49:28.960]   - Yeah.
[00:49:28.960 --> 00:49:29.800]   - Aw.
[00:49:29.800 --> 00:49:30.640]   - Isn't that nice?
[00:49:30.640 --> 00:49:31.480]   He sounds good to us.
[00:49:31.480 --> 00:49:32.320]   - Indolge.
[00:49:32.320 --> 00:49:33.640]   - Indolge.
[00:49:33.640 --> 00:49:37.080]   - So that was the indulge ad.
[00:49:37.080 --> 00:49:40.960]   Man, that guy's gonna get more work than Casey Casey-Kesom.
[00:49:40.960 --> 00:49:43.000]   - So he gets out of rehab.
[00:49:43.000 --> 00:49:44.440]   - Oh, yeah.
[00:49:44.440 --> 00:49:45.280]   - I don't know.
[00:49:45.280 --> 00:49:47.120]   - Did something happen while I was gone?
[00:49:47.120 --> 00:49:47.960]   - Yeah.
[00:49:47.960 --> 00:49:50.080]   (sighing)
[00:49:50.080 --> 00:49:53.360]   - Anyway, Eileen's got an Oscar.
[00:49:53.360 --> 00:49:55.520]   You're gonna do that, right, Gina?
[00:49:55.520 --> 00:49:57.640]   Eileen's Oscar, a poll.
[00:49:57.640 --> 00:49:58.960]   - A poll.
[00:49:58.960 --> 00:49:59.800]   - Oscar, a poll.
[00:49:59.800 --> 00:50:00.800]   - Oscar, a poll.
[00:50:00.800 --> 00:50:02.120]   - Oh, Oscar, a poll.
[00:50:02.120 --> 00:50:03.800]   - Well, send them the thing.
[00:50:03.800 --> 00:50:05.120]   We gotta get them in that.
[00:50:05.120 --> 00:50:05.960]   - Sure, I'm in.
[00:50:05.960 --> 00:50:07.800]   - Do you put money into that?
[00:50:07.800 --> 00:50:10.360]   - That makes it an illegal gambler thing.
[00:50:10.360 --> 00:50:11.520]   No, yes, we put money into it.
[00:50:11.520 --> 00:50:12.440]   A lot of money into it.
[00:50:12.440 --> 00:50:13.440]   You could win thousands of dollars.
[00:50:13.440 --> 00:50:15.240]   - We just fed Zinga dollars, that's all.
[00:50:15.240 --> 00:50:16.080]   - Yeah.
[00:50:16.080 --> 00:50:16.920]   (laughing)
[00:50:16.920 --> 00:50:18.320]   - Bit-kiling. - I won, hey!
[00:50:18.320 --> 00:50:19.160]   I won, hey!
[00:50:19.160 --> 00:50:21.640]   (laughing)
[00:50:21.640 --> 00:50:25.640]   - Flash is gonna be, Adobe has announced
[00:50:25.640 --> 00:50:26.880]   in a little, (snapping)
[00:50:26.880 --> 00:50:31.880]   Apple that Android 3 will come with Flash.
[00:50:31.880 --> 00:50:35.960]   Not on the first tablet,
[00:50:35.960 --> 00:50:36.800]   so it's gonna take a little while
[00:50:36.800 --> 00:50:39.480]   after the first tablet's come out.
[00:50:39.480 --> 00:50:40.480]   But that's interesting.
[00:50:40.480 --> 00:50:41.800]   - It will ship with it pre-installed,
[00:50:41.800 --> 00:50:42.800]   or this is gonna be part,
[00:50:42.800 --> 00:50:44.800]   it can be part of the code base, right?
[00:50:45.800 --> 00:50:47.240]   - Let's see.
[00:50:47.240 --> 00:50:48.080]   - I'm trying to see if--
[00:50:48.080 --> 00:50:50.360]   - Adobe has, it says,
[00:50:50.360 --> 00:50:53.360]   "Flashfire 10.2, the version of Flash
[00:50:53.360 --> 00:50:56.920]   "that will be compatible with upcoming Android tablets,
[00:50:56.920 --> 00:51:00.240]   "will be ready to few weeks after Android 3 comes out,
[00:51:00.240 --> 00:51:03.040]   "after which it'll be available for over-the-air installation,
[00:51:03.040 --> 00:51:04.840]   "so it will not be bundled."
[00:51:04.840 --> 00:51:05.680]   - Okay.
[00:51:05.680 --> 00:51:07.160]   - I thought it was, I misunderstood.
[00:51:07.160 --> 00:51:08.760]   I did think it was gonna be bundled.
[00:51:12.840 --> 00:51:14.920]   So I guess they didn't do a deal,
[00:51:14.920 --> 00:51:16.920]   a deal with the Google to do that.
[00:51:16.920 --> 00:51:19.280]   All right, we're gonna take a break,
[00:51:19.280 --> 00:51:20.040]   come back with more,
[00:51:20.040 --> 00:51:21.280]   Gina Trapani is here,
[00:51:21.280 --> 00:51:23.600]   Jeff Jarvis coming up just a bit,
[00:51:23.600 --> 00:51:25.900]   our tool, a tip and number of the week.
[00:51:25.900 --> 00:51:29.240]   And we'll answer the question,
[00:51:29.240 --> 00:51:32.480]   why did Google ask for kids' social security numbers?
[00:51:32.480 --> 00:51:34.720]   - Before we do that,
[00:51:34.720 --> 00:51:36.800]   I'd like to talk about Squarespace.com,
[00:51:36.800 --> 00:51:39.680]   the secret behind exceptional websites,
[00:51:39.680 --> 00:51:42.080]   go to squarespace.com/twig.
[00:51:42.080 --> 00:51:45.080]   Right now, I gave a talk on the cruise,
[00:51:45.080 --> 00:51:47.720]   as I mentioned about social media.
[00:51:47.720 --> 00:51:50.520]   And we talked about Twitter and Facebook
[00:51:50.520 --> 00:51:52.280]   and how to claim your Facebook username
[00:51:52.280 --> 00:51:54.640]   and all that stuff, but I said, look,
[00:51:54.640 --> 00:51:58.000]   the most important thing for you to do,
[00:51:58.000 --> 00:52:00.040]   the most important place you should exist on the web
[00:52:00.040 --> 00:52:02.240]   is your own website.
[00:52:02.240 --> 00:52:05.280]   So many people think, oh, I have a Facebook page,
[00:52:05.280 --> 00:52:06.760]   that's not enough.
[00:52:06.760 --> 00:52:08.440]   But the good news is very easy
[00:52:08.440 --> 00:52:11.080]   and affordable to create your own website.
[00:52:11.080 --> 00:52:14.160]   Get your go to hover.com, get your name,
[00:52:14.160 --> 00:52:17.880]   register your name, then go to squarespace.com/twig.
[00:52:17.880 --> 00:52:18.880]   Click that green button,
[00:52:18.880 --> 00:52:20.080]   you can try it free for two weeks
[00:52:20.080 --> 00:52:21.920]   and you get all the features.
[00:52:21.920 --> 00:52:23.080]   You don't have to give them a credit card
[00:52:23.080 --> 00:52:26.280]   or anything, just the site name, password, email address
[00:52:26.280 --> 00:52:28.320]   and a little capture and you're in.
[00:52:28.320 --> 00:52:30.600]   And you can try all the great features of Squarespace.
[00:52:30.600 --> 00:52:35.200]   It's hosting plus the best content management software
[00:52:35.200 --> 00:52:36.040]   out there, right?
[00:52:36.040 --> 00:52:38.000]   I don't wanna scare you with that CMS term,
[00:52:38.000 --> 00:52:40.000]   but what it means is for a blog,
[00:52:40.000 --> 00:52:43.200]   for a photo gallery, for a forum even,
[00:52:43.200 --> 00:52:44.680]   or just for a site that says,
[00:52:44.680 --> 00:52:49.320]   hey, I'm here, this is me, here's my stuff,
[00:52:49.320 --> 00:52:50.440]   which at least you gotta do,
[00:52:50.440 --> 00:52:54.680]   at least if you have a social media strategy,
[00:52:54.680 --> 00:52:55.920]   you gotta have a website.
[00:52:55.920 --> 00:52:57.240]   I don't care if you're a small business
[00:52:57.240 --> 00:52:58.280]   or just an individual,
[00:52:58.280 --> 00:53:00.440]   you gotta have a website and there's no easier way to do it
[00:53:00.440 --> 00:53:02.280]   than squarespace.com.
[00:53:02.280 --> 00:53:04.440]   Go to squarespace.com/twig,
[00:53:04.440 --> 00:53:06.560]   try it free for two weeks
[00:53:06.560 --> 00:53:08.120]   and I have a feeling you will love it.
[00:53:08.120 --> 00:53:09.760]   The beautiful templates make it easy
[00:53:09.760 --> 00:53:12.480]   to make a site that looks totally professional.
[00:53:12.480 --> 00:53:15.880]   Social network integration so that you're,
[00:53:15.880 --> 00:53:18.080]   yes, your Facebook page and your Twitter and all that.
[00:53:18.080 --> 00:53:19.880]   I mean, actually they do it better than anybody
[00:53:19.880 --> 00:53:20.840]   I've ever seen before.
[00:53:20.840 --> 00:53:23.280]   They have these very simple plugins.
[00:53:23.280 --> 00:53:24.520]   There's the Flickr widget
[00:53:24.520 --> 00:53:28.160]   and you can have thumbnails or pictures.
[00:53:28.160 --> 00:53:29.080]   You can have a slideshow.
[00:53:29.080 --> 00:53:31.040]   Here's the Twitter widget.
[00:53:31.040 --> 00:53:33.640]   And you see it's just sliders, checkboxes, styles.
[00:53:33.640 --> 00:53:36.920]   It's so easy, but of course, if you know CSS,
[00:53:36.920 --> 00:53:38.160]   you could do any RSS feed.
[00:53:38.160 --> 00:53:41.520]   If you know CSS, the sky's the limit
[00:53:41.520 --> 00:53:43.920]   because all of this can be completely configured
[00:53:43.920 --> 00:53:44.920]   to your hearts and contents.
[00:53:44.920 --> 00:53:48.160]   squarespace.com/twig.
[00:53:48.160 --> 00:53:51.280]   It's the secret behind exceptional websites.
[00:53:51.280 --> 00:53:53.840]   So I didn't know this.
[00:53:53.840 --> 00:53:56.440]   We talked about the Google Doodle contest
[00:53:56.440 --> 00:54:01.240]   where kids were encouraged to send in doodles,
[00:54:01.240 --> 00:54:04.080]   Google doodles, but apparently when you fill out the form
[00:54:04.080 --> 00:54:05.440]   when mom or dad fills out the form,
[00:54:05.440 --> 00:54:06.840]   'cause I guess they have to,
[00:54:06.840 --> 00:54:10.360]   Google was asking for the last four digits
[00:54:10.360 --> 00:54:12.260]   of the kids social.
[00:54:12.260 --> 00:54:16.000]   They've taken that off.
[00:54:16.000 --> 00:54:17.440]   That was on the parental consent form.
[00:54:17.440 --> 00:54:19.360]   They wanted the date of birth,
[00:54:19.360 --> 00:54:20.400]   where you were born.
[00:54:20.400 --> 00:54:21.920]   They wanted your parents full details
[00:54:21.920 --> 00:54:24.880]   and it wanted the kids last four digits,
[00:54:24.880 --> 00:54:27.160]   even if you're six years old.
[00:54:27.160 --> 00:54:29.840]   - They said that they did this
[00:54:29.840 --> 00:54:30.960]   because they wanted to make sure
[00:54:30.960 --> 00:54:33.200]   there weren't duplicate entries, right?
[00:54:33.200 --> 00:54:34.800]   But this actually dovetails really nicely
[00:54:34.800 --> 00:54:35.880]   in what we were talking about earlier
[00:54:35.880 --> 00:54:38.680]   about creepiness and what you can do when you have data.
[00:54:38.680 --> 00:54:40.360]   When you have someone's place of birth
[00:54:40.360 --> 00:54:41.320]   and their time of birth,
[00:54:41.320 --> 00:54:43.560]   you can make a very good guess
[00:54:43.560 --> 00:54:46.760]   at the first five digits of their social security number.
[00:54:46.760 --> 00:54:49.400]   So if you have the last four,
[00:54:49.400 --> 00:54:51.800]   you could, people were saying,
[00:54:51.800 --> 00:54:53.400]   when there was a writer up in the post,
[00:54:53.400 --> 00:54:55.080]   who made the point that Google could guess
[00:54:55.080 --> 00:54:57.720]   these children's full social security number
[00:54:57.720 --> 00:55:00.400]   given this information.
[00:55:00.400 --> 00:55:02.880]   I have to say, I think they're just making
[00:55:02.880 --> 00:55:04.040]   a big deal out of nothing.
[00:55:04.040 --> 00:55:05.720]   I think that this was really just about Google
[00:55:05.720 --> 00:55:07.680]   wanting to dedupe entries.
[00:55:07.680 --> 00:55:09.160]   But same time, like this is the creepy thing
[00:55:09.160 --> 00:55:10.000]   we were talking about.
[00:55:10.000 --> 00:55:13.320]   It's like, if Google has this much information about me,
[00:55:13.320 --> 00:55:14.560]   what else can they deduce,
[00:55:14.560 --> 00:55:16.360]   we know that they're in the business of doing this.
[00:55:16.360 --> 00:55:18.840]   So it makes us question whether or not they are,
[00:55:18.840 --> 00:55:20.480]   even if, no, especially when there are six and seven
[00:55:20.480 --> 00:55:21.580]   year olds in the long,
[00:55:21.580 --> 00:55:24.240]   - It feels like it's like my first Google.
[00:55:24.240 --> 00:55:25.920]   You know, Sony has my first Walkman.
[00:55:25.920 --> 00:55:27.160]   It's like my first Google.
[00:55:27.160 --> 00:55:29.640]   It's like, we'll start your data collection now,
[00:55:29.640 --> 00:55:30.480]   if you don't mind.
[00:55:30.480 --> 00:55:33.120]   We're just starting a little dossier on you.
[00:55:33.120 --> 00:55:33.960]   Don't mind us.
[00:55:33.960 --> 00:55:35.680]   It's not gonna not a big deal.
[00:55:35.680 --> 00:55:38.560]   - The Google spokesperson emphasized the company
[00:55:38.560 --> 00:55:43.200]   has never before asked for social security numbers.
[00:55:43.200 --> 00:55:44.280]   This, I think you're right, Gina.
[00:55:44.280 --> 00:55:47.120]   This is the typical programmer thing where a programmer goes,
[00:55:47.120 --> 00:55:48.600]   oh, I know how we could disambiguate.
[00:55:48.600 --> 00:55:50.200]   Well, just what would be unique?
[00:55:50.200 --> 00:55:52.240]   Oh, the last four digits of their social.
[00:55:52.240 --> 00:55:54.040]   - Right.
[00:55:54.040 --> 00:55:55.120]   - But they didn't think.
[00:55:55.120 --> 00:55:56.120]   - They didn't think.
[00:55:56.120 --> 00:55:58.760]   - And actually-- - That's the kid will say,
[00:55:58.760 --> 00:56:00.280]   get an iris scan.
[00:56:00.280 --> 00:56:01.680]   (laughing)
[00:56:01.680 --> 00:56:03.720]   - That's a good way to disambiguate, disambiguate.
[00:56:03.720 --> 00:56:07.000]   - By the way, could my little camera here do an iris scan?
[00:56:07.000 --> 00:56:09.880]   - I don't know.
[00:56:09.880 --> 00:56:10.720]   - I don't know.
[00:56:10.720 --> 00:56:12.920]   He's launched a camera, so pretty good.
[00:56:12.920 --> 00:56:15.600]   - Does it have to, I think it's probably no different
[00:56:15.600 --> 00:56:17.720]   than the cameras that they use for that clear.
[00:56:17.720 --> 00:56:20.440]   Remember clear, which is back now, I guess.
[00:56:20.440 --> 00:56:21.360]   It went out of business briefly.
[00:56:21.360 --> 00:56:22.400]   - Yeah, I signed up for the one.
[00:56:22.400 --> 00:56:24.120]   I actually got to use it.
[00:56:24.120 --> 00:56:25.520]   - It's cool. - The new one?
[00:56:25.520 --> 00:56:26.360]   - The new one.
[00:56:26.360 --> 00:56:27.760]   Nope, no, I'm gonna get it.
[00:56:27.760 --> 00:56:28.760]   - You know your dark game.
[00:56:28.760 --> 00:56:29.840]   - I signed up for the old one,
[00:56:29.840 --> 00:56:31.920]   and they took an iris scan,
[00:56:31.920 --> 00:56:33.720]   although they never used it again.
[00:56:33.720 --> 00:56:39.440]   They did a whole bunch of highly intrusive stuff.
[00:56:39.440 --> 00:56:41.160]   And I don't know where that database ended up.
[00:56:41.160 --> 00:56:42.320]   They just went out of business and said,
[00:56:42.320 --> 00:56:43.960]   "Thank you very much, we'll see ya.
[00:56:43.960 --> 00:56:45.200]   Bye!"
[00:56:45.200 --> 00:56:46.880]   We got your iris, your fingerprints.
[00:56:46.880 --> 00:56:48.600]   They take all 10 fingers.
[00:56:48.600 --> 00:56:51.720]   It was really arduous.
[00:56:51.720 --> 00:56:54.080]   Did they do the same thing this time around?
[00:56:54.080 --> 00:56:54.920]   - Yeah, it wasn't that bad.
[00:56:54.920 --> 00:56:57.080]   No, you just go fill out a format and do this and that,
[00:56:57.080 --> 00:56:58.200]   and then you go through.
[00:56:58.200 --> 00:56:59.040]   It was nice.
[00:56:59.040 --> 00:57:00.720]   - The thing about, for some people who know
[00:57:00.720 --> 00:57:02.320]   what we're talking about, this is the idea.
[00:57:02.320 --> 00:57:04.520]   In fact, it was an idea by...
[00:57:04.520 --> 00:57:05.360]   - Steve Brill.
[00:57:05.360 --> 00:57:06.200]   - Steve Brill.
[00:57:06.200 --> 00:57:10.480]   With that, I guess he didn't like waiting in security lines
[00:57:10.480 --> 00:57:12.400]   that if you had the clear card, you have a special,
[00:57:12.400 --> 00:57:14.200]   although it really wasn't a special line,
[00:57:14.200 --> 00:57:16.680]   at least not in the airports I ever went to.
[00:57:16.680 --> 00:57:18.320]   It was actually quite embarrassing.
[00:57:18.320 --> 00:57:20.320]   You'd go to the clear booth, which had no line,
[00:57:20.320 --> 00:57:21.360]   'cause nobody used it.
[00:57:21.360 --> 00:57:23.280]   You'd give him your clear card,
[00:57:23.280 --> 00:57:27.160]   and I can't remember how they'd verified it to you,
[00:57:27.160 --> 00:57:29.360]   but maybe you, I don't know, something.
[00:57:30.360 --> 00:57:31.640]   I don't think they didn't iris scan.
[00:57:31.640 --> 00:57:32.960]   I don't think they did the fingerprints.
[00:57:32.960 --> 00:57:34.040]   They just give him the card.
[00:57:34.040 --> 00:57:34.960]   They go, "Oh, hey."
[00:57:34.960 --> 00:57:38.880]   And then a lady comes over and gives you a tub.
[00:57:38.880 --> 00:57:41.040]   You put all your stuff in the tub, and she goes,
[00:57:41.040 --> 00:57:42.560]   she's like an icebreaker.
[00:57:42.560 --> 00:57:44.560]   She goes to the head of the line.
[00:57:44.560 --> 00:57:46.200]   - Excuse me, out of the way, out of the way.
[00:57:46.200 --> 00:57:47.520]   Leo's gotta get through.
[00:57:47.520 --> 00:57:49.440]   There's kids, there's ladies, there's people,
[00:57:49.440 --> 00:57:51.160]   there's pregnant people, there's people who wield shit.
[00:57:51.160 --> 00:57:53.560]   Out of the way, Leo paid for clear.
[00:57:53.560 --> 00:57:54.560]   And you're getting to the head,
[00:57:54.560 --> 00:57:55.800]   it was the most embarrassing thing.
[00:57:55.800 --> 00:57:57.720]   I never used it again.
[00:57:57.720 --> 00:57:58.840]   No wonder they went out of business.
[00:57:58.840 --> 00:58:02.400]   So it's the same thing now, or do they have special lines?
[00:58:02.400 --> 00:58:04.240]   - It's when you're coming through customs
[00:58:04.240 --> 00:58:05.440]   at the end of the stock first.
[00:58:05.440 --> 00:58:07.600]   - Oh, yeah, well the customs thing is different.
[00:58:07.600 --> 00:58:10.440]   Both US and Canada do this, yeah.
[00:58:10.440 --> 00:58:11.640]   That was even more intrusive,
[00:58:11.640 --> 00:58:12.920]   but at least it's a federal government,
[00:58:12.920 --> 00:58:14.240]   and you could trust them.
[00:58:14.240 --> 00:58:18.720]   Well, that was dead silence.
[00:58:18.720 --> 00:58:20.400]   Russia says it's,
[00:58:20.400 --> 00:58:21.840]   (laughing)
[00:58:21.840 --> 00:58:26.840]   Russia says that Google planned
[00:58:27.760 --> 00:58:30.040]   the Egyptian revolution,
[00:58:30.040 --> 00:58:33.120]   that Google manipulated the energy of the people,
[00:58:33.120 --> 00:58:35.560]   the comments during an interview
[00:58:35.560 --> 00:58:37.160]   about the investment climate in Russia
[00:58:37.160 --> 00:58:39.520]   with the Wall Street Journal,
[00:58:39.520 --> 00:58:41.160]   with Russian Deputy Prime Minister
[00:58:41.160 --> 00:58:43.960]   and Energy Minister Igor Sechin.
[00:58:43.960 --> 00:58:48.400]   I guess the problem was the initial question,
[00:58:48.400 --> 00:58:49.920]   the reporter for the journal said,
[00:58:49.920 --> 00:58:51.840]   how can we trust Russia?
[00:58:51.840 --> 00:58:54.900]   How can you convince investors to trust Russia?
[00:58:57.240 --> 00:58:59.240]   Sechin said Russia's changed radically
[00:58:59.240 --> 00:59:00.400]   in the last 25 years,
[00:59:00.400 --> 00:59:03.760]   one of the world's most stable political systems.
[00:59:03.760 --> 00:59:05.160]   Then the reporter really,
[00:59:05.160 --> 00:59:08.640]   sent in the knife, he said,
[00:59:08.640 --> 00:59:11.640]   well, Mubarak probably said the same thing.
[00:59:11.640 --> 00:59:13.520]   (laughing)
[00:59:13.520 --> 00:59:15.520]   Sechin said, look what they have done in Egypt,
[00:59:15.520 --> 00:59:17.800]   those highly placed managers of Google,
[00:59:17.800 --> 00:59:20.280]   what manipulations of the energy of the people
[00:59:20.280 --> 00:59:22.920]   took place there, wow.
[00:59:22.920 --> 00:59:24.960]   - Yeah, wow.
[00:59:24.960 --> 00:59:27.960]   And the hilarious thing is that puts Russia and Putin's
[00:59:27.960 --> 00:59:32.360]   spokesman squarely in the same camp as Glenn Beck.
[00:59:32.360 --> 00:59:33.200]   - What?
[00:59:33.200 --> 00:59:34.360]   Glenn Beck said that?
[00:59:34.360 --> 00:59:35.360]   - Glenn Beck's been saying,
[00:59:35.360 --> 00:59:37.520]   I don't want Google involved in my world affairs,
[00:59:37.520 --> 00:59:39.520]   I don't want Google involved in this or that.
[00:59:39.520 --> 00:59:40.600]   You know, it's the weirdest thing,
[00:59:40.600 --> 00:59:42.400]   not that I listen to Glenn Beck very often,
[00:59:42.400 --> 00:59:45.480]   I try not to, but geez,
[00:59:45.480 --> 00:59:47.120]   he's being wacky about this,
[00:59:47.120 --> 00:59:49.960]   and so basically he doesn't want to see any good news
[00:59:49.960 --> 00:59:52.440]   out of Egypt, because it's the,
[00:59:52.440 --> 00:59:54.360]   you know, it's he's anti-Muslim,
[00:59:54.360 --> 00:59:57.480]   Marathi Arabs are going to come to your backyard next.
[00:59:57.480 --> 00:59:58.840]   - She's Louise.
[00:59:58.840 --> 00:59:59.680]   - Wow.
[00:59:59.680 --> 01:00:01.320]   - So it's really strange the reaction to this.
[01:00:01.320 --> 01:00:03.120]   - So this all comes from the fact that it was a Google
[01:00:03.120 --> 01:00:04.560]   executive.
[01:00:04.560 --> 01:00:06.480]   - Right, right, go name.
[01:00:06.480 --> 01:00:08.200]   - Walla gomime, go name.
[01:00:08.200 --> 01:00:09.040]   - I don't know, yeah.
[01:00:09.040 --> 01:00:12.480]   - Who created the Facebook page that was widely credited
[01:00:12.480 --> 01:00:14.800]   with being the beginning of the revolution.
[01:00:14.800 --> 01:00:16.120]   - Who took a leave of absence,
[01:00:16.120 --> 01:00:17.400]   who sort of didn't lie,
[01:00:17.400 --> 01:00:19.560]   but cut, or took a leave of Dastin's up first,
[01:00:19.560 --> 01:00:21.040]   didn't let Google know that he was,
[01:00:21.040 --> 01:00:22.160]   what he was doing.
[01:00:22.160 --> 01:00:23.520]   And then when it was all over,
[01:00:23.520 --> 01:00:27.040]   tweeted, you know, I hope that Google will have me back.
[01:00:27.040 --> 01:00:28.600]   And actually Google tweeted back to him,
[01:00:28.600 --> 01:00:30.400]   sort of publicly, and said that they were gonna try
[01:00:30.400 --> 01:00:31.240]   and they have him back.
[01:00:31.240 --> 01:00:32.080]   - No kidding.
[01:00:32.080 --> 01:00:34.200]   - Right, guys, a hero, but it had nothing to do.
[01:00:34.200 --> 01:00:35.040]   I mean, actually--
[01:00:35.040 --> 01:00:38.280]   - I talked to Karen Wickry, who actually sent that tweet,
[01:00:38.280 --> 01:00:40.720]   and on behalf of the company, she typed it out,
[01:00:40.720 --> 01:00:44.160]   but it was, they saw that immediately and said,
[01:00:44.160 --> 01:00:46.080]   we'll have you back, and we're very proud of you.
[01:00:46.080 --> 01:00:46.920]   - Good.
[01:00:46.920 --> 01:00:48.440]   - It was a very important statement from Google.
[01:00:48.440 --> 01:00:49.360]   - Yeah.
[01:00:49.360 --> 01:00:51.520]   - And he did say in a 60 minute interview
[01:00:51.520 --> 01:00:55.720]   that Google put some pressure to get him out.
[01:00:55.720 --> 01:00:57.520]   So Google was involved in getting him out, but--
[01:00:57.520 --> 01:00:58.720]   - Out of the country.
[01:00:58.720 --> 01:00:59.560]   - Out of jail.
[01:00:59.560 --> 01:01:00.400]   - Oh, out of jail.
[01:01:00.400 --> 01:01:01.760]   - That's where he's in jail, that's right, yeah.
[01:01:01.760 --> 01:01:03.840]   - It's very interesting because you have companies
[01:01:03.840 --> 01:01:07.120]   like Google and Facebook want to help,
[01:01:07.120 --> 01:01:08.560]   but want to not get too close,
[01:01:08.560 --> 01:01:10.920]   because then there's another reason not to have you
[01:01:10.920 --> 01:01:11.920]   in China and so on.
[01:01:11.920 --> 01:01:12.760]   - Right.
[01:01:12.760 --> 01:01:14.040]   - And Facebook, I was seeing that,
[01:01:14.040 --> 01:01:15.760]   you know, I'm gonna call it a story this week,
[01:01:15.760 --> 01:01:18.040]   that there are those who said that,
[01:01:18.040 --> 01:01:20.160]   'cause Gorem's page on Facebook,
[01:01:20.160 --> 01:01:24.200]   because he was pseudonymous,
[01:01:24.200 --> 01:01:25.560]   they originally killed the page,
[01:01:25.560 --> 01:01:26.920]   because he wasn't using his real name,
[01:01:26.920 --> 01:01:30.040]   and they argue with it as, well, no, he couldn't.
[01:01:30.040 --> 01:01:33.080]   But the argument back is, well, that's what Facebook is.
[01:01:33.080 --> 01:01:34.800]   And so there are those who are trying to argue
[01:01:34.800 --> 01:01:38.680]   that Facebook should enable pseudonyms and false identities,
[01:01:38.680 --> 01:01:41.400]   but I'm not so sure, I think that's Facebook.
[01:01:41.400 --> 01:01:44.840]   You should tell four square,
[01:01:44.840 --> 01:01:45.920]   maybe I say in the four square,
[01:01:45.920 --> 01:01:48.440]   that you should set up so that I can lie wherever I am.
[01:01:48.440 --> 01:01:49.320]   - Yeah.
[01:01:49.320 --> 01:01:50.720]   - No, that's not what it is.
[01:01:50.720 --> 01:01:51.840]   - It's an issue.
[01:01:51.840 --> 01:01:52.680]   - Yeah.
[01:01:52.680 --> 01:01:53.720]   - No, that's not what it is.
[01:01:53.720 --> 01:01:56.200]   And look, Facebook played a role
[01:01:56.200 --> 01:01:57.720]   and they didn't need anonymity,
[01:01:57.720 --> 01:02:01.240]   and he was, going in was very brave.
[01:02:01.240 --> 01:02:05.560]   And, you know, I think that's part of the reason
[01:02:05.560 --> 01:02:10.320]   that he was trusted by the people in Tahrir Square.
[01:02:10.320 --> 01:02:12.880]   I mean, this guy paid his dues.
[01:02:12.880 --> 01:02:14.280]   - And it was in public.
[01:02:14.280 --> 01:02:16.080]   - When he got out of jail,
[01:02:16.080 --> 01:02:18.200]   the rumor had spread that he was out.
[01:02:18.200 --> 01:02:21.160]   People said, "I'm not believing it till I see it on Twitter."
[01:02:21.160 --> 01:02:22.440]   'Cause that's for him.
[01:02:22.440 --> 01:02:24.080]   Also-- - Frank, 'cause he got dark, right?
[01:02:24.080 --> 01:02:25.840]   His Twitter had gone dark there for a while.
[01:02:25.840 --> 01:02:27.080]   - So you knew that was him.
[01:02:27.080 --> 01:02:31.960]   The night that Mubarak didn't leave,
[01:02:31.960 --> 01:02:34.120]   Ganyim said on Twitter,
[01:02:34.120 --> 01:02:35.600]   "I'm not gonna talk to the press tomorrow.
[01:02:35.600 --> 01:02:39.320]   "I'm gonna talk to my people through my Facebook page."
[01:02:39.320 --> 01:02:40.480]   And then the great moment, you know,
[01:02:40.480 --> 01:02:42.680]   when he said that he wanted to, on CNN,
[01:02:42.680 --> 01:02:44.120]   that I wanna meet Mark Zuckerberg,
[01:02:44.120 --> 01:02:46.840]   which I'm sure he will now, to thank him.
[01:02:46.840 --> 01:02:48.640]   Meanwhile, we have this whole, I think,
[01:02:48.640 --> 01:02:50.760]   rather silly argument going on
[01:02:50.760 --> 01:02:55.200]   about the triumphalist versus the curmudgeon's,
[01:02:55.200 --> 01:02:59.760]   where, to some extent, you're getting more ads off
[01:02:59.760 --> 01:03:01.120]   and a few others were saying that,
[01:03:01.120 --> 01:03:02.480]   well, especially Malcolm Gladwell,
[01:03:02.480 --> 01:03:05.000]   that this is not the Twitter revolution Facebook.
[01:03:05.000 --> 01:03:06.320]   Has it ever been that before then?
[01:03:06.320 --> 01:03:08.440]   - What, why did Malcolm get it wrong?
[01:03:08.440 --> 01:03:10.240]   - Oh, geez. - Oh boy.
[01:03:10.240 --> 01:03:14.360]   I mean, this is, I mean, you couldn't have,
[01:03:14.360 --> 01:03:16.680]   more right on the heels of Malcolm Gladwell's
[01:03:16.680 --> 01:03:18.600]   New Yorker article saying, "Twitter just promotes
[01:03:18.600 --> 01:03:20.920]   "the status quo, it's not used for revolutions."
[01:03:20.920 --> 01:03:22.580]   And then this happens.
[01:03:22.580 --> 01:03:25.920]   - There's a great cartoon of Malcolm Gladwell,
[01:03:25.920 --> 01:03:27.400]   hits his tipping point.
[01:03:27.400 --> 01:03:28.400]   - Yeah. (laughs)
[01:03:28.400 --> 01:03:30.480]   I mean, I got nothing against the guy I love his stuff
[01:03:30.480 --> 01:03:32.680]   and I've read his books and he's a great speaker.
[01:03:32.680 --> 01:03:34.480]   - Oh, the hair's ridiculous.
[01:03:34.480 --> 01:03:36.160]   - The hair's a little silly, but he got it wrong.
[01:03:36.160 --> 01:03:37.440]   And that's the point.
[01:03:37.440 --> 01:03:42.240]   And the naysayers who said this Facebook, Twitter stuff,
[01:03:42.240 --> 01:03:46.200]   it's just trivia, I think, after now, kind of say,
[01:03:46.200 --> 01:03:48.800]   look, the internet is changing the world.
[01:03:48.800 --> 01:03:50.640]   - There's a plate of pro-bones ready for him.
[01:03:50.640 --> 01:03:52.560]   - Yeah. - The internet,
[01:03:52.560 --> 01:03:54.480]   digital technology is changing the world,
[01:03:54.480 --> 01:03:56.800]   not always for the good, but in general for the good,
[01:03:56.800 --> 01:04:00.520]   because I think the free flow of information
[01:04:00.520 --> 01:04:02.520]   ultimately benefits everyone.
[01:04:02.520 --> 01:04:06.160]   - The problem is that they keep on trying to
[01:04:06.160 --> 01:04:09.240]   shoot at a made up red hair.
[01:04:09.240 --> 01:04:11.240]   They keep on saying, "Do the triumphalist say
[01:04:11.240 --> 01:04:13.040]   "that Twitter causes revolution?
[01:04:13.040 --> 01:04:14.520]   "I find me the person who says that,
[01:04:14.520 --> 01:04:15.880]   "I know no one who says that.
[01:04:15.880 --> 01:04:17.840]   "Everyone I know says this is a revolution."
[01:04:17.840 --> 01:04:19.640]   - It's a tool, it's a people revolution.
[01:04:19.640 --> 01:04:21.280]   - People rules to their advantage.
[01:04:21.280 --> 01:04:23.240]   The people who did the revolution said
[01:04:23.240 --> 01:04:25.200]   these tools were valuable to us.
[01:04:25.200 --> 01:04:27.040]   - You still have to fill the square,
[01:04:27.040 --> 01:04:28.760]   and in some places, like Libya,
[01:04:28.760 --> 01:04:31.480]   you still have to throw your body in front of a tank.
[01:04:31.480 --> 01:04:34.280]   Twitter won't do that for you, but it's sure as a tool.
[01:04:34.280 --> 01:04:38.600]   And I have to think that, I mean, the fact that Egypt
[01:04:38.600 --> 01:04:40.720]   cut off the internet, that Libya is now cutting off
[01:04:40.720 --> 01:04:42.480]   the internet tells you something,
[01:04:42.480 --> 01:04:44.120]   that this is a tool for democratization.
[01:04:44.120 --> 01:04:45.840]   We said that TV would be that.
[01:04:45.840 --> 01:04:48.000]   And I think in some ways it was.
[01:04:48.000 --> 01:04:51.920]   It certainly showed people another part of the world.
[01:04:51.920 --> 01:04:53.840]   But the internet is so unmediated,
[01:04:53.840 --> 01:04:55.880]   I think in the long run, it's a better tool
[01:04:55.880 --> 01:04:57.840]   for that kind of democratization.
[01:04:57.840 --> 01:05:00.280]   - And interactive, you have to have an entire community
[01:05:00.280 --> 01:05:02.120]   of people ready for change.
[01:05:02.120 --> 01:05:04.920]   You know, it has to be, the community has to be ready,
[01:05:04.920 --> 01:05:07.160]   and then the tools will work.
[01:05:07.160 --> 01:05:08.520]   - That's just pretty darn exciting.
[01:05:08.520 --> 01:05:10.600]   - Well, you know, there's another way to go.
[01:05:10.600 --> 01:05:12.000]   This is gonna go away.
[01:05:12.000 --> 01:05:17.000]   What the hell work, this is side road day on Quay.
[01:05:17.000 --> 01:05:19.840]   I interviewed Elizabeth Eisenstein,
[01:05:19.840 --> 01:05:23.640]   who wrote the definitive book on Gutenberg.
[01:05:23.640 --> 01:05:25.560]   In fact, I'm reading her next book,
[01:05:25.560 --> 01:05:29.520]   we're a plug right now, about Gutenberg and presses,
[01:05:29.520 --> 01:05:31.000]   Divine Art and Fertile Machine.
[01:05:31.000 --> 01:05:34.080]   - I think Gutenberg presses a very good analog
[01:05:34.080 --> 01:05:35.000]   of what's happening today.
[01:05:35.000 --> 01:05:37.600]   - I believe that now, Morazov yelled at me,
[01:05:37.600 --> 01:05:39.320]   made fun of me for it, but effem.
[01:05:39.320 --> 01:05:41.960]   - Well, you can't, you know, she said,
[01:05:41.960 --> 01:05:44.720]   and I could be careful, 'cause I didn't quiz her enough
[01:05:44.720 --> 01:05:47.960]   on this, but she said that the Gutenberg revolution,
[01:05:47.960 --> 01:05:49.760]   to some extent, skipped Arabia.
[01:05:49.760 --> 01:05:53.040]   Prating in some quarters was forbidden for three centuries.
[01:05:53.040 --> 01:05:55.720]   The same, and Steve, I don't think about it,
[01:05:55.720 --> 01:05:57.400]   mad at me for that, that it was too simplistic,
[01:05:57.400 --> 01:05:59.360]   and she's not saying very carefully
[01:05:59.360 --> 01:06:01.040]   that Arabia was in the Middle Ages.
[01:06:01.040 --> 01:06:03.080]   She's just saying that the impact was different.
[01:06:03.080 --> 01:06:03.920]   - Different.
[01:06:03.920 --> 01:06:06.040]   - And in a sense, what's happening now,
[01:06:06.040 --> 01:06:08.440]   'cause they stayed in some measure in oral tradition,
[01:06:08.440 --> 01:06:10.280]   the impact of printing wasn't the same,
[01:06:10.280 --> 01:06:13.320]   and now they're Gutenberg press is Twitter and Facebook.
[01:06:13.320 --> 01:06:14.480]   - Yeah.
[01:06:14.480 --> 01:06:17.400]   - And when people are empowered to speak,
[01:06:17.400 --> 01:06:19.200]   look at the amazing things that happen.
[01:06:19.200 --> 01:06:20.520]   It happened with a reformation,
[01:06:20.520 --> 01:06:22.080]   it's happening again with tools
[01:06:22.080 --> 01:06:24.200]   that enable the public to be public,
[01:06:24.200 --> 01:06:26.320]   which is a plug for my book, but what the hell?
[01:06:26.320 --> 01:06:28.200]   - Well, this is the subject.
[01:06:28.200 --> 01:06:29.040]   - Yeah.
[01:06:29.040 --> 01:06:30.040]   - It's a great time.
[01:06:30.040 --> 01:06:31.080]   - Yeah, yeah.
[01:06:31.080 --> 01:06:31.920]   Public works.
[01:06:31.920 --> 01:06:33.800]   - It's what Gina said before about, you know,
[01:06:33.800 --> 01:06:35.320]   being a great time to be alive for Watson,
[01:06:35.320 --> 01:06:39.640]   it's a great time to be, to see not only machines empowered,
[01:06:39.640 --> 01:06:41.040]   but people empowered.
[01:06:41.040 --> 01:06:44.560]   - I feel very fortunate that early in my career,
[01:06:44.560 --> 01:06:47.360]   as a journalist, I said, "I think I wanna cover technology."
[01:06:47.360 --> 01:06:50.200]   Well, that was a hell of a beat.
[01:06:50.200 --> 01:06:52.480]   (both laughing)
[01:06:52.480 --> 01:06:53.320]   - Yeah, for me, it was like,
[01:06:53.320 --> 01:06:54.800]   oh, this web thing is kind of interesting.
[01:06:54.800 --> 01:06:55.640]   - Kinda cool.
[01:06:55.640 --> 01:06:57.040]   - I'm really glad I said not that.
[01:06:57.040 --> 01:06:57.960]   (both laughing)
[01:06:57.960 --> 01:06:59.480]   - Oh, damn.
[01:06:59.480 --> 01:07:02.800]   I can't claim any pressions, but boy, I feel lucky.
[01:07:02.800 --> 01:07:06.920]   We have ringside seats, and everyone who watches Twitter
[01:07:06.920 --> 01:07:10.480]   is ringside seats to a world is changing so rapidly.
[01:07:10.480 --> 01:07:12.720]   I can't wait to talk to Ray Kurzweil on a couple of weeks.
[01:07:12.720 --> 01:07:13.720]   - Oh, great.
[01:07:13.720 --> 01:07:14.560]   - It's gonna be great.
[01:07:14.560 --> 01:07:17.600]   Time for our tool, tip, and number of the week.
[01:07:17.600 --> 01:07:21.000]   Let's start with Gina Trapani and her tip of the week.
[01:07:21.000 --> 01:07:24.040]   - Sure, my tip this week is actually a little bit of a tool
[01:07:24.040 --> 01:07:26.360]   where all of us are, at least I'm gonna start
[01:07:26.360 --> 01:07:30.280]   in together by our income tax return soon,
[01:07:30.280 --> 01:07:32.360]   which is always a thrill.
[01:07:32.360 --> 01:07:34.200]   But there's a really cool data visualization
[01:07:34.200 --> 01:07:37.400]   that shows you where your tax dollars go.
[01:07:37.400 --> 01:07:41.040]   So you go to datavischallenge.org,
[01:07:41.040 --> 01:07:42.920]   there's a click on see an example,
[01:07:42.920 --> 01:07:45.760]   you can enter in the year and how much you paid in taxes
[01:07:45.760 --> 01:07:47.040]   and then where that money went,
[01:07:47.040 --> 01:07:50.080]   and a really neat interactive visualization
[01:07:50.080 --> 01:07:52.560]   that lets you zoom around and see exactly
[01:07:52.560 --> 01:07:53.880]   what where your money's going.
[01:07:53.880 --> 01:07:57.440]   And this data comes from what we pay for.com,
[01:07:57.440 --> 01:07:58.640]   which was a data visualization,
[01:07:58.640 --> 01:08:00.560]   that didn't have anything to do with Google.
[01:08:00.560 --> 01:08:02.240]   Google was so impressed with it though.
[01:08:02.240 --> 01:08:03.920]   They started this datavis challenge
[01:08:03.920 --> 01:08:07.160]   and said, "Hey, let's look at different ways
[01:08:07.160 --> 01:08:10.440]   that we can get insights into where your tax dollars go."
[01:08:10.440 --> 01:08:12.120]   So this kind of goes back to what we were talking about earlier.
[01:08:12.120 --> 01:08:14.480]   When you have the data, what are the interesting ways
[01:08:14.480 --> 01:08:17.000]   that you can look at it and insights you can get into it?
[01:08:17.000 --> 01:08:18.680]   So yeah, Leo, you've got it up on the screen there.
[01:08:18.680 --> 01:08:21.640]   Like you can say in 2010, if you paid $10,000
[01:08:21.640 --> 01:08:23.520]   of federal income tax,
[01:08:23.520 --> 01:08:26.920]   you can see that 2,500 went to national defense,
[01:08:26.920 --> 01:08:30.400]   2,300 income security, 2,500 to social security,
[01:08:30.400 --> 01:08:33.760]   and it breaks it down into a really cool interactive graph.
[01:08:33.760 --> 01:08:36.080]   So when you look at the size of the interest,
[01:08:36.080 --> 01:08:38.480]   that thing is floating away.
[01:08:38.480 --> 01:08:42.080]   Holy cow, that is really a great, great.
[01:08:42.080 --> 01:08:42.920]   - Really is.
[01:08:42.920 --> 01:08:45.000]   So if you want to have a discussion about the economy
[01:08:45.000 --> 01:08:46.000]   and where we're headed and spending,
[01:08:46.000 --> 01:08:47.160]   this is the kind of data
[01:08:47.160 --> 01:08:50.000]   and making data available to people, it's matters.
[01:08:50.000 --> 01:08:50.840]   - Yeah.
[01:08:50.840 --> 01:08:51.680]   - Absolutely, absolutely.
[01:08:51.680 --> 01:08:53.040]   I thought this was really, really cool.
[01:08:53.040 --> 01:08:54.800]   And that datavischallenge.org,
[01:08:54.800 --> 01:08:57.720]   they're asking for more different and interesting ways
[01:08:57.720 --> 01:09:00.760]   to look at these numbers, to break these numbers down.
[01:09:00.760 --> 01:09:03.240]   - So you can put in the numbers yourself
[01:09:03.240 --> 01:09:06.040]   and come up with a new visualization for it.
[01:09:06.040 --> 01:09:08.000]   - Right, right, yeah, on this visit,
[01:09:08.000 --> 01:09:09.880]   you can change the year and your filing status
[01:09:09.880 --> 01:09:12.480]   and your income, but they're actually looking
[01:09:12.480 --> 01:09:14.200]   for different ways to visualize.
[01:09:14.200 --> 01:09:15.600]   So this is kind of a bunch of, you know,
[01:09:15.600 --> 01:09:18.240]   sort of vibrating bubbles.
[01:09:18.240 --> 01:09:19.080]   - Right.
[01:09:19.080 --> 01:09:20.800]   - But they're looking for kind of other ways
[01:09:20.800 --> 01:09:22.880]   that you can look at tax data like this.
[01:09:22.880 --> 01:09:24.160]   - Right, here's one from Slate.
[01:09:24.160 --> 01:09:27.240]   Click the green play button,
[01:09:27.240 --> 01:09:28.520]   the animation of the data.
[01:09:28.520 --> 01:09:29.680]   This is neat.
[01:09:29.680 --> 01:09:31.720]   Data visualization is a fascinating,
[01:09:31.720 --> 01:09:33.840]   this is an unemployment statistics, by the way.
[01:09:33.840 --> 01:09:34.840]   - I wanna learn it,
[01:09:34.840 --> 01:09:36.600]   it's like a huge journalist, it's so important.
[01:09:36.600 --> 01:09:37.680]   - Oh, it really is.
[01:09:37.680 --> 01:09:38.520]   - It's so important.
[01:09:38.520 --> 01:09:40.680]   I just went to the Edward Tuffity's One Day course
[01:09:40.680 --> 01:09:42.360]   and I just, I did, it was amazing.
[01:09:42.360 --> 01:09:43.200]   - I wanted to do that.
[01:09:43.200 --> 01:09:44.040]   - He was here in San Diego.
[01:09:44.040 --> 01:09:45.440]   - Yeah, he was up here and I missed it.
[01:09:45.440 --> 01:09:46.280]   - Completely worth it.
[01:09:46.280 --> 01:09:47.120]   - Worth it.
[01:09:47.120 --> 01:09:47.960]   - Really worth it.
[01:09:47.960 --> 01:09:52.120]   Yeah, great, really good day of thinking through a whole lot.
[01:09:52.120 --> 01:09:55.400]   And you get his books, but they actually get all of his books.
[01:09:55.400 --> 01:09:57.960]   - So what does he, is it a hands-on
[01:09:57.960 --> 01:10:00.560]   or a possibilities session?
[01:10:00.560 --> 01:10:03.840]   - It's a possibility session.
[01:10:03.840 --> 01:10:04.840]   So he's a really good speaker.
[01:10:04.840 --> 01:10:06.560]   It's a one day deal, you get all of his books
[01:10:06.560 --> 01:10:09.880]   and he basically shows you examples of good visualizations,
[01:10:09.880 --> 01:10:12.440]   what are the characteristics of a good visualization?
[01:10:12.440 --> 01:10:14.800]   But very engaging, it's definitely not,
[01:10:14.800 --> 01:10:16.880]   it doesn't feel like a lecture.
[01:10:16.880 --> 01:10:18.440]   You're reading and looking and seeing examples
[01:10:18.440 --> 01:10:20.200]   throughout, throughout, and I mean, all day,
[01:10:20.200 --> 01:10:23.280]   I was just writing pages and pages and notes of ideas
[01:10:23.280 --> 01:10:25.720]   that I had for ThinkUp and other apps.
[01:10:25.720 --> 01:10:29.080]   But it really, it makes you really zero in
[01:10:29.080 --> 01:10:33.240]   what makes a good visualization and how important visualizations are
[01:10:33.240 --> 01:10:35.400]   and how important it is to be truthful and honest to them
[01:10:35.400 --> 01:10:38.920]   and how important it is to show data in the right way
[01:10:38.920 --> 01:10:40.720]   to tell the whole story.
[01:10:40.720 --> 01:10:42.720]   So yeah, I highly recommend the class.
[01:10:42.720 --> 01:10:44.560]   - This, I've always loved this poster.
[01:10:44.560 --> 01:10:48.040]   My dad has this on his wall in Napoleon's March.
[01:10:48.040 --> 01:10:49.440]   - Yes, yes, so.
[01:10:49.440 --> 01:10:51.440]   - It's a Moscow in the war of 1812.
[01:10:51.440 --> 01:10:54.400]   - Yeah, the best data is ever made in the history
[01:10:54.400 --> 01:10:55.960]   of data visualization.
[01:10:55.960 --> 01:10:57.120]   - Yeah, that's so cool.
[01:10:57.120 --> 01:10:58.080]   - Amazing image.
[01:10:58.080 --> 01:11:00.240]   - Yeah, we looked at that one actually for quite a long time.
[01:11:00.240 --> 01:11:01.080]   - Yeah.
[01:11:01.080 --> 01:11:03.080]   Oh, that's so neat, I'm so jealous.
[01:11:03.080 --> 01:11:03.920]   (laughing)
[01:11:03.920 --> 01:11:04.920]   - Yeah, I recommend it.
[01:11:04.920 --> 01:11:05.760]   - Oh yeah.
[01:11:05.760 --> 01:11:08.720]   - He comes every year, he comes to the big cities
[01:11:08.720 --> 01:11:09.800]   every year, travels a lot.
[01:11:09.800 --> 01:11:12.920]   And his work is what the visual display
[01:11:12.920 --> 01:11:15.240]   of quantitative information, something like that.
[01:11:15.240 --> 01:11:16.280]   - Yeah, that's one of his books.
[01:11:16.280 --> 01:11:18.440]   He's got a few books out.
[01:11:18.440 --> 01:11:19.440]   - Wow, I'm jealous.
[01:11:19.440 --> 01:11:20.800]   I've always wanted to see him.
[01:11:20.800 --> 01:11:24.160]   Your number of the week, Mr. Jarvis.
[01:11:24.160 --> 01:11:27.480]   - I think I'll do this one, 304,899,
[01:11:27.480 --> 01:11:29.240]   which after two weeks is how many followers
[01:11:29.240 --> 01:11:30.520]   Howard Stern has.
[01:11:30.520 --> 01:11:32.160]   - How many, 304,000?
[01:11:32.160 --> 01:11:34.000]   - Yeah, went up ramp up pretty quickly.
[01:11:34.000 --> 01:11:36.400]   The reason I mention it is because he disappeared.
[01:11:36.400 --> 01:11:38.200]   - He went for a long time.
[01:11:38.200 --> 01:11:39.320]   - He made fun of Twitter.
[01:11:39.320 --> 01:11:40.160]   He went to Twitter.
[01:11:40.160 --> 01:11:41.640]   I went on the air trying to convince him to do Twitter.
[01:11:41.640 --> 01:11:42.480]   Why would I do that?
[01:11:42.480 --> 01:11:43.680]   Why would I give it away?
[01:11:43.680 --> 01:11:45.320]   And suddenly, before he went on Letterman,
[01:11:45.320 --> 01:11:47.160]   he decided to do it that night.
[01:11:47.160 --> 01:11:49.720]   And then he's been on, and Stern being Stern,
[01:11:49.720 --> 01:11:53.160]   I love what he did next, is that he was sitting at home,
[01:11:53.160 --> 01:11:55.160]   private parts, his movie was coming on.
[01:11:55.160 --> 01:11:56.560]   That's not a plug for the book.
[01:11:56.560 --> 01:11:59.960]   And next thing you know,
[01:11:59.960 --> 01:12:03.280]   he was giving the alternative soundtrack,
[01:12:03.280 --> 01:12:06.880]   the explanation track, the DVD Extra Reel to it,
[01:12:06.880 --> 01:12:08.480]   as it was going on using Twitter.
[01:12:08.480 --> 01:12:11.480]   And it's really cool because you can basically go watch
[01:12:11.480 --> 01:12:13.720]   the movie and kind of play that back.
[01:12:13.720 --> 01:12:16.560]   And it was a neat new use of Twitter that I quite like.
[01:12:16.560 --> 01:12:17.400]   - That's neat.
[01:12:17.400 --> 01:12:18.960]   - I like to do it quickly.
[01:12:18.960 --> 01:12:19.800]   - Yeah.
[01:12:19.800 --> 01:12:21.240]   - Yeah, it's really kind of cool.
[01:12:21.240 --> 01:12:22.880]   While I'm on the numbers subject,
[01:12:22.880 --> 01:12:24.920]   I don't know if I plugged him last week,
[01:12:24.920 --> 01:12:26.040]   and I want to mention to everybody,
[01:12:26.040 --> 01:12:28.000]   all of our friends at Twig,
[01:12:28.000 --> 01:12:30.720]   if you haven't started following or looking at Andy Carvin,
[01:12:30.720 --> 01:12:31.960]   A-C-A-R-V-I-M.
[01:12:31.960 --> 01:12:33.400]   - I found him, yeah, he's great.
[01:12:33.400 --> 01:12:34.680]   - And he's magnificent.
[01:12:34.680 --> 01:12:38.120]   - He's an NPR social media strategist
[01:12:38.120 --> 01:12:40.040]   who has been tweeting the revolutions
[01:12:40.040 --> 01:12:41.800]   and adds real journalistic value,
[01:12:41.800 --> 01:12:43.200]   finding the good people,
[01:12:43.200 --> 01:12:44.960]   pointing out what's not confirmed yet,
[01:12:44.960 --> 01:12:48.480]   asking questions, he has about 27,000 followers.
[01:12:48.480 --> 01:12:49.800]   And I'm so amazed at that.
[01:12:49.800 --> 01:12:50.720]   - He's sad.
[01:12:50.720 --> 01:12:51.560]   - Yeah, it is.
[01:12:51.560 --> 01:12:54.600]   - Now the problem is-- - A-C-A-R-V-I-N.
[01:12:54.600 --> 01:12:56.200]   You will take over your feed
[01:12:56.200 --> 01:12:57.680]   in the midst of something going on.
[01:12:57.680 --> 01:13:00.760]   So some people are making a list that is nothing but him.
[01:13:00.760 --> 01:13:01.600]   - Oh, that's funny.
[01:13:01.600 --> 01:13:02.440]   - But he is-- - Right.
[01:13:02.440 --> 01:13:03.640]   - Carvin list.
[01:13:03.640 --> 01:13:06.360]   - He is quite amazing, and I really recommend,
[01:13:06.360 --> 01:13:08.400]   'cause I think that he's creating a new sense
[01:13:08.400 --> 01:13:09.760]   of what journalism-- - Yes.
[01:13:09.760 --> 01:13:14.160]   - And news are in a world of live feeds, so A-Carvin.
[01:13:14.160 --> 01:13:18.440]   - And curation, he's the kind of the epitome of a curation.
[01:13:18.440 --> 01:13:19.560]   - Exactly. - Yeah.
[01:13:19.560 --> 01:13:20.960]   - Yeah, I started following you
[01:13:20.960 --> 01:13:22.200]   after you mentioned him last week, Jeff,
[01:13:22.200 --> 01:13:23.720]   and I feel way more informed.
[01:13:23.720 --> 01:13:24.920]   He really is doing some good stuff.
[01:13:24.920 --> 01:13:25.760]   - Yeah.
[01:13:25.760 --> 01:13:27.720]   - I think I got his name from Jay Rose,
[01:13:27.720 --> 01:13:29.480]   and I remember when Jay published that list
[01:13:29.480 --> 01:13:31.520]   of journalists to follow on Twitter,
[01:13:31.520 --> 01:13:32.720]   and I think Andy was one of them.
[01:13:32.720 --> 01:13:34.160]   - Yeah. - Yeah.
[01:13:34.160 --> 01:13:35.800]   - You know, I taught Regis had a tweet.
[01:13:35.800 --> 01:13:37.920]   (laughs)
[01:13:37.920 --> 01:13:41.120]   Not exactly momentous, but it was very interesting
[01:13:41.120 --> 01:13:43.920]   to watch somebody who's been 60 years in show business
[01:13:43.920 --> 01:13:46.080]   suddenly have an epiphany.
[01:13:46.080 --> 01:13:48.720]   This aired just as I was leaving,
[01:13:48.720 --> 01:13:51.000]   so I hadn't had a chance to talk about it until now,
[01:13:51.000 --> 01:13:54.440]   but we went up to his, I have a little clip of it,
[01:13:54.440 --> 01:13:56.040]   I can show you, we went up to his office,
[01:13:56.040 --> 01:13:58.520]   and I sat down next to him.
[01:13:58.520 --> 01:13:59.360]   - And the computer.
[01:13:59.360 --> 01:14:00.200]   - Somebody. (laughs)
[01:14:00.200 --> 01:14:01.360]   - You give them a message, and they tweet.
[01:14:01.360 --> 01:14:02.520]   - Have you ever sent a text message?
[01:14:02.520 --> 01:14:03.640]   - Never. - Okay.
[01:14:03.640 --> 01:14:04.560]   So it's kind of like that,
[01:14:04.560 --> 01:14:06.960]   except instead of going just to one person,
[01:14:06.960 --> 01:14:10.120]   when you tweet, it goes to everybody who's following you.
[01:14:10.120 --> 01:14:11.240]   You got a lot of followers.
[01:14:11.240 --> 01:14:12.760]   You've got hundreds of thousands of people
[01:14:12.760 --> 01:14:14.200]   who watch your Twitter account.
[01:14:14.200 --> 01:14:15.640]   - Does that matter? - So if you type something
[01:14:15.640 --> 01:14:17.800]   on Twitter, all of those people will see it.
[01:14:17.800 --> 01:14:19.640]   - But who's been talking to these people?
[01:14:19.640 --> 01:14:21.560]   - I think Kelly, Kelly, Kelly, Kelly,
[01:14:21.560 --> 01:14:22.560]   - Kelly tweets a lot.
[01:14:22.560 --> 01:14:23.400]   - I wanna be a part of this.
[01:14:23.400 --> 01:14:25.080]   - So you're on, this is the webpage, the Twitter page.
[01:14:25.080 --> 01:14:26.760]   - So I showed him, and you know what was interesting,
[01:14:26.760 --> 01:14:28.000]   this was the day that he announced
[01:14:28.000 --> 01:14:29.840]   that he was leaving the show.
[01:14:29.840 --> 01:14:33.040]   And so he tweeted, actually, his first tweet was quite good,
[01:14:33.040 --> 01:14:35.280]   it was made a joke, and he said,
[01:14:35.280 --> 01:14:37.160]   I just announced that I'm leaving the show,
[01:14:37.160 --> 01:14:39.720]   and David Letterman called and said, "Congratulations,
[01:14:39.720 --> 01:14:41.520]   "what the hell does that mean?"
[01:14:41.520 --> 01:14:43.440]   And, "What the hell does that mean?"
[01:14:43.440 --> 01:14:44.400]   "What the hell does that mean?"
[01:14:44.400 --> 01:14:45.600]   "Leo, what does that mean?"
[01:14:45.600 --> 01:14:48.520]   And, but there was this moving moment,
[01:14:48.520 --> 01:14:50.280]   I don't know, this is the first time I've seen the video,
[01:14:50.280 --> 01:14:51.880]   there was a moving moment where he said,
[01:14:51.880 --> 01:14:54.160]   I said, "Now, if you click mentions,
[01:14:54.160 --> 01:14:55.440]   "these are people talking back to you,
[01:14:55.440 --> 01:14:58.080]   "and he saw all these hundreds and hundreds of them."
[01:14:58.080 --> 01:14:59.320]   He says, "Is this happening right now?"
[01:14:59.320 --> 01:15:02.600]   I said, "Yeah, click it again, and there was more."
[01:15:02.600 --> 01:15:04.800]   He called his wife, he said, "Joy,
[01:15:04.800 --> 01:15:06.640]   "you gotta go to Twitter."
[01:15:06.640 --> 01:15:11.360]   They're talking, he'd never had this kind of direct
[01:15:11.360 --> 01:15:14.360]   connection to the audience, and it was actually,
[01:15:14.360 --> 01:15:16.280]   it was very interesting to watch this,
[01:15:16.280 --> 01:15:21.280]   very savvy guy, but he's been 60 years in broadcasting,
[01:15:21.280 --> 01:15:22.600]   getting this experience, by the way,
[01:15:22.600 --> 01:15:23.680]   that guy can't type for...
[01:15:23.680 --> 01:15:25.000]   - No, it's not worth it.
[01:15:25.000 --> 01:15:26.600]   - Like they sped it up, you can call these back up.
[01:15:26.600 --> 01:15:27.600]   - This is good enough a lot.
[01:15:27.600 --> 01:15:29.960]   I was, this is an hour's worth of typing,
[01:15:29.960 --> 01:15:31.240]   and then I said, "Watch this."
[01:15:31.240 --> 01:15:32.960]   I said, "Now, click the tweet."
[01:15:32.960 --> 01:15:35.400]   - A little joke, a little light, a little levity,
[01:15:35.400 --> 01:15:37.600]   'cause you're using the Regis and Kelly to count.
[01:15:37.600 --> 01:15:39.840]   Regis underscore and underscore Kelly.
[01:15:39.840 --> 01:15:40.680]   - Yeah.
[01:15:40.680 --> 01:15:41.520]   - Kelly also tweets in this account.
[01:15:41.520 --> 01:15:42.720]   - Well, that's why I said, "Our show."
[01:15:42.720 --> 01:15:45.760]   - Right, so I'll put a space and then a dash bar,
[01:15:45.760 --> 01:15:47.360]   so they know that this came from you.
[01:15:47.360 --> 01:15:48.200]   - No, okay.
[01:15:48.200 --> 01:15:50.520]   - Now, okay, now this is the chance you have
[01:15:50.520 --> 01:15:52.440]   before you press that button that says, "Tweet."
[01:15:52.440 --> 01:15:54.080]   Just review it, make sure that you watch the release.
[01:15:54.080 --> 01:15:55.960]   - Yeah, I announced my leaving our show today,
[01:15:55.960 --> 01:15:58.120]   David Littleman just called, he said, "Congratulations,
[01:15:58.120 --> 01:15:59.480]   "I don't know if that's good or bad."
[01:15:59.480 --> 01:16:00.800]   - See, I think that's a perfect tweet.
[01:16:00.800 --> 01:16:01.640]   - Yeah, I do too.
[01:16:01.640 --> 01:16:03.080]   - Now press the, click the tweet button.
[01:16:03.080 --> 01:16:03.920]   - Watch this.
[01:16:03.920 --> 01:16:04.760]   - Where is that tweet button?
[01:16:04.760 --> 01:16:07.240]   - It's on the screen there, so if you just move
[01:16:07.240 --> 01:16:08.640]   the mouse there and you press the mouse.
[01:16:08.640 --> 01:16:10.480]   - Watch, he picks up the mouse.
[01:16:10.480 --> 01:16:12.560]   He's gonna, he's trying to click the screen.
[01:16:12.560 --> 01:16:14.480]   (laughing)
[01:16:14.480 --> 01:16:16.600]   - This guy, I'm sure he's never using computer.
[01:16:16.600 --> 01:16:19.120]   Never the, that's the comedy, but the thing that I thought
[01:16:19.120 --> 01:16:21.800]   was really moving is just this impact,
[01:16:21.800 --> 01:16:23.560]   this sudden light goes on in his head,
[01:16:23.560 --> 01:16:27.720]   oh my God, this is my, I'm talking to my people.
[01:16:27.720 --> 01:16:28.560]   - That's so great.
[01:16:28.560 --> 01:16:30.880]   - It was really a neat moment,
[01:16:30.880 --> 01:16:33.200]   but that is not my tool of the week,
[01:16:33.200 --> 01:16:35.400]   and I'll do this very quickly 'cause we wanna make room
[01:16:35.400 --> 01:16:37.680]   for TNT, which is coming up next.
[01:16:37.680 --> 01:16:39.920]   But as you know, there was a terrible earthquake
[01:16:39.920 --> 01:16:42.920]   in New Zealand, many of our listeners are down there,
[01:16:42.920 --> 01:16:44.960]   and we wish you all the best in Christchurch.
[01:16:44.960 --> 01:16:49.960]   And here is, as again, Google's done this time and time again.
[01:16:49.960 --> 01:16:51.920]   They didn't hate it, and they've done it again.
[01:16:51.920 --> 01:16:54.760]   The person finder, if you're looking for someone,
[01:16:54.760 --> 01:16:56.240]   they're tracking about 9,400 records,
[01:16:56.240 --> 01:16:58.680]   you can enter the person's name.
[01:16:58.680 --> 01:17:01.760]   If you know where someone is, this is, you know,
[01:17:01.760 --> 01:17:05.480]   this is an internet, this is a 21st century bulletin board.
[01:17:05.480 --> 01:17:08.520]   But it's amazingly effective, and it's very powerful.
[01:17:08.520 --> 01:17:09.800]   You can embed the tool on your site,
[01:17:09.800 --> 01:17:14.040]   and I think Google deserves credit for doing this.
[01:17:14.040 --> 01:17:19.040]   This is AppSpot, Christchurch-2011.person-finder.appspot.com.
[01:17:19.040 --> 01:17:24.800]   And I think it was done by Google, right?
[01:17:24.800 --> 01:17:25.920]   I believe it was done by Google.
[01:17:25.920 --> 01:17:26.760]   - I think it was.
[01:17:26.760 --> 01:17:27.600]   - Yeah.
[01:17:27.600 --> 01:17:29.320]   - At this point, they probably just have,
[01:17:29.320 --> 01:17:30.840]   this app, you know, just roll out,
[01:17:30.840 --> 01:17:32.000]   everything's disaster, right?
[01:17:32.000 --> 01:17:33.880]   - Like, like, yeah, yeah.
[01:17:33.880 --> 01:17:35.320]   - That's, I don't know if I talked about this
[01:17:35.320 --> 01:17:37.240]   in the show before, but the head of privacy,
[01:17:37.240 --> 01:17:38.320]   'cause we're in protection in Germany,
[01:17:38.320 --> 01:17:41.440]   said that using geographic location
[01:17:41.440 --> 01:17:44.720]   and face recognition is taboo, it's ever, it's forever bad.
[01:17:44.720 --> 01:17:46.920]   But imagine how you could use it in an earthquake to say,
[01:17:46.920 --> 01:17:49.840]   oh, so-and-so was spotted, we know who's there.
[01:17:49.840 --> 01:17:52.440]   You know, it's incredible what technology could do
[01:17:52.440 --> 01:17:54.080]   in those cases to put people back together.
[01:17:54.080 --> 01:17:56.640]   - Yeah, it really, really amazing.
[01:17:56.640 --> 01:17:59.320]   Jeff Jarvis, the author of What with Google Do?
[01:17:59.320 --> 01:18:01.240]   Leo, what would Google do?
[01:18:01.240 --> 01:18:04.480]   It is a, he's got a nice hat from Canada.
[01:18:04.480 --> 01:18:05.800]   It's available now in Bookstores.
[01:18:05.800 --> 01:18:07.080]   - Can we wrap it?
[01:18:07.080 --> 01:18:08.880]   - Yeah, you do look a little like we're in Fuddish.
[01:18:08.880 --> 01:18:10.840]   - Dude, elbow five, that's it.
[01:18:10.840 --> 01:18:13.100]   (laughing)
[01:18:13.100 --> 01:18:17.560]   - He's also at Buzzmachine.com, great to talk to you.
[01:18:17.560 --> 01:18:18.880]   Once again, I missed you guys.
[01:18:18.880 --> 01:18:19.720]   Gina Trapani.
[01:18:19.720 --> 01:18:20.560]   - Always missed you.
[01:18:20.560 --> 01:18:23.400]   - Smartawear.org, always a pleasure.
[01:18:23.400 --> 01:18:24.600]   We'll see you next week.
[01:18:24.600 --> 01:18:25.760]   We do the show every Wednesday.
[01:18:25.760 --> 01:18:29.080]   Now, we're gonna be following the Big Apple iPad
[01:18:29.080 --> 01:18:30.640]   announcement next week, so we'll have some stuff
[01:18:30.640 --> 01:18:32.960]   to talk about, I'm sure.
[01:18:32.960 --> 01:18:35.480]   We are doing live coverage of that,
[01:18:35.480 --> 01:18:38.920]   starting at 10 a.m. Pacific, 1 p.m. Eastern time
[01:18:38.920 --> 01:18:41.240]   at live.trit.tv/March 2nd.
[01:18:41.240 --> 01:18:44.400]   And then right after that this week in Google,
[01:18:44.400 --> 01:18:45.280]   you can watch live.
[01:18:45.280 --> 01:18:47.280]   Thanks guys, and we'll see you next time.
[01:18:47.280 --> 01:18:49.120]   (upbeat music)
[01:18:49.120 --> 01:18:49.960]   Bama.
[01:18:49.960 --> 01:18:52.540]   (upbeat music)
[01:18:52.540 --> 01:18:55.120]   (upbeat music)
[01:18:55.120 --> 01:18:57.700]   (upbeat music)
[01:18:57.700 --> 01:19:00.280]   (bells chiming)

