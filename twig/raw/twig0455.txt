;FFMETADATA1
title=CanuckCanoeCast
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=455
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.120]   It's time for Twig this week in Google. I'm Jason Howell. I'm here along with Jeff Jarvis,
[00:00:06.120 --> 00:00:12.080]   Stacey Higginbotham and Matthew Ingram. Actually Jeff is at the Facebook F8 conferences in his
[00:00:12.080 --> 00:00:16.480]   Hotel Romano ways. We're going to talk all about the announcements from F8. Also a little
[00:00:16.480 --> 00:00:23.160]   bit of a preview for Google I/O and we do a little deep dive on top level domains with
[00:00:23.160 --> 00:00:27.640]   Stacey's husband. It's really cool impromptu interview that you don't want to miss. This
[00:00:27.640 --> 00:00:29.640]   week in Google is next.
[00:00:29.640 --> 00:00:34.640]   Netcast you love.
[00:00:34.640 --> 00:00:36.640]   From people you trust.
[00:00:36.640 --> 00:00:41.640]   This is Twig.
[00:00:41.640 --> 00:00:45.640]   Bandwidth for this week in Google is provided by cash fly.
[00:00:45.640 --> 00:00:49.640]   C A C A C H E F L Y .com.
[00:00:53.640 --> 00:01:01.640]   This is Twig this week in Google. Episode 455 recorded on Wednesday, May 2nd, 2018.
[00:01:01.640 --> 00:01:03.640]   K'nuk K'nuk cast.
[00:01:03.640 --> 00:01:09.640]   This episode of This Week in Google is brought to you by Trace Pontes. Freshly roasted gourmet coffee
[00:01:09.640 --> 00:01:16.840]   shipped directly to you. Visit TracePontes.com/Twig and use code TWIG to save 20% off every
[00:01:16.840 --> 00:01:19.840]   bag of coffee in your subscription.
[00:01:20.840 --> 00:01:26.840]   It's time for Twig this week in Google. Leo Laporte of course still doing his gallivanting
[00:01:26.840 --> 00:01:31.840]   thing around the world, literally on the other side of the world having fun. But he's got
[00:01:31.840 --> 00:01:37.840]   to have that kind of that paying at this point because his trip is nearing the end and he's
[00:01:37.840 --> 00:01:40.840]   going to have to come back and jump right into work again. So Leo I'm sorry about that.
[00:01:40.840 --> 00:01:44.840]   But I hope you're having a good time. I'm Jason Howell. I'm happy to be here. My phone is
[00:01:44.840 --> 00:01:49.840]   yelling at me apparently so I'll have to silence that. And I'm just thrilled to be here once
[00:01:49.840 --> 00:01:54.840]   here last week, had a great time. And I've returned for more great time starting with
[00:01:54.840 --> 00:02:01.840]   Jeff Jarvis, Buzzmachine.com, professor at the CUNY School of Journalism and live from
[00:02:01.840 --> 00:02:06.840]   a hotel near F8, Facebook's F8. And come back to us Jeff.
[00:02:06.840 --> 00:02:14.840]   Wearing the Oculus Go obviously. So you already have the Oculus Go. That didn't take long.
[00:02:14.840 --> 00:02:20.840]   Was it under the chairs? I was at the partner breakfast yesterday so they gave a toss early.
[00:02:20.840 --> 00:02:26.840]   Oh, lucky you. And you've lived at the last 24 hours in Oculus Go.
[00:02:26.840 --> 00:02:36.840]   That's fine. But I finally set it up. So it's pretty cool. It's nice. It's no fun to put in.
[00:02:36.840 --> 00:02:38.840]   That's all one piece.
[00:02:38.840 --> 00:02:43.840]   Can you see yourself in that? Or if I'm looking at you in that, do I see my own face? Because
[00:02:43.840 --> 00:02:47.840]   it's super creepy but it looks super shiny. Like on the outside it's super shiny. It's
[00:02:47.840 --> 00:02:52.840]   like a mirror. Oh, it's not that shiny. Okay. It's a mirror to everyone else.
[00:02:52.840 --> 00:02:58.840]   I was like, they missed a really big opportunity. I just took off the plastic.
[00:02:58.840 --> 00:03:05.840]   Oh, that'll do it. You're one of those that keeps the plastic on there. You don't want
[00:03:05.840 --> 00:03:09.840]   the technology to get all scuffed up. Could you go snorkeling with it?
[00:03:12.840 --> 00:03:16.840]   You know how I wasted. Oh, I'm sorry. Finish your introduction.
[00:03:16.840 --> 00:03:20.840]   Okay. Just real quick. Stacey Higginbotham. You were out last week. I'm super happy that
[00:03:20.840 --> 00:03:25.840]   you're back this week. Creator of the IoT podcast at IoTpodcast.com and Internet of Things
[00:03:25.840 --> 00:03:28.840]   newsletter at Stacey on IoT.com. How you doing Stacey?
[00:03:28.840 --> 00:03:31.840]   I am doing super well. Back from Sweden. Yay.
[00:03:31.840 --> 00:03:33.840]   Excellent. How long were you in Sweden?
[00:03:33.840 --> 00:03:36.840]   A week. Nice.
[00:03:36.840 --> 00:03:39.840]   Did I know that? Where were you in Sweden? Were you in Stockholm?
[00:03:39.840 --> 00:03:44.840]   I flew into Copenhagen, stayed there a night, and then went to Malmo. So southern Sweden.
[00:03:44.840 --> 00:03:46.840]   Me too. Me too.
[00:03:46.840 --> 00:03:47.840]   Me too.
[00:03:47.840 --> 00:03:51.840]   Awesome. Well, it's great to have you back. Welcome back to the States.
[00:03:51.840 --> 00:03:55.840]   And also joining us once again, Matthew Ingram. He was on last week making a return
[00:03:55.840 --> 00:04:01.840]   appearance, Chief Digital Writer, CJR.org at Matthew I on Twitter. How's it going, Matthew?
[00:04:01.840 --> 00:04:03.840]   Good. Yeah. Great. Happy to be here.
[00:04:03.840 --> 00:04:07.840]   Excellent. Happy to have you here. You and your Star Trek shirt,
[00:04:07.840 --> 00:04:10.840]   which thankfully appears right above the lower third. So everybody.
[00:04:10.840 --> 00:04:11.840]   Represent.
[00:04:11.840 --> 00:04:14.840]   Yeah, I understand. You got to represent.
[00:04:14.840 --> 00:04:18.840]   So obviously we probably have to start with Facebook, right?
[00:04:18.840 --> 00:04:24.840]   Because Jeff, you're there. Like you were surrounded by the Zuckerberg and all of his glory on
[00:04:24.840 --> 00:04:25.840]   school.
[00:04:25.840 --> 00:04:32.840]   Yeah. He started off with a confession and then asked for penance and forgiveness.
[00:04:32.840 --> 00:04:40.840]   So from a general sense, the tenor of the show, I mean, this is a very important year for Facebook.
[00:04:40.840 --> 00:04:47.840]   And, you know, I imagine they're placing a lot of emphasis on their place in the world and the
[00:04:47.840 --> 00:04:52.840]   responsibility and security and all that kind of stuff. Was that apparent from the very beginning of the
[00:04:52.840 --> 00:04:53.840]   time?
[00:04:53.840 --> 00:04:57.840]   Oh, yeah. That let off every single talk. I mean, the hair shirt was there in every case.
[00:04:57.840 --> 00:05:03.840]   And Cher Sandberg at the Partners breakfast beforehand talked immediately about the responsibility that they
[00:05:03.840 --> 00:05:04.840]   have.
[00:05:04.840 --> 00:05:08.840]   Zuck, as you probably saw it, and he notes started off with that.
[00:05:08.840 --> 00:05:14.840]   But the, the, I mean, a couple of things about this. One, this is before thousands of builders, of
[00:05:14.840 --> 00:05:17.840]   developers. And so the reception here is going to be different.
[00:05:17.840 --> 00:05:21.840]   Now their app approvals have been shut off and now they're back on again. So they're happy about that.
[00:05:21.840 --> 00:05:26.840]   They can get back to work. And, but, but I, yeah, there's a, there's a sobriety to it.
[00:05:26.840 --> 00:05:32.840]   This year, I would say definitely also interestingly, it was a much larger this year than last year,
[00:05:32.840 --> 00:05:37.840]   much larger. They had a different, different hall, the keynote, different hall down here.
[00:05:37.840 --> 00:05:41.840]   Nothing, you know, terribly new. So the dating service, I think, was new.
[00:05:41.840 --> 00:05:47.840]   The security stuff we knew. Some neat little bits here and there, I would say.
[00:05:47.840 --> 00:05:54.840]   I just, I went to the technical keynote this morning on what they're doing with AR and, and AI and, you know,
[00:05:54.840 --> 00:05:56.840]   a lot of neat stuff.
[00:05:56.840 --> 00:06:00.840]   I feel like the, the clear history thing is actually a pretty big deal, right?
[00:06:00.840 --> 00:06:04.840]   Yeah, it was a bit, uh, announced that they're going to allow you, I don't know if you have controls yet,
[00:06:04.840 --> 00:06:06.840]   but they're going to allow.
[00:06:06.840 --> 00:06:08.840]   I don't think it's up yet, but I think it's, I think it's important to note.
[00:06:08.840 --> 00:06:15.840]   Interestingly, it mimics what those who argue that Facebook tries to be the web, that it needs to give you
[00:06:15.840 --> 00:06:20.840]   similar functionality to the web and the browsers. And so you can get your history of browsers.
[00:06:20.840 --> 00:06:23.840]   You should be able to do the same on, on Facebook.
[00:06:23.840 --> 00:06:31.840]   And, and I think we should point out that Facebook didn't make this kind of change just because Mark came to the conclusion.
[00:06:31.840 --> 00:06:38.840]   It was a good idea. These are things that Facebook is doing to try and get ahead of the general data protection regulations in the EU.
[00:06:38.840 --> 00:06:39.840]   So.
[00:06:39.840 --> 00:06:43.840]   And, and I think the sort of general, by the way, I should do my copy out here.
[00:06:43.840 --> 00:06:47.840]   My, my disclosure, I receive funds from Facebook to structure this integrity initiative.
[00:06:47.840 --> 00:06:52.840]   I'm independent of Facebook and I receive nobody personally from any of the platforms and of disclosure. Thank you.
[00:06:52.840 --> 00:06:57.840]   Were they talking yet about Cambridge Analytica shutting down there at all?
[00:06:57.840 --> 00:07:02.840]   No, because that just came out. I think I saw it after the morning to go today.
[00:07:02.840 --> 00:07:04.840]   Just an hour or two ago.
[00:07:04.840 --> 00:07:06.840]   Yeah, that was just the morning Wall Street Journal.
[00:07:06.840 --> 00:07:07.840]   I see news reporting that.
[00:07:07.840 --> 00:07:11.840]   So it sounds to me, I just did a little bit of research, but it sounds to me like.
[00:07:11.840 --> 00:07:16.840]   So Cambridge was a subsidiary of this large SCL, I think was called.
[00:07:16.840 --> 00:07:23.840]   They're both shutting down, but it sounds like the principles are effectively starting another company.
[00:07:23.840 --> 00:07:24.840]   So.
[00:07:24.840 --> 00:07:25.840]   Of course they are.
[00:07:25.840 --> 00:07:26.840]   Yeah.
[00:07:26.840 --> 00:07:27.840]   Yeah.
[00:07:27.840 --> 00:07:28.840]   Rebranding.
[00:07:28.840 --> 00:07:30.840]   The name is poison at this point.
[00:07:30.840 --> 00:07:31.840]   Yeah.
[00:07:31.840 --> 00:07:32.840]   Right.
[00:07:32.840 --> 00:07:33.840]   Hmm.
[00:07:33.840 --> 00:07:34.840]   It's like Philip Morris to.
[00:07:34.840 --> 00:07:35.840]   Altraia.
[00:07:35.840 --> 00:07:36.840]   Is it Altraia?
[00:07:36.840 --> 00:07:39.840]   The Oxford and Littaker is like that now.
[00:07:39.840 --> 00:07:40.840]   Yeah.
[00:07:40.840 --> 00:07:41.840]   Yale Analytica.
[00:07:41.840 --> 00:07:42.840]   Cambridge Analytica.
[00:07:42.840 --> 00:07:45.840]   I'm sure Cambridge University will be happy.
[00:07:45.840 --> 00:07:46.840]   Yeah.
[00:07:46.840 --> 00:07:47.840]   Yeah.
[00:07:47.840 --> 00:07:48.840]   Yeah.
[00:07:48.840 --> 00:07:54.840]   Are you talking to developers, Jeff, about their plans for monetization and what the kind
[00:07:54.840 --> 00:08:00.840]   of looming privacy crisis or the constant privacy crisis right now means for how they're building their stuff?
[00:08:00.840 --> 00:08:02.840]   It's a really great question, Stacey.
[00:08:02.840 --> 00:08:08.840]   And not so much developers is that I am media people and I talk to a major European publisher
[00:08:08.840 --> 00:08:14.840]   who has warned his staff that they could lose 30% of their business for GDPR comes in.
[00:08:14.840 --> 00:08:15.840]   Wow.
[00:08:15.840 --> 00:08:17.840]   And so you've got journalists who are saying, oh, yeah, GDPR, wonderful.
[00:08:17.840 --> 00:08:18.840]   And he said, watch it.
[00:08:18.840 --> 00:08:22.840]   You know, one of the people next to you could lose their job because of this.
[00:08:22.840 --> 00:08:27.840]   So there's that because because program addicts going to go down advertising in general is
[00:08:27.840 --> 00:08:28.840]   going to go down.
[00:08:28.840 --> 00:08:30.840]   So there's nothing to do with Facebook per se is general.
[00:08:30.840 --> 00:08:36.840]   The second piece of this though, Stacey is this right now, the laser of the publishers is
[00:08:36.840 --> 00:08:44.240]   going from Facebook back to Google because Google is making the publishers get consent
[00:08:44.240 --> 00:08:46.240]   from users on behalf of Google.
[00:08:46.240 --> 00:08:51.240]   And if they don't, Google will pull its ad service within three months and the publishers are
[00:08:51.240 --> 00:08:54.240]   going for a jerk off of them, which I think could reason.
[00:08:54.240 --> 00:08:56.240]   So I'm sure this will get negotiated.
[00:08:56.240 --> 00:09:00.240]   But yeah, GDPR is, it's the exact right question.
[00:09:00.240 --> 00:09:01.240]   It's panic time.
[00:09:01.240 --> 00:09:04.240]   A lot of people still do not know what it means.
[00:09:04.240 --> 00:09:08.240]   One of the publishers also told me that the EU has to do things in 476 languages.
[00:09:08.240 --> 00:09:11.240]   You know, it's Canada times 10.
[00:09:11.240 --> 00:09:19.240]   That there were new translations of the regulations and word changes here or there that made tremendous
[00:09:19.240 --> 00:09:21.240]   difference in the execution.
[00:09:21.240 --> 00:09:22.240]   And so they're tearing their hair out.
[00:09:22.240 --> 00:09:24.240]   Everybody's tearing their hair out.
[00:09:24.240 --> 00:09:28.240]   The presumption is it remains that Facebook and Google have the resources.
[00:09:28.240 --> 00:09:29.240]   They'll be fine.
[00:09:29.240 --> 00:09:30.240]   They'll probably be stronger.
[00:09:30.240 --> 00:09:36.240]   But publisher large publishers will go through expense at hassle and small guys are going
[00:09:36.240 --> 00:09:37.240]   to be screw it.
[00:09:37.240 --> 00:09:39.240]   Yeah, that's so important.
[00:09:39.240 --> 00:09:40.240]   Sorry.
[00:09:40.240 --> 00:09:41.240]   Go ahead.
[00:09:41.240 --> 00:09:45.240]   Oh, no, I was going to tie this too because we're skipping ahead a little bit to Google
[00:09:45.240 --> 00:09:48.640]   because someone put this on the story rundown and I thought this was actually really interesting
[00:09:48.640 --> 00:09:54.240]   is this idea of four publisher groups telling Google their GDPR proposals all short.
[00:09:54.240 --> 00:09:58.240]   Yeah, that's what it is.
[00:09:58.240 --> 00:10:04.240]   It's because who gets the permission for what?
[00:10:04.240 --> 00:10:06.240]   And so it's wild to come.
[00:10:06.240 --> 00:10:11.800]   The other thing I've heard from some publishers is that they could be losing 80, 90% of their
[00:10:11.800 --> 00:10:17.760]   email traffic email subscriptions because they're going to go back and try to get permissions
[00:10:17.760 --> 00:10:21.760]   that they don't have now and they're going to lose tremendous amounts of that plus advertising
[00:10:21.760 --> 00:10:27.280]   targeting or advertising value plus other kinds of targeting.
[00:10:27.280 --> 00:10:30.000]   And then a lot of these publishers just don't have the mechanism to do this stuff and store
[00:10:30.000 --> 00:10:31.000]   it.
[00:10:31.000 --> 00:10:32.240]   They don't know what they have.
[00:10:32.240 --> 00:10:35.400]   So it's going to be a cluster F.
[00:10:35.400 --> 00:10:40.520]   As I understand it, the problem with the Google proposal is that Google wants to effectively
[00:10:40.520 --> 00:10:47.520]   get publishers to give it the right to be an intermediary for the data of their users.
[00:10:47.520 --> 00:10:55.440]   So Google's saying, "Assign us the right to handle that data to be the party of record
[00:10:55.440 --> 00:10:57.440]   for that data," which I don't think about.
[00:10:57.440 --> 00:10:58.440]   Which best makes sense?
[00:10:58.440 --> 00:11:02.980]   Well, it's going to make sense because Google is, apart from AppNexus, Google is the ad
[00:11:02.980 --> 00:11:05.560]   server for most every publisher out there.
[00:11:05.560 --> 00:11:08.260]   And it has the infrastructure and the legal team.
[00:11:08.260 --> 00:11:09.260]   Yes, exactly.
[00:11:09.260 --> 00:11:11.140]   So it does make sense.
[00:11:11.140 --> 00:11:12.540]   I get that.
[00:11:12.540 --> 00:11:16.380]   But there's all kinds of nuances here and difficulties.
[00:11:16.380 --> 00:11:19.940]   And this is not thought through.
[00:11:19.940 --> 00:11:24.340]   And basically the Google changes came, I think, less than a week ago with a May 25 deadline.
[00:11:24.340 --> 00:11:29.860]   Well, and that's one of the big complaints that the publishers group is placing upon
[00:11:29.860 --> 00:11:36.220]   Google is how dare you make this announcement so close to the switchover, which is happening
[00:11:36.220 --> 00:11:38.740]   in just a little bit more than a month at this point.
[00:11:38.740 --> 00:11:40.740]   It does feel like they're putting them under the gap.
[00:11:40.740 --> 00:11:41.740]   Less than a month.
[00:11:41.740 --> 00:11:42.740]   Or less than a month.
[00:11:42.740 --> 00:11:48.060]   Unless you have to agree within two weeks or something bad will happen.
[00:11:48.060 --> 00:11:55.860]   And I think it's important to note there's a significant viewpoint that GDPR, I think
[00:11:55.860 --> 00:12:03.140]   Jeff kind of got out this GDPR, could actually help make Google and Facebook more powerful
[00:12:03.140 --> 00:12:09.380]   or sort of entrench them in a way by kind of building walls around their data, companies
[00:12:09.380 --> 00:12:13.820]   that could theoretically compete or build up new services won't be able to do a lot of
[00:12:13.820 --> 00:12:18.540]   the things that Google and Facebook were able to do because GDPR won't let them do it.
[00:12:18.540 --> 00:12:22.940]   The Google and Facebook already have businesses that are up and running, they have all that
[00:12:22.940 --> 00:12:23.940]   data.
[00:12:23.940 --> 00:12:29.220]   In fact, they'll protect them and in many cases make those walls higher.
[00:12:29.220 --> 00:12:30.780]   >> The best way to.
[00:12:30.780 --> 00:12:36.180]   >> The paradox here is always that when you try to, so right to be forgotten, Google has
[00:12:36.180 --> 00:12:37.180]   too much power.
[00:12:37.180 --> 00:12:40.300]   We must take away their power, we must erase things that people don't want on the internet.
[00:12:40.300 --> 00:12:41.300]   Well, who's going to do that?
[00:12:41.300 --> 00:12:45.700]   Well, we don't know how to, so we'll make Google do it and Google ends up with more power.
[00:12:45.700 --> 00:12:49.540]   And every time they try this new regulation, they do that the publisher I talked to said
[00:12:49.540 --> 00:12:53.260]   these are frustrated because the regulators don't understand the medium business.
[00:12:53.260 --> 00:12:56.060]   And I said it's because the publisher spent so long trying to fight Google, they didn't
[00:12:56.060 --> 00:12:57.500]   explain their own business.
[00:12:57.500 --> 00:12:58.500]   >> Right.
[00:12:58.500 --> 00:13:02.340]   And Google, I mean, this is how laws work.
[00:13:02.340 --> 00:13:08.820]   And I mean, Google and Facebook had people at the table and publishers did, but their
[00:13:08.820 --> 00:13:10.780]   message was not as unified.
[00:13:10.780 --> 00:13:13.660]   And this is just the way the world works.
[00:13:13.660 --> 00:13:20.340]   So your next innovation is going to have to come after these rules have settled.
[00:13:20.340 --> 00:13:23.860]   And then we're going to start seeing people figure out how to work around them.
[00:13:23.860 --> 00:13:29.300]   And there is definitely opportunities here for innovation around data collection, permissions,
[00:13:29.300 --> 00:13:32.700]   and that sort of thing.
[00:13:32.700 --> 00:13:38.540]   We have to wait just a little bit to see one, how these are actually going to be enforced.
[00:13:38.540 --> 00:13:43.780]   Because that's still very few countries are talking about how they plan to enforce these
[00:13:43.780 --> 00:13:44.860]   rules.
[00:13:44.860 --> 00:13:47.340]   So we've got to see that first.
[00:13:47.340 --> 00:13:48.940]   So don't despair just yet.
[00:13:48.940 --> 00:13:53.220]   >> This is a common cycle in the world.
[00:13:53.220 --> 00:13:58.860]   >> Who's going to die in the meantime?
[00:13:58.860 --> 00:13:59.860]   I just bear for those folks.
[00:13:59.860 --> 00:14:05.020]   I talked to somebody who said, really should have kind of tears of regulation, where the
[00:14:05.020 --> 00:14:07.300]   big guys are expected to do the best.
[00:14:07.300 --> 00:14:10.780]   But at the beginning, you give some slack to the little guys to let them adjust and figure
[00:14:10.780 --> 00:14:15.180]   it out or come up with new vendors or other things to treat them all the same.
[00:14:15.180 --> 00:14:18.260]   >> I don't think we're going to see the EU come after the tiny guys.
[00:14:18.260 --> 00:14:19.260]   I really don't.
[00:14:19.260 --> 00:14:24.260]   I mean, they're not going to be able to come after everyone all at once on May 25th.
[00:14:24.260 --> 00:14:25.300]   That's going to be impossible.
[00:14:25.300 --> 00:14:28.980]   They're going to pick and choose who they focus on.
[00:14:28.980 --> 00:14:31.540]   And I imagine- >> But you're a sure owner, you can't be
[00:14:31.540 --> 00:14:32.740]   assured of that though, right?
[00:14:32.740 --> 00:14:37.380]   Stacey, the problem is you want surety and that's not surety.
[00:14:37.380 --> 00:14:42.820]   >> I don't think any business today who can't adapt and expect surety, they're crazy.
[00:14:42.820 --> 00:14:45.740]   I mean, it makes you sad.
[00:14:45.740 --> 00:14:50.580]   I would love that, but I don't think that's a reasonable thing to expect today, especially
[00:14:50.580 --> 00:14:53.380]   with El-Pest.
[00:14:53.380 --> 00:15:01.380]   >> We know that many organizations are nothing if not adaptable and quick to evolve.
[00:15:01.380 --> 00:15:04.900]   >> It's a special thing.
[00:15:04.900 --> 00:15:08.580]   >> And by the way, as far as Cambridge Analytica is concerned, the new name, as far as I can
[00:15:08.580 --> 00:15:11.260]   tell, is AmerData or e-MairData.
[00:15:11.260 --> 00:15:15.260]   >> It seems to be what- >> Like e-Mair of data?
[00:15:15.260 --> 00:15:16.820]   >> Like E-M-E-R data.
[00:15:16.820 --> 00:15:17.820]   One word.
[00:15:17.820 --> 00:15:18.820]   >> One word data.
[00:15:18.820 --> 00:15:21.660]   >> So that'll be the new word that we start hearing every day.
[00:15:21.660 --> 00:15:23.100]   >> There now the year of data.
[00:15:23.100 --> 00:15:25.620]   Are there-are you serious?
[00:15:25.620 --> 00:15:27.620]   >> It's not Emir, like M-E-I-R.
[00:15:27.620 --> 00:15:28.620]   They're just M-E-E-R.
[00:15:28.620 --> 00:15:29.620]   >> E-M-E-R.
[00:15:29.620 --> 00:15:30.620]   >> Like emerging.
[00:15:30.620 --> 00:15:31.620]   >> Right.
[00:15:31.620 --> 00:15:32.620]   >> Emir data.
[00:15:32.620 --> 00:15:34.780]   Okay, that makes more sense, yeah.
[00:15:34.780 --> 00:15:36.780]   >> Oh, which is a Gaelic name.
[00:15:36.780 --> 00:15:37.780]   Ta-da.
[00:15:37.780 --> 00:15:38.940]   >> Is it?
[00:15:38.940 --> 00:15:40.620]   >> So say it to Google.
[00:15:40.620 --> 00:15:41.620]   >> Google is all.
[00:15:41.620 --> 00:15:45.340]   >> Anyway, the Mercers are going to put their billions somewhere.
[00:15:45.340 --> 00:15:47.260]   So it doesn't matter what it's called.
[00:15:47.260 --> 00:15:49.860]   >> Right, right, right.
[00:15:49.860 --> 00:15:50.860]   Let's see here.
[00:15:50.860 --> 00:15:53.660]   So all right, secure privacy.
[00:15:53.660 --> 00:15:58.700]   Obviously, a big deal, especially with just like the crazy timing of the Cambridge Analytica
[00:15:58.700 --> 00:16:02.060]   announcement anyways or revelation today.
[00:16:02.060 --> 00:16:03.580]   But what else about Facebook?
[00:16:03.580 --> 00:16:04.580]   Dating.
[00:16:04.580 --> 00:16:05.580]   You mentioned this.
[00:16:05.580 --> 00:16:06.580]   >> Dating.
[00:16:06.580 --> 00:16:07.580]   That's a big deal.
[00:16:07.580 --> 00:16:08.580]   >> And that's fun to talk about.
[00:16:08.580 --> 00:16:11.620]   Match is pretty upset or maybe they're not.
[00:16:11.620 --> 00:16:12.620]   >> They're not the first set.
[00:16:12.620 --> 00:16:15.820]   >> Publicly they're not upset, but their stock is not doing very well.
[00:16:15.820 --> 00:16:16.820]   >> Investors are upset.
[00:16:16.820 --> 00:16:17.820]   >> Yeah.
[00:16:17.820 --> 00:16:21.740]   >> At the moment of the announcement of somebody next to me in the hole showed me the screen
[00:16:21.740 --> 00:16:24.540]   that was down 17% in a flash.
[00:16:24.540 --> 00:16:25.540]   >> Wow.
[00:16:25.540 --> 00:16:29.020]   >> What's interesting to me about this, it's kind of what I really presumed Facebook was
[00:16:29.020 --> 00:16:31.940]   from the beginning and they never did it.
[00:16:31.940 --> 00:16:38.340]   And that's what I think it was Chris Cox who said, "I really thought that's what you
[00:16:38.340 --> 00:16:41.780]   were, but we kind of never did it and they're doing it now."
[00:16:41.780 --> 00:16:49.580]   The interesting thing to me is that Facebook has been strictly focusing on interesting
[00:16:49.580 --> 00:16:52.900]   you to people you, connecting you to people you know.
[00:16:52.900 --> 00:16:55.180]   And this is an effort to connect to people you don't know.
[00:16:55.180 --> 00:16:58.860]   And at the dating level, they also say that they want meaningful relationships.
[00:16:58.860 --> 00:17:02.420]   They said, "What is more meaningful than getting married to somebody following up with somebody
[00:17:02.420 --> 00:17:03.420]   getting married?"
[00:17:03.420 --> 00:17:08.940]   And they said, "This is not for hooking up, this is for relationships."
[00:17:08.940 --> 00:17:12.020]   But that idea of connecting to people you don't know, I've said on the show many, many
[00:17:12.020 --> 00:17:15.620]   times that what I hope for Facebook is it starts to make strangers less strange.
[00:17:15.620 --> 00:17:19.660]   If this is the start of a new expertise in an area that's fairly safe and well-taught
[00:17:19.660 --> 00:17:24.420]   in an exhibition, now of course on the internet everybody says, "Oh my God, privacy Facebook,
[00:17:24.420 --> 00:17:26.100]   the world knows how to do dating."
[00:17:26.100 --> 00:17:30.220]   I think in lots of ways without the newspapers you should do it for years where I don't think
[00:17:30.220 --> 00:17:31.580]   privacy is trot upon.
[00:17:31.580 --> 00:17:35.620]   They're thinking this through where your friends will not see your profile, only people you
[00:17:35.620 --> 00:17:38.460]   allow to see your profile will see your profile.
[00:17:38.460 --> 00:17:40.100]   The transaction is obvious.
[00:17:40.100 --> 00:17:44.940]   I think this function is obvious and plus they can tie it into things like groups and
[00:17:44.940 --> 00:17:47.020]   interests and it becomes a lot richer.
[00:17:47.020 --> 00:17:50.300]   And that presumes that interest is the right way to find somebody.
[00:17:50.300 --> 00:17:54.300]   You know, it could be that, you know, because right now, my day, how did you do it?
[00:17:54.300 --> 00:17:56.580]   We happened to like the same bar.
[00:17:56.580 --> 00:18:01.020]   So what are the commonalities that will bring people together for meaningful relationships
[00:18:01.020 --> 00:18:04.300]   and are they on Facebook really interesting to me?
[00:18:04.300 --> 00:18:13.900]   I wonder if this increases the filter bubble in a sense like dating is one area where you,
[00:18:13.900 --> 00:18:16.340]   and it's been a long time since I've dated.
[00:18:16.340 --> 00:18:18.100]   So let's say that.
[00:18:18.100 --> 00:18:20.460]   We can't because of us can play with this.
[00:18:20.460 --> 00:18:24.540]   I know where I'm like, I could, but I think my husband would be upset.
[00:18:24.540 --> 00:18:30.820]   So it's an idea where you actually, you meet someone without knowing all that much about
[00:18:30.820 --> 00:18:36.260]   them and then you go in and you encounter these bumps in the road where you're like,
[00:18:36.260 --> 00:18:38.220]   oh my God, this person voted for Trump.
[00:18:38.220 --> 00:18:41.540]   Could I really date someone who voted for Trump?
[00:18:41.540 --> 00:18:47.220]   But that presumably wouldn't happen on Facebook, but it's kind of a fun, I mean, that's kind
[00:18:47.220 --> 00:18:50.020]   of the interesting part about dating or.
[00:18:50.020 --> 00:18:51.020]   Right.
[00:18:51.020 --> 00:18:54.020]   And it's whether you find other interests that tie you together.
[00:18:54.020 --> 00:18:58.420]   I think that's the secret to civility is going to be when we get off the Trump v. Clinton
[00:18:58.420 --> 00:18:59.420]   world.
[00:18:59.420 --> 00:19:03.860]   And we start to say, oh, we both like surfing, you know, and we like literature, we like
[00:19:03.860 --> 00:19:07.620]   other things and find other commonalities.
[00:19:07.620 --> 00:19:13.500]   That's, by the way, so this is going to be image free for security at the start.
[00:19:13.500 --> 00:19:17.380]   At some point you obviously connect and meet each other and see each other.
[00:19:17.380 --> 00:19:21.860]   But at the first, this is not about doing the origins of Facebook and the look book.
[00:19:21.860 --> 00:19:24.780]   Oh, I wonder if you're going to get a tie?
[00:19:24.780 --> 00:19:28.460]   That's, that's an interesting, like, I can't imagine.
[00:19:28.460 --> 00:19:30.820]   I could imagine women being like hot diggity.
[00:19:30.820 --> 00:19:35.060]   So I guess guys will go where the women are, but that's, that's an intriguing option.
[00:19:35.060 --> 00:19:36.060]   Really interesting.
[00:19:36.060 --> 00:19:38.220]   So you'll have a profile, right?
[00:19:38.220 --> 00:19:41.500]   But you can put whatever you want, perfectly, you put your cartoon avatar in there, your,
[00:19:41.500 --> 00:19:44.900]   your, your, your Oculus avatar who knows.
[00:19:44.900 --> 00:19:47.580]   But but the end, you won't be sending back.
[00:19:47.580 --> 00:19:49.060]   Porty pictures or anything.
[00:19:49.060 --> 00:19:50.060]   You'll be talking.
[00:19:50.060 --> 00:19:51.060]   Okay.
[00:19:51.060 --> 00:19:52.900]   People will still send back porty pictures.
[00:19:52.900 --> 00:19:53.900]   Sure.
[00:19:53.900 --> 00:19:54.900]   I'm married.
[00:19:54.900 --> 00:19:55.900]   I'm going to be asking.
[00:19:55.900 --> 00:19:57.700]   There's going to be asking porn.
[00:19:57.700 --> 00:19:59.460]   I mean, there was a text.
[00:19:59.460 --> 00:20:01.940]   You know, someone will just highly realistic.
[00:20:01.940 --> 00:20:02.940]   Ask you.
[00:20:02.940 --> 00:20:08.420]   But I have to say, I don't really see this as having a chance in hell of succeeding.
[00:20:08.420 --> 00:20:12.100]   I think this is going to be one of those things that six months from now, Facebook is going
[00:20:12.100 --> 00:20:13.940]   to shut it down.
[00:20:13.940 --> 00:20:16.060]   And, and you know, it'll, it'll die without a ripple.
[00:20:16.060 --> 00:20:21.500]   I just don't see this is the company that everyone is talking about privacy and their
[00:20:21.500 --> 00:20:22.700]   data.
[00:20:22.700 --> 00:20:23.700]   So now they're going to.
[00:20:23.700 --> 00:20:28.700]   Thank you.
[00:20:28.700 --> 00:20:29.700]   Lots of people.
[00:20:29.700 --> 00:20:30.700]   I talk to you.
[00:20:30.700 --> 00:20:31.700]   Mention it.
[00:20:31.700 --> 00:20:32.700]   Normal people, civilians.
[00:20:32.700 --> 00:20:34.940]   And so now they're going to think, you know what I should do?
[00:20:34.940 --> 00:20:38.060]   I should give Facebook a lot of dating information.
[00:20:38.060 --> 00:20:43.140]   And you know, my, my sexual proclivities or something or whatever.
[00:20:43.140 --> 00:20:46.140]   I should, is this information that people are going to want to share with Facebook?
[00:20:46.140 --> 00:20:47.140]   I don't think so.
[00:20:47.140 --> 00:20:48.140]   Plus, I'm not coming.
[00:20:48.140 --> 00:20:51.060]   Those things are perfectly successful.
[00:20:51.060 --> 00:20:55.300]   What, what, what, I'm intrigued by putting sexual proclivities on your dating profile,
[00:20:55.300 --> 00:20:56.300]   Matthew.
[00:20:56.300 --> 00:20:57.940]   That seems to look forward.
[00:20:57.940 --> 00:20:58.940]   Yeah.
[00:20:58.940 --> 00:21:05.660]   As a user, how much of, how much of creating that, that profile that, that exists outside
[00:21:05.660 --> 00:21:07.700]   of your friends profile?
[00:21:07.700 --> 00:21:09.140]   Like do you build that from the ground up?
[00:21:09.140 --> 00:21:10.140]   Yeah, you build that yourself.
[00:21:10.140 --> 00:21:11.140]   Yeah.
[00:21:11.140 --> 00:21:12.140]   That's the thing.
[00:21:12.140 --> 00:21:13.140]   That's what, what you're doing.
[00:21:13.140 --> 00:21:17.180]   And, and you know, of course there's a big age problem here is because when I was young
[00:21:17.180 --> 00:21:21.940]   and single, the only thing you could do then was, you know, personal ads in the New York
[00:21:21.940 --> 00:21:25.060]   review of books if you were studying intellectual, right?
[00:21:25.060 --> 00:21:27.220]   And there was no such structure.
[00:21:27.220 --> 00:21:30.820]   And young people today, I mean, I couple of, couple of, I have to meet online, online,
[00:21:30.820 --> 00:21:31.820]   online, right?
[00:21:31.820 --> 00:21:34.700]   There was a stigma about that in the time that went away like that.
[00:21:34.700 --> 00:21:38.380]   I talked to a woman some years ago who spent seven years in Japan.
[00:21:38.380 --> 00:21:41.740]   And then she came, she did a great blog about being, being single.
[00:21:41.740 --> 00:21:45.740]   And, and then she came back to the US and she was just gobsmacked about how suddenly that
[00:21:45.740 --> 00:21:49.780]   which had had kudis before was now the way to date.
[00:21:49.780 --> 00:21:55.180]   And it changed because when I was involved in accounting, asked in bridal, yes, I was.
[00:21:55.180 --> 00:22:01.000]   What I learned was that the, that the audience for those kinds of things spins out very quickly.
[00:22:01.000 --> 00:22:03.940]   So the norm can change very quickly.
[00:22:03.940 --> 00:22:08.180]   So when we own brides and modern bride and elegant bride, we thought we own bridal along
[00:22:08.180 --> 00:22:12.620]   came the knot and they stole the market because they had new functionality in a new way.
[00:22:12.620 --> 00:22:17.580]   So Matthew, I think it depends strictly on how smart they are and what they add.
[00:22:17.580 --> 00:22:20.980]   People may not like going through match or may not like going through city services and
[00:22:20.980 --> 00:22:23.860]   paying for them, by the way, was the point.
[00:22:23.860 --> 00:22:29.420]   Now they can do it in a place where they already have some comfort and some, and some
[00:22:29.420 --> 00:22:30.420]   other content.
[00:22:30.420 --> 00:22:35.980]   Well, in, I mean, the key to something like match according to, you know, their commercials
[00:22:35.980 --> 00:22:39.660]   is how well they can actually connect people.
[00:22:39.660 --> 00:22:45.980]   In Facebook, what will be interesting is how much of the iceberg you actually create versus
[00:22:45.980 --> 00:22:49.180]   what Facebook uses to match you to someone.
[00:22:49.180 --> 00:22:54.140]   Because I may say all kinds of things in my dating profile, but Facebook knows who I really
[00:22:54.140 --> 00:22:56.380]   am to a certain extent.
[00:22:56.380 --> 00:23:01.260]   And if it finds people based on that versus just what I put on there, then it becomes
[00:23:01.260 --> 00:23:02.260]   really interesting.
[00:23:02.260 --> 00:23:10.340]   And if people do meet their life partners or whatever these things, that's compelling.
[00:23:10.340 --> 00:23:11.340]   People will use it.
[00:23:11.340 --> 00:23:14.260]   But there's going to be lots of people who don't want that.
[00:23:14.260 --> 00:23:17.060]   Because there's going to be lots of people who don't have to say no.
[00:23:17.060 --> 00:23:18.260]   They don't have to opt in.
[00:23:18.260 --> 00:23:21.300]   Yeah, I just think those are going to be the majority of the market.
[00:23:21.300 --> 00:23:25.820]   I don't think Facebook, it just, it strikes me every time Facebook tries to launch, I
[00:23:25.820 --> 00:23:29.220]   saw a list of the things that it has tried that have failed.
[00:23:29.220 --> 00:23:33.100]   I remember it had a Groupon clone.
[00:23:33.100 --> 00:23:35.140]   There's a long list.
[00:23:35.140 --> 00:23:40.460]   And I think every time they try and sort of target a vertical like this, it seems to
[00:23:40.460 --> 00:23:41.460]   fail.
[00:23:41.460 --> 00:23:46.820]   Because people, I think, want to go to a site or a service that's dedicated to that thing.
[00:23:46.820 --> 00:23:49.820]   They don't want to mix it all in with the other stuff they do on Facebook.
[00:23:49.820 --> 00:23:54.700]   However, maybe what's different with this versus something like a Groupon clone.
[00:23:54.700 --> 00:24:00.100]   And we could talk about the many different avenues that Facebook makes money.
[00:24:00.100 --> 00:24:01.460]   That might be one way.
[00:24:01.460 --> 00:24:06.100]   But when you're talking about Facebook at its core, relationships is its biggest selling
[00:24:06.100 --> 00:24:07.100]   point.
[00:24:07.100 --> 00:24:08.100]   Yes.
[00:24:08.100 --> 00:24:13.020]   And this is a very major other aspect of the relationships that we as human beings enjoy
[00:24:13.020 --> 00:24:14.020]   on a daily basis.
[00:24:14.020 --> 00:24:19.780]   So from that perspective, it kind of makes sense to me that they might actually be really
[00:24:19.780 --> 00:24:20.780]   good at this.
[00:24:20.780 --> 00:24:27.260]   If they're not using the wide range of information that they've been gathering on users over
[00:24:27.260 --> 00:24:32.700]   the course of however many years to help inform how those matchups happening, then I think
[00:24:32.700 --> 00:24:34.940]   they're doing it wrong from their perspective.
[00:24:34.940 --> 00:24:38.460]   Because that's the power of the Facebook network.
[00:24:38.460 --> 00:24:44.340]   Yeah, the problem will be obviously that is where the privacy is going to be.
[00:24:44.340 --> 00:24:45.340]   It could be right.
[00:24:45.340 --> 00:24:48.900]   Oh, how did it know that I'm a foot fetishist like you are?
[00:24:48.900 --> 00:24:50.900]   What do we reveal that?
[00:24:50.900 --> 00:24:52.540]   By the way, I'm not.
[00:24:52.540 --> 00:24:57.940]   But yeah, those moments when you don't know what's going to come out, so how do they
[00:24:57.940 --> 00:25:00.900]   fence off that?
[00:25:00.900 --> 00:25:04.900]   And but on the other hand, it becomes really interesting.
[00:25:04.900 --> 00:25:07.900]   With enough data, they could make better, longer lasting marriages.
[00:25:07.900 --> 00:25:08.900]   Right.
[00:25:08.900 --> 00:25:09.900]   Well, it's an angel.
[00:25:09.900 --> 00:25:11.300]   And we don't know what it'll be.
[00:25:11.300 --> 00:25:14.460]   Why it that is, but they could find that AI.
[00:25:14.460 --> 00:25:17.820]   And we might just inherently trust, distrust them rather.
[00:25:17.820 --> 00:25:21.940]   We might be like, Oh my gosh, you like weird esoteric thing.
[00:25:21.940 --> 00:25:23.860]   And I like we're Facebook.
[00:25:23.860 --> 00:25:27.740]   What kind of shenanigans are you pulling when it's really just natural?
[00:25:27.740 --> 00:25:31.060]   Because you know, when you there's a name for this, when you think about something and
[00:25:31.060 --> 00:25:32.180]   then you see it everywhere.
[00:25:32.180 --> 00:25:38.500]   So once you're suspicious, you're going to assume the worst or maybe just we will.
[00:25:38.500 --> 00:25:40.300]   What is the name for that?
[00:25:40.300 --> 00:25:41.980]   Carson, no, he's the best.
[00:25:41.980 --> 00:25:44.100]   That is the Bader mine half.
[00:25:44.100 --> 00:25:45.100]   Yes.
[00:25:45.100 --> 00:25:46.100]   Yes.
[00:25:46.100 --> 00:25:48.500]   And you notice that in all media for the.
[00:25:48.500 --> 00:25:49.500]   Yeah.
[00:25:49.500 --> 00:25:50.500]   You'll see Bader mine half everywhere.
[00:25:50.500 --> 00:25:53.820]   And you know, it's a big reason why many people probably think that Facebook is recording
[00:25:53.820 --> 00:25:55.620]   them through their through the microphone.
[00:25:55.620 --> 00:25:56.620]   Exactly.
[00:25:56.620 --> 00:25:58.820]   It's like once you see it, you see it.
[00:25:58.820 --> 00:25:59.820]   You see it.
[00:25:59.820 --> 00:26:02.140]   I was talking about this and then Facebook showed me that I don't know.
[00:26:02.140 --> 00:26:03.140]   I've had that conversation.
[00:26:03.140 --> 00:26:04.340]   I don't know how many times.
[00:26:04.340 --> 00:26:05.340]   Yeah.
[00:26:05.340 --> 00:26:06.340]   Yes.
[00:26:06.340 --> 00:26:07.340]   You know, it occurred to me.
[00:26:07.340 --> 00:26:12.060]   So I've been doing this project about the moral implications and and imperatives around
[00:26:12.060 --> 00:26:14.540]   so the decisions being made in this world.
[00:26:14.540 --> 00:26:18.020]   And I had a great interview with my friend David Weinberger, one of the co co authors at the
[00:26:18.020 --> 00:26:20.620]   Blue Train Manifesto.
[00:26:20.620 --> 00:26:27.300]   And he was saying that if you're Google or you're Wikipedia, your goal is clear, right?
[00:26:27.300 --> 00:26:31.460]   You're organizing knowledge, one information, one way or the other.
[00:26:31.460 --> 00:26:34.740]   If you're Facebook or Twitter, they weren't clear.
[00:26:34.740 --> 00:26:37.060]   It's we have this place where people can come in and talk to them.
[00:26:37.060 --> 00:26:38.460]   I thought about it more.
[00:26:38.460 --> 00:26:39.860]   Data is clean.
[00:26:39.860 --> 00:26:41.860]   People are messy.
[00:26:41.860 --> 00:26:44.460]   Everything people do is messy.
[00:26:44.460 --> 00:26:45.460]   And it's not people.
[00:26:45.460 --> 00:26:47.460]   We can't make it clean.
[00:26:47.460 --> 00:26:51.260]   And we've met the enemy and guess who?
[00:26:51.260 --> 00:26:56.620]   And so what we're asking these platforms to do is to clean up human behavior.
[00:26:56.620 --> 00:27:00.260]   Because I don't believe they caused it.
[00:27:00.260 --> 00:27:01.260]   Right?
[00:27:01.260 --> 00:27:02.260]   They're there.
[00:27:02.260 --> 00:27:03.260]   We didn't expect the phone company to clean it up.
[00:27:03.260 --> 00:27:05.420]   We do expect Facebook to clean it up.
[00:27:05.420 --> 00:27:10.700]   And that's that's a very tall order because we are messy.
[00:27:10.700 --> 00:27:11.700]   That is true.
[00:27:11.700 --> 00:27:13.540]   I actually talk about that in the smart home all the time.
[00:27:13.540 --> 00:27:17.780]   I'm like, we're expecting our houses and our devices in them to mitigate things that
[00:27:17.780 --> 00:27:19.420]   we as people can't even mitigate.
[00:27:19.420 --> 00:27:20.420]   So this is.
[00:27:20.420 --> 00:27:21.420]   Amen.
[00:27:21.420 --> 00:27:22.420]   You're right.
[00:27:22.420 --> 00:27:23.420]   You're also.
[00:27:23.420 --> 00:27:24.420]   Wait, wait, wait, wait, wait.
[00:27:24.420 --> 00:27:27.260]   I want to savor that moment.
[00:27:27.260 --> 00:27:28.260]   Record this.
[00:27:28.260 --> 00:27:29.260]   Oh, you're right.
[00:27:29.260 --> 00:27:30.260]   Time stamp.
[00:27:30.260 --> 00:27:33.900]   We just agreed about a high level of Facebook.
[00:27:33.900 --> 00:27:34.900]   40401.
[00:27:34.900 --> 00:27:35.900]   May 2nd.
[00:27:35.900 --> 00:27:39.300]   I don't even know what data it is.
[00:27:39.300 --> 00:27:40.300]   Colin.
[00:27:40.300 --> 00:27:44.140]   But Stacey, you said data is not clean.
[00:27:44.140 --> 00:27:46.220]   Data is not clean.
[00:27:46.220 --> 00:27:49.700]   We think it's clean because it's.
[00:27:49.700 --> 00:27:51.260]   Because we think it's one thing or the other.
[00:27:51.260 --> 00:27:56.060]   But when you start actually trying to apply real world data to things, you have to convert
[00:27:56.060 --> 00:27:57.700]   it to that one thing or the other.
[00:27:57.700 --> 00:28:02.420]   We actually ascribe meaning to our data for the data.
[00:28:02.420 --> 00:28:08.820]   So we we declare that a these numbers are going to represent temperature, for example,
[00:28:08.820 --> 00:28:10.020]   just for something easy.
[00:28:10.020 --> 00:28:15.340]   And then we're also we also say we write the algorithms that say when this happens, this
[00:28:15.340 --> 00:28:16.340]   happens.
[00:28:16.340 --> 00:28:20.140]   So data is no cleaner than our world.
[00:28:20.140 --> 00:28:24.180]   I mean, it is it is right up until we interpret it.
[00:28:24.180 --> 00:28:28.420]   I mean, in every case, and this happens with Facebook to the algorithm.
[00:28:28.420 --> 00:28:30.420]   No, the gathering.
[00:28:30.420 --> 00:28:32.900]   Look at the reproducibility.
[00:28:32.900 --> 00:28:33.900]   Crisis and science.
[00:28:33.900 --> 00:28:34.900]   Yeah.
[00:28:34.900 --> 00:28:39.980]   So I was at the technical keynote, the sporting and the end of it was.
[00:28:39.980 --> 00:28:41.580]   Well, a great I would have her name.
[00:28:41.580 --> 00:28:43.860]   Unfortunately, I missed it, but I'll get it somewhere.
[00:28:43.860 --> 00:28:50.380]   But she gave a great 20 minute talk on algorithmic responsibility on the diversity of the sources
[00:28:50.380 --> 00:28:54.900]   of the data on the biases in the gathering of the data on the biases and the impact of
[00:28:54.900 --> 00:28:55.900]   what they're doing.
[00:28:55.900 --> 00:28:56.900]   They're trying to show that they are thinking about this.
[00:28:56.900 --> 00:28:58.940]   They have big brains on this.
[00:28:58.940 --> 00:29:05.060]   And then I went to a session about preventing suicide.
[00:29:05.060 --> 00:29:08.180]   You want to get personal, right?
[00:29:08.180 --> 00:29:11.660]   And it's fascinating how they because they have a responsibility, right?
[00:29:11.660 --> 00:29:13.460]   On the one hand, you can say what a terrible validation.
[00:29:13.460 --> 00:29:14.780]   Look, people do what they want to do.
[00:29:14.780 --> 00:29:16.380]   Well, no, they have a responsibility.
[00:29:16.380 --> 00:29:20.100]   If there's something that's going on with their nose, they want to try to fix it and
[00:29:20.100 --> 00:29:22.420]   having a problem.
[00:29:22.420 --> 00:29:26.180]   Well, yeah, that's exactly where they're going.
[00:29:26.180 --> 00:29:27.180]   That's exactly it, right?
[00:29:27.180 --> 00:29:29.860]   So that I'm sure they did quite on purpose to say, you know, look how we're trying to
[00:29:29.860 --> 00:29:32.020]   do use the data responsibly.
[00:29:32.020 --> 00:29:35.860]   But it was it was really fascinating because somebody says, I have so much homework.
[00:29:35.860 --> 00:29:36.860]   I want to build myself.
[00:29:36.860 --> 00:29:38.460]   Well, that'll trigger it.
[00:29:38.460 --> 00:29:41.740]   But then they look at the behavior and obviously the discussion, oh, yeah, me too.
[00:29:41.740 --> 00:29:43.980]   I don't know how you feel the discussion.
[00:29:43.980 --> 00:29:45.500]   They know when to judge it.
[00:29:45.500 --> 00:29:52.460]   But otherwise, the AI is now faster than the people at flagging really dangerous ones.
[00:29:52.460 --> 00:29:53.460]   And it's flagged.
[00:29:53.460 --> 00:29:56.980]   I forget the number they had, like a hundred thousand of these.
[00:29:56.980 --> 00:29:57.980]   A thousand.
[00:29:57.980 --> 00:29:58.980]   Oh, was it a thousand actions?
[00:29:58.980 --> 00:29:59.980]   A thousand actions taken.
[00:29:59.980 --> 00:30:00.980]   A thousand actions taken.
[00:30:00.980 --> 00:30:01.980]   A thousand actions.
[00:30:01.980 --> 00:30:05.500]   A thousand actions are out of a thousand something else that they did go, a thousand actions taken, right?
[00:30:05.500 --> 00:30:09.660]   And thank you, Stacy.
[00:30:09.660 --> 00:30:12.860]   But that gets really close for comfort too.
[00:30:12.860 --> 00:30:17.660]   I think we would all agree that if you see a suicide potential under your nose, you should
[00:30:17.660 --> 00:30:20.660]   do something about it.
[00:30:20.660 --> 00:30:25.220]   But you can also argue it's invasive as hell as one's privacy.
[00:30:25.220 --> 00:30:26.420]   I just find it.
[00:30:26.420 --> 00:30:31.700]   This is kind of off topic, but I find it amazing that in interviews Zuckerberg has said a
[00:30:31.700 --> 00:30:39.300]   couple of times that for the first 10 years, 10 years, all Facebook was focused on was
[00:30:39.300 --> 00:30:42.100]   the positive things that Facebook could do.
[00:30:42.100 --> 00:30:47.820]   And so it's only recently that they've thought, wow, all this stuff could actually have negative
[00:30:47.820 --> 00:30:48.820]   consequences.
[00:30:48.820 --> 00:30:49.980]   I find that mind boggling.
[00:30:49.980 --> 00:30:53.300]   So either that's not true or.
[00:30:53.300 --> 00:30:55.860]   I think that's more responsible for the point.
[00:30:55.860 --> 00:30:56.860]   It's incredibly funny.
[00:30:56.860 --> 00:30:57.860]   No, I think we're fun.
[00:30:57.860 --> 00:31:00.620]   But I know I'll put myself the exact same boat, Matthew.
[00:31:00.620 --> 00:31:03.180]   I'm fundamentally an optimist.
[00:31:03.180 --> 00:31:04.180]   There's going to be an optimist.
[00:31:04.180 --> 00:31:06.540]   I am William said it too.
[00:31:06.540 --> 00:31:10.180]   As self myself was, we've been short before, where he said we didn't see the extent of
[00:31:10.180 --> 00:31:11.180]   the bad behavior.
[00:31:11.180 --> 00:31:13.660]   The bad behavior does not come from all the mention.
[00:31:13.660 --> 00:31:15.220]   I don't think that's true at all.
[00:31:15.220 --> 00:31:19.420]   I think they did see it and they chose not to pay attention to it.
[00:31:19.420 --> 00:31:20.420]   Well, here's this.
[00:31:20.420 --> 00:31:24.900]   I'm going to say it's a little bit more nefarious in the sense that I think they honestly didn't
[00:31:24.900 --> 00:31:26.980]   see it and didn't pay or they saw it.
[00:31:26.980 --> 00:31:31.780]   They didn't pay attention to it because of, and I'll say it, their positions of privilege
[00:31:31.780 --> 00:31:34.860]   as a woman looking at a lot of tech services.
[00:31:34.860 --> 00:31:38.940]   I have always brought up the fact that, oh, I had a stalker in college.
[00:31:38.940 --> 00:31:40.460]   This would be a freaking dream for him.
[00:31:40.460 --> 00:31:43.980]   And no one ever pays attention to it because the people building this stuff.
[00:31:43.980 --> 00:31:44.980]   Yeah, I agree.
[00:31:44.980 --> 00:31:45.980]   Yeah, I agree.
[00:31:45.980 --> 00:31:46.980]   Yeah, no, you're right.
[00:31:46.980 --> 00:31:48.980]   You're totally right.
[00:31:48.980 --> 00:31:55.620]   And let's say they were also focused on growth and the way to grow is to just get more people
[00:31:55.620 --> 00:31:56.620]   on the platform.
[00:31:56.620 --> 00:31:58.900]   Their bots or trolls or that's engagement.
[00:31:58.900 --> 00:32:03.780]   Well, here's another thing Matthew, and they will never say this on Facebook again.
[00:32:03.780 --> 00:32:06.260]   That from Zuckerberg said it and got smashed.
[00:32:06.260 --> 00:32:11.740]   He might have been right in his first response to the election when he said, listen, the
[00:32:11.740 --> 00:32:15.300]   amount of fake news stuff was very small and couldn't have had an impact on the election.
[00:32:15.300 --> 00:32:18.700]   I think that may very well be true.
[00:32:18.700 --> 00:32:21.380]   The actual impact and actual harm, we don't know.
[00:32:21.380 --> 00:32:22.980]   We don't have good research.
[00:32:22.980 --> 00:32:26.420]   And what we're saying to them as society is, well, whatever it is, it's over our tolerance
[00:32:26.420 --> 00:32:27.940]   and do something about it.
[00:32:27.940 --> 00:32:29.140]   And fine.
[00:32:29.140 --> 00:32:34.780]   But the actual impact, when they saw how much bad stuff was happening or how many Russian
[00:32:34.780 --> 00:32:40.140]   ads at first, that kind of stuff, in the scale they have, they didn't think it was necessary
[00:32:40.140 --> 00:32:41.140]   to do it.
[00:32:41.140 --> 00:32:43.140]   Here's the number that blew me away.
[00:32:43.140 --> 00:32:47.220]   Blew me away from the one thing that blew me away from all of that fake was when Zuckerberg
[00:32:47.220 --> 00:32:52.260]   said yesterday that they kill and he used a singular and today they used a plural of
[00:32:52.260 --> 00:32:53.260]   this.
[00:32:53.260 --> 00:32:59.780]   He said, a million fake accounts a day, a million fake accounts a day they catch and
[00:32:59.780 --> 00:33:00.780]   kill.
[00:33:00.780 --> 00:33:02.380]   The scale of that is just my boy.
[00:33:02.380 --> 00:33:05.860]   So somebody said in the Q&A session, well, when I find the fake account, I will report
[00:33:05.860 --> 00:33:06.860]   to you.
[00:33:06.860 --> 00:33:10.380]   And they said, fine, please do, but that doesn't help at our scale.
[00:33:10.380 --> 00:33:11.380]   Yeah.
[00:33:11.380 --> 00:33:16.180]   I mean, the scale of Facebook is impossible to sort of comprehend to begin with.
[00:33:16.180 --> 00:33:23.220]   I mean, if Zuckerberg says fake news is like 1%, that's 1% of 800%.
[00:33:23.220 --> 00:33:27.260]   A billion pieces of content that are uploaded every day or 2 billion users.
[00:33:27.260 --> 00:33:32.660]   I mean, it's impossible to comprehend the scale that Facebook exists at, I think.
[00:33:32.660 --> 00:33:39.220]   And so maybe it's unfair to expect them to manage that in a way that you would if it
[00:33:39.220 --> 00:33:40.220]   was a lot smaller.
[00:33:40.220 --> 00:33:43.940]   But that's their job, you know, that's their business.
[00:33:43.940 --> 00:33:45.140]   They're supposed to be doing it.
[00:33:45.140 --> 00:33:49.300]   It's not, you know, I didn't make Mark Zuckerberg create this giant entity.
[00:33:49.300 --> 00:33:50.780]   It's his problem.
[00:33:50.780 --> 00:33:53.940]   Well, no, hold on.
[00:33:53.940 --> 00:33:55.700]   Part of the, absolutely.
[00:33:55.700 --> 00:34:00.460]   But all of society's problems, I think the problem here is that there's this presumption
[00:34:00.460 --> 00:34:04.500]   that they call, society was just fine before they came along.
[00:34:04.500 --> 00:34:06.860]   They screwed it up and they got a fixable with that.
[00:34:06.860 --> 00:34:07.860]   Right.
[00:34:07.860 --> 00:34:11.380]   And you heard the discussions we had in Peruja, Matthew, where I had two sessions where I
[00:34:11.380 --> 00:34:14.340]   asked people, okay, let's bounce the problems down.
[00:34:14.340 --> 00:34:15.420]   What do we want them to do about it?
[00:34:15.420 --> 00:34:19.100]   And the answers were 180 degrees.
[00:34:19.100 --> 00:34:23.060]   And so we rarely have that discussion about actual solutions.
[00:34:23.060 --> 00:34:24.060]   Expectations.
[00:34:24.060 --> 00:34:27.340]   And Jay Rosen is the one who said to me, we've not had this conversation.
[00:34:27.340 --> 00:34:29.220]   We don't have the terms of this conversation.
[00:34:29.220 --> 00:34:33.020]   There's presumption that they're all screwed up and they've got to do something.
[00:34:33.020 --> 00:34:36.060]   But we haven't, what should we do law?
[00:34:36.060 --> 00:34:39.500]   They should be the regulation that says the defines exactly what they screwed up so we
[00:34:39.500 --> 00:34:43.740]   can define exactly what they've got to fix and how we have to have that conversation.
[00:34:43.740 --> 00:34:46.460]   I'm saying that we stop there.
[00:34:46.460 --> 00:34:47.460]   I agree.
[00:34:47.460 --> 00:34:49.580]   We haven't had that conversation.
[00:34:49.580 --> 00:34:52.780]   Because it's, Facebook is unlike anything that ever existed before.
[00:34:52.780 --> 00:34:56.940]   We don't have any terms on which to discuss it or to describe it.
[00:34:56.940 --> 00:34:57.940]   There's never been.
[00:34:57.940 --> 00:35:01.700]   Yes, there's been an entity that had that kind of power before.
[00:35:01.700 --> 00:35:03.620]   And I think that I think that was.
[00:35:03.620 --> 00:35:05.260]   Yes, for man, books could do that too.
[00:35:05.260 --> 00:35:06.260]   Yes.
[00:35:06.260 --> 00:35:07.260]   Right.
[00:35:07.260 --> 00:35:08.260]   But I forget who it was.
[00:35:08.260 --> 00:35:12.140]   I wish I could remember who used this analogy, but I said I was going to steal it.
[00:35:12.140 --> 00:35:18.140]   They said that, I think it might have been Jonathan Albright actually, who said that Facebook
[00:35:18.140 --> 00:35:24.380]   or social media or whether it was the election or the filter bubbles is not, it didn't create
[00:35:24.380 --> 00:35:27.060]   problems, these problems.
[00:35:27.060 --> 00:35:29.060]   It's what he called an accelerant.
[00:35:29.060 --> 00:35:36.540]   So it social media effectively pours fuel on existing human behaviors and human nature.
[00:35:36.540 --> 00:35:40.260]   And it metastasizes those.
[00:35:40.260 --> 00:35:46.020]   They grow faster and broader than they ever could have before.
[00:35:46.020 --> 00:35:48.220]   That's not something that's their fault.
[00:35:48.220 --> 00:35:51.700]   I'm just saying.
[00:35:51.700 --> 00:35:55.140]   People raise $250,000 for the hero of the Waffle House.
[00:35:55.140 --> 00:35:59.620]   It's impossible for people saved other people from suicide.
[00:35:59.620 --> 00:36:03.620]   Facebook started a whole structure for donating blood because they saw the necessity of wanting
[00:36:03.620 --> 00:36:05.620]   to help.
[00:36:05.620 --> 00:36:11.460]   The dystopia of saying that society is all screwed up is really not about Facebook at
[00:36:11.460 --> 00:36:12.460]   all.
[00:36:12.460 --> 00:36:14.460]   It's what you're saying is about us, messy humans.
[00:36:14.460 --> 00:36:15.460]   Right.
[00:36:15.460 --> 00:36:16.460]   And I'm not saying.
[00:36:16.460 --> 00:36:17.460]   That's where I am more optimistic.
[00:36:17.460 --> 00:36:23.340]   And I don't think the dystopic view or the utopian view are, I mean, the truth obviously
[00:36:23.340 --> 00:36:25.180]   is somewhere in the middle.
[00:36:25.180 --> 00:36:31.100]   The internet, social media, the web effectively enable all the good aspects of human nature
[00:36:31.100 --> 00:36:34.260]   and all the bad aspects of human nature.
[00:36:34.260 --> 00:36:37.420]   Data is not clean.
[00:36:37.420 --> 00:36:38.900]   Humans are messy.
[00:36:38.900 --> 00:36:41.900]   This is all going to be on the exam.
[00:36:41.900 --> 00:36:42.900]   All right.
[00:36:42.900 --> 00:36:45.900]   I've got those bullets on my sheet.
[00:36:45.900 --> 00:36:50.100]   Oh, good discussion there you guys.
[00:36:50.100 --> 00:36:54.260]   What about I feel like there was like a whole laundry list of announcements from Facebook.
[00:36:54.260 --> 00:36:56.420]   We probably don't need to go into all of them.
[00:36:56.420 --> 00:36:57.820]   That's the top of the list.
[00:36:57.820 --> 00:37:03.020]   We're just talking about what are some of the other things that really I think group calling
[00:37:03.020 --> 00:37:08.060]   comes to more of their platforms.
[00:37:08.060 --> 00:37:13.300]   The AI enabled AR stuff comes to more of the platform.
[00:37:13.300 --> 00:37:16.060]   They're expanding this stuff now.
[00:37:16.060 --> 00:37:17.060]   They're proud of WhatsApp.
[00:37:17.060 --> 00:37:21.420]   I think one thing that we in America have a huge blind spot about us, the use of WhatsApp
[00:37:21.420 --> 00:37:23.100]   elsewhere in the world.
[00:37:23.100 --> 00:37:27.900]   And as the largest encrypted network out there, we're bad things by the way are happening.
[00:37:27.900 --> 00:37:31.540]   We're in Colombia and India and other countries.
[00:37:31.540 --> 00:37:32.900]   Hate's being spread there.
[00:37:32.900 --> 00:37:36.900]   It's an issue, but also safety is possible there.
[00:37:36.900 --> 00:37:40.900]   But anyway, fun is now there too because you can put a mustache on somebody's face.
[00:37:40.900 --> 00:37:41.900]   Finally.
[00:37:41.900 --> 00:37:42.900]   Yeah.
[00:37:42.900 --> 00:37:43.900]   I was telling you that before.
[00:37:43.900 --> 00:37:44.900]   Now that's probably.
[00:37:44.900 --> 00:37:50.260]   That was the great line from Zuckerberg where he puts some pictures on his face and he said,
[00:37:50.260 --> 00:37:51.260]   my daughter loves seeing this.
[00:37:51.260 --> 00:37:53.820]   Oh, look, data is a bunny.
[00:37:53.820 --> 00:37:54.820]   Data is an oaker.
[00:37:54.820 --> 00:37:57.620]   It's just like reading about him in the press.
[00:37:57.620 --> 00:38:04.180]   I actually liked when he introduced the watch feature so you can watch something with somebody.
[00:38:04.180 --> 00:38:09.980]   And he said, let's say your friend is testifying before Congress and you want to watch them.
[00:38:09.980 --> 00:38:10.980]   Nice.
[00:38:10.980 --> 00:38:15.060]   What about this 3D stuff?
[00:38:15.060 --> 00:38:17.820]   I didn't catch this in the presentation, but.
[00:38:17.820 --> 00:38:18.820]   Love.
[00:38:18.820 --> 00:38:19.820]   Turned.
[00:38:19.820 --> 00:38:20.820]   Yeah, no kidding.
[00:38:20.820 --> 00:38:30.060]   The 3D, but taking still photographs and obviously applying the machine learning, the neural networks
[00:38:30.060 --> 00:38:33.540]   to it and then 3D, 3D, applying them in your feed.
[00:38:33.540 --> 00:38:34.540]   That kind of looks pretty cool.
[00:38:34.540 --> 00:38:35.540]   Right.
[00:38:35.540 --> 00:38:36.540]   The fit for this.
[00:38:36.540 --> 00:38:37.540]   Yeah.
[00:38:37.540 --> 00:38:43.780]   So the tech in the tech keynote, they showed how they just take multiple images from two
[00:38:43.780 --> 00:38:48.260]   cameras and then just use that to create a different kind of image.
[00:38:48.260 --> 00:38:51.340]   And then when you're going to view in a more immersive state, you get a different view
[00:38:51.340 --> 00:38:52.340]   of it.
[00:38:52.340 --> 00:38:55.580]   I think there's two camera stuff because we talked about the show before with phones
[00:38:55.580 --> 00:38:58.700]   starting to have two cameras and the stereopic possibilities of that.
[00:38:58.700 --> 00:39:04.220]   I think we're going to see a lot more 3D photography created through AI.
[00:39:04.220 --> 00:39:06.060]   So I think this is a chance.
[00:39:06.060 --> 00:39:12.660]   This is an effort to make the $2 billion or so that it's been an Oculus payoff because
[00:39:12.660 --> 00:39:18.220]   the biggest, the biggest issue for 3D is, well, there's several.
[00:39:18.220 --> 00:39:19.940]   There's a lot that they've got to do.
[00:39:19.940 --> 00:39:24.300]   They've got to create the devices that are capable of viewing it.
[00:39:24.300 --> 00:39:26.500]   And then they've got to create stuff that's worth viewing.
[00:39:26.500 --> 00:39:31.980]   So being able to jumpstart one side of that market so they can get the other one makes
[00:39:31.980 --> 00:39:39.020]   sense because Facebook is very, like Mark Zuckerberg seems to sincerely believe in VR.
[00:39:39.020 --> 00:39:43.060]   I don't meet a lot of people who sincerely believe in VR.
[00:39:43.060 --> 00:39:50.620]   So I think this is just another example to try to push that and yeah, more powerful.
[00:39:50.620 --> 00:39:52.900]   Remember when Bill Gates loved pen computing?
[00:39:52.900 --> 00:39:55.420]   Remember when the future was going to be pen computing?
[00:39:55.420 --> 00:40:00.340]   I mean, yeah, that's exactly what this feels like.
[00:40:00.340 --> 00:40:02.300]   Like, all right, keep going, man.
[00:40:02.300 --> 00:40:03.300]   Sure.
[00:40:03.300 --> 00:40:06.820]   Or maybe he cares about VR because he spent $2 billion on Oculus and he kind of has to
[00:40:06.820 --> 00:40:11.220]   care until they figure out a way that they don't need to care anymore.
[00:40:11.220 --> 00:40:15.940]   He could be incredibly forward thinking in five, 10 years from now.
[00:40:15.940 --> 00:40:19.740]   VR actually is a big deal because the technology is advanced and they were there first.
[00:40:19.740 --> 00:40:22.260]   Yeah, we just.
[00:40:22.260 --> 00:40:29.980]   Yeah, but the iPhone, the iPhone came out when all of these tech things aligned in a form
[00:40:29.980 --> 00:40:35.740]   factor that was great and then they came out with an app developer program that created
[00:40:35.740 --> 00:40:38.860]   demand that continued to like push that engine.
[00:40:38.860 --> 00:40:39.860]   VR.
[00:40:39.860 --> 00:40:40.860]   They need those things together.
[00:40:40.860 --> 00:40:41.860]   Yeah.
[00:40:41.860 --> 00:40:43.780]   The tech isn't even ready for VR.
[00:40:43.780 --> 00:40:44.780]   I mean, this is.
[00:40:44.780 --> 00:40:46.420]   So Stacey, they showed this morning, you're right.
[00:40:46.420 --> 00:40:47.420]   You're absolutely right.
[00:40:47.420 --> 00:40:48.980]   And that's the way they position it.
[00:40:48.980 --> 00:40:52.780]   They say, here are the milestones we need and they're huge and they're going to take
[00:40:52.780 --> 00:40:53.780]   a lot of time.
[00:40:53.780 --> 00:40:55.220]   So they showed they showed the hardware.
[00:40:55.220 --> 00:41:01.620]   Stacey, where because you're in like a, I guess, is 10 feet radius of focal length and
[00:41:01.620 --> 00:41:04.020]   you want to look, you get your hands, you're going to look at something to close.
[00:41:04.020 --> 00:41:05.340]   It's out of focal.
[00:41:05.340 --> 00:41:11.100]   They're showing actually physically moving the screen in the viewer as you do that, as
[00:41:11.100 --> 00:41:12.940]   you look up at something, right?
[00:41:12.940 --> 00:41:18.220]   Wacky stuff, but you're, because you're right, Stacey, they know how far away this is from
[00:41:18.220 --> 00:41:19.220]   usable.
[00:41:19.220 --> 00:41:20.580]   And I'm going to agree with you.
[00:41:20.580 --> 00:41:22.900]   I'm getting vertigo just listening to you describe it.
[00:41:22.900 --> 00:41:23.900]   I know.
[00:41:23.900 --> 00:41:24.900]   I'm like, Oh my God.
[00:41:24.900 --> 00:41:25.900]   I don't.
[00:41:25.900 --> 00:41:26.900]   I hate VR.
[00:41:26.900 --> 00:41:27.900]   I never feel safe.
[00:41:27.900 --> 00:41:28.900]   Yeah.
[00:41:28.900 --> 00:41:33.060]   Like, unless I'm in my home, like every time I'm trying these on, it shows, I'm just like,
[00:41:33.060 --> 00:41:34.860]   God, someone is going to come up.
[00:41:34.860 --> 00:41:38.060]   Well, I'm just afraid someone's going to like, like, I don't know.
[00:41:38.060 --> 00:41:41.540]   What is it when they lick their finger and they stick it like in your ear on your neck?
[00:41:41.540 --> 00:41:43.540]   I just feel like someone's going to.
[00:41:43.540 --> 00:41:44.540]   Yes.
[00:41:44.540 --> 00:41:45.540]   Really?
[00:41:45.540 --> 00:41:47.260]   You're afraid specifically?
[00:41:47.260 --> 00:41:51.700]   I just hate the idea of someone coming up and being in my personal space without me being
[00:41:51.700 --> 00:41:52.700]   aware of them.
[00:41:52.700 --> 00:41:55.380]   It's like anathema to everything I've been taught.
[00:41:55.380 --> 00:42:00.380]   My problem is that VR thing I've ever tried has made me physically ill.
[00:42:00.380 --> 00:42:07.980]   So unless they can figure out some way that it won't, I guess it's just a problem I have.
[00:42:07.980 --> 00:42:12.420]   Lots of other people seem to think it's great, but I'm much more interested in augmented
[00:42:12.420 --> 00:42:13.420]   reality.
[00:42:13.420 --> 00:42:20.380]   I'd much rather have data popping up as I'm looking at things or sort of entering reality
[00:42:20.380 --> 00:42:21.380]   with me.
[00:42:21.380 --> 00:42:24.660]   I don't necessarily want to go into a whole separate environment.
[00:42:24.660 --> 00:42:25.660]   Me too.
[00:42:25.660 --> 00:42:32.460]   I'm a VR optimist, even though what I've seen, little bits and pieces, I'm like, oh, that
[00:42:32.460 --> 00:42:33.460]   was really cool.
[00:42:33.460 --> 00:42:37.300]   But it never lives up to my dream, my hopes.
[00:42:37.300 --> 00:42:43.060]   As far back as watching lawnmower man back when I was younger, that set the stage for
[00:42:43.060 --> 00:42:47.660]   me or this immersive world that you could go to and lose yourself in.
[00:42:47.660 --> 00:42:50.580]   We're kind of there with VR, but it still feels like early days.
[00:42:50.580 --> 00:42:55.820]   I still totally believe that we will get there some day and that we're very early on at
[00:42:55.820 --> 00:42:56.820]   this point.
[00:42:56.820 --> 00:42:59.580]   I don't know how important it's going to be, but it'll be cool when we get there.
[00:42:59.580 --> 00:43:04.780]   Companies will still be developing it and figuring out how to make it immersive because
[00:43:04.780 --> 00:43:07.020]   that's a big wall to break down.
[00:43:07.020 --> 00:43:12.340]   It's a big barrier to move from this flat surface to an immersive environment.
[00:43:12.340 --> 00:43:18.540]   Look at the early days of photography or how horrible everything was and how long it
[00:43:18.540 --> 00:43:19.540]   took.
[00:43:19.540 --> 00:43:22.980]   I hear lots of people thought this photography stuff is dumb.
[00:43:22.980 --> 00:43:24.500]   It's not really look stupid.
[00:43:24.500 --> 00:43:26.900]   It takes hours to take a photograph.
[00:43:26.900 --> 00:43:29.260]   No one smiles because it takes a while.
[00:43:29.260 --> 00:43:33.860]   One thing I forgot about this, when I did try it out for a brief little bit this morning
[00:43:33.860 --> 00:43:40.020]   because for the show, because I do everything to show, the business model really struck
[00:43:40.020 --> 00:43:41.020]   me.
[00:43:41.020 --> 00:43:42.020]   I forgot this.
[00:43:42.020 --> 00:43:46.020]   So this is only $200, $0.99, all of those that's fine, right?
[00:43:46.020 --> 00:43:48.980]   Well, you want to use this or that.
[00:43:48.980 --> 00:43:53.140]   The first software purchase you got what it uses is $40.
[00:43:53.140 --> 00:43:55.580]   Is it like a console model?
[00:43:55.580 --> 00:43:59.380]   Like a gaming console model?
[00:43:59.380 --> 00:44:01.580]   Oh, you buy the console.
[00:44:01.580 --> 00:44:04.060]   The games are like 50 or 80 bucks.
[00:44:04.060 --> 00:44:06.100]   Prices are high.
[00:44:06.100 --> 00:44:09.340]   So that's becomes a, I see I'm old enough, Stacy.
[00:44:09.340 --> 00:44:11.140]   I'd call it a razor model.
[00:44:11.140 --> 00:44:12.500]   Okay, fair enough.
[00:44:12.500 --> 00:44:14.020]   But I still use those.
[00:44:14.020 --> 00:44:19.540]   I was going to add the one thing that VR has going for it or that could really change the
[00:44:19.540 --> 00:44:25.500]   scales in a big way for VR is if we utterly destroy the planet because then you actually,
[00:44:25.500 --> 00:44:26.500]   I'm serious.
[00:44:26.500 --> 00:44:28.740]   I mean, it's just like the most of the competition.
[00:44:28.740 --> 00:44:30.900]   There is a good chance.
[00:44:30.900 --> 00:44:33.020]   You know, the ready player one happening.
[00:44:33.020 --> 00:44:36.660]   So, yeah, ready player one.
[00:44:36.660 --> 00:44:40.940]   Yeah, that's you got the, at least an element of the plot point right there.
[00:44:40.940 --> 00:44:42.660]   I don't think that's spoiler.
[00:44:42.660 --> 00:44:43.660]   I don't think that's the case.
[00:44:43.660 --> 00:44:46.740]   No, that guy actually lives in Austin, Ernest Klein, the author.
[00:44:46.740 --> 00:44:48.700]   He lives in my neighborhood.
[00:44:48.700 --> 00:44:50.380]   In the trailer park like that?
[00:44:50.380 --> 00:44:51.380]   No, no.
[00:44:51.380 --> 00:44:57.140]   Just a nice neighborhood.
[00:44:57.140 --> 00:44:58.660]   I'm curious to check out Oculus Go.
[00:44:58.660 --> 00:45:01.260]   I didn't realize it was based on Android.
[00:45:01.260 --> 00:45:02.460]   It's running Android.
[00:45:02.460 --> 00:45:03.460]   Yeah.
[00:45:03.460 --> 00:45:04.860]   Nougat underneath.
[00:45:04.860 --> 00:45:10.460]   So which makes me wonder like when you're pricing, it's like this, this, this, this sliding
[00:45:10.460 --> 00:45:15.300]   scale between what we've had with Daydream VR, which is totally mobile VR.
[00:45:15.300 --> 00:45:18.340]   This is a step up because you don't need the phone to slide into it.
[00:45:18.340 --> 00:45:19.340]   It's all standalone.
[00:45:19.340 --> 00:45:24.420]   Google's also working on a standalone VR, but it's not quite premium like a full blown
[00:45:24.420 --> 00:45:25.420]   Oculus Rift.
[00:45:25.420 --> 00:45:26.580]   There's no room tracking.
[00:45:26.580 --> 00:45:30.980]   It's all in the goggles meant to be sat down while doing the experience and everything.
[00:45:30.980 --> 00:45:33.420]   And I just don't like, I don't know if that's worth it.
[00:45:33.420 --> 00:45:34.420]   Is that worth $200?
[00:45:34.420 --> 00:45:35.420]   I guess we'll find out.
[00:45:35.420 --> 00:45:38.980]   I guess Jeff, you'll find out and let us all know.
[00:45:38.980 --> 00:45:39.980]   Let us know.
[00:45:39.980 --> 00:45:43.220]   I'd say that it's the right question.
[00:45:43.220 --> 00:45:47.900]   I mean, is VR, part of what we're saying on the show is VR worth anything?
[00:45:47.900 --> 00:45:51.100]   And to a reddish then, am I going to go out of my way to get VR?
[00:45:51.100 --> 00:45:52.100]   No.
[00:45:52.100 --> 00:45:53.780]   We're geek people, so we do this.
[00:45:53.780 --> 00:45:58.540]   But Ben, I saw plenty of people lined up for the demos, but they're geeks.
[00:45:58.540 --> 00:46:02.260]   The phone is a limiter.
[00:46:02.260 --> 00:46:05.820]   It is a clumsy thing to get the damn thing going and get it in there.
[00:46:05.820 --> 00:46:07.780]   And then it goes off and it does that.
[00:46:07.780 --> 00:46:09.780]   And you can have it all.
[00:46:09.780 --> 00:46:10.780]   Is it a necessity?
[00:46:10.780 --> 00:46:13.060]   The phone was a step toward this.
[00:46:13.060 --> 00:46:15.900]   I think this is where this goes down.
[00:46:15.900 --> 00:46:20.140]   And so if you want VR, yeah, I think you'll buy a container.
[00:46:20.140 --> 00:46:22.620]   I think that makes sense.
[00:46:22.620 --> 00:46:25.900]   And I think it might be, I mean, go ahead.
[00:46:25.900 --> 00:46:30.820]   I keep saying this, but I think there's going to be a lot of people who are interested
[00:46:30.820 --> 00:46:37.140]   in VR for specific purposes, whether it's education or medical or, you know, let's say
[00:46:37.140 --> 00:46:44.100]   you're a housebound because you're a quadriplegic or, I mean, VR, really good VR could be something
[00:46:44.100 --> 00:46:46.020]   incredibly liberating.
[00:46:46.020 --> 00:46:49.700]   Good 3D could be incredibly liberating.
[00:46:49.700 --> 00:46:55.220]   So it might not necessarily be a mass thing where everybody you see is wearing an oculus
[00:46:55.220 --> 00:46:57.300]   or a magic leap or whatever.
[00:46:57.300 --> 00:47:01.580]   But it could certainly find markets, I think, where it's applicable.
[00:47:01.580 --> 00:47:02.580]   Oh, yeah.
[00:47:02.580 --> 00:47:06.860]   I talked to somebody who's at Johns Hopkins, the hospital.
[00:47:06.860 --> 00:47:10.780]   One of the, he's an innovation guy.
[00:47:10.780 --> 00:47:15.260]   So they actually created a program where they, while people are doing chemotherapy, which
[00:47:15.260 --> 00:47:22.780]   takes a while, or dialysis, they send, they put VR goggles on them and then they send volunteers
[00:47:22.780 --> 00:47:28.220]   out to like the Washington Monument, and they like video and they go places on behalf of
[00:47:28.220 --> 00:47:29.820]   the person stuck in the chair.
[00:47:29.820 --> 00:47:31.940]   Yeah, that's a great idea.
[00:47:31.940 --> 00:47:33.860]   I would actually pay money for that.
[00:47:33.860 --> 00:47:38.140]   Like if you were stuck in a situation like that, you know, that would be a huge, like
[00:47:38.140 --> 00:47:41.860]   something that would change your life in a way.
[00:47:41.860 --> 00:47:47.260]   Seeing, let's say you're bedridden, you could walk around Rome virtually or you could walk
[00:47:47.260 --> 00:47:53.820]   around Paris virtually, that'd be a massive, you know, improvement in your life.
[00:47:53.820 --> 00:47:54.820]   So yeah.
[00:47:54.820 --> 00:47:56.580]   Interesting stuff.
[00:47:56.580 --> 00:48:02.820]   Facebook, F8, any final thoughts before we venture into Google news?
[00:48:02.820 --> 00:48:04.140]   We're about halfway through.
[00:48:04.140 --> 00:48:05.860]   So probably she gets some Google news.
[00:48:05.860 --> 00:48:06.860]   I thought it was interesting.
[00:48:06.860 --> 00:48:13.460]   We didn't mention this, but I thought it was interesting that, uh, that Jan, uh, can't
[00:48:13.460 --> 00:48:16.540]   remember his last name, who started WhatsApp has left.
[00:48:16.540 --> 00:48:17.540]   Oh, yeah.
[00:48:17.540 --> 00:48:18.540]   I did too.
[00:48:18.540 --> 00:48:19.540]   I was so busy.
[00:48:19.540 --> 00:48:21.100]   I just appeared on that.
[00:48:21.100 --> 00:48:22.100]   Was it Coom?
[00:48:22.100 --> 00:48:23.100]   Zylie, that was too.
[00:48:23.100 --> 00:48:27.100]   No, Jan Lecunus, they're, uh, they're AI dude.
[00:48:27.100 --> 00:48:28.100]   He's gone to.
[00:48:28.100 --> 00:48:29.100]   Oh, okay.
[00:48:29.100 --> 00:48:30.100]   Uh, the WhatsApp founder.
[00:48:30.100 --> 00:48:31.100]   Uh, yeah.
[00:48:31.100 --> 00:48:33.100]   What is his name?
[00:48:33.100 --> 00:48:34.100]   I'm looking for it.
[00:48:34.100 --> 00:48:35.100]   Uh, yeah.
[00:48:35.100 --> 00:48:36.100]   Yeah.
[00:48:36.100 --> 00:48:37.100]   Yeah.
[00:48:37.100 --> 00:48:38.100]   Yanko.
[00:48:38.100 --> 00:48:39.100]   Yeah.
[00:48:39.100 --> 00:48:40.100]   It is.
[00:48:40.100 --> 00:48:41.100]   Okay.
[00:48:41.100 --> 00:48:43.700]   And if he, and if he leaves now versus hanging on a little bit longer, he's given up a billion
[00:48:43.700 --> 00:48:45.300]   dollars, which says something.
[00:48:45.300 --> 00:48:47.100]   But he's got a bunch.
[00:48:47.100 --> 00:48:48.100]   I suppose so.
[00:48:48.100 --> 00:48:49.100]   Yeah.
[00:48:49.100 --> 00:48:52.580]   But it was interesting that the reason he gave, what's a billion?
[00:48:52.580 --> 00:48:57.940]   The reason he gave was that Facebook is going to start using WhatsApp data, basically
[00:48:57.940 --> 00:49:02.620]   blending data, which, which he understood was not going to happen.
[00:49:02.620 --> 00:49:03.620]   And so he felt that there's.
[00:49:03.620 --> 00:49:06.740]   How can they, when they're encrypted, that's what I don't understand.
[00:49:06.740 --> 00:49:11.780]   If they, they brag constantly to Facebook, that, that was, and they had encrypted.
[00:49:11.780 --> 00:49:12.780]   So your message is.
[00:49:12.780 --> 00:49:16.180]   Can you pull your messages are, but not your profile data?
[00:49:16.180 --> 00:49:20.620]   Well, your profile data and what about your phone, like location data, that sort of thing
[00:49:20.620 --> 00:49:21.620]   associated.
[00:49:21.620 --> 00:49:22.780]   I mean, you're not encrypted.
[00:49:22.780 --> 00:49:24.180]   I don't know what's encrypted.
[00:49:24.180 --> 00:49:30.780]   So like knowing that I'm using WhatsApp would be at, in where I am, would be very interesting,
[00:49:30.780 --> 00:49:31.780]   especially to everybody.
[00:49:31.780 --> 00:49:34.620]   It was a big deal for you and to give up a billion dollars.
[00:49:34.620 --> 00:49:35.620]   Yeah.
[00:49:35.620 --> 00:49:36.620]   To leave Facebook.
[00:49:36.620 --> 00:49:40.780]   And also I can very good was, you know, thanks for your service.
[00:49:40.780 --> 00:49:41.780]   I'm glad I'm here.
[00:49:41.780 --> 00:49:44.620]   I'll let the door hit you on the way out.
[00:49:44.620 --> 00:49:45.620]   Yeah.
[00:49:45.620 --> 00:49:49.060]   Don't let the Facebook door hit you on the way out.
[00:49:49.060 --> 00:49:53.580]   You know, we will, let's take a break.
[00:49:53.580 --> 00:49:58.140]   And we'll come back and we'll check in on some of the top Google news from the week.
[00:49:58.140 --> 00:50:00.780]   We got Google I/O literally right around the corner.
[00:50:00.780 --> 00:50:04.660]   So we can kind of talk about what we think we're going to see there and everything.
[00:50:04.660 --> 00:50:08.300]   But before we do that, let's thank the sponsor of this episode.
[00:50:08.300 --> 00:50:13.420]   I've been drinking the coffee that is the sponsor of this episode, Trace Pontes.
[00:50:13.420 --> 00:50:15.460]   I've been drinking their coffee for a while.
[00:50:15.460 --> 00:50:19.540]   My mornings have never been as amazing as they are with Trace Pontes.
[00:50:19.540 --> 00:50:21.380]   It is such good coffee.
[00:50:21.380 --> 00:50:22.380]   We're brewing it every morning.
[00:50:22.380 --> 00:50:26.540]   I'm a new ritual right now, by the way, where I wake up at 5.30 every single morning.
[00:50:26.540 --> 00:50:28.260]   My alarm goes off at 5.30.
[00:50:28.260 --> 00:50:29.260]   I get up.
[00:50:29.260 --> 00:50:31.100]   I meditate while I'm meditating.
[00:50:31.100 --> 00:50:32.420]   My coffee's brewing.
[00:50:32.420 --> 00:50:35.580]   When I'm done, it's the first thing that I do afterwards.
[00:50:35.580 --> 00:50:36.900]   And my morning starts off right.
[00:50:36.900 --> 00:50:38.540]   It's pretty awesome.
[00:50:38.540 --> 00:50:42.460]   You've heard of single origin coffee, but Trace Pontes takes it to another level.
[00:50:42.460 --> 00:50:47.900]   Their coffee comes from a single family farm, the race family coffee farm.
[00:50:47.900 --> 00:50:51.220]   It's located near the town of Trace Pontes in Brazil.
[00:50:51.220 --> 00:50:55.260]   The Trace Pontes mountain range is famous for growing some of the best coffee beans in
[00:50:55.260 --> 00:50:57.060]   the world for over 100 years.
[00:50:57.060 --> 00:51:01.580]   And three generations, the race family, has been growing some of the best premium gourmet
[00:51:01.580 --> 00:51:02.580]   coffee in Brazil.
[00:51:02.580 --> 00:51:06.940]   And this is the first time that they've ever exported their coffee to the US.
[00:51:06.940 --> 00:51:09.100]   The coffee beans are roasted to order.
[00:51:09.100 --> 00:51:11.100]   They're shipped out immediately.
[00:51:11.100 --> 00:51:16.500]   Every bag of beans has the roasted date printed so you know that your coffee is fresh.
[00:51:16.500 --> 00:51:19.380]   And you can see it right down at the bottom of this package right here.
[00:51:19.380 --> 00:51:24.220]   You can see it was especially roasted for us on April 11, 2018.
[00:51:24.220 --> 00:51:27.900]   That's printed on the bag so you know what you're getting.
[00:51:27.900 --> 00:51:33.700]   You can learn more about where your coffee originated if you use a QR scanning app here.
[00:51:33.700 --> 00:51:36.740]   I'll try and do this on the stream without reflection.
[00:51:36.740 --> 00:51:38.660]   I scan the QR code.
[00:51:38.660 --> 00:51:40.420]   Come on, grab it.
[00:51:40.420 --> 00:51:41.420]   You got it.
[00:51:41.420 --> 00:51:42.420]   Grab it.
[00:51:42.420 --> 00:51:44.340]   My scanner's not working, apparently.
[00:51:44.340 --> 00:51:46.500]   Let me try this again.
[00:51:46.500 --> 00:51:47.500]   It's the scanner.
[00:51:47.500 --> 00:51:49.100]   To be honest, there's a million of these.
[00:51:49.100 --> 00:51:50.700]   There we go.
[00:51:50.700 --> 00:51:54.420]   And it's going to pull it up on Google Maps to show you exactly where this coffee came
[00:51:54.420 --> 00:51:55.420]   from.
[00:51:55.420 --> 00:51:56.420]   Isn't that awesome?
[00:51:56.420 --> 00:52:01.300]   It launches a Google Earth satellite image of the exact farm where this coffee was born,
[00:52:01.300 --> 00:52:03.820]   where this coffee was brought to life.
[00:52:03.820 --> 00:52:06.420]   And you've got the awesome coffee inside.
[00:52:06.420 --> 00:52:08.540]   You can go ahead and unwrap this.
[00:52:08.540 --> 00:52:13.060]   I actually have to cut into it in order to get to the beans here, which I want to do
[00:52:13.060 --> 00:52:18.220]   because I really enjoy the waft of the smell of coffee.
[00:52:18.220 --> 00:52:21.140]   Apparently, I can't use scissors.
[00:52:21.140 --> 00:52:22.780]   There we go.
[00:52:22.780 --> 00:52:23.780]   Looking good in there.
[00:52:23.780 --> 00:52:24.780]   That smells awesome.
[00:52:24.780 --> 00:52:28.580]   There's a huge difference between drinking coffee that's been freshly roasted versus
[00:52:28.580 --> 00:52:32.460]   coffee that's been sitting on grocery shelves for weeks.
[00:52:32.460 --> 00:52:39.980]   Trace Pontes only uses 100% arabica beans, certified non-GMO and certified kosher,
[00:52:39.980 --> 00:52:46.380]   picked by hand, roasted by hand in small batches, pulped natural, processed naturally.
[00:52:46.380 --> 00:52:47.900]   It's not washed.
[00:52:47.900 --> 00:52:52.380]   And then you'll get freshly roasted beans sent to every one, every two or four weeks.
[00:52:52.380 --> 00:52:59.660]   You can get on a shipping schedule, 12-ounce bags in both whole and ground coffee.
[00:52:59.660 --> 00:53:02.180]   Personally, you probably want to get whole and then ground it yourself.
[00:53:02.180 --> 00:53:03.940]   That's how you keep it as fresh as possible.
[00:53:03.940 --> 00:53:07.460]   Light, medium, dark and French roast and free shipping in the US.
[00:53:07.460 --> 00:53:09.540]   I've been drinking it throughout the course of this show.
[00:53:09.540 --> 00:53:10.540]   It's just great coffee.
[00:53:10.540 --> 00:53:11.540]   You've got to check it out.
[00:53:11.540 --> 00:53:13.380]   Sign up for a subscription.
[00:53:13.380 --> 00:53:17.500]   You can save 10% off every bag of coffee.
[00:53:17.500 --> 00:53:24.860]   More listeners here on this week in Google get an extra 10% off when you visit tracepontes.com/twig
[00:53:24.860 --> 00:53:27.180]   and use the code twig, TWIG.
[00:53:27.180 --> 00:53:32.060]   This means you get a total of 20% off every bag of coffee in your subscription.
[00:53:32.060 --> 00:53:33.060]   And don't forget about mom.
[00:53:33.060 --> 00:53:36.180]   This is actually a perfect Mother's Day gift.
[00:53:36.180 --> 00:53:38.700]   Mother's Day is right around the corner a couple of weeks away.
[00:53:38.700 --> 00:53:43.060]   Freshly roasted coffee subscription makes a great gift for Mother's Day.
[00:53:43.060 --> 00:53:44.060]   Send her the gift of coffee.
[00:53:44.060 --> 00:53:46.700]   I think she'd probably appreciate that.
[00:53:46.700 --> 00:53:53.660]   You can also order on Amazon, but you'll only get the 20% off every bag of coffee in your
[00:53:53.660 --> 00:54:01.180]   subscription when you visit tracepontes.com/twig and use the code TWIG and we thank tracepontes
[00:54:01.180 --> 00:54:02.260]   for their support.
[00:54:02.260 --> 00:54:05.020]   I thank them for waking me up every single morning.
[00:54:05.020 --> 00:54:07.860]   It's really great and you should check it out.
[00:54:07.860 --> 00:54:10.220]   All right, Google News.
[00:54:10.220 --> 00:54:13.660]   We are almost Google I/O Eve.
[00:54:13.660 --> 00:54:17.660]   It starts a little bit earlier this year instead of starting on a Wednesday, it starts next
[00:54:17.660 --> 00:54:20.580]   Tuesday morning with a keynote.
[00:54:20.580 --> 00:54:25.820]   And I don't know, it's right around the corner of those of us on this show who will be roaming
[00:54:25.820 --> 00:54:29.340]   the fields of Shoreline Amphitheater.
[00:54:29.340 --> 00:54:32.380]   50% can't hear you.
[00:54:32.380 --> 00:54:34.020]   Do you have them muted?
[00:54:34.020 --> 00:54:35.020]   That's right.
[00:54:35.020 --> 00:54:36.020]   We had you muted.
[00:54:36.020 --> 00:54:37.020]   Sorry about that.
[00:54:37.020 --> 00:54:38.020]   Okay.
[00:54:38.020 --> 00:54:39.020]   Not me.
[00:54:39.020 --> 00:54:40.020]   No.
[00:54:40.020 --> 00:54:41.020]   No.
[00:54:41.020 --> 00:54:42.020]   Okay.
[00:54:42.020 --> 00:54:45.660]   We are roaming the fields of Microsoft to build at the ACI.
[00:54:45.660 --> 00:54:46.660]   Oh, right.
[00:54:46.660 --> 00:54:51.180]   Because there's kind of a big keynote collision going on.
[00:54:51.180 --> 00:54:52.180]   Yes.
[00:54:52.180 --> 00:54:57.340]   So, Jason, you know whether you and I can join into the afternoon TWIG from there?
[00:54:57.340 --> 00:54:58.340]   That's a good question.
[00:54:58.340 --> 00:54:59.340]   I think TWIG, is it shifting?
[00:54:59.340 --> 00:55:01.340]   We're going to do it on Tuesday.
[00:55:01.340 --> 00:55:03.340]   I mean, TWIG, I thought we're going to shift to Tuesday.
[00:55:03.340 --> 00:55:04.340]   We are.
[00:55:04.340 --> 00:55:06.580]   We do it from, can we do it from the...
[00:55:06.580 --> 00:55:07.580]   Okay.
[00:55:07.580 --> 00:55:08.580]   Yes, Carson is yelling at me.
[00:55:08.580 --> 00:55:09.580]   Yes.
[00:55:09.580 --> 00:55:10.580]   Oh, good.
[00:55:10.580 --> 00:55:11.580]   Yes.
[00:55:11.580 --> 00:55:14.540]   I love everybody who's watching this show now when we're actually going to have it because
[00:55:14.540 --> 00:55:15.540]   I'm curious too.
[00:55:15.540 --> 00:55:16.540]   Yeah.
[00:55:16.540 --> 00:55:17.540]   So we're having that on to...
[00:55:17.540 --> 00:55:20.900]   Yeah, Tuesday, I should have prepared this because I'm not remembering it off the top
[00:55:20.900 --> 00:55:21.900]   of my head.
[00:55:21.900 --> 00:55:22.900]   Do you have...
[00:55:22.900 --> 00:55:23.900]   Sometimes I'm after the keynote.
[00:55:23.900 --> 00:55:24.900]   There we go.
[00:55:24.900 --> 00:55:25.900]   Carson says Tuesday at 11.30.
[00:55:25.900 --> 00:55:26.900]   Thank you, Carson.
[00:55:26.900 --> 00:55:27.900]   11.30.
[00:55:27.900 --> 00:55:28.900]   11.30.
[00:55:28.900 --> 00:55:29.900]   Pacific.
[00:55:29.900 --> 00:55:30.900]   They won't be done early.
[00:55:30.900 --> 00:55:31.900]   Oh, the keynote is.
[00:55:31.900 --> 00:55:32.900]   When the keynote is so...
[00:55:32.900 --> 00:55:33.900]   Oh, I see.
[00:55:33.900 --> 00:55:34.900]   Oh, I see.
[00:55:34.900 --> 00:55:36.460]   Immediately following the keynote.
[00:55:36.460 --> 00:55:37.460]   We'll be at the end of the keynote.
[00:55:37.460 --> 00:55:39.460]   As soon as we can get our act together after the keynote.
[00:55:39.460 --> 00:55:40.460]   Okay.
[00:55:40.460 --> 00:55:41.460]   Okay.
[00:55:41.460 --> 00:55:46.100]   Yeah, because the keynote starts at like nine or something like that that morning.
[00:55:46.100 --> 00:55:47.740]   It's going to extend as long as it does.
[00:55:47.740 --> 00:55:51.980]   We are going to have live coverage on the Twit network of the keynote.
[00:55:51.980 --> 00:55:53.700]   Stacy, you're going to be there for that?
[00:55:53.700 --> 00:55:54.700]   Mm.
[00:55:54.700 --> 00:55:56.700]   No, I am at Build.
[00:55:56.700 --> 00:55:57.700]   Okay, that's right.
[00:55:57.700 --> 00:55:58.700]   I'm going to be interviewing...
[00:55:58.700 --> 00:56:01.340]   I'm actually interviewing the creator of the Misty 2 personal robot.
[00:56:01.340 --> 00:56:02.340]   Woo!
[00:56:02.340 --> 00:56:03.340]   Oh.
[00:56:03.340 --> 00:56:04.500]   I'm excited.
[00:56:04.500 --> 00:56:06.100]   That launched today.
[00:56:06.100 --> 00:56:07.860]   I have not heard about the Misty 2.
[00:56:07.860 --> 00:56:08.860]   Oh.
[00:56:08.860 --> 00:56:09.860]   Can you look at it?
[00:56:09.860 --> 00:56:11.020]   It's way better than Misty 1.
[00:56:11.020 --> 00:56:17.900]   It's the electric boogaloo sequel.
[00:56:17.900 --> 00:56:22.220]   So Google I/O, we're definitely going to hear about Android P, the next version.
[00:56:22.220 --> 00:56:23.980]   We've got the developer preview one out.
[00:56:23.980 --> 00:56:29.500]   I'm still using it and I have to say, I mean, I'm using it on my daily phone.
[00:56:29.500 --> 00:56:32.580]   It's my Pixel 2 XL, no backup.
[00:56:32.580 --> 00:56:37.460]   And I've really encountered very few issues since they launched this developer preview.
[00:56:37.460 --> 00:56:40.020]   So it can only go up from here.
[00:56:40.020 --> 00:56:42.180]   And we'll hear more about that.
[00:56:42.180 --> 00:56:43.180]   We've got...
[00:56:43.180 --> 00:56:45.180]   Are you particularly good in it?
[00:56:45.180 --> 00:56:51.860]   In what we have right now, I mean, kind of the design touches are kind of nice.
[00:56:51.860 --> 00:56:55.780]   You got the little breakout volume, which I actually use a lot when I'm connected to
[00:56:55.780 --> 00:56:56.780]   Bluetooth.
[00:56:56.780 --> 00:56:59.980]   It breaks out and I can jump right into a Bluetooth connection.
[00:56:59.980 --> 00:57:03.660]   Sorry, let me move my coffee.
[00:57:03.660 --> 00:57:07.860]   But yeah, I mean, just in general, I'm enjoying it.
[00:57:07.860 --> 00:57:11.620]   Some of the stuff that they do in navigation, or sorry, in the notifications kind of grouping
[00:57:11.620 --> 00:57:13.380]   things is kind of nice.
[00:57:13.380 --> 00:57:17.860]   You've got a lot of the different design touches, you know, different changes that make it almost
[00:57:17.860 --> 00:57:22.020]   look a little like third party launcher stuff.
[00:57:22.020 --> 00:57:23.020]   But yeah, so far, so...
[00:57:23.020 --> 00:57:24.620]   So the material design?
[00:57:24.620 --> 00:57:28.780]   Well, yeah, I mean, that's going to be a big part of what we're going to find out.
[00:57:28.780 --> 00:57:34.380]   There's a lot of different redesigns, including the Gmail app or the Gmail desktop app that
[00:57:34.380 --> 00:57:37.220]   got its big design overhaul last week.
[00:57:37.220 --> 00:57:45.380]   That are showing a very consistent new UI style that's close to what we've expected from
[00:57:45.380 --> 00:57:51.380]   the legacy material design, but adding a bunch of new things like oblong, pill-shaped, fab
[00:57:51.380 --> 00:57:58.260]   buttons and very white, open layout, very particular type of font that matches the Google
[00:57:58.260 --> 00:57:59.860]   font, things like that.
[00:57:59.860 --> 00:58:03.500]   So I have a feeling we're going to see a lot and also an explanation around what material
[00:58:03.500 --> 00:58:10.140]   design the sequel is and kind of how developers can use that.
[00:58:10.140 --> 00:58:12.940]   So can I ask you a public service question, Jason Hill?
[00:58:12.940 --> 00:58:13.940]   Sure.
[00:58:13.940 --> 00:58:19.180]   How do I get the new Gmail design on my Google apps account?
[00:58:19.180 --> 00:58:21.380]   Google apps account.
[00:58:21.380 --> 00:58:23.980]   Or when should I expect that?
[00:58:23.980 --> 00:58:27.380]   I've been like waiting for this and I'm like, "Rig it."
[00:58:27.380 --> 00:58:28.380]   Do you go into the setting?
[00:58:28.380 --> 00:58:32.820]   I don't know because I haven't tried it on my apps account, but can you go into Gmail
[00:58:32.820 --> 00:58:34.620]   and there's the little gear setting?
[00:58:34.620 --> 00:58:39.060]   If you go in there, if you have the ability to switch to it right now, there should be
[00:58:39.060 --> 00:58:42.340]   a try the new layout or the new UI.
[00:58:42.340 --> 00:58:44.140]   Yeah, not on apps.
[00:58:44.140 --> 00:58:45.260]   And I have no fault.
[00:58:45.260 --> 00:58:46.260]   And I--
[00:58:46.260 --> 00:58:47.420]   Slowly I turn.
[00:58:47.420 --> 00:58:52.580]   From what I understand, it was either tasks or it was Gmail, but from what I understand,
[00:58:52.580 --> 00:58:57.780]   they made this available to apps users is just that the administrator needs to allow for
[00:58:57.780 --> 00:59:00.060]   it prior to you getting access to it.
[00:59:00.060 --> 00:59:01.580]   I am the administrator.
[00:59:01.580 --> 00:59:03.820]   OK, then it might be tasks and not Gmail.
[00:59:03.820 --> 00:59:04.820]   No, Stacey.
[00:59:04.820 --> 00:59:05.820]   No.
[00:59:05.820 --> 00:59:08.180]   It's the problem I go through with Chrome OS.
[00:59:08.180 --> 00:59:10.660]   No, don't tell me that this is the same problem.
[00:59:10.660 --> 00:59:11.980]   I refuse to hear it, Jeff.
[00:59:11.980 --> 00:59:13.300]   I will get off apps.
[00:59:13.300 --> 00:59:14.300]   I'm going to--
[00:59:14.300 --> 00:59:15.700]   And find-- I need another--
[00:59:15.700 --> 00:59:16.700]   I'm going to bet.
[00:59:16.700 --> 00:59:17.980]   It's the same problem.
[00:59:17.980 --> 00:59:19.460]   Ah.
[00:59:19.460 --> 00:59:20.900]   Administrator writes.
[00:59:20.900 --> 00:59:23.780]   OK, I'm just going to give up-- I'm giving up on Google apps.
[00:59:23.780 --> 00:59:24.980]   I really am.
[00:59:24.980 --> 00:59:26.100]   I'm sick of this.
[00:59:26.100 --> 00:59:31.460]   I want my email from work to work with all of my Google stuff in a dozen.
[00:59:31.460 --> 00:59:33.060]   Newman.
[00:59:33.060 --> 00:59:35.540]   That doesn't feel like a lot to ask.
[00:59:35.540 --> 00:59:36.300]   Yeah.
[00:59:36.300 --> 00:59:37.060]   Well, in a keypad.
[00:59:37.060 --> 00:59:38.340]   A lot to ask.
[00:59:38.340 --> 00:59:42.140]   I'm sure it's on someone's to-do list to fix.
[00:59:42.140 --> 00:59:43.300]   What is Jeff doing?
[00:59:43.300 --> 00:59:44.060]   What happened?
[00:59:44.060 --> 00:59:46.620]   Jeff, did you just go portrait?
[00:59:46.620 --> 00:59:47.180]   Jeff, what?
[00:59:47.180 --> 00:59:47.700]   Yes.
[00:59:47.700 --> 00:59:48.300]   And I don't know how.
[00:59:48.300 --> 00:59:49.380]   No, I can't get back.
[00:59:49.380 --> 00:59:50.340]   I'm going to have to--
[00:59:50.340 --> 00:59:53.020]   Portrait is the new landscape.
[00:59:53.020 --> 00:59:56.020]   You're such a portrait rebel that you do portrait, but sideways.
[00:59:56.020 --> 00:59:58.820]   Jeff, now you need to lay down to do the show.
[00:59:58.820 --> 01:00:00.380]   It feels fine.
[01:00:00.380 --> 01:00:02.140]   I'm going to rotate the monitor.
[01:00:02.140 --> 01:00:04.500]   All right, Jeff, you go ahead and give us a call back.
[01:00:04.500 --> 01:00:05.500]   Maybe that'll fix the browser.
[01:00:05.500 --> 01:00:07.500]   OK, well, do.
[01:00:07.500 --> 01:00:10.300]   Some of the other things, apparently,
[01:00:10.300 --> 01:00:15.620]   Assistant Slices, which is a way to bring app functions into notifications.
[01:00:15.620 --> 01:00:21.220]   Similar to smart replies, how those have started to appear in notifications.
[01:00:21.220 --> 01:00:24.980]   And I can't remember if that's an Android P thing or if that's also on earlier versions.
[01:00:24.980 --> 01:00:29.100]   But Slices would bring other functionality from apps into theirs
[01:00:29.100 --> 01:00:34.060]   that you don't have to go into the app and waste all that valuable time of yours doing that.
[01:00:34.060 --> 01:00:35.620]   So I just noticed something else.
[01:00:35.620 --> 01:00:40.140]   So the reason I went sideways is because I was signing into my other account
[01:00:40.140 --> 01:00:43.220]   and it was asking me to verify and I'm on my tablet.
[01:00:43.220 --> 01:00:44.900]   So it was doing an Android thing.
[01:00:44.900 --> 01:00:45.100]   Right.
[01:00:45.100 --> 01:00:46.020]   Sorry.
[01:00:46.020 --> 01:00:50.620]   So I'm in my other-- my Gmail account on inbox.
[01:00:50.620 --> 01:00:52.540]   It has lost the switch.
[01:00:52.540 --> 01:00:56.580]   It's lost the switch to Gmail button.
[01:00:56.580 --> 01:00:57.420]   It ain't there.
[01:00:57.420 --> 01:00:58.660]   Here, do you find that?
[01:00:58.660 --> 01:01:00.100]   I feel like I went deep.
[01:01:00.100 --> 01:01:02.700]   On the left column.
[01:01:02.700 --> 01:01:06.540]   Yeah, I feel like I went digging one time for that and I was able to find it.
[01:01:06.540 --> 01:01:08.860]   Oh, but I can just go to GV.com.
[01:01:08.860 --> 01:01:12.620]   Go to-- OK, inbox side-- left side panel, go to the bottom.
[01:01:12.620 --> 01:01:13.660]   There's the Settings button.
[01:01:13.660 --> 01:01:15.100]   Click that.
[01:01:15.100 --> 01:01:16.940]   And then go into Other.
[01:01:16.940 --> 01:01:21.540]   And you will probably find redirect Gmail to inbox.google.com.
[01:01:21.540 --> 01:01:22.300]   Checked.
[01:01:22.300 --> 01:01:22.980]   Uncheck that.
[01:01:22.980 --> 01:01:26.140]   First, I have a wizard with a sword and a bucket in front of me.
[01:01:26.140 --> 01:01:28.060]   I had to figure out how to get through.
[01:01:28.060 --> 01:01:29.300]   Sorry.
[01:01:29.300 --> 01:01:30.860]   Oh, lucky you, you found the wizard.
[01:01:30.860 --> 01:01:32.180]   Where are the dragon?
[01:01:32.180 --> 01:01:34.100]   Where are the dragon?
[01:01:34.100 --> 01:01:38.460]   I've been looking for the wizard for so long and you just happened upon the wizard.
[01:01:38.460 --> 01:01:41.620]   So Stacey, I can't get to on my apps account.
[01:01:41.620 --> 01:01:42.500]   I can't get to it either.
[01:01:42.500 --> 01:01:44.460]   And God knows how we're going to get to it.
[01:01:44.460 --> 01:01:46.180]   Oh.
[01:01:46.180 --> 01:01:46.980]   Well, that's disappointing.
[01:01:46.980 --> 01:01:50.980]   You don't want to say, you see, it's just telling you you should use inbox.
[01:01:50.980 --> 01:01:55.780]   OK, well, no, I'm going to go back to my admin console and see if I can do it.
[01:01:55.780 --> 01:01:58.340]   Because I've got it on my personal thing.
[01:01:58.340 --> 01:02:00.060]   And I love the calendar feature.
[01:02:00.060 --> 01:02:00.740]   Yeah, I know.
[01:02:00.740 --> 01:02:02.220]   You'll probably talk about this last week.
[01:02:02.220 --> 01:02:03.740]   But I'm just like--
[01:02:03.740 --> 01:02:04.620]   Embedded calendar.
[01:02:04.620 --> 01:02:06.020]   And there is nice.
[01:02:06.020 --> 01:02:07.020]   I agree.
[01:02:07.020 --> 01:02:12.780]   It makes it more like outlook of like 10 years ago, which is actually was like the definitively
[01:02:12.780 --> 01:02:15.100]   awesome professional email program.
[01:02:15.100 --> 01:02:16.060]   Come at me, guys.
[01:02:16.060 --> 01:02:16.780]   Come at me.
[01:02:16.780 --> 01:02:17.980]   I will not lie.
[01:02:17.980 --> 01:02:19.220]   It was amazing.
[01:02:19.220 --> 01:02:19.780]   All right.
[01:02:19.780 --> 01:02:22.340]   That's it.
[01:02:22.340 --> 01:02:24.420]   Well, I hope that you are able to get access.
[01:02:24.420 --> 01:02:26.580]   Just agree to the new Gmail.
[01:02:26.580 --> 01:02:32.220]   Although in my week of using both of them, like I'm basically just using inbox still.
[01:02:32.220 --> 01:02:35.780]   Like it's hard for me to switch over to Gmail, even with all the changes.
[01:02:35.780 --> 01:02:36.780]   It's nice.
[01:02:36.780 --> 01:02:39.860]   But it's just I'm so used to inbox.
[01:02:39.860 --> 01:02:43.580]   Apparently, we're going to see-- or I'm guessing smart displays.
[01:02:43.580 --> 01:02:45.580]   We've been hearing about these for a little while.
[01:02:45.580 --> 01:02:46.580]   You know, this--
[01:02:46.580 --> 01:02:47.580]   I can't wait to buy it.
[01:02:47.580 --> 01:02:48.580]   Yeah.
[01:02:48.580 --> 01:02:52.620]   I am ready to shell out money for one of these.
[01:02:52.620 --> 01:02:54.260]   That is what I have to tell you guys.
[01:02:54.260 --> 01:02:58.700]   After CES, it's like the Amazon Echo Show.
[01:02:58.700 --> 01:02:59.700]   Oh, yeah.
[01:02:59.700 --> 01:03:00.700]   Or I hear a little fuck.
[01:03:00.700 --> 01:03:03.540]   So it's like they do a home of the screen, essentially.
[01:03:03.540 --> 01:03:04.540]   Face time.
[01:03:04.540 --> 01:03:05.980]   That's cheap enough they might give us one.
[01:03:05.980 --> 01:03:06.980]   I don't know.
[01:03:06.980 --> 01:03:13.420]   There's-- I mean, they're like two-- I think the Lenovo had a bit-- the big one was 200.
[01:03:13.420 --> 01:03:16.100]   I think the smaller one was 150.
[01:03:16.100 --> 01:03:17.460]   So I would love that.
[01:03:17.460 --> 01:03:22.540]   I mean, because right now you can get some interesting functionality through your Chromecast
[01:03:22.540 --> 01:03:28.980]   with your Google Nest Cam or your Nest Hello doorbell.
[01:03:28.980 --> 01:03:33.540]   But having kind of a screen, you can just go to and see, I cannot wait.
[01:03:33.540 --> 01:03:34.540]   So--
[01:03:34.540 --> 01:03:39.180]   Our technique says it's probably not coming in time for I/O.
[01:03:39.180 --> 01:03:41.460]   Well, so here's-- yeah, and I saw that.
[01:03:41.460 --> 01:03:44.580]   Ronam audio has a really great walkthrough.
[01:03:44.580 --> 01:03:46.300]   Hey, don't shoot the messenger.
[01:03:46.300 --> 01:03:47.780]   You're a part of the bird.
[01:03:47.780 --> 01:03:49.420]   Yeah, shoot Ronam audio.
[01:03:49.420 --> 01:03:50.740]   He's the one to say in that.
[01:03:50.740 --> 01:03:51.580]   This is fault.
[01:03:51.580 --> 01:03:52.980]   It's a really great walkthrough.
[01:03:52.980 --> 01:03:58.260]   What I wonder is that maybe we will see it to some degree, not that it would be released
[01:03:58.260 --> 01:04:02.500]   there, but maybe we will see it to some degree because apparently these smart displays in
[01:04:02.500 --> 01:04:10.140]   that platform relies on Android things-- Android things, by the way-- two years in on the developer
[01:04:10.140 --> 01:04:12.980]   preview still has not had an official release.
[01:04:12.980 --> 01:04:17.420]   There's eight sessions of Android things at Google I/O this year, which makes you wonder,
[01:04:17.420 --> 01:04:21.820]   OK, so are they focusing more on it because there will be a big, major release?
[01:04:21.820 --> 01:04:24.780]   And if these are based on that, we already know they exist.
[01:04:24.780 --> 01:04:26.340]   They showed them off at CES.
[01:04:26.340 --> 01:04:28.420]   Like maybe this is the coming out party.
[01:04:28.420 --> 01:04:29.420]   We might get a date.
[01:04:29.420 --> 01:04:29.940]   Yeah.
[01:04:29.940 --> 01:04:30.620]   Or they'll show them.
[01:04:30.620 --> 01:04:30.940]   Right.
[01:04:30.940 --> 01:04:31.980]   Yeah, yeah, yeah, totally.
[01:04:31.980 --> 01:04:32.500]   Let you play with it.
[01:04:32.500 --> 01:04:34.820]   Kevin and I are hopeful.
[01:04:34.820 --> 01:04:38.780]   I actually wanted to send Kevin to I/O just so he could attend these and try to figure
[01:04:38.780 --> 01:04:40.500]   out what the heck is happening.
[01:04:40.500 --> 01:04:44.580]   Part of it is probably tied up in the Nest Reorg is my hunch.
[01:04:44.580 --> 01:04:45.340]   Yeah.
[01:04:45.340 --> 01:04:45.820]   So--
[01:04:45.820 --> 01:04:46.660]   That's a little messy and comfortable.
[01:04:46.660 --> 01:04:48.460]   It's a little messy and complicated, for sure.
[01:04:48.460 --> 01:04:49.460]   [LAUGHTER]
[01:04:49.460 --> 01:04:54.060]   We also mentioned-- Ron mentions a mid-range Pixel phone.
[01:04:54.060 --> 01:04:55.060]   That would be interesting.
[01:04:55.060 --> 01:04:59.140]   Well, and that's a rumor that we've been hearing, is that there's a potential-- potentially
[01:04:59.140 --> 01:05:00.300]   a mid-range Pixel.
[01:05:00.300 --> 01:05:03.340]   I just don't see I/O as the place where they do that.
[01:05:03.340 --> 01:05:07.500]   Like, it seems like their hardware announcements from the smartphone side of things is usually
[01:05:07.500 --> 01:05:10.980]   left to near the end of the year on a October-ish time frame.
[01:05:10.980 --> 01:05:13.180]   Maybe we hear about it.
[01:05:13.180 --> 01:05:17.060]   I really doubt that they would release anything then.
[01:05:17.060 --> 01:05:22.260]   But maybe we hear about those efforts.
[01:05:22.260 --> 01:05:29.820]   Flutter SDK/Fuchsia, they're experimental operating system that we keep hearing about
[01:05:29.820 --> 01:05:33.020]   little pieces of information over the course of the last couple of years.
[01:05:33.020 --> 01:05:36.060]   Everybody scratching their head wondering, what is Fuchsia?
[01:05:36.060 --> 01:05:41.700]   Is this the buildup of a replacement for Android or for Chrome OS?
[01:05:41.700 --> 01:05:44.860]   Apparently, what did I see?
[01:05:44.860 --> 01:05:50.740]   Art, Android runtime, they've built Fuchsia with ART support.
[01:05:50.740 --> 01:05:54.220]   So that suggests Android app support on Fuchsia.
[01:05:54.220 --> 01:05:55.580]   So it's very confusing.
[01:05:55.580 --> 01:05:59.420]   I think this time last year, we were also thinking, we're going to hear about Fuchsia
[01:05:59.420 --> 01:06:00.860]   at Google I/O, and that didn't happen.
[01:06:00.860 --> 01:06:02.420]   So it's probably not going to happen this year either.
[01:06:02.420 --> 01:06:03.980]   We're probably a few years out on app.
[01:06:03.980 --> 01:06:05.340]   Are they trying to get off Linux?
[01:06:05.340 --> 01:06:07.100]   Or do they want to have their own--
[01:06:07.100 --> 01:06:08.620]   That's a good question.
[01:06:08.620 --> 01:06:09.780]   No one really knows.
[01:06:09.780 --> 01:06:12.660]   But they know this exists in Google.
[01:06:12.660 --> 01:06:16.380]   I mean, somebody installed it on a Pixelbook not too long ago.
[01:06:16.380 --> 01:06:20.340]   So it exists is just not 100%.
[01:06:20.340 --> 01:06:22.900]   I'll say this.
[01:06:22.900 --> 01:06:26.860]   So I'm talking to you right now on my tablet, which being an Android device works really
[01:06:26.860 --> 01:06:28.860]   well across lots of things.
[01:06:28.860 --> 01:06:32.860]   On Android on Chrome, still ain't there.
[01:06:32.860 --> 01:06:37.660]   By Netflix and Showtime and that kind of stuff doesn't really work.
[01:06:37.660 --> 01:06:38.940]   Some other stuff doesn't really work.
[01:06:38.940 --> 01:06:40.820]   It's really rough.
[01:06:40.820 --> 01:06:47.700]   They do need, I hope, an integrated operating system across all possible platforms.
[01:06:47.700 --> 01:06:49.860]   And I'm guessing that's what they're trying to do.
[01:06:49.860 --> 01:06:53.740]   They're just trying to start to explore that because they know how complex it is and how
[01:06:53.740 --> 01:06:55.980]   much retrofitting would be needed.
[01:06:55.980 --> 01:07:02.180]   But what that frees up in the future to not be to have a wall between platforms or to
[01:07:02.180 --> 01:07:03.180]   have this clue.
[01:07:03.180 --> 01:07:05.460]   It's a clever clue, and they do a pretty good job with it.
[01:07:05.460 --> 01:07:10.620]   But it is far from fault trees.
[01:07:10.620 --> 01:07:12.340]   And this kind of interesting.
[01:07:12.340 --> 01:07:16.020]   Flutter SDK is the app platform for Fuchsia.
[01:07:16.020 --> 01:07:20.380]   There are six sessions devoted to the Flutter SDK at Google I/O.
[01:07:20.380 --> 01:07:27.260]   And Flutter SDK, from what I understand, is more or less, you know, it's obviously an
[01:07:27.260 --> 01:07:32.860]   SDK for developers, but it's really geared for writing something one time and having it
[01:07:32.860 --> 01:07:38.140]   appear on both Android and iOS, probably doing a horrible job describing that.
[01:07:38.140 --> 01:07:44.460]   But this idea of building one thing and having it be compatible with multiple systems, including,
[01:07:44.460 --> 01:07:49.940]   in this case, the Fuchsia operating system, RONOM audio in ours, and it pointed out, maybe
[01:07:49.940 --> 01:07:54.420]   this is laying the groundwork for a big transition that happens somewhere down the line, maybe
[01:07:54.420 --> 01:07:56.300]   2020, 2021.
[01:07:56.300 --> 01:08:00.260]   And this is a really great way to get developers kind of working on that now so that when that
[01:08:00.260 --> 01:08:04.500]   transition happens, there's support for it.
[01:08:04.500 --> 01:08:07.780]   But that's a lot of guessing.
[01:08:07.780 --> 01:08:09.340]   So we'll see what happens there.
[01:08:09.340 --> 01:08:15.540]   Did you see, sorry, someone in the chat room mentioned that someone at Google is working
[01:08:15.540 --> 01:08:17.380]   on a social gaming startup?
[01:08:17.380 --> 01:08:18.540]   Did you see that?
[01:08:18.540 --> 01:08:19.540]   Yes.
[01:08:19.540 --> 01:08:20.540]   Absolutely.
[01:08:20.540 --> 01:08:21.540]   That's interesting.
[01:08:21.540 --> 01:08:24.900]   That actually seemed to drop shortly before showtime.
[01:08:24.900 --> 01:08:30.420]   A start up, a gaming startup call, and they're working on an, I don't know if it's the app
[01:08:30.420 --> 01:08:31.780]   or the division is called Arcade.
[01:08:31.780 --> 01:08:34.380]   I think it's the division called Arcade.
[01:08:34.380 --> 01:08:38.660]   Led by Michael Salmon, who actually began at Facebook as an intern at 17 years old.
[01:08:38.660 --> 01:08:40.540]   He's now 21 years old.
[01:08:40.540 --> 01:08:42.460]   So you know, he's all grown up.
[01:08:42.460 --> 01:08:45.420]   He moved on to Google and he's working.
[01:08:45.420 --> 01:08:46.660]   See your executive.
[01:08:46.660 --> 01:08:48.380]   Yes, exactly.
[01:08:48.380 --> 01:08:53.460]   Working as part of Area 120, which is one of their experimental divisions on this like
[01:08:53.460 --> 01:08:56.500]   social gaming startup.
[01:08:56.500 --> 01:09:01.900]   Their initial app is a trivia app that's slated for this summer sometime.
[01:09:01.900 --> 01:09:03.380]   It seems like a natural way to go.
[01:09:03.380 --> 01:09:08.060]   I mean, I see, you know, even things like Word with friends, words with friends, lots
[01:09:08.060 --> 01:09:11.780]   of people are obsessed with games like that, playing them socially.
[01:09:11.780 --> 01:09:17.300]   It seems like a natural area for, particularly for Facebook, but also for Google.
[01:09:17.300 --> 01:09:18.300]   Yeah.
[01:09:18.300 --> 01:09:22.860]   I mean, you know, we could go for another Farmville, a social gaming.
[01:09:22.860 --> 01:09:23.860]   Yeah.
[01:09:23.860 --> 01:09:24.860]   Experience.
[01:09:24.860 --> 01:09:25.860]   Fortnite.
[01:09:25.860 --> 01:09:26.860]   Fortnite.
[01:09:26.860 --> 01:09:27.860]   Fortnite.
[01:09:27.860 --> 01:09:28.860]   Yeah.
[01:09:28.860 --> 01:09:30.860]   That's probably more like it.
[01:09:30.860 --> 01:09:32.060]   But yeah, that's cool.
[01:09:32.060 --> 01:09:35.340]   We also, let's see here what else Android Auto.
[01:09:35.340 --> 01:09:39.100]   There's some, you know, information in the rundown that shows that they're going to
[01:09:39.100 --> 01:09:44.340]   be showing off Android Auto and some sort of a new media experience in Android Auto.
[01:09:44.340 --> 01:09:46.100]   Who knows what that means.
[01:09:46.100 --> 01:09:52.580]   I hope we find out about chat, which is the RCS, the universal profile powered kind of
[01:09:52.580 --> 01:09:55.260]   chat thing that we talk about.
[01:09:55.260 --> 01:09:57.780]   Wait, Google killed, what did it kill?
[01:09:57.780 --> 01:09:58.980]   Last week it killed something.
[01:09:58.980 --> 01:09:59.980]   Aloe.
[01:09:59.980 --> 01:10:00.980]   Aloe, yeah.
[01:10:00.980 --> 01:10:01.980]   It was Aloe.
[01:10:01.980 --> 01:10:03.820]   It didn't actually kill it.
[01:10:03.820 --> 01:10:04.820]   Right.
[01:10:04.820 --> 01:10:06.300]   But I mean, it's not going anywhere anymore.
[01:10:06.300 --> 01:10:10.380]   They took all the people working on it and redirected them to chat.
[01:10:10.380 --> 01:10:11.380]   Okay.
[01:10:11.380 --> 01:10:13.460]   So it still technically exists.
[01:10:13.460 --> 01:10:18.100]   I just have to know which of the eight Google messaging things I can do for my phone.
[01:10:18.100 --> 01:10:19.100]   Yes.
[01:10:19.100 --> 01:10:21.380]   Remember Hangouts was going to be sunsetted.
[01:10:21.380 --> 01:10:23.260]   And then all of a sudden it still wasn't.
[01:10:23.260 --> 01:10:24.260]   Yeah.
[01:10:24.260 --> 01:10:25.260]   I love Hangouts.
[01:10:25.260 --> 01:10:27.500]   I'm going to be so sad when that goes away.
[01:10:27.500 --> 01:10:30.660]   But is it going to go away or will it just continue but not be supported?
[01:10:30.660 --> 01:10:31.660]   I don't know.
[01:10:31.660 --> 01:10:34.180]   They will all continue and not be supported.
[01:10:34.180 --> 01:10:37.580]   That's just kind of the way it goes apparently.
[01:10:37.580 --> 01:10:41.780]   Me looking at the schedule, it is going back to its roots.
[01:10:41.780 --> 01:10:42.780]   It's very developer.
[01:10:42.780 --> 01:10:45.500]   They've got some of our dumb outsides in the past.
[01:10:45.500 --> 01:10:47.700]   This is purely for developers, which is good.
[01:10:47.700 --> 01:10:49.260]   I love that.
[01:10:49.260 --> 01:10:52.020]   I love the developer sessions.
[01:10:52.020 --> 01:10:55.580]   I think they're so rich in content and I don't know.
[01:10:55.580 --> 01:10:56.580]   I just I love it.
[01:10:56.580 --> 01:10:58.380]   I hate when they get all normal for people.
[01:10:58.380 --> 01:11:00.580]   I'm like, you can just put it in.
[01:11:00.580 --> 01:11:01.580]   Nodles.
[01:11:01.580 --> 01:11:03.820]   Who wants noodles at IO?
[01:11:03.820 --> 01:11:07.980]   For anyone paying for the conference, I mean, what is the value proposition for someone
[01:11:07.980 --> 01:11:12.260]   to drop in and be, you know, and sit through a product announcement?
[01:11:12.260 --> 01:11:13.900]   Like it really doesn't make a whole lot of sense.
[01:11:13.900 --> 01:11:18.500]   They go there because they want to walk away with a leg up over everyone else that wasn't
[01:11:18.500 --> 01:11:19.500]   there.
[01:11:19.500 --> 01:11:20.500]   That's why you go.
[01:11:20.500 --> 01:11:21.500]   They wouldn't drop in, Jason.
[01:11:21.500 --> 01:11:22.500]   They would hang out.
[01:11:22.500 --> 01:11:23.500]   Oh.
[01:11:23.500 --> 01:11:27.020]   Drop in belongs to the Amazon ecosystem now.
[01:11:27.020 --> 01:11:30.100]   Dang, I'm getting my ecosystems confused.
[01:11:30.100 --> 01:11:31.100]   I apologize.
[01:11:31.100 --> 01:11:32.100]   Yeah.
[01:11:32.100 --> 01:11:33.100]   I don't know.
[01:11:33.100 --> 01:11:39.420]   Is there anything that you guys are hoping that you see at IO outside of this stuff now?
[01:11:39.420 --> 01:11:41.420]   I'm like, I want the screen.
[01:11:41.420 --> 01:11:44.660]   I would like I mean, I would like the update on Android things.
[01:11:44.660 --> 01:11:48.420]   I would like actually to see a little bit more on Weave.
[01:11:48.420 --> 01:11:50.820]   But that's just my IOT self speaking.
[01:11:50.820 --> 01:11:52.820]   But yeah.
[01:11:52.820 --> 01:11:53.820]   Yeah.
[01:11:53.820 --> 01:11:57.420]   We're hearing, gosh, I thought I muted you.
[01:11:57.420 --> 01:12:02.300]   We're hearing a couple of other things because Google, this is like the pre IO time period
[01:12:02.300 --> 01:12:04.900]   where Google's like, yeah, we got to get this out before IO.
[01:12:04.900 --> 01:12:09.380]   So that we have something to refer to and be like, last week we told you about we're
[01:12:09.380 --> 01:12:15.420]   getting those now starting with Google who's investing in early stage startups that are
[01:12:15.420 --> 01:12:19.460]   focused on integrating assistant into the business.
[01:12:19.460 --> 01:12:25.540]   They're providing not only money, but support early access to features, tools, Google Cloud
[01:12:25.540 --> 01:12:33.500]   platform access, Google marketing and developers can sign up via a forum if you're interested.
[01:12:33.500 --> 01:12:38.460]   They're targeting this at startups that are at a stage where this money actually makes
[01:12:38.460 --> 01:12:39.460]   a difference.
[01:12:39.460 --> 01:12:47.060]   So not looking to do this sort of a partnership with the really big, big companies out there.
[01:12:47.060 --> 01:12:52.180]   I noticed that I don't know if this is in the rundown, but someone again in the chat
[01:12:52.180 --> 01:13:01.700]   room posted that Google's working on transcription of podcasts so that they can index that information.
[01:13:01.700 --> 01:13:03.460]   That'd be hugely useful.
[01:13:03.460 --> 01:13:04.460]   Yeah.
[01:13:04.460 --> 01:13:10.660]   Awesome. Sorry, as a podcast person who I get transcripts of my guest interviews, not the
[01:13:10.660 --> 01:13:16.780]   whole thing, I'm a little concerned because Google has that now.
[01:13:16.780 --> 01:13:18.300]   I mean, I guess it's good for indexing.
[01:13:18.300 --> 01:13:19.300]   Never mind.
[01:13:19.300 --> 01:13:20.300]   It's only a good thing.
[01:13:20.300 --> 01:13:21.300]   I won't be.
[01:13:21.300 --> 01:13:24.340]   Why wouldn't it be good?
[01:13:24.340 --> 01:13:28.020]   Depending on how they use it or they're going to send it back to me, I really want, you
[01:13:28.020 --> 01:13:33.220]   know, my ultimate goal as quote unquote, a media company is to get people's email addresses
[01:13:33.220 --> 01:13:35.420]   so I know who's listening to me.
[01:13:35.420 --> 01:13:38.380]   Who is reading my content?
[01:13:38.380 --> 01:13:40.820]   The only way I can do that is to have people opt in.
[01:13:40.820 --> 01:13:44.100]   I mean, that's the only way I want to do it is to have people opt in.
[01:13:44.100 --> 01:13:45.660]   But let's put it this way.
[01:13:45.660 --> 01:13:51.380]   If I was searching for Internet of Things stuff, Google was indexing your podcast.
[01:13:51.380 --> 01:13:54.340]   Your podcast would come up and I would see it in my search.
[01:13:54.340 --> 01:13:55.540]   I'd be like, that's interesting.
[01:13:55.540 --> 01:13:58.500]   I should go sign up for that and listen to it.
[01:13:58.500 --> 01:13:59.500]   Yes.
[01:13:59.500 --> 01:14:04.100]   It is a good thing because I know, and this is why I started transcribing my guest interviews,
[01:14:04.100 --> 01:14:09.620]   is because a lot of stuff is set on the show that even news is broken on the show, but
[01:14:09.620 --> 01:14:11.860]   people don't realize it because they're so.
[01:14:11.860 --> 01:14:12.860]   Yeah.
[01:14:12.860 --> 01:14:13.860]   Yes.
[01:14:13.860 --> 01:14:14.860]   It's good.
[01:14:14.860 --> 01:14:16.900]   And I think if you don't, like I don't have as much time to listen to podcasts because
[01:14:16.900 --> 01:14:19.300]   I don't drive and I don't.
[01:14:19.300 --> 01:14:21.860]   Yeah, I never go, never leave my room.
[01:14:21.860 --> 01:14:27.100]   And I just don't have a time where I've kind of carved out that I can listen to podcasts.
[01:14:27.100 --> 01:14:32.500]   And I would love to, like the ones that do post transcriptions are hugely useful to
[01:14:32.500 --> 01:14:34.820]   me because I can skim them.
[01:14:34.820 --> 01:14:36.980]   Lots of them I go back to.
[01:14:36.980 --> 01:14:40.100]   That's the main way that I consume that type of content.
[01:14:40.100 --> 01:14:44.060]   So if it's not transcribed, I miss the whole thing basically.
[01:14:44.060 --> 01:14:47.500]   I think you ought to be doing podcasts on the boat.
[01:14:47.500 --> 01:14:48.500]   Matthew.
[01:14:48.500 --> 01:14:50.660]   The boat in the kayak.
[01:14:50.660 --> 01:14:52.300]   I think what can do?
[01:14:52.300 --> 01:14:53.300]   Can you do casks?
[01:14:53.300 --> 01:14:54.300]   I could do that.
[01:14:54.300 --> 01:14:55.900]   But usually I'm just listening to the birds.
[01:14:55.900 --> 01:14:56.900]   New cast for clinics.
[01:14:56.900 --> 01:15:02.380]   I should do a podcast in the kayak.
[01:15:02.380 --> 01:15:05.300]   I like the little Ripley water in the background.
[01:15:05.300 --> 01:15:06.300]   Yeah.
[01:15:06.300 --> 01:15:07.300]   Very peaceful.
[01:15:07.300 --> 01:15:10.420]   You have lunes of the lunes.
[01:15:10.420 --> 01:15:11.420]   Yeah.
[01:15:11.420 --> 01:15:12.420]   Oh yeah.
[01:15:12.420 --> 01:15:13.420]   Of course they have lunes.
[01:15:13.420 --> 01:15:14.420]   It's Canada.
[01:15:14.420 --> 01:15:22.220]   They would, it would be noisy interrupting a podcast, but it would be interesting.
[01:15:22.220 --> 01:15:25.100]   I really like the name canoe cast for Canucks.
[01:15:25.100 --> 01:15:26.100]   There you go.
[01:15:26.100 --> 01:15:28.020]   As the title of your podcast.
[01:15:28.020 --> 01:15:29.020]   Trade Marco.
[01:15:29.020 --> 01:15:31.340]   I got somebody to show because I've written.
[01:15:31.340 --> 01:15:36.380]   Or you could do the canuck or the canoe cast.
[01:15:36.380 --> 01:15:37.620]   Oh, there you go.
[01:15:37.620 --> 01:15:38.620]   Can you cast?
[01:15:38.620 --> 01:15:41.460]   Can you do the canoe cast?
[01:15:41.460 --> 01:15:42.460]   Oh boy.
[01:15:42.460 --> 01:15:43.460]   Okay.
[01:15:43.460 --> 01:15:44.460]   So many good ideas.
[01:15:44.460 --> 01:15:45.460]   So many.
[01:15:45.460 --> 01:15:46.460]   Yeah, just take your pick.
[01:15:46.460 --> 01:15:50.220]   And whatever you don't use is the title of today's show.
[01:15:50.220 --> 01:15:54.700]   Matthew apologized for going off topic, not knowing that's what we are here to do.
[01:15:54.700 --> 01:15:55.700]   Right.
[01:15:55.700 --> 01:15:57.660]   That's the MO.
[01:15:57.660 --> 01:16:01.980]   Another thing that we might be hearing, well that we are hearing, and I'm sure it's ahead
[01:16:01.980 --> 01:16:03.380]   of IO for a reason.
[01:16:03.380 --> 01:16:09.980]   A big update launching for Google Maps API platform begins with a new name Google Maps
[01:16:09.980 --> 01:16:15.580]   platform is what it's now called new features for businesses who are looking to embed maps
[01:16:15.580 --> 01:16:16.820]   into their products.
[01:16:16.820 --> 01:16:22.860]   The example that they give is like, you know, your ride sharing companies that need that
[01:16:22.860 --> 01:16:26.140]   want to integrate turn by turn into their ride sharing apps.
[01:16:26.140 --> 01:16:32.220]   So Google's turn by turn, you don't have to switch between the lift app and Google Maps
[01:16:32.220 --> 01:16:34.020]   or whatever you're doing.
[01:16:34.020 --> 01:16:37.100]   Good for managing fleets as it were.
[01:16:37.100 --> 01:16:38.100]   And there's-
[01:16:38.100 --> 01:16:39.860]   Elon, put that on the Tesla, please.
[01:16:39.860 --> 01:16:40.860]   Yeah.
[01:16:40.860 --> 01:16:42.100]   Oh yeah, right.
[01:16:42.100 --> 01:16:43.980]   I just got the update on the Tesla.
[01:16:43.980 --> 01:16:45.020]   It's smarter navigation.
[01:16:45.020 --> 01:16:46.420]   The voice is different.
[01:16:46.420 --> 01:16:51.500]   The navigation is slightly better, but still I trust Google now way better.
[01:16:51.500 --> 01:16:52.500]   Yeah.
[01:16:52.500 --> 01:16:57.140]   The Tesla now do the smart kind of like traffic analysis and be like, yeah.
[01:16:57.140 --> 01:16:58.140]   It does.
[01:16:58.140 --> 01:16:59.140]   It has a tie in with ways.
[01:16:59.140 --> 01:17:00.140]   So it does do that now.
[01:17:00.140 --> 01:17:01.140]   Okay.
[01:17:01.140 --> 01:17:02.140]   That's nice.
[01:17:02.140 --> 01:17:03.140]   Right.
[01:17:03.140 --> 01:17:06.380]   But I probably should upgrade from the 3G modem in mind.
[01:17:06.380 --> 01:17:07.740]   Oh, Mother's Day.
[01:17:07.740 --> 01:17:09.020]   There you go.
[01:17:09.020 --> 01:17:15.140]   I have this ongoing battle with a friend who claims that Google Maps is terrible and
[01:17:15.140 --> 01:17:16.700]   ways is fantastic.
[01:17:16.700 --> 01:17:17.700]   But I'm-
[01:17:17.700 --> 01:17:19.460]   I'd agree with your friend, Matthew.
[01:17:19.460 --> 01:17:23.660]   The one who's referencing ways data incorporated into Google Maps, like don't they-
[01:17:23.660 --> 01:17:25.140]   It's actually reverse.
[01:17:25.140 --> 01:17:26.140]   It's more-
[01:17:26.140 --> 01:17:28.420]   Yeah, ways data is a Google Maps, Google Maps UI.
[01:17:28.420 --> 01:17:30.340]   I do not like nearly as well as ways.
[01:17:30.340 --> 01:17:31.980]   Yeah, I know the UI is not as good.
[01:17:31.980 --> 01:17:32.980]   I agree.
[01:17:32.980 --> 01:17:33.980]   So, what's now then?
[01:17:33.980 --> 01:17:36.620]   Why are you defending Google Maps over ways then?
[01:17:36.620 --> 01:17:38.340]   I'm just so used to it, I guess.
[01:17:38.340 --> 01:17:40.180]   I used to the crappy UI.
[01:17:40.180 --> 01:17:41.180]   And so-
[01:17:41.180 --> 01:17:42.180]   It's true.
[01:17:42.180 --> 01:17:44.260]   You're not friend under the bus.
[01:17:44.260 --> 01:17:47.140]   And now you're coming around and saying your friends right.
[01:17:47.140 --> 01:17:48.660]   He can stand up for himself.
[01:17:48.660 --> 01:17:50.060]   That'll teach your friend.
[01:17:50.060 --> 01:17:52.260]   Yeah, I don't like him that much.
[01:17:52.260 --> 01:17:53.260]   You're a media.
[01:17:53.260 --> 01:17:54.260]   Apologize.
[01:17:54.260 --> 01:17:55.260]   Apologize.
[01:17:55.260 --> 01:17:56.260]   He-
[01:17:56.260 --> 01:18:01.020]   So, his point is that the directions are significantly qualitatively better.
[01:18:01.020 --> 01:18:05.020]   But how can they be better if it's the same data effectively?
[01:18:05.020 --> 01:18:06.020]   I don't know.
[01:18:06.020 --> 01:18:07.020]   Oh, I think-
[01:18:07.020 --> 01:18:09.860]   That's why the UI is all that.
[01:18:09.860 --> 01:18:11.580]   We're all like, "Oh, data's awesome."
[01:18:11.580 --> 01:18:13.060]   But no, no, it's what you do.
[01:18:13.060 --> 01:18:14.660]   Yes, the data accounts.
[01:18:14.660 --> 01:18:15.660]   Yeah.
[01:18:15.660 --> 01:18:16.660]   I thought it was fascinating.
[01:18:16.660 --> 01:18:18.500]   I don't know if you guys talked about this on other shows.
[01:18:18.500 --> 01:18:25.620]   But there was an article about how Waze and I guess Google Maps, driving apps, are pushing
[01:18:25.620 --> 01:18:29.300]   people on to secondary and tertiary streets.
[01:18:29.300 --> 01:18:35.540]   And they're causing chaos in small neighborhoods because Waze will tell you, "Get off the freeway
[01:18:35.540 --> 01:18:38.060]   and go and take this side street."
[01:18:38.060 --> 01:18:41.980]   And then all this traffic pours onto these streets that aren't used to it.
[01:18:41.980 --> 01:18:47.500]   And so people in what were formerly quiet neighborhoods are seeing lines of Waze drivers
[01:18:47.500 --> 01:18:50.540]   basically plowing through their neighborhood.
[01:18:50.540 --> 01:18:57.380]   I just thought it was fascinating, the way that those apps are changing our behavior
[01:18:57.380 --> 01:19:01.020]   and changing the way cities function.
[01:19:01.020 --> 01:19:05.020]   Yeah, I've read articles similar to this.
[01:19:05.020 --> 01:19:10.620]   I haven't read this particular one, but it is very interesting how right Google Maps,
[01:19:10.620 --> 01:19:14.060]   I use Google Maps, I don't use Waze, apparently I don't use Waze.
[01:19:14.060 --> 01:19:18.620]   But how Google Maps will route me and I trust it and then I realize I get there faster.
[01:19:18.620 --> 01:19:23.340]   But so many times I'm following that path and I'm thinking about that.
[01:19:23.340 --> 01:19:27.500]   If it's directing me to go this way to avoid that traffic, it's directed many people before
[01:19:27.500 --> 01:19:31.180]   me and many people after me, how does that impact this neighborhood?
[01:19:31.180 --> 01:19:33.660]   Because sometimes you're driving through neighborhoods.
[01:19:33.660 --> 01:19:34.660]   And that is the benefit.
[01:19:34.660 --> 01:19:35.660]   It's a benefit.
[01:19:35.660 --> 01:19:36.660]   It's a benefit.
[01:19:36.660 --> 01:19:37.660]   It's taking that stress.
[01:19:37.660 --> 01:19:38.660]   They're all our role.
[01:19:38.660 --> 01:19:39.660]   I always share.
[01:19:39.660 --> 01:19:40.660]   Right?
[01:19:40.660 --> 01:19:41.660]   Yeah.
[01:19:41.660 --> 01:19:44.980]   It's theoretically alternative benefits for that neighborhood.
[01:19:44.980 --> 01:19:47.900]   They might not like having all the traffic go through, but it might save the highway
[01:19:47.900 --> 01:19:49.900]   from getting congested.
[01:19:49.900 --> 01:19:51.740]   So there's an overall benefit.
[01:19:51.740 --> 01:19:57.660]   But I could definitely see neighborhoods bitching about this Waze traffic, blogging
[01:19:57.660 --> 01:19:59.940]   up our side streets for sure.
[01:19:59.940 --> 01:20:01.180]   They do.
[01:20:01.180 --> 01:20:05.220]   And we talked about this a couple of weeks ago on the show with I think an L.A. street
[01:20:05.220 --> 01:20:06.460]   that was really steep.
[01:20:06.460 --> 01:20:11.860]   But I will say I have been in the car following the directions and had them change as the
[01:20:11.860 --> 01:20:14.500]   cars backed up, which was kind of cool.
[01:20:14.500 --> 01:20:18.220]   So the rerouting, it's not even rerouting.
[01:20:18.220 --> 01:20:21.060]   It's like, oh, now I've got this option.
[01:20:21.060 --> 01:20:22.060]   It's really cool.
[01:20:22.060 --> 01:20:23.060]   Yeah.
[01:20:23.060 --> 01:20:28.420]   The interesting thing to me is when the latency is an issue as with any of this data.
[01:20:28.420 --> 01:20:30.980]   And so I was driving on the highway.
[01:20:30.980 --> 01:20:32.220]   It started to get clogged up.
[01:20:32.220 --> 01:20:36.860]   I said, get off, go down the service road by the time I got off and got on the service
[01:20:36.860 --> 01:20:37.860]   road.
[01:20:37.860 --> 01:20:40.580]   The thing that had clogged up the highway was cleared.
[01:20:40.580 --> 01:20:44.140]   And that now was stuck on a service road and I had to get back on the highway.
[01:20:44.140 --> 01:20:49.780]   So whereas if I had waited, you know, 30 seconds or a minute, I probably would have been better
[01:20:49.780 --> 01:20:50.780]   off.
[01:20:50.780 --> 01:20:54.860]   But at that moment in time, getting off onto the service road was the best option.
[01:20:54.860 --> 01:20:55.860]   Yeah.
[01:20:55.860 --> 01:20:56.860]   Yeah.
[01:20:56.860 --> 01:20:57.860]   I have two wishes.
[01:20:57.860 --> 01:20:58.860]   One.
[01:20:58.860 --> 01:20:59.860]   No, sorry, go ahead.
[01:20:59.860 --> 01:21:00.860]   Stacey.
[01:21:00.860 --> 01:21:05.820]   I'm just going to say, this is why I want my car to open the sunroof, launch a drone so
[01:21:05.820 --> 01:21:09.340]   I can see what's happening overhead and then come back to me with information.
[01:21:09.340 --> 01:21:10.340]   So, okay.
[01:21:10.340 --> 01:21:11.340]   That's a great idea.
[01:21:11.340 --> 01:21:12.340]   Back to mama.
[01:21:12.340 --> 01:21:16.940]   I want my car to open up the sunroof and have the helicopter propellers rise up and I can
[01:21:16.940 --> 01:21:17.940]   fly over and go away.
[01:21:17.940 --> 01:21:19.780]   I'll take the drone though.
[01:21:19.780 --> 01:21:20.780]   That would be cool.
[01:21:20.780 --> 01:21:22.020]   Jeff, what were you going to say?
[01:21:22.020 --> 01:21:23.380]   So I have two wishes.
[01:21:23.380 --> 01:21:27.700]   One is when I get in the car and Waze or Google Maps doesn't know which way I'm pointing.
[01:21:27.700 --> 01:21:33.140]   Let me just point the point to say this way, I'm pointing this way because then I, you
[01:21:33.140 --> 01:21:34.140]   start driving.
[01:21:34.140 --> 01:21:37.140]   Oh, no, I thought you were going the other way and you get around and around and around.
[01:21:37.140 --> 01:21:38.140]   Oh, that's so annoying.
[01:21:38.140 --> 01:21:39.140]   Yeah.
[01:21:39.140 --> 01:21:40.140]   It's got to be solved.
[01:21:40.140 --> 01:21:41.140]   It's got to be solved.
[01:21:41.140 --> 01:21:43.740]   Second, Google Maps and walking really sucks.
[01:21:43.740 --> 01:21:44.740]   Oh, yeah.
[01:21:44.740 --> 01:21:45.740]   Really?
[01:21:45.740 --> 01:21:46.740]   Really?
[01:21:46.740 --> 01:21:49.740]   I cannot tell everybody my compass in GPS, that thing.
[01:21:49.740 --> 01:21:50.740]   Yeah.
[01:21:50.740 --> 01:21:52.100]   Well, and that's a problem in cities for sure.
[01:21:52.100 --> 01:21:55.060]   Because I do the figure eight still my arm falls off.
[01:21:55.060 --> 01:21:56.060]   Yeah.
[01:21:56.060 --> 01:21:59.620]   Are you sure you don't want a third wish and that's for the drone to go out and fly and
[01:21:59.620 --> 01:22:01.100]   tell you what's.
[01:22:01.100 --> 01:22:02.860]   I would take the drone for sure.
[01:22:02.860 --> 01:22:05.980]   Well, no, that's where Amazon comes in and wins.
[01:22:05.980 --> 01:22:06.980]   Yeah.
[01:22:06.980 --> 01:22:07.980]   Yeah.
[01:22:07.980 --> 01:22:09.940]   Amazon's not going to talk to my Google gear.
[01:22:09.940 --> 01:22:11.460]   This is an important issue for me.
[01:22:11.460 --> 01:22:14.780]   I think what the Amazon drone does is it comes over to your sunroof and delivers you
[01:22:14.780 --> 01:22:17.020]   a burrito while you're waiting.
[01:22:17.020 --> 01:22:18.020]   There's a good idea.
[01:22:18.020 --> 01:22:19.020]   Yeah.
[01:22:19.020 --> 01:22:23.460]   Or Amazon is going to give you a car for free if you just deliver five packages on the
[01:22:23.460 --> 01:22:25.540]   way to where you're going.
[01:22:25.540 --> 01:22:26.540]   I would do that.
[01:22:26.540 --> 01:22:28.780]   Or if you let strangers pick up their packages in your trunk.
[01:22:28.780 --> 01:22:29.780]   I would do that.
[01:22:29.780 --> 01:22:30.780]   Yeah.
[01:22:30.780 --> 01:22:31.780]   That's right.
[01:22:31.780 --> 01:22:32.780]   Yeah.
[01:22:32.780 --> 01:22:33.780]   The future's freaking cool.
[01:22:33.780 --> 01:22:34.780]   I love the future.
[01:22:34.780 --> 01:22:38.220]   Oh, oh, I should ask anyone because this isn't really for this show.
[01:22:38.220 --> 01:22:39.780]   But what the heck?
[01:22:39.780 --> 01:22:42.940]   Amazon prime cost increase.
[01:22:42.940 --> 01:22:44.300]   We're all for it.
[01:22:44.300 --> 01:22:46.300]   We're all we're all still going to continue with prime.
[01:22:46.300 --> 01:22:47.300]   Right.
[01:22:47.300 --> 01:22:48.300]   One of my new master.
[01:22:48.300 --> 01:22:49.300]   Yeah.
[01:22:49.300 --> 01:22:50.620]   I'm a prisoner.
[01:22:50.620 --> 01:22:53.900]   Still cheap cheap at the price.
[01:22:53.900 --> 01:22:59.100]   The ISO and analysis somewhere somebody said that in order for Amazon to even break even
[01:22:59.100 --> 01:23:02.300]   on prime, it would have to be $200 plus.
[01:23:02.300 --> 01:23:03.300]   Yeah.
[01:23:03.300 --> 01:23:06.740]   My little reminder that comes up right.
[01:23:06.740 --> 01:23:09.340]   It actually came up right before that announcement was made.
[01:23:09.340 --> 01:23:13.140]   It was like, by the way, you saved $300 and something dollars on prime.
[01:23:13.140 --> 01:23:16.580]   I'm like, oh, thanks, Amazon.
[01:23:16.580 --> 01:23:20.860]   I just kind of assumed with prime, like, yes, I use it a lot and we all use it a lot.
[01:23:20.860 --> 01:23:24.060]   But I assumed it's kind of like the gift certificate approach, right?
[01:23:24.060 --> 01:23:28.020]   Like you pay for the prime, but you don't really know throughout the course of the year
[01:23:28.020 --> 01:23:30.300]   what your usage actually adds up to.
[01:23:30.300 --> 01:23:31.300]   Right.
[01:23:31.300 --> 01:23:33.780]   So there's going to be a large percentage of people that pay more than what they would
[01:23:33.780 --> 01:23:36.860]   have used regardless and kind of helps make up for it.
[01:23:36.860 --> 01:23:38.860]   And they subsidize everybody else.
[01:23:38.860 --> 01:23:39.860]   Right.
[01:23:39.860 --> 01:23:40.860]   Yeah.
[01:23:40.860 --> 01:23:41.860]   Yeah.
[01:23:41.860 --> 01:23:45.940]   Let's see here other Google news of note has nothing to do with IO.
[01:23:45.940 --> 01:23:49.220]   I think we're out of the IO section.
[01:23:49.220 --> 01:23:50.220]   We have.
[01:23:50.220 --> 01:23:51.820]   One ball, one little tiny.
[01:23:51.820 --> 01:23:52.820]   I don't know.
[01:23:52.820 --> 01:23:57.300]   Well, it's after we all just ARV or earlier.
[01:23:57.300 --> 01:24:03.140]   Note that that number one in IO, there's a whole session on immersive experiences ARVR
[01:24:03.140 --> 01:24:09.220]   are the future of the web that they're still flying the flag and they're investing in.
[01:24:09.220 --> 01:24:12.060]   YouTube is investing in a bunch of VR contents.
[01:24:12.060 --> 01:24:14.060]   There's still these guys are all trying.
[01:24:14.060 --> 01:24:16.060]   Yeah, they're still trying.
[01:24:16.060 --> 01:24:21.060]   We don't know.
[01:24:21.060 --> 01:24:22.060]   Yeah.
[01:24:22.060 --> 01:24:24.060]   SNL, Vanderpump rules.
[01:24:24.060 --> 01:24:25.220]   I had riles in there.
[01:24:25.220 --> 01:24:26.220]   That's wrong.
[01:24:26.220 --> 01:24:34.420]   SIFI, sci-fi wire, all partners at this point, 360 degree and 180 degree VR episodic content.
[01:24:34.420 --> 01:24:35.420]   So they have the two different cameras.
[01:24:35.420 --> 01:24:39.060]   They've got the jump system, which is the 17 cameras are rated for that kind of immersive
[01:24:39.060 --> 01:24:40.700]   360 degree thing.
[01:24:40.700 --> 01:24:48.500]   And they've got the 180 degree VR for a locked down, but three dimensional VR shot that's
[01:24:48.500 --> 01:24:50.460]   relatively easy to make.
[01:24:50.460 --> 01:24:53.820]   And we're going to see a bunch of episodic content along those lines.
[01:24:53.820 --> 01:24:55.300]   And maybe we will watch it.
[01:24:55.300 --> 01:24:56.300]   Maybe we won't.
[01:24:56.300 --> 01:24:57.300]   I don't know.
[01:24:57.300 --> 01:24:58.300]   Vanderpump rules.
[01:24:58.300 --> 01:25:01.980]   I don't know if I've ever watched a single second of whatever that show is.
[01:25:01.980 --> 01:25:06.220]   So I'm really intrigued by the, like, I get stressed.
[01:25:06.220 --> 01:25:09.320]   I don't know if anyone else gets the stress, but I'm the type of person who read my choose
[01:25:09.320 --> 01:25:13.440]   your own adventure books, like all of the adventures I had to do them all.
[01:25:13.440 --> 01:25:18.160]   So 3D content freaks me out because I'm like, oh, I have to look up.
[01:25:18.160 --> 01:25:19.160]   I have to look around.
[01:25:19.160 --> 01:25:20.160]   What's happening behind me?
[01:25:20.160 --> 01:25:21.160]   Yeah.
[01:25:21.160 --> 01:25:22.160]   Yeah.
[01:25:22.160 --> 01:25:23.160]   Like there's no indication.
[01:25:23.160 --> 01:25:27.620]   And I think this will be really important for telling stories correctly in this medium is
[01:25:27.620 --> 01:25:29.680]   indicating where a person should look.
[01:25:29.680 --> 01:25:30.680]   Right.
[01:25:30.680 --> 01:25:31.680]   And we don't have those context.
[01:25:31.680 --> 01:25:32.680]   It's going to fall back.
[01:25:32.680 --> 01:25:38.200]   Well, so one of the things that they said that they was basically VR now has a range
[01:25:38.200 --> 01:25:43.280]   vision like this, or we tend to be more like about 200 degrees.
[01:25:43.280 --> 01:25:48.720]   What if what if the experience Stacy was not that you ever had what behind you, but instead
[01:25:48.720 --> 01:25:53.160]   that you had more of the field of view you actually have you have a 180 at least.
[01:25:53.160 --> 01:25:54.160]   Would that be useful?
[01:25:54.160 --> 01:25:55.680]   Is it some of the concert stuff?
[01:25:55.680 --> 01:25:56.680]   He's 180 only.
[01:25:56.680 --> 01:25:57.680]   Yeah.
[01:25:57.680 --> 01:25:59.480]   And that would be useful.
[01:25:59.480 --> 01:26:05.960]   But okay, the first time I watched alien with a surround sound system and you know that
[01:26:05.960 --> 01:26:08.920]   you hear it coming up from behind you, you got it bit.
[01:26:08.920 --> 01:26:13.160]   It would be awesome to look around and be like, Oh, crap.
[01:26:13.160 --> 01:26:14.800]   So that's just me.
[01:26:14.800 --> 01:26:19.400]   I feel like there actually are really cool storytelling possibilities.
[01:26:19.400 --> 01:26:25.560]   If you give people the right clues to like create that kind of immersive experience, would
[01:26:25.560 --> 01:26:26.560]   it?
[01:26:26.560 --> 01:26:28.560]   But but yes, truly.
[01:26:28.560 --> 01:26:30.960]   I also want to be podcast.
[01:26:30.960 --> 01:26:31.960]   So it's cutie.
[01:26:31.960 --> 01:26:35.080]   I wanted to do a podcast in 360.
[01:26:35.080 --> 01:26:38.320]   So that one of you, if I'm talking, yeah, that would be good.
[01:26:38.320 --> 01:26:41.520]   Look at your face and see your eyes roll.
[01:26:41.520 --> 01:26:42.520]   Yeah.
[01:26:42.520 --> 01:26:45.960]   So you're all surrounding the camera that's all around the center.
[01:26:45.960 --> 01:26:46.960]   Yeah.
[01:26:46.960 --> 01:26:48.360]   Doesn't Google have?
[01:26:48.360 --> 01:26:52.840]   Didn't they do something with AI telling you who's speaking in a video clip?
[01:26:52.840 --> 01:26:54.080]   Oh, wait a minute.
[01:26:54.080 --> 01:26:55.080]   Yes, they did that.
[01:26:55.080 --> 01:26:56.920]   Like two weeks ago.
[01:26:56.920 --> 01:27:02.720]   It wasn't even so I'm just that's technology that could help you make that possible, Jeff.
[01:27:02.720 --> 01:27:03.720]   Yeah.
[01:27:03.720 --> 01:27:04.720]   Oh, yeah.
[01:27:04.720 --> 01:27:07.160]   I had my tea set up for years where you can tell it.
[01:27:07.160 --> 01:27:08.160]   Yeah.
[01:27:08.160 --> 01:27:14.640]   I did a demo of VR demo where you were watching Cirque du Soleil and you could turn to either
[01:27:14.640 --> 01:27:23.280]   side and see performers sitting on the stage sort of near you reacting to the show.
[01:27:23.280 --> 01:27:28.440]   So it was kind of like just watching the regular show, but then there were other things added
[01:27:28.440 --> 01:27:29.440]   to it.
[01:27:29.440 --> 01:27:31.680]   So it wasn't full kind of immersive or 360.
[01:27:31.680 --> 01:27:35.360]   I thought it was really powerful.
[01:27:35.360 --> 01:27:36.360]   The article.
[01:27:36.360 --> 01:27:37.920]   We've resurrected 360.
[01:27:37.920 --> 01:27:38.920]   You know, I don't know.
[01:27:38.920 --> 01:27:39.920]   But I'm done.
[01:27:39.920 --> 01:27:40.920]   Now we're both 360.
[01:27:40.920 --> 01:27:41.920]   220.
[01:27:41.920 --> 01:27:42.920]   220.
[01:27:42.920 --> 01:27:49.880]   I think it would be interesting to get those VR 180 cameras and play around with them.
[01:27:49.880 --> 01:27:53.600]   I feel like when they were when they were showing those off and first releasing them,
[01:27:53.600 --> 01:27:57.840]   it seemed like their idea was anyone can get one and you can say, but I don't know if
[01:27:57.840 --> 01:27:59.960]   anyone actually is.
[01:27:59.960 --> 01:28:01.960]   So can I have a little Jeff fit?
[01:28:01.960 --> 01:28:03.840]   A little fit at just a minor one.
[01:28:03.840 --> 01:28:04.840]   Sure.
[01:28:04.840 --> 01:28:05.840]   Fitlight.
[01:28:05.840 --> 01:28:06.840]   Sure.
[01:28:06.840 --> 01:28:07.840]   Fitlight.
[01:28:07.840 --> 01:28:11.960]   So the story of, oh my God, Twitter sold data to Cambridge Analytica.
[01:28:11.960 --> 01:28:15.760]   To me reveals for the problem with this whole storyline.
[01:28:15.760 --> 01:28:20.280]   Twitter sells the fire hose to whoever pays them enough money and you come in and you
[01:28:20.280 --> 01:28:22.800]   say, I'm going to buy the fire hose from you.
[01:28:22.800 --> 01:28:23.800]   You can buy it.
[01:28:23.800 --> 01:28:25.240]   It's a product you can buy.
[01:28:25.240 --> 01:28:26.240]   A.
[01:28:26.240 --> 01:28:27.240]   B.
[01:28:27.240 --> 01:28:28.240]   I presume they're not selling DMs or anything.
[01:28:28.240 --> 01:28:33.520]   They're selling data that is public that you chose to make public on Twitter.
[01:28:33.520 --> 01:28:38.080]   So why there's a lot of pearl clutching about that.
[01:28:38.080 --> 01:28:39.080]   I'm not sure.
[01:28:39.080 --> 01:28:40.880]   That was just not a big change.
[01:28:40.880 --> 01:28:42.880]   That was an involved Cambridge Analytica.
[01:28:42.880 --> 01:28:43.880]   Right.
[01:28:43.880 --> 01:28:44.880]   Right.
[01:28:44.880 --> 01:28:45.880]   So it's part of the case.
[01:28:45.880 --> 01:28:52.920]   It's the Cambridge Analytica's code for using data in ways it's not supposed to be used
[01:28:52.920 --> 01:28:58.120]   or using data to target people for foreign election purposes or something.
[01:28:58.120 --> 01:29:00.880]   So it's not so much the data they got.
[01:29:00.880 --> 01:29:04.920]   But what else is that data doing?
[01:29:04.920 --> 01:29:07.400]   But even so, there's no secret to this.
[01:29:07.400 --> 01:29:09.280]   It's a product you can sell.
[01:29:09.280 --> 01:29:10.520]   It's the fire hose.
[01:29:10.520 --> 01:29:14.880]   It's public data and anybody can use it.
[01:29:14.880 --> 01:29:15.880]   So they used it.
[01:29:15.880 --> 01:29:16.880]   They're schmucks.
[01:29:16.880 --> 01:29:17.880]   They're bad.
[01:29:17.880 --> 01:29:18.880]   I'm glad they're out of business.
[01:29:18.880 --> 01:29:19.880]   You've kind of.
[01:29:19.880 --> 01:29:22.440]   But I don't see any candles there.
[01:29:22.440 --> 01:29:23.440]   That's all.
[01:29:23.440 --> 01:29:25.640]   See, it was a minor com fit.
[01:29:25.640 --> 01:29:28.720]   Yeah, that wasn't even really a fit.
[01:29:28.720 --> 01:29:31.920]   That was like a mild rant.
[01:29:31.920 --> 01:29:33.320]   It felt good to get it off my chest.
[01:29:33.320 --> 01:29:34.720]   I mean, it's because I'm in California.
[01:29:34.720 --> 01:29:36.480]   I'm just more mellow right now.
[01:29:36.480 --> 01:29:38.400]   That was therapy.
[01:29:38.400 --> 01:29:39.400]   That wasn't a fit.
[01:29:39.400 --> 01:29:40.400]   That was just therapy.
[01:29:40.400 --> 01:29:44.200]   What do we think of the Sprint T-Mobile thing?
[01:29:44.200 --> 01:29:47.080]   I feel like this was bouncing around forever and ever and ever.
[01:29:47.080 --> 01:29:52.920]   And then finally, they announced that there's a deal, $26.5 billion deal in stock for T-Mobile
[01:29:52.920 --> 01:29:54.120]   to acquire Sprint.
[01:29:54.120 --> 01:30:01.480]   They really talked up the idea of, you know, we are behind China in 5G development.
[01:30:01.480 --> 01:30:04.640]   And this is not something we can allow.
[01:30:04.640 --> 01:30:09.040]   That's playing off the Trump administration's apparent freak out over 5G.
[01:30:09.040 --> 01:30:16.280]   However, however, back in what is it?
[01:30:16.280 --> 01:30:18.720]   2013, I think it was.
[01:30:18.720 --> 01:30:19.720]   Oh, no.
[01:30:19.720 --> 01:30:20.720]   Nope.
[01:30:20.720 --> 01:30:24.240]   It was AT&T that tried to buy T-Mobile back in 2012.
[01:30:24.240 --> 01:30:25.240]   That's right.
[01:30:25.240 --> 01:30:26.240]   Yeah.
[01:30:26.240 --> 01:30:27.240]   That's right.
[01:30:27.240 --> 01:30:30.080]   And then everybody wanted T-Mobile after that happened.
[01:30:30.080 --> 01:30:34.080]   And Sprint was the talk of the town and then someone bought Sprint.
[01:30:34.080 --> 01:30:35.080]   Who was it?
[01:30:35.080 --> 01:30:36.080]   Do I?
[01:30:36.080 --> 01:30:37.080]   No.
[01:30:37.080 --> 01:30:40.280]   SoftBank Dude invested a lot of money in Sprint, right?
[01:30:40.280 --> 01:30:41.280]   Oh, yeah.
[01:30:41.280 --> 01:30:42.280]   Massayoshi.
[01:30:42.280 --> 01:30:43.280]   Son.
[01:30:43.280 --> 01:30:50.120]   Anyway, so there has been ever, ever since we've basically been saying, "Hey, you know what?
[01:30:50.120 --> 01:30:52.160]   The US is a three-carrier market.
[01:30:52.160 --> 01:30:54.320]   We just, four is too many."
[01:30:54.320 --> 01:30:58.080]   So there's actually a lot of scholarship.
[01:30:58.080 --> 01:31:03.640]   And if you look at other countries based on just like straight up countries, three is
[01:31:03.640 --> 01:31:04.640]   a good number.
[01:31:04.640 --> 01:31:08.960]   If you look at it based on population, surely we could support more.
[01:31:08.960 --> 01:31:12.040]   But it's not really viable.
[01:31:12.040 --> 01:31:17.480]   There's a huge economic case to say that it is not viable to have four different carriers.
[01:31:17.480 --> 01:31:18.480]   Really?
[01:31:18.480 --> 01:31:20.880]   Yes.
[01:31:20.880 --> 01:31:22.120]   Those arguments exist.
[01:31:22.120 --> 01:31:24.520]   They are actually compelling.
[01:31:24.520 --> 01:31:29.640]   They are not like completely persuasive, but they are compelling.
[01:31:29.640 --> 01:31:37.400]   It's based on the cost, the capital costs of leasing towers, buying the spectrum, running
[01:31:37.400 --> 01:31:38.640]   a network.
[01:31:38.640 --> 01:31:45.080]   So it's not crazy, but it is probably not good for the consumer.
[01:31:45.080 --> 01:31:47.960]   Did you read Tim Wu's piece in the New York Times?
[01:31:47.960 --> 01:31:48.960]   Yes.
[01:31:48.960 --> 01:31:51.240]   And again, I have been in this.
[01:31:51.240 --> 01:31:53.680]   He basically said it's a terrible idea.
[01:31:53.680 --> 01:31:55.200]   It is a terrible idea.
[01:31:55.200 --> 01:31:56.200]   It's bad for consumers.
[01:31:56.200 --> 01:31:59.840]   The moving down, yeah, the moving to three carriers is bad.
[01:31:59.840 --> 01:32:03.920]   So maybe there's an economic rationale for it, but that doesn't make it good.
[01:32:03.920 --> 01:32:07.720]   There is a economic rationale as a business to do it.
[01:32:07.720 --> 01:32:12.720]   It is very expensive to operate and maintain a good wireless network.
[01:32:12.720 --> 01:32:19.000]   It is hard for both Sprint and Timo to compete against AT&T and Verizon for a bunch of reasons.
[01:32:19.000 --> 01:32:20.000]   Agreed.
[01:32:20.000 --> 01:32:26.360]   But I think if Canada can have two, surely the US can have more than three.
[01:32:26.360 --> 01:32:28.360]   No.
[01:32:28.360 --> 01:32:33.520]   Again, consumers, this will suck for you.
[01:32:33.520 --> 01:32:37.640]   But there is a compelling argument to be made for the Department of Justice and the
[01:32:37.640 --> 01:32:42.840]   FTC who are going to have to decide if this was worthwhile, that we do need this.
[01:32:42.840 --> 01:32:47.280]   And I'm sure the FCC, you know, AGP is probably like, "Yeah, yeah, make it happen.
[01:32:47.280 --> 01:32:49.120]   This is why this is happening now."
[01:32:49.120 --> 01:32:51.760]   Because Tom Wheeler was against these mergers.
[01:32:51.760 --> 01:32:58.080]   But I mean, that seems, maybe I'm wrong, but it seems to me that T-Mobile was all about,
[01:32:58.080 --> 01:33:03.720]   you know, we're the consumer-friendly phone company and we're looking out for you and
[01:33:03.720 --> 01:33:05.200]   we're fighting the big guys.
[01:33:05.200 --> 01:33:07.000]   And I don't understand how that.
[01:33:07.000 --> 01:33:10.640]   And then the CEO shows up with Trump.
[01:33:10.640 --> 01:33:12.680]   Trump, Trump, or Trump.
[01:33:12.680 --> 01:33:19.680]   Because they have shareholders, because they have to make money in a market that is, they're
[01:33:19.680 --> 01:33:21.880]   fighting against Verizon and AT&T.
[01:33:21.880 --> 01:33:26.840]   And Timo actually has done a really good job, but they do lack capacity from a spectrum
[01:33:26.840 --> 01:33:28.200]   point of view.
[01:33:28.200 --> 01:33:30.840]   So they need to solve that problem.
[01:33:30.840 --> 01:33:38.360]   Both Sprint and Timo have to pay AT&T and Verizon for access to the internet itself, so to connect
[01:33:38.360 --> 01:33:40.760]   their cell towers to the internet.
[01:33:40.760 --> 01:33:52.480]   So they're, again, Tim said, "If you want the mobile industry to look more like the airline
[01:33:52.480 --> 01:33:56.040]   industry, then this merger is the one for you."
[01:33:56.040 --> 01:33:57.040]   Yes.
[01:33:57.040 --> 01:33:59.080]   It's a crap deal for consumers.
[01:33:59.080 --> 01:34:05.240]   But it is a rational deal from an economic, like from a shareholder business perspective.
[01:34:05.240 --> 01:34:08.800]   But there's probably a rationale that you should only have one airline company and one
[01:34:08.800 --> 01:34:11.480]   phone company and one TV company.
[01:34:11.480 --> 01:34:13.680]   That would be by far the most economically efficient.
[01:34:13.680 --> 01:34:17.360]   Not an monopolistic society.
[01:34:17.360 --> 01:34:26.400]   But in a socialist society, sure, what the heck, or a communist society, yes.
[01:34:26.400 --> 01:34:31.920]   I'm against the merger because I am pro-consume.
[01:34:31.920 --> 01:34:39.040]   I've been for having as many carriers as possible, but I would not bet against this deal.
[01:34:39.040 --> 01:34:40.040]   Yeah.
[01:34:40.040 --> 01:34:43.160]   I bet I do know the time is right for it now.
[01:34:43.160 --> 01:34:44.600]   And that's obviously why I'm a secret.
[01:34:44.600 --> 01:34:50.680]   It's just hugely ironic that T-Mobile was pushing like their whole marketing campaign was consumer-
[01:34:50.680 --> 01:34:52.240]   It was the unfair.
[01:34:52.240 --> 01:34:53.240]   Right.
[01:34:53.240 --> 01:34:58.600]   Yeah, but they also did some things that were very smart from an economic perspective, like
[01:34:58.600 --> 01:35:04.240]   in brought them subscribers, which was like they did the first deal, the first zero rating
[01:35:04.240 --> 01:35:05.240]   deal.
[01:35:05.240 --> 01:35:06.640]   That was T-Mobile.
[01:35:06.640 --> 01:35:16.640]   So they're not like some sort of crusader for like awesome broadband and competition in
[01:35:16.640 --> 01:35:17.760]   the telco industry.
[01:35:17.760 --> 01:35:18.760]   They are a business.
[01:35:18.760 --> 01:35:22.240]   No, but you could argue zero rating was actually consumer-friendly.
[01:35:23.240 --> 01:35:24.840]   You can in the short term.
[01:35:24.840 --> 01:35:25.840]   Yes.
[01:35:25.840 --> 01:35:27.840]   Not competition, Fred.
[01:35:27.840 --> 01:35:29.840]   I want to consumers.
[01:35:29.840 --> 01:35:32.840]   You know, the short term is good enough, I think, for a lot of people.
[01:35:32.840 --> 01:35:33.840]   Well, yes.
[01:35:33.840 --> 01:35:35.240]   You get stuff for free.
[01:35:35.240 --> 01:35:36.240]   Yeah.
[01:35:36.240 --> 01:35:40.240]   And that gets us into all kinds of fun places.
[01:35:40.240 --> 01:35:46.240]   I should note that conductcoucast.com is available.
[01:35:46.240 --> 01:35:50.040]   That's a good new cast.
[01:35:50.040 --> 01:35:51.040]   I love it.
[01:35:51.040 --> 01:35:53.440]   Well, then I think you obviously have to get it.
[01:35:53.440 --> 01:35:54.440]   You have to buy it right now.
[01:35:54.440 --> 01:35:56.040]   Somebody else is going to get it now that you mentioned it.
[01:35:56.040 --> 01:35:57.040]   I'd like to register it.
[01:35:57.040 --> 01:35:58.040]   Yeah.
[01:35:58.040 --> 01:35:59.040]   Good enough canoe is just fun to say.
[01:35:59.040 --> 01:36:00.040]   It is.
[01:36:00.040 --> 01:36:01.040]   I don't.
[01:36:01.040 --> 01:36:02.040]   Oh, wait.
[01:36:02.040 --> 01:36:03.040]   Oh, here we go.
[01:36:03.040 --> 01:36:04.040]   Ready?
[01:36:04.040 --> 01:36:05.040]   Segue.
[01:36:05.040 --> 01:36:06.040]   Can you cast .app?
[01:36:06.040 --> 01:36:07.040]   Dot app.
[01:36:07.040 --> 01:36:08.040]   Yeah.
[01:36:08.040 --> 01:36:09.040]   Oh, nice.
[01:36:09.040 --> 01:36:10.040]   Very nice.
[01:36:10.040 --> 01:36:11.040]   Okay.
[01:36:11.040 --> 01:36:12.440]   For a second, I was okay.
[01:36:12.440 --> 01:36:13.440]   Yes.
[01:36:13.440 --> 01:36:14.440]   You guys were all right.
[01:36:14.440 --> 01:36:15.440]   I'm there.
[01:36:15.440 --> 01:36:16.440]   No, I'm with you.
[01:36:16.440 --> 01:36:17.440]   I'm with you.
[01:36:17.440 --> 01:36:23.120]   So Google paid $25 million for exclusive rights to the dot app domain three years ago.
[01:36:23.120 --> 01:36:29.840]   Now Google is going to require HTTPS for all dot app sites, which is basically making
[01:36:29.840 --> 01:36:36.160]   those domains, the dot app domains available now through May 7 via an early access program
[01:36:36.160 --> 01:36:41.560]   and then opening it up to everyone May 8 to go on sale to the general public.
[01:36:41.560 --> 01:36:47.400]   So it does anyone here have the have access to early access program so we can nail down
[01:36:47.400 --> 01:36:50.720]   can I canoe dot app?
[01:36:50.720 --> 01:36:52.320]   I do actually.
[01:36:52.320 --> 01:36:54.280]   Can I can do app casts?
[01:36:54.280 --> 01:36:58.480]   Yeah, I'm 100% sure what what domain we're supposed to be getting.
[01:36:58.480 --> 01:36:59.480]   Yeah.
[01:36:59.480 --> 01:37:00.480]   I think we get them all.
[01:37:00.480 --> 01:37:01.480]   This is very important.
[01:37:01.480 --> 01:37:02.480]   Yeah.
[01:37:02.480 --> 01:37:05.560]   Anything with can I can canoe?
[01:37:05.560 --> 01:37:06.560]   Any combination.
[01:37:06.560 --> 01:37:07.560]   There you go.
[01:37:07.560 --> 01:37:10.200]   Any combo of can I canoe cast?
[01:37:10.200 --> 01:37:11.200]   Yeah.
[01:37:11.200 --> 01:37:17.360]   So Kevin has bought some, but apparently we ran into a domain, a pending trademark claim
[01:37:17.360 --> 01:37:18.360]   on one of them.
[01:37:18.360 --> 01:37:21.920]   So I know.
[01:37:21.920 --> 01:37:24.000]   But that's OK.
[01:37:24.000 --> 01:37:28.200]   You know, we do what we can sort of feels sort of feels a little do you remember dot
[01:37:28.200 --> 01:37:29.200]   Moby?
[01:37:29.200 --> 01:37:31.200]   Oh, yeah.
[01:37:31.200 --> 01:37:34.640]   Yeah, that I don't know.
[01:37:34.640 --> 01:37:38.320]   Did that was that I was that I'm trying to remember what was that?
[01:37:38.320 --> 01:37:40.040]   It seemed to be mostly marketing.
[01:37:40.040 --> 01:37:45.440]   Well, the TLDs, there have been a couple that have actually is that top level domain?
[01:37:45.440 --> 01:37:49.400]   Yes, there's been a couple that have been sort of worthwhile.
[01:37:49.400 --> 01:37:50.400]   What?
[01:37:50.400 --> 01:37:51.880]   Well, hold on.
[01:37:51.880 --> 01:37:52.880]   Let me ask you.
[01:37:52.880 --> 01:37:54.320]   There was X, X, X, two, I think.
[01:37:54.320 --> 01:37:56.160]   Yeah, you have an expert.
[01:37:56.160 --> 01:37:57.160]   I do.
[01:37:57.160 --> 01:37:59.200]   Only a successful TLDs.
[01:37:59.200 --> 01:38:02.160]   Talk about talk amongst yourself.
[01:38:02.160 --> 01:38:05.480]   Dot Moby was for those.
[01:38:05.480 --> 01:38:10.960]   Well, OK, the Wikipedia says anyways, indicating it was used for mobile devices for accessing
[01:38:10.960 --> 01:38:12.440]   internet resources via the mobile.
[01:38:12.440 --> 01:38:14.640]   It was like the follow up to WAP domain.
[01:38:14.640 --> 01:38:18.240]   That's when we had a mobile web instead of just the web.
[01:38:18.240 --> 01:38:19.240]   Right.
[01:38:19.240 --> 01:38:20.240]   Exactly.
[01:38:20.240 --> 01:38:21.240]   2005 was when that was approved.
[01:38:21.240 --> 01:38:22.240]   Yeah.
[01:38:22.240 --> 01:38:25.680]   So it would fit on your palm pilot or your hand spraying in your.
[01:38:25.680 --> 01:38:28.760]   Oh, don't be.
[01:38:28.760 --> 01:38:30.040]   Not the electronic musician Moby.
[01:38:30.040 --> 01:38:31.560]   I think Moby actually sued.
[01:38:31.560 --> 01:38:33.040]   Yeah, there was a trademark.
[01:38:33.040 --> 01:38:34.640]   Yeah, probably so.
[01:38:34.640 --> 01:38:36.440]   That sounds like something Moby would do.
[01:38:36.440 --> 01:38:38.080]   He's with a Y.
[01:38:38.080 --> 01:38:41.920]   Yeah, but it sounds the same.
[01:38:41.920 --> 01:38:43.840]   Does sound the same.
[01:38:43.840 --> 01:38:50.440]   Also, Dot Moby with a Y, but it was all just easy listening sort of trance music.
[01:38:50.440 --> 01:38:53.960]   So every website.
[01:38:53.960 --> 01:38:58.120]   If you're a trans DJ, this is the perfect domain for you.
[01:38:58.120 --> 01:39:02.040]   So requiring HTTPS to be built in, that's kind of cool.
[01:39:02.040 --> 01:39:08.240]   That falls in line with Google's also making this transition with Google Chrome browser.
[01:39:08.240 --> 01:39:13.760]   I think that happens in July, where if you visit a website that doesn't have the HTTP
[01:39:13.760 --> 01:39:17.760]   HTTPS built in that you're going to get a warning.
[01:39:17.760 --> 01:39:20.200]   So before that will happen.
[01:39:20.200 --> 01:39:25.400]   Obviously, if they're launching these domains, they would make it compatible with that.
[01:39:25.400 --> 01:39:27.520]   So that doesn't happen on those domains.
[01:39:27.520 --> 01:39:29.280]   I'm guessing.
[01:39:29.280 --> 01:39:35.480]   So here, the only top level domain name success that my husband apparently has seen is Dot
[01:39:35.480 --> 01:39:37.120]   AI, and that was an accident.
[01:39:37.120 --> 01:39:40.840]   So that was an accident.
[01:39:40.840 --> 01:39:44.320]   And that started out as a country or that was a country code.
[01:39:44.320 --> 01:39:47.360]   But which is why he's calling it accidental.
[01:39:47.360 --> 01:39:49.360]   For what country?
[01:39:49.360 --> 01:39:51.200]   Oh, what is Dot AI?
[01:39:51.200 --> 01:39:54.200]   Was it the islands?
[01:39:54.200 --> 01:39:58.200]   That'd be my guess.
[01:39:58.200 --> 01:40:00.440]   Dot TV had its own angular.
[01:40:00.440 --> 01:40:02.920]   Oh, it's in Guilla.
[01:40:02.920 --> 01:40:03.920]   In Guilla.
[01:40:03.920 --> 01:40:04.920]   In Guilla.
[01:40:04.920 --> 01:40:05.920]   In Guilla.
[01:40:05.920 --> 01:40:08.360]   Yeah, Dot, it was two volus.
[01:40:08.360 --> 01:40:09.360]   It was TV.
[01:40:09.360 --> 01:40:15.960]   Yeah, they actually sold off the rights to the domain to raise money because they basically
[01:40:15.960 --> 01:40:17.880]   have no economy.
[01:40:17.880 --> 01:40:19.680]   And they're sinking into the ocean.
[01:40:19.680 --> 01:40:22.680]   I thought that was fascinating.
[01:40:22.680 --> 01:40:26.800]   And then Libya had a big resurgence with Dot LY.
[01:40:26.800 --> 01:40:27.800]   If anybody wanted.
[01:40:27.800 --> 01:40:28.800]   If we see how.
[01:40:28.800 --> 01:40:30.960]   Yeah, bit.ly and musically.
[01:40:30.960 --> 01:40:31.960]   Oh, yeah.
[01:40:31.960 --> 01:40:32.960]   All the other.
[01:40:32.960 --> 01:40:33.960]   Good for Libya.
[01:40:33.960 --> 01:40:34.960]   Yeah.
[01:40:34.960 --> 01:40:35.960]   Good.
[01:40:35.960 --> 01:40:36.960]   Good for that.
[01:40:36.960 --> 01:40:41.040]   And I think that's really the every time I had to go to delicious, I had to think for
[01:40:41.040 --> 01:40:42.040]   five minutes.
[01:40:42.040 --> 01:40:43.040]   Yeah.
[01:40:43.040 --> 01:40:44.040]   Yeah.
[01:40:44.040 --> 01:40:45.040]   Dell is.
[01:40:45.040 --> 01:40:54.680]   Well, I think that Mullenway, he's got ma dot TT.
[01:40:54.680 --> 01:40:57.760]   But I forget what TT is the domain for.
[01:40:57.760 --> 01:41:01.080]   And why would that be good?
[01:41:01.080 --> 01:41:05.200]   See, unfortunately, Matthew, you couldn't use that.
[01:41:05.200 --> 01:41:06.200]   No, I couldn't.
[01:41:06.200 --> 01:41:08.200]   Because there's I don't have to.
[01:41:08.200 --> 01:41:13.600]   Did you do that so that no one would call you Matt?
[01:41:13.600 --> 01:41:14.880]   That was a theory.
[01:41:14.880 --> 01:41:19.840]   Yes, my mother loves the name Matthew, but hates the name Matt.
[01:41:19.840 --> 01:41:21.360]   Oh, really?
[01:41:21.360 --> 01:41:25.960]   So I explained to her later that you can't actually say the name Matthew so that it only
[01:41:25.960 --> 01:41:26.960]   has one T.
[01:41:26.960 --> 01:41:32.040]   So as soon as you say it, people start calling you Matt, but she actually at one point when
[01:41:32.040 --> 01:41:34.960]   I was in high school, people would call and say is Matt there.
[01:41:34.960 --> 01:41:37.360]   And she would say no one by that name lives here.
[01:41:37.360 --> 01:41:39.360]   And then she would have heard that.
[01:41:39.360 --> 01:41:40.360]   Wow.
[01:41:40.360 --> 01:41:43.360]   Are you sure that just wasn't some sort of passive aggressive thing against your friends?
[01:41:43.360 --> 01:41:44.360]   Oh, this exactly.
[01:41:44.360 --> 01:41:46.360]   It's going to be so much.
[01:41:46.360 --> 01:41:47.360]   So much.
[01:41:47.360 --> 01:41:50.600]   Oh, you know, here's my room for sticking to it.
[01:41:50.600 --> 01:41:53.760]   Yeah, I was going to say that's admirable, right?
[01:41:53.760 --> 01:41:55.960]   I'll make an offer to you guys.
[01:41:55.960 --> 01:41:56.960]   It doesn't agree.
[01:41:56.960 --> 01:42:02.920]   Hey, my husband is volunteering to come up and talk about top level domains and dot app.
[01:42:02.920 --> 01:42:07.440]   If you would like a domain name expert on this, however, yes, you.
[01:42:07.440 --> 01:42:08.440]   Oh, really?
[01:42:08.440 --> 01:42:10.440]   I mean, right?
[01:42:10.440 --> 01:42:13.040]   Whoever come on up.
[01:42:13.040 --> 01:42:14.040]   There we go.
[01:42:14.040 --> 01:42:16.560]   His wife is hungry and doesn't want to talk too long.
[01:42:16.560 --> 01:42:17.560]   Yeah.
[01:42:17.560 --> 01:42:18.560]   Oh, that's what I'm like.
[01:42:18.560 --> 01:42:20.920]   I'll go down and get a snack.
[01:42:20.920 --> 01:42:27.840]   Yes, this is only if you guys actually want this and he's he's coming up.
[01:42:27.840 --> 01:42:28.840]   So now you're.
[01:42:28.840 --> 01:42:31.000]   We're like, ask all.
[01:42:31.000 --> 01:42:34.120]   Ask all of your questions, man.
[01:42:34.120 --> 01:42:35.120]   Okay.
[01:42:35.120 --> 01:42:39.840]   And while we wait, all right.
[01:42:39.840 --> 01:42:40.840]   What else?
[01:42:40.840 --> 01:42:41.840]   What else?
[01:42:41.840 --> 01:42:46.240]   Final final things before we get the TLDR or the top level domain prior.
[01:42:46.240 --> 01:42:47.880]   I think you did a good job, boss.
[01:42:47.880 --> 01:42:49.800]   I even through all the good stuff.
[01:42:49.800 --> 01:42:50.800]   Got it.
[01:42:50.800 --> 01:42:52.280]   Let's see.
[01:42:52.280 --> 01:42:56.440]   Do we dive into tips and all that kind of stuff with the time that we have?
[01:42:56.440 --> 01:42:57.440]   Oh, yeah.
[01:42:57.440 --> 01:42:58.440]   You know what?
[01:42:58.440 --> 01:43:00.360]   I'm going to make my husband my tips since I didn't bring.
[01:43:00.360 --> 01:43:01.360]   There you go.
[01:43:01.360 --> 01:43:02.360]   Mine was kind of lazy.
[01:43:02.360 --> 01:43:03.360]   All right.
[01:43:03.360 --> 01:43:04.360]   That's a good idea.
[01:43:04.360 --> 01:43:05.360]   I'll go and help you.
[01:43:05.360 --> 01:43:09.640]   That's like when you're in kindergarten, you bring your mom for show and tell.
[01:43:09.640 --> 01:43:10.640]   That's right.
[01:43:10.640 --> 01:43:11.640]   Show for her.
[01:43:11.640 --> 01:43:12.640]   Yes.
[01:43:12.640 --> 01:43:13.640]   Mom, this is bring my husband to work day.
[01:43:13.640 --> 01:43:14.640]   Right.
[01:43:14.640 --> 01:43:18.040]   Do you think I don't know if this is an I/O question, but do you think that we're going
[01:43:18.040 --> 01:43:23.880]   to see that Google is going to straighten out the whole sort of music service, YouTube
[01:43:23.880 --> 01:43:25.600]   thread play thing?
[01:43:25.600 --> 01:43:29.080]   I think that's a big question mark.
[01:43:29.080 --> 01:43:32.120]   Because we're hearing these rumors and everything.
[01:43:32.120 --> 01:43:37.280]   I mean, if you were following what Ron Amadio wrote in his article, No, they probably aren't
[01:43:37.280 --> 01:43:39.920]   going to mention very much about that if at all.
[01:43:39.920 --> 01:43:41.640]   But yeah, I don't know.
[01:43:41.640 --> 01:43:47.400]   I feel like if there's any mention of kind of a podcast strategy like you were talking,
[01:43:47.400 --> 01:43:49.480]   that involves play music potentially.
[01:43:49.480 --> 01:43:53.280]   We're hearing a lot about, you know, they're making public comments about the kind of future
[01:43:53.280 --> 01:43:56.000]   of YouTube as a music platform.
[01:43:56.000 --> 01:44:00.520]   Maybe this is all happening right now because they're preparing for sort of an announcement.
[01:44:00.520 --> 01:44:02.800]   But I would certainly need to fix it.
[01:44:02.800 --> 01:44:05.520]   I think you just straighten it out for sure.
[01:44:05.520 --> 01:44:06.520]   Yeah.
[01:44:06.520 --> 01:44:07.520]   Absolutely.
[01:44:07.520 --> 01:44:08.520]   All right.
[01:44:08.520 --> 01:44:09.760]   So Jeff, you want to do your number?
[01:44:09.760 --> 01:44:11.160]   Oh, wait, my dude's here.
[01:44:11.160 --> 01:44:12.160]   Oh, wait a minute.
[01:44:12.160 --> 01:44:13.720]   He's trying to do it.
[01:44:13.720 --> 01:44:14.720]   Okay.
[01:44:14.720 --> 01:44:17.400]   My dude, the formal, the formal title.
[01:44:17.400 --> 01:44:18.400]   All right.
[01:44:18.400 --> 01:44:20.160]   I'm going to pass the stuff to him.
[01:44:20.160 --> 01:44:21.160]   Okay.
[01:44:21.160 --> 01:44:22.160]   Okay.
[01:44:22.160 --> 01:44:25.240]   We're passing the stuff to Stacy's dude right now.
[01:44:25.240 --> 01:44:27.960]   So everybody stand by while the stuff is passed by.
[01:44:27.960 --> 01:44:29.880]   Do not adjust your set.
[01:44:29.880 --> 01:44:30.880]   All right.
[01:44:30.880 --> 01:44:31.880]   I'm here.
[01:44:31.880 --> 01:44:34.720]   Hello, Stacy's dude as you were introduced to us.
[01:44:34.720 --> 01:44:35.880]   How's it going Andrew?
[01:44:35.880 --> 01:44:37.360]   Good to meet you.
[01:44:37.360 --> 01:44:40.280]   Nice to meet you as well.
[01:44:40.280 --> 01:44:41.280]   Welcome to the show.
[01:44:41.280 --> 01:44:42.280]   All right.
[01:44:42.280 --> 01:44:47.600]   So you're going to give us a primer on top level demand.
[01:44:47.600 --> 01:44:48.600]   A dot.
[01:44:48.600 --> 01:44:49.800]   A domain name is right.
[01:44:49.800 --> 01:44:51.800]   Is it worthwhile or not?
[01:44:51.800 --> 01:44:52.960]   You know, this is an interesting one.
[01:44:52.960 --> 01:44:56.160]   I think they're going to sell a lot of domain names and buy a lot.
[01:44:56.160 --> 01:44:57.640]   I mean, it's all relative, right?
[01:44:57.640 --> 01:45:00.400]   None of these new top level domain names is really taken off.
[01:45:00.400 --> 01:45:06.760]   I mean, .com has 135 million domains registered somewhere in that vicinity.
[01:45:06.760 --> 01:45:11.440]   The biggest of these new top level domains probably has a few million domains.
[01:45:11.440 --> 01:45:16.240]   And the only reason that many got registered is they literally like gave them away or sold
[01:45:16.240 --> 01:45:19.320]   them for a quarter or a penny.
[01:45:19.320 --> 01:45:23.920]   So it's relatively speaking, I think .app will be one of the bigger ones, but it still won't
[01:45:23.920 --> 01:45:27.640]   be human guess.
[01:45:27.640 --> 01:45:29.400]   And what would be the benefit of having one?
[01:45:29.400 --> 01:45:32.240]   Like why is it easier to remember?
[01:45:32.240 --> 01:45:34.720]   Are you going to be like, why would I want one?
[01:45:34.720 --> 01:45:39.040]   I mean, you might want to get a .app because you could get a short one that matches the
[01:45:39.040 --> 01:45:42.280]   name of an app you're bringing out rather than a long .com.
[01:45:42.280 --> 01:45:47.360]   You see a lot of times on .com domains like they'll use get something because they can't
[01:45:47.360 --> 01:45:52.040]   get the actual name of the app in .com.
[01:45:52.040 --> 01:45:56.600]   So it'll be shorter like that is in the .app signifies exactly what it is.
[01:45:56.600 --> 01:45:58.520]   Of course, you can do the same thing with a .com.
[01:45:58.520 --> 01:46:01.840]   You could do the name of your app, app.com.
[01:46:01.840 --> 01:46:07.480]   So I wouldn't say there's necessarily a benefit to using a .app domain other than maybe you
[01:46:07.480 --> 01:46:10.000]   can get a better domain name than you can get in .com.
[01:46:10.000 --> 01:46:11.000]   Right.
[01:46:11.000 --> 01:46:12.000]   Yeah.
[01:46:12.000 --> 01:46:13.000]   Yeah, that's a good point.
[01:46:13.000 --> 01:46:14.160]   I mean, the .coms are so clogged.
[01:46:14.160 --> 01:46:20.080]   It's impossible to get a decent domain anymore because someone's got it or it's related to
[01:46:20.080 --> 01:46:23.000]   some other thing that's got the same name.
[01:46:23.000 --> 01:46:24.000]   Right.
[01:46:24.000 --> 01:46:28.800]   Is there any data on consumer recollection of non-com, so to speak, domains?
[01:46:28.800 --> 01:46:32.760]   That's a tricky one, because even some of the names that have been out forever that aren't
[01:46:32.760 --> 01:46:38.040]   considered new top-level domains, but .org, which has been around for almost as long as
[01:46:38.040 --> 01:46:40.440]   .com, really.
[01:46:40.440 --> 01:46:44.360]   Even with that, sometimes people will go type the .com by accident.
[01:46:44.360 --> 01:46:46.160]   So there is a challenge there.
[01:46:46.160 --> 01:46:50.040]   And there's also with new top-level domain names, sometimes there's a singular and a
[01:46:50.040 --> 01:46:51.040]   plural.
[01:46:51.040 --> 01:46:55.040]   Like there's a .loan top-level domain and then a .loan top-level domain.
[01:46:55.040 --> 01:46:56.640]   So people have to remember that.
[01:46:56.640 --> 01:46:58.720]   So it can't get really confusing.
[01:46:58.720 --> 01:47:02.920]   There are a few that have been relatively successful.
[01:47:02.920 --> 01:47:05.520]   .club is one that's been fairly popular.
[01:47:05.520 --> 01:47:09.240]   They put a lot of marketing muscle into that one.
[01:47:09.240 --> 01:47:10.920]   And that's part of the reason.
[01:47:10.920 --> 01:47:17.000]   There's a site called ntldstats.com in like new.
[01:47:17.000 --> 01:47:22.000]   And you can see the number of registered domains there for each of these new top-level domain
[01:47:22.000 --> 01:47:23.000]   names.
[01:47:23.000 --> 01:47:26.720]   But I give you the caveat again that the ones you see at the top of the list, they're mostly
[01:47:26.720 --> 01:47:30.520]   there because they've offered heavily discounted domain names.
[01:47:30.520 --> 01:47:32.520]   And that has been somewhat of a challenge.
[01:47:32.520 --> 01:47:37.320]   So yeah, if you scroll down here, you'll see the top domains on the right-hand side.
[01:47:37.320 --> 01:47:43.400]   So .loan has about 2.6 million there.
[01:47:43.400 --> 01:47:47.920]   But again, they've done that by basically giving names away.
[01:47:47.920 --> 01:47:50.360]   All those top ones you see there.
[01:47:50.360 --> 01:47:55.400]   .vip has been pretty popular in China.
[01:47:55.400 --> 01:48:00.080]   So yeah, overall, obviously these numbers are fine.
[01:48:00.080 --> 01:48:06.000]   But again.com, 135 million names.org, over 10 million names.
[01:48:06.000 --> 01:48:07.640]   It's kind of hard to compare them.
[01:48:07.640 --> 01:48:12.320]   Even ones that like .info and .biz, I don't recall the most recent numbers.
[01:48:12.320 --> 01:48:15.040]   But we're talking single digit millions on those.
[01:48:15.040 --> 01:48:25.600]   Is it better to get to go the route of say like company name . obscure TLD versus company
[01:48:25.600 --> 01:48:28.880]   name with an extra attachment in the URL.com?
[01:48:28.880 --> 01:48:31.160]   Like is there any benefit to one versus the other?
[01:48:31.160 --> 01:48:32.160]   What do you think about that?
[01:48:32.160 --> 01:48:38.480]   Well, I think the having the .com again, like you guys said, do people remember .com?
[01:48:38.480 --> 01:48:41.680]   Or will they remember one of these new top level domain names when they go to type it
[01:48:41.680 --> 01:48:42.680]   in?
[01:48:42.680 --> 01:48:44.720]   And so again, that's the struggle there.
[01:48:44.720 --> 01:48:48.520]   Over time, I think people will become more comfortable with these new top level domains
[01:48:48.520 --> 01:48:50.080]   in these extensions.
[01:48:50.080 --> 01:48:57.040]   But right now in 2018, at least in the United States, the recognition there isn't very
[01:48:57.040 --> 01:48:58.400]   strong.
[01:48:58.400 --> 01:49:04.120]   Now, there's a lot of debate within circles on which one, which is better there, the
[01:49:04.120 --> 01:49:07.960]   longer .com or the shorter new top level domain name.
[01:49:07.960 --> 01:49:14.320]   But I think right now, again in the United States, at least the .com is your safer of
[01:49:14.320 --> 01:49:15.320]   the bets.
[01:49:15.320 --> 01:49:20.960]   Now, in some places in Europe .com is secondary to like the country code domain name, right?
[01:49:20.960 --> 01:49:21.960]   So non.com.
[01:49:21.960 --> 01:49:26.120]   Tell Karsten that your last name isn't taking a bottle.
[01:49:26.120 --> 01:49:28.440]   Stacey Chumpton.
[01:49:28.440 --> 01:49:34.640]   My last name is not taking a bottle of them, but I do get caught in this for taking a bottle
[01:49:34.640 --> 01:49:35.640]   of them.
[01:49:35.640 --> 01:49:45.000]   I wish you did you pay them to do that.
[01:49:45.000 --> 01:49:48.760]   So my last name is Olliman, A-L-L-E-M-A-N.
[01:49:48.760 --> 01:49:51.760]   And so,
[01:49:51.760 --> 01:49:55.920]   I'm taking both of them as a fine name.
[01:49:55.920 --> 01:49:57.160]   It's very long and it's difficult to spell.
[01:49:57.160 --> 01:49:59.120]   I guess my last name is too.
[01:49:59.120 --> 01:50:00.120]   Yeah.
[01:50:00.120 --> 01:50:02.200]   So I write about all this about domain names.
[01:50:02.200 --> 01:50:04.480]   That's like Stacey does something important.
[01:50:04.480 --> 01:50:09.560]   The Internet of Things I write about something not as important domain names on domain name
[01:50:09.560 --> 01:50:10.560]   wire .com.
[01:50:10.560 --> 01:50:13.320]   So do you have an breathe this stuff?
[01:50:13.320 --> 01:50:20.320]   Do you own many URLs attached to many obscure domain names to kind of breathe it?
[01:50:20.320 --> 01:50:22.520]   I have about 1,300.
[01:50:22.520 --> 01:50:23.520]   Yeah.
[01:50:23.520 --> 01:50:24.520]   I'm a domain.
[01:50:24.520 --> 01:50:27.800]   So in some of those are new top level domains.
[01:50:27.800 --> 01:50:29.960]   Most of them are .com domains.
[01:50:29.960 --> 01:50:32.440]   But you have to understand in the circles I'm in.
[01:50:32.440 --> 01:50:34.680]   1,300 names is not many names.
[01:50:34.680 --> 01:50:39.760]   We're talking people of hundreds of thousands, in some cases millions.
[01:50:39.760 --> 01:50:43.080]   So I stupidly let a four letter domain go.
[01:50:43.080 --> 01:50:45.520]   How much would that be worth though?
[01:50:45.520 --> 01:50:46.520]   Four letters.
[01:50:46.520 --> 01:50:48.720]   It really depends on the letters.
[01:50:48.720 --> 01:50:51.680]   The low single digit thousands.
[01:50:51.680 --> 01:50:56.360]   It's the three letter domains where you start talking at least 10 to 15,000.
[01:50:56.360 --> 01:50:58.160]   Oftentimes much more.
[01:50:58.160 --> 01:51:02.560]   Two letter domains, at least a half million dollars.
[01:51:02.560 --> 01:51:08.440]   And then there are a few one letter domains out there and those are in the millions.
[01:51:08.440 --> 01:51:10.320]   So we're talking about .com here.
[01:51:10.320 --> 01:51:11.320]   Yeah.
[01:51:11.320 --> 01:51:12.320]   Thank you.
[01:51:12.320 --> 01:51:14.800]   Matthew, it was one of the names we tried for day life back in the day.
[01:51:14.800 --> 01:51:16.120]   And it was what the world knows.
[01:51:16.120 --> 01:51:17.120]   So wtwk.com.
[01:51:17.120 --> 01:51:18.120]   Wow.
[01:51:18.120 --> 01:51:20.800]   It's a big thing.
[01:51:20.800 --> 01:51:25.760]   So the interesting thing is a few years ago before Bitcoin, before cryptocurrency was
[01:51:25.760 --> 01:51:30.040]   a big craze in China, people were investing in a lot of these short domain names and they're
[01:51:30.040 --> 01:51:32.440]   treating them almost like a cryptocurrency.
[01:51:32.440 --> 01:51:33.800]   It was an asset.
[01:51:33.800 --> 01:51:39.080]   They buy a huge swaths of these four letter domains, five letter, number domains.
[01:51:39.080 --> 01:51:42.200]   And they invested millions and millions of dollars in these.
[01:51:42.200 --> 01:51:46.120]   So that's why these three four character domain names kind of really started over the past
[01:51:46.120 --> 01:51:47.920]   few years to take off in value.
[01:51:47.920 --> 01:51:52.120]   So yeah, it's a fascinating little corner of the world.
[01:51:52.120 --> 01:51:53.360]   So when you have that many.
[01:51:53.360 --> 01:51:54.360]   Sorry.
[01:51:54.360 --> 01:51:55.360]   Go ahead.
[01:51:55.360 --> 01:52:02.240]   I was just going to ask like when you have when you own that many, you know, URLs domains,
[01:52:02.240 --> 01:52:03.800]   like what do you do with them?
[01:52:03.800 --> 01:52:07.520]   Just collect them, fold onto them and wait for someone to come along and be like, hey,
[01:52:07.520 --> 01:52:12.240]   actually, generally, yes, I wait for someone to come along that wants to use it for their
[01:52:12.240 --> 01:52:13.240]   website.
[01:52:13.240 --> 01:52:16.920]   And so just to be clear here, these are kind of generic or dictionary terms, right?
[01:52:16.920 --> 01:52:20.600]   I'm not, I'm not cyber squatting on brands and that sort of thing.
[01:52:20.600 --> 01:52:24.360]   So generally speaking, I'll just put a page up there that says it's for sale.
[01:52:24.360 --> 01:52:27.440]   And if someone comes along and they, they like it, they make an offer.
[01:52:27.440 --> 01:52:31.360]   And if we, if we can strike a bargain, then, then we do a deal.
[01:52:31.360 --> 01:52:32.360]   Nice.
[01:52:32.360 --> 01:52:39.040]   So, so I own Schmittternet.com as an internet Schmittert, which was a, which was from this
[01:52:39.040 --> 01:52:41.080]   show years ago.
[01:52:41.080 --> 01:52:48.040]   And see if I, if I try to stop carstering, having to put this, I own sh it widget.com.
[01:52:48.040 --> 01:52:50.760]   I can't even remember why.
[01:52:50.760 --> 01:52:51.760]   Why not?
[01:52:51.760 --> 01:52:52.760]   Why not?
[01:52:52.760 --> 01:52:56.120]   That's the answer to a lot of the main name registration ones.
[01:52:56.120 --> 01:52:57.120]   Yeah.
[01:52:57.120 --> 01:52:59.640]   Although it has widget in it, which means it's already dated.
[01:52:59.640 --> 01:53:00.640]   Right.
[01:53:00.640 --> 01:53:02.600]   Which is the thing of the past at this point.
[01:53:02.600 --> 01:53:03.600]   It's true.
[01:53:03.600 --> 01:53:04.600]   Yeah.
[01:53:04.600 --> 01:53:09.000]   I've owned my share of domain names that were once popular terms that no longer are.
[01:53:09.000 --> 01:53:10.000]   So.
[01:53:10.000 --> 01:53:14.280]   Well, yeah, no, and at what point do you kind of pull the trigger and be like, eh, this,
[01:53:14.280 --> 01:53:16.520]   this is no longer needed by anybody.
[01:53:16.520 --> 01:53:17.720]   I can let go of this.
[01:53:17.720 --> 01:53:18.720]   Right.
[01:53:18.720 --> 01:53:19.720]   Right.
[01:53:19.720 --> 01:53:20.720]   Exactly.
[01:53:20.720 --> 01:53:21.720]   Not any second decision to make.
[01:53:21.720 --> 01:53:23.800]   Uh, any other questions?
[01:53:23.800 --> 01:53:25.520]   I think that's, thank you.
[01:53:25.520 --> 01:53:26.520]   Thank you.
[01:53:26.520 --> 01:53:27.520]   Yeah.
[01:53:27.520 --> 01:53:28.520]   Yeah.
[01:53:28.520 --> 01:53:35.680]   You asked us to apologize for holding your wife too late on afternoon on these afternoons
[01:53:35.680 --> 01:53:36.920]   and delaying dinner.
[01:53:36.920 --> 01:53:37.920]   That's so.
[01:53:37.920 --> 01:53:41.880]   So the two you go out to dinner, I, we apologize, but, but Stacy too wonderful.
[01:53:41.880 --> 01:53:43.720]   So we hold on to her.
[01:53:43.720 --> 01:53:44.720]   Awesome.
[01:53:44.720 --> 01:53:46.360]   And you can leave the olliman up for her.
[01:53:46.360 --> 01:53:48.760]   You can do Stacy olliman now if you want.
[01:53:48.760 --> 01:53:49.760]   All right.
[01:53:49.760 --> 01:53:50.760]   Even things.
[01:53:50.760 --> 01:53:51.760]   Thank you, Andrew.
[01:53:51.760 --> 01:53:52.760]   See you guys.
[01:53:52.760 --> 01:53:53.760]   Take care.
[01:53:53.760 --> 01:53:56.760]   Andrew, that was fun.
[01:53:56.760 --> 01:53:59.760]   That was worth explaining gold.
[01:53:59.760 --> 01:54:02.160]   I'm going to share that with everybody.
[01:54:02.160 --> 01:54:03.160]   Mr.
[01:54:03.160 --> 01:54:04.160]   Hickenbob is great.
[01:54:04.160 --> 01:54:08.920]   And I think, I think the tool or the tip is ntldstats.com aside.
[01:54:08.920 --> 01:54:11.720]   I never knew existed and it's very interesting to look at.
[01:54:11.720 --> 01:54:14.080]   I didn't realize weighing was in the top 10.
[01:54:14.080 --> 01:54:15.080]   Yeah.
[01:54:15.080 --> 01:54:16.320]   Number eight.
[01:54:16.320 --> 01:54:19.520]   Number eight down 440 something's.
[01:54:19.520 --> 01:54:20.520]   Yeah.
[01:54:20.520 --> 01:54:22.760]   For what it says there.
[01:54:22.760 --> 01:54:23.760]   Cool stuff.
[01:54:23.760 --> 01:54:26.320]   Uh, Jeff, what is your number?
[01:54:26.320 --> 01:54:27.320]   Okay.
[01:54:27.320 --> 01:54:28.320]   Ushis.
[01:54:28.320 --> 01:54:34.120]   Um, so, um, so I was going to do the fact that a quarter of all Taco Bell orders are
[01:54:34.120 --> 01:54:36.720]   had not show fries and they're not going to do that.
[01:54:36.720 --> 01:54:38.120]   I don't expect what Stacy.
[01:54:38.120 --> 01:54:45.000]   Um, but I am going to say, uh, that there's a, a, a, a one of those kind of gift, Jeff
[01:54:45.000 --> 01:54:49.040]   fights is going to drive us nuts for years, a Bruin thanks to Buzzfeed, which is what
[01:54:49.040 --> 01:54:50.040]   they do well.
[01:54:50.040 --> 01:54:51.040]   Oh, yeah.
[01:54:51.040 --> 01:54:52.040]   I am a Joe.
[01:54:52.040 --> 01:54:53.440]   I am a Joe.
[01:54:53.440 --> 01:54:57.080]   What does the H stand for before we do anything?
[01:54:57.080 --> 01:54:58.080]   A poll.
[01:54:58.080 --> 01:55:00.080]   Each of you say the H stands for.
[01:55:00.080 --> 01:55:01.080]   That's the combo.
[01:55:01.080 --> 01:55:02.080]   Matthew Humboldt.
[01:55:02.080 --> 01:55:03.080]   Yeah.
[01:55:03.080 --> 01:55:04.080]   Yeah.
[01:55:04.080 --> 01:55:07.680]   And anybody who's over 25 knows that it's humble.
[01:55:07.680 --> 01:55:09.760]   Wait, what's it supposed to be?
[01:55:09.760 --> 01:55:16.200]   Well, it's honest, honest, over 50% of people think it's honest.
[01:55:16.200 --> 01:55:20.560]   According to their own side, but that's very disturbing.
[01:55:20.560 --> 01:55:21.560]   It's crazy.
[01:55:21.560 --> 01:55:22.560]   It's crazy.
[01:55:22.560 --> 01:55:23.560]   Yeah.
[01:55:23.560 --> 01:55:24.560]   Yeah.
[01:55:24.560 --> 01:55:25.560]   Okay.
[01:55:25.560 --> 01:55:26.560]   Yeah, that's, that's weird.
[01:55:26.560 --> 01:55:27.560]   I mean, acronyms are hard.
[01:55:27.560 --> 01:55:32.160]   I had someone who their moms thought L.O.L. meant, uh, lots of love.
[01:55:32.160 --> 01:55:37.840]   And so they would put L.O.L. at the end of, uh, you know, after it's like a sad message
[01:55:37.840 --> 01:55:42.040]   in a text, they would put L.O.L. because it's not a meant lot, lots of love until their
[01:55:42.040 --> 01:55:45.960]   child said it sounds like you're laughing at me.
[01:55:45.960 --> 01:55:48.120]   But no, no, I thought it was lots of love.
[01:55:48.120 --> 01:55:53.600]   I mean, it is hard if you don't know what things stand for, but it's obviously humble.
[01:55:53.600 --> 01:55:54.600]   It's humble and they're wrong.
[01:55:54.600 --> 01:55:55.600]   Everyone.
[01:55:55.600 --> 01:55:56.600]   Yes.
[01:55:56.600 --> 01:55:58.080]   In our humble opinion.
[01:55:58.080 --> 01:55:59.080]   Yeah.
[01:55:59.080 --> 01:56:00.080]   Yes.
[01:56:00.080 --> 01:56:01.080]   Exactly.
[01:56:01.080 --> 01:56:04.160]   Uh, Matthew, what you got?
[01:56:04.160 --> 01:56:05.680]   Uh, what do I got?
[01:56:05.680 --> 01:56:10.160]   Um, I was interested in something that this isn't a tip or a trick or anything, but I
[01:56:10.160 --> 01:56:14.080]   was interested in something that was in the lineup we didn't get to, which was snap.
[01:56:14.080 --> 01:56:15.080]   Oh, yeah.
[01:56:15.080 --> 01:56:17.000]   Uh, has gotten snapped.
[01:56:17.000 --> 01:56:21.600]   They're stock, uh, tanked, uh, results, not great.
[01:56:21.600 --> 01:56:23.600]   Lots of people don't like the redesign.
[01:56:23.600 --> 01:56:28.120]   Uh, I just thought it was fascinating that, you know, for a long time, they were the, the
[01:56:28.120 --> 01:56:32.280]   bomb and they were going up and to the right at a huge rate.
[01:56:32.280 --> 01:56:37.080]   Um, their MAU and DAU numbers are not great.
[01:56:37.080 --> 01:56:40.040]   Um, might be the redesign.
[01:56:40.040 --> 01:56:45.920]   Maybe anyway, I thought it was interesting that it's something that I watch from afar.
[01:56:45.920 --> 01:56:48.200]   Like I don't use it a lot, but my kids do.
[01:56:48.200 --> 01:56:52.000]   And, um, and I find it fascinating as a company.
[01:56:52.000 --> 01:56:55.920]   So interesting to see if they can kind of get back to.
[01:56:55.920 --> 01:56:56.920]   Yeah.
[01:56:56.920 --> 01:57:00.440]   Superstar again or now your kids are, are using snap.
[01:57:00.440 --> 01:57:06.120]   Have they been, um, lure, have they been interested in kind of heading over to Instagram, which
[01:57:06.120 --> 01:57:08.520]   seems to be the, the kind of biggest direct.
[01:57:08.520 --> 01:57:10.120]   So, yeah.
[01:57:10.120 --> 01:57:16.040]   And I think certainly when Instagram, uh, launch stories that I think sucked a huge amount
[01:57:16.040 --> 01:57:21.240]   of oxygen out of snap because that was one of the main things that certainly my kids,
[01:57:21.240 --> 01:57:24.200]   um, you know, who are in their twenties.
[01:57:24.200 --> 01:57:26.240]   That's, that's almost all they did.
[01:57:26.240 --> 01:57:30.560]   And they certainly didn't really look at any of the other snap stuff, like discover.
[01:57:30.560 --> 01:57:35.880]   I don't think most of them even knew what it was for or why they would care that CNN or
[01:57:35.880 --> 01:57:37.800]   time put something up on snap.
[01:57:37.800 --> 01:57:38.800]   Right.
[01:57:38.800 --> 01:57:39.800]   You know, it was all about the stories.
[01:57:39.800 --> 01:57:43.680]   And so Instagram, Instagram is also much more social.
[01:57:43.680 --> 01:57:47.280]   So snap is very, you know, private, which is good.
[01:57:47.280 --> 01:57:52.160]   But if you're interested in the social aspect at all, then Instagram is much better for
[01:57:52.160 --> 01:57:53.160]   that.
[01:57:53.160 --> 01:57:58.160]   So a lot of, um, uptake sort of in Instagram stories.
[01:57:58.160 --> 01:57:59.160]   Hmm.
[01:57:59.160 --> 01:58:00.160]   Interesting.
[01:58:00.160 --> 01:58:01.160]   Yeah.
[01:58:01.160 --> 01:58:08.840]   It's very, um, I like, I'm not a Snapchat user, um, but I feel like the dialogue around
[01:58:08.840 --> 01:58:12.520]   Snapchat has been all over the map, but just in the last couple of years, like you were
[01:58:12.520 --> 01:58:18.920]   saying, you know, top of the world and now can do no right, you know, even with the redesign,
[01:58:18.920 --> 01:58:25.120]   which Evan Spiegel, you know, had had mentioned during this, this, uh, earnings announcement
[01:58:25.120 --> 01:58:29.240]   that, you know, there were big changes to the design and that's going, it's just too
[01:58:29.240 --> 01:58:32.520]   big of a thing to avoid some disruption.
[01:58:32.520 --> 01:58:36.440]   I guess the question is, is that really the entirety of the disruption?
[01:58:36.440 --> 01:58:40.760]   Is that the entire reason why or they're dealing with a number of different forces spectacles
[01:58:40.760 --> 01:58:41.760]   to help?
[01:58:41.760 --> 01:58:42.760]   Yeah.
[01:58:42.760 --> 01:58:45.360]   But spectacles, I mean, I don't know.
[01:58:45.360 --> 01:58:49.440]   I never saw that as being much more than a, a marketing thing.
[01:58:49.440 --> 01:58:50.440]   It doesn't.
[01:58:50.440 --> 01:58:51.440]   Yeah.
[01:58:51.440 --> 01:58:54.640]   And it's interesting that they're doing it, but, and they call themselves a camera company.
[01:58:54.640 --> 01:59:02.160]   Um, you know, I just, it feels like they need like a second act kind of, they need something
[01:59:02.160 --> 01:59:07.560]   to move on to, you know, cause the lots of people use it and I think it's great, but some
[01:59:07.560 --> 01:59:09.240]   of them are moving away.
[01:59:09.240 --> 01:59:11.840]   So it's got to be something that kind of juice things up again.
[01:59:11.840 --> 01:59:17.400]   I mean, when your stock drops, I think Chrissy Teigen, a disk snap and the stock dropped
[01:59:17.400 --> 01:59:20.360]   like 20% or something, like billions of dollars in market value.
[01:59:20.360 --> 01:59:25.960]   Um, you know, when that happens, you know, you got to branch out a little bit, maybe.
[01:59:25.960 --> 01:59:26.960]   Yeah.
[01:59:26.960 --> 01:59:28.800]   Wait, didn't they piss off Rihanna too?
[01:59:28.800 --> 01:59:31.880]   Was there an unfortunate Chris Brown reference or something?
[01:59:31.880 --> 01:59:33.560]   They did an ad campaign featuring.
[01:59:33.560 --> 01:59:34.560]   Yes.
[01:59:34.560 --> 01:59:35.560]   Yeah.
[01:59:35.560 --> 01:59:36.560]   Yeah.
[01:59:36.560 --> 01:59:37.560]   That's right.
[01:59:37.560 --> 01:59:38.560]   They did.
[01:59:38.560 --> 01:59:39.560]   Yeah.
[01:59:39.560 --> 01:59:40.560]   Yeah.
[01:59:40.560 --> 01:59:41.560]   Right.
[01:59:41.560 --> 01:59:42.560]   Nope.
[01:59:42.560 --> 01:59:43.560]   Nope.
[01:59:43.560 --> 01:59:44.560]   Nope.
[01:59:44.560 --> 01:59:45.560]   Nope.
[01:59:45.560 --> 01:59:46.560]   Nope.
[01:59:46.560 --> 01:59:47.560]   Nope.
[01:59:47.560 --> 01:59:48.560]   Nope.
[01:59:48.560 --> 01:59:49.560]   Nope.
[01:59:49.560 --> 01:59:50.560]   Nope.
[01:59:50.560 --> 01:59:51.560]   Nope.
[01:59:51.560 --> 01:59:52.560]   Nope.
[01:59:52.560 --> 01:59:53.560]   Um, mine is a tip.
[01:59:53.560 --> 01:59:54.560]   If you didn't know, uh, well, you all know about assistant.
[01:59:54.560 --> 01:59:55.560]   This isn't great.
[01:59:55.560 --> 01:59:56.560]   Uh, it can do so many things.
[01:59:56.560 --> 01:59:58.960]   Sometimes it can be hard to know just how many things it can do and how good those things
[01:59:58.960 --> 01:59:59.960]   are.
[01:59:59.960 --> 02:00:00.960]   I'll show you this.
[02:00:00.960 --> 02:00:03.600]   If you launch assistant, it's a new feature.
[02:00:03.600 --> 02:00:05.360]   You can go into your thing.
[02:00:05.360 --> 02:00:07.440]   It'll take you to your explore tab.
[02:00:07.440 --> 02:00:12.520]   You can go to any of these and jump in and not only can you rate it, you can also review
[02:00:12.520 --> 02:00:13.520]   it now.
[02:00:13.520 --> 02:00:19.440]   You can leave, uh, reviews on these actions now to get it and, you know, leave a review,
[02:00:19.440 --> 02:00:24.040]   read other people's reviews to kind of get a nice sense and hopefully kind of, you know,
[02:00:24.040 --> 02:00:28.680]   bring more awareness to all the things that assistant can do for you because I feel like
[02:00:28.680 --> 02:00:29.680]   I get lost.
[02:00:29.680 --> 02:00:32.000]   Like on one hand, it's great that it does so many things.
[02:00:32.000 --> 02:00:35.440]   On the other hand, it does so many things that it's really hard to know what to focus
[02:00:35.440 --> 02:00:36.440]   on maybe.
[02:00:36.440 --> 02:00:40.640]   Um, but anyways, if you want to find out more information about some of these, you can,
[02:00:40.640 --> 02:00:44.560]   uh, you can leave a review or find out what other people are saying about talk to universe
[02:00:44.560 --> 02:00:47.000]   facts and that sort of stuff.
[02:00:47.000 --> 02:00:50.600]   More context, uh, and discovery never hurt anyone.
[02:00:50.600 --> 02:00:58.520]   I think that is it's we've, uh, we've, we've come up with the title for Matthews next big
[02:00:58.520 --> 02:01:02.520]   podcast called kunukka, kunukka, kunukka cast.
[02:01:02.520 --> 02:01:05.040]   I really have a hard time saying that.
[02:01:05.040 --> 02:01:06.040]   It's not easy to say.
[02:01:06.040 --> 02:01:07.040]   It's a Canadian.
[02:01:07.040 --> 02:01:12.320]   So obviously you'd be really good at saying it then Matthew and that's why it should be
[02:01:12.320 --> 02:01:13.720]   the name of your podcast.
[02:01:13.720 --> 02:01:14.960]   Matthew, you have to do it.
[02:01:14.960 --> 02:01:15.960]   Sorry.
[02:01:15.960 --> 02:01:17.960]   You have to do it while you're out of the house.
[02:01:17.960 --> 02:01:22.000]   Oh, I was going to say you could do connect kunukka.a.
[02:01:22.000 --> 02:01:23.000]   Yeah.
[02:01:23.000 --> 02:01:24.000]   Dot a.
[02:01:24.000 --> 02:01:26.200]   That's a good one.
[02:01:26.200 --> 02:01:27.200]   Is that a good?
[02:01:27.200 --> 02:01:28.200]   No.
[02:01:28.200 --> 02:01:29.200]   Can I connect?
[02:01:29.200 --> 02:01:30.200]   Can you cast dot?
[02:01:30.200 --> 02:01:31.200]   Sorry.
[02:01:31.200 --> 02:01:35.280]   Yeah, and I apologize about that.
[02:01:35.280 --> 02:01:36.880]   Matthew, I have many Canadian jokes.
[02:01:36.880 --> 02:01:37.880]   We've just used them all.
[02:01:37.880 --> 02:01:38.880]   Okay.
[02:01:38.880 --> 02:01:39.880]   All right.
[02:01:39.880 --> 02:01:40.880]   All right.
[02:01:40.880 --> 02:01:41.880]   So not offending.
[02:01:41.880 --> 02:01:47.480]   We haven't, we haven't referenced strange brew or hockey yet or Justin Bieber or Mike
[02:01:47.480 --> 02:01:52.600]   Myers, uh, Matthew, what, uh, what do you want to leave people with?
[02:01:52.600 --> 02:01:55.280]   Where can people follow all the stuff you're doing online?
[02:01:55.280 --> 02:01:59.960]   Uh, well, place I spend the most time, of course, is Twitter at Matthew.
[02:01:59.960 --> 02:02:04.200]   I was one T and I write at CJR dot org.
[02:02:04.200 --> 02:02:05.200]   Right on.
[02:02:05.200 --> 02:02:06.200]   Always fun, Matthew.
[02:02:06.200 --> 02:02:07.200]   Thank you for joining us today.
[02:02:07.200 --> 02:02:08.200]   Thanks for having me.
[02:02:08.200 --> 02:02:09.200]   Really appreciate it.
[02:02:09.200 --> 02:02:12.720]   And Stacy, it was great to check in with you again and have you on this week.
[02:02:12.720 --> 02:02:14.840]   Tell people what you're working on.
[02:02:14.840 --> 02:02:18.920]   Oh, I was going to give people a way to find my husband if they wanted to.
[02:02:18.920 --> 02:02:19.920]   Perfect.
[02:02:19.920 --> 02:02:21.480]   But because you know where to find me.
[02:02:21.480 --> 02:02:27.840]   So if you want to find him, you can find him at dnw.com and yeah.
[02:02:27.840 --> 02:02:35.640]   Or at my, at my smart house or dnw.biz or dnw.com or D&W dot.
[02:02:35.640 --> 02:02:40.520]   You know, I don't know if anyone wants to play a joke on him, they can go and buy with
[02:02:40.520 --> 02:02:41.520]   him.
[02:02:41.520 --> 02:02:42.520]   Yeah.
[02:02:42.520 --> 02:02:44.520]   Dnw dot app.
[02:02:44.520 --> 02:02:45.520]   Go.
[02:02:45.520 --> 02:02:48.920]   Oh, here, here's an interesting, uh, uh, fact.
[02:02:48.920 --> 02:02:57.040]   So dot EH is not actually a country level top level domain, but it is reserved in case,
[02:02:57.040 --> 02:03:03.040]   uh, Western Sahara, uh, becomes a, uh, it's a disputed territory.
[02:03:03.040 --> 02:03:04.120]   It's a disputed territory.
[02:03:04.120 --> 02:03:08.980]   So if the Western Sahara conflict results in an agreement between Morocco and the armies
[02:03:08.980 --> 02:03:14.240]   in the territory, then Western Sahara will get the EH domain name and then I can get it.
[02:03:14.240 --> 02:03:15.240]   So, yeah.
[02:03:15.240 --> 02:03:19.200]   Dude, we could, it was out on Wikipedia because it was awesome.
[02:03:19.200 --> 02:03:21.200]   And now I feel like I could go on the.
[02:03:21.200 --> 02:03:22.200]   It sure was.
[02:03:22.200 --> 02:03:26.680]   So Stacy, Stacy, I heard that as.
[02:03:26.680 --> 02:03:29.400]   Go to D and W dot com.
[02:03:29.400 --> 02:03:30.400]   Please go there.
[02:03:30.400 --> 02:03:33.000]   That's where I thought your husband, D and W.
[02:03:33.000 --> 02:03:34.000]   D and W.
[02:03:34.000 --> 02:03:35.000]   Please go there right now.
[02:03:35.000 --> 02:03:37.000]   Uh, should we be worried?
[02:03:37.000 --> 02:03:40.000]   Am I going to regret this?
[02:03:40.000 --> 02:03:41.000]   Yeah.
[02:03:41.000 --> 02:03:42.000]   Oh, nice.
[02:03:42.000 --> 02:03:43.000]   Oh, recipes.
[02:03:43.000 --> 02:03:44.000]   Yeah.
[02:03:44.000 --> 02:03:45.000]   Spread the Watson.
[02:03:45.000 --> 02:03:46.000]   So someone's grandma.
[02:03:46.000 --> 02:03:47.000]   I think it's awesome.
[02:03:47.000 --> 02:03:48.000]   Cooks food or something.
[02:03:48.000 --> 02:03:49.000]   Okay.
[02:03:49.000 --> 02:03:50.000]   All right.
[02:03:50.000 --> 02:03:51.000]   Turkey.
[02:03:51.000 --> 02:03:52.000]   Now I'm going to have a drink.
[02:03:52.000 --> 02:03:57.000]   Yeah, Turkey.
[02:03:57.000 --> 02:03:59.120]   And W dot com.
[02:03:59.120 --> 02:04:01.920]   Chicken breast, Buffalo style chicken breast.
[02:04:01.920 --> 02:04:02.920]   Turkey.
[02:04:02.920 --> 02:04:05.920]   That's not as interesting as my Western Sahara fact.
[02:04:05.920 --> 02:04:08.120]   It's a press company.
[02:04:08.120 --> 02:04:09.600]   But yeah, no, no.
[02:04:09.600 --> 02:04:10.600]   Company has.
[02:04:10.600 --> 02:04:11.600]   You know what?
[02:04:11.600 --> 02:04:12.600]   It's easy to make sense kind of, right?
[02:04:12.600 --> 02:04:14.440]   You know, it's the food in the house.
[02:04:14.440 --> 02:04:17.080]   It does domain name wires what it stands for.
[02:04:17.080 --> 02:04:20.640]   And I think he owns domain name wire, but that's, that's so many letters.
[02:04:20.640 --> 02:04:21.640]   Yes.
[02:04:21.640 --> 02:04:22.640]   All right.
[02:04:22.640 --> 02:04:24.560]   We're giving you plenty of sites to check out today.
[02:04:24.560 --> 02:04:25.920]   Thank you, Stacy.
[02:04:25.920 --> 02:04:27.520]   Uh, Jeff, what about you?
[02:04:27.520 --> 02:04:29.000]   Do you have any more days?
[02:04:29.000 --> 02:04:30.560]   Uh, more, more, more, more, more, more, more, more keynote.
[02:04:30.560 --> 02:04:31.840]   It's heard enough of me.
[02:04:31.840 --> 02:04:33.400]   The world has heard enough of me.
[02:04:33.400 --> 02:04:34.400]   That's it.
[02:04:34.400 --> 02:04:35.400]   All right.
[02:04:35.400 --> 02:04:37.520]   Well, I appreciate the opportunity to get to podcast with you guys.
[02:04:37.520 --> 02:04:38.960]   It's been a lot of fun today.
[02:04:38.960 --> 02:04:39.960]   Always fun.
[02:04:39.960 --> 02:04:40.960]   Great job.
[02:04:40.960 --> 02:04:41.960]   Great job.
[02:04:41.960 --> 02:04:42.960]   Thank you.
[02:04:42.960 --> 02:04:43.960]   Thank you.
[02:04:43.960 --> 02:04:44.960]   That's your last.
[02:04:44.960 --> 02:04:45.960]   Uh, you bet.
[02:04:45.960 --> 02:04:46.960]   Uh, you can find me on Twitter.
[02:04:46.960 --> 02:04:48.360]   I mean, I'm here all over the network.
[02:04:48.360 --> 02:04:54.600]   Uh, all about Android, uh, tech news weekly, uh, know how, screen savers, pretty much everything.
[02:04:54.600 --> 02:04:57.800]   You know, most of the shows that we're doing on the network, I drop in from time to time
[02:04:57.800 --> 02:04:59.000]   and I have a lot of fun doing it.
[02:04:59.000 --> 02:05:01.000]   So I'll see you here on the network.
[02:05:01.000 --> 02:05:04.600]   Uh, if you want to find this showed, that's easy to find.
[02:05:04.600 --> 02:05:06.800]   You go to twit.tv/twig, T-W-I-G.
[02:05:06.800 --> 02:05:11.760]   There you can find all the information to subscribe, all of our past episodes.
[02:05:11.760 --> 02:05:14.920]   If you want to get caught up so you know what's going to, so what we're leading up
[02:05:14.920 --> 02:05:18.280]   to on the next episode, you don't want to lose the, the plot line.
[02:05:18.280 --> 02:05:19.280]   You can do that.
[02:05:19.280 --> 02:05:20.280]   Go to twit.tv/twig.
[02:05:20.280 --> 02:05:23.880]   Uh, and if you want to catch us live, you can do that as well.
[02:05:23.880 --> 02:05:26.520]   We record live every Wednesday at 4 p.m.
[02:05:26.520 --> 02:05:27.960]   Eastern 1 p.m.
[02:05:27.960 --> 02:05:31.000]   Pacific, uh, 20 hundred UTC.
[02:05:31.000 --> 02:05:33.000]   Although next week that's different.
[02:05:33.000 --> 02:05:34.000]   What is it, Carson?
[02:05:34.000 --> 02:05:35.800]   Next week on Tuesday.
[02:05:35.800 --> 02:05:37.760]   On Tuesday at sometime.
[02:05:37.760 --> 02:05:38.760]   11th or 12th.
[02:05:38.760 --> 02:05:39.760]   That's right.
[02:05:39.760 --> 02:05:40.760]   11th or 12th.
[02:05:40.760 --> 02:05:48.160]   Uh, 12 p.m. after we have the Google I/O keynote, which is also on twit.tv/live and
[02:05:48.160 --> 02:05:49.160]   you can watch that live.
[02:05:49.160 --> 02:05:50.800]   Uh, we'll be covering that as well.
[02:05:50.800 --> 02:05:53.480]   Uh, I will be at Google I/O, so I'll wave to you from afar.
[02:05:53.480 --> 02:05:55.320]   Uh, but that is it for this week.
[02:05:55.320 --> 02:05:58.360]   We'll see y'all next week on another episode of This Week in Google.
[02:05:58.360 --> 02:05:59.360]   Take care you guys.
[02:05:59.360 --> 02:05:59.360]   Bye.
[02:05:59.360 --> 02:05:59.960]   Bye!
[02:05:59.960 --> 02:06:08.960]   [Music]

