;FFMETADATA1
title=Last Media
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=382
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.080]   It's time for Twig this week in Google, Stacey Higginbotham, Matthew Ingram and Jeff Jarvis
[00:00:06.080 --> 00:00:09.280]   are all here to talk about some Googly stuff.
[00:00:09.280 --> 00:00:11.480]   Google's gone all solar.
[00:00:11.480 --> 00:00:16.080]   Deep Minds has an ethics board, but no one will say who it is.
[00:00:16.080 --> 00:00:18.920]   And it looks like they're dropping the drone deliveries.
[00:00:18.920 --> 00:00:20.360]   I hope it's not on your head.
[00:00:20.360 --> 00:00:22.360]   Coming up next on Twig.
[00:00:22.360 --> 00:00:25.520]   [MUSIC]
[00:00:25.520 --> 00:00:27.560]   Netcast you love.
[00:00:27.560 --> 00:00:32.560]   From people you trust.
[00:00:32.560 --> 00:00:35.200]   This is Twig.
[00:00:35.200 --> 00:00:42.360]   Bandwidth for this week in Google is provided by cashfly, C-A-C-H-E-F-L-Y.com.
[00:00:42.360 --> 00:00:46.160]   [MUSIC]
[00:00:46.160 --> 00:00:47.400]   This is Twig.
[00:00:47.400 --> 00:00:55.360]   This week in Google, episode 382 recorded Wednesday, December 7, 2016, last media.
[00:00:55.360 --> 00:01:00.200]   This week in Google is brought to you by Casper, an online retailer of premium mattresses
[00:01:00.200 --> 00:01:03.760]   for a fraction of the price, because everyone deserves a great night's sleep.
[00:01:03.760 --> 00:01:09.360]   Get $50 off any mattress purchase by visiting casper.com/twig.
[00:01:09.360 --> 00:01:12.960]   And enter the promo code TWIG.
[00:01:12.960 --> 00:01:15.400]   And buy rocket mortgage.
[00:01:15.400 --> 00:01:19.760]   By quick and loans, rocket mortgage brings the mortgage process into the 21st century
[00:01:19.760 --> 00:01:23.000]   with a fast, easy and completely online process.
[00:01:23.000 --> 00:01:28.920]   Check out rocket mortgage today at quickandloans.com/twig.
[00:01:28.920 --> 00:01:33.320]   It's time for Twig this week in Google, a show where we talk about the latest and Google
[00:01:33.320 --> 00:01:37.000]   Facebook, Twitter, the world.
[00:01:37.000 --> 00:01:39.840]   That's because we have such a smart, fun, interesting panel.
[00:01:39.840 --> 00:01:41.960]   We like to get their opinions starting.
[00:01:41.960 --> 00:01:47.320]   To my right with the wonderful Stacey Higginbotham who's done double duty this week, she of course
[00:01:47.320 --> 00:01:50.080]   is on the Stacey and IoT podcast.
[00:01:50.080 --> 00:01:53.840]   But she was also on Twitter on Sunday and has returned on Wednesday.
[00:01:53.840 --> 00:01:56.840]   It was fun having you and Om together again.
[00:01:56.840 --> 00:01:58.000]   We had a good time.
[00:01:58.000 --> 00:01:59.000]   Yeah.
[00:01:59.000 --> 00:02:03.920]   We should have had Matthew Ingram on too, another giga-om veteran.
[00:02:03.920 --> 00:02:05.240]   He's now at fortune.com.
[00:02:05.240 --> 00:02:06.240]   Hi Matthew.
[00:02:06.240 --> 00:02:07.240]   Hi.
[00:02:07.240 --> 00:02:09.080]   From the Great White North.
[00:02:09.080 --> 00:02:10.080]   Yes.
[00:02:10.080 --> 00:02:12.080]   Is it snowing?
[00:02:12.080 --> 00:02:13.080]   No.
[00:02:13.080 --> 00:02:14.080]   No.
[00:02:14.080 --> 00:02:15.920]   In fact, we've had no snow at all.
[00:02:15.920 --> 00:02:17.680]   That's misnamed.
[00:02:17.680 --> 00:02:21.640]   The north of the 49th parallel, that's all we need to say.
[00:02:21.640 --> 00:02:26.920]   And visiting us from just down the road apiece this week, which explains why his sound is
[00:02:26.920 --> 00:02:30.840]   so poor, Jeff Jarvis.
[00:02:30.840 --> 00:02:32.840]   It's always better in Germany, Jeff.
[00:02:32.840 --> 00:02:33.840]   I'm sorry.
[00:02:33.840 --> 00:02:34.840]   No, I don't know.
[00:02:34.840 --> 00:02:35.840]   I think something happened.
[00:02:35.840 --> 00:02:37.640]   It's sat on your headset or something.
[00:02:37.640 --> 00:02:38.640]   That's right.
[00:02:38.640 --> 00:02:41.240]   The picture is superb.
[00:02:41.240 --> 00:02:42.720]   That's why I know it's not a bandwidth thing.
[00:02:42.720 --> 00:02:43.720]   It's not a Skype thing.
[00:02:43.720 --> 00:02:44.720]   It's something.
[00:02:44.720 --> 00:02:45.720]   No, it's Google Wi-Fi.
[00:02:45.720 --> 00:02:46.720]   It's a Google.
[00:02:46.720 --> 00:02:47.720]   Google has enough Wi-Fi.
[00:02:47.720 --> 00:02:49.120]   Hey, you know what?
[00:02:49.120 --> 00:02:50.280]   That's kind of cool.
[00:02:50.280 --> 00:02:52.600]   All of that Wi-Fi, solar powered.
[00:02:52.600 --> 00:02:53.600]   Yeah.
[00:02:53.600 --> 00:02:54.600]   Yeah.
[00:02:54.600 --> 00:02:56.040]   I am stunned.
[00:02:56.040 --> 00:02:58.800]   This is the Google keyword blog.
[00:02:58.800 --> 00:03:03.480]   We're set to reach 100% renewable energy.
[00:03:03.480 --> 00:03:06.240]   As you might imagine, actually, I don't think people think about this, but when you do a
[00:03:06.240 --> 00:03:08.280]   Google search, it uses energy.
[00:03:08.280 --> 00:03:10.640]   When you watch a YouTube video, it searches energy.
[00:03:10.640 --> 00:03:14.800]   When you upload a YouTube video, it uses energy.
[00:03:14.800 --> 00:03:22.800]   By next year, Google is going to be 100% renewable energy for every bit of their operation, including
[00:03:22.800 --> 00:03:23.800]   data centers.
[00:03:23.800 --> 00:03:25.720]   What about buses?
[00:03:25.720 --> 00:03:28.200]   That's a good question.
[00:03:28.200 --> 00:03:30.000]   I don't know.
[00:03:30.000 --> 00:03:32.920]   Look at this, though, because this graph tells you something.
[00:03:32.920 --> 00:03:35.720]   Let me zoom in a little bit so you can see.
[00:03:35.720 --> 00:03:38.200]   It's the yellow part of the graph is solar.
[00:03:38.200 --> 00:03:40.320]   It's really just a fraction solar.
[00:03:40.320 --> 00:03:41.920]   It's almost all wind.
[00:03:41.920 --> 00:03:42.920]   Holy cow.
[00:03:42.920 --> 00:03:44.400]   That's a lot of wind.
[00:03:44.400 --> 00:03:50.800]   Wind is plentiful and cheap.
[00:03:50.800 --> 00:03:54.720]   You can put it where a lot of their data center operations, they've been planning and putting
[00:03:54.720 --> 00:03:58.640]   their data centers in places where they have access to easy wind power.
[00:03:58.640 --> 00:04:02.160]   That's been part of their planning strategy.
[00:04:02.160 --> 00:04:03.160]   Oh, really?
[00:04:03.160 --> 00:04:04.480]   Is that true that they kill birds?
[00:04:04.480 --> 00:04:08.040]   Aren't birds smart enough not to fly into the spinning?
[00:04:08.040 --> 00:04:11.560]   It's not like they spin like a fan in your house.
[00:04:11.560 --> 00:04:13.680]   It's kind of their stately.
[00:04:13.680 --> 00:04:14.680]   Dumb birds, then.
[00:04:14.680 --> 00:04:17.360]   You'd have to be a dumb bird.
[00:04:17.360 --> 00:04:23.880]   There are issues there, but it's better than killing birds with coal oil.
[00:04:23.880 --> 00:04:24.880]   Yeah.
[00:04:24.880 --> 00:04:25.880]   Yeah.
[00:04:25.880 --> 00:04:26.880]   Facebook is 100.
[00:04:26.880 --> 00:04:28.880]   It looks like it's 100% so a wind.
[00:04:28.880 --> 00:04:31.480]   Does Googor do geothermal as well?
[00:04:31.480 --> 00:04:32.480]   No.
[00:04:32.480 --> 00:04:38.120]   This graph, they have an 80 megawatt project in Chile.
[00:04:38.120 --> 00:04:43.880]   They just bought all the electricity from a 100, actually didn't just do it.
[00:04:43.880 --> 00:04:50.880]   This was their first purchase from 114 megawatt wind farm in Iowa.
[00:04:50.880 --> 00:04:55.240]   They currently buy 2.6 gigawatts of power.
[00:04:55.240 --> 00:04:57.240]   Giga, or giga?
[00:04:57.240 --> 00:04:58.240]   Well, okay.
[00:04:58.240 --> 00:04:59.240]   Okay.
[00:04:59.240 --> 00:05:02.320]   As Urs Holsel, the senior vice president for technical infrastructure rights, that's bigger
[00:05:02.320 --> 00:05:06.840]   than many large utilities and more than twice as much as the 1.21 gigawatts it took to
[00:05:06.840 --> 00:05:11.480]   send Marty McFly to the future.
[00:05:11.480 --> 00:05:17.880]   So that's how they said it in the movie, "Jigawatts," but obviously it's gigawatts,
[00:05:17.880 --> 00:05:18.880]   I think.
[00:05:18.880 --> 00:05:19.880]   Is it the old GIF?
[00:05:19.880 --> 00:05:20.880]   Yeah.
[00:05:20.880 --> 00:05:22.880]   I was going to say, "I'm not going to be jigga-stacy."
[00:05:22.880 --> 00:05:25.240]   Excellent point.
[00:05:25.240 --> 00:05:28.840]   Excellent point.
[00:05:28.840 --> 00:05:35.840]   Now, is this the question is, are they using this directly or are these with credits?
[00:05:35.840 --> 00:05:36.840]   Yes.
[00:05:36.840 --> 00:05:37.840]   Subsidies.
[00:05:37.840 --> 00:05:38.840]   Yeah.
[00:05:38.840 --> 00:05:39.840]   Like offset?
[00:05:39.840 --> 00:05:40.840]   Is it offset or is it direct?
[00:05:40.840 --> 00:05:44.720]   It kind of implies that it's direct, but...
[00:05:44.720 --> 00:05:48.240]   Some of their data center stuff is direct.
[00:05:48.240 --> 00:05:50.160]   I don't know if it's all direct.
[00:05:50.160 --> 00:05:53.080]   Actually, this whole post is basically that it's direct.
[00:05:53.080 --> 00:05:54.080]   Implies that it's direct.
[00:05:54.080 --> 00:05:56.360]   They're not saying we're buying offsets.
[00:05:56.360 --> 00:05:58.600]   Well, but the graphics is a little blun.
[00:05:58.600 --> 00:06:01.960]   We were one of the first corporations to create large scale local contracts.
[00:06:01.960 --> 00:06:02.960]   Oh, the graphics is correct.
[00:06:02.960 --> 00:06:03.960]   Okay.
[00:06:03.960 --> 00:06:04.960]   Oh, yeah, recs.
[00:06:04.960 --> 00:06:06.840]   Green lines are recs.
[00:06:06.840 --> 00:06:11.120]   Those are the renewable energy credits.
[00:06:11.120 --> 00:06:17.140]   And then the yellow lines electricity and then the mix are bundled energy and recs.
[00:06:17.140 --> 00:06:18.700]   So yeah, you're right.
[00:06:18.700 --> 00:06:19.700]   You're right.
[00:06:19.700 --> 00:06:20.700]   Oh, I don't know.
[00:06:20.700 --> 00:06:21.700]   It's still good.
[00:06:21.700 --> 00:06:22.700]   I don't know what I just did here.
[00:06:22.700 --> 00:06:24.200]   Tap the button too many times.
[00:06:24.200 --> 00:06:25.200]   See, double tap.
[00:06:25.200 --> 00:06:26.200]   It makes sense, because like...
[00:06:26.200 --> 00:06:27.200]   It makes sense.
[00:06:27.200 --> 00:06:30.800]   It's supposed to be able to illustrate this.
[00:06:30.800 --> 00:06:36.800]   Yeah, because you don't necessarily have wind farms next door to the Mountain View
[00:06:36.800 --> 00:06:39.080]   offices, things like that.
[00:06:39.080 --> 00:06:42.720]   Although, you know, it'll be nice if we did.
[00:06:42.720 --> 00:06:45.720]   Twenty agreements to purchase renewable energy.
[00:06:45.720 --> 00:06:49.800]   Six new agreements last year, 842 megawatts.
[00:06:49.800 --> 00:06:54.240]   The largest aggregate purchase of renewable energy ever made by a non-utility.
[00:06:54.240 --> 00:06:59.760]   $3.5 billion in capital investments worldwide generated by renewable energy products from
[00:06:59.760 --> 00:07:01.040]   which we buy electricity.
[00:07:01.040 --> 00:07:04.720]   So that's not Google money, but they're kind of subsidizing it.
[00:07:04.720 --> 00:07:08.440]   The largest corporate purchaser of renewable energy in the world.
[00:07:08.440 --> 00:07:09.440]   Wow.
[00:07:09.440 --> 00:07:16.280]   So as we said in 2015, they consumed 5.7 terawatt hours of electricity across all their operations,
[00:07:16.280 --> 00:07:19.720]   which is nearly as much electricity as San Francisco used in the same year.
[00:07:19.720 --> 00:07:20.720]   Wow.
[00:07:20.720 --> 00:07:21.720]   And that's from their white paper.
[00:07:21.720 --> 00:07:23.640]   Well, what that tells you.
[00:07:23.640 --> 00:07:28.120]   I mean, you know, you never think about the fact that you're doing a Google search, you're
[00:07:28.120 --> 00:07:29.760]   using energy.
[00:07:29.760 --> 00:07:30.760]   I do.
[00:07:30.760 --> 00:07:31.760]   Good for you.
[00:07:31.760 --> 00:07:32.760]   That's because you're...
[00:07:32.760 --> 00:07:35.160]   Well, it's part of their cost.
[00:07:35.160 --> 00:07:37.120]   It's part of their costs of goods, basically.
[00:07:37.120 --> 00:07:38.120]   So you've got to...
[00:07:38.120 --> 00:07:39.720]   They've got to take that into consideration.
[00:07:39.720 --> 00:07:42.040]   So making it clean is nice.
[00:07:42.040 --> 00:07:46.400]   Remember a few years ago, a few years ago, I was reading an interview with somebody I
[00:07:46.400 --> 00:07:50.960]   can't remember who now, who was sitting beside Larry Page at some event and asked him, "What
[00:07:50.960 --> 00:07:54.360]   is the single biggest challenge Google faces in the future?"
[00:07:54.360 --> 00:07:57.160]   And Larry reportedly said, "Power."
[00:07:57.160 --> 00:08:01.000]   Yeah, that makes sense.
[00:08:01.000 --> 00:08:07.160]   They designed these networks operation centers, which are the chief users of power.
[00:08:07.160 --> 00:08:13.960]   They designed them to be in places where power is cheap, like Oregon, where wind and other
[00:08:13.960 --> 00:08:16.000]   renewable resources are plentiful.
[00:08:16.000 --> 00:08:22.520]   A lot of times they put them somewhere because cooling is the other big use of power.
[00:08:22.520 --> 00:08:25.680]   So they put them somewhere where they have seawatered cooled.
[00:08:25.680 --> 00:08:31.400]   I think Facebook at least has some seawatered cooled network operation centers as well.
[00:08:31.400 --> 00:08:38.040]   Actually, a bunch of downtown Toronto is cooled by water from the harbor.
[00:08:38.040 --> 00:08:39.040]   Really?
[00:08:39.040 --> 00:08:40.040]   Interesting.
[00:08:40.040 --> 00:08:41.040]   So birds aren't killed.
[00:08:41.040 --> 00:08:42.040]   People are like eating in Canada.
[00:08:42.040 --> 00:08:51.000]   Loop Liam says annually, 214,000 to 368,000 birds are killed according to treehuggers.com
[00:08:51.000 --> 00:08:52.160]   by windmills.
[00:08:52.160 --> 00:08:55.640]   But the Smithsonian says it's 10,000 to 600,000.
[00:08:55.640 --> 00:08:57.640]   So we've got lots of birds, right?
[00:08:57.640 --> 00:08:59.280]   Am I wrong?
[00:08:59.280 --> 00:09:01.680]   How many birds are killed by cats annually?
[00:09:01.680 --> 00:09:03.960]   I think it's a lot more net.
[00:09:03.960 --> 00:09:06.760]   And we ain't getting rid of cats anytime soon.
[00:09:06.760 --> 00:09:07.880]   And they don't provide power.
[00:09:07.880 --> 00:09:09.680]   So all the cat does.
[00:09:09.680 --> 00:09:11.600]   Well, there's some purring involved, but that's not...
[00:09:11.600 --> 00:09:12.600]   Well, look at the cat behind me.
[00:09:12.600 --> 00:09:15.360]   I was going to say, Matthew, there's a cat right behind you.
[00:09:15.360 --> 00:09:16.360]   How's he handling?
[00:09:16.360 --> 00:09:17.360]   No power.
[00:09:17.360 --> 00:09:18.360]   Powerless.
[00:09:18.360 --> 00:09:19.360]   I should ask you.
[00:09:19.360 --> 00:09:20.360]   Sleep for 23 hours a day.
[00:09:20.360 --> 00:09:21.360]   Let me ask.
[00:09:21.360 --> 00:09:24.160]   Let me use some of this cheap energy and ask Google.
[00:09:24.160 --> 00:09:29.480]   How many birds are killed annually by cats?
[00:09:29.480 --> 00:09:32.480]   How much power does a cat produce?
[00:09:32.480 --> 00:09:37.320]   3.7 billion birds are killed annually by cats.
[00:09:37.320 --> 00:09:38.320]   Wow.
[00:09:38.320 --> 00:09:42.360]   How many birds are killed by wind farms?
[00:09:42.360 --> 00:09:48.320]   How many birds are killed annually by wind farms?
[00:09:48.320 --> 00:09:51.520]   573,000 e-4.
[00:09:51.520 --> 00:09:55.360]   888,000 bats are killed every year by wind turbines.
[00:09:55.360 --> 00:09:56.800]   You kill all the bats you want.
[00:09:56.800 --> 00:09:57.800]   I don't like them.
[00:09:57.800 --> 00:09:58.800]   No, bats are great.
[00:09:58.800 --> 00:10:00.440]   No, no, they eat bugs.
[00:10:00.440 --> 00:10:01.440]   They eat mosquitoes.
[00:10:01.440 --> 00:10:02.440]   We love bats.
[00:10:02.440 --> 00:10:05.680]   How many birds are killed by office towers?
[00:10:05.680 --> 00:10:06.880]   I know that's a big number.
[00:10:06.880 --> 00:10:07.880]   What?
[00:10:07.880 --> 00:10:08.880]   They fly into the windows?
[00:10:08.880 --> 00:10:09.880]   Yeah.
[00:10:09.880 --> 00:10:10.880]   Wow.
[00:10:10.880 --> 00:10:11.880]   How many birds are killed by skyscrapers?
[00:10:11.880 --> 00:10:15.680]   Because they're migratory routes for some kind of bird.
[00:10:15.680 --> 00:10:18.080]   So they black them out at night.
[00:10:18.080 --> 00:10:19.560]   By the way, I don't know how you...
[00:10:19.560 --> 00:10:22.800]   38 million dying window collisions.
[00:10:22.800 --> 00:10:23.800]   Oh, so...
[00:10:23.800 --> 00:10:25.000]   That's almost a billion.
[00:10:25.000 --> 00:10:26.000]   Okay.
[00:10:26.000 --> 00:10:27.000]   Wow.
[00:10:27.000 --> 00:10:28.000]   Okay.
[00:10:28.000 --> 00:10:29.000]   So that puts the number in perspective.
[00:10:29.000 --> 00:10:32.800]   Yes, a lot of birds are killed by wind turbines, even with, you know, Smithsonian, the lowest
[00:10:32.800 --> 00:10:37.640]   estimates 10,000 annually, the highest estimates 600,000.
[00:10:37.640 --> 00:10:38.880]   But that's a tiny fraction.
[00:10:38.880 --> 00:10:40.400]   A fraction of the number just...
[00:10:40.400 --> 00:10:41.800]   The fly into buildings.
[00:10:41.800 --> 00:10:42.800]   Yeah.
[00:10:42.800 --> 00:10:47.240]   I had two killed last year who flew in our windows.
[00:10:47.240 --> 00:10:48.240]   So...
[00:10:48.240 --> 00:10:49.240]   Bird killer.
[00:10:49.240 --> 00:10:50.240]   I know.
[00:10:50.240 --> 00:10:53.520]   How many turkeys are killed every year for Thanksgiving?
[00:10:53.520 --> 00:10:55.520]   Hey, Lord.
[00:10:55.520 --> 00:10:59.480]   According to PETA, like chickens, the 300 million turkeys raised and killed for their
[00:10:59.480 --> 00:11:02.960]   flesh every year in the United States have no federal legal protection.
[00:11:02.960 --> 00:11:06.600]   I didn't ask you about that.
[00:11:06.600 --> 00:11:08.800]   That's an over answer.
[00:11:08.800 --> 00:11:09.800]   Thank you.
[00:11:09.800 --> 00:11:10.800]   But that's what you're over answering.
[00:11:10.800 --> 00:11:13.040]   We're going down a rabbit hole now.
[00:11:13.040 --> 00:11:15.680]   She's so preachy.
[00:11:15.680 --> 00:11:16.680]   Google's timelapse.
[00:11:16.680 --> 00:11:17.680]   So Google is actually...
[00:11:17.680 --> 00:11:20.160]   Now, it's good PR.
[00:11:20.160 --> 00:11:22.160]   It's good for their business.
[00:11:22.160 --> 00:11:25.200]   But I think they actually do care about renewable.
[00:11:25.200 --> 00:11:27.160]   And I'm glad to see they're doing this.
[00:11:27.160 --> 00:11:33.040]   They have put together these really interesting timelapses at the Google Earth engine.
[00:11:33.040 --> 00:11:34.400]   Yeah, those are fascinating.
[00:11:34.400 --> 00:11:39.040]   These are zoomable videos that let you see how the Earth changed over 32 years, because
[00:11:39.040 --> 00:11:41.880]   that's as long as we've had satellite pictures.
[00:11:41.880 --> 00:11:42.880]   This is Miami.
[00:11:42.880 --> 00:11:45.840]   So you can see as it gets built up.
[00:11:45.840 --> 00:11:47.640]   What do you want to look at, San Francisco?
[00:11:47.640 --> 00:11:54.280]   I wish we had this for 100 or 200 years, because that's when you'd really see these
[00:11:54.280 --> 00:11:56.960]   cities appear out of nowhere.
[00:11:56.960 --> 00:12:01.760]   After you build your time machine, you can go back and put up satellites.
[00:12:01.760 --> 00:12:04.440]   Or go into the future.
[00:12:04.440 --> 00:12:07.320]   Here's the Shirei's Glacier.
[00:12:07.320 --> 00:12:08.480]   Which one do you want to see?
[00:12:08.480 --> 00:12:11.040]   I was going to say, go look at Greenland or Iceland.
[00:12:11.040 --> 00:12:17.600]   Yeah, this is an Antarctic glacier over 32 years, which pretty much looks the same.
[00:12:17.600 --> 00:12:19.400]   Yeah, it looks fine.
[00:12:19.400 --> 00:12:23.840]   You could try down in like Chile or Brazil.
[00:12:23.840 --> 00:12:33.320]   Here's the Columbia Glacier, which is in Alaska up above the 49th parallel.
[00:12:33.320 --> 00:12:34.600]   You know, these are not as well.
[00:12:34.600 --> 00:12:36.400]   There's a melting going on there.
[00:12:36.400 --> 00:12:37.400]   Yeah.
[00:12:37.400 --> 00:12:38.400]   How about Vegas?
[00:12:38.400 --> 00:12:39.880]   Vegas has changed a lot.
[00:12:39.880 --> 00:12:45.280]   No more glaciers in the desert.
[00:12:45.280 --> 00:12:46.840]   I know, it's just kind of cool.
[00:12:46.840 --> 00:12:47.840]   It is.
[00:12:47.840 --> 00:12:48.840]   And it's limited totally.
[00:12:48.840 --> 00:12:49.840]   Oh boy.
[00:12:49.840 --> 00:12:51.320]   That's a lot of growth in 32 years.
[00:12:51.320 --> 00:12:52.320]   It's raw.
[00:12:52.320 --> 00:12:53.320]   Yeah.
[00:12:53.320 --> 00:12:58.560]   This is totally limited, of course, by the prevalence of satellite pictures.
[00:12:58.560 --> 00:12:59.680]   But this is a cool idea.
[00:12:59.680 --> 00:13:03.360]   So this comes from NASA's Landsat program, most of them.
[00:13:03.360 --> 00:13:11.440]   The Copernicus Sentinel program from the EU and other US Geological Survey.
[00:13:11.440 --> 00:13:17.080]   You know, it struck me speaking of power, looking at, especially driving through Philadelphia
[00:13:17.080 --> 00:13:22.320]   or anywhere, Pittsburgh area, anywhere there were sort of steel mills.
[00:13:22.320 --> 00:13:28.360]   A lot of those spots are where Google and other companies have put server farms because
[00:13:28.360 --> 00:13:29.640]   they get a lot of power.
[00:13:29.640 --> 00:13:32.800]   It's right by a dam or something.
[00:13:32.800 --> 00:13:40.960]   And in many cases, they're orders of magnitude larger than the steel mills they replaced.
[00:13:40.960 --> 00:13:48.400]   But they take, you know, 10 people to operate, whereas the steel mill employed like 20,000.
[00:13:48.400 --> 00:13:49.400]   Yeah.
[00:13:49.400 --> 00:13:55.560]   You know, I just discovered a Bethlehem PA that took the rusting old hulk of Bethlehem
[00:13:55.560 --> 00:14:00.840]   Steel and built a bridge next to a secret walk along.
[00:14:00.840 --> 00:14:06.280]   And it is awe-inspiring, a huge amount of energy that it took to make some burn things
[00:14:06.280 --> 00:14:09.200]   to push forced air into it.
[00:14:09.200 --> 00:14:14.360]   It's amazing at the energy we do use.
[00:14:14.360 --> 00:14:20.880]   Well, and this is where, you know, this is what Google's mission is is data, right?
[00:14:20.880 --> 00:14:28.680]   And it's very interesting to see how data is used to learn things.
[00:14:28.680 --> 00:14:29.680]   Hour of code.
[00:14:29.680 --> 00:14:30.680]   This is the week of the hour code.
[00:14:30.680 --> 00:14:33.800]   Are you taking your daughter somewhere Stacey to code?
[00:14:33.800 --> 00:14:34.800]   Her school does it.
[00:14:34.800 --> 00:14:39.200]   Although every time she comes home with her, I did my hour of code, she's kind of like,
[00:14:39.200 --> 00:14:40.480]   I'm like, and how did you feel about it?
[00:14:40.480 --> 00:14:41.480]   And she's like, yeah.
[00:14:41.480 --> 00:14:42.480]   Mm-hmm.
[00:14:42.480 --> 00:14:43.480]   Oh, she made it.
[00:14:43.480 --> 00:14:47.880]   So you remember President Obama said, I want every child to learn how to code.
[00:14:47.880 --> 00:14:48.880]   I don't.
[00:14:48.880 --> 00:14:49.880]   Mm-hmm.
[00:14:49.880 --> 00:14:55.560]   I mean, I actually, what I believe is that, and I think there's a lot of research to show
[00:14:55.560 --> 00:15:00.640]   this and I've talked to people who agree that coding could be taught in math classes,
[00:15:00.640 --> 00:15:06.920]   but much of the benefit you get in math, which is rigorous thinking, problem solving, you
[00:15:06.920 --> 00:15:11.160]   could get from coding and they're very closely related and you could integrate easily integrate
[00:15:11.160 --> 00:15:15.280]   coding into math curricula all around the country.
[00:15:15.280 --> 00:15:19.520]   And I think, you know, a lot of times when kids do an algebra, they go, why am I doing
[00:15:19.520 --> 00:15:20.520]   this?
[00:15:20.520 --> 00:15:21.520]   What am I going to ever get out of this?
[00:15:21.520 --> 00:15:27.000]   And they code as would be equally probably challenging and maybe uninteresting to some,
[00:15:27.000 --> 00:15:31.000]   but at least you could look at it and say, well, I could see what the value of this is.
[00:15:31.000 --> 00:15:34.200]   You know, I mean, I may not be that interested, but I could see why you would want to learn
[00:15:34.200 --> 00:15:35.200]   that.
[00:15:35.200 --> 00:15:39.040]   I think it would be for kids a better way to do it.
[00:15:39.040 --> 00:15:40.240]   And her school does it this way.
[00:15:40.240 --> 00:15:42.560]   They code using Minecraft.
[00:15:42.560 --> 00:15:49.160]   So they're actually making Minecraft mods for their Hour of Code, which shows them, hey,
[00:15:49.160 --> 00:15:52.840]   this directly applies to something you care desperately about.
[00:15:52.840 --> 00:15:53.840]   Does she play Minecraft?
[00:15:53.840 --> 00:15:55.240]   Oh, God, yes.
[00:15:55.240 --> 00:15:57.440]   So she watches the videos too.
[00:15:57.440 --> 00:15:58.440]   So much happening.
[00:15:58.440 --> 00:15:59.440]   Yeah, no.
[00:15:59.440 --> 00:16:03.160]   Well, this is a Microsoft course on Minecraft and they're doing a whole bunch of Hour of
[00:16:03.160 --> 00:16:04.160]   Code stuff.
[00:16:04.160 --> 00:16:09.840]   And I'm sure her school is using the curricula that Microsoft offers for free for grades
[00:16:09.840 --> 00:16:11.360]   two and up.
[00:16:11.360 --> 00:16:12.920]   How about that?
[00:16:12.920 --> 00:16:16.520]   I think it's important that they see this.
[00:16:16.520 --> 00:16:19.680]   You think they got a good deal on Minecraft?
[00:16:19.680 --> 00:16:20.680]   What was it?
[00:16:20.680 --> 00:16:21.680]   3 billion?
[00:16:21.680 --> 00:16:22.680]   3.2 billion?
[00:16:22.680 --> 00:16:23.680]   Yeah.
[00:16:23.680 --> 00:16:27.280]   I mean, I think it's worth like 10 times that much.
[00:16:27.280 --> 00:16:35.280]   Well, and also the mind share that they get as a result of this has got to be huge.
[00:16:35.280 --> 00:16:41.280]   I mean, these kids love Minecraft and now it's a Microsoft thing.
[00:16:41.280 --> 00:16:47.520]   And do they get licensing deals based on all the Lego things and all of the...
[00:16:47.520 --> 00:16:49.960]   I mean, we have Minecraft stuffed animals in our house.
[00:16:49.960 --> 00:16:50.960]   So...
[00:16:50.960 --> 00:16:51.960]   Oh, yeah.
[00:16:51.960 --> 00:16:54.560]   That's right in the Bill Gates pocket.
[00:16:54.560 --> 00:16:56.520]   Okay, so the chicken...
[00:16:56.520 --> 00:16:59.520]   Here's the chicken is frozen.
[00:16:59.520 --> 00:17:04.920]   Place move and turn blocks in the wind spawn shot to get it to move.
[00:17:04.920 --> 00:17:06.560]   Chicken wind spawn move forward.
[00:17:06.560 --> 00:17:09.680]   You put that in here.
[00:17:09.680 --> 00:17:10.680]   Uh huh.
[00:17:10.680 --> 00:17:12.240]   Turn left.
[00:17:12.240 --> 00:17:13.400]   Put that in there.
[00:17:13.400 --> 00:17:14.400]   Snaps.
[00:17:14.400 --> 00:17:15.920]   And then play a clock.
[00:17:15.920 --> 00:17:17.000]   Let's see.
[00:17:17.000 --> 00:17:18.200]   Did I program my...
[00:17:18.200 --> 00:17:20.520]   Let's get that snapped in there too.
[00:17:20.520 --> 00:17:21.760]   There we go.
[00:17:21.760 --> 00:17:23.080]   And let's run my code.
[00:17:23.080 --> 00:17:24.560]   Go check it out.
[00:17:24.560 --> 00:17:25.560]   Yeah.
[00:17:25.560 --> 00:17:26.560]   Yay.
[00:17:26.560 --> 00:17:28.040]   See how fun this is?
[00:17:28.040 --> 00:17:29.040]   And what's nice, they're smart.
[00:17:29.040 --> 00:17:30.040]   You're a programmer.
[00:17:30.040 --> 00:17:31.040]   It even...
[00:17:31.040 --> 00:17:32.040]   Yeah, my programmer.
[00:17:32.040 --> 00:17:34.200]   Look, I'm going to write a billion dollar app.
[00:17:34.200 --> 00:17:35.200]   This is good.
[00:17:35.200 --> 00:17:36.400]   They show a hip young woman doing it.
[00:17:36.400 --> 00:17:37.400]   Hi, I'm Lisa.
[00:17:37.400 --> 00:17:39.840]   I'm a software developer on Minecraft.
[00:17:39.840 --> 00:17:40.840]   I work on...
[00:17:40.840 --> 00:17:42.400]   I'm telling you the sparkly shoes.
[00:17:42.400 --> 00:17:43.400]   They would win over like...
[00:17:43.400 --> 00:17:44.400]   Yeah.
[00:17:44.400 --> 00:17:45.400]   Actually, me right now.
[00:17:45.400 --> 00:17:46.400]   You see what...
[00:17:46.400 --> 00:17:47.400]   I would be like, yeah.
[00:17:47.400 --> 00:17:48.400]   You can see why they showed it, right?
[00:17:48.400 --> 00:17:49.400]   I mean, that's...
[00:17:49.400 --> 00:17:50.400]   Oh, she's hip and cool.
[00:17:50.400 --> 00:17:54.040]   She'll sneak towards you and if you feed it the fish, you tame it.
[00:17:54.040 --> 00:17:55.640]   And the Ocelot is your own cat.
[00:17:55.640 --> 00:17:58.120]   Oh my God, my daughter went to Ocelot so bad.
[00:17:58.120 --> 00:17:59.120]   As he was...
[00:17:59.120 --> 00:18:00.120]   Not a real one.
[00:18:00.120 --> 00:18:01.120]   A Minecraft Ocelot, I hope.
[00:18:01.120 --> 00:18:02.120]   A Minecraft Ocelot.
[00:18:02.120 --> 00:18:05.360]   She's got her Benazurey and Minecraft is pretty intense.
[00:18:05.360 --> 00:18:06.360]   Yeah.
[00:18:06.360 --> 00:18:07.360]   I have a little...
[00:18:07.360 --> 00:18:11.000]   At this school, people are building like hard drives or like functioning processors
[00:18:11.000 --> 00:18:12.000]   inside Minecraft.
[00:18:12.000 --> 00:18:13.000]   Oh, yeah.
[00:18:13.000 --> 00:18:14.000]   There's a...
[00:18:14.000 --> 00:18:15.000]   There's some really amazing...
[00:18:15.000 --> 00:18:16.000]   There's a...
[00:18:16.000 --> 00:18:17.520]   Let me see if I can find it.
[00:18:17.520 --> 00:18:18.520]   There's a wonderful video.
[00:18:18.520 --> 00:18:25.120]   This is kind of old of a Minecraft computer using Redstone.
[00:18:25.120 --> 00:18:26.120]   This is...
[00:18:26.120 --> 00:18:27.360]   I don't know.
[00:18:27.360 --> 00:18:28.920]   The guy who did this...
[00:18:28.920 --> 00:18:29.920]   Wow.
[00:18:29.920 --> 00:18:35.920]   Spent a lot of time.
[00:18:35.920 --> 00:18:38.160]   But Minecraft is Lego.
[00:18:38.160 --> 00:18:39.480]   It really is the...
[00:18:39.480 --> 00:18:42.360]   It's Lego for the 21st century and it's getting kids.
[00:18:42.360 --> 00:18:47.240]   I think in a lot of ways, even just playing Minecraft, teaches you kind of fundamental
[00:18:47.240 --> 00:18:51.840]   concepts that are useful in later life in technology in a lot of ways.
[00:18:51.840 --> 00:18:52.840]   This is huge.
[00:18:52.840 --> 00:18:53.840]   What did...
[00:18:53.840 --> 00:18:54.840]   Did I show you guys...
[00:18:54.840 --> 00:18:56.320]   I think this was my pick one week.
[00:18:56.320 --> 00:18:58.840]   Was the little bits Minecraft mod that actually...
[00:18:58.840 --> 00:18:59.840]   Yeah.
[00:18:59.840 --> 00:19:00.840]   Yeah.
[00:19:00.840 --> 00:19:01.840]   So...
[00:19:01.840 --> 00:19:02.840]   Yeah, really neat stuff.
[00:19:02.840 --> 00:19:03.840]   That's cool.
[00:19:03.840 --> 00:19:04.840]   And we've talked about...
[00:19:04.840 --> 00:19:05.840]   In fact, we had...
[00:19:05.840 --> 00:19:12.240]   Carsten's son came in, Zach came in and reviewed the Piper computer kit, which is a kit that
[00:19:12.240 --> 00:19:13.240]   you...
[00:19:13.240 --> 00:19:14.240]   It's actually going to be...
[00:19:14.240 --> 00:19:15.240]   I'm sure it's a hot Christmas present.
[00:19:15.240 --> 00:19:16.240]   Look, he's typing on the...
[00:19:16.240 --> 00:19:18.240]   He's typing on the pipes and it's coming out of the terminal.
[00:19:18.240 --> 00:19:19.240]   Wow.
[00:19:19.240 --> 00:19:21.520]   In Minecraft, folks, non-trivial.
[00:19:21.520 --> 00:19:24.240]   What you have to understand is that terminal is like 800 stories.
[00:19:24.240 --> 00:19:25.240]   I...
[00:19:25.240 --> 00:19:26.240]   Yeah.
[00:19:26.240 --> 00:19:27.240]   That is gigantic.
[00:19:27.240 --> 00:19:28.240]   It's huge.
[00:19:28.240 --> 00:19:32.720]   Let me show you the Piper.
[00:19:32.720 --> 00:19:33.720]   This is...
[00:19:33.720 --> 00:19:35.120]   This is for parents who are...
[00:19:35.120 --> 00:19:40.200]   Of kids like around maybe eight to twelve.
[00:19:40.200 --> 00:19:41.200]   I got that.
[00:19:41.200 --> 00:19:42.440]   Did you get the Piper?
[00:19:42.440 --> 00:19:43.840]   Oh, you have that.
[00:19:43.840 --> 00:19:44.840]   You have that child.
[00:19:44.840 --> 00:19:46.160]   I have a child for me to do.
[00:19:46.160 --> 00:19:47.880]   You play with the cano, but not the Piper.
[00:19:47.880 --> 00:19:49.880]   This is playpiper.com.
[00:19:49.880 --> 00:19:54.720]   If she's in a Minecraft, because what's neat is it's three hundred bucks, a little pricey,
[00:19:54.720 --> 00:20:01.240]   but what you get is a whole computer, a Minecraft computer, that you assemble, but also with
[00:20:01.240 --> 00:20:06.720]   it, and this is the really cool stuff, comes a little assignments that you...
[00:20:06.720 --> 00:20:11.520]   Because they also have switches and buttons and knobs and buzzers and breadboards.
[00:20:11.520 --> 00:20:16.680]   And so you get little levels like freaky fungi, drilled an array of buttons and switches,
[00:20:16.680 --> 00:20:20.880]   physical ones, not in Minecraft, to navigate your way across giant mushrooms.
[00:20:20.880 --> 00:20:24.880]   So it's going to use the actual physical buttons that come with a kit, plus the switches.
[00:20:24.880 --> 00:20:25.880]   So I think...
[00:20:25.880 --> 00:20:28.200]   That's sort of wish I had younger kids now.
[00:20:28.200 --> 00:20:29.200]   I know.
[00:20:29.200 --> 00:20:30.200]   Wouldn't this be fun?
[00:20:30.200 --> 00:20:36.160]   It really does probably need a little help from mom or dad, but I think this is really neat.
[00:20:36.160 --> 00:20:37.160]   I don't know.
[00:20:37.160 --> 00:20:38.160]   Are we over...
[00:20:38.160 --> 00:20:42.760]   Are we over-burdening Minecraft to make it responsible for teaching our kids everything
[00:20:42.760 --> 00:20:43.760]   now?
[00:20:43.760 --> 00:20:44.960]   It's like, "No, you're going to like this.
[00:20:44.960 --> 00:20:45.960]   It's Minecraft."
[00:20:45.960 --> 00:20:47.560]   Yeah, yeah, I heard that before.
[00:20:47.560 --> 00:20:51.360]   Yeah, like whenever I get my daughter or some of these things, she looks at me and she's
[00:20:51.360 --> 00:20:52.920]   like, "I see this.
[00:20:52.920 --> 00:20:56.560]   This is just one of your STEM toys, mom."
[00:20:56.560 --> 00:21:03.000]   I did a big review of children's software, like educational software.
[00:21:03.000 --> 00:21:04.200]   This was years ago.
[00:21:04.200 --> 00:21:05.680]   So they were CDs and stuff.
[00:21:05.680 --> 00:21:11.480]   But I remember talking to this professor and he said, "Kids are really, really good at finding
[00:21:11.480 --> 00:21:15.920]   the fun parts of whatever you give them and avoiding or finding ways around the educational
[00:21:15.920 --> 00:21:16.920]   parts."
[00:21:16.920 --> 00:21:20.200]   Well, don't you remember that as a kid, right?
[00:21:20.200 --> 00:21:21.200]   Oh, yeah.
[00:21:21.200 --> 00:21:22.200]   Yeah.
[00:21:22.200 --> 00:21:28.200]   I mean, it's less tricky, but giving them the opportunity to say, because some kids are,
[00:21:28.200 --> 00:21:31.360]   they're going to be like, "Holy cow, I can totally own this game."
[00:21:31.360 --> 00:21:33.120]   And those are the same people who...
[00:21:33.120 --> 00:21:34.120]   Yeah.
[00:21:34.120 --> 00:21:37.640]   And years ago, played, learned how to code on their own.
[00:21:37.640 --> 00:21:38.640]   So it's...
[00:21:38.640 --> 00:21:39.640]   Yeah.
[00:21:39.640 --> 00:21:41.040]   I think it's important to have the exposure, but yeah.
[00:21:41.040 --> 00:21:45.920]   No, that was always my attitude is, "I don't know what's going to stick, but I want to
[00:21:45.920 --> 00:21:46.920]   get my kids..."
[00:21:46.920 --> 00:21:50.640]   I'm sure you guys felt the same way I exposed to as many different things as possible so
[00:21:50.640 --> 00:21:56.360]   that they can find the one that sticks because you don't really know ahead of time.
[00:21:56.360 --> 00:21:57.360]   You do not?
[00:21:57.360 --> 00:21:58.360]   You don't.
[00:21:58.360 --> 00:21:59.360]   You can't tell.
[00:21:59.360 --> 00:22:00.360]   Oh, no.
[00:22:00.360 --> 00:22:01.360]   Although...
[00:22:01.360 --> 00:22:02.360]   Oh, no.
[00:22:02.360 --> 00:22:04.080]   That's going to say, next week, I'm going to break up.
[00:22:04.080 --> 00:22:05.080]   I'm going to bring it.
[00:22:05.080 --> 00:22:06.080]   We...
[00:22:06.080 --> 00:22:10.200]   I got my daughter a Enki Cosmo, the little Cosmo robot.
[00:22:10.200 --> 00:22:11.240]   Oh, you're going to love it.
[00:22:11.240 --> 00:22:12.480]   We had one here.
[00:22:12.480 --> 00:22:13.480]   It's so cool.
[00:22:13.480 --> 00:22:16.360]   We're so excited.
[00:22:16.360 --> 00:22:17.920]   You told her already?
[00:22:17.920 --> 00:22:22.960]   Oh, so her grandparents are giving it to her and we're doing Christmas this weekend at
[00:22:22.960 --> 00:22:25.960]   their house.
[00:22:25.960 --> 00:22:26.960]   Oh, nice.
[00:22:26.960 --> 00:22:27.960]   She...
[00:22:27.960 --> 00:22:31.560]   This is really interesting because this is a programmable computer, but it's got...
[00:22:31.560 --> 00:22:33.760]   The design was by some...
[00:22:33.760 --> 00:22:35.840]   A former Pixar engineers.
[00:22:35.840 --> 00:22:39.360]   And so it's very much personified, kind of like Wal-E.
[00:22:39.360 --> 00:22:43.160]   And that's to me what makes this kind of interesting.
[00:22:43.160 --> 00:22:46.640]   And then you program it, you can actually write Python code for it.
[00:22:46.640 --> 00:22:49.160]   It's got an API.
[00:22:49.160 --> 00:22:50.440]   But it also plays games.
[00:22:50.440 --> 00:22:52.120]   Yeah, I think this is...
[00:22:52.120 --> 00:22:56.000]   This is, I think, a really interesting...
[00:22:56.000 --> 00:23:00.280]   If I had to pick one of these toys, this would be the one that would be the big one
[00:23:00.280 --> 00:23:01.280]   this season.
[00:23:01.280 --> 00:23:02.720]   It's got a little companion cube.
[00:23:02.720 --> 00:23:04.000]   He could play games with...
[00:23:04.000 --> 00:23:05.000]   Nice.
[00:23:05.000 --> 00:23:06.560]   I was trying to write a piece.
[00:23:06.560 --> 00:23:14.320]   I really fear that we're going to see a huge backlash to technology when populace discovered
[00:23:14.320 --> 00:23:16.480]   that it's not immigration that costs their jobs.
[00:23:16.480 --> 00:23:18.680]   It's this little thing.
[00:23:18.680 --> 00:23:20.640]   It's what lots of automation and technology...
[00:23:20.640 --> 00:23:22.400]   That was the Luddite Revolution, right?
[00:23:22.400 --> 00:23:29.240]   Ned Ludd, who may or may not have existed, led weavers to destroy the Jack Hard Loom because
[00:23:29.240 --> 00:23:31.920]   they were losing jobs to Jack Hard Loom.
[00:23:31.920 --> 00:23:32.920]   Right.
[00:23:32.920 --> 00:23:34.560]   Well, in the physics about...
[00:23:34.560 --> 00:23:36.040]   Go ahead, Matthew.
[00:23:36.040 --> 00:23:45.040]   Just the other day I was looking at the number of long haul truck drivers in the United States.
[00:23:45.040 --> 00:23:48.080]   That job is effectively going to disappear.
[00:23:48.080 --> 00:23:53.240]   That's literally hundreds of thousands of people.
[00:23:53.240 --> 00:23:54.240]   And those are...
[00:23:54.240 --> 00:23:58.240]   Look at the map of the most common jobs in most American states is truck rubber.
[00:23:58.240 --> 00:23:59.240]   Yeah.
[00:23:59.240 --> 00:24:05.360]   So humanizing automation like that, I think is really interesting.
[00:24:05.360 --> 00:24:12.320]   I wonder what impact have any it has on the national conversation around it.
[00:24:12.320 --> 00:24:16.040]   So Amazon Go, which I don't know if we're going to talk about, but the grocery store
[00:24:16.040 --> 00:24:18.640]   concept that they just unveiled in Seattle.
[00:24:18.640 --> 00:24:19.640]   Oh my God.
[00:24:19.640 --> 00:24:20.640]   Why first job?
[00:24:20.640 --> 00:24:21.640]   Forget about it.
[00:24:21.640 --> 00:24:22.640]   Was it cashier?
[00:24:22.640 --> 00:24:23.640]   I don't like...
[00:24:23.640 --> 00:24:24.640]   Yeah.
[00:24:24.640 --> 00:24:30.640]   Now, I think there'll still be customer service kind of jobs like people in the store, but
[00:24:30.640 --> 00:24:32.640]   not as many.
[00:24:32.640 --> 00:24:36.320]   If you think about automation and stocking, then...
[00:24:36.320 --> 00:24:37.320]   Oof.
[00:24:37.320 --> 00:24:38.320]   Oof.
[00:24:38.320 --> 00:24:39.320]   Yeah.
[00:24:39.320 --> 00:24:44.960]   So the idea of the store and they only have one right now is kind of a beta is there
[00:24:44.960 --> 00:24:47.240]   isn't even an automated checkout.
[00:24:47.240 --> 00:24:51.640]   You just put stuff in your bag and it has cameras.
[00:24:51.640 --> 00:24:56.720]   It's kind of like in Vegas, the honor bar in Vegas, where if you move the peanuts, you
[00:24:56.720 --> 00:24:58.520]   get charged for the peanuts.
[00:24:58.520 --> 00:24:59.520]   But...
[00:24:59.520 --> 00:25:02.520]   That's exactly what we talked about it on our show for tomorrow.
[00:25:02.520 --> 00:25:03.520]   That's exactly what I was like.
[00:25:03.520 --> 00:25:04.760]   It's the hotel mini bar for it.
[00:25:04.760 --> 00:25:05.760]   Yeah.
[00:25:05.760 --> 00:25:06.760]   I think it's a little more sophisticated.
[00:25:06.760 --> 00:25:11.920]   You saw in this video that when you go in, you use your smartphone to check in so it
[00:25:11.920 --> 00:25:16.040]   knows you and it's clearly got to associate you with the purchase, right?
[00:25:16.040 --> 00:25:21.440]   So there's cameras following you around, I would guess, and sensors.
[00:25:21.440 --> 00:25:24.960]   Because it's got to know that you're the one that moved the cheesecake cupcake from the
[00:25:24.960 --> 00:25:27.960]   refrigerator and put it in the bag.
[00:25:27.960 --> 00:25:28.960]   But then you just walk...
[00:25:28.960 --> 00:25:33.480]   I mean, as a shopper, you love this, right?
[00:25:33.480 --> 00:25:34.640]   Oh, yeah.
[00:25:34.640 --> 00:25:37.480]   As a worker.
[00:25:37.480 --> 00:25:38.480]   But this is...
[00:25:38.480 --> 00:25:39.480]   Look, this is coming.
[00:25:39.480 --> 00:25:41.480]   I mean, can you legislate against stuff like this?
[00:25:41.480 --> 00:25:42.480]   I guess you could.
[00:25:42.480 --> 00:25:46.440]   Well, they're going to need someone to repair the sensors, right?
[00:25:46.440 --> 00:25:47.440]   Yeah.
[00:25:47.440 --> 00:25:54.920]   The economics of doing this are really interesting because you turn your wage expenditures over
[00:25:54.920 --> 00:25:58.600]   time into an upfront capital expenditure.
[00:25:58.600 --> 00:26:05.280]   And then you think about where down the value chain, like who affixes the RFID to the packaging.
[00:26:05.280 --> 00:26:06.800]   Right now, it's not integrated.
[00:26:06.800 --> 00:26:12.360]   So I'm not saying all these jobs are going to be instantly replaced, but there is just
[00:26:12.360 --> 00:26:13.360]   a shift.
[00:26:13.360 --> 00:26:18.240]   So figuring out where that shift is will be.
[00:26:18.240 --> 00:26:23.360]   The safety I was talking to a German and trying to hear it explain what's happening
[00:26:23.360 --> 00:26:28.720]   retail in the US and how we only have one bookstore left and one electronics store left.
[00:26:28.720 --> 00:26:33.360]   And I said, Amazon is going to bring down everything it can be commoditized into same
[00:26:33.360 --> 00:26:34.880]   day delivery and Amazon delivery.
[00:26:34.880 --> 00:26:35.880]   And then the fresh...
[00:26:35.880 --> 00:26:39.920]   Now they're attacking the only thing left which is fresh.
[00:26:39.920 --> 00:26:43.320]   And when it picks up stuff up and Amazon is going to be the future of all retail.
[00:26:43.320 --> 00:26:46.440]   Or something like that.
[00:26:46.440 --> 00:26:54.680]   So politicians at this point have chosen an easy kind of straw man to blame for the loss
[00:26:54.680 --> 00:26:59.440]   of jobs, which is international trade and offshoring.
[00:26:59.440 --> 00:27:00.840]   And furniture is coming in.
[00:27:00.840 --> 00:27:09.560]   I really don't see anybody saying the truth of the matter, which is that automation is
[00:27:09.560 --> 00:27:11.960]   going to cost far more jobs.
[00:27:11.960 --> 00:27:16.600]   And really the jobs it costs are lower skilled jobs.
[00:27:16.600 --> 00:27:18.440]   Yeah, entry level jobs.
[00:27:18.440 --> 00:27:20.280]   Entry level jobs here.
[00:27:20.280 --> 00:27:21.280]   You know, truck driver.
[00:27:21.280 --> 00:27:22.280]   Truck driver.
[00:27:22.280 --> 00:27:23.280]   That's a great job.
[00:27:23.280 --> 00:27:28.360]   One of the really well paid jobs that you don't need a college degree to do.
[00:27:28.360 --> 00:27:30.120]   And those are going to go away.
[00:27:30.120 --> 00:27:32.120]   Those are going to go away first.
[00:27:32.120 --> 00:27:34.280]   So that's problem one.
[00:27:34.280 --> 00:27:36.840]   And I don't see anybody saying, well, and what would you say?
[00:27:36.840 --> 00:27:37.840]   Well, let's stop automation.
[00:27:37.840 --> 00:27:38.840]   I don't know what you would say.
[00:27:38.840 --> 00:27:39.840]   Well, who's the...
[00:27:39.840 --> 00:27:42.560]   I'm going to be effort around basic income.
[00:27:42.560 --> 00:27:45.680]   Yeah, basic income though is a really bad idea.
[00:27:45.680 --> 00:27:48.920]   I'm not, I'm not, but this is Silicon Valley.
[00:27:48.920 --> 00:27:53.520]   People there are trying to push this in.
[00:27:53.520 --> 00:27:56.880]   Politicians can't go against automation because yes, it's going to take our jobs away, but
[00:27:56.880 --> 00:28:00.640]   it's also going to make our goods incredibly cheap.
[00:28:00.640 --> 00:28:03.680]   And that's what Mark Andreisien says.
[00:28:03.680 --> 00:28:04.680]   Exactly.
[00:28:04.680 --> 00:28:07.520]   He said, yeah, he says, well, but everything's going to be so cheap.
[00:28:07.520 --> 00:28:09.080]   But it's not infinitely cheap.
[00:28:09.080 --> 00:28:10.080]   It's not free.
[00:28:10.080 --> 00:28:13.680]   But you're still going to have to figure out what to do with people.
[00:28:13.680 --> 00:28:22.760]   If your Amazon is in your interest to maintain a large middle class that can buy goods because
[00:28:22.760 --> 00:28:32.160]   if you become so efficient that you eliminate your customers incomes, then it doesn't matter.
[00:28:32.160 --> 00:28:35.600]   So I think even companies like Amazon need to think about this.
[00:28:35.600 --> 00:28:39.120]   And of course, right now, the only groups that are thinking about it are unions.
[00:28:39.120 --> 00:28:45.560]   Well, it seems to me from a political point of view, if automation starts getting rid
[00:28:45.560 --> 00:28:53.400]   of millions of jobs, who are people going to look to sort of target as the to blame for
[00:28:53.400 --> 00:28:54.400]   that?
[00:28:54.400 --> 00:28:57.760]   It's going to be Silicon Valley and technology companies.
[00:28:57.760 --> 00:29:02.920]   And then the other blame piles on Matthew, I think you're right, then surveillance and
[00:29:02.920 --> 00:29:06.960]   privacy and taxes and all kinds of things pile on.
[00:29:06.960 --> 00:29:13.080]   And I think Silicon Valley is in for a rough ride going ahead that and they're not prepared
[00:29:13.080 --> 00:29:14.080]   for it.
[00:29:14.080 --> 00:29:15.720]   They're looking to fake news difficult.
[00:29:15.720 --> 00:29:17.520]   They're who bristic is ever out here.
[00:29:17.520 --> 00:29:23.040]   I mean, I do love the idea of, well, you'll only work at stuff you find interesting that
[00:29:23.040 --> 00:29:25.800]   the robots will do all the unpleasant work.
[00:29:25.800 --> 00:29:29.320]   And people who don't have a higher skill said who haven't been to college or haven't been
[00:29:29.320 --> 00:29:36.160]   trained in more advanced technologies will just have a basic income.
[00:29:36.160 --> 00:29:40.240]   They may not have the frills, but they'll be able to survive.
[00:29:40.240 --> 00:29:42.760]   Is that is what's wrong?
[00:29:42.760 --> 00:29:47.320]   Actually, let me I should take a step back because I said that's a bad idea.
[00:29:47.320 --> 00:29:48.320]   Is it a bad idea?
[00:29:48.320 --> 00:29:50.840]   Maybe that's not such a bad that sounds almost like a utopia.
[00:29:50.840 --> 00:29:51.840]   Why is it a bad idea?
[00:29:51.840 --> 00:29:52.840]   What about it?
[00:29:52.840 --> 00:29:56.280]   Is a basic income a bad idea?
[00:29:56.280 --> 00:29:59.280]   I actually don't think it's a bad idea at all.
[00:29:59.280 --> 00:30:03.800]   And it's funny, you can get people on the far left and you can get people sort of libertarians
[00:30:03.800 --> 00:30:10.360]   on the far right agreeing that basic income is a good idea.
[00:30:10.360 --> 00:30:19.000]   If you can't guarantee people sort of a shot at a reasonable job or living, then you have
[00:30:19.000 --> 00:30:20.440]   to give them something.
[00:30:20.440 --> 00:30:24.840]   Here's the one concern I've read about a basic income.
[00:30:24.840 --> 00:30:29.600]   I don't know enough about this and this is of course a matter of debate.
[00:30:29.600 --> 00:30:35.200]   But when Obama's chief economist and chairman of the council economic advisors talked about
[00:30:35.200 --> 00:30:41.200]   this, he says, replacing our current anti-poverty programs, and that's the part I want you to
[00:30:41.200 --> 00:30:47.640]   pay attention to, with universal basic income, would in any realistic design make the distribution
[00:30:47.640 --> 00:30:52.240]   of income worse, not better.
[00:30:52.240 --> 00:30:58.720]   Our tax and transfer system, in other words entitlements and poverty, any poverty programs,
[00:30:58.720 --> 00:31:02.800]   is largely targeted towards those in the lower half of the income distribution, which means
[00:31:02.800 --> 00:31:07.120]   it works to reduce both poverty and income inequality.
[00:31:07.120 --> 00:31:11.160]   Replacing part or all of that system with a universal cash grant would mean relatively
[00:31:11.160 --> 00:31:17.640]   less of the system was targeted towards those at the bottom, increasing income inequality
[00:31:17.640 --> 00:31:25.840]   because they replace everything from head start to food stamps with a check to medical
[00:31:25.840 --> 00:31:26.840]   care with a check.
[00:31:26.840 --> 00:31:32.520]   Then it's your responsibility to pay for everything out of that.
[00:31:32.520 --> 00:31:34.240]   I don't know enough about it.
[00:31:34.240 --> 00:31:38.880]   I mean, Furman is the chairman of the council of economic advisors.
[00:31:38.880 --> 00:31:42.280]   He's dead set against this for that reason.
[00:31:42.280 --> 00:31:45.400]   I would suggest reading more about it because I don't know.
[00:31:45.400 --> 00:31:47.320]   That's where that comes from.
[00:31:47.320 --> 00:31:50.520]   Aren't they doing experiments right now in Canada?
[00:31:50.520 --> 00:31:53.440]   Is it Vancouver or Matthew somewhere in Canada?
[00:31:53.440 --> 00:31:57.360]   They're doing a basic income experiment for a couple of months for a year.
[00:31:57.360 --> 00:31:58.600]   We should.
[00:31:58.600 --> 00:32:04.280]   To see what happens.
[00:32:04.280 --> 00:32:08.360]   Well, I guess it, the devil's in the details.
[00:32:08.360 --> 00:32:12.320]   I think Matthew's talking, but he's not saying anything.
[00:32:12.320 --> 00:32:15.920]   How many times has that happened to me?
[00:32:15.920 --> 00:32:20.000]   I think it replaces other things.
[00:32:20.000 --> 00:32:21.000]   Your point is a good one.
[00:32:21.000 --> 00:32:23.040]   If it replaces other things that are valuable.
[00:32:23.040 --> 00:32:24.040]   It has to.
[00:32:24.040 --> 00:32:25.040]   Right.
[00:32:25.040 --> 00:32:28.800]   But it doesn't, but it leaves people worse off as a result.
[00:32:28.800 --> 00:32:29.800]   Right.
[00:32:29.800 --> 00:32:30.800]   Then that's probably bad.
[00:32:30.800 --> 00:32:34.800]   This strikes me as the typical Silicon Valley utopianism, which usually involves a lot of
[00:32:34.800 --> 00:32:35.800]   hand waving.
[00:32:35.800 --> 00:32:37.520]   Like, oh, no, no, it's not a problem.
[00:32:37.520 --> 00:32:38.520]   Stuff's going to be good.
[00:32:38.520 --> 00:32:39.520]   It's going to be really cheap.
[00:32:39.520 --> 00:32:42.680]   You give everybody a basic income and it's utopia.
[00:32:42.680 --> 00:32:45.440]   The government ends up buying all of our services for people.
[00:32:45.440 --> 00:32:46.440]   Yay.
[00:32:46.440 --> 00:32:49.840]   But where does the government, so the government's tax base comes from where?
[00:32:49.840 --> 00:32:55.800]   I mean, this reminds me of, so the dystopian view would be that episode of Black Mirror,
[00:32:55.800 --> 00:33:01.600]   where people who didn't have the means just provided power for people by biking.
[00:33:01.600 --> 00:33:06.840]   So somewhere in the middle, maybe we can come up with something.
[00:33:06.840 --> 00:33:10.800]   Think about all the services we still need that involve people in robots are never going
[00:33:10.800 --> 00:33:11.800]   to take over.
[00:33:11.800 --> 00:33:18.520]   I think teaching, while you can augment that with computers, I think children and people
[00:33:18.520 --> 00:33:20.400]   still need people around them.
[00:33:20.400 --> 00:33:25.920]   So elder care, I think, could be an option.
[00:33:25.920 --> 00:33:29.800]   Any service where you have to teach people things, I don't know.
[00:33:29.800 --> 00:33:36.240]   Well, the hard part is that a lot of those jobs are relatively skilled in the sense that
[00:33:36.240 --> 00:33:42.800]   so cash your jobs and delivery truck driving jobs and loading and unloading warehouse jobs
[00:33:42.800 --> 00:33:49.600]   are great jobs for people who either can't get or can't afford to get skills where they
[00:33:49.600 --> 00:33:52.760]   could get a better job.
[00:33:52.760 --> 00:33:57.560]   I think the debate around what kind of education you need for things is also something worth
[00:33:57.560 --> 00:34:07.560]   talking about going forward because right now we have a very old set of thought processes
[00:34:07.560 --> 00:34:08.560]   basically.
[00:34:08.560 --> 00:34:11.360]   It's very simplistic and out of date.
[00:34:11.360 --> 00:34:15.920]   And that's why the political conversation right now is on loss of industrial jobs and
[00:34:15.920 --> 00:34:21.040]   offshoring when really the smart, the prudent thing would be to look to the future where
[00:34:21.040 --> 00:34:23.680]   it's really going to be about automation.
[00:34:23.680 --> 00:34:25.040]   And what do we do now?
[00:34:25.040 --> 00:34:29.960]   What kind of training, what kind of preparation, what kind of programs can we put in place?
[00:34:29.960 --> 00:34:36.360]   Because frankly, otherwise, if you have a large, unemployed group of unemployed people,
[00:34:36.360 --> 00:34:37.360]   nobody wants that.
[00:34:37.360 --> 00:34:39.760]   No government benefits when you have a large group of people.
[00:34:39.760 --> 00:34:42.160]   No, it's bad for every business, but for everybody.
[00:34:42.160 --> 00:34:45.360]   Education is just about the job skills.
[00:34:45.360 --> 00:34:49.760]   It's about understanding how to have a civic civil discussion in society.
[00:34:49.760 --> 00:34:52.000]   And that's what we're talking right now.
[00:34:52.000 --> 00:34:56.720]   It's about understanding the value of facts and the value of rationality.
[00:34:56.720 --> 00:35:01.200]   So did you know, so anyway, I agree, I think this is this.
[00:35:01.200 --> 00:35:02.400]   I don't know what the answers are.
[00:35:02.400 --> 00:35:05.760]   And this is why I brought this up kind of is what we need to think.
[00:35:05.760 --> 00:35:07.520]   We need to start preparing for this future though.
[00:35:07.520 --> 00:35:08.760]   And that's what everybody seems to agree.
[00:35:08.760 --> 00:35:11.480]   And by the way, we do a lot of interviews on this kind of stuff on triangulation.
[00:35:11.480 --> 00:35:15.160]   One of the things, one of the books we interviewed, I can't remember who it was, maybe you do
[00:35:15.160 --> 00:35:20.600]   Carsten talked about the fact it's not going to restrict itself to less skilled jobs.
[00:35:20.600 --> 00:35:24.880]   News and doctors are going to be out of work or reduced work because of automation as
[00:35:24.880 --> 00:35:25.880]   well.
[00:35:25.880 --> 00:35:31.400]   There's a, you know, the highlight from, it was a father and son who wrote this book.
[00:35:31.400 --> 00:35:38.000]   The highlight of it was that just that these more like a lawyer, well, you won't have to
[00:35:38.000 --> 00:35:39.440]   do all the busy work.
[00:35:39.440 --> 00:35:41.720]   You can do the stuff that a computer can't do very well.
[00:35:41.720 --> 00:35:45.360]   But what we're seeing is computers can do more and more stuff pretty well.
[00:35:45.360 --> 00:35:51.160]   And I just think there's fewer jobs in every category, I guess.
[00:35:51.160 --> 00:35:58.600]   In case of a dog, it won't replace, but it in augments, it makes diagnosis better.
[00:35:58.600 --> 00:36:00.400]   But I don't know that it's going to be more efficient.
[00:36:00.400 --> 00:36:02.600]   Well, if you're a radiology, let me put it this way.
[00:36:02.600 --> 00:36:06.000]   If you're a radiologist today, you should be thinking about what else you're going to
[00:36:06.000 --> 00:36:08.800]   do in five years.
[00:36:08.800 --> 00:36:10.480]   What if you think about it from this?
[00:36:10.480 --> 00:36:16.440]   So when I talk to industrial internet, like about industrial IoT, one of the big things
[00:36:16.440 --> 00:36:19.760]   that they're thinking about is the centralization of expertise.
[00:36:19.760 --> 00:36:26.640]   And you're seeing this happen with doctors with telemedicine is you can now send data
[00:36:26.640 --> 00:36:27.640]   wherever you want.
[00:36:27.640 --> 00:36:33.040]   So maybe we're going to get pools of places where you have people who are really good
[00:36:33.040 --> 00:36:36.000]   at what the automation isn't.
[00:36:36.000 --> 00:36:42.320]   And maybe we can get to a place where you can really fine tune and get to things that otherwise
[00:36:42.320 --> 00:36:44.880]   people weren't able to do.
[00:36:44.880 --> 00:36:51.440]   So maybe it's deeper, crazy, more esoteric surgeries that computers can't handle.
[00:36:51.440 --> 00:36:53.760]   I don't know.
[00:36:53.760 --> 00:36:59.920]   What I'd worry about though is when you can have those things anywhere, where are those
[00:36:59.920 --> 00:37:04.640]   things going to pool and if you don't have access to broadband, then you're out of that
[00:37:04.640 --> 00:37:05.880]   loop entirely.
[00:37:05.880 --> 00:37:09.520]   So this is tough.
[00:37:09.520 --> 00:37:13.440]   I actually think that's a huge element is a lot of the things that we're talking about,
[00:37:13.440 --> 00:37:18.640]   whether it's automation or sort of knowledge networks enabled by the internet.
[00:37:18.640 --> 00:37:23.960]   A lot of that stuff simply isn't available to people because of where they live.
[00:37:23.960 --> 00:37:27.200]   They have something that amounts to dial up access.
[00:37:27.200 --> 00:37:29.880]   Well, I think that that's another reason.
[00:37:29.880 --> 00:37:40.040]   There's a huge gulf between the urban elites and liberals and the rural disenfranchised.
[00:37:40.040 --> 00:37:44.120]   And boy, you see that gulf in this country and it's just widened and widened and widened.
[00:37:44.120 --> 00:37:49.120]   Well, in the election, I think it highlighted reflected some of that.
[00:37:49.120 --> 00:37:53.000]   And boy, that's as clear as crystal clear that that's happening.
[00:37:53.000 --> 00:37:54.880]   And it has been happening.
[00:37:54.880 --> 00:38:00.880]   People also see at a government level licensing requirements about people being in the mix.
[00:38:00.880 --> 00:38:02.480]   That for sure is going to happen.
[00:38:02.480 --> 00:38:09.480]   So we're never going to have a robot doing surgery without somebody present and probably
[00:38:09.480 --> 00:38:12.040]   several someone's present for a long time to come.
[00:38:12.040 --> 00:38:16.320]   And that's how the government's probably going to help ease some of this out.
[00:38:16.320 --> 00:38:19.480]   And there will be people who are like, "Ah, that's so unfair.
[00:38:19.480 --> 00:38:23.480]   It could be cheaper and better when robots can do everything."
[00:38:23.480 --> 00:38:25.840]   So it'll be kind of an interesting fun debate.
[00:38:25.840 --> 00:38:30.600]   Well, and that can definitely see there's no way they're going to let massive amounts
[00:38:30.600 --> 00:38:35.240]   of tractor trailers drive across the country without human being sitting in the cab to make
[00:38:35.240 --> 00:38:36.240]   it safer.
[00:38:36.240 --> 00:38:37.240]   What if it's safer?
[00:38:37.240 --> 00:38:38.240]   Feel better.
[00:38:38.240 --> 00:38:40.600]   What if you get better medicine because it's automated and it's cheaper and we can't afford
[00:38:40.600 --> 00:38:41.960]   it to have humans do it?
[00:38:41.960 --> 00:38:47.720]   What if there are fewer accidents because robot trucks are safer?
[00:38:47.720 --> 00:38:50.120]   But if a robot kills you?
[00:38:50.120 --> 00:38:52.320]   Yeah, but it's very different.
[00:38:52.320 --> 00:38:59.440]   I think it's going to be increasingly difficult for regulations to enforce something that has
[00:38:59.440 --> 00:39:01.200]   such a high cost in other areas.
[00:39:01.200 --> 00:39:02.200]   I don't know.
[00:39:02.200 --> 00:39:03.200]   I don't know.
[00:39:03.200 --> 00:39:04.200]   Think about...
[00:39:04.200 --> 00:39:07.920]   I hate to think that government's going to protect us from all of the...
[00:39:07.920 --> 00:39:13.560]   It's less government and more like licensing zeros and agencies.
[00:39:13.560 --> 00:39:15.760]   Or think about safety regulations.
[00:39:15.760 --> 00:39:29.120]   Think about the airplane, that industry pilots are needed for a relatively small portion
[00:39:29.120 --> 00:39:30.800]   of the average airplane flight.
[00:39:30.800 --> 00:39:33.640]   Still fewer pilot jobs, right?
[00:39:33.640 --> 00:39:38.200]   Many of them fall asleep during the flight because they're simply not necessary.
[00:39:38.200 --> 00:39:40.840]   Planes could easily take off and land themselves.
[00:39:40.840 --> 00:39:44.840]   But I don't think we're prepared to accept that for a whole bunch of reasons.
[00:39:44.840 --> 00:39:48.520]   So we still have human beings in the content.
[00:39:48.520 --> 00:39:49.520]   Hey!
[00:39:49.520 --> 00:39:53.000]   Stuff that I wish we were seeing more of this kind of conversation going on in the public
[00:39:53.000 --> 00:39:54.000]   for...
[00:39:54.000 --> 00:39:58.160]   And we've got a good segue if we want to take it.
[00:39:58.160 --> 00:39:59.160]   Let's take it.
[00:39:59.160 --> 00:40:00.160]   Google.
[00:40:00.160 --> 00:40:03.960]   To Google Wings program because that is delivery jobs possibly.
[00:40:03.960 --> 00:40:06.000]   What is the Google...
[00:40:06.000 --> 00:40:08.720]   You mean Wing Marketplace?
[00:40:08.720 --> 00:40:11.480]   Wing Marketplace, sorry.
[00:40:11.480 --> 00:40:14.680]   There's an app that takes you to the airport here in Austin since we don't have Uber and
[00:40:14.680 --> 00:40:15.920]   Lyft that's called Wings.
[00:40:15.920 --> 00:40:18.680]   And so my brain just went wings.
[00:40:18.680 --> 00:40:19.680]   This is...
[00:40:19.680 --> 00:40:20.680]   This is...
[00:40:20.680 --> 00:40:21.680]   This is...
[00:40:21.680 --> 00:40:23.640]   This is a Google drone delivery thing?
[00:40:23.640 --> 00:40:25.080]   Is that what this is?
[00:40:25.080 --> 00:40:26.080]   Yes.
[00:40:26.080 --> 00:40:27.080]   Wing Marketplace.
[00:40:27.080 --> 00:40:29.120]   Is that what it's called?
[00:40:29.120 --> 00:40:31.160]   But only for chicken wings.
[00:40:31.160 --> 00:40:32.160]   Not for chicken wings.
[00:40:32.160 --> 00:40:33.760]   Not for chicken wings.
[00:40:33.760 --> 00:40:34.760]   Maybe for chicken wings.
[00:40:34.760 --> 00:40:35.760]   I don't know.
[00:40:35.760 --> 00:40:36.760]   Although that would be a good idea, am I right?
[00:40:36.760 --> 00:40:38.760]   You'd be looking at the wrong article.
[00:40:38.760 --> 00:40:39.760]   Here Wall Street Journal.
[00:40:39.760 --> 00:40:47.120]   Google X plans Wing Marketplace, I guess, made the wrong link every time.
[00:40:47.120 --> 00:40:50.120]   An online exchange for $6 drone deliveries for...
[00:40:50.120 --> 00:40:51.120]   What the...
[00:40:51.120 --> 00:40:54.760]   See, this is why when people say, "Oh, well, this is years off."
[00:40:54.760 --> 00:40:56.360]   And then you read stuff like this.
[00:40:56.360 --> 00:40:57.600]   Oh, radiologists.
[00:40:57.600 --> 00:40:59.400]   We got another couple of decades.
[00:40:59.400 --> 00:41:00.640]   And then you read stuff like this.
[00:41:00.640 --> 00:41:03.520]   This stuff's happening pretty fast.
[00:41:03.520 --> 00:41:11.960]   So drone deliveries for $6, I don't understand.
[00:41:11.960 --> 00:41:16.240]   But now remember we were talking about the Chipotle deliveries in Virginia Tech, which
[00:41:16.240 --> 00:41:18.840]   were discontinued, right?
[00:41:18.840 --> 00:41:27.080]   Starbucks pulled out of the negotiations because Starbucks wanted the customer data.
[00:41:27.080 --> 00:41:29.440]   So they're working with...
[00:41:29.440 --> 00:41:33.320]   They've reportedly met with Domino's pizza, Whole Foods, and other fast food chains to
[00:41:33.320 --> 00:41:34.320]   get the program.
[00:41:34.320 --> 00:41:39.560]   They haven't approved for test flights, but only at a special location, right?
[00:41:39.560 --> 00:41:40.560]   Yes.
[00:41:40.560 --> 00:41:46.440]   So they haven't yet been approved for general drone deliveries.
[00:41:46.440 --> 00:41:48.760]   What's the interest in drone deliveries?
[00:41:48.760 --> 00:41:51.520]   I was just going to ask that because I was sitting here...
[00:41:51.520 --> 00:41:55.480]   I understand the logic, right?
[00:41:55.480 --> 00:41:58.120]   UPS trucks are too big to get places.
[00:41:58.120 --> 00:42:00.840]   The air is relatively un-conjested for now.
[00:42:00.840 --> 00:42:05.200]   Yeah, wait until every package has thrown into us to it.
[00:42:05.200 --> 00:42:09.360]   But if you think about sending a drone through a warehouse, it can pick up what it needs because
[00:42:09.360 --> 00:42:11.320]   it's tagged automatically.
[00:42:11.320 --> 00:42:16.200]   Because it's computerized, it can be scaled to massive deliveries, right?
[00:42:16.200 --> 00:42:20.400]   But yet, because it's small and lightweight, it can do it at a personalization.
[00:42:20.400 --> 00:42:24.560]   So you combine scale, yay, plus personalization, way.
[00:42:24.560 --> 00:42:27.200]   So I see why it's intellectually appealing.
[00:42:27.200 --> 00:42:30.760]   But would you picture the world like this?
[00:42:30.760 --> 00:42:33.000]   It's not really appealing at all.
[00:42:33.000 --> 00:42:38.760]   I guess what this is looking at is the continued trend towards the distribution of intelligence
[00:42:38.760 --> 00:42:42.160]   into every little small thing.
[00:42:42.160 --> 00:42:47.120]   And drone technology allows it to be mobile intelligence.
[00:42:47.120 --> 00:42:49.360]   And it's kind of like nanobots, right?
[00:42:49.360 --> 00:42:57.880]   The idea that you can have millions of tiny, intelligent things all acting, avoiding running
[00:42:57.880 --> 00:42:59.360]   into stuff.
[00:42:59.360 --> 00:43:03.400]   And so you had millions of drones just, like you said, Stacey, flying into the factory,
[00:43:03.400 --> 00:43:05.840]   getting the thing and flying it to me.
[00:43:05.840 --> 00:43:09.040]   I guess that's more efficient, but it's kind of a sci-fi future.
[00:43:09.040 --> 00:43:12.320]   I mean, there are places where it makes sense.
[00:43:12.320 --> 00:43:14.560]   I think it just sounds cool.
[00:43:14.560 --> 00:43:15.560]   Delivering drugs and Haiti.
[00:43:15.560 --> 00:43:18.360]   Well, see, part of what we do is because it sounds cool, right?
[00:43:18.360 --> 00:43:20.920]   They feel like Eric Schmidt's going, not Eric Schmidt.
[00:43:20.920 --> 00:43:22.920]   Sergey Brin's going, well, how to be cool.
[00:43:22.920 --> 00:43:24.400]   Let's do that.
[00:43:24.400 --> 00:43:29.160]   So I was talking to somebody, maybe now Jeff, close your ears because you're at Google,
[00:43:29.160 --> 00:43:35.000]   starting with somebody who had a friend who worked at Google, who said he's everybody's
[00:43:35.000 --> 00:43:40.800]   dispirited at Google because Ruth Porat, the new CFO, apparently Larry and Sergey are
[00:43:40.800 --> 00:43:42.080]   out smoking blunts.
[00:43:42.080 --> 00:43:47.360]   They're just kind of dialed out and Ruth Porat's in charge and she's been slashing everything,
[00:43:47.360 --> 00:43:51.760]   including, by the way, this drone project.
[00:43:51.760 --> 00:43:57.240]   In fact, this is exactly what it says, this article from Bloomberg Technology last month.
[00:43:57.240 --> 00:44:02.720]   The Project Wing is the latest alphabet project to be targeted financial restraint, aka Ruth
[00:44:02.720 --> 00:44:03.720]   Porat.
[00:44:03.720 --> 00:44:08.360]   There do seem to be a lot of cuts.
[00:44:08.360 --> 00:44:10.360]   This person was very dispirited.
[00:44:10.360 --> 00:44:17.760]   Well, Google was always the one that funded stuff that seemed futuristic and probably
[00:44:17.760 --> 00:44:20.720]   unmonetizable.
[00:44:20.720 --> 00:44:23.880]   That's part of what we liked about it, I think, was that they were the ones willing to take
[00:44:23.880 --> 00:44:26.320]   on these massive programs.
[00:44:26.320 --> 00:44:27.320]   Go ahead, Jeff.
[00:44:27.320 --> 00:44:28.320]   You're right, Matthew.
[00:44:28.320 --> 00:44:30.480]   Where else is there pure research going on?
[00:44:30.480 --> 00:44:31.480]   Well, everywhere.
[00:44:31.480 --> 00:44:32.960]   We just don't talk about it.
[00:44:32.960 --> 00:44:37.720]   I'm sure Apple is doing a lot of pure research in a lot of interesting areas.
[00:44:37.720 --> 00:44:42.320]   Apple clearly is Mark Zuckerberg's building Jarvis in his house.
[00:44:42.320 --> 00:44:44.320]   You call that?
[00:44:44.320 --> 00:44:45.320]   That's not.
[00:44:45.320 --> 00:44:51.880]   Yeah, but Google always felt like the research and sort of making the world better or whatever.
[00:44:51.880 --> 00:44:56.320]   Maybe I'm just naive, but that was part of what they were doing, not just trying to
[00:44:56.320 --> 00:44:58.760]   create something they could sell for a bunch of money.
[00:44:58.760 --> 00:45:04.600]   According to this journal article, the reason Wing Project kind of got clipped is because
[00:45:04.600 --> 00:45:08.680]   they were aiming for a thousand successful flights and they couldn't get without accident.
[00:45:08.680 --> 00:45:10.480]   They couldn't get past 300.
[00:45:10.480 --> 00:45:13.960]   They kept running into trees and falling out of the sky.
[00:45:13.960 --> 00:45:15.560]   So it wasn't Ruth Porrett.
[00:45:15.560 --> 00:45:20.440]   It was a technology problem that clipped wings.
[00:45:20.440 --> 00:45:24.160]   I think the drones, have you seen the pizza delivering drone?
[00:45:24.160 --> 00:45:28.960]   It's just a little cooler with wheels and it drives around neighborhoods and comes to
[00:45:28.960 --> 00:45:29.960]   your door.
[00:45:29.960 --> 00:45:34.480]   That seems way more realistic to me than things flying through the air and dropping
[00:45:34.480 --> 00:45:35.480]   pizzas.
[00:45:35.480 --> 00:45:36.480]   Like why?
[00:45:36.480 --> 00:45:41.080]   Well, imagine if we're trying to take off from SFO and you have to wait till 300 drones.
[00:45:41.080 --> 00:45:42.960]   We've been carrying pizzas.
[00:45:42.960 --> 00:45:45.080]   Get out of the way.
[00:45:45.080 --> 00:45:46.440]   Forget the person drone.
[00:45:46.440 --> 00:45:47.440]   Bird strikes.
[00:45:47.440 --> 00:45:50.920]   Wasn't there a drone accident with a plane?
[00:45:50.920 --> 00:45:51.920]   Was there?
[00:45:51.920 --> 00:45:52.920]   Has there been now?
[00:45:52.920 --> 00:45:53.920]   I think there was one.
[00:45:53.920 --> 00:45:55.880]   No, I think it was with all boats.
[00:45:55.880 --> 00:45:56.880]   I think.
[00:45:56.880 --> 00:45:57.880]   Yeah.
[00:45:57.880 --> 00:45:58.880]   It could have been.
[00:45:58.880 --> 00:46:01.440]   Let's take a break and then we're going to talk about deep mind.
[00:46:01.440 --> 00:46:04.440]   Ooh, as long as we're talking about deep things.
[00:46:04.440 --> 00:46:11.240]   But first, how about some deep sleep brought to you by Casper, the world's best mattress.
[00:46:11.240 --> 00:46:18.480]   Casper offers free shipping and returns in the US and Canada of the best mattress ever
[00:46:18.480 --> 00:46:21.160]   made in the US of a live the dream.
[00:46:21.160 --> 00:46:23.600]   It's the perfect mattress.
[00:46:23.600 --> 00:46:27.400]   The technology behind the Casper mattress is amazing.
[00:46:27.400 --> 00:46:31.560]   Time magazine named it one of the best inventions of 2015.
[00:46:31.560 --> 00:46:37.240]   Fast company, design, finalist 2015, big innovation, award winner 2016 because these
[00:46:37.240 --> 00:46:44.760]   mattresses are made in the USA with some really sophisticated technology so that they breathe.
[00:46:44.760 --> 00:46:50.240]   Actually, I love, let me see if I can find, they talk about the technology here on.
[00:46:50.240 --> 00:46:52.880]   This is the website.
[00:46:52.880 --> 00:46:57.480]   How they designed the mattress, they had the criterion that they used.
[00:46:57.480 --> 00:46:58.480]   See the design story?
[00:46:58.480 --> 00:47:00.880]   Here it is.
[00:47:00.880 --> 00:47:02.160]   They were looking for a mattress.
[00:47:02.160 --> 00:47:03.160]   These are the factors.
[00:47:03.160 --> 00:47:06.400]   Firmness, density, the factors they considered.
[00:47:06.400 --> 00:47:10.320]   Rebound speed, airflow, transition temperature.
[00:47:10.320 --> 00:47:17.560]   If you've ever had a smart memory foam mattress, you know that they get hard when it's cold.
[00:47:17.560 --> 00:47:22.120]   It's weird and odor because nobody wants to smell latex.
[00:47:22.120 --> 00:47:23.120]   They solve these.
[00:47:23.120 --> 00:47:25.600]   I can tell you from experience because I have a Casper mattress.
[00:47:25.600 --> 00:47:26.600]   I like it so much.
[00:47:26.600 --> 00:47:27.600]   I gave one to my son.
[00:47:27.600 --> 00:47:29.600]   Our nephew has one as well.
[00:47:29.600 --> 00:47:32.560]   These are great mattresses made in the United States.
[00:47:32.560 --> 00:47:35.560]   They did 1,000 different formulations of foam.
[00:47:35.560 --> 00:47:44.080]   3,240 hours of testing delivered 108 prototypes before they came out with the perfect mattress.
[00:47:44.080 --> 00:47:50.080]   An award winning combination of latex memory and support foams and combined in such a way
[00:47:50.080 --> 00:47:53.800]   that you get this amazing night's sleep with no springs, no coils.
[00:47:53.800 --> 00:47:56.560]   It has just the right give, just the right firmness.
[00:47:56.560 --> 00:47:59.040]   Look, here's the deal.
[00:47:59.040 --> 00:48:00.040]   You got to try it.
[00:48:00.040 --> 00:48:04.600]   The beauty part of this, it comes in this great box.
[00:48:04.600 --> 00:48:09.080]   Surprisingly small box and you just open it up and the mattress emerges, which makes
[00:48:09.080 --> 00:48:11.880]   it easy to get into the bedroom.
[00:48:11.880 --> 00:48:14.320]   You might say, "Well, when if I don't like it, well, good news.
[00:48:14.320 --> 00:48:17.200]   You have 100 days to return it."
[00:48:17.200 --> 00:48:23.720]   If at any time in the first 100 days you don't like it, Casper sends along a courier
[00:48:23.720 --> 00:48:27.040]   who will take it off your hands and refund every penny.
[00:48:27.040 --> 00:48:31.360]   There's no risk in getting a Casper mattress.
[00:48:31.360 --> 00:48:36.280]   We love our Casper and I want you to try it for a great, a great sleep.
[00:48:36.280 --> 00:48:41.920]   100 night free trial awaits you and we're going to get you $50 off your mattress purchase.
[00:48:41.920 --> 00:48:51.040]   When you go to Casper, C-A-S-P-E-R.com/twig, Casper.com/twig, use the offer code twig at
[00:48:51.040 --> 00:48:57.640]   checkout to save 50 bucks on any mattress from Casper terms and conditions to apply.
[00:48:57.640 --> 00:49:03.000]   Casper.com/twig.
[00:49:03.000 --> 00:49:05.960]   If your mattress is more than 10 years old, it's time for anyone.
[00:49:05.960 --> 00:49:08.080]   You should not keep sleeping on it.
[00:49:08.080 --> 00:49:11.400]   People do not replace mattresses often enough.
[00:49:11.400 --> 00:49:18.960]   I didn't realize this, but when Google acquired DeepMind, the artificial intelligence lab,
[00:49:18.960 --> 00:49:29.920]   they created a board, according to Business Insider, a mysterious AI ethics board.
[00:49:29.920 --> 00:49:35.920]   Earlier this week, DeepMind's co-founder Mustafa Suleiman was speaking at TechCrunch
[00:49:35.920 --> 00:49:38.200]   Disrupt in London.
[00:49:38.200 --> 00:49:41.120]   He refused who said who's on the board.
[00:49:41.120 --> 00:49:43.600]   It's a secret.
[00:49:43.600 --> 00:49:45.320]   The ethics board is ongoing.
[00:49:45.320 --> 00:49:48.680]   We have internally to oversee some of our efforts.
[00:49:48.680 --> 00:49:50.360]   We've tried other approaches most recently.
[00:49:50.360 --> 00:49:54.400]   We got together with Amazon, Facebook, IBM, Microsoft, and Google to start the partnership
[00:49:54.400 --> 00:49:56.560]   on AI.
[00:49:56.560 --> 00:50:02.400]   We've often said, "Google's SkyNet," blah, blah, blah, but I think even they are a little
[00:50:02.400 --> 00:50:03.400]   nervous.
[00:50:03.400 --> 00:50:06.800]   They've got an ethics board.
[00:50:06.800 --> 00:50:11.320]   Last year, he said he wanted to publish the names that people have said on the board, but
[00:50:11.320 --> 00:50:14.640]   for some reason pulled back.
[00:50:14.640 --> 00:50:17.240]   What is the rationale for not making that secret?
[00:50:17.240 --> 00:50:18.240]   That's a secret.
[00:50:18.240 --> 00:50:19.240]   I don't know.
[00:50:19.240 --> 00:50:20.240]   But why?
[00:50:20.240 --> 00:50:21.240]   I don't know.
[00:50:21.240 --> 00:50:22.240]   See, that's what I wonder.
[00:50:22.240 --> 00:50:25.760]   The fact that it's making it public would be wonderful because you could actually say
[00:50:25.760 --> 00:50:28.640]   things like, "Hey, look at your board.
[00:50:28.640 --> 00:50:30.720]   It's all white men."
[00:50:30.720 --> 00:50:31.720]   That's probably why, right?
[00:50:31.720 --> 00:50:32.720]   That's probably why.
[00:50:32.720 --> 00:50:36.560]   That has a very different effect on the types of algorithms and how you're training
[00:50:36.560 --> 00:50:39.120]   thing, I mean, how you think about ethics.
[00:50:39.120 --> 00:50:43.960]   This, John C. Havens, we interviewed about his book, "Heart Official Intelligence, Embracing
[00:50:43.960 --> 00:50:46.840]   Our Humanity that Maximize Machines" wrote on Medium.
[00:50:46.840 --> 00:50:49.560]   Deep Mind, where's the AI ethics board?
[00:50:49.560 --> 00:50:51.480]   He said exactly that.
[00:50:51.480 --> 00:50:57.960]   Okay, great that you have an ethics board, but you've got to tell us who these people
[00:50:57.960 --> 00:51:00.920]   are so we understand what your guidelines are.
[00:51:00.920 --> 00:51:04.960]   You've got to reveal guidelines regarding ethical considerations.
[00:51:04.960 --> 00:51:07.520]   What have Peter Thiel's on there?
[00:51:07.520 --> 00:51:08.520]   Yeah.
[00:51:08.520 --> 00:51:11.320]   I'm just saying.
[00:51:11.320 --> 00:51:15.280]   No, I'm not going to go there.
[00:51:15.280 --> 00:51:16.280]   Not today.
[00:51:16.280 --> 00:51:17.280]   Thank you.
[00:51:17.280 --> 00:51:18.280]   Not today, thank you.
[00:51:18.280 --> 00:51:21.480]   He says, "I'm tired of being angry at Google.
[00:51:21.480 --> 00:51:22.480]   Here's my appeal.
[00:51:22.480 --> 00:51:26.840]   Googlers, please announce some specifics about the AI ethics board.
[00:51:26.840 --> 00:51:29.000]   Delight us all with the experts.
[00:51:29.000 --> 00:51:33.640]   You've asked to be part of this groundbreaking group that aren't all on your board, Silicon
[00:51:33.640 --> 00:51:36.240]   Valley types or technocrats.
[00:51:36.240 --> 00:51:41.920]   Surprise us with your choices of multiracial women, heavy, globally represented voices
[00:51:41.920 --> 00:51:45.720]   that can spark a conversation about humanity and ethics.
[00:51:45.720 --> 00:51:51.360]   Because if all you got is a bunch of people reading science fiction, it's not going to
[00:51:51.360 --> 00:51:52.360]   do it."
[00:51:52.360 --> 00:51:54.000]   Good point.
[00:51:54.000 --> 00:51:55.160]   I didn't even know they had a board.
[00:51:55.160 --> 00:52:00.040]   I'm glad to see they have a board, but it doesn't mean much if it's not.
[00:52:00.040 --> 00:52:02.800]   Who should be on it?
[00:52:02.800 --> 00:52:04.920]   Oh, Jeff, turn it in into a positive.
[00:52:04.920 --> 00:52:06.920]   You know who'd be great?
[00:52:06.920 --> 00:52:11.880]   Just because I love his writing on AI and just the world, it's Ken Liu.
[00:52:11.880 --> 00:52:12.880]   He's a story.
[00:52:12.880 --> 00:52:13.880]   He's a writer.
[00:52:13.880 --> 00:52:16.040]   Gosh, Ken, let's see.
[00:52:16.040 --> 00:52:19.120]   Is that how you say it spell his name?
[00:52:19.120 --> 00:52:20.360]   I'm trying to think.
[00:52:20.360 --> 00:52:21.360]   No.
[00:52:21.360 --> 00:52:22.360]   Did we interview Ken?
[00:52:22.360 --> 00:52:23.360]   I think we did.
[00:52:23.360 --> 00:52:24.360]   That sounds familiar.
[00:52:24.360 --> 00:52:25.360]   What does he do?
[00:52:25.360 --> 00:52:26.360]   Ken, so L-I-U.
[00:52:26.360 --> 00:52:31.320]   Yeah, he graced of kings on the paper of an agery.
[00:52:31.320 --> 00:52:32.320]   I think you're right.
[00:52:32.320 --> 00:52:34.520]   I think sometimes writers might be the right people.
[00:52:34.520 --> 00:52:38.640]   I'm not saying he should be the only one, but he writes about this and he follows research
[00:52:38.640 --> 00:52:44.000]   very closely and then clearly is spinning it into these kind of narratives that put
[00:52:44.000 --> 00:52:48.040]   people at this core, and that's so essential.
[00:52:48.040 --> 00:52:50.040]   So he's a paper manager.
[00:52:50.040 --> 00:52:52.040]   Nick Carr would be great.
[00:52:52.040 --> 00:52:55.440]   I also think you want people, I think Stacy's instinct is right here.
[00:52:55.440 --> 00:52:57.480]   You want people from outside the field too.
[00:52:57.480 --> 00:53:00.960]   You want a clergy and a historian.
[00:53:00.960 --> 00:53:05.400]   That's kind of a Unitarian on that board.
[00:53:05.400 --> 00:53:06.400]   Unitarian.
[00:53:06.400 --> 00:53:10.880]   Well, you're laughing at my faith.
[00:53:10.880 --> 00:53:12.680]   I was brought up Unitarian.
[00:53:12.680 --> 00:53:15.800]   The thing I like about Unitarian is because the message, at least when they told me, is
[00:53:15.800 --> 00:53:17.720]   worship the God of your choice.
[00:53:17.720 --> 00:53:18.720]   Yeah.
[00:53:18.720 --> 00:53:19.720]   Yeah.
[00:53:19.720 --> 00:53:20.720]   Anything goes.
[00:53:20.720 --> 00:53:21.720]   Anything goes.
[00:53:21.720 --> 00:53:24.280]   It's the least religious religion.
[00:53:24.280 --> 00:53:25.960]   That's for me, baby.
[00:53:25.960 --> 00:53:26.960]   Yeah.
[00:53:26.960 --> 00:53:28.880]   But I'm glad they have an ethics board.
[00:53:28.880 --> 00:53:30.200]   I'd like to know who's on it.
[00:53:30.200 --> 00:53:31.920]   And I think you're right, Jeff.
[00:53:31.920 --> 00:53:34.920]   We can think about there's some people you would want on there.
[00:53:34.920 --> 00:53:36.400]   You'd want a Nelson Mandela.
[00:53:36.400 --> 00:53:41.400]   You'd want some people who are great humanitarians on that board.
[00:53:41.400 --> 00:53:42.400]   Yeah.
[00:53:42.400 --> 00:53:43.400]   Yeah.
[00:53:43.400 --> 00:53:45.760]   Who's the writer for weapons of math destruction?
[00:53:45.760 --> 00:53:47.240]   Catherianila be great.
[00:53:47.240 --> 00:53:48.240]   Catherianila.
[00:53:48.240 --> 00:53:50.240]   We want Catherianila.
[00:53:50.240 --> 00:53:51.240]   Larry Leste.
[00:53:51.240 --> 00:53:52.240]   Larry Leste.
[00:53:52.240 --> 00:53:53.240]   Larry Leste.
[00:53:53.240 --> 00:53:54.240]   Daina Boyd.
[00:53:54.240 --> 00:53:55.240]   Daina Boyd.
[00:53:55.240 --> 00:53:56.240]   Daina Boyd.
[00:53:56.240 --> 00:53:57.240]   David Brinneal Stevenson.
[00:53:57.240 --> 00:53:58.880]   And we can go on and on.
[00:53:58.880 --> 00:54:01.120]   There are lots of people who should be on that board.
[00:54:01.120 --> 00:54:02.120]   Margaret Atwood.
[00:54:02.120 --> 00:54:03.120]   Mm-hmm.
[00:54:03.120 --> 00:54:04.120]   And she'd be great.
[00:54:04.120 --> 00:54:05.760]   I like that a lot.
[00:54:05.760 --> 00:54:06.760]   Wouldn't she be great?
[00:54:06.760 --> 00:54:07.760]   It would be.
[00:54:07.760 --> 00:54:09.320]   And she's written a lot about these issues.
[00:54:09.320 --> 00:54:11.200]   She's thought about these issues.
[00:54:11.200 --> 00:54:12.200]   Yeah.
[00:54:12.200 --> 00:54:13.200]   Okay.
[00:54:13.200 --> 00:54:14.200]   Well, gosh.
[00:54:14.200 --> 00:54:18.760]   We should have the AI ethics board episode of Twig and just get some of these people
[00:54:18.760 --> 00:54:20.680]   in the room and we'll ask them questions.
[00:54:20.680 --> 00:54:26.680]   That would be fascinating just to just to just to record show a meeting of this group
[00:54:26.680 --> 00:54:28.560]   and what they're talking about thinking.
[00:54:28.560 --> 00:54:29.960]   But here's the thing Leo.
[00:54:29.960 --> 00:54:32.000]   Actually, I don't think it's the number of problems.
[00:54:32.000 --> 00:54:36.440]   I'll bet that there is discussion of capabilities that they just don't want out.
[00:54:36.440 --> 00:54:37.800]   That would be scary.
[00:54:37.800 --> 00:54:38.800]   Probably.
[00:54:38.800 --> 00:54:42.440]   Because Google knows better than anybody what these things can do.
[00:54:42.440 --> 00:54:43.440]   Yeah.
[00:54:43.440 --> 00:54:44.440]   Yeah.
[00:54:44.440 --> 00:54:48.600]   Remember when they said they weren't going to enable facial recognition even though they
[00:54:48.600 --> 00:54:49.600]   could?
[00:54:49.600 --> 00:54:50.600]   Right.
[00:54:50.600 --> 00:54:51.600]   Sorry.
[00:54:51.600 --> 00:54:56.560]   Well, my complaint then was, well, government already has all that.
[00:54:56.560 --> 00:54:57.560]   Why can't we have it?
[00:54:57.560 --> 00:54:58.560]   Yeah.
[00:54:58.560 --> 00:54:59.560]   Yeah.
[00:54:59.560 --> 00:55:00.560]   Yeah.
[00:55:00.560 --> 00:55:02.800]   The government doesn't know how to implement a lot of these things in a way that-
[00:55:02.800 --> 00:55:04.360]   Thank God.
[00:55:04.360 --> 00:55:06.800]   Sometimes the lack of competence is-
[00:55:06.800 --> 00:55:08.080]   Yeah, that's good.
[00:55:08.080 --> 00:55:16.640]   So we had on Monday the most mind-boggling interview with the director of Jason Matheny
[00:55:16.640 --> 00:55:22.120]   of the Iarpa, which is a government- it's like DARPA, but it's under the director of
[00:55:22.120 --> 00:55:24.120]   national intelligence.
[00:55:24.120 --> 00:55:29.720]   It's the internet, it's the intelligence advanced research projects activity.
[00:55:29.720 --> 00:55:35.560]   And if you look at the things they're investigating, it's all of that.
[00:55:35.560 --> 00:55:37.120]   Frightening about it.
[00:55:37.120 --> 00:55:38.120]   Frightening.
[00:55:38.120 --> 00:55:44.200]   Well, what's- yeah, actually I was kind of a little reassured because they were paying
[00:55:44.200 --> 00:55:46.040]   attention, I guess.
[00:55:46.040 --> 00:55:50.040]   But yeah, I mean, it's automatic speech recognition in reverberant environments.
[00:55:50.040 --> 00:55:54.640]   In other words, speech recognition in less than favorable acoustic environments.
[00:55:54.640 --> 00:55:58.440]   They had this great thing, this challenge called Jedi Mind.
[00:55:58.440 --> 00:56:00.160]   Who can you trust?
[00:56:00.160 --> 00:56:07.320]   And what metrics would you apply to find out if somebody you're talking to is trustworthy?
[00:56:07.320 --> 00:56:13.760]   And what they do is they open it to researchers, scientists, universities.
[00:56:13.760 --> 00:56:18.080]   It's- it was a- but if you didn't hear the interview, it was- wow.
[00:56:18.080 --> 00:56:23.400]   It was kind of the stuff that the government is investigating.
[00:56:23.400 --> 00:56:25.880]   And this is for pretty blue sky research.
[00:56:25.880 --> 00:56:33.680]   What Jason Matheny said is this is high risk, high reward investigations.
[00:56:33.680 --> 00:56:36.840]   High risk, high payoff research is very, very interesting.
[00:56:36.840 --> 00:56:42.960]   So yeah, I mean, I think a lot of the things our government even is- so one of the- what
[00:56:42.960 --> 00:56:47.840]   maybe think of this is the Janis program, facial recognition and real world conditions
[00:56:47.840 --> 00:56:51.160]   of off-pose, low quality, obstructed images.
[00:56:51.160 --> 00:56:57.160]   Oh, so what you're- you know, people are wearing the- we saw the videos-
[00:56:57.160 --> 00:57:00.160]   Those reflective sunglasses, yes.
[00:57:00.160 --> 00:57:05.040]   You could put that into the snap goggles or snap glasses.
[00:57:05.040 --> 00:57:08.840]   We actually- Colleen was going to make this for us in the studio because people would
[00:57:08.840 --> 00:57:12.760]   come into the studio and be on camera and they didn't want to.
[00:57:12.760 --> 00:57:16.560]   And so we were going to have hanging on the hooks, a little collar you could put on that
[00:57:16.560 --> 00:57:20.320]   had infrared lights, so they're invisible to humans, but they would blast the cameras
[00:57:20.320 --> 00:57:25.360]   and you would look like a glowing head floating in the studio.
[00:57:25.360 --> 00:57:26.360]   Nice.
[00:57:26.360 --> 00:57:28.320]   I know, I thought that was a great idea.
[00:57:28.320 --> 00:57:29.320]   That is.
[00:57:29.320 --> 00:57:30.320]   Why didn't you build it?
[00:57:30.320 --> 00:57:32.640]   Oh, she had other things to do, I guess.
[00:57:32.640 --> 00:57:38.000]   And now she's working- now she's working at Facebook where she is like one of the most
[00:57:38.000 --> 00:57:40.520]   important people over there in blue sky research.
[00:57:40.520 --> 00:57:41.520]   She's doing some amazing stuff.
[00:57:41.520 --> 00:57:43.960]   Hey, I didn't know when to go to Google.
[00:57:43.960 --> 00:57:44.960]   I do that.
[00:57:44.960 --> 00:57:47.840]   And she's been at Facebook for a couple of years.
[00:57:47.840 --> 00:57:54.000]   I am told that she's the woman who designed Facebook's 360 degree camera.
[00:57:54.000 --> 00:58:00.960]   She's an expert in video streaming, which I might say she learned from us here to it.
[00:58:00.960 --> 00:58:02.160]   And no, not at all.
[00:58:02.160 --> 00:58:04.880]   In fact, we benefited more from her.
[00:58:04.880 --> 00:58:12.360]   How about IARPA's OSI program, automated tools that provide early warning of societal instability
[00:58:12.360 --> 00:58:18.680]   and disease outbreaks more than a week earlier than traditional methods?
[00:58:18.680 --> 00:58:20.080]   So Twitter.
[00:58:20.080 --> 00:58:21.080]   Twitter.
[00:58:21.080 --> 00:58:28.520]   How about this, the ACE program, crowdsourcing to reduce the error of geopolitical forecasts
[00:58:28.520 --> 00:58:29.920]   by more than 50%.
[00:58:29.920 --> 00:58:33.120]   Turns out the wisdom of the crowds ain't so bad.
[00:58:33.120 --> 00:58:35.720]   Did you see DNA to face?
[00:58:35.720 --> 00:58:37.200]   What's that?
[00:58:37.200 --> 00:58:44.080]   They're seeking information on using genetic information to predict facial structure.
[00:58:44.080 --> 00:58:48.120]   So if you have someone's DNA, you could theoretically look like-
[00:58:48.120 --> 00:58:50.280]   Oh my God.
[00:58:50.280 --> 00:58:53.520]   It's a brave new world.
[00:58:53.520 --> 00:58:56.280]   I just saw some fascinating research here in the public.
[00:58:56.280 --> 00:59:06.160]   So I'm talking about the gene at Davis Institute about time on camera and time speaking men
[00:59:06.160 --> 00:59:07.160]   versus women.
[00:59:07.160 --> 00:59:08.160]   Oh dear.
[00:59:08.160 --> 00:59:09.160]   Major entertainment.
[00:59:09.160 --> 00:59:10.160]   Oh dear.
[00:59:10.160 --> 00:59:12.160]   And it's what exactly-
[00:59:12.160 --> 00:59:13.160]   Sorry Stacey.
[00:59:13.160 --> 00:59:16.320]   And Stacey will know well how often men interrupt.
[00:59:16.320 --> 00:59:19.440]   And I'm sorry Stacey, every time I do it, I apologize.
[00:59:19.440 --> 00:59:20.440]   Sorry Stacey.
[00:59:20.440 --> 00:59:21.440]   I'm sorry Stacey.
[00:59:21.440 --> 00:59:22.440]   I apologize.
[00:59:22.440 --> 00:59:23.440]   The interrupts me too.
[00:59:23.440 --> 00:59:24.440]   Well, that's for a different reason, Matthew.
[00:59:24.440 --> 00:59:25.440]   Sorry Stacey.
[00:59:25.440 --> 00:59:27.280]   It's entirely different.
[00:59:27.280 --> 00:59:33.600]   So anyway, but to watch the representation of the facial recognition go by, that had
[00:59:33.600 --> 00:59:38.680]   a scene from my big Greek wedding and the number of faces that had its figurative nail,
[00:59:38.680 --> 00:59:45.620]   which is female, for NLGBTQI, but it's fascinating to see what this stuff can do on the fly.
[00:59:45.620 --> 00:59:51.960]   I was actually thinking this morning that I wish that my Amazon Echo would listen to me
[00:59:51.960 --> 00:59:56.400]   and my wife talking and at the end of the day, say how many words she spoke and how
[00:59:56.400 --> 00:59:58.720]   many words I got an inch wise.
[00:59:58.720 --> 00:59:59.720]   You want to know.
[00:59:59.720 --> 01:00:01.880]   I think it's the opposite.
[01:00:01.880 --> 01:00:03.160]   You don't Leo, I'll bet it's-
[01:00:03.160 --> 01:00:05.840]   At home, it's the complete opposite.
[01:00:05.840 --> 01:00:08.840]   We men think that we, you know, nope.
[01:00:08.840 --> 01:00:09.840]   Yes dear.
[01:00:09.840 --> 01:00:10.840]   Right Stacey?
[01:00:10.840 --> 01:00:11.840]   Yeah, the stats are hilarious.
[01:00:11.840 --> 01:00:12.840]   The stats are hilarious.
[01:00:12.840 --> 01:00:13.840]   Like a mental word.
[01:00:13.840 --> 01:00:16.280]   I'm just going to let you all talk.
[01:00:16.280 --> 01:00:21.160]   The last time I said anything about women, I actually received some of the negative attention
[01:00:21.160 --> 01:00:22.160]   that Leo is so-
[01:00:22.160 --> 01:00:23.720]   Oh, welcome to the classic.
[01:00:23.720 --> 01:00:24.720]   I was told-
[01:00:24.720 --> 01:00:25.720]   What's my-
[01:00:25.720 --> 01:00:26.720]   Oh, you guys.
[01:00:26.720 --> 01:00:27.720]   I was told that I mansplained you on Sunday.
[01:00:27.720 --> 01:00:30.000]   Did I mansplain you at some point?
[01:00:30.000 --> 01:00:31.000]   It's possible.
[01:00:31.000 --> 01:00:32.000]   I get mansplained a lot.
[01:00:32.000 --> 01:00:33.000]   I'm sorry.
[01:00:33.000 --> 01:00:34.000]   I don't-
[01:00:34.000 --> 01:00:35.000]   I don't worry about it.
[01:00:35.000 --> 01:00:36.000]   I don't worry about it.
[01:00:36.000 --> 01:00:37.000]   I don't worry about it.
[01:00:37.000 --> 01:00:38.000]   I don't worry about it.
[01:00:38.000 --> 01:00:39.000]   If you explain something, you did.
[01:00:39.000 --> 01:00:40.000]   I'm a man and I explained it.
[01:00:40.000 --> 01:00:41.000]   Well, no.
[01:00:41.000 --> 01:00:42.760]   No, I'm just kidding.
[01:00:42.760 --> 01:00:44.400]   I try not to be condescending.
[01:00:44.400 --> 01:00:47.240]   I think mansplaining implies, you know, some patronizing.
[01:00:47.240 --> 01:00:48.800]   But the study I saw-
[01:00:48.800 --> 01:00:50.920]   Oh honey, you just don't understand.
[01:00:50.920 --> 01:00:51.920]   What makes playing it to you?
[01:00:51.920 --> 01:00:53.720]   Oh, I would've stopped you there.
[01:00:53.720 --> 01:00:54.960]   I think you would've.
[01:00:54.960 --> 01:00:55.960]   Yes.
[01:00:55.960 --> 01:01:02.080]   If a woman speaks more than I think it's 23%, men who are surveyed believe that she
[01:01:02.080 --> 01:01:03.080]   hogged the conversation.
[01:01:03.080 --> 01:01:04.080]   Oh, geez.
[01:01:04.080 --> 01:01:05.080]   That is so true.
[01:01:05.080 --> 01:01:06.080]   Yes.
[01:01:06.080 --> 01:01:08.920]   That's why I don't like sometimes I just shut up.
[01:01:08.920 --> 01:01:10.520]   I'm like, nope, not worth it.
[01:01:10.520 --> 01:01:11.520]   And that's it's self-sensoring.
[01:01:11.520 --> 01:01:13.520]   Don't do that here.
[01:01:13.520 --> 01:01:15.320]   Yeah, don't do that.
[01:01:15.320 --> 01:01:16.800]   Just interrupt.
[01:01:16.800 --> 01:01:19.120]   We want you to talk twice as much.
[01:01:19.120 --> 01:01:21.120]   I could never do it.
[01:01:21.120 --> 01:01:24.440]   One, you guys have actually have good things to say.
[01:01:24.440 --> 01:01:25.440]   So yay.
[01:01:25.440 --> 01:01:31.360]   And two, the more I talk, the more negative feedback I get.
[01:01:31.360 --> 01:01:33.480]   Not from us, but from the outside world.
[01:01:33.480 --> 01:01:36.960]   From the outside world who are like, oh, either you don't know that or you talk too
[01:01:36.960 --> 01:01:37.960]   much or-
[01:01:37.960 --> 01:01:41.560]   And the more likely I am to say something that people don't want to hear, which is,
[01:01:41.560 --> 01:01:43.280]   again, me self-sensoring.
[01:01:43.280 --> 01:01:44.280]   Yay.
[01:01:44.280 --> 01:01:46.760]   Wow, this went in a weird direction.
[01:01:46.760 --> 01:01:47.760]   Let's take it away from us.
[01:01:47.760 --> 01:01:48.760]   Ignore them.
[01:01:48.760 --> 01:01:49.760]   Just ignore them.
[01:01:49.760 --> 01:01:53.600]   Did you know that you can now tweet emoji at Google and get directions to tacos?
[01:01:53.600 --> 01:01:54.600]   I saw that.
[01:01:54.600 --> 01:01:56.320]   See, now we're talking real progress.
[01:01:56.320 --> 01:01:58.400]   I am so old.
[01:01:58.400 --> 01:02:01.600]   What I saw that story, I was like, dear God, I am old.
[01:02:01.600 --> 01:02:02.600]   Well, that's program.
[01:02:02.600 --> 01:02:07.160]   This is Devinda Harder writing and then gadget, which I hope you would explain this to me.
[01:02:07.160 --> 01:02:15.400]   So you go, you like tweet a taco emoji at Google and then Google will respond.
[01:02:15.400 --> 01:02:17.160]   I got to try this.
[01:02:17.160 --> 01:02:22.920]   That's the only way to understand 200 emojis.
[01:02:22.920 --> 01:02:23.920]   I don't, I don't.
[01:02:23.920 --> 01:02:24.920]   Oh, look at this.
[01:02:24.920 --> 01:02:25.920]   Oh, look at this.
[01:02:25.920 --> 01:02:31.680]   So Devinda tweeted a eggplant to Google, which is the first thing I would do.
[01:02:31.680 --> 01:02:32.680]   And it's-
[01:02:32.680 --> 01:02:33.680]   And the first thing?
[01:02:33.680 --> 01:02:34.680]   Yeah.
[01:02:34.680 --> 01:02:35.680]   Well, just to see what-
[01:02:35.680 --> 01:02:36.680]   Okay.
[01:02:36.680 --> 01:02:37.680]   All right.
[01:02:37.680 --> 01:02:40.840]   And well, with Devinda and I apparently think alike, Devinda, you were looking for Baba
[01:02:40.840 --> 01:02:42.160]   Ganush recipes, right?
[01:02:42.160 --> 01:02:43.160]   Here's a few.
[01:02:43.160 --> 01:02:44.160]   Wow.
[01:02:44.160 --> 01:02:45.160]   Yes.
[01:02:45.160 --> 01:02:46.160]   Wow.
[01:02:46.160 --> 01:02:50.480]   I think that is- That's what you should do, Stacey.
[01:02:50.480 --> 01:02:54.000]   I know there's a dumpling emoji thanks to-
[01:02:54.000 --> 01:02:55.680]   Yes, Jennifer Lee.
[01:02:55.680 --> 01:02:56.680]   Yeah.
[01:02:56.680 --> 01:02:58.400]   And Jennifer Lee.
[01:02:58.400 --> 01:02:59.400]   Okay.
[01:02:59.400 --> 01:03:02.240]   So then he's then Devinda got complicated.
[01:03:02.240 --> 01:03:07.200]   He's tweeted a poop emoji at it and Google said, "Need a breath of fresh air?"
[01:03:07.200 --> 01:03:09.200]   Well, that's fair.
[01:03:09.200 --> 01:03:10.200]   Well, yes.
[01:03:10.200 --> 01:03:11.200]   Taco.
[01:03:11.200 --> 01:03:17.880]   Isn't the eggplant emoji used for- Yes.
[01:03:17.880 --> 01:03:19.680]   To represent other things as well?
[01:03:19.680 --> 01:03:20.680]   Yes.
[01:03:20.680 --> 01:03:21.680]   Okay.
[01:03:21.680 --> 01:03:22.680]   Sorry.
[01:03:22.680 --> 01:03:23.680]   There we go.
[01:03:23.680 --> 01:03:26.480]   So this is where having guys on your development team, because I probably wouldn't have thought
[01:03:26.480 --> 01:03:28.920]   about that for at least like a while.
[01:03:28.920 --> 01:03:30.920]   So there you go.
[01:03:30.920 --> 01:03:35.080]   You see, you do need- See, you do need men on your team, don't you?
[01:03:35.080 --> 01:03:36.080]   Exactly.
[01:03:36.080 --> 01:03:37.080]   See, there you go.
[01:03:37.080 --> 01:03:39.160]   I wouldn't have gone there for a while.
[01:03:39.160 --> 01:03:41.360]   So I heard another great diversity story today.
[01:03:41.360 --> 01:03:42.360]   Yes.
[01:03:42.360 --> 01:03:43.360]   It's public.
[01:03:43.360 --> 01:03:47.600]   So when YouTube started, who's right?
[01:03:47.600 --> 01:03:49.040]   Is anybody here left-handed?
[01:03:49.040 --> 01:03:50.040]   Yes.
[01:03:50.040 --> 01:03:51.040]   Moi.
[01:03:51.040 --> 01:03:52.040]   Okay.
[01:03:52.040 --> 01:03:53.040]   So Matthew, you're right-handed.
[01:03:53.040 --> 01:03:54.040]   Stacey is right-handed.
[01:03:54.040 --> 01:03:55.040]   Yes.
[01:03:55.040 --> 01:03:56.040]   I'm right-handed.
[01:03:56.040 --> 01:04:00.320]   So Stacey, take your phone and show how you rotate your camera in your right hand to be
[01:04:00.320 --> 01:04:02.720]   able to watch horizontal video.
[01:04:02.720 --> 01:04:03.720]   Okay.
[01:04:03.720 --> 01:04:04.720]   I go, okay.
[01:04:04.720 --> 01:04:05.720]   Yeah.
[01:04:05.720 --> 01:04:07.280]   I won't poison them well yet.
[01:04:07.280 --> 01:04:08.280]   Yeah.
[01:04:08.280 --> 01:04:09.280]   All right.
[01:04:09.280 --> 01:04:11.680]   I'm horizontal video.
[01:04:11.680 --> 01:04:14.920]   So you do it your right hand?
[01:04:14.920 --> 01:04:16.240]   She doesn't count her.
[01:04:16.240 --> 01:04:17.720]   She doesn't count her clockwise as do I.
[01:04:17.720 --> 01:04:19.000]   Now, do you know how do you do?
[01:04:19.000 --> 01:04:20.000]   Count her to use a clockwise.
[01:04:20.000 --> 01:04:21.000]   I go like this.
[01:04:21.000 --> 01:04:22.000]   You do?
[01:04:22.000 --> 01:04:24.480]   Oh, see, they found that left-handed people did it this way.
[01:04:24.480 --> 01:04:25.680]   Oh, you know what?
[01:04:25.680 --> 01:04:31.000]   This is more disinformation about our sinister friends.
[01:04:31.000 --> 01:04:32.000]   Fake news.
[01:04:32.000 --> 01:04:33.000]   Fake news.
[01:04:33.000 --> 01:04:34.000]   Fake.
[01:04:34.000 --> 01:04:35.000]   No, it's funny.
[01:04:35.000 --> 01:04:38.200]   So they found that they had users who were looking at the video with coming in upside
[01:04:38.200 --> 01:04:40.880]   down and they didn't know why because the whole team was right handed.
[01:04:40.880 --> 01:04:41.880]   Nobody thought.
[01:04:41.880 --> 01:04:42.880]   Okay.
[01:04:42.880 --> 01:04:44.880]   Oh, wow.
[01:04:44.880 --> 01:04:49.480]   I am influenced by where the white where the home button would be.
[01:04:49.480 --> 01:04:50.480]   Me too.
[01:04:50.480 --> 01:04:52.520]   So I always try to get that to the right.
[01:04:52.520 --> 01:04:53.520]   Apple.
[01:04:53.520 --> 01:04:54.520]   Me too.
[01:04:54.520 --> 01:04:55.520]   Having been trained by Apple.
[01:04:55.520 --> 01:04:56.520]   Oh, that's okay.
[01:04:56.520 --> 01:04:57.520]   That's, that's, yeah, that's right.
[01:04:57.520 --> 01:04:59.520]   So that is interesting though.
[01:04:59.520 --> 01:05:00.520]   It is.
[01:05:00.520 --> 01:05:01.520]   It is.
[01:05:01.520 --> 01:05:02.520]   It is.
[01:05:02.520 --> 01:05:03.520]   It is.
[01:05:03.520 --> 01:05:04.520]   It is.
[01:05:04.520 --> 01:05:06.360]   Right-handed and left-handed and people with no hands.
[01:05:06.360 --> 01:05:09.440]   Yeah, it just, well, yeah, but it just shows you, you know, we have to kind of think outside
[01:05:09.440 --> 01:05:12.120]   the box and this is a big problem in Silicon Valley.
[01:05:12.120 --> 01:05:13.120]   It's very much a bubble.
[01:05:13.120 --> 01:05:14.120]   Huge problem.
[01:05:14.120 --> 01:05:15.120]   Yeah.
[01:05:15.120 --> 01:05:16.120]   Huge.
[01:05:16.120 --> 01:05:18.600]   And as a white male, I feel I'm underrepresented.
[01:05:18.600 --> 01:05:22.840]   Well, wasn't it Snapchat?
[01:05:22.840 --> 01:05:25.440]   They did filters and they came up with these.
[01:05:25.440 --> 01:05:26.440]   Oh, yeah.
[01:05:26.440 --> 01:05:27.440]   The racist filters.
[01:05:27.440 --> 01:05:28.440]   Yeah.
[01:05:28.440 --> 01:05:33.560]   Filters and how could that have gotten all the way through meetings and approvals?
[01:05:33.560 --> 01:05:35.640]   Presumably they do those things.
[01:05:35.640 --> 01:05:40.280]   No one said, wait a second.
[01:05:40.280 --> 01:05:43.600]   Stacy, you have the Eero.
[01:05:43.600 --> 01:05:45.600]   Have you told me?
[01:05:45.600 --> 01:05:47.320]   Right now I have something else.
[01:05:47.320 --> 01:05:49.800]   Well, that's what I was going to ask you.
[01:05:49.800 --> 01:05:50.800]   Oh, you got the loom?
[01:05:50.800 --> 01:05:53.280]   Those are the plumes.
[01:05:53.280 --> 01:05:54.800]   These are the plumes.
[01:05:54.800 --> 01:05:57.800]   This is a non FCC approved one, so I can't sell it.
[01:05:57.800 --> 01:05:59.800]   Is it power liner?
[01:05:59.800 --> 01:06:00.800]   No.
[01:06:00.800 --> 01:06:01.800]   No.
[01:06:01.800 --> 01:06:02.800]   Okay.
[01:06:02.800 --> 01:06:03.960]   So the cool thing here, or Leo, do you want to do it?
[01:06:03.960 --> 01:06:04.960]   No, you, you're the plumber.
[01:06:04.960 --> 01:06:05.960]   So the cool thing is--
[01:06:05.960 --> 01:06:06.960]   So the cool thing--
[01:06:06.960 --> 01:06:09.880]   Now I'm going to just shut up from now on and let Stacy talk.
[01:06:09.880 --> 01:06:12.640]   No, this is your show, man.
[01:06:12.640 --> 01:06:14.120]   I'm a newcomer.
[01:06:14.120 --> 01:06:16.040]   So this is a Wi-Fi router.
[01:06:16.040 --> 01:06:17.920]   Comes in pack of six.
[01:06:17.920 --> 01:06:24.000]   And what's cool about this is most Wi-Fi routers do their brains are in the box along
[01:06:24.000 --> 01:06:28.240]   the brains that handle the routing, and then also the radios.
[01:06:28.240 --> 01:06:34.720]   Plume has the brains in the cloud and only the radios in these things.
[01:06:34.720 --> 01:06:39.120]   So right here, you plug this bottom port into your modem.
[01:06:39.120 --> 01:06:41.200]   Only one has to be plugged in.
[01:06:41.200 --> 01:06:42.200]   Only one.
[01:06:42.200 --> 01:06:43.920]   And then you plug it into an outlet.
[01:06:43.920 --> 01:06:47.440]   And then the rest of these, you just shove in to outlets around your house.
[01:06:47.440 --> 01:06:50.160]   But you're supposed to have one in every single room you'd want Wi-Fi?
[01:06:50.160 --> 01:06:51.160]   Yes.
[01:06:51.160 --> 01:06:53.280]   But a six pack is, what, $330?
[01:06:53.280 --> 01:06:55.400]   Yeah, they're $75 each.
[01:06:55.400 --> 01:06:58.280]   No, it's not expensive.
[01:06:58.280 --> 01:06:59.600]   It's kind of expensive.
[01:06:59.600 --> 01:07:05.120]   So I've got seven in my house, and it's a 2,500 square foot house.
[01:07:05.120 --> 01:07:09.800]   And the cool thing is, because the brains are in the cloud, it learns.
[01:07:09.800 --> 01:07:14.400]   So I was going to actually tell you about how they work, but mine hasn't been installed
[01:07:14.400 --> 01:07:17.960]   long enough to actually start performance testing it.
[01:07:17.960 --> 01:07:25.640]   What it does is it's gathering data on the types of devices I have, where things are
[01:07:25.640 --> 01:07:28.320]   being used and how things move around my household.
[01:07:28.320 --> 01:07:33.240]   And it's going to start to optimize for that, which is really cool, I think.
[01:07:33.240 --> 01:07:34.240]   That is cool.
[01:07:34.240 --> 01:07:38.000]   I've ordered, I've been using the ERO with great result.
[01:07:38.000 --> 01:07:40.480]   I ordered the Google, and that's supposed to come pretty soon.
[01:07:40.480 --> 01:07:47.800]   We're going to do a review of the Orbe, which is Netgear's Google ERO, and maybe Plume
[01:07:47.800 --> 01:07:52.800]   2 with Dave Hamilton on Saturday on the new screen savers.
[01:07:52.800 --> 01:07:56.560]   I feel like the Plume is the most interesting.
[01:07:56.560 --> 01:08:01.520]   All of them, by the way, claim they're sending information back to the Home Office for analysis,
[01:08:01.520 --> 01:08:02.520]   right?
[01:08:02.520 --> 01:08:03.520]   Well, they all do.
[01:08:03.520 --> 01:08:08.360]   So ERO just boosted some of their features based on some of the analysis they had done.
[01:08:08.360 --> 01:08:11.920]   But this is interesting because it's supposed to be real time.
[01:08:11.920 --> 01:08:20.440]   And one of the issues with ERO's and traditional mesh networks is that as you do hops, you're
[01:08:20.440 --> 01:08:29.560]   decreasing your throughput, and so as you're hopping from hub to hub, so mesh to mesh,
[01:08:29.560 --> 01:08:31.520]   unless you've got it plugged into a LAN.
[01:08:31.520 --> 01:08:36.680]   So with Plume though, they say that you don't have those because they will move from different
[01:08:36.680 --> 01:08:37.680]   channels.
[01:08:37.680 --> 01:08:39.080]   And this is really techy.
[01:08:39.080 --> 01:08:40.080]   So I'm sorry.
[01:08:40.080 --> 01:08:43.160]   Get techy, please.
[01:08:43.160 --> 01:08:45.280]   So we'll see how it works.
[01:08:45.280 --> 01:08:48.880]   I mean, I'm going to start doing performance testing, and I can report back next week,
[01:08:48.880 --> 01:08:50.200]   but you have a show on it too.
[01:08:50.200 --> 01:08:51.960]   No, I want to get you.
[01:08:51.960 --> 01:08:54.640]   I'm very interested.
[01:08:54.640 --> 01:09:00.720]   By the way, ERO also says we're better than just Wi-Fi extenders because as you get,
[01:09:00.720 --> 01:09:05.520]   you know, those do attenuate the signal as you go down the line.
[01:09:05.520 --> 01:09:08.520]   And so ERO also makes similar claims.
[01:09:08.520 --> 01:09:11.000]   I have to say I've used them.
[01:09:11.000 --> 01:09:12.000]   I'm sorry.
[01:09:12.000 --> 01:09:16.600]   Oh, I was just going to say now that I talked to the CEO of Plume about ERO and I've talked
[01:09:16.600 --> 01:09:22.200]   to ERO about Plume and they both make kind of contradictory claims about each other
[01:09:22.200 --> 01:09:23.200]   for what it's worth.
[01:09:23.200 --> 01:09:25.160]   Well, they're in deep competition with one another.
[01:09:25.160 --> 01:09:26.160]   Yes, they are.
[01:09:26.160 --> 01:09:27.480]   Okay, Matthew, sorry.
[01:09:27.480 --> 01:09:28.480]   I tried.
[01:09:28.480 --> 01:09:33.560]   I'd spend a bunch of money for a range extender for my house and I don't know if I'm doing
[01:09:33.560 --> 01:09:41.280]   something wrong, but my devices, like particularly iPhones and iPads seem to have a problem.
[01:09:41.280 --> 01:09:43.160]   They drop the network.
[01:09:43.160 --> 01:09:44.160]   They drop.
[01:09:44.160 --> 01:09:46.160]   They can't reconnect automatically.
[01:09:46.160 --> 01:09:48.960]   If you move around or you stay still.
[01:09:48.960 --> 01:09:52.200]   Was that as you move around or as you stay still?
[01:09:52.200 --> 01:09:53.920]   No, just staying still.
[01:09:53.920 --> 01:10:01.920]   And this extender, you know, I tried renaming the networks, the extended versions.
[01:10:01.920 --> 01:10:04.320]   I tried using the same name.
[01:10:04.320 --> 01:10:10.880]   I don't know if it's a problem with this extender or if it's a problem with Apple, Wi-Fi.
[01:10:10.880 --> 01:10:15.600]   So I know that iPhones are sticky.
[01:10:15.600 --> 01:10:17.680]   They're from a Wi-Fi perspective.
[01:10:17.680 --> 01:10:23.000]   So they tend to pop onto one network in one access point and try to stay there as long
[01:10:23.000 --> 01:10:24.280]   as possible.
[01:10:24.280 --> 01:10:26.520]   So a lot of times if you're moving, that can be an issue.
[01:10:26.520 --> 01:10:32.040]   But if it's popped onto one and it's not the closest one, then you might still be getting
[01:10:32.040 --> 01:10:33.800]   issues, if that makes sense.
[01:10:33.800 --> 01:10:34.800]   Yeah.
[01:10:34.800 --> 01:10:35.800]   It's weird.
[01:10:35.800 --> 01:10:39.360]   Do you count bathrooms as rooms?
[01:10:39.360 --> 01:10:40.880]   No, no, you can still.
[01:10:40.880 --> 01:10:43.000]   But don't you want to use the...
[01:10:43.000 --> 01:10:45.200]   Well, not the mail.
[01:10:45.200 --> 01:10:46.200]   So actually, I have to...
[01:10:46.200 --> 01:10:48.880]   I'm trying to figure out how many plumes I need.
[01:10:48.880 --> 01:10:51.080]   I think I have like nine or ten.
[01:10:51.080 --> 01:10:52.600]   Yeah, three years.
[01:10:52.600 --> 01:10:53.600]   So I've got...
[01:10:53.600 --> 01:10:54.600]   Okay.
[01:10:54.600 --> 01:10:59.920]   I've got my house, which is a garage, the first floor, which is an open floor plan that's
[01:10:59.920 --> 01:11:03.160]   really big, and then the second floor, and then a rooftop deck.
[01:11:03.160 --> 01:11:06.640]   And I have Wi-Fi requirements for all of my floors.
[01:11:06.640 --> 01:11:14.200]   So because Wi-Fi signals travel down easily compared to up, I worked with one on.
[01:11:14.200 --> 01:11:15.040]   Yeah.
[01:11:15.040 --> 01:11:16.640]   So you should always put them high.
[01:11:16.640 --> 01:11:17.640]   Yeah.
[01:11:17.640 --> 01:11:18.640]   Oh.
[01:11:18.640 --> 01:11:19.640]   They're like heat.
[01:11:19.640 --> 01:11:20.640]   I don't know why that is.
[01:11:20.640 --> 01:11:21.640]   I had no idea.
[01:11:21.640 --> 01:11:23.880]   Stacy, that is the factoid of the deck.
[01:11:23.880 --> 01:11:27.000]   I was just asking this question this morning because I had about two more euros.
[01:11:27.000 --> 01:11:30.600]   I have five now, and I put it on the low shelf of the bookshelf and I thought, "You know,
[01:11:30.600 --> 01:11:32.320]   I better be better on the high shelf."
[01:11:32.320 --> 01:11:33.960]   Just intuitively because...
[01:11:33.960 --> 01:11:35.960]   Because you're there.
[01:11:35.960 --> 01:11:36.960]   So I was there.
[01:11:36.960 --> 01:11:39.200]   I didn't know that.
[01:11:39.200 --> 01:11:40.200]   Okay.
[01:11:40.200 --> 01:11:43.200]   Oh, I promised I wouldn't make big gestures because my sink...
[01:11:43.200 --> 01:11:44.200]   Heat rises.
[01:11:44.200 --> 01:11:45.200]   You've got to stop reading the Twitter.
[01:11:45.200 --> 01:11:46.520]   Now you know why I don't like the Twitter.
[01:11:46.520 --> 01:11:49.200]   You're reading too much of the Twitter and people giving you bad ideas.
[01:11:49.200 --> 01:11:50.200]   It's like if you're getting a...
[01:11:50.200 --> 01:11:52.040]   I'm sorry, I turn it on doctor for a moment.
[01:11:52.040 --> 01:11:53.040]   It's like...
[01:11:53.040 --> 01:11:54.040]   What just happened?
[01:11:54.040 --> 01:11:56.680]   No, I just saw myself on the screen.
[01:11:56.680 --> 01:12:00.240]   I went back to the screen and I'm like, "Oh, I'm so far behind how I'm talking."
[01:12:00.240 --> 01:12:01.240]   No.
[01:12:01.240 --> 01:12:02.240]   Do not take feedback.
[01:12:02.240 --> 01:12:03.240]   Just be your...
[01:12:03.240 --> 01:12:04.640]   I don't accept your feedback.
[01:12:04.640 --> 01:12:05.480]   Be yourself.
[01:12:05.480 --> 01:12:08.360]   So up there, let's see.
[01:12:08.360 --> 01:12:10.160]   So there's one on the roof.
[01:12:10.160 --> 01:12:13.600]   I put one in my study because there's all this gear.
[01:12:13.600 --> 01:12:14.600]   Wait, wait, wait, wait.
[01:12:14.600 --> 01:12:15.600]   Put one on the roof?
[01:12:15.600 --> 01:12:19.440]   Yes, I have a cabinet in the roof where I have a router in...
[01:12:19.440 --> 01:12:21.400]   Because I've got Sonos on the roof plus I've got...
[01:12:21.400 --> 01:12:22.400]   Is there anything...
[01:12:22.400 --> 01:12:25.920]   I mean, is there a room up there or just on the roof?
[01:12:25.920 --> 01:12:26.920]   It's a rooftop deck.
[01:12:26.920 --> 01:12:27.920]   Oh, it's a deck.
[01:12:27.920 --> 01:12:28.920]   Oh, it's a deck.
[01:12:28.920 --> 01:12:29.920]   Okay.
[01:12:29.920 --> 01:12:30.920]   I'm sorry.
[01:12:30.920 --> 01:12:31.920]   I've got a little putt putt grid up there.
[01:12:31.920 --> 01:12:32.920]   What?
[01:12:32.920 --> 01:12:33.920]   Oh, wow.
[01:12:33.920 --> 01:12:34.920]   What?
[01:12:34.920 --> 01:12:35.920]   Yeah, it's nice.
[01:12:35.920 --> 01:12:38.880]   You have a putting green on your roof.
[01:12:38.880 --> 01:12:41.000]   Is there a Tiki bar?
[01:12:41.000 --> 01:12:43.800]   There is not a Tiki bar.
[01:12:43.800 --> 01:12:44.800]   What is the view?
[01:12:44.800 --> 01:12:46.640]   Do you see Lake Austin from where you sit?
[01:12:46.640 --> 01:12:50.760]   I see the bridge over at the 360 bridge in the lake.
[01:12:50.760 --> 01:12:51.760]   It's nice.
[01:12:51.760 --> 01:12:53.600]   And you have a drone launching pad?
[01:12:53.600 --> 01:12:55.600]   I could.
[01:12:55.600 --> 01:13:01.480]   Still, though, even though from there I don't get great...
[01:13:01.480 --> 01:13:02.960]   What's it called?
[01:13:02.960 --> 01:13:03.960]   Digital TV signals.
[01:13:03.960 --> 01:13:04.960]   Figure.
[01:13:04.960 --> 01:13:08.640]   Do you need a plump for your guest room?
[01:13:08.640 --> 01:13:10.440]   So I put one in my guest room.
[01:13:10.440 --> 01:13:12.800]   You know, as I test, I'm going to see how that works.
[01:13:12.800 --> 01:13:18.040]   I definitely need one in my garage, though, even though the Wi-Fi signal travels down
[01:13:18.040 --> 01:13:19.480]   because the Tesla needs it.
[01:13:19.480 --> 01:13:21.440]   I've got the MyQ garage door opener.
[01:13:21.440 --> 01:13:22.440]   And then I have a...
[01:13:22.440 --> 01:13:24.440]   I need like 12.
[01:13:24.440 --> 01:13:25.440]   Yeah.
[01:13:25.440 --> 01:13:27.800]   So I've got seven.
[01:13:27.800 --> 01:13:31.560]   And so far we haven't encountered much drama.
[01:13:31.560 --> 01:13:38.160]   Although when I created the network, I gave it the wrong SSID.
[01:13:38.160 --> 01:13:39.160]   I did.
[01:13:39.160 --> 01:13:40.160]   Anyway.
[01:13:40.160 --> 01:13:44.640]   And then I realized like everything failed.
[01:13:44.640 --> 01:13:50.560]   So I had a hard time getting my Sonos and my Philips Hue lights back online for a little
[01:13:50.560 --> 01:13:52.560]   bit after I switched networks.
[01:13:52.560 --> 01:13:55.960]   Do you change SSIDs or because what they're using?
[01:13:55.960 --> 01:13:57.360]   I changed it back.
[01:13:57.360 --> 01:14:01.640]   It was very easy to change the SSID back because obviously if your SSID is wrong from all of
[01:14:01.640 --> 01:14:06.600]   your connected devices, none of them are going to hop on.
[01:14:06.600 --> 01:14:10.520]   But once I changed it back, I think...
[01:14:10.520 --> 01:14:11.520]   Is it DCHP?
[01:14:11.520 --> 01:14:12.520]   I can't...
[01:14:12.520 --> 01:14:13.520]   AHCP.
[01:14:13.520 --> 01:14:14.520]   Yeah.
[01:14:14.520 --> 01:14:15.520]   DHCP.
[01:14:15.520 --> 01:14:18.960]   I think all of those leases had to reset and they hadn't yet.
[01:14:18.960 --> 01:14:21.200]   So I had to reboot just about everything.
[01:14:21.200 --> 01:14:22.200]   That's kind of normal.
[01:14:22.200 --> 01:14:23.200]   Yeah.
[01:14:23.200 --> 01:14:24.200]   Half of my devices.
[01:14:24.200 --> 01:14:27.200]   So I'm going to get 12 of them.
[01:14:27.200 --> 01:14:28.920]   Jesus, I would start less.
[01:14:28.920 --> 01:14:29.920]   Or just...
[01:14:29.920 --> 01:14:34.000]   Well, actually, what I should really do is wait till I hear from you.
[01:14:34.000 --> 01:14:37.920]   So you're using even though it hasn't done the intelligence thing yet.
[01:14:37.920 --> 01:14:38.920]   Is it working okay?
[01:14:38.920 --> 01:14:41.040]   Yeah, it's working fine.
[01:14:41.040 --> 01:14:42.400]   Like for example, don't hate me.
[01:14:42.400 --> 01:14:43.400]   I'm actually...
[01:14:43.400 --> 01:14:48.400]   This is actually maybe why I'm late and I just realized I'm on the Wi-Fi and not my...
[01:14:48.400 --> 01:14:50.200]   That's exactly why you're late.
[01:14:50.200 --> 01:14:52.200]   I'm sorry.
[01:14:52.200 --> 01:14:54.200]   It's because I am...
[01:14:54.200 --> 01:14:58.600]   By the way, this is the one person in this group that doesn't need any of this because
[01:14:58.600 --> 01:15:01.800]   she's got ethernet in every room of her house.
[01:15:01.800 --> 01:15:02.800]   Mm-hmm.
[01:15:02.800 --> 01:15:03.800]   Yes.
[01:15:03.800 --> 01:15:09.960]   But this is actually a great test because this one, I guess I could plug it into my land
[01:15:09.960 --> 01:15:11.080]   in all my rooms.
[01:15:11.080 --> 01:15:18.320]   But this is one of the first times I'm going to be working without having the land backup.
[01:15:18.320 --> 01:15:19.320]   So it should be fun.
[01:15:19.320 --> 01:15:21.320]   I'll see what everyone else's Wi-Fi is like.
[01:15:21.320 --> 01:15:22.520]   I'm going to wait and see.
[01:15:22.520 --> 01:15:23.680]   So you have the hero.
[01:15:23.680 --> 01:15:25.760]   Have you tried any of the others of these?
[01:15:25.760 --> 01:15:28.680]   I have the almond three, which is a mesh.
[01:15:28.680 --> 01:15:30.320]   It's not a great mesh so far.
[01:15:30.320 --> 01:15:32.480]   But yes, I have that.
[01:15:32.480 --> 01:15:34.800]   I could try the Orbeez if you want me to try the Orbeez.
[01:15:34.800 --> 01:15:36.800]   Well, I know why I can't use the loom.
[01:15:36.800 --> 01:15:37.800]   A plume.
[01:15:37.800 --> 01:15:38.800]   Why?
[01:15:38.800 --> 01:15:45.080]   Because I need to also connect to a switch for hardwired ethernet.
[01:15:45.080 --> 01:15:50.400]   So I have a switch for hardwired ethernet in...
[01:15:50.400 --> 01:15:51.560]   I have three switches.
[01:15:51.560 --> 01:15:53.000]   I have...
[01:15:53.000 --> 01:15:55.360]   So the one up here...
[01:15:55.360 --> 01:15:56.760]   Let's see if I can print something actually.
[01:15:56.760 --> 01:15:59.840]   Because each of those plumes has one ethernet jack.
[01:15:59.840 --> 01:16:01.360]   Yes.
[01:16:01.360 --> 01:16:07.240]   So what I need is one with the hero or the Google that has at least two ethernet jacks
[01:16:07.240 --> 01:16:13.520]   so that I can connect to my router modem and then to a switch to a big ethernet switch
[01:16:13.520 --> 01:16:17.520]   so I can get other hardwired ethernet in there.
[01:16:17.520 --> 01:16:18.520]   I've read...
[01:16:18.520 --> 01:16:21.040]   How do you do that?
[01:16:21.040 --> 01:16:25.080]   Well, that's a good question.
[01:16:25.080 --> 01:16:28.080]   Everything's working, so how did I do it?
[01:16:28.080 --> 01:16:33.720]   I guess you could go to another plume and plug into that but that's going to be Wi-Fi.
[01:16:33.720 --> 01:16:34.880]   I don't want any Wi-Fi.
[01:16:34.880 --> 01:16:35.880]   See, this is...
[01:16:35.880 --> 01:16:42.000]   So all the 4K stuff I want to have hardwired right into the wall for best...
[01:16:42.000 --> 01:16:49.400]   Oh, so it must be going through my actual modem instead of my router?
[01:16:49.400 --> 01:16:52.600]   You may have a modem that has multiple ethernet jacks in which case you're...
[01:16:52.600 --> 01:16:53.600]   I do.
[01:16:53.600 --> 01:16:54.600]   I have a modem with multiple ethernet.
[01:16:54.600 --> 01:16:55.600]   That's what it is.
[01:16:55.600 --> 01:16:56.600]   Okay, so that's where it's...
[01:16:56.600 --> 01:16:57.600]   Wait a second.
[01:16:57.600 --> 01:16:58.600]   I have my hub...
[01:16:58.600 --> 01:17:00.000]   In which case, you probably...
[01:17:00.000 --> 01:17:03.040]   That means your modem is probably doing routing, which is in case you want to make the plumes
[01:17:03.040 --> 01:17:04.040]   bridge.
[01:17:04.040 --> 01:17:05.040]   Can you do that?
[01:17:05.040 --> 01:17:06.040]   You can't.
[01:17:06.040 --> 01:17:07.040]   That is an option.
[01:17:07.040 --> 01:17:08.880]   Otherwise, you'll have double net.
[01:17:08.880 --> 01:17:09.880]   You don't want double net.
[01:17:09.880 --> 01:17:10.880]   Yeah, I don't have that.
[01:17:10.880 --> 01:17:11.880]   Bad.
[01:17:11.880 --> 01:17:12.880]   No, double net.
[01:17:12.880 --> 01:17:13.880]   Double net.
[01:17:13.880 --> 01:17:14.880]   Double net.
[01:17:14.880 --> 01:17:15.880]   No, no, no.
[01:17:15.880 --> 01:17:16.880]   Done.
[01:17:16.880 --> 01:17:17.880]   Okay.
[01:17:17.880 --> 01:17:21.480]   It's amazing how we've all had to become network nerds.
[01:17:21.480 --> 01:17:22.480]   Yes.
[01:17:22.480 --> 01:17:23.480]   It's sad.
[01:17:23.480 --> 01:17:31.880]   It ended amazing that it's probably 15 years since we had ubiquitous connectivity and Wi-Fi
[01:17:31.880 --> 01:17:33.080]   and whatnot.
[01:17:33.080 --> 01:17:37.320]   We still have problems where you talk to a network guy and you're like, "Well, then
[01:17:37.320 --> 01:17:38.320]   this happened.
[01:17:38.320 --> 01:17:39.320]   Why do you think that happened?"
[01:17:39.320 --> 01:17:40.320]   I don't know.
[01:17:40.320 --> 01:17:41.320]   Oh, all the time.
[01:17:41.320 --> 01:17:42.320]   Yeah.
[01:17:42.320 --> 01:17:43.320]   All the time.
[01:17:43.320 --> 01:17:44.320]   Like, it's...
[01:17:44.320 --> 01:17:45.320]   I didn't...
[01:17:45.320 --> 01:17:49.600]   In fact, this was kind of an eye-opener when I realized how much trial and error is involved
[01:17:49.600 --> 01:17:50.600]   in this stuff.
[01:17:50.600 --> 01:17:51.600]   Well, let's see what happens.
[01:17:51.600 --> 01:17:52.600]   It's huge.
[01:17:52.600 --> 01:17:59.000]   I went on a support forum and there were a bunch of network engineers like IT guys.
[01:17:59.000 --> 01:18:00.000]   This is their job.
[01:18:00.000 --> 01:18:01.000]   They're guessing.
[01:18:01.000 --> 01:18:03.720]   The one guy said, "I tried everything.
[01:18:03.720 --> 01:18:09.720]   I still can't figure it out."
[01:18:09.720 --> 01:18:12.120]   That's because it's hardware and wires.
[01:18:12.120 --> 01:18:15.160]   I mean, it's interference in radios.
[01:18:15.160 --> 01:18:18.000]   It's because networking is very complicated is really why.
[01:18:18.000 --> 01:18:19.000]   It is.
[01:18:19.000 --> 01:18:21.960]   Well, I think we're making progress and I think the plume is good.
[01:18:21.960 --> 01:18:23.640]   Okay, I decided not to pull the trigger.
[01:18:23.640 --> 01:18:26.400]   I'm going to wait until you're review, okay?
[01:18:26.400 --> 01:18:28.200]   Wait until yes, I'll figure out my actual network.
[01:18:28.200 --> 01:18:30.160]   I'm very happy with the Iro.
[01:18:30.160 --> 01:18:31.160]   Are you really...
[01:18:31.160 --> 01:18:35.280]   I haven't had the very detailed review.
[01:18:35.280 --> 01:18:36.280]   The verge...
[01:18:36.280 --> 01:18:37.280]   A lot of...
[01:18:37.280 --> 01:18:38.440]   The verge, I think.
[01:18:38.440 --> 01:18:44.760]   And the verge, by the way, which was reviewing the Google Wi-Fi.
[01:18:44.760 --> 01:18:47.520]   And by the way, Dan Seifert, Seifert, who did it, is very good.
[01:18:47.520 --> 01:18:51.320]   I mean, I trust Dan implicitly.
[01:18:51.320 --> 01:18:53.640]   He had a different result than...
[01:18:53.640 --> 01:18:58.840]   Remember Google's announced that in their independent survey that the Google device
[01:18:58.840 --> 01:19:03.840]   had the best throughput, Dan's result was not the same.
[01:19:03.840 --> 01:19:08.040]   He said, "Actually, the fastest device that he tried was the Orbe of all things, the
[01:19:08.040 --> 01:19:09.040]   neck gear."
[01:19:09.040 --> 01:19:10.040]   You did.
[01:19:10.040 --> 01:19:14.440]   The wire cutter actually named the Orbe the best mesh networking router, too.
[01:19:14.440 --> 01:19:15.440]   Interesting.
[01:19:15.440 --> 01:19:16.440]   Believe it or not.
[01:19:16.440 --> 01:19:17.440]   So...
[01:19:17.440 --> 01:19:18.440]   Here's the graph.
[01:19:18.440 --> 01:19:21.960]   The light red is downloaded.
[01:19:21.960 --> 01:19:25.720]   The dark red is uploaded and the brown is pink.
[01:19:25.720 --> 01:19:29.480]   And all of the graphs, the leftmost bar, is the Google Wi-Fi.
[01:19:29.480 --> 01:19:32.360]   The middle one is the Iro and the right one is the Orbe.
[01:19:32.360 --> 01:19:35.960]   So when you were nearby, you're all in the same room and they're all roughly equal.
[01:19:35.960 --> 01:19:41.060]   But as you get farther away, the Orbe really starts to outpace in speed and downloads
[01:19:41.060 --> 01:19:43.120]   be both the Iro and Google Wi-Fi.
[01:19:43.120 --> 01:19:49.200]   And in his test, the Iro and Google Wi-Fi were pretty darn close.
[01:19:49.200 --> 01:19:51.880]   There was only one test with the Wi-Fi was significantly faster.
[01:19:51.880 --> 01:19:52.880]   But the Orbe...
[01:19:52.880 --> 01:19:54.680]   The Orbe is Orbe so much better.
[01:19:54.680 --> 01:19:58.280]   It could be that neck gear has been doing Wi-Fi for freaking ever and they finally just
[01:19:58.280 --> 01:20:02.480]   decided to get on this bandwagon and when they did, boom.
[01:20:02.480 --> 01:20:05.240]   They did a good job.
[01:20:05.240 --> 01:20:07.080]   So anyway...
[01:20:07.080 --> 01:20:10.280]   Yeah.
[01:20:10.280 --> 01:20:12.440]   Yeah.
[01:20:12.440 --> 01:20:18.600]   Plume seems like it could be the best potentially because you've got a radio in every room.
[01:20:18.600 --> 01:20:20.840]   And if it actually learns, that would be...
[01:20:20.840 --> 01:20:21.840]   It does.
[01:20:21.840 --> 01:20:22.840]   Yeah.
[01:20:22.840 --> 01:20:23.840]   So we'll see.
[01:20:23.840 --> 01:20:24.840]   Next week, you guys.
[01:20:24.840 --> 01:20:25.840]   Next week.
[01:20:25.840 --> 01:20:26.840]   Okay.
[01:20:26.840 --> 01:20:27.840]   My bad for not...
[01:20:27.840 --> 01:20:28.840]   When I set it up, I was like, "Oh, cool."
[01:20:28.840 --> 01:20:31.200]   And then I'm like, "Oh, I'm not going to be in time."
[01:20:31.200 --> 01:20:32.200]   I still...
[01:20:32.200 --> 01:20:36.280]   And the plume looks like it's less expensive to you realize how many you need.
[01:20:36.280 --> 01:20:39.280]   It's only 75 bytes per unit, but then you need a whole lot of...
[01:20:39.280 --> 01:20:41.600]   So it'll require an outlet.
[01:20:41.600 --> 01:20:43.560]   So think about that.
[01:20:43.560 --> 01:20:44.560]   If you don't have...
[01:20:44.560 --> 01:20:47.960]   I have tons of spare outlets running around because we went crazy when we designed our
[01:20:47.960 --> 01:20:48.960]   house.
[01:20:48.960 --> 01:20:49.960]   That's your deal.
[01:20:49.960 --> 01:20:50.960]   That's your deal.
[01:20:50.960 --> 01:21:01.040]   I'm like, the wall where I knew I was putting my desk has three plus ethernet on both sides.
[01:21:01.040 --> 01:21:06.640]   So yes, most people probably did not have that luxury and they may want to think about
[01:21:06.640 --> 01:21:09.120]   the fact that they're going to have to use an outlet.
[01:21:09.120 --> 01:21:13.160]   There's just days of trying to do the extender through the electrical system.
[01:21:13.160 --> 01:21:14.160]   Those were the worst.
[01:21:14.160 --> 01:21:15.160]   I tried that.
[01:21:15.160 --> 01:21:16.160]   Actually, they got better.
[01:21:16.160 --> 01:21:19.000]   Powerline is better nowadays, but not...
[01:21:19.000 --> 01:21:21.200]   There's a lot of loss in the...
[01:21:21.200 --> 01:21:22.760]   I couldn't get it working at all.
[01:21:22.760 --> 01:21:25.840]   I'm in a room on top of the garage.
[01:21:25.840 --> 01:21:28.360]   I tried power line networking.
[01:21:28.360 --> 01:21:30.160]   I tried an extender.
[01:21:30.160 --> 01:21:33.760]   And finally, believe it or not, I ran an ethernet cable out the window downstairs.
[01:21:33.760 --> 01:21:35.320]   That's a waste from the router.
[01:21:35.320 --> 01:21:38.880]   And up across the roof and through the window of my office.
[01:21:38.880 --> 01:21:42.680]   I should mention, I forgot to mention, I apologize.
[01:21:42.680 --> 01:21:43.960]   The hero is a sponsor.
[01:21:43.960 --> 01:21:47.160]   So just for your own disclaimer purposes.
[01:21:47.160 --> 01:21:51.120]   I've got to mention that.
[01:21:51.120 --> 01:21:54.800]   Moto.
[01:21:54.800 --> 01:21:56.640]   I'm very intrigued by this.
[01:21:56.640 --> 01:22:00.880]   Lenovo has announced that they're going to do a Moto Mod a month.
[01:22:00.880 --> 01:22:01.880]   What?
[01:22:01.880 --> 01:22:02.880]   A Moto Mod.
[01:22:02.880 --> 01:22:07.720]   Those are the snap on backs for the Moto Z's or I'll do this in deference to Matthew,
[01:22:07.720 --> 01:22:12.880]   Moto Z, Moto Z Force and the Moto Z Play.
[01:22:12.880 --> 01:22:15.000]   And they plan to do a whole bunch of mods.
[01:22:15.000 --> 01:22:16.560]   And these are third parties.
[01:22:16.560 --> 01:22:21.480]   There's a Kate Spade mod.
[01:22:21.480 --> 01:22:24.920]   There's going to be all sorts of mods from all sorts of groups.
[01:22:24.920 --> 01:22:25.920]   So that's kind of...
[01:22:25.920 --> 01:22:27.640]   Just designed or a mod functionality?
[01:22:27.640 --> 01:22:32.280]   Well, there's a Hasselblad camera back, which I've heard is only mediocre.
[01:22:32.280 --> 01:22:35.360]   There's a Lofi mod, which is a battery mod.
[01:22:35.360 --> 01:22:40.200]   And Sipio makes a docking station that clips into your car.
[01:22:40.200 --> 01:22:41.320]   All sorts of things.
[01:22:41.320 --> 01:22:43.120]   Game controls and more.
[01:22:43.120 --> 01:22:44.520]   You're going to need a Dachty.
[01:22:44.520 --> 01:22:45.520]   I want to not the Kate Spade.
[01:22:45.520 --> 01:22:46.520]   I want to not the Kate Spade.
[01:22:46.520 --> 01:22:47.520]   I want to not the Kate Spade.
[01:22:47.520 --> 01:22:48.520]   Oh, the mod.
[01:22:48.520 --> 01:22:49.520]   Why does the Kate Spade want to just...
[01:22:49.520 --> 01:22:50.520]   It doesn't do anything, but it looks great.
[01:22:50.520 --> 01:22:51.520]   I don't know what those things...
[01:22:51.520 --> 01:22:52.520]   It looks expensive.
[01:22:52.520 --> 01:22:54.520]   Yeah, it looks expensive.
[01:22:54.520 --> 01:22:55.520]   Yeah.
[01:22:55.520 --> 01:22:56.520]   It looks expensive.
[01:22:56.520 --> 01:22:57.520]   Yeah.
[01:22:57.520 --> 01:22:59.800]   Kate Spade's been very involved.
[01:22:59.800 --> 01:23:01.360]   She's of course a women's fashion designer.
[01:23:01.360 --> 01:23:05.200]   She's been very involved in cases and phones for a while now.
[01:23:05.200 --> 01:23:08.200]   A breathalyzer mod?
[01:23:08.200 --> 01:23:09.800]   Hmm.
[01:23:09.800 --> 01:23:11.160]   Color sensors for the blind.
[01:23:11.160 --> 01:23:15.240]   These are potential ideas.
[01:23:15.240 --> 01:23:17.600]   Additional storage.
[01:23:17.600 --> 01:23:20.360]   That's kind of an interesting idea.
[01:23:20.360 --> 01:23:22.720]   A lot of people really like these.
[01:23:22.720 --> 01:23:24.880]   The Moto Z...
[01:23:24.880 --> 01:23:28.640]   The battery life of the Moto Z play is very good.
[01:23:28.640 --> 01:23:31.600]   And it's a $400 phone.
[01:23:31.600 --> 01:23:37.600]   Well, as a result, it's thick and heavy.
[01:23:37.600 --> 01:23:39.400]   And then of course you snap on these backs.
[01:23:39.400 --> 01:23:41.800]   The backs snap on magnetically.
[01:23:41.800 --> 01:23:44.120]   Ooh, I love magnets.
[01:23:44.120 --> 01:23:45.120]   That's kind of cool.
[01:23:45.120 --> 01:23:46.120]   Yeah, that's cool.
[01:23:46.120 --> 01:23:50.320]   But this is a speaker back if you're looking at the video.
[01:23:50.320 --> 01:23:51.320]   Hmm.
[01:23:51.320 --> 01:23:54.080]   So this is why I was excited to remember the...
[01:23:54.080 --> 01:23:55.840]   You like Project Aura.
[01:23:55.840 --> 01:23:56.840]   Thank you.
[01:23:56.840 --> 01:23:57.840]   I was like, it's not Harlow.
[01:23:57.840 --> 01:23:58.840]   It's...
[01:23:58.840 --> 01:23:59.840]   Yeah, so...
[01:23:59.840 --> 01:24:00.840]   Project Harlow.
[01:24:00.840 --> 01:24:01.840]   Project, yeah.
[01:24:01.840 --> 01:24:02.840]   Yeah.
[01:24:02.840 --> 01:24:03.840]   So...
[01:24:03.840 --> 01:24:04.840]   I don't know.
[01:24:04.840 --> 01:24:05.840]   I think this is kind of fun.
[01:24:05.840 --> 01:24:06.840]   Anything with magnets.
[01:24:06.840 --> 01:24:07.840]   Anything with magnets.
[01:24:07.840 --> 01:24:10.840]   Because snapping magnets together is just so satisfying.
[01:24:10.840 --> 01:24:12.680]   You should have a Pixel C.
[01:24:12.680 --> 01:24:14.600]   The Pixel C magnet's the best.
[01:24:14.600 --> 01:24:15.600]   What?
[01:24:15.600 --> 01:24:16.600]   The Pixel C.
[01:24:16.600 --> 01:24:18.160]   Oh, yeah, the way that keyboard...
[01:24:18.160 --> 01:24:20.000]   You pry it off the tablet.
[01:24:20.000 --> 01:24:21.000]   That's the Google tablet.
[01:24:21.000 --> 01:24:22.520]   By the way, I keep your rumors.
[01:24:22.520 --> 01:24:25.080]   There's going to be another Google tablet.
[01:24:25.080 --> 01:24:26.080]   Pixel tablets soon.
[01:24:26.080 --> 01:24:28.680]   There should be.
[01:24:28.680 --> 01:24:32.040]   The C just wasn't quite it.
[01:24:32.040 --> 01:24:33.120]   I would love that.
[01:24:33.120 --> 01:24:36.040]   I do love it though, yeah.
[01:24:36.040 --> 01:24:39.000]   How are you feeling about the Pixel now?
[01:24:39.000 --> 01:24:40.000]   I'm liking the Pixel a lot.
[01:24:40.000 --> 01:24:41.000]   Better and better.
[01:24:41.000 --> 01:24:46.560]   Oh, so the horror story from "Mittertail" is on my Pixel laptop.
[01:24:46.560 --> 01:24:53.480]   I finally came out for the version for Android apps.
[01:24:53.480 --> 01:24:54.880]   You can guess where this is going to go.
[01:24:54.880 --> 01:24:55.880]   You can guess.
[01:24:55.880 --> 01:24:57.200]   It doesn't work on yours.
[01:24:57.200 --> 01:24:59.200]   Because you have the 2013 model.
[01:24:59.200 --> 01:25:00.200]   No, no, no, no.
[01:25:00.200 --> 01:25:01.200]   I have to do one more.
[01:25:01.200 --> 01:25:02.200]   No, no, no.
[01:25:02.200 --> 01:25:03.200]   His accounts.
[01:25:03.200 --> 01:25:04.200]   Oh, no.
[01:25:04.200 --> 01:25:05.200]   I win.
[01:25:05.200 --> 01:25:07.200]   You win, Stacey.
[01:25:07.200 --> 01:25:20.160]   So, because it's a G-spot, I have to go through unbelievable efforts to approve and approve
[01:25:20.160 --> 01:25:23.320]   and approve and approve.
[01:25:23.320 --> 01:25:24.920]   I could prove the whole organization.
[01:25:24.920 --> 01:25:26.760]   I had to create an organization to put myself in it.
[01:25:26.760 --> 01:25:28.760]   I got three people on this G-speed.
[01:25:28.760 --> 01:25:33.880]   Then I had to approve that and go through all these levels of when I do all that, then
[01:25:33.880 --> 01:25:38.320]   you have to approve every single app for the organization.
[01:25:38.320 --> 01:25:43.280]   There's no way to give me as the administrator and user the opportunity to just download a
[01:25:43.280 --> 01:25:44.280]   damned app.
[01:25:44.280 --> 01:25:49.600]   No, I have to go approve the individual app and then force its install on my laptop to
[01:25:49.600 --> 01:25:50.600]   get it to use.
[01:25:50.600 --> 01:25:56.600]   I'm on F and believe it.
[01:25:56.600 --> 01:25:57.600]   Good times.
[01:25:57.600 --> 01:25:58.600]   I'm sorry, Jeff.
[01:25:58.600 --> 01:26:04.040]   Here end of the weekly Jarvis Trustee rant of slash rant.
[01:26:04.040 --> 01:26:06.040]   Less Moonvests is added again, man.
[01:26:06.040 --> 01:26:07.040]   Somebody's got a...
[01:26:07.040 --> 01:26:10.040]   This guy is the...
[01:26:10.040 --> 01:26:13.600]   I guess Rupert Murdoch used to kind of let slip a lot of stuff.
[01:26:13.600 --> 01:26:14.600]   Less is taken over.
[01:26:14.600 --> 01:26:18.040]   He's the head of CBS.
[01:26:18.040 --> 01:26:24.160]   And he has apparently confirmed accidentally that CBS has done a deal with YouTube, which
[01:26:24.160 --> 01:26:30.880]   confirms the supposition that YouTube is doing a TV package and over the top TV package.
[01:26:30.880 --> 01:26:35.640]   Rumor to be called unplugged on Monday.
[01:26:35.640 --> 01:26:40.160]   Moonvests was speaking at the UBS Global Media Communications Conference and said, "Well,
[01:26:40.160 --> 01:26:42.840]   yeah, we made a deal with YouTube."
[01:26:42.840 --> 01:26:49.840]   And then he said, "Well, I probably shouldn't have said that."
[01:26:49.840 --> 01:26:52.840]   Thanks, Glass.
[01:26:52.840 --> 01:26:54.840]   Never mind.
[01:26:54.840 --> 01:26:59.840]   But we knew that was happening anyway.
[01:26:59.840 --> 01:27:00.840]   Yeah.
[01:27:00.840 --> 01:27:01.840]   And I...
[01:27:01.840 --> 01:27:04.000]   CBS, I'm trying to think...
[01:27:04.000 --> 01:27:09.000]   Where else is CBS TV is seen?
[01:27:09.000 --> 01:27:15.680]   The interesting thing, I actually wrote about this when there was a rumor that CBS was involved.
[01:27:15.680 --> 01:27:20.440]   CBS has been notorious in the past for not doing these types of deals.
[01:27:20.440 --> 01:27:22.760]   Yeah, they're not on direct TV now.
[01:27:22.760 --> 01:27:23.760]   Right.
[01:27:23.760 --> 01:27:28.560]   And at one point, I think it was Apple's venture.
[01:27:28.560 --> 01:27:32.520]   Moonvests basically came out and said they weren't going to pay us enough, so we told
[01:27:32.520 --> 01:27:34.440]   them to f off.
[01:27:34.440 --> 01:27:41.160]   So the fact that they are participating with YouTube is interesting to me because they've
[01:27:41.160 --> 01:27:46.160]   kind of been the holdout in lots of these streaming services.
[01:27:46.160 --> 01:27:51.320]   CBS also owns Showtime and CNET.
[01:27:51.320 --> 01:27:58.440]   They apparently have a deal with PlayStation View because you can get Showtime on PlayStation
[01:27:58.440 --> 01:28:01.880]   View, but you can't get it on Hulu or...
[01:28:01.880 --> 01:28:02.880]   Can you get on a Hulu?
[01:28:02.880 --> 01:28:03.880]   I don't know.
[01:28:03.880 --> 01:28:10.400]   You can buy Showtime on Amazon Prime as a standalone channel.
[01:28:10.400 --> 01:28:11.400]   Yeah.
[01:28:11.400 --> 01:28:12.400]   Yeah.
[01:28:12.400 --> 01:28:13.400]   So interesting.
[01:28:13.400 --> 01:28:15.720]   And is Homeland on Showtime?
[01:28:15.720 --> 01:28:16.720]   Yes.
[01:28:16.720 --> 01:28:17.720]   Okay.
[01:28:17.720 --> 01:28:22.800]   And that's the big thing that PlayStation's advertising is Homeland.
[01:28:22.800 --> 01:28:24.840]   That's the reason you would want to get it.
[01:28:24.840 --> 01:28:31.320]   I should note that Les is also the guy who said Donald Trump is terrible for America,
[01:28:31.320 --> 01:28:32.320]   but he's great for CBS.
[01:28:32.320 --> 01:28:33.320]   Yes, that's right.
[01:28:33.320 --> 01:28:34.320]   Yep.
[01:28:34.320 --> 01:28:35.480]   Very famously.
[01:28:35.480 --> 01:28:43.680]   I think we're actually starting to see the log jam break over the top TV subscriptions.
[01:28:43.680 --> 01:28:47.960]   We're getting closer and closer to a time when you can get all your TV over the internet.
[01:28:47.960 --> 01:28:51.320]   Although you will pay the same amount as you paid for your time.
[01:28:51.320 --> 01:28:52.320]   Or more.
[01:28:52.320 --> 01:28:54.400]   So I think we have found that medium point.
[01:28:54.400 --> 01:28:55.400]   Yeah.
[01:28:55.400 --> 01:28:58.640]   And that's probably why it's all coming together.
[01:28:58.640 --> 01:29:05.280]   Although I think cable is right to worry that their grip is going to be weakened once content
[01:29:05.280 --> 01:29:12.680]   creators can go directly or can find other avenues to go directly to consumers.
[01:29:12.680 --> 01:29:16.000]   The tight monopolistic grip that cable has had on these guys.
[01:29:16.000 --> 01:29:19.440]   I mean, people have been very reluctant to do deals with anybody else because they don't
[01:29:19.440 --> 01:29:21.800]   want to make the cable companies mad.
[01:29:21.800 --> 01:29:27.920]   Well, as that slips, I think that really it's almost like the cue ball hitting the
[01:29:27.920 --> 01:29:30.520]   rack on the beginning of a pool game.
[01:29:30.520 --> 01:29:33.520]   Everything starts to scatter and lots of things can happen now.
[01:29:33.520 --> 01:29:37.000]   Yeah, I think we're at we're at or close to that tipping point.
[01:29:37.000 --> 01:29:42.280]   I mean, if you look even at Netflix and Amazon Prime Video, they're cutting content deals
[01:29:42.280 --> 01:29:44.960]   directly with creators.
[01:29:44.960 --> 01:29:49.440]   Lots of those deals are probably going to be as lucrative or more lucrative.
[01:29:49.440 --> 01:29:56.520]   So I think there's probably lots of opportunity for those alternate OTT providers to go direct.
[01:29:56.520 --> 01:30:00.320]   Some great quotes from Edward Snowden.
[01:30:00.320 --> 01:30:06.440]   He spoke extensively to Katie Currick, who flew to Moscow to talk to him and to a magazine
[01:30:06.440 --> 01:30:09.360]   called Turning Points.
[01:30:09.360 --> 01:30:12.320]   This is from the New York Times quoting Turning Points.
[01:30:12.320 --> 01:30:17.400]   Actually, it's a discussion between Stephen Erlanger, who's the Times London bureau chief
[01:30:17.400 --> 01:30:18.840]   and Edward Snowden.
[01:30:18.840 --> 01:30:22.760]   And of course, one of the reasons I think we're seeing a lot of Snowden is because the drum
[01:30:22.760 --> 01:30:25.760]   beat is ramping up for the president to pardon him.
[01:30:25.760 --> 01:30:31.600]   He only has about a month and a half left to do so if he's if he's going to.
[01:30:31.600 --> 01:30:35.920]   I think the general consensus is at this point that it is unlikely.
[01:30:35.920 --> 01:30:37.840]   I wish he would.
[01:30:37.840 --> 01:30:38.840]   I wish he would do.
[01:30:38.840 --> 01:30:42.320]   It's going to make a strong case for why he should be pardoned.
[01:30:42.320 --> 01:30:45.040]   He said, I never published a single document on my own.
[01:30:45.040 --> 01:30:48.000]   I partnered with news outlets.
[01:30:48.000 --> 01:30:50.320]   This is why we have a free press and democracy.
[01:30:50.320 --> 01:30:54.600]   The government has many great powers, but as the press is charged with determining what
[01:30:54.600 --> 01:31:00.760]   information is truly within the public interest to know.
[01:31:00.760 --> 01:31:06.360]   He said, part of the reason he hasn't turned himself in, Daniel Ellsberg turned himself
[01:31:06.360 --> 01:31:11.000]   in so that there would be a trial and so forth.
[01:31:11.000 --> 01:31:15.280]   He was Daniel Ellsberg as the leaker of the Pentagon Papers back in the '70s.
[01:31:15.280 --> 01:31:19.400]   He said, Ellsberg himself has argued that I made the right decision not to present myself
[01:31:19.400 --> 01:31:23.160]   to the court because things have changed so much since the '70s.
[01:31:23.160 --> 01:31:27.880]   The law today, and this is true and it's sad, does not allow you to make a defense against
[01:31:27.880 --> 01:31:31.040]   espionage act charges in front of a jury.
[01:31:31.040 --> 01:31:36.480]   I am legally prohibited from even speaking to the jury about my motivation.
[01:31:36.480 --> 01:31:39.760]   Can there be a fair trial when you can't put forward a defense?
[01:31:39.760 --> 01:31:42.760]   At the sentencing phase, you can express to the judge while you did what you did, but
[01:31:42.760 --> 01:31:44.840]   that's not democratic.
[01:31:44.840 --> 01:31:49.360]   The jury system was created so you can discuss with your peers what you did and why you
[01:31:49.360 --> 01:31:51.160]   did it and let them decide.
[01:31:51.160 --> 01:31:53.200]   I completely agree with him.
[01:31:53.200 --> 01:31:54.200]   The espionage act.
[01:31:54.200 --> 01:31:56.160]   The government happened to Chelsea in that name.
[01:31:56.160 --> 01:31:57.160]   Right.
[01:31:57.160 --> 01:31:58.160]   That doesn't...
[01:31:58.160 --> 01:31:59.160]   Just get railroaded.
[01:31:59.160 --> 01:32:00.160]   Yeah.
[01:32:00.160 --> 01:32:01.160]   Yeah.
[01:32:01.160 --> 01:32:05.160]   I mean, the Obama administration has been terrible, terrible for freedom of the press, press access
[01:32:05.160 --> 01:32:06.160]   and missile blowers.
[01:32:06.160 --> 01:32:07.160]   Agreed.
[01:32:07.160 --> 01:32:08.160]   Yeah.
[01:32:08.160 --> 01:32:15.320]   They've been one of the biggest, most secret, the one that's cracked down the most on
[01:32:15.320 --> 01:32:17.320]   freedom of information.
[01:32:17.320 --> 01:32:20.320]   So, yeah.
[01:32:20.320 --> 01:32:27.320]   It does not look good, sadly.
[01:32:27.320 --> 01:32:28.840]   Sad noise.
[01:32:28.840 --> 01:32:30.760]   Being patriotic Snowden wraps up.
[01:32:30.760 --> 01:32:34.000]   Being patriotic doesn't simply mean agreeing with your government.
[01:32:34.000 --> 01:32:39.320]   Being willing to disagree, particularly in a risky manner, is actually what we need more
[01:32:39.320 --> 01:32:44.320]   of today when we have this incredible, often fact-free environment where politicians can
[01:32:44.320 --> 01:32:47.480]   make claims and then they're reported as truth.
[01:32:47.480 --> 01:32:49.440]   How do we actually steer democracy?
[01:32:49.440 --> 01:32:54.840]   If we have the facts, we can help facilitate democracy and this is my role.
[01:32:54.840 --> 01:32:59.520]   So he's unchasing.
[01:32:59.520 --> 01:33:00.520]   And I don't blame him.
[01:33:00.520 --> 01:33:03.880]   Well, he's right about the news environment.
[01:33:03.880 --> 01:33:05.880]   Yeah.
[01:33:05.880 --> 01:33:06.880]   Google Fixity.
[01:33:06.880 --> 01:33:07.880]   Go ahead.
[01:33:07.880 --> 01:33:10.600]   Oh, I was going to say, and his entire life has been ripped apart.
[01:33:10.600 --> 01:33:12.720]   So he better be...
[01:33:12.720 --> 01:33:16.560]   I mean, I can't imagine second-guessing that.
[01:33:16.560 --> 01:33:17.560]   That would be just terrible.
[01:33:17.560 --> 01:33:18.560]   The time...
[01:33:18.560 --> 01:33:19.560]   Blow into yourself, Steve.
[01:33:19.560 --> 01:33:21.640]   Time's asked him about that and he said, "Well, I'm kind of an indoor cat.
[01:33:21.640 --> 01:33:22.640]   I'm fine."
[01:33:22.640 --> 01:33:30.920]   Oh, this was an interesting website.
[01:33:30.920 --> 01:33:33.920]   I'm actually going to save that maybe for my pick.
[01:33:33.920 --> 01:33:34.920]   Pewdiepie.
[01:33:34.920 --> 01:33:35.920]   Pewdiepie.
[01:33:35.920 --> 01:33:37.920]   I can't figure this one out.
[01:33:37.920 --> 01:33:42.520]   Pewdiepie says, "YouTube is killing them because he's white."
[01:33:42.520 --> 01:33:43.520]   Yeah.
[01:33:43.520 --> 01:33:51.760]   Pewdiepie is complaining because viewership of his, the number one YouTuber, viewership
[01:33:51.760 --> 01:33:52.600]   is down.
[01:33:52.600 --> 01:33:58.200]   He says the site has YouTube has changed its algorithm so that fewer people see his videos.
[01:33:58.200 --> 01:34:00.920]   This has led to his popularity falling, he said, in a video.
[01:34:00.920 --> 01:34:02.560]   How about they're just sick of your shtick?
[01:34:02.560 --> 01:34:04.760]   Maybe they're just shick of your shtick.
[01:34:04.760 --> 01:34:09.400]   The problem might be that he is white, he said, in the same rant.
[01:34:09.400 --> 01:34:10.400]   That's so...
[01:34:10.400 --> 01:34:11.400]   I'm white.
[01:34:11.400 --> 01:34:12.400]   Can I make that comment?
[01:34:12.400 --> 01:34:13.400]   That's a problem.
[01:34:13.400 --> 01:34:15.920]   It's more than offensive, it's unbelievable.
[01:34:15.920 --> 01:34:21.720]   And then he says, he claims YouTube wants to put someone else on the top of the site.
[01:34:21.720 --> 01:34:27.880]   Someone extremely, this is a quote, someone extremely cancerous.
[01:34:27.880 --> 01:34:32.320]   This article from the UK, from the independent in the UK thinks it might be Lilly Singh who's
[01:34:32.320 --> 01:34:34.120]   a Canadian YouTuber within Indian.
[01:34:34.120 --> 01:34:35.560]   Oh no, he said it.
[01:34:35.560 --> 01:34:36.560]   Lilly Singh.
[01:34:36.560 --> 01:34:37.560]   He said it.
[01:34:37.560 --> 01:34:39.480]   Lilly Singh and Canadian YouTuber with Indian Heritage.
[01:34:39.480 --> 01:34:40.480]   Oh, MJ.
[01:34:40.480 --> 01:34:50.480]   So I mentioned this online and I had a number of people respond to me saying he's just trolling.
[01:34:50.480 --> 01:34:54.480]   Like PewDiePie does this apparently routinely.
[01:34:54.480 --> 01:34:56.880]   He doesn't actually think that.
[01:34:56.880 --> 01:35:00.160]   And that's not why he is talking about deleting his channel.
[01:35:00.160 --> 01:35:06.280]   A lot of it is just attention seeking behavior and he knows that if he says something dramatic
[01:35:06.280 --> 01:35:07.280]   it'll get picked up.
[01:35:07.280 --> 01:35:10.320]   He's the excuse for a lot of bad behavior these days.
[01:35:10.320 --> 01:35:11.320]   Yeah, true.
[01:35:11.320 --> 01:35:14.160]   Oh, he's just attention seeking.
[01:35:14.160 --> 01:35:15.160]   He's just trolling.
[01:35:15.160 --> 01:35:17.120]   He doesn't mean it.
[01:35:17.120 --> 01:35:18.960]   That doesn't matter.
[01:35:18.960 --> 01:35:21.280]   That doesn't matter.
[01:35:21.280 --> 01:35:22.280]   You said it.
[01:35:22.280 --> 01:35:25.080]   Doesn't matter if you met it.
[01:35:25.080 --> 01:35:30.160]   And if his numbers are down, I think PewDiePie you need to look in the mirror.
[01:35:30.160 --> 01:35:31.160]   Crime and that.
[01:35:31.160 --> 01:35:32.160]   The problem.
[01:35:32.160 --> 01:35:33.920]   I mean, this is this happens to everybody.
[01:35:33.920 --> 01:35:38.200]   This is called being, you know, this is popularity.
[01:35:38.200 --> 01:35:40.040]   It's boxes and falls.
[01:35:40.040 --> 01:35:44.200]   And he had a much longer run than anybody would have ever guessed.
[01:35:44.200 --> 01:35:45.200]   Yeah.
[01:35:45.200 --> 01:35:49.360]   Well, that's just because we're old and we don't understand what the kids watch.
[01:35:49.360 --> 01:35:50.360]   That's true.
[01:35:50.360 --> 01:35:51.520]   We watch all land.
[01:35:51.520 --> 01:35:52.520]   We don't.
[01:35:52.520 --> 01:35:55.400]   Yeah, we're into that other stuff.
[01:35:55.400 --> 01:36:03.600]   Congratulations to our friend, Anil Dash, Gina Trapani's partner, former partner at Think,
[01:36:03.600 --> 01:36:04.600]   Up.
[01:36:04.600 --> 01:36:07.800]   He is now the new CEO of Fall Creek Software.
[01:36:07.800 --> 01:36:12.200]   The software startup created by Joel Spolsky.
[01:36:12.200 --> 01:36:16.760]   I didn't realize this, but they kind of spun off Trello and stack overflow.
[01:36:16.760 --> 01:36:19.920]   Two big creations.
[01:36:19.920 --> 01:36:26.040]   But they, but Fall Creek still does a developer tool called FogBugs and its new project will
[01:36:26.040 --> 01:36:28.880]   be relaunched under Anil Dash this week.
[01:36:28.880 --> 01:36:29.880]   Go Mix.
[01:36:29.880 --> 01:36:32.960]   The easiest way to build the app or bot of your dreams.
[01:36:32.960 --> 01:36:35.840]   So congratulations, Anil, love Anil.
[01:36:35.840 --> 01:36:39.840]   He's really widely regarded everywhere.
[01:36:39.840 --> 01:36:43.960]   I think anybody who knows him knows what a great guy is.
[01:36:43.960 --> 01:36:44.960]   He's spectacular.
[01:36:44.960 --> 01:36:45.960]   And he and Gina.
[01:36:45.960 --> 01:36:46.960]   I mean, like he-
[01:36:46.960 --> 01:36:47.960]   Go ahead.
[01:36:47.960 --> 01:36:51.200]   Oh, I was going to say he, he's a genuinely nice fellow.
[01:36:51.200 --> 01:36:56.840]   And then he also does so much work for advocating for diversity in tech and just different,
[01:36:56.840 --> 01:37:00.320]   like being thoughtful about how you build your tech.
[01:37:00.320 --> 01:37:01.320]   Yep.
[01:37:01.320 --> 01:37:02.320]   I agree with you.
[01:37:02.320 --> 01:37:03.320]   Yeah.
[01:37:03.320 --> 01:37:05.480]   I mean, he's been a part of so many other amazing things.
[01:37:05.480 --> 01:37:06.960]   Six apart, right?
[01:37:06.960 --> 01:37:07.960]   Type pad, yeah.
[01:37:07.960 --> 01:37:08.960]   Type pad.
[01:37:08.960 --> 01:37:12.480]   That's where I met him, I think, was when I first started using a type pad.
[01:37:12.480 --> 01:37:13.640]   There were a lot of smart people there.
[01:37:13.640 --> 01:37:19.360]   I spent the one day at Facebook and got to see Andrew Wanker, who's now in charge of
[01:37:19.360 --> 01:37:20.360]   news products there.
[01:37:20.360 --> 01:37:21.360]   And he was six apart.
[01:37:21.360 --> 01:37:24.440]   There were some really good people in six apart, but he back in the days.
[01:37:24.440 --> 01:37:25.440]   Yeah.
[01:37:25.440 --> 01:37:27.840]   They came out of Petaluma, you know.
[01:37:27.840 --> 01:37:28.840]   Yeah.
[01:37:28.840 --> 01:37:29.840]   Did they?
[01:37:29.840 --> 01:37:30.840]   Yeah.
[01:37:30.840 --> 01:37:31.840]   Type pad.
[01:37:31.840 --> 01:37:32.840]   What's the most of it?
[01:37:32.840 --> 01:37:33.840]   Yeah.
[01:37:33.840 --> 01:37:34.840]   Mina?
[01:37:34.840 --> 01:37:35.840]   Yeah.
[01:37:35.840 --> 01:37:36.840]   Yeah.
[01:37:36.840 --> 01:37:37.840]   Yeah.
[01:37:37.840 --> 01:37:38.840]   Mina.
[01:37:38.840 --> 01:37:39.840]   Trot.
[01:37:39.840 --> 01:37:40.840]   Trot.
[01:37:40.840 --> 01:37:41.840]   Mina.
[01:37:41.840 --> 01:37:42.840]   Yeah.
[01:37:42.840 --> 01:37:43.840]   Whatever happened to you?
[01:37:43.840 --> 01:37:44.840]   Good question.
[01:37:44.840 --> 01:37:45.840]   Yeah.
[01:37:45.840 --> 01:37:46.840]   Good question.
[01:37:46.840 --> 01:37:48.840]   It was a great feature on the quick network somewhere.
[01:37:48.840 --> 01:37:50.840]   So whatever happened to you?
[01:37:50.840 --> 01:37:53.840]   Well, you know, there's this thing called Wikipedia.
[01:37:53.840 --> 01:37:56.080]   Yeah, there is.
[01:37:56.080 --> 01:37:59.440]   There's Mina, Mina Trot, Ben and Mina Trot.
[01:37:59.440 --> 01:38:02.440]   They were, I think Ben wrote the original TypePad software.
[01:38:02.440 --> 01:38:05.320]   I used it when it was still in beta.
[01:38:05.320 --> 01:38:08.000]   And oh, I guess they're no longer together.
[01:38:08.000 --> 01:38:09.520]   Oh, no.
[01:38:09.520 --> 01:38:14.080]   Ex-husband it says.
[01:38:14.080 --> 01:38:16.160]   They started at 2001.
[01:38:16.160 --> 01:38:21.440]   She started blogging at dollars short dot org, which is a great, a great site name.
[01:38:21.440 --> 01:38:23.400]   It's still her Twitter handle.
[01:38:23.400 --> 01:38:25.360]   Dollars short is awesome.
[01:38:25.360 --> 01:38:27.160]   She's doing a sewing blog.
[01:38:27.160 --> 01:38:29.440]   Like, yes, or maybe she was.
[01:38:29.440 --> 01:38:31.520]   And it doesn't, it stops at 2012.
[01:38:31.520 --> 01:38:32.520]   We don't know.
[01:38:32.520 --> 01:38:36.040]   Well, I hope she made, I hope she had been made so much money.
[01:38:36.040 --> 01:38:37.360]   They've just retired.
[01:38:37.360 --> 01:38:39.160]   That would be my hope.
[01:38:39.160 --> 01:38:40.160]   That would be nice.
[01:38:40.160 --> 01:38:41.160]   Yeah.
[01:38:41.160 --> 01:38:42.160]   They were the sweetest people.
[01:38:42.160 --> 01:38:43.160]   I really liked them.
[01:38:43.160 --> 01:38:46.360]   Well, they sold, they sold the company to say media, I think it was.
[01:38:46.360 --> 01:38:48.640]   And then it shut it down.
[01:38:48.640 --> 01:38:51.560]   It was some sort of dodgy kind of.
[01:38:51.560 --> 01:38:57.120]   Remember they did Vox, which was kind of, uh, that was kind of, they're easy to use
[01:38:57.120 --> 01:38:59.520]   blogging platform.
[01:38:59.520 --> 01:39:01.160]   Six apart purchase live journal.
[01:39:01.160 --> 01:39:02.160]   Wow.
[01:39:02.160 --> 01:39:03.160]   I didn't realize that.
[01:39:03.160 --> 01:39:04.160]   They sold that at a profit.
[01:39:04.160 --> 01:39:05.160]   Mm hmm.
[01:39:05.160 --> 01:39:06.960]   Then they started Vox, which I used also that way.
[01:39:06.960 --> 01:39:10.160]   I've been, I've been with the ice used all their products.
[01:39:10.160 --> 01:39:11.160]   Then Sam was.
[01:39:11.160 --> 01:39:14.680]   It was an, it was an type pad.
[01:39:14.680 --> 01:39:19.600]   I think launching a for pay version that helped jumpstart WordPress.
[01:39:19.600 --> 01:39:20.600]   Maybe that's the case.
[01:39:20.600 --> 01:39:21.600]   Well, it was more than that.
[01:39:21.600 --> 01:39:22.600]   Yeah.
[01:39:22.600 --> 01:39:23.600]   It was.
[01:39:23.600 --> 01:39:25.560]   It's actually if I find a fascinating story.
[01:39:25.560 --> 01:39:26.720]   So moveable type.
[01:39:26.720 --> 01:39:27.720]   That's what I used.
[01:39:27.720 --> 01:39:28.720]   Moveable type.
[01:39:28.720 --> 01:39:29.720]   That's what I used.
[01:39:29.720 --> 01:39:30.720]   Moveable type.
[01:39:30.720 --> 01:39:35.120]   Moveable type had its platform and then it wanted to have a hosted service.
[01:39:35.120 --> 01:39:36.120]   Right.
[01:39:36.120 --> 01:39:40.080]   And so they enabled the platform to be licensed, but they limited that license so that you
[01:39:40.080 --> 01:39:45.240]   couldn't compete too much with the moveable type hosting platform.
[01:39:45.240 --> 01:39:48.880]   And all the hosts said, I know along comes WordPress.
[01:39:48.880 --> 01:39:53.000]   WordPress has done, no, no, no, no, we're going to make open source.
[01:39:53.000 --> 01:39:54.000]   The underlying code.
[01:39:54.000 --> 01:39:57.360]   Yes, we're going to build the first for profit on top of that.
[01:39:57.360 --> 01:40:01.160]   And they got VC funding for this entirely new model to do that because they didn't own
[01:40:01.160 --> 01:40:02.160]   the IP.
[01:40:02.160 --> 01:40:05.280]   The IP was all in the dot org.
[01:40:05.280 --> 01:40:07.520]   The brand is now owned by the dot org.
[01:40:07.520 --> 01:40:12.360]   And it was wildly more successful because it enabled scale and everybody used moveable
[01:40:12.360 --> 01:40:16.400]   type and that hurt type pad and six part.
[01:40:16.400 --> 01:40:17.400]   We had Ben and Mina.
[01:40:17.400 --> 01:40:19.600]   I'm looking at my blog because I ran a mobile type blog.
[01:40:19.600 --> 01:40:21.400]   It was one of the first platforms I used.
[01:40:21.400 --> 01:40:25.520]   We had them on the screen savers in 2002.
[01:40:25.520 --> 01:40:30.480]   Way back when way back when I use blogger first.
[01:40:30.480 --> 01:40:31.480]   It's amazing.
[01:40:31.480 --> 01:40:38.400]   The bloggers still around by the way and then used a mobile type and then used a WordPress.
[01:40:38.400 --> 01:40:43.720]   I think my first blogging program was a program called gray matter.
[01:40:43.720 --> 01:40:45.560]   Yeah, gray matter.
[01:40:45.560 --> 01:40:47.120]   That was great.
[01:40:47.120 --> 01:40:48.120]   Yeah.
[01:40:48.120 --> 01:40:51.440]   Noah had some health issues as I remember.
[01:40:51.440 --> 01:40:53.280]   Noah Gray was great though.
[01:40:53.280 --> 01:40:58.960]   So I started doing that in 2000 and he stopped maintaining in 2002 and I think that's when
[01:40:58.960 --> 01:41:03.360]   I moved to moveable type and both these I was hosting it and then type pad was a hosted
[01:41:03.360 --> 01:41:04.360]   solution.
[01:41:04.360 --> 01:41:06.760]   Yeah, I think I did exactly.
[01:41:06.760 --> 01:41:07.760]   Yeah, yeah, yeah.
[01:41:07.760 --> 01:41:08.760]   First gray matter.
[01:41:08.760 --> 01:41:10.360]   Yeah, then moveable type.
[01:41:10.360 --> 01:41:12.080]   The matter was so cool.
[01:41:12.080 --> 01:41:14.240]   Do you know where six apart came from the name?
[01:41:14.240 --> 01:41:15.240]   No.
[01:41:15.240 --> 01:41:17.480]   Ben and Mina's birthdays were six days.
[01:41:17.480 --> 01:41:19.800]   Oh, that's cute.
[01:41:19.800 --> 01:41:21.000]   Oh, that's cute.
[01:41:21.000 --> 01:41:23.000]   That's awesome.
[01:41:23.000 --> 01:41:27.280]   You know, I'm on Squarespace.
[01:41:27.280 --> 01:41:28.280]   They're a sponsor.
[01:41:28.280 --> 01:41:29.280]   I'm happy.
[01:41:29.280 --> 01:41:33.880]   But I'm always looking for I would love to host what's the best blogging software these
[01:41:33.880 --> 01:41:34.880]   days?
[01:41:34.880 --> 01:41:39.880]   What's I would like to host it myself and I think WordPress is still the best word presses
[01:41:39.880 --> 01:41:40.880]   the king, isn't it?
[01:41:40.880 --> 01:41:43.000]   Yeah, I'm still using WordPress.
[01:41:43.000 --> 01:41:45.200]   Are you so hosted?
[01:41:45.200 --> 01:41:46.880]   Um, yes.
[01:41:46.880 --> 01:41:48.760]   You know, no WordPress.com you have your own.
[01:41:48.760 --> 01:41:49.760]   No, I'm not.
[01:41:49.760 --> 01:41:51.480]   No, I have two different hosts.
[01:41:51.480 --> 01:41:55.760]   I just was making sure that that was true.
[01:41:55.760 --> 01:41:57.440]   Remember when people blogged and stuff?
[01:41:57.440 --> 01:41:58.440]   That was great.
[01:41:58.440 --> 01:41:59.440]   Yeah.
[01:41:59.440 --> 01:42:00.440]   I blog.
[01:42:00.440 --> 01:42:04.040]   I try to blog at least now two or three times a year.
[01:42:04.040 --> 01:42:05.440]   I'm so ruined.
[01:42:05.440 --> 01:42:06.440]   I'm ruined.
[01:42:06.440 --> 01:42:08.840]   Yeah, I used to blog five times a day.
[01:42:08.840 --> 01:42:09.840]   I know.
[01:42:09.840 --> 01:42:10.840]   Me too.
[01:42:10.840 --> 01:42:11.840]   Me too.
[01:42:11.840 --> 01:42:12.840]   Oh, no way, Matthew.
[01:42:12.840 --> 01:42:13.840]   No way.
[01:42:13.840 --> 01:42:14.840]   What?
[01:42:14.840 --> 01:42:15.840]   I did.
[01:42:15.840 --> 01:42:18.440]   Are you calling him out?
[01:42:18.440 --> 01:42:21.520]   I'm calling him out as a former Matthew editor and colleague.
[01:42:21.520 --> 01:42:23.720]   I'm like two posts a day.
[01:42:23.720 --> 01:42:29.360]   Stacy believes I am incapable of writing anything shorter than like 800 words.
[01:42:29.360 --> 01:42:32.200]   Oh, you don't do short posts.
[01:42:32.200 --> 01:42:33.200]   Which is mostly true.
[01:42:33.200 --> 01:42:34.200]   Yeah.
[01:42:34.200 --> 01:42:35.200]   You're doing a lot though.
[01:42:35.200 --> 01:42:39.680]   I did do a lot of shorter posts and now I just tweak that stuff.
[01:42:39.680 --> 01:42:46.080]   I can use to do blog posts that were a paragraph.
[01:42:46.080 --> 01:42:47.760]   I guess I used blogger.
[01:42:47.760 --> 01:42:49.800]   Yeah, I used blogger.
[01:42:49.800 --> 01:42:52.160]   I think I used, maybe I didn't use blogger first.
[01:42:52.160 --> 01:42:57.440]   What's nice is I've been able to import all the posts, the old posts to my Squarespace
[01:42:57.440 --> 01:42:58.440]   blog.
[01:42:58.440 --> 01:42:59.440]   So I have all these old posts.
[01:42:59.440 --> 01:43:02.880]   I don't think any of the imagery survived.
[01:43:02.880 --> 01:43:03.880]   Yeah.
[01:43:03.880 --> 01:43:05.440]   That's not a problem.
[01:43:05.440 --> 01:43:06.440]   Yeah.
[01:43:06.440 --> 01:43:07.440]   But that's okay.
[01:43:07.440 --> 01:43:08.760]   I can live with that.
[01:43:08.760 --> 01:43:09.760]   I called my original blog.
[01:43:09.760 --> 01:43:12.040]   I started right after 9/11.
[01:43:12.040 --> 01:43:14.480]   I called it World War 3.
[01:43:14.480 --> 01:43:15.480]   Wow.
[01:43:15.480 --> 01:43:23.640]   In some ways, that's why I'd like to still have all this stuff because it really is
[01:43:23.640 --> 01:43:27.560]   your history, your life history.
[01:43:27.560 --> 01:43:30.000]   Yeah.
[01:43:30.000 --> 01:43:32.040]   I did something.
[01:43:32.040 --> 01:43:39.040]   I started at Gigome, which used WordPress.
[01:43:39.040 --> 01:43:43.360]   I hosted the VIP, but it would often swallow posts and not give them back or other things
[01:43:43.360 --> 01:43:44.360]   would happen.
[01:43:44.360 --> 01:43:54.040]   So I started writing in my own hosted version of WordPress and then like cutting and pasting
[01:43:54.040 --> 01:43:56.080]   it over to the Gigome version.
[01:43:56.080 --> 01:43:59.240]   I do that at Fortune Now too, so I have a copy of everything I've written.
[01:43:59.240 --> 01:44:00.240]   Nice.
[01:44:00.240 --> 01:44:02.240]   When did you first start blogging?
[01:44:02.240 --> 01:44:04.600]   Let's get our blog.
[01:44:04.600 --> 01:44:05.600]   Let's get our blog.
[01:44:05.600 --> 01:44:06.600]   Birthdays, everybody.
[01:44:06.600 --> 01:44:12.800]   I think it was 2002 or 2003, but I don't know that I called it blogging.
[01:44:12.800 --> 01:44:17.240]   I was keeping track of links and stuff.
[01:44:17.240 --> 01:44:19.160]   In fact, well, that's what I had a blog.
[01:44:19.160 --> 01:44:20.160]   It was a link role.
[01:44:20.160 --> 01:44:22.160]   That's what blogging was originally, right?
[01:44:22.160 --> 01:44:23.160]   Yeah.
[01:44:23.160 --> 01:44:29.760]   So I had a blog, if you want to call it that, or I had a site in '95, I think it was '94
[01:44:29.760 --> 01:44:32.120]   and '95.
[01:44:32.120 --> 01:44:34.480]   And I just kept track of links, interesting links.
[01:44:34.480 --> 01:44:35.480]   Right.
[01:44:35.480 --> 01:44:38.200]   I guess that's kind of what I did with my first site too.
[01:44:38.200 --> 01:44:43.180]   But it wasn't, I guess, when did it become, a blog is the idea of a kind of a sequential
[01:44:43.180 --> 01:44:46.640]   series of chronological series of posts.
[01:44:46.640 --> 01:44:47.640]   Yeah, chronological.
[01:44:47.640 --> 01:44:49.320]   It was a web blog tour.
[01:44:49.320 --> 01:44:51.320]   It was a web blog tour.
[01:44:51.320 --> 01:44:53.040]   It was a web blog tour.
[01:44:53.040 --> 01:44:55.040]   But even a blog of your web tour.
[01:44:55.040 --> 01:44:57.120]   It was a blog, yeah, or your tour.
[01:44:57.120 --> 01:44:58.120]   Yeah.
[01:44:58.120 --> 01:44:59.720]   It was a link blog, right?
[01:44:59.720 --> 01:45:00.920]   When you were first bloggers.
[01:45:00.920 --> 01:45:01.920]   Yeah.
[01:45:01.920 --> 01:45:02.920]   How about you, Jeff?
[01:45:02.920 --> 01:45:03.920]   What was your, what did you first post?
[01:45:03.920 --> 01:45:05.760]   The week after 9/11, 2001.
[01:45:05.760 --> 01:45:06.760]   2001.
[01:45:06.760 --> 01:45:07.760]   Oh.
[01:45:07.760 --> 01:45:10.400]   Mine is February 28th, 2001.
[01:45:10.400 --> 01:45:12.360]   And I have it right here.
[01:45:12.360 --> 01:45:13.840]   This is the new Leoville web blog.
[01:45:13.840 --> 01:45:15.880]   I'll be posting random thoughts here.
[01:45:15.880 --> 01:45:20.200]   Things too short or stupid to make it to any of the other media I work in.
[01:45:20.200 --> 01:45:22.120]   I guess there's going to be a lot of stuff here.
[01:45:22.120 --> 01:45:23.120]   Nice.
[01:45:23.120 --> 01:45:24.760]   Oh, you sound exactly the same.
[01:45:24.760 --> 01:45:27.840]   I'm like 15 years later.
[01:45:27.840 --> 01:45:29.240]   Character is still similar.
[01:45:29.240 --> 01:45:31.160]   I would hope so.
[01:45:31.160 --> 01:45:33.320]   It's not like I'm making it up.
[01:45:33.320 --> 01:45:34.320]   When did you start?
[01:45:34.320 --> 01:45:36.200]   It stays a year or a lot younger than the rest of us.
[01:45:36.200 --> 01:45:37.200]   When did you start?
[01:45:37.200 --> 01:45:40.600]   Yeah, I think 95 is when I got my first email account.
[01:45:40.600 --> 01:45:41.600]   Nice.
[01:45:41.600 --> 01:45:43.160]   That's too early.
[01:45:43.160 --> 01:45:44.160]   I was okay.
[01:45:44.160 --> 01:45:47.080]   I was a junior in high school.
[01:45:47.080 --> 01:45:48.560]   Oh, wow.
[01:45:48.560 --> 01:45:49.560]   Oh, yeah.
[01:45:49.560 --> 01:45:51.800]   Oh, it was just a curriculum in the park.
[01:45:51.800 --> 01:45:53.360]   I'm sorry.
[01:45:53.360 --> 01:45:56.880]   And then I had a website in college.
[01:45:56.880 --> 01:46:00.440]   I did more stuff on IRC in chat rooms.
[01:46:00.440 --> 01:46:01.440]   Did you really?
[01:46:01.440 --> 01:46:06.800]   Yeah, because I don't know because I'm a nerd.
[01:46:06.800 --> 01:46:12.720]   That's the idea of posting any of my stuff publicly on the internet just felt really
[01:46:12.720 --> 01:46:13.720]   not great.
[01:46:13.720 --> 01:46:14.720]   Oh, you were smart.
[01:46:14.720 --> 01:46:15.720]   You were right.
[01:46:15.720 --> 01:46:18.040]   I wish I'd learned that lesson sooner.
[01:46:18.040 --> 01:46:19.040]   Yeah.
[01:46:19.040 --> 01:46:20.560]   So my first blog was professional in it.
[01:46:20.560 --> 01:46:25.440]   I started it when I worked at the deal in 2006 or 2007.
[01:46:25.440 --> 01:46:29.320]   We were all old timers, even for a youngin.
[01:46:29.320 --> 01:46:33.240]   Well, you know, we are digital media people.
[01:46:33.240 --> 01:46:34.240]   We are digital.
[01:46:34.240 --> 01:46:35.240]   We're digital.
[01:46:35.240 --> 01:46:36.240]   Where's your first step?
[01:46:36.240 --> 01:46:37.840]   That's really what we should know.
[01:46:37.840 --> 01:46:41.320]   I just learned about that snap thing.
[01:46:41.320 --> 01:46:42.320]   I just got it.
[01:46:42.320 --> 01:46:43.320]   It looks pretty cool.
[01:46:43.320 --> 01:46:45.320]   What do you do with it?
[01:46:45.320 --> 01:46:50.800]   I found a piece of paper, speaking of blogging, I found a piece of paper on which I had written
[01:46:50.800 --> 01:46:52.560]   as cleaning up my office.
[01:46:52.560 --> 01:46:58.440]   And I had written down the specs for two internet service providers that I was thinking about
[01:46:58.440 --> 01:47:01.200]   getting a dial up account for.
[01:47:01.200 --> 01:47:04.800]   And it was a mind-boggling to me how much money I paid.
[01:47:04.800 --> 01:47:08.560]   I think it was like $45 a month.
[01:47:08.560 --> 01:47:12.600]   And I got five megabytes or something.
[01:47:12.600 --> 01:47:18.040]   And I got FTP access, I think.
[01:47:18.040 --> 01:47:19.640]   It was just ridiculous.
[01:47:19.640 --> 01:47:21.240]   Anyway, remind me.
[01:47:21.240 --> 01:47:23.240]   It felt like it was a thousand years ago.
[01:47:23.240 --> 01:47:26.320]   Is it on the way back machine?
[01:47:26.320 --> 01:47:27.320]   Might be.
[01:47:27.320 --> 01:47:28.320]   Have you searched?
[01:47:28.320 --> 01:47:29.720]   I should, actually.
[01:47:29.720 --> 01:47:33.080]   I think you have to know your URL to do that.
[01:47:33.080 --> 01:47:34.080]   You do, yeah.
[01:47:34.080 --> 01:47:40.880]   I had my website was on a long defunct ISP and San Francisco called crl.com.
[01:47:40.880 --> 01:47:43.760]   But I don't remember.
[01:47:43.760 --> 01:47:46.680]   I don't remember my domain name.
[01:47:46.680 --> 01:47:53.720]   The first one I used called interlog was run by a 17-year-old who started with IRC, I think,
[01:47:53.720 --> 01:47:55.320]   in chat rooms.
[01:47:55.320 --> 01:48:01.200]   And he eventually sold this ISP for millions of dollars a few years later.
[01:48:01.200 --> 01:48:02.200]   Nice.
[01:48:02.200 --> 01:48:03.200]   Yeah.
[01:48:03.200 --> 01:48:07.360]   If you get in early, you can make some pretty good money on this internet.
[01:48:07.360 --> 01:48:09.480]   It's got to get in early.
[01:48:09.480 --> 01:48:13.240]   That's the key.
[01:48:13.240 --> 01:48:15.880]   Anything else you want to talk about?
[01:48:15.880 --> 01:48:16.880]   What if I missed?
[01:48:16.880 --> 01:48:19.480]   Do you want to talk about Intel?
[01:48:19.480 --> 01:48:21.280]   Well, Qualcomm's new server chips.
[01:48:21.280 --> 01:48:22.280]   Yeah.
[01:48:22.280 --> 01:48:23.280]   Our server chips.
[01:48:23.280 --> 01:48:24.280]   Yeah.
[01:48:24.280 --> 01:48:28.400]   Well, you know, this is where you feel for Intel.
[01:48:28.400 --> 01:48:29.400]   Go ahead.
[01:48:29.400 --> 01:48:30.400]   Tell us about it.
[01:48:30.400 --> 01:48:31.400]   Yes.
[01:48:31.400 --> 01:48:33.640]   I'm like, oh, yes.
[01:48:33.640 --> 01:48:35.600]   So basically today, I think it was today.
[01:48:35.600 --> 01:48:36.600]   It was a day yesterday.
[01:48:36.600 --> 01:48:37.600]   Yeah, it was today.
[01:48:37.600 --> 01:48:38.600]   No, it's today.
[01:48:38.600 --> 01:48:39.600]   Okay.
[01:48:39.600 --> 01:48:43.120]   Qualcomm basically announced the centric 2400 series.
[01:48:43.120 --> 01:48:47.000]   And this is going to be a chip for servers.
[01:48:47.000 --> 01:48:52.880]   And it is also the first-- well, it's actually not Qualcomm's first 10 nanometer chips built
[01:48:52.880 --> 01:48:55.160]   on a brand new-- it's not brand new anymore.
[01:48:55.160 --> 01:48:59.560]   The FinFET 3D kind of building up the transistor process.
[01:48:59.560 --> 01:49:01.120]   So there's a couple of things here.
[01:49:01.120 --> 01:49:06.640]   One is Intel's not going to have-- it's not going to be on that process node to the middle
[01:49:06.640 --> 01:49:08.360]   and next year for its server chips.
[01:49:08.360 --> 01:49:10.560]   So these should be more energy efficient.
[01:49:10.560 --> 01:49:15.240]   They should run their denser.
[01:49:15.240 --> 01:49:22.200]   And this is also ARM-based chips coming into the data center, which is like Intel's motherhood
[01:49:22.200 --> 01:49:23.720]   and apple pie.
[01:49:23.720 --> 01:49:25.920]   So kind of scary.
[01:49:25.920 --> 01:49:27.680]   I will say reality check here.
[01:49:27.680 --> 01:49:32.160]   I've been writing about ARM going into servers since 2009.
[01:49:32.160 --> 01:49:34.560]   Every year was supposed to be the year.
[01:49:34.560 --> 01:49:40.640]   We do have now software that's actually compatible with ARM because that was always going to
[01:49:40.640 --> 01:49:43.240]   be a big issue, was getting things like VMware, etc.
[01:49:43.240 --> 01:49:46.680]   But now with the internet, we're not so worried about that.
[01:49:46.680 --> 01:49:49.160]   So this is kind of interesting.
[01:49:49.160 --> 01:49:50.160]   Kind of interesting.
[01:49:50.160 --> 01:49:51.160]   It is interesting.
[01:49:51.160 --> 01:49:56.480]   Well, and they're also beating Intel to the 10 nanometer FinFET by something like six months.
[01:49:56.480 --> 01:50:00.680]   Yes, that was-- got to make them kind of crazy.
[01:50:00.680 --> 01:50:04.520]   Does it tell you FinFET or do they use their--?
[01:50:04.520 --> 01:50:05.520]   They have their--
[01:50:05.520 --> 01:50:07.920]   They don't have a FinFET yet, right.
[01:50:07.920 --> 01:50:12.720]   They have 3D planer or some other 3D-- I can't remember what it's called.
[01:50:12.720 --> 01:50:20.920]   All right, I'm going to test you all to see how up you are on your YouTube stars.
[01:50:20.920 --> 01:50:21.920]   Oh, God.
[01:50:21.920 --> 01:50:25.960]   It's time for the-- I'm going to fail.
[01:50:25.960 --> 01:50:28.240]   We need a 12-year-old.
[01:50:28.240 --> 01:50:32.240]   It's time for the YouTube Rewind 2016 quiz.
[01:50:32.240 --> 01:50:38.160]   Who is this absolute legend, unbeatable champion and a man with a very sore face?
[01:50:38.160 --> 01:50:44.280]   Is it Scott Sterling, Dan Howell, Squeezy or Fallula?
[01:50:44.280 --> 01:50:46.800]   I don't know who any of those people are.
[01:50:46.800 --> 01:50:47.800]   I don't even know.
[01:50:47.800 --> 01:50:50.000]   I'm going to guess Dan Howell.
[01:50:50.000 --> 01:50:54.960]   That's incorrect with Scott Sterling, Sketch Comedy Group Studio C. Well, let's try another
[01:50:54.960 --> 01:50:55.960]   one.
[01:50:55.960 --> 01:51:00.280]   What is T-Rex's hidden talent?
[01:51:00.280 --> 01:51:02.520]   I'm guessing it's not push-ups.
[01:51:02.520 --> 01:51:03.520]   Handstands.
[01:51:03.520 --> 01:51:04.520]   Handstands?
[01:51:04.520 --> 01:51:05.520]   I like it.
[01:51:05.520 --> 01:51:06.520]   That's wrong.
[01:51:06.520 --> 01:51:07.520]   Oh, okay.
[01:51:07.520 --> 01:51:11.320]   Lovers of the Cretaceous Period shared the plight of our favorite short-arm predators
[01:51:11.320 --> 01:51:16.480]   donning inflatable T-Rex costumes and flailing around.
[01:51:16.480 --> 01:51:19.480]   What 2016 challenge got absolutely glowing reviews?
[01:51:19.480 --> 01:51:23.080]   The Sparkles Challenge, the Face Glitter Challenge, the Highlighter Challenge, or the Lightning
[01:51:23.080 --> 01:51:25.680]   Challenge?
[01:51:25.680 --> 01:51:27.800]   Face Glitter Challenge.
[01:51:27.800 --> 01:51:28.800]   Highlighter.
[01:51:28.800 --> 01:51:30.800]   Zero for four.
[01:51:30.800 --> 01:51:32.800]   Actually, if it's one of those...
[01:51:32.800 --> 01:51:33.800]   This is what it was.
[01:51:33.800 --> 01:51:34.800]   I was obsessed with highlighting.
[01:51:34.800 --> 01:51:38.960]   You should watch the guy in the T-Rex costume trying to go through the American Ninja course.
[01:51:38.960 --> 01:51:40.560]   It's pretty funny.
[01:51:40.560 --> 01:51:45.440]   Which sports star dabbed their way into pop culture history in 2016?
[01:51:45.440 --> 01:51:50.000]   Lionel Messi, Cam Newton, LeBron James, or the Philly fanatic?
[01:51:50.000 --> 01:51:51.000]   Cam Newton.
[01:51:51.000 --> 01:51:52.920]   All right, Cam Newton.
[01:51:52.920 --> 01:51:53.920]   Finally, thanks to you...
[01:51:53.920 --> 01:51:54.920]   Thank you.
[01:51:54.920 --> 01:51:57.280]   The hip is one.
[01:51:57.280 --> 01:51:58.520]   The dab, baby.
[01:51:58.520 --> 01:51:59.520]   More Orbeez, please.
[01:51:59.520 --> 01:52:03.240]   What was the biggest body of water used for the Orbeez challenge?
[01:52:03.240 --> 01:52:04.640]   There's more challenges.
[01:52:04.640 --> 01:52:05.640]   How many challenges are there?
[01:52:05.640 --> 01:52:06.640]   What are the Orbeez challenge?
[01:52:06.640 --> 01:52:07.640]   I don't know.
[01:52:07.640 --> 01:52:08.640]   What are the Orbeez challenge?
[01:52:08.640 --> 01:52:09.640]   I don't know.
[01:52:09.640 --> 01:52:10.640]   This is the Orbeez challenge.
[01:52:10.640 --> 01:52:12.600]   Apparently, you drop a bunch of whatever Orbeez are on your head.
[01:52:12.600 --> 01:52:14.080]   What are they?
[01:52:14.080 --> 01:52:15.080]   Colorful balls.
[01:52:15.080 --> 01:52:16.080]   Colorful balls.
[01:52:16.080 --> 01:52:19.760]   The glow in water filled up bathtub swimples and the view counts.
[01:52:19.760 --> 01:52:23.120]   This just shows that there's a whole subculture of YouTube...
[01:52:23.120 --> 01:52:24.120]   Yes, there is.
[01:52:24.120 --> 01:52:28.400]   We know nothing in the Google show.
[01:52:28.400 --> 01:52:29.960]   That's why I love VidCon.
[01:52:29.960 --> 01:52:30.960]   But Fettie Cream Cheese.
[01:52:30.960 --> 01:52:33.720]   Fun Fettie Cream Cheese is absolutely right.
[01:52:33.720 --> 01:52:37.840]   It's what makes rainbow bagels so delicious.
[01:52:37.840 --> 01:52:40.920]   Oh no, your mannequins have stopped dancing.
[01:52:40.920 --> 01:52:44.960]   What song do you play to get them moving?
[01:52:44.960 --> 01:52:46.760]   Not walk like an Egyptian.
[01:52:46.760 --> 01:52:49.320]   Window shopper Juju on that beat?
[01:52:49.320 --> 01:52:51.200]   I'm going to say I just like the name.
[01:52:51.200 --> 01:52:53.400]   Juju on that beat is absolutely right.
[01:52:53.400 --> 01:52:54.400]   You got it.
[01:52:54.400 --> 01:52:58.560]   What '90s classic had people busting out the running man in 2016?
[01:52:58.560 --> 01:53:02.800]   Mmm-bop, my boo, real love are all my life.
[01:53:02.800 --> 01:53:05.080]   Again, no.
[01:53:05.080 --> 01:53:07.000]   This is why I feel old.
[01:53:07.000 --> 01:53:08.000]   You got it.
[01:53:08.000 --> 01:53:09.000]   I'm a good guesser.
[01:53:09.000 --> 01:53:10.000]   You got it.
[01:53:10.000 --> 01:53:11.000]   You are old.
[01:53:11.000 --> 01:53:12.000]   It was my boo.
[01:53:12.000 --> 01:53:15.360]   Where did a water bottle make its market internet history and flip everybody out on a road trip
[01:53:15.360 --> 01:53:20.760]   at Escape Park at the Pancake House at a talent show?
[01:53:20.760 --> 01:53:21.760]   Talent show?
[01:53:21.760 --> 01:53:22.760]   Wow.
[01:53:22.760 --> 01:53:28.720]   The Mike Senator, Stundenation May, when he athletically threw a water bottle at his school's
[01:53:28.720 --> 01:53:32.880]   talent show, six million views.
[01:53:32.880 --> 01:53:35.720]   Yeah, I watched that one.
[01:53:35.720 --> 01:53:36.720]   I got a pen.
[01:53:36.720 --> 01:53:37.720]   I got a pineapple.
[01:53:37.720 --> 01:53:38.720]   What else do I have?
[01:53:38.720 --> 01:53:44.000]   A confused grocer, artistic fruit, a pineapple pen, or I think a pineapple pen?
[01:53:44.000 --> 01:53:45.720]   Absolutely.
[01:53:45.720 --> 01:53:46.760]   I think that's...
[01:53:46.760 --> 01:53:49.000]   I think I vaguely remember that.
[01:53:49.000 --> 01:53:51.000]   It was a fever dream.
[01:53:51.000 --> 01:53:52.000]   No mountain, no problem.
[01:53:52.000 --> 01:53:56.520]   Which city streets bear the where there's new CNN star Casey Neistat?
[01:53:56.520 --> 01:53:57.520]   Which city streets have the greatest...
[01:53:57.520 --> 01:54:01.320]   But who is now withdrawn from YouTube, right, to vote his attentions?
[01:54:01.320 --> 01:54:02.480]   Or from vlogging at least.
[01:54:02.480 --> 01:54:03.480]   A draw for vlogging.
[01:54:03.480 --> 01:54:05.960]   Obviously, he's going to be doing CNN on YouTube.
[01:54:05.960 --> 01:54:08.880]   Which city streets have the greatest snowboarding in 2016?
[01:54:08.880 --> 01:54:12.440]   Oslo, Venice, San Francisco, New York.
[01:54:12.440 --> 01:54:13.440]   New York.
[01:54:13.440 --> 01:54:14.440]   Snowboarding.
[01:54:14.440 --> 01:54:15.440]   Oh, yeah, Casey did a great job.
[01:54:15.440 --> 01:54:16.440]   I remember that.
[01:54:16.440 --> 01:54:17.440]   I watched that one too.
[01:54:17.440 --> 01:54:18.440]   I saw that one.
[01:54:18.440 --> 01:54:19.640]   Snowpocalypse.
[01:54:19.640 --> 01:54:23.080]   Which challenge had people saying, "Ola como estas" in 2016?
[01:54:23.080 --> 01:54:26.960]   The bienveninos challenge, the cinnamon challenge, the domine challenge.
[01:54:26.960 --> 01:54:28.920]   The say anything challenge.
[01:54:28.920 --> 01:54:30.120]   This is culture.
[01:54:30.120 --> 01:54:31.120]   This is modern culture.
[01:54:31.120 --> 01:54:32.600]   No, you blew it.
[01:54:32.600 --> 01:54:34.480]   Oh, you knew.
[01:54:34.480 --> 01:54:35.480]   Did you know?
[01:54:35.480 --> 01:54:36.480]   I did not.
[01:54:36.480 --> 01:54:37.480]   Was the domine challenge?
[01:54:37.480 --> 01:54:38.480]   Damn.
[01:54:38.480 --> 01:54:40.460]   Back at it again with White Vans.
[01:54:40.460 --> 01:54:41.920]   Daniel, son, Daniel.
[01:54:41.920 --> 01:54:42.920]   Daniel.
[01:54:42.920 --> 01:54:43.920]   Daniel.
[01:54:43.920 --> 01:54:44.920]   Who's Daniel?
[01:54:44.920 --> 01:54:45.920]   Daniel.
[01:54:45.920 --> 01:54:46.920]   Daniel.
[01:54:46.920 --> 01:54:53.160]   His sister, the investigator of Joshua Holtz, received over 50 million views in February.
[01:54:53.160 --> 01:54:55.760]   And he got a lifetime supply of vans.
[01:54:55.760 --> 01:55:01.280]   Oh, the hydraulic press channel crushed it in 2016.
[01:55:01.280 --> 01:55:03.640]   What did they not crush?
[01:55:03.640 --> 01:55:05.400]   Graphene diamond dynamite or a lava lamp?
[01:55:05.400 --> 01:55:06.560]   I would hope dynamite.
[01:55:06.560 --> 01:55:07.560]   Graphene.
[01:55:07.560 --> 01:55:08.560]   Graphene?
[01:55:08.560 --> 01:55:09.560]   Graphene?
[01:55:09.560 --> 01:55:10.560]   Yeah.
[01:55:10.560 --> 01:55:13.040]   You can't get crushed graphene.
[01:55:13.040 --> 01:55:14.040]   This is all the guy does.
[01:55:14.040 --> 01:55:16.760]   He's crushed up with his hydraulic press.
[01:55:16.760 --> 01:55:18.640]   It's the will it blend of 2016?
[01:55:18.640 --> 01:55:19.640]   Yeah.
[01:55:19.640 --> 01:55:20.640]   Yeah.
[01:55:20.640 --> 01:55:21.640]   Do you think these?
[01:55:21.640 --> 01:55:24.760]   I mean, so they got a lot of views.
[01:55:24.760 --> 01:55:26.400]   Are they culturally significant?
[01:55:26.400 --> 01:55:28.240]   Is it just because they get a lot of views?
[01:55:28.240 --> 01:55:30.080]   Is that make them culturally significant?
[01:55:30.080 --> 01:55:33.840]   In a year will anybody think no or care about this stuff?
[01:55:33.840 --> 01:55:35.840]   I think it's like any internet meme.
[01:55:35.840 --> 01:55:38.920]   I think it's culturally significant for a while.
[01:55:38.920 --> 01:55:42.280]   I mean, people drop it into conversation.
[01:55:42.280 --> 01:55:46.640]   It's not that different from people dropping sort of Game of Thrones references into
[01:55:46.640 --> 01:55:49.680]   conversation or and so if you haven't watched their show.
[01:55:49.680 --> 01:55:51.520]   It's on that level of what people are talking about.
[01:55:51.520 --> 01:55:54.600]   But I think a lot of people think it is the next big thing in media.
[01:55:54.600 --> 01:55:56.360]   Well, and it is in a way.
[01:55:56.360 --> 01:55:57.360]   I mean, I certainly-
[01:55:57.360 --> 01:56:01.320]   Well, it is because it's not, it's not a lot of stimulus in the show before, but it's
[01:56:01.320 --> 01:56:02.320]   not mediated.
[01:56:02.320 --> 01:56:04.320]   People passing these around as part of their conversation.
[01:56:04.320 --> 01:56:05.320]   Yeah.
[01:56:05.320 --> 01:56:06.320]   It's achieved the conversation.
[01:56:06.320 --> 01:56:07.320]   It's clap-shot.
[01:56:07.320 --> 01:56:08.320]   In fact, it is conversation.
[01:56:08.320 --> 01:56:09.320]   The content is clap-shot.
[01:56:09.320 --> 01:56:10.320]   Exactly.
[01:56:10.320 --> 01:56:11.320]   Bingo.
[01:56:11.320 --> 01:56:12.320]   I was on Facebook.
[01:56:12.320 --> 01:56:13.320]   I said stop calling what you do content.
[01:56:13.320 --> 01:56:14.960]   And then you get compared to the Washington Post.
[01:56:14.960 --> 01:56:16.200]   What you do is conversation.
[01:56:16.200 --> 01:56:18.240]   It's YouTube rewind time.
[01:56:18.240 --> 01:56:19.240]   The video is out.
[01:56:19.240 --> 01:56:20.240]   We're going to play it now.
[01:56:20.240 --> 01:56:23.560]   That's your reward for getting all these answers right.
[01:56:23.560 --> 01:56:25.640]   By the way, the only one I recognize.
[01:56:25.640 --> 01:56:29.400]   I recognize faces, but I don't know who the are except for Marques Brownlee who was featured
[01:56:29.400 --> 01:56:30.640]   in the thumbnail.
[01:56:30.640 --> 01:56:31.640]   We love.
[01:56:31.640 --> 01:56:32.640]   We love.
[01:56:32.640 --> 01:56:33.640]   Let's see who we got here.
[01:56:33.640 --> 01:56:34.640]   YouTube rewind.
[01:56:34.640 --> 01:56:37.440]   Let me turn up the sound.
[01:56:37.440 --> 01:56:39.760]   Pump up the volume.
[01:56:39.760 --> 01:56:42.120]   Okay.
[01:56:42.120 --> 01:56:43.120]   Who is it?
[01:56:43.120 --> 01:56:44.120]   Who's Fanny Pack?
[01:56:44.120 --> 01:56:45.120]   Is it?
[01:56:45.120 --> 01:56:46.120]   Oh, it's the rock.
[01:56:46.120 --> 01:56:47.120]   Go ahead.
[01:56:47.120 --> 01:56:55.040]   They always have to have one real celebrity amongst all these people I never heard of
[01:56:55.040 --> 01:56:56.760]   because I'm old.
[01:56:56.760 --> 01:57:01.680]   You know, I try to go into YouTube and discover things, but it's such a horrible discovery
[01:57:01.680 --> 01:57:02.680]   platform.
[01:57:02.680 --> 01:57:03.680]   You have to know more teenagers.
[01:57:03.680 --> 01:57:04.680]   Really is what you have to do.
[01:57:04.680 --> 01:57:08.000]   I think that I don't think the author has said to all of her so I could just get the
[01:57:08.000 --> 01:57:09.160]   recommendations from that.
[01:57:09.160 --> 01:57:12.800]   Yeah, these don't become big because they are on the top of the YouTube page.
[01:57:12.800 --> 01:57:13.800]   I don't think.
[01:57:13.800 --> 01:57:14.800]   No, no, no, no.
[01:57:14.800 --> 01:57:17.080]   I think it's just sharing.
[01:57:17.080 --> 01:57:19.960]   It's sharing among kids.
[01:57:19.960 --> 01:57:25.160]   And not on YouTube, ironically, or any Google platform, including Google+, but Twitter,
[01:57:25.160 --> 01:57:28.360]   Snapchat, all of that.
[01:57:28.360 --> 01:57:31.920]   So I'm glad I took the quiz because now I'm recognizing a lot more of this than I might
[01:57:31.920 --> 01:57:32.920]   have earlier.
[01:57:32.920 --> 01:57:34.920]   And you feel what you're for?
[01:57:34.920 --> 01:57:38.200]   Well, now I know what the Orbee Challenge here come white vans.
[01:57:38.200 --> 01:57:39.720]   I mean, I kind of now know.
[01:57:39.720 --> 01:57:40.720]   Wait, is that Justine?
[01:57:40.720 --> 01:57:43.080]   I can't tell she was making a face.
[01:57:43.080 --> 01:57:44.640]   There is the volleyball hit.
[01:57:44.640 --> 01:57:45.840]   There's the white vans.
[01:57:45.840 --> 01:57:46.840]   Yeah.
[01:57:46.840 --> 01:57:48.840]   There's the Casey Neistat.
[01:57:48.840 --> 01:57:49.840]   Casey Neistat.
[01:57:49.840 --> 01:57:50.840]   Yeah.
[01:57:50.840 --> 01:57:59.680]   25 million dollars he sold beam and his celebrity to CNN.
[01:57:59.680 --> 01:58:01.640]   Good deal for CNN, you think?
[01:58:01.640 --> 01:58:02.640]   Yeah.
[01:58:02.640 --> 01:58:04.000]   If they don't ruin it.
[01:58:04.000 --> 01:58:05.000]   I don't think it's...
[01:58:05.000 --> 01:58:06.000]   I guess we'll find out.
[01:58:06.000 --> 01:58:07.600]   I think you can't translate this kind of success.
[01:58:07.600 --> 01:58:11.040]   Hey, there's Trevanoa.
[01:58:11.040 --> 01:58:12.440]   Will PewDiePie be in this?
[01:58:12.440 --> 01:58:14.440]   Of course he will.
[01:58:14.440 --> 01:58:16.440]   Oh, there he is.
[01:58:16.440 --> 01:58:17.440]   Oh, there he is.
[01:58:17.440 --> 01:58:18.440]   Is that him?
[01:58:18.440 --> 01:58:19.440]   I can't tell.
[01:58:19.440 --> 01:58:20.440]   Look at him.
[01:58:20.440 --> 01:58:21.440]   Look at him.
[01:58:21.440 --> 01:58:22.440]   Yep.
[01:58:22.440 --> 01:58:23.440]   I think it was.
[01:58:23.440 --> 01:58:24.960]   It's hard to tell without the emo haircut.
[01:58:24.960 --> 01:58:27.720]   There's some construction workers break dancing.
[01:58:27.720 --> 01:58:32.160]   Oh, this is that dance that we were supposed to know.
[01:58:32.160 --> 01:58:38.720]   I feel like YouTube is a little bit coasting now on...
[01:58:38.720 --> 01:58:41.760]   I don't feel like it was as important this year as it was years past.
[01:58:41.760 --> 01:58:42.760]   Am I wrong?
[01:58:42.760 --> 01:58:44.760]   I think they're going to be doing a lot more live.
[01:58:44.760 --> 01:58:46.760]   He was doing what young Turks were doing.
[01:58:46.760 --> 01:58:48.480]   They're doing live times.
[01:58:48.480 --> 01:58:50.240]   They're rolling out, getting it on.
[01:58:50.240 --> 01:58:51.240]   My face like...
[01:58:51.240 --> 01:58:52.240]   This is the year Facebook decided to live.
[01:58:52.240 --> 01:58:55.320]   I even saw NFL ads for Facebook live.
[01:58:55.320 --> 01:58:56.320]   Yeah.
[01:58:56.320 --> 01:58:57.320]   Why?
[01:58:57.320 --> 01:58:59.320]   Okay, here's the pen and the pineapple guy.
[01:58:59.320 --> 01:59:00.320]   I don't...
[01:59:00.320 --> 01:59:01.320]   Why?
[01:59:01.320 --> 01:59:03.440]   And then the weird mannequins.
[01:59:03.440 --> 01:59:04.920]   And then actual Olympians.
[01:59:04.920 --> 01:59:07.560]   And then dancing T-Rexes.
[01:59:07.560 --> 01:59:11.080]   It's great because it's all inside references to a society that knows the...
[01:59:11.080 --> 01:59:12.080]   Yeah.
[01:59:12.080 --> 01:59:15.680]   I mean, I'm sure if you're into YouTube and if you're...
[01:59:15.680 --> 01:59:17.600]   Must be, is it only teenage...
[01:59:17.600 --> 01:59:19.560]   I mean, what age demographic are we talking about?
[01:59:19.560 --> 01:59:20.560]   Well, I think in '22.
[01:59:20.560 --> 01:59:23.400]   I guess my son would recognize all of this, right?
[01:59:23.400 --> 01:59:24.400]   It's '22.
[01:59:24.400 --> 01:59:25.400]   Yeah, it should have better annotation.
[01:59:25.400 --> 01:59:26.400]   Oh, no, you're...
[01:59:26.400 --> 01:59:27.400]   No, no, no, that's the whole point.
[01:59:27.400 --> 01:59:28.400]   You don't...
[01:59:28.400 --> 01:59:29.400]   It's inside Facebook.
[01:59:29.400 --> 01:59:32.400]   The whole of the old parts don't want to go on.
[01:59:32.400 --> 01:59:35.400]   I know, but if you could turn on annotation, that would be awesome.
[01:59:35.400 --> 01:59:36.400]   I've had a lot of...
[01:59:36.400 --> 01:59:39.400]   So just have somebody do a wiki around that.
[01:59:39.400 --> 01:59:40.400]   Yeah.
[01:59:40.400 --> 01:59:41.400]   I'm sure they will, right?
[01:59:41.400 --> 01:59:42.720]   It's easier to use too, but...
[01:59:42.720 --> 01:59:43.720]   I only know.
[01:59:43.720 --> 01:59:44.720]   So is that Marquez?
[01:59:44.720 --> 01:59:45.720]   I can't...
[01:59:45.720 --> 01:59:46.720]   They go so...
[01:59:46.720 --> 01:59:51.120]   Yeah, that's Marquez Browner in a white room.
[01:59:51.120 --> 01:59:52.880]   Here's the bottle of water guy.
[01:59:52.880 --> 01:59:55.800]   Oh, this is a take-off on the Kanye video, right?
[01:59:55.800 --> 01:59:56.960]   They're all sleeping in bed.
[01:59:56.960 --> 01:59:57.960]   Yeah.
[01:59:57.960 --> 01:59:58.960]   This is...
[01:59:58.960 --> 01:59:59.960]   I don't know.
[01:59:59.960 --> 02:00:04.960]   I think there's so much...
[02:00:04.960 --> 02:00:07.040]   There's more competition now, isn't there?
[02:00:07.040 --> 02:00:09.920]   Then YouTube doesn't dominate as it did.
[02:00:09.920 --> 02:00:13.600]   Well, I think Snapchat has really taken a lot of the...
[02:00:13.600 --> 02:00:17.600]   I mean, Snapchat videos are the way that lots of people communicate now.
[02:00:17.600 --> 02:00:22.560]   But what you're going to have on YouTube, you can have 5 billion subscribers if you're
[02:00:22.560 --> 02:00:26.000]   a star of YouTube, or a star.
[02:00:26.000 --> 02:00:27.000]   Do you...
[02:00:27.000 --> 02:00:28.480]   You're a star within that...
[02:00:28.480 --> 02:00:31.480]   Within your 5 billion followers, but hey.
[02:00:31.480 --> 02:00:32.480]   Yeah.
[02:00:32.480 --> 02:00:37.120]   It's the end of mass.
[02:00:37.120 --> 02:00:39.880]   Do we see one of the Green Brothers there?
[02:00:39.880 --> 02:00:40.880]   You sure?
[02:00:40.880 --> 02:00:41.880]   This is good.
[02:00:41.880 --> 02:00:42.880]   It's fine.
[02:00:42.880 --> 02:00:43.880]   I don't know.
[02:00:43.880 --> 02:00:45.880]   I'm guessing that's really sick, right?
[02:00:45.880 --> 02:00:48.120]   Do you want to see a reference?
[02:00:48.120 --> 02:00:51.200]   Oh, yeah.
[02:00:51.200 --> 02:00:52.360]   I got that one.
[02:00:52.360 --> 02:00:58.040]   Very good.
[02:00:58.040 --> 02:00:59.040]   I just...
[02:00:59.040 --> 02:01:02.120]   All I do is I look for people like Marquez and I just deem that I know and the rest of
[02:01:02.120 --> 02:01:03.120]   it is like...
[02:01:03.120 --> 02:01:07.000]   Then I can say, "Oh, she had three seconds, or one second, or two seconds."
[02:01:07.000 --> 02:01:10.440]   The interesting thing about Snapchat is it's all so private.
[02:01:10.440 --> 02:01:11.440]   You don't have...
[02:01:11.440 --> 02:01:14.640]   You can't have this mask.
[02:01:14.640 --> 02:01:19.040]   And I think maybe the era of mass media is dwindling, is it not?
[02:01:19.040 --> 02:01:20.040]   Oh, yeah.
[02:01:20.040 --> 02:01:21.600]   The business model is that?
[02:01:21.600 --> 02:01:23.360]   What is the mass media?
[02:01:23.360 --> 02:01:26.960]   Is what we do here at Twitter is this kind of last media?
[02:01:26.960 --> 02:01:27.960]   Mass media.
[02:01:27.960 --> 02:01:28.960]   It's a bit.
[02:01:28.960 --> 02:01:30.960]   The end of mass media.
[02:01:30.960 --> 02:01:33.120]   It's kind of the last gas.
[02:01:33.120 --> 02:01:35.600]   No, you never wanted to be a mass, right?
[02:01:35.600 --> 02:01:38.040]   I don't want to be massing that size, but...
[02:01:38.040 --> 02:01:39.040]   You're a niche.
[02:01:39.040 --> 02:01:40.040]   Yeah, but I mean...
[02:01:40.040 --> 02:01:43.680]   Five billion is more mass than you are.
[02:01:43.680 --> 02:01:45.960]   No, we do about 7 million a month.
[02:01:45.960 --> 02:01:46.960]   We do about 7 million a month.
[02:01:46.960 --> 02:01:48.960]   We have a richer around 5 million.
[02:01:48.960 --> 02:01:50.440]   I think for an individual show.
[02:01:50.440 --> 02:01:53.560]   For an individual show, we're talking tens or hundreds of thousands, yeah.
[02:01:53.560 --> 02:01:54.560]   Yeah, yeah.
[02:01:54.560 --> 02:01:56.640]   So, you're the future.
[02:01:56.640 --> 02:01:57.640]   You're about...
[02:01:57.640 --> 02:01:58.640]   So remittiveness.
[02:01:58.640 --> 02:01:59.640]   Small media.
[02:01:59.640 --> 02:02:00.640]   Small media.
[02:02:00.640 --> 02:02:01.640]   Small media.
[02:02:01.640 --> 02:02:04.640]   Sustainable business model.
[02:02:04.640 --> 02:02:05.640]   Artisanal media.
[02:02:05.640 --> 02:02:06.640]   Well, that's...
[02:02:06.640 --> 02:02:09.880]   Yeah, we called our ad agency Artisanal for that very reason.
[02:02:09.880 --> 02:02:12.400]   I've always thought it was kind of handmade.
[02:02:12.400 --> 02:02:13.400]   So there you go.
[02:02:13.400 --> 02:02:16.040]   And then now there's a behind the scenes and then there's a 360.
[02:02:16.040 --> 02:02:17.040]   That's new.
[02:02:17.040 --> 02:02:18.640]   Yeah, I got to hit off.
[02:02:18.640 --> 02:02:19.640]   Well, good.
[02:02:19.640 --> 02:02:20.640]   You just...
[02:02:20.640 --> 02:02:21.640]   The show's over.
[02:02:21.640 --> 02:02:22.640]   So I'm going to...
[02:02:22.640 --> 02:02:25.120]   I'll tell you what I'm going to do an ad, but if you...
[02:02:25.120 --> 02:02:26.360]   I shouldn't have played that rewind.
[02:02:26.360 --> 02:02:29.120]   I didn't realize you had to get going.
[02:02:29.120 --> 02:02:31.960]   Do you want to do a number before I do the ad?
[02:02:31.960 --> 02:02:32.960]   Sure.
[02:02:32.960 --> 02:02:33.960]   Sure.
[02:02:33.960 --> 02:02:39.240]   So Matthew, what about this too, so we can talk about it as well.
[02:02:39.240 --> 02:02:46.160]   The wonderful Craig Silverman at Buzzfeed, they did a survey of, I think, of 3,000 people
[02:02:46.160 --> 02:02:49.200]   looking at people who believe in false news headlines.
[02:02:49.200 --> 02:02:52.680]   Now, the problem with the methodology here is that the majority of people had never heard
[02:02:52.680 --> 02:02:54.280]   of the false news stories.
[02:02:54.280 --> 02:02:56.640]   Among those who had heard of it.
[02:02:56.640 --> 02:03:00.440]   So it was then down to like 300 or fewer respondents.
[02:03:00.440 --> 02:03:06.280]   But among them, 70 some percent believe these ridiculous false news stories, including Democrats
[02:03:06.280 --> 02:03:11.600]   in majority believing false news anti-stories about Hillary Clinton.
[02:03:11.600 --> 02:03:15.640]   Does not bode well for the judgment of...
[02:03:15.640 --> 02:03:21.480]   Yeah, but I think the important takeaway here is that most people didn't even see the...
[02:03:21.480 --> 02:03:22.480]   Yes, that's what I agree with.
[02:03:22.480 --> 02:03:27.080]   And that the people who saw them wanted to believe them.
[02:03:27.080 --> 02:03:28.080]   Yeah, that's all right.
[02:03:28.080 --> 02:03:34.080]   And my contention is that you don't fight fake news by censoring it because really it's
[02:03:34.080 --> 02:03:36.840]   being shared by people who want to believe it.
[02:03:36.840 --> 02:03:41.760]   It's more a statement just as sharing a YouTube video as it's a statement of your ethos than
[02:03:41.760 --> 02:03:42.760]   it is anything else.
[02:03:42.760 --> 02:03:43.760]   Exactly.
[02:03:43.760 --> 02:03:45.520]   It's a membership in a tribe.
[02:03:45.520 --> 02:03:46.520]   Membership in a tribe.
[02:03:46.520 --> 02:03:47.520]   Right.
[02:03:47.520 --> 02:03:51.240]   FBI suspected that Hillary email leaks found dead in apparent murder suicide.
[02:03:51.240 --> 02:03:52.240]   Yeah.
[02:03:52.240 --> 02:03:53.920]   There were eight Twitter respondents.
[02:03:53.920 --> 02:03:55.800]   Twenty-two percent have seen it.
[02:03:55.800 --> 02:04:00.280]   And those, which is to say, three hundred eight nine respondents, 72 percent believed
[02:04:00.280 --> 02:04:01.280]   it.
[02:04:01.280 --> 02:04:03.840]   It was interesting though.
[02:04:03.840 --> 02:04:10.240]   I wrote about the survey and I picked up on something that Marcie Wheeler, who's on Twitter's
[02:04:10.240 --> 02:04:13.360]   empty wheel mentioned, which was exactly that.
[02:04:13.360 --> 02:04:20.560]   The vast majority of people in that survey actually could not remember fake or real headlines.
[02:04:20.560 --> 02:04:26.920]   So it was below, I think, twenty five percent who even remembered some of these incredible
[02:04:26.920 --> 02:04:32.760]   clickbait headlines, which just says to me, people don't either don't remember lots of
[02:04:32.760 --> 02:04:37.960]   the stuff they see on Facebook or don't see Facebook as a place where there's stuff like
[02:04:37.960 --> 02:04:42.280]   news where you might want to remember what it said or where it came from.
[02:04:42.280 --> 02:04:43.840]   Oh, but you get a tone.
[02:04:43.840 --> 02:04:46.040]   I mean, that's you may not remember.
[02:04:46.040 --> 02:04:50.520]   It's like those, oh, I don't remember where I read it, but Hillary Clinton was a real jerk.
[02:04:50.520 --> 02:04:52.640]   So yes, that's the last thing.
[02:04:52.640 --> 02:04:55.440]   It definitely has an impact, for sure.
[02:04:55.440 --> 02:04:57.560]   But I think it's mostly confirmation bias.
[02:04:57.560 --> 02:04:58.560]   Well, that's the question.
[02:04:58.560 --> 02:05:02.880]   And somebody in the chatroom says, but those people already were Andrew Clinton.
[02:05:02.880 --> 02:05:05.240]   So it didn't change anything.
[02:05:05.240 --> 02:05:07.480]   Maybe that's a better question asked.
[02:05:07.480 --> 02:05:09.760]   Whose mind was changed by fake news?
[02:05:09.760 --> 02:05:11.240]   Whose mind was changed?
[02:05:11.240 --> 02:05:15.160]   It entrenches you further into your beliefs.
[02:05:15.160 --> 02:05:16.680]   That's the filter bubble.
[02:05:16.680 --> 02:05:17.680]   Your filter bubble.
[02:05:17.680 --> 02:05:18.680]   Yes.
[02:05:18.680 --> 02:05:20.000]   I mean, so I don't know.
[02:05:20.000 --> 02:05:22.680]   This is not a link related to that filter.
[02:05:22.680 --> 02:05:27.240]   Well, Hank, is that for your closing for my thing?
[02:05:27.240 --> 02:05:28.240]   Closing thing.
[02:05:28.240 --> 02:05:29.240]   Okay, then hang on.
[02:05:29.240 --> 02:05:31.560]   Jeff will let you go back to work.
[02:05:31.560 --> 02:05:32.560]   It's great to see you.
[02:05:32.560 --> 02:05:34.160]   I'll throw out this headset and get another one.
[02:05:34.160 --> 02:05:35.160]   Sorry.
[02:05:35.160 --> 02:05:36.160]   We'll send you a new one.
[02:05:36.160 --> 02:05:37.160]   No problem.
[02:05:37.160 --> 02:05:38.160]   No, I'll get one.
[02:05:38.160 --> 02:05:39.160]   They're cheap.
[02:05:39.160 --> 02:05:40.160]   They had one that came in a case so it didn't get.
[02:05:40.160 --> 02:05:41.160]   That's what you want.
[02:05:41.160 --> 02:05:43.040]   I travel with and it doesn't travel well.
[02:05:43.040 --> 02:05:44.040]   Yeah.
[02:05:44.040 --> 02:05:45.040]   It's already like.
[02:05:45.040 --> 02:05:46.040]   It's too late.
[02:05:46.040 --> 02:05:47.040]   We already sent it on its way.
[02:05:47.040 --> 02:05:48.040]   Aren't you nice?
[02:05:48.040 --> 02:05:49.040]   All right.
[02:05:49.040 --> 02:05:50.040]   See you all later.
[02:05:50.040 --> 02:05:51.040]   See you, Jeff.
[02:05:51.040 --> 02:05:52.040]   Bye, Jeff.
[02:05:52.040 --> 02:05:53.040]   Thanks so much.
[02:05:53.040 --> 02:05:56.160]   Jeff Jarvis, professor of journalism at City University of New York, the author of so
[02:05:56.160 --> 02:05:59.840]   many good books, including Gutenberg, The Geek and what would Google do?
[02:05:59.840 --> 02:06:03.200]   He is also a blogger at buzzmachine.com.
[02:06:03.200 --> 02:06:07.440]   It has been since the year 2001.
[02:06:07.440 --> 02:06:11.080]   Our show today brought to you by Rocket Mortgage from Quick and Loans.
[02:06:11.080 --> 02:06:15.720]   It's a speedy way to get your next home loan or re-fi.
[02:06:15.720 --> 02:06:20.800]   Rocket Mortgage was created by the best mortgage lender in the country, Quick and Loans, for
[02:06:20.800 --> 02:06:26.520]   you and us, for the people who don't want to get out of our chair to get a home loan.
[02:06:26.520 --> 02:06:30.000]   We want to do it all fast, easy online.
[02:06:30.000 --> 02:06:32.960]   Rocket Mortgage completely online.
[02:06:32.960 --> 02:06:37.120]   You can get that mortgage approval on your phone, on your tablet, on your computer without
[02:06:37.120 --> 02:06:39.000]   even getting up from the couch.
[02:06:39.000 --> 02:06:43.600]   Submit all the documents you need with a push of a button, no more shuffling through
[02:06:43.600 --> 02:06:44.600]   papers.
[02:06:44.600 --> 02:06:48.480]   You can get a video because they're showing a little on the website, a couple looking
[02:06:48.480 --> 02:06:49.480]   at an open house.
[02:06:49.480 --> 02:06:50.480]   You know, sometimes that happens.
[02:06:50.480 --> 02:06:54.360]   You go look at open houses, just kind of looking around and you say, "Oh gosh, we should
[02:06:54.360 --> 02:06:56.000]   buy this."
[02:06:56.000 --> 02:06:59.800]   How about applying for the loan at the open house and getting your approval then and there
[02:06:59.800 --> 02:07:04.560]   in minutes and getting a loan that's tailored for your financial situation?
[02:07:04.560 --> 02:07:06.800]   That's what Rocket Mortgage is all about.
[02:07:06.800 --> 02:07:08.480]   Only Quick and Loans could do this.
[02:07:08.480 --> 02:07:10.000]   Rocket Mortgage from Quick and Loans.
[02:07:10.000 --> 02:07:18.400]   Go to quickandloans.com/twig=housing-lender-licence-in-all-50-states and MLSconsumeraccess.org 3030.
[02:07:18.400 --> 02:07:19.400]   Book market.
[02:07:19.400 --> 02:07:24.960]   So when you go out and do a little looky-looing at open houses this weekend, you'll know where
[02:07:24.960 --> 02:07:26.320]   to go.
[02:07:26.320 --> 02:07:33.200]   Rocket Mortgage at quickandloans.com/twig.
[02:07:33.200 --> 02:07:34.920]   Who's eating chips?
[02:07:34.920 --> 02:07:35.920]   That was me.
[02:07:35.920 --> 02:07:36.920]   Sorry, it's my thing.
[02:07:36.920 --> 02:07:39.040]   Show us your thing.
[02:07:39.040 --> 02:07:40.040]   It's in cellophane.
[02:07:40.040 --> 02:07:41.040]   It is in cellophane.
[02:07:41.040 --> 02:07:44.240]   Ooh, now I'm hungry.
[02:07:44.240 --> 02:07:45.240]   Okay.
[02:07:45.240 --> 02:07:46.240]   Switch.
[02:07:46.240 --> 02:07:47.240]   See?
[02:07:47.240 --> 02:07:50.720]   Is this what's on your deck?
[02:07:50.720 --> 02:07:54.960]   This is my secret to automated Christmas lights.
[02:07:54.960 --> 02:08:01.080]   Alright, so if you are someone who has smart things, wink, any Z-Wave hub, like a VeroLite
[02:08:01.080 --> 02:08:07.240]   system, this is about 35 bucks and you can buy it a lot of places.
[02:08:07.240 --> 02:08:09.040]   It is super simple.
[02:08:09.040 --> 02:08:10.040]   It's outdoor capable.
[02:08:10.040 --> 02:08:12.960]   It is one of the only outdoor switches out there.
[02:08:12.960 --> 02:08:15.880]   So you plug in your outdoor lights and then you can hook them up through your echo.
[02:08:15.880 --> 02:08:16.880]   Is this it?
[02:08:16.880 --> 02:08:17.880]   This is it.
[02:08:17.880 --> 02:08:19.840]   40 bucks.
[02:08:19.840 --> 02:08:23.200]   It's so easy to pair.
[02:08:23.200 --> 02:08:26.720]   If you have problems, I can help you.
[02:08:26.720 --> 02:08:27.720]   But that's it.
[02:08:27.720 --> 02:08:29.880]   Can you come over to my house and help me?
[02:08:29.880 --> 02:08:30.880]   Yeah, can you come over and help me?
[02:08:30.880 --> 02:08:32.360]   You can just find me on Twitter.
[02:08:32.360 --> 02:08:34.800]   I have troubleshooted so many of these things.
[02:08:34.800 --> 02:08:40.320]   So that is for people who are like have a hub and are comfortable with Z-Wave.
[02:08:40.320 --> 02:08:43.440]   If you're not, this is not the outdoor version.
[02:08:43.440 --> 02:08:48.040]   This is the indoor version, but iDevices also makes an outdoor capable switch that works
[02:08:48.040 --> 02:08:49.760]   with HomeKit.
[02:08:49.760 --> 02:08:50.760]   That is $80.
[02:08:50.760 --> 02:08:52.640]   So much money.
[02:08:52.640 --> 02:08:55.360]   So there you have it, you guys.
[02:08:55.360 --> 02:09:00.000]   For outdoor Christmas lights, you want to automate the heck out of them, two products for
[02:09:00.000 --> 02:09:01.000]   you.
[02:09:01.000 --> 02:09:03.920]   Describe for me how you would use these.
[02:09:03.920 --> 02:09:11.760]   So I plug my outdoor, a string of outdoor lights in, and then I plug it into that guy.
[02:09:11.760 --> 02:09:18.080]   Oh, before I do that, for the Z-Wave one, I hook up the Z-Wave first.
[02:09:18.080 --> 02:09:22.440]   Oh, and I should say that this has two outlets, the outdoor one.
[02:09:22.440 --> 02:09:29.760]   So I don't particularly love it because I only run one strand of Christmas lights on
[02:09:29.760 --> 02:09:35.760]   each, well, I run three, you can connect three strands, but I run one to that plug on each
[02:09:35.760 --> 02:09:36.760]   balcony.
[02:09:36.760 --> 02:09:38.760]   You could also have them daisy change, right?
[02:09:38.760 --> 02:09:39.760]   Right.
[02:09:39.760 --> 02:09:41.880]   That's why I'm not like keen on the two.
[02:09:41.880 --> 02:09:45.120]   But if you're keen on the two, that's the one to get.
[02:09:45.120 --> 02:09:53.520]   Anyway, you connect the outlet to your platform first inside because of range kind of issues.
[02:09:53.520 --> 02:09:59.680]   So I just, and then you plug that in outside, then you plug your lights in, and it's weather
[02:09:59.680 --> 02:10:01.280]   proof, which is why you use this.
[02:10:01.280 --> 02:10:03.880]   It's one of the only weatherproof ones on the market.
[02:10:03.880 --> 02:10:06.560]   And then I can control it with my phone.
[02:10:06.560 --> 02:10:10.280]   So let me show you my Christmas lights.
[02:10:10.280 --> 02:10:15.440]   So this is for turning them off and on, not for like elaborate displays and things.
[02:10:15.440 --> 02:10:18.680]   Yeah, this is, this is just so I can turn them off and on for my phone.
[02:10:18.680 --> 02:10:20.320]   I can make rules and schedules.
[02:10:20.320 --> 02:10:24.320]   And then I can also talk to it via the Echo.
[02:10:24.320 --> 02:10:26.920]   If you do it through the Wing Cup, if you do it through SmartThings, you can do it through
[02:10:26.920 --> 02:10:28.520]   the Google Home Hub.
[02:10:28.520 --> 02:10:30.520]   So these are my Christmas lights right here.
[02:10:30.520 --> 02:10:31.520]   Oh, that's neat.
[02:10:31.520 --> 02:10:35.600]   The group and then like upper balcony, lower balcony.
[02:10:35.600 --> 02:10:36.600]   Oh.
[02:10:36.600 --> 02:10:39.520]   And you could presumably have like an if this than that that would automatically turn them
[02:10:39.520 --> 02:10:41.440]   on a sunset and turn them off at sunrise.
[02:10:41.440 --> 02:10:45.680]   I have mindset to turn on 10 minutes after sunset.
[02:10:45.680 --> 02:10:46.920]   And then turn off at a certain time.
[02:10:46.920 --> 02:10:48.640]   So that's what these are for.
[02:10:48.640 --> 02:10:54.880]   And you can also do things like, Hey, goo, hey, hey, gee, turn on holiday.
[02:10:54.880 --> 02:10:55.880]   And then boom.
[02:10:55.880 --> 02:10:58.000]   You're just a work with an Amazon Echo as well.
[02:10:58.000 --> 02:10:59.000]   Yeah, that's kind of cool.
[02:10:59.000 --> 02:11:00.000]   Yes.
[02:11:00.000 --> 02:11:02.200]   So that's what I, that's what I do every year.
[02:11:02.200 --> 02:11:07.920]   And I actually do normal holiday and then I have Christmas Eve holiday because, or in
[02:11:07.920 --> 02:11:11.400]   Christmas day holiday, which is indoor for daylight lights.
[02:11:11.400 --> 02:11:15.160]   So I have my indoor and outdoor lights all running through the same place.
[02:11:15.160 --> 02:11:16.160]   So impressed.
[02:11:16.160 --> 02:11:19.120]   I, I keep thinking I should set all this stuff up.
[02:11:19.120 --> 02:11:24.440]   The closest I ever did was setting up some hue lights and putting an S thermostat.
[02:11:24.440 --> 02:11:27.760]   And then we moved and I didn't bother doing it again.
[02:11:27.760 --> 02:11:31.440]   It seems like it's a lot of work, but yet I would love to have that capability.
[02:11:31.440 --> 02:11:35.600]   It's really, I mean, like connecting, you're going to do your Christmas lights.
[02:11:35.600 --> 02:11:41.280]   The beauty of not, of doing it at that outlet is you don't have to mess with like 18 different
[02:11:41.280 --> 02:11:42.280]   things.
[02:11:42.280 --> 02:11:48.360]   So really, it's like an extra five minute process to pair that to a hub.
[02:11:48.360 --> 02:11:54.080]   So all I have to remember to do is just have my phone on me basically.
[02:11:54.080 --> 02:11:55.080]   And then you set up a rule.
[02:11:55.080 --> 02:11:57.000]   Actually, my rules are leftover from last year.
[02:11:57.000 --> 02:12:01.560]   So it's really not my ethics are left over from last year.
[02:12:01.560 --> 02:12:06.960]   So I'm in this someone in the chat room said their Google home responded to you saying
[02:12:06.960 --> 02:12:09.040]   Hey, Jean, what?
[02:12:09.040 --> 02:12:10.040]   I did that on purpose.
[02:12:10.040 --> 02:12:11.040]   So it wouldn't.
[02:12:11.040 --> 02:12:12.040]   I'm sorry.
[02:12:12.040 --> 02:12:15.680]   Oh, you can't even watch TV anymore because it all is.
[02:12:15.680 --> 02:12:16.680]   What?
[02:12:16.680 --> 02:12:17.680]   Yeah, what you asked me?
[02:12:17.680 --> 02:12:18.680]   No, I'm sorry.
[02:12:18.680 --> 02:12:19.680]   I don't know what you're talking about.
[02:12:19.680 --> 02:12:20.680]   What?
[02:12:20.680 --> 02:12:21.680]   Hello, not you.
[02:12:21.680 --> 02:12:23.520]   Ah, Matthew Ingram.
[02:12:23.520 --> 02:12:26.600]   What do you got for us?
[02:12:26.600 --> 02:12:33.440]   So we sort of touched on it, I guess the fake news issue or problem, which is obviously
[02:12:33.440 --> 02:12:38.120]   got a whole bunch of different facets to it.
[02:12:38.120 --> 02:12:39.680]   Some of them are behavioral.
[02:12:39.680 --> 02:12:42.320]   Some of them are, you know, structural.
[02:12:42.320 --> 02:12:48.680]   There's the influence of Facebook as a platform, which I think is is a hugely complex issue
[02:12:48.680 --> 02:12:49.680]   in a bunch of ways.
[02:12:49.680 --> 02:12:52.680]   The way we use it, how it impacts us.
[02:12:52.680 --> 02:13:01.920]   But anyway, there was when this sort of exploded recently, Eli Parriser, who wrote the book,
[02:13:01.920 --> 02:13:08.680]   The Filter Bubble and Coinde term, I'm pretty sure went on to start something called Upworthy.
[02:13:08.680 --> 02:13:12.040]   He started at Google Doc and the link is in the.
[02:13:12.040 --> 02:13:13.040]   It's kind of ironic.
[02:13:13.040 --> 02:13:14.040]   He started up worthy.
[02:13:14.040 --> 02:13:15.040]   Yeah, I know.
[02:13:15.040 --> 02:13:16.040]   I know.
[02:13:16.040 --> 02:13:19.040]   Well, he's seen things from both sides.
[02:13:19.040 --> 02:13:20.040]   Yes.
[02:13:20.040 --> 02:13:21.040]   Yes.
[02:13:21.040 --> 02:13:29.640]   So the Google Doc was basically an open document for kind of suggesting ways of dealing with
[02:13:29.640 --> 02:13:34.320]   the fake news problem specifically on Facebook design.
[02:13:34.320 --> 02:13:39.760]   How could sort of technology be used to help people identify what's fake and what isn't
[02:13:39.760 --> 02:13:40.760]   that sort of thing.
[02:13:40.760 --> 02:13:45.560]   And it just kind of spawned this massive collaborative sort of.
[02:13:45.560 --> 02:13:46.560]   I have to read this.
[02:13:46.560 --> 02:13:50.400]   Discussion, which is, which continues on the doc.
[02:13:50.400 --> 02:13:51.400]   I thought it was interesting.
[02:13:51.400 --> 02:13:53.960]   Some of the ideas in there are interesting.
[02:13:53.960 --> 02:13:55.640]   Some are strictly technological.
[02:13:55.640 --> 02:14:01.520]   Some of them are kind of behavioral or some require things of Facebook.
[02:14:01.520 --> 02:14:04.280]   Some require things of sort of users of Facebook.
[02:14:04.280 --> 02:14:07.520]   Anyway, I thought it was interesting if you're interested in that topic.
[02:14:07.520 --> 02:14:08.520]   Yeah.
[02:14:08.520 --> 02:14:13.600]   And I kind of like this idea of a collaborative document with all these people.
[02:14:13.600 --> 02:14:14.600]   It's a Google Doc.
[02:14:14.600 --> 02:14:15.600]   So everybody's in.
[02:14:15.600 --> 02:14:17.360]   I mean, it's you can watch it.
[02:14:17.360 --> 02:14:19.160]   It's 123 pages already.
[02:14:19.160 --> 02:14:20.160]   Yeah.
[02:14:20.160 --> 02:14:23.880]   And I got into it and posted something.
[02:14:23.880 --> 02:14:25.600]   I think it was a single page.
[02:14:25.600 --> 02:14:28.160]   So it's really exploded since then.
[02:14:28.160 --> 02:14:35.080]   The only problem, of course, is that the entity that isn't part of this discussion is
[02:14:35.080 --> 02:14:36.880]   Facebook.
[02:14:36.880 --> 02:14:41.120]   They haven't really talked about, you know, they said they're concerned and they're working
[02:14:41.120 --> 02:14:42.120]   on stuff.
[02:14:42.120 --> 02:14:47.680]   But I would much rather that this was a sort of as open and collaborative as possible.
[02:14:47.680 --> 02:14:51.800]   Maybe we could, you know, there could be open source things that Facebook could implement
[02:14:51.800 --> 02:14:58.040]   that could help kind of plug into a lot of the fact checking and verification stuff that's
[02:14:58.040 --> 02:14:59.480]   already out there.
[02:14:59.480 --> 02:15:06.240]   But so far, Facebook hasn't really shown that it wants to be part of that.
[02:15:06.240 --> 02:15:12.680]   I've started to see a lot of posts from a variety of sources on how to find how to detect
[02:15:12.680 --> 02:15:13.680]   face news.
[02:15:13.680 --> 02:15:17.640]   Some of the fake news, some of their intended students, which I think is really the real
[02:15:17.640 --> 02:15:22.520]   sweet spot for this, because students have to have to learn this, you know, how to know
[02:15:22.520 --> 02:15:30.920]   if the source you're citing for your theme or your term paper is legit or made up or
[02:15:30.920 --> 02:15:33.440]   and it's really useful for them.
[02:15:33.440 --> 02:15:34.440]   This is disappointing.
[02:15:34.440 --> 02:15:42.360]   But if you I wrote about a study recently, if you just Google fortune and fake news,
[02:15:42.360 --> 02:15:43.360]   I saw it.
[02:15:43.360 --> 02:15:44.360]   Yeah.
[02:15:44.360 --> 02:15:50.740]   There's a study that showed that a fairly massive proportion of students in high school
[02:15:50.740 --> 02:15:56.960]   and college could not distinguish a fake news story or a piece of sponsored advertising
[02:15:56.960 --> 02:15:58.880]   from a real news story.
[02:15:58.880 --> 02:15:59.880]   Yeah.
[02:15:59.880 --> 02:16:01.880]   We actually talked about it last week or the week before.
[02:16:01.880 --> 02:16:02.880]   Yeah.
[02:16:02.880 --> 02:16:03.880]   Incredibly depressing.
[02:16:03.880 --> 02:16:04.880]   Yeah.
[02:16:04.880 --> 02:16:10.320]   So clearly there's a huge amount of sort of news literacy, you know, required, education
[02:16:10.320 --> 02:16:12.720]   required about how to do.
[02:16:12.720 --> 02:16:18.680]   And in fact, I made the same point about Google not like years ago when we were talking about
[02:16:18.680 --> 02:16:23.480]   how to determine whether a source on Google is is trustworthy or not.
[02:16:23.480 --> 02:16:29.520]   We need we need more education and teaching people how to determine sort of trustworthy
[02:16:29.520 --> 02:16:31.240]   from not trustworthy.
[02:16:31.240 --> 02:16:35.520]   Here are some of the makes you if it makes you feel better, my daughter actually, they
[02:16:35.520 --> 02:16:38.040]   have media literacy starting in fourth grade.
[02:16:38.040 --> 02:16:39.040]   Great.
[02:16:39.040 --> 02:16:40.040]   Great.
[02:16:40.040 --> 02:16:43.520]   I think they're teacher to this from all tech considered on NPR.
[02:16:43.520 --> 02:16:49.640]   They did a really simple checklist for everybody on if you read something.
[02:16:49.640 --> 02:16:52.840]   Here's how you could just quickly, you know, here's what you should look at.
[02:16:52.840 --> 02:16:58.680]   Pay attention to the domain and the URL.
[02:16:58.680 --> 02:17:01.760]   Read the about us section.
[02:17:01.760 --> 02:17:06.640]   Look at the quotes in a story or rather look at the lack of quotes.
[02:17:06.640 --> 02:17:12.400]   Look at who said them, check the comments because a lot of times on social media platforms,
[02:17:12.400 --> 02:17:14.320]   people will say, Oh, that's fake.
[02:17:14.320 --> 02:17:15.720]   Here's the Snopes link.
[02:17:15.720 --> 02:17:17.560]   Oh, I love this one.
[02:17:17.560 --> 02:17:21.440]   If you see an image, do a reverse image search.
[02:17:21.440 --> 02:17:26.840]   You may find this a clip art that's been slightly modified.
[02:17:26.840 --> 02:17:31.400]   The really depressing thing from that survey was that there were obvious clues.
[02:17:31.400 --> 02:17:32.400]   Yeah.
[02:17:32.400 --> 02:17:36.440]   Like say, a piece of sponsored content said sponsored content on it.
[02:17:36.440 --> 02:17:42.640]   And they missed that or there was no verified checkmark and they missed that or they said
[02:17:42.640 --> 02:17:49.280]   the site looked really professional so they thought it was trustworthy.
[02:17:49.280 --> 02:17:50.440]   This is kind of a related.
[02:17:50.440 --> 02:17:52.800]   This is my one of the things I want to talk about.
[02:17:52.800 --> 02:17:54.560]   This is from dark patterns.org.
[02:17:54.560 --> 02:17:56.600]   We've talked before about dark patterns.
[02:17:56.600 --> 02:18:02.160]   You see it in software all the time, a user interface that's been designed to trick you
[02:18:02.160 --> 02:18:09.040]   into maybe downloading an additional bit of malware or signing up for a recurring bill.
[02:18:09.040 --> 02:18:14.360]   When I sign up for 18 or try to sign up for AT&T's direct TV now, I inadvertently got
[02:18:14.360 --> 02:18:18.480]   sucked into a $150 charge.
[02:18:18.480 --> 02:18:22.240]   So this is a site where you can browse the library of dark patterns.
[02:18:22.240 --> 02:18:28.320]   I think this is a great thing that high schools could probably do is just to make people aware
[02:18:28.320 --> 02:18:35.600]   of a lot of what the games you play, the sites you visit are really intending to trick you
[02:18:35.600 --> 02:18:39.840]   into doing something they want you to do using human psychology.
[02:18:39.840 --> 02:18:45.800]   So this is a UI professional who's designed a really great site with bait and switch,
[02:18:45.800 --> 02:18:54.160]   disguised ads, something the far away bill, which is this is from capital one.
[02:18:54.160 --> 02:18:58.800]   You check your credit card balance, suddenly a physical bill will no longer come to your
[02:18:58.800 --> 02:19:03.160]   door.
[02:19:03.160 --> 02:19:09.400]   These are tricks that I guarantee you every one of us has been bit by at some point and
[02:19:09.400 --> 02:19:11.280]   may not even know about.
[02:19:11.280 --> 02:19:20.800]   So there's one called privacy's Zuckering, which is a Facebook technique, the Roach
[02:19:20.800 --> 02:19:27.720]   Motel, the site that you can easy to get into, but pretty hard to get out of.
[02:19:27.720 --> 02:19:33.680]   Yeah, the sneak into basket where they sneak something into your shopping basket.
[02:19:33.680 --> 02:19:35.920]   Oh, that happens on hotel bills.
[02:19:35.920 --> 02:19:40.080]   I mean, that's in the real world where they're like, well, this is all real world.
[02:19:40.080 --> 02:19:48.080]   These, this library are actual sites, programs, stuff you might have been sucked into.
[02:19:48.080 --> 02:19:53.920]   My favorite is when you install something and it automatically checks boxes that say,
[02:19:53.920 --> 02:20:00.640]   hate that, you know, redirect my search to bang and load this thing and add this toolbar.
[02:20:00.640 --> 02:20:02.320]   We've all been bit.
[02:20:02.320 --> 02:20:03.320]   So this is a great site.
[02:20:03.320 --> 02:20:07.360]   And I think this would be a good one too to get high schoolers to visit dark patterns
[02:20:07.360 --> 02:20:08.880]   dot org.
[02:20:08.880 --> 02:20:10.520]   And you can submit additional patterns.
[02:20:10.520 --> 02:20:15.360]   These are a couple of UI designers who really think that maybe this is something we got
[02:20:15.360 --> 02:20:20.000]   to learn more about dark patterns dot org.
[02:20:20.000 --> 02:20:23.760]   Everybody, I thank you for your time and attention.
[02:20:23.760 --> 02:20:29.440]   I especially thank our hosts today, Matthew Ingram from fortune.com.
[02:20:29.440 --> 02:20:31.200]   Always a thrill and a pleasure.
[02:20:31.200 --> 02:20:34.400]   I'm glad to see you and talk to you every time.
[02:20:34.400 --> 02:20:35.400]   Thank you for being here.
[02:20:35.400 --> 02:20:36.400]   Thanks for having me.
[02:20:36.400 --> 02:20:37.400]   Yeah.
[02:20:37.400 --> 02:20:42.400]   And of course, the wonderful Stacey Higginbotham, who is an expert on IOT and Intel and everything
[02:20:42.400 --> 02:20:46.120]   else, you can read her stuff at IOT.
[02:20:46.120 --> 02:20:50.480]   Actually Stacey on IOT.com and listen to her podcast on IOT podcast.com that she does
[02:20:50.480 --> 02:20:58.080]   with the wonderful Kevin Tofel, another giga home survivor.
[02:20:58.080 --> 02:20:59.080]   You're all the survivors.
[02:20:59.080 --> 02:21:00.080]   Survivors.
[02:21:00.080 --> 02:21:01.720]   Thank you for being here.
[02:21:01.720 --> 02:21:02.720]   Survivors.
[02:21:02.720 --> 02:21:07.200]   Hey, one more thing I wanted to mention since we are heading up to Christmas, you know,
[02:21:07.200 --> 02:21:09.760]   when advent calendars are the big thing.
[02:21:09.760 --> 02:21:12.680]   This is the geekiest advent calendar I've ever seen.
[02:21:12.680 --> 02:21:16.000]   I don't know if if you know about chemo, which is an emu later.
[02:21:16.000 --> 02:21:17.000]   QEMU.
[02:21:17.000 --> 02:21:18.000]   QEMU.
[02:21:18.000 --> 02:21:25.680]   So every day through the 25th, a new chemo desk image, a disk image, the first one was
[02:21:25.680 --> 02:21:32.000]   an OS, then a desktop, then a gem, the free gem.
[02:21:32.000 --> 02:21:33.000]   Remember gem?
[02:21:33.000 --> 02:21:35.680]   The gem desktop.
[02:21:35.680 --> 02:21:39.920]   Here's a tower of Hanoi written in fourth, 3.6 kilobytes.
[02:21:39.920 --> 02:21:41.720]   All right.
[02:21:41.720 --> 02:21:44.760]   Here's an entire operating system and 660 kilobytes.
[02:21:44.760 --> 02:21:48.200]   So you have to have QEMU to do this.
[02:21:48.200 --> 02:21:52.280]   Here's a tribute for the anniversary, 35th anniversary of the PC.
[02:21:52.280 --> 02:21:54.840]   Remember donkey base, donkey duck base.
[02:21:54.840 --> 02:21:59.600]   So sorry ass is written in pure assembly, fits onto a floppy disk boot sector.
[02:21:59.600 --> 02:22:01.840]   It's less than 5k.
[02:22:01.840 --> 02:22:03.840]   And we'll let you play this wonderful game.
[02:22:03.840 --> 02:22:07.200]   And day eight is coming.
[02:22:07.200 --> 02:22:09.280]   So this is really fun.
[02:22:09.280 --> 02:22:10.280]   QEMU.
[02:22:10.280 --> 02:22:11.280]   That is, that's fun.
[02:22:11.280 --> 02:22:12.280]   I had one thing.
[02:22:12.280 --> 02:22:16.120]   I wanted to update people.
[02:22:16.120 --> 02:22:19.720]   My family finally got rid of their, because a lot of people are very concerned.
[02:22:19.720 --> 02:22:24.760]   They finally got rid of their note sevens and switched to the note seven bezel edge one.
[02:22:24.760 --> 02:22:25.760]   I know.
[02:22:25.760 --> 02:22:26.760]   QEMU.
[02:22:26.760 --> 02:22:27.760]   I'm relieved.
[02:22:27.760 --> 02:22:28.760]   QEMU.
[02:22:28.760 --> 02:22:31.280]   Yes, it finally got too much because Sam's son kept telling them every time a phone recall
[02:22:31.280 --> 02:22:33.800]   came in, it would be like, your device has been recalled.
[02:22:33.800 --> 02:22:34.800]   Are you aware of this?
[02:22:34.800 --> 02:22:37.360]   And they finally, wow, they really were punishing them, basically.
[02:22:37.360 --> 02:22:38.360]   They really would.
[02:22:38.360 --> 02:22:42.640]   I mean, when in charge, except to 60% and then constant messages.
[02:22:42.640 --> 02:22:43.640]   Wow.
[02:22:43.640 --> 02:22:48.480]   So they got the galaxy S seven no edge.
[02:22:48.480 --> 02:22:53.400]   Ah, yes, yes, yes, the fancy wrap around.
[02:22:53.400 --> 02:22:54.960]   Oh, they got the edge one.
[02:22:54.960 --> 02:22:56.120]   Oh, nice.
[02:22:56.120 --> 02:22:57.120]   That's a pretty one.
[02:22:57.120 --> 02:22:58.120]   I like that.
[02:22:58.120 --> 02:22:59.960]   Oh, well, we're glad they didn't blow up.
[02:22:59.960 --> 02:23:04.000]   So there you go for all the people, my family is now safe.
[02:23:04.000 --> 02:23:05.600]   We're very relieved.
[02:23:05.600 --> 02:23:06.600]   Good to hear them.
[02:23:06.600 --> 02:23:07.600]   Thank you for that update.
[02:23:07.600 --> 02:23:13.280]   We do this week in Google every Wednesday, 130 Pacific, 430 Eastern, 23rd, 21 30 UTC.
[02:23:13.280 --> 02:23:15.040]   If you'd like to join us live, I would love it if you would.
[02:23:15.040 --> 02:23:20.080]   But if you can't on demand, on your own video of every show available at Twit.tv in this
[02:23:20.080 --> 02:23:24.360]   case, Twit.tv slash twig.
[02:23:24.360 --> 02:23:27.600]   You'll also find it on your favorite podcatcher.
[02:23:27.600 --> 02:23:28.600]   Do subscribe.
[02:23:28.600 --> 02:23:29.600]   We'd like to get you every day.
[02:23:29.600 --> 02:23:32.760]   Oh, and we're opening a store.
[02:23:32.760 --> 02:23:35.440]   Well, this is actually our new Teespring.
[02:23:35.440 --> 02:23:36.800]   Teespring.com.
[02:23:36.800 --> 02:23:38.680]   This is just in time for the holidays.
[02:23:38.680 --> 02:23:44.000]   If you have a Twit fanatic in your family, you can have them join the Twit army.
[02:23:44.000 --> 02:23:49.800]   Our newest t-shirt design from Teespring is at t-w-e-s-p-r-i-n-g.com/twit.
[02:23:49.800 --> 02:23:55.200]   We felt so bad about the Mary Twitmas shirts, which nobody bought.
[02:23:55.200 --> 02:24:00.640]   We've created an emergency sale.
[02:24:00.640 --> 02:24:09.560]   If you order by December 15th, I think they promised that it will come in time for Christmas.
[02:24:09.560 --> 02:24:10.560]   We're going to cut it off.
[02:24:10.560 --> 02:24:14.040]   We're only going to give you seven days because we want to make sure you get this in time
[02:24:14.040 --> 02:24:16.360]   for Christmas or Hanukkah or whatever.
[02:24:16.360 --> 02:24:20.760]   There's t-shirts, there's tank tops, and a very nice hoodie.
[02:24:20.760 --> 02:24:22.960]   I would actually really like that hoodie.
[02:24:22.960 --> 02:24:27.440]   In the Twit army, or really more like the Twit Air Force, isn't it?
[02:24:27.440 --> 02:24:28.440]   They're affordably priced.
[02:24:28.440 --> 02:24:29.600]   The T is $22.99.
[02:24:29.600 --> 02:24:33.920]   It comes in a variety of colors from a variety of manufacturers.
[02:24:33.920 --> 02:24:37.840]   It is officially licensed apparel.
[02:24:37.840 --> 02:24:38.840]   Teespring.
[02:24:38.840 --> 02:24:40.160]   T-w-e-spring.com/twit.
[02:24:40.160 --> 02:24:42.120]   It's Christmica.
[02:24:42.120 --> 02:24:45.280]   I'm informed.
[02:24:45.280 --> 02:24:47.960]   Mary Christmica.
[02:24:47.960 --> 02:24:48.960]   Happy Kwanzaa.
[02:24:48.960 --> 02:24:52.120]   Thank you all for being here, and we'll see you next time on Twig.
[02:24:52.120 --> 02:25:01.580]   [Music]

