;FFMETADATA1
title=Indoctrinized and Radicalated
artist=Leo Laporte, Jeff Jarvis, Glenn Fleishman, Kevin Marks
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2022-10-20
track=686
language=English
genre=Podcast
comment=Ye to buy Parler, Musk's absolute Twitter control, Bluesky roadmap
encoded_by=Uniblab 5.3
date=2022
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.320]   It's time for Twig this week in Google and Stacey of the Week Off.
[00:00:04.320 --> 00:00:09.560]   So I'm thrilled to say Jeff Jarvis, Glenn Fleischman, and Kevin Marks join us this week
[00:00:09.560 --> 00:00:17.600]   to talk about Kanye, Elon, and Donald, the new big social media owners.
[00:00:17.600 --> 00:00:21.440]   We'll talk about Jack Dorsey's blue sky initiative.
[00:00:21.440 --> 00:00:24.360]   In fact, Kevin's going to weigh in on the new protocol.
[00:00:24.360 --> 00:00:31.160]   Can this be the future of Twitter and all social media and how TikTok ate the internet?
[00:00:31.160 --> 00:00:32.160]   Mm-hmm.
[00:00:32.160 --> 00:00:33.160]   Good.
[00:00:33.160 --> 00:00:37.560]   It's all coming up next on Twig.
[00:00:37.560 --> 00:00:41.560]   Podcasts you love from people you trust.
[00:00:41.560 --> 00:00:48.320]   This is Twig.
[00:00:48.320 --> 00:00:56.720]   This is Twig, this week in Google, Episode 686, recorded Wednesday, October 19, 2022,
[00:00:56.720 --> 00:01:00.240]   in Doctrineized and Radicalated.
[00:01:00.240 --> 00:01:04.920]   This episode of This Week in Google is brought to you by ITProTV.
[00:01:04.920 --> 00:01:09.600]   If you're looking to break into the world of IT or if your IT team needs to level up,
[00:01:09.600 --> 00:01:12.960]   get the introduction you need with ITProTV.
[00:01:12.960 --> 00:01:20.560]   Check out an ITProTV business plan by visiting itpro.tv/twit today.
[00:01:20.560 --> 00:01:27.560]   And by HPE GreenLake, orchestrated by the experts at CDW, who can help you consolidate
[00:01:27.560 --> 00:01:34.240]   and manage all your data in one flexible, edge-to-cloud platform to scale and innovate.
[00:01:34.240 --> 00:01:38.720]   Learn more at CDW.com/HPE.
[00:01:38.720 --> 00:01:40.400]   And by Nureva.
[00:01:40.400 --> 00:01:44.280]   Nureva has simplified everything about meetings and classroom audio.
[00:01:44.280 --> 00:01:48.280]   You get great audio and systems that are easy to install and manage.
[00:01:48.280 --> 00:01:54.800]   Visit nureva.com/twit and get 50% off one Nureva HDL 300 system for mid-sized rooms
[00:01:54.800 --> 00:02:02.160]   when you get a live online demo and by before December 16, 2022.
[00:02:02.160 --> 00:02:06.320]   It's time for Twig this week in Google to show where we get together with our favorite
[00:02:06.320 --> 00:02:07.800]   Google Versions.
[00:02:07.800 --> 00:02:12.800]   Let's talk about Twitter, Facebook and everything else.
[00:02:12.800 --> 00:02:26.740]   Jeff Jarvis is a UN
[00:02:26.740 --> 00:02:32.840]   It's the same Logitech, but I just adjusted, I've got to play with the adjusting.
[00:02:32.840 --> 00:02:34.040]   It looks really good.
[00:02:34.040 --> 00:02:35.020]   I'll have to adjust again.
[00:02:35.020 --> 00:02:36.420]   Yeah, now it looks actually good.
[00:02:36.420 --> 00:02:37.420]   Like a lot.
[00:02:37.420 --> 00:02:38.420]   You look normal.
[00:02:38.420 --> 00:02:39.420]   Yeah.
[00:02:39.420 --> 00:02:42.440]   You look like you have to play with the weight balance and the exposure time and the gain
[00:02:42.440 --> 00:02:43.440]   and the brightness.
[00:02:43.440 --> 00:02:44.520]   You look like a really good rotation.
[00:02:44.520 --> 00:02:49.500]   He's got a hold of you and it's just really really clean.
[00:02:49.500 --> 00:02:50.500]   Yep.
[00:02:50.500 --> 00:02:51.560]   Good.
[00:02:51.560 --> 00:02:53.800]   Stacy has the weak off.
[00:02:53.800 --> 00:02:55.020]   So does Aunt Pruitt.
[00:02:55.020 --> 00:02:57.620]   Has the weak off, but good news.
[00:02:57.620 --> 00:02:58.620]   Glenn Fleischman's here.
[00:02:58.620 --> 00:03:01.140]   We always love having Glenn on Glenn.
[00:03:01.140 --> 00:03:02.140]   Hello, Glenn.
[00:03:02.140 --> 00:03:03.140]   Hello.
[00:03:03.140 --> 00:03:04.140]   How are you all?
[00:03:04.140 --> 00:03:05.140]   Great to see you.
[00:03:05.140 --> 00:03:11.620]   You've been on a jaunt across the Great Midwest in search of lead.
[00:03:11.620 --> 00:03:12.620]   Right.
[00:03:12.620 --> 00:03:16.900]   I went to the, I went to, there should be a song for this, the Billy Ireland Cartoon
[00:03:16.900 --> 00:03:21.940]   Library, a museum at the OSU, the Ohio State University Libraries.
[00:03:21.940 --> 00:03:24.620]   Is this the Cartoon Library or a...
[00:03:24.620 --> 00:03:25.620]   Cartoon Library.
[00:03:25.620 --> 00:03:28.180]   It's a, hey, but it's a very good one.
[00:03:28.180 --> 00:03:29.820]   They have an amazing collection.
[00:03:29.820 --> 00:03:35.740]   They have an upcoming exhibition that's going to show off the collection of Bill Blackbeard,
[00:03:35.740 --> 00:03:36.740]   great name.
[00:03:36.740 --> 00:03:42.500]   A guy who in a San Francisco rental house, accumulated millions of comic strips, whether
[00:03:42.500 --> 00:03:44.980]   they're being thrown out and geek session by newspapers.
[00:03:44.980 --> 00:03:45.980]   Oh wow.
[00:03:45.980 --> 00:03:46.980]   So that's what won it.
[00:03:46.980 --> 00:03:49.740]   It's an amazing collection, an un-reproducible collection.
[00:03:49.740 --> 00:03:54.460]   And they're about to do an exhibition celebrating the 25th anniversary of having acquired that
[00:03:54.460 --> 00:03:56.380]   from the now late Mr. Blackbeard.
[00:03:56.380 --> 00:04:00.540]   Because we do have in San Francisco a, not a great cartoon library.
[00:04:00.540 --> 00:04:03.340]   And I would imagine other cities have something similar.
[00:04:03.340 --> 00:04:05.900]   This looks like a scholarly library of cartoons.
[00:04:05.900 --> 00:04:06.900]   Yeah.
[00:04:06.900 --> 00:04:07.900]   Yeah.
[00:04:07.900 --> 00:04:11.740]   They're great exhibitions, nice exhibition space and they're, but they're archives.
[00:04:11.740 --> 00:04:16.140]   They pulled stuff out from the back for me and it was, it was a glorious few days of
[00:04:16.140 --> 00:04:18.140]   sitting in a room and staring at things.
[00:04:18.140 --> 00:04:21.380]   So you, as an archive is happy to have you there, oh, let me show you this.
[00:04:21.380 --> 00:04:22.380]   Let me show you that.
[00:04:22.380 --> 00:04:23.380]   Kind of like that, I can't say.
[00:04:23.380 --> 00:04:24.380]   Absolutely.
[00:04:24.380 --> 00:04:27.700]   So they answered questions about printing and looked at things and got answers.
[00:04:27.700 --> 00:04:28.700]   Oh, interesting.
[00:04:28.700 --> 00:04:31.460]   So you were there not merely as a visitor.
[00:04:31.460 --> 00:04:33.260]   You were there as an expert.
[00:04:33.260 --> 00:04:37.740]   I have developed the, as you know, a very strange expertise and very, very niche subjects.
[00:04:37.740 --> 00:04:43.180]   And so I've got a video that's in this upcoming exhibition about the Blackbeard and about
[00:04:43.180 --> 00:04:49.060]   how comics were printed or syndicated and then printed in the metal type era.
[00:04:49.060 --> 00:04:52.540]   So I did a video for them that will be running during the exhibition, which is very exciting.
[00:04:52.540 --> 00:04:54.460]   And just participation and exhibition.
[00:04:54.460 --> 00:04:57.740]   Did you bring this an opportunity to explain the phrase boilerplate?
[00:04:57.740 --> 00:05:02.460]   Oh, not in that one, but I could, but you know, okay, hold something back for later when
[00:05:02.460 --> 00:05:03.460]   it's good.
[00:05:03.460 --> 00:05:07.500]   Did you bring any loot back from your trip?
[00:05:07.500 --> 00:05:09.980]   No, unfortunately, no, no loot.
[00:05:09.980 --> 00:05:12.620]   Well, actually I have a new flong, but it's too boring to show.
[00:05:12.620 --> 00:05:13.620]   Oh, somewhat.
[00:05:13.620 --> 00:05:15.660]   I want to hear about the next.
[00:05:15.660 --> 00:05:17.460]   Wait, I'll unpack later later.
[00:05:17.460 --> 00:05:19.620]   I'll get up at some point and I'll show some metal type.
[00:05:19.620 --> 00:05:21.020]   I did pick up along the way.
[00:05:21.020 --> 00:05:22.020]   Oh, excellent.
[00:05:22.020 --> 00:05:24.020]   I want to hear about the next visit.
[00:05:24.020 --> 00:05:28.740]   The TSA had to inspect my luggage because I was carrying pounds of metal type, lead type
[00:05:28.740 --> 00:05:29.740]   back.
[00:05:29.740 --> 00:05:32.140]   How heavy was your bag?
[00:05:32.140 --> 00:05:34.700]   It was pretty heavy.
[00:05:34.700 --> 00:05:42.340]   So you went to a collection of type foundry machines and materials, yes?
[00:05:42.340 --> 00:05:47.020]   Yeah, there's this lovely fellow who passed away early this year in his 70s, Greg Walters,
[00:05:47.020 --> 00:05:52.740]   and he spent a good chunk of his life acquiring American type founding and type casting equipment.
[00:05:52.740 --> 00:05:56.380]   So the stuff that was used to make metal type for printers.
[00:05:56.380 --> 00:06:00.100]   And it all, you know, it over by the 80s, nobody wanted this stuff.
[00:06:00.100 --> 00:06:01.740]   It was being thrown out and junked.
[00:06:01.740 --> 00:06:03.980]   And fortunately, this is kind of like the Bill Blackbeard story.
[00:06:03.980 --> 00:06:08.180]   He and a few other people have been having rigor, have been collecting it and keeping
[00:06:08.180 --> 00:06:14.100]   it, many of them keeping it in use and learning how to use it or refurbishing it.
[00:06:14.100 --> 00:06:20.460]   So Greg passed away and some of his friends and colleagues have been working to consolidate
[00:06:20.460 --> 00:06:21.460]   his collection.
[00:06:21.460 --> 00:06:25.660]   He's got a giant barn in Piqua, Ohio, apparently home of Captain Underpants.
[00:06:25.660 --> 00:06:29.540]   I learned after being a little bit of a love cat.
[00:06:29.540 --> 00:06:30.540]   Yeah.
[00:06:30.540 --> 00:06:31.540]   Kids grew up on cat underpants.
[00:06:31.540 --> 00:06:33.900]   Glad if you read this.
[00:06:33.900 --> 00:06:34.900]   I have not.
[00:06:34.900 --> 00:06:35.900]   I know of that book.
[00:06:35.900 --> 00:06:40.260]   That's very hard to find alcohol, tobacco and firearms.
[00:06:40.260 --> 00:06:42.180]   American type founders.
[00:06:42.180 --> 00:06:43.180]   Oh.
[00:06:43.180 --> 00:06:47.100]   The, there were independent when they, before the line of type, there were independent type
[00:06:47.100 --> 00:06:49.820]   foundries doing different sizes, different this, different that.
[00:06:49.820 --> 00:06:54.140]   And with the line of type and the other type of machine hit, they knew they were doomed.
[00:06:54.140 --> 00:06:57.580]   And so they combined eventually into one company.
[00:06:57.580 --> 00:06:58.580]   And it was American type.
[00:06:58.580 --> 00:07:00.780]   Yeah, there was a legal combine.
[00:07:00.780 --> 00:07:04.620]   They were allowed because if they'd gone into business, there would have been no independent
[00:07:04.620 --> 00:07:07.020]   type production in America, which is kind of a big deal.
[00:07:07.020 --> 00:07:10.900]   I mean, we don't think about it now, but it was there were hundreds of thousands of individual
[00:07:10.900 --> 00:07:17.260]   printers and they needed type to set the work for businesses and academic institutions
[00:07:17.260 --> 00:07:18.260]   all over the country.
[00:07:18.260 --> 00:07:20.060]   They made little boxes like this.
[00:07:20.060 --> 00:07:21.060]   Yeah.
[00:07:21.060 --> 00:07:22.060]   Well, so.
[00:07:22.060 --> 00:07:25.940]   We, I, we thought we were going to have Kevin Marks on.
[00:07:25.940 --> 00:07:26.940]   He's scheduled to be on.
[00:07:26.940 --> 00:07:32.060]   If he shows up, I'm going to hold a story until he shows up.
[00:07:32.060 --> 00:07:37.060]   But one of the big stories this week is we're starting to see for the first time a sort
[00:07:37.060 --> 00:07:43.060]   of an API for blue sky or at least a roadmap for decentralized networks.
[00:07:43.060 --> 00:07:49.940]   And because Kevin is all about open standards on the web, I'm going to, we'll get to this
[00:07:49.940 --> 00:07:52.060]   if he shows up, I'll hold it until he shows up.
[00:07:52.060 --> 00:07:53.060]   Otherwise, we'll get to it.
[00:07:53.060 --> 00:07:55.660]   And let's note to the next week you have rabble on.
[00:07:55.660 --> 00:07:56.660]   And rabble is going to be on.
[00:07:56.660 --> 00:07:57.660]   Yeah.
[00:07:57.660 --> 00:08:01.260]   So we're really, this is, we're going to be delving into this whole idea of social networks
[00:08:01.260 --> 00:08:03.220]   and federated social networks.
[00:08:03.220 --> 00:08:08.220]   And then we'll create something that you were talking about with Mike Masnick some weeks
[00:08:08.220 --> 00:08:11.340]   ago and you, you set me up with it.
[00:08:11.340 --> 00:08:12.540]   And he saw that I had joined.
[00:08:12.540 --> 00:08:13.540]   It's called planetary.
[00:08:13.540 --> 00:08:18.340]   There hasn't been much activity on planetary.
[00:08:18.340 --> 00:08:21.980]   But I did create an account and followed him.
[00:08:21.980 --> 00:08:25.700]   He also worked at Odeo and at Twitter and worked on blue sky and knows a lot about blue
[00:08:25.700 --> 00:08:26.700]   sky.
[00:08:26.700 --> 00:08:30.660]   So anything we say today is just a preliminary to what we might talk about next week when
[00:08:30.660 --> 00:08:31.660]   rabble.
[00:08:31.660 --> 00:08:32.660]   We'll wait until that discussion.
[00:08:32.660 --> 00:08:39.220]   But in the meantime, well, I thought in the meantime, we could still talk about social
[00:08:39.220 --> 00:08:48.940]   networks because now we have yay and musk and Trump potentially owning three of the biggest,
[00:08:48.940 --> 00:08:51.260]   well, not biggest, most prominent.
[00:08:51.260 --> 00:08:54.460]   I don't even know three social networks.
[00:08:54.460 --> 00:08:55.980]   One big network and two other things.
[00:08:55.980 --> 00:08:58.820]   Yeah, two other lesser networks, Twitter, of course.
[00:08:58.820 --> 00:09:04.260]   Kind of makes you miss Jack and think that Mark Zuckerberg isn't so bad.
[00:09:04.260 --> 00:09:09.100]   Folks, there's no one you had when you had it.
[00:09:09.100 --> 00:09:15.500]   So I don't even know where to dip into this devil's food cake of fun.
[00:09:15.500 --> 00:09:19.620]   But I guess we could start with Kanye West, the artist formerly known as Kanye West,
[00:09:19.620 --> 00:09:26.160]   now known as yay, who after being booted off of Instagram and Twitter for blatantly
[00:09:26.160 --> 00:09:35.080]   racist and any semantic postings has decided, by the way, not a coincidence shortly before
[00:09:35.080 --> 00:09:43.560]   those tweets and Instagram posts, he was seen at New York Fashion Week in a white lives matter
[00:09:43.560 --> 00:09:47.040]   outfit, which I guess if you're given the benefit of the doubt could be some sort of
[00:09:47.040 --> 00:09:49.600]   social commentary, I don't know.
[00:09:49.600 --> 00:09:54.520]   White lives matter standing next to Candace Owens was also wearing a white lives matter
[00:09:54.520 --> 00:09:55.520]   t-shirt.
[00:09:55.520 --> 00:10:02.560]   He is the wife of the founder of Parler, which Kanye has now announced that he wishes to
[00:10:02.560 --> 00:10:11.200]   buy in light of his being banned from Meta's Instagram and Twitter.
[00:10:11.200 --> 00:10:16.920]   Now the whistleblower or a leaker, I don't know what you call him, from Parler says,
[00:10:16.920 --> 00:10:20.640]   Parler only has about 50,000 daily active users, which is a goodly number.
[00:10:20.640 --> 00:10:22.120]   I bet you it's more than Mastodon.
[00:10:22.120 --> 00:10:27.640]   But anyway, 50,000 is not an insignificant number, but it's not 300 million, which is
[00:10:27.640 --> 00:10:28.640]   what Twitter has.
[00:10:28.640 --> 00:10:35.640]   50 million daily active users, 50,000, I did say 50,000, and that's correct, 50,000.
[00:10:35.640 --> 00:10:42.200]   And this same leaker said and is what they've been shopping it for some time at a wildly
[00:10:42.200 --> 00:10:43.600]   overblown valuation.
[00:10:43.600 --> 00:10:45.400]   We still don't know what that amount of money is.
[00:10:45.400 --> 00:10:47.960]   Kanye is one of the richest musicians in the world.
[00:10:47.960 --> 00:10:52.520]   He's worth $6 billion.
[00:10:52.520 --> 00:10:54.520]   But he could probably afford Parler.
[00:10:54.520 --> 00:10:57.040]   I've come over who said it.
[00:10:57.040 --> 00:10:58.200]   I was just saw this the other day.
[00:10:58.200 --> 00:11:01.800]   It might have been Ryan Broderick who runs the garbage day newsletter.
[00:11:01.800 --> 00:11:07.160]   But it was that when you're an angry middle-aged or older man and someone tells you you can't
[00:11:07.160 --> 00:11:09.960]   say something, you buy a social network now.
[00:11:09.960 --> 00:11:12.600]   Yeah, that seems to be the case.
[00:11:12.600 --> 00:11:19.720]   Elon, certainly one of the motivations for him bidding, $44 billion for Twitter, was
[00:11:19.720 --> 00:11:24.840]   President Trump's deep quote, deep platforming, getting kicked off of Twitter.
[00:11:24.840 --> 00:11:31.080]   Mike Masnick says that, "Yay is being taken advantage of."
[00:11:31.080 --> 00:11:34.760]   Yes, that's kind of the consensus.
[00:11:34.760 --> 00:11:37.040]   A lot of people say, "Well, he's mentally ill.
[00:11:37.040 --> 00:11:38.760]   We have to give him a pass."
[00:11:38.760 --> 00:11:39.760]   I don't know.
[00:11:39.760 --> 00:11:40.760]   Really?
[00:11:40.760 --> 00:11:41.760]   I don't know.
[00:11:41.760 --> 00:11:45.600]   You're all on some spectrum of the list.
[00:11:45.600 --> 00:11:48.240]   You can have this as a thing.
[00:11:48.240 --> 00:11:52.760]   A lot of things can attribute to people who are in mental health crises.
[00:11:52.760 --> 00:11:54.960]   But there's a lot of people with mental health issues.
[00:11:54.960 --> 00:11:58.000]   There's a huge number of people who have them.
[00:11:58.000 --> 00:12:02.400]   A very, very, very small number of them are jerks in relative terms.
[00:12:02.400 --> 00:12:05.680]   Compared to the rest of the population, having a mental health problem doesn't mean you
[00:12:05.680 --> 00:12:09.640]   kill people, doesn't mean you're a jerk, doesn't mean you don't listen to people.
[00:12:09.640 --> 00:12:16.040]   Kanye or he could be both a terrible person and be in a mental health crisis.
[00:12:16.040 --> 00:12:18.120]   And so you're allowed to have sympathy both.
[00:12:18.120 --> 00:12:19.120]   He could be both.
[00:12:19.120 --> 00:12:20.120]   Yeah, right.
[00:12:20.120 --> 00:12:21.120]   He could be both.
[00:12:21.120 --> 00:12:22.120]   He could be both.
[00:12:22.120 --> 00:12:23.120]   I mean, there's nothing that's possible.
[00:12:23.120 --> 00:12:24.120]   He doesn't get a pass.
[00:12:24.120 --> 00:12:25.120]   Right.
[00:12:25.120 --> 00:12:26.600]   You have to look at his actions.
[00:12:26.600 --> 00:12:27.600]   Yeah.
[00:12:27.600 --> 00:12:31.000]   I mean, you can worry about his behavior and you wish there's people who he could listen
[00:12:31.000 --> 00:12:34.600]   to, but he's far too wealthy for anyone to tell him not to do something or for him to
[00:12:34.600 --> 00:12:35.600]   listen.
[00:12:35.600 --> 00:12:37.440]   And he's not going to be put into a conservatorship.
[00:12:37.440 --> 00:12:40.040]   He's certainly in control enough of his affairs.
[00:12:40.040 --> 00:12:45.440]   But you're like, it seems like he's engaged in self-destructive and erratic behavior.
[00:12:45.440 --> 00:12:46.440]   And that's one thing.
[00:12:46.440 --> 00:12:50.720]   But the other is he's doing things that are intentionally harmful and damaging to groups
[00:12:50.720 --> 00:12:51.720]   of people and individuals.
[00:12:51.720 --> 00:12:56.320]   I mean, he was practically stalking David's at one point when David's was dating his
[00:12:56.320 --> 00:12:57.320]   son.
[00:12:57.320 --> 00:12:58.320]   He still is.
[00:12:58.320 --> 00:13:00.600]   I mean, he tweeted he was a hero and he's been saying all sorts of that.
[00:13:00.600 --> 00:13:05.080]   So this is what Elon posted this morning and it immediately took down.
[00:13:05.080 --> 00:13:10.480]   The three, Elon says in retrospect, where's the fourth horseman of the apocalypse?
[00:13:10.480 --> 00:13:13.080]   In retrospect, it was inevitable there.
[00:13:13.080 --> 00:13:20.560]   It's a Trump musk and yay dressed as musketeers with their swords, parlor truth, social interestingly,
[00:13:20.560 --> 00:13:27.640]   musk does not say Twitter, but says X because of course that's his plan, I guess, his his
[00:13:27.640 --> 00:13:30.840]   evil genius, Dr. No plan.
[00:13:30.840 --> 00:13:32.240]   Yeah.
[00:13:32.240 --> 00:13:35.760]   Yeah, in retrospect, it was inevitable.
[00:13:35.760 --> 00:13:37.840]   Is it the end of these kinds of social media?
[00:13:37.840 --> 00:13:44.640]   I mean, this is it's increasingly it must post this.
[00:13:44.640 --> 00:13:51.440]   This tells you that his plans for Twitter are not completely neutral or benign.
[00:13:51.440 --> 00:13:52.440]   Right?
[00:13:52.440 --> 00:13:54.160]   What do you think first?
[00:13:54.160 --> 00:13:59.480]   Moderation is already a problem on the best moderated platform among those three would
[00:13:59.480 --> 00:14:00.480]   be Twitter.
[00:14:00.480 --> 00:14:01.960]   And it's a huge problem.
[00:14:01.960 --> 00:14:08.680]   They have a huge issues with people being brigaded and dog piled and harassed and celebrities
[00:14:08.680 --> 00:14:12.240]   deciding whether celebrities you might like and agree with or celebrities that you think
[00:14:12.240 --> 00:14:19.760]   are odious or other political figures, figuring out ways to weaponize Twitter to attack people
[00:14:19.760 --> 00:14:22.320]   to point all their followers to them and produce harm.
[00:14:22.320 --> 00:14:26.360]   So Twitter already has that problem and musk looks at that and says there's not enough
[00:14:26.360 --> 00:14:27.360]   free speech there.
[00:14:27.360 --> 00:14:28.360]   Yeah.
[00:14:28.360 --> 00:14:29.760]   There's too much control going on there.
[00:14:29.760 --> 00:14:34.320]   So most social networks, I think thrive by the participation of a relatively small number
[00:14:34.320 --> 00:14:37.120]   of people who make it worthwhile to be there.
[00:14:37.120 --> 00:14:42.440]   And by some kind of oversight that keeps the noise just low enough that enough people stay
[00:14:42.440 --> 00:14:44.800]   there that it's worthwhile to advertisers.
[00:14:44.800 --> 00:14:50.440]   So musk is basically going to drive off the people who are already like on the fence about
[00:14:50.440 --> 00:14:55.280]   staying on Twitter, whether celebrities or Jeff Jarvis is of the world, probably, right?
[00:14:55.280 --> 00:14:59.720]   Jeff and then also the people who come there for some amount of content.
[00:14:59.720 --> 00:15:05.000]   Some amount of some participation, parasocial or otherwise, they're going to leave too when
[00:15:05.000 --> 00:15:08.720]   it's all noise, when it's all garbage.
[00:15:08.720 --> 00:15:18.040]   So I tweeted this slide during the week that the extremes now see speech as censorship.
[00:15:18.040 --> 00:15:19.040]   You can't cancel me.
[00:15:19.040 --> 00:15:20.840]   You can't criticize me.
[00:15:20.840 --> 00:15:26.440]   And they see moderation and editing and publishing and choice as censorship.
[00:15:26.440 --> 00:15:30.000]   And they don't see, of course, the paradox of that because they want to have their say
[00:15:30.000 --> 00:15:32.160]   whatever they want to do.
[00:15:32.160 --> 00:15:38.440]   And yeah, I think it's the death of that kind of corporately controlled platform, potentially.
[00:15:38.440 --> 00:15:39.880]   We're not there yet.
[00:15:39.880 --> 00:15:43.600]   Must doesn't own it yet.
[00:15:43.600 --> 00:15:50.720]   And that's why the blue sky and planetary discussion is so interesting.
[00:15:50.720 --> 00:15:51.720]   Is there an opportunity for a more...
[00:15:51.720 --> 00:15:54.000]   This might be the time, right?
[00:15:54.000 --> 00:15:56.600]   I put another story in the rundown.
[00:15:56.600 --> 00:16:01.400]   Well, before we do, I just want to mention real quickly, the fifth district did this
[00:16:01.400 --> 00:16:09.720]   week and I think in good news, it's good news, delay the enforcement of Texas's social media
[00:16:09.720 --> 00:16:10.720]   law.
[00:16:10.720 --> 00:16:17.400]   So now both Florida and Texas's questionable social media laws are on hold until, according
[00:16:17.400 --> 00:16:20.080]   to the fifth district, the Supreme Court weighs in on this.
[00:16:20.080 --> 00:16:25.240]   They haven't agreed to take it, but either do not take it or to agree to take it.
[00:16:25.240 --> 00:16:26.440]   It seems so prima fascia.
[00:16:26.440 --> 00:16:31.520]   I mean, I'm not a constitutional lawyer, but I think that everything I've read makes it
[00:16:31.520 --> 00:16:36.120]   sound like this is so blatantly unconstitutional, except if the Supreme Court decides to carve
[00:16:36.120 --> 00:16:38.280]   out something that then is constitutional.
[00:16:38.280 --> 00:16:39.280]   Then it's constitutional.
[00:16:39.280 --> 00:16:42.400]   You know, it's the magic constitutional one, but I don't think so.
[00:16:42.400 --> 00:16:47.440]   I don't think this falls inside the purview of the things that the conservative majority
[00:16:47.440 --> 00:16:48.600]   court wants to do.
[00:16:48.600 --> 00:16:57.480]   I don't think they don't seem to be eager to restrict speech by commercial entities,
[00:16:57.480 --> 00:17:01.480]   even if it's anti-conservative speech or whatever might be alleged.
[00:17:01.480 --> 00:17:02.480]   Yeah.
[00:17:02.480 --> 00:17:08.280]   Somebody I think we pointed out last week, Kanye's evil tweets had the Texas law been
[00:17:08.280 --> 00:17:13.720]   in effect, could have been Texas could have forced them to not take them down.
[00:17:13.720 --> 00:17:19.000]   So effectively bans moderation on large social networks.
[00:17:19.000 --> 00:17:23.040]   Jeff, I thought Jeff, what you're saying is I think you have the same people saying,
[00:17:23.040 --> 00:17:26.440]   don't say gay and saying, I want to be able to say the-
[00:17:26.440 --> 00:17:27.440]   Whatever I want.
[00:17:27.440 --> 00:17:28.440]   Yeah.
[00:17:28.440 --> 00:17:29.440]   For about gay people.
[00:17:29.440 --> 00:17:36.040]   And I'm like, those are so obviously contradictory that they are fascist in nature, right?
[00:17:36.040 --> 00:17:37.680]   There's no way to interpret that.
[00:17:37.680 --> 00:17:38.680]   Yes.
[00:17:38.680 --> 00:17:40.360]   Speak for me and not for thee.
[00:17:40.360 --> 00:17:41.360]   Exactly.
[00:17:41.360 --> 00:17:46.640]   They couch it in all this approach as if it is some kind of free speech maximalism.
[00:17:46.640 --> 00:17:47.960]   And then they're constantly, right?
[00:17:47.960 --> 00:17:49.280]   The cancel culture, everything else.
[00:17:49.280 --> 00:17:54.240]   They don't want people to say anything that is outside of what they think is okay to say.
[00:17:54.240 --> 00:18:00.200]   That means pretty clear to me at this point that after four years of Donald Trump, the
[00:18:00.200 --> 00:18:05.320]   lesson learned by some people was deny and lie.
[00:18:05.320 --> 00:18:09.600]   You could say anything you want, even if it's clearly not fact-willed based.
[00:18:09.600 --> 00:18:16.840]   Just say whatever you want, say what and so any inconsistency in that, they just gloss
[00:18:16.840 --> 00:18:22.920]   over and the people who believe in them and support them will go along with it and the
[00:18:22.920 --> 00:18:25.080]   rest of us didn't like them much anyway.
[00:18:25.080 --> 00:18:26.440]   So there you go.
[00:18:26.440 --> 00:18:27.720]   But the point is here to people.
[00:18:27.720 --> 00:18:29.080]   The point is to own the libs.
[00:18:29.080 --> 00:18:30.560]   The point is to be in directions.
[00:18:30.560 --> 00:18:31.560]   I don't know what the point is.
[00:18:31.560 --> 00:18:33.280]   It doesn't matter what you say.
[00:18:33.280 --> 00:18:37.040]   Ultimately, that's the real point is to gain power.
[00:18:37.040 --> 00:18:38.040]   Yes.
[00:18:38.040 --> 00:18:40.080]   Not to irritate the libs, but the way you do it.
[00:18:40.080 --> 00:18:45.080]   Well, but the way you do it, there's a group of people in the world for whom the goal is
[00:18:45.080 --> 00:18:47.800]   to irritate the libs and they will vote for you.
[00:18:47.800 --> 00:18:48.800]   And you, exactly.
[00:18:48.800 --> 00:18:49.800]   Yeah, and they will vote for you.
[00:18:49.800 --> 00:18:57.920]   But I don't have, I am not at all saying when about Ron DeSantis or any of these people,
[00:18:57.920 --> 00:18:59.680]   their intent is not to irritate the libs.
[00:18:59.680 --> 00:19:01.800]   They're just using that as a way to get elected.
[00:19:01.800 --> 00:19:04.640]   Their intent is to consolidate power.
[00:19:04.640 --> 00:19:07.640]   Their intent is to destroy what there's another paradox here.
[00:19:07.640 --> 00:19:10.160]   Their intent is to destroy the institutions of democracy.
[00:19:10.160 --> 00:19:11.160]   Yeah, because that's how...
[00:19:11.160 --> 00:19:12.160]   That's how the autocrats do.
[00:19:12.160 --> 00:19:14.040]   They know and they have said, they've said it.
[00:19:14.040 --> 00:19:15.200]   They've said the quiet part out loud.
[00:19:15.200 --> 00:19:17.320]   We can't win if we don't.
[00:19:17.320 --> 00:19:18.320]   Right.
[00:19:18.320 --> 00:19:21.840]   And so they know that they only have 30 or 40% of the populace.
[00:19:21.840 --> 00:19:26.520]   And so they don't, just as Hitler did not have a majority in Weimar Germany, they know
[00:19:26.520 --> 00:19:31.280]   that they have to win by other means and they've used this social platform, not the social
[00:19:31.280 --> 00:19:35.480]   media platform, but the social platform of gay marriage and abortion and all of these
[00:19:35.480 --> 00:19:36.480]   things to convince...
[00:19:36.480 --> 00:19:37.480]   Where's your Hitler jar?
[00:19:37.480 --> 00:19:39.280]   You have to put $5 in the Hitler jar.
[00:19:39.280 --> 00:19:41.040]   Oh, that one is a full jar.
[00:19:41.040 --> 00:19:42.040]   There's no room.
[00:19:42.040 --> 00:19:43.040]   That's bulging.
[00:19:43.040 --> 00:19:44.040]   No room elected in the Hitler jar.
[00:19:44.040 --> 00:19:47.800]   I think Godwin has given a past solution for...
[00:19:47.800 --> 00:19:50.200]   God was given us a past today.
[00:19:50.200 --> 00:19:51.560]   No, but it's true, right.
[00:19:51.560 --> 00:19:58.560]   Democracy, a minoritarian governments are not democratic, typically democratic in nature
[00:19:58.560 --> 00:19:59.720]   because the minority...
[00:19:59.720 --> 00:20:01.280]   Well, look at Italy.
[00:20:01.280 --> 00:20:02.800]   It's a long term.
[00:20:02.800 --> 00:20:06.040]   She only won 24% of the vote.
[00:20:06.040 --> 00:20:10.640]   But it was enough to make a parliament for her in a parliamentary democracy.
[00:20:10.640 --> 00:20:11.640]   Look at England.
[00:20:11.640 --> 00:20:14.720]   Anyone who's about to have the fifth prime minister in how many years?
[00:20:14.720 --> 00:20:15.720]   And she won...
[00:20:15.720 --> 00:20:18.920]   People keep saying, "Here's the thing I think you have to say about the UK is they say that
[00:20:18.920 --> 00:20:24.240]   Liz Truss won the votes of 160,000 conservative party members and it's far fewer than that
[00:20:24.240 --> 00:20:27.600]   voted and she won a minority of those votes in the first round."
[00:20:27.600 --> 00:20:30.840]   So she didn't even get 160,000 votes.
[00:20:30.840 --> 00:20:31.840]   Yeah.
[00:20:31.840 --> 00:20:36.360]   So, Musk, according to the information, will have absolute control over Twitter.
[00:20:36.360 --> 00:20:39.640]   They have apparently seen the new purchase documents.
[00:20:39.640 --> 00:20:42.120]   These are the new ones.
[00:20:42.120 --> 00:20:50.000]   And he will have sole discretion to decide what to do with Twitter, whether to sell it,
[00:20:50.000 --> 00:20:51.680]   to have an IPO.
[00:20:51.680 --> 00:20:52.680]   Who's on the board?
[00:20:52.680 --> 00:20:57.720]   He will have, quote, "exclusive authority" to appoint and remove members of the board.
[00:20:57.720 --> 00:21:02.920]   But all minority investors have to agree to vote for whoever he nominates, according.
[00:21:02.920 --> 00:21:03.920]   This is the...
[00:21:03.920 --> 00:21:05.720]   Said like a true autocrat.
[00:21:05.720 --> 00:21:06.720]   Yeah.
[00:21:06.720 --> 00:21:12.320]   Somebody pointed out yesterday is this comes from Elon being ousted at PayPal back in the
[00:21:12.320 --> 00:21:13.320]   day.
[00:21:13.320 --> 00:21:14.320]   Yeah.
[00:21:14.320 --> 00:21:15.320]   He needs that kind of control.
[00:21:15.320 --> 00:21:18.520]   He doesn't feel secure otherwise.
[00:21:18.520 --> 00:21:24.400]   This is the shareholders agreement prepared by Musk lawyers for equity investors.
[00:21:24.400 --> 00:21:28.600]   So he can do an IPO if he wants.
[00:21:28.600 --> 00:21:32.160]   I mean, he's got to find some way to recoup his 44 billion.
[00:21:32.160 --> 00:21:34.680]   He's not going to be able to finance this, though, still, right?
[00:21:34.680 --> 00:21:35.680]   I mean, that's the...
[00:21:35.680 --> 00:21:40.520]   I was reading about some of the banks involved or dubious about whether they'd like to pull
[00:21:40.520 --> 00:21:42.680]   out if they can find an excuse.
[00:21:42.680 --> 00:21:45.040]   They will, so you could have subsidiary lawsuits.
[00:21:45.040 --> 00:21:46.040]   He's...
[00:21:46.040 --> 00:21:50.120]   What's the best way to destroy yourself, I guess, is to try to buy a social network,
[00:21:50.120 --> 00:21:55.720]   because boy, if his fortunes changed despite the success of Tesla as a car company, since
[00:21:55.720 --> 00:22:01.160]   he said he was going to buy Twitter, it just feels like he cursed himself.
[00:22:01.160 --> 00:22:07.720]   Is it some sort of indication that we are at end times for social networks?
[00:22:07.720 --> 00:22:10.720]   Because let's face it, meta is not doing so great either.
[00:22:10.720 --> 00:22:11.720]   No.
[00:22:11.720 --> 00:22:15.200]   Well, so there is a story I put on the rundown that I think is oddly relevant, Leo.
[00:22:15.200 --> 00:22:16.200]   It is...
[00:22:16.200 --> 00:22:18.200]   I've got to give you the land number, don't I?
[00:22:18.200 --> 00:22:19.200]   63.
[00:22:19.200 --> 00:22:25.520]   A company formerly known as Jarvis.ai, now called Jasper.ai, because I'm going to guess
[00:22:25.520 --> 00:22:30.560]   a certain movie company had a problem with using my name.
[00:22:30.560 --> 00:22:36.280]   And so they just got a big investment at a $1.5 billion.
[00:22:36.280 --> 00:22:37.280]   So if you go...
[00:22:37.280 --> 00:22:40.640]   Go back up again, if you would, be so kind.
[00:22:40.640 --> 00:22:42.800]   And go under...
[00:22:42.800 --> 00:22:44.360]   I think it's features.
[00:22:44.360 --> 00:22:46.360]   Try that.
[00:22:46.360 --> 00:22:47.880]   I want to go to their product page.
[00:22:47.880 --> 00:22:52.440]   I tweeted the whole of these product pages today, and it's just amazing.
[00:22:52.440 --> 00:22:53.560]   Or maybe start for free.
[00:22:53.560 --> 00:22:54.560]   Try that.
[00:22:54.560 --> 00:22:55.560]   Down below.
[00:22:55.560 --> 00:22:56.560]   There you go.
[00:22:56.560 --> 00:22:57.560]   No, sorry, back.
[00:22:57.560 --> 00:23:04.000]   Sorry, I didn't prepare well enough to get you on the right.
[00:23:04.000 --> 00:23:07.520]   What they're saying is we're going to use your AI to create...
[00:23:07.520 --> 00:23:08.920]   Oh, here we go, there's the things.
[00:23:08.920 --> 00:23:09.920]   So that's it.
[00:23:09.920 --> 00:23:10.920]   That's it.
[00:23:10.920 --> 00:23:11.920]   Social media.
[00:23:11.920 --> 00:23:14.680]   You're going to use AI to create months of social media.
[00:23:14.680 --> 00:23:15.680]   Come up to 10 minutes.
[00:23:15.680 --> 00:23:16.680]   In minutes.
[00:23:16.680 --> 00:23:17.680]   You can see some of the Instagram captions.
[00:23:17.680 --> 00:23:18.680]   Some.
[00:23:18.680 --> 00:23:19.680]   Some.
[00:23:19.680 --> 00:23:20.680]   Some.
[00:23:20.680 --> 00:23:21.680]   Maybe quite funny.
[00:23:21.680 --> 00:23:22.680]   Right.
[00:23:22.680 --> 00:23:23.680]   Catchy videos.
[00:23:23.680 --> 00:23:26.440]   Already, by the way, you can see this on TikTok.
[00:23:26.440 --> 00:23:28.240]   I guess somewhat on YouTube.
[00:23:28.240 --> 00:23:29.240]   It's a little more opaque.
[00:23:29.240 --> 00:23:33.720]   But on TikTok, it's clear that a lot of the content is AI generated.
[00:23:33.720 --> 00:23:35.360]   A lot of the scripts are...
[00:23:35.360 --> 00:23:40.240]   There's a lot of accounts that are completely spammy accounts.
[00:23:40.240 --> 00:23:41.840]   TikTok is suffering from this already.
[00:23:41.840 --> 00:23:42.840]   You can also...
[00:23:42.840 --> 00:23:43.840]   No.
[00:23:43.840 --> 00:23:44.840]   With Jasper.
[00:23:44.840 --> 00:23:45.840]   So Jasper's an AI platform.
[00:23:45.840 --> 00:23:46.840]   It's basically...
[00:23:46.840 --> 00:23:47.840]   In fact, G3, it's like GPT-3.
[00:23:47.840 --> 00:23:48.840]   It goes to January.
[00:23:48.840 --> 00:23:50.520]   It's been around a little bit longer.
[00:23:50.520 --> 00:23:51.520]   I don't know.
[00:23:51.520 --> 00:23:52.520]   It does ART 2.
[00:23:52.520 --> 00:23:54.520]   But if you go to the articles one of the...
[00:23:54.520 --> 00:23:57.880]   It's the only AI trained with direct response marketing frameworks.
[00:23:57.880 --> 00:23:59.680]   Oh, that's good news.
[00:23:59.680 --> 00:24:00.680]   Now, go to the articles.
[00:24:00.680 --> 00:24:02.280]   It'll also write your WordPress articles.
[00:24:02.280 --> 00:24:06.240]   Stop scrunnelling with how to begin an article and break through your writer's block with
[00:24:06.240 --> 00:24:07.240]   AI.
[00:24:07.240 --> 00:24:10.720]   Write SEO optimized blog post 10 times faster with Jasper.
[00:24:10.720 --> 00:24:12.320]   This is very dystopian.
[00:24:12.320 --> 00:24:13.320]   It's a...
[00:24:13.320 --> 00:24:14.320]   Isn't it?
[00:24:14.320 --> 00:24:16.560]   It's filled with AI generated content.
[00:24:16.560 --> 00:24:17.560]   So that's what I think...
[00:24:17.560 --> 00:24:18.560]   I can't...
[00:24:18.560 --> 00:24:19.560]   What this leads to?
[00:24:19.560 --> 00:24:21.120]   It's not the death of social.
[00:24:21.120 --> 00:24:22.120]   It's the death of content.
[00:24:22.120 --> 00:24:27.040]   It's the death of the idea of content.
[00:24:27.040 --> 00:24:28.040]   So this is...
[00:24:28.040 --> 00:24:30.400]   Okay, so this is the interesting thing we had to make.
[00:24:30.400 --> 00:24:36.040]   Because two weeks ago, we talked about that article you brought up about the end of social
[00:24:36.040 --> 00:24:41.200]   and it's being replaced by content, by TikTok and YouTube videos.
[00:24:41.200 --> 00:24:42.200]   And now...
[00:24:42.200 --> 00:24:43.200]   Now...
[00:24:43.200 --> 00:24:44.200]   It's been ended.
[00:24:44.200 --> 00:24:45.200]   Two weeks later.
[00:24:45.200 --> 00:24:46.200]   Two weeks later.
[00:24:46.200 --> 00:24:48.160]   When can we get cut out of this?
[00:24:48.160 --> 00:24:52.160]   Like I can't wait for AIs to both produce and consume content.
[00:24:52.160 --> 00:24:53.160]   We don't need to be involved.
[00:24:53.160 --> 00:24:55.440]   We can be doing something much more useful with our content.
[00:24:55.440 --> 00:24:56.440]   Well, that's my AI.
[00:24:56.440 --> 00:24:57.440]   We'll fight with your AI.
[00:24:57.440 --> 00:24:58.440]   Yeah.
[00:24:58.440 --> 00:25:00.760]   That's clearly the premise of Jasper AIs.
[00:25:00.760 --> 00:25:06.160]   Don't waste your time creating content or marketing tools or advertising.
[00:25:06.160 --> 00:25:10.880]   Just let AI do it and you go on to do what play golf attempt to buy a social test.
[00:25:10.880 --> 00:25:14.200]   Content and conversation become completely devalued.
[00:25:14.200 --> 00:25:15.200]   Yeah.
[00:25:15.200 --> 00:25:16.200]   Right?
[00:25:16.200 --> 00:25:19.160]   Because we hit an endless abundance of it.
[00:25:19.160 --> 00:25:21.400]   We don't know the source.
[00:25:21.400 --> 00:25:24.040]   We don't have any real relationships.
[00:25:24.040 --> 00:25:25.200]   This is the dystopia.
[00:25:25.200 --> 00:25:28.640]   And then I think that I think it burns through all the old companies.
[00:25:28.640 --> 00:25:34.720]   And then I think a little blue sky from the ashes of the nuclear waste comes up with new
[00:25:34.720 --> 00:25:35.720]   conversations and new ways.
[00:25:35.720 --> 00:25:40.640]   Well, you're acting as if it's a human need to post 200 AV character.
[00:25:40.640 --> 00:25:44.520]   It's a human need for me to meet Glenn Fleischman.
[00:25:44.520 --> 00:25:45.520]   Yes, it is.
[00:25:45.520 --> 00:25:49.960]   But here's my question about that though, is that I feel like we are in a golden aid.
[00:25:49.960 --> 00:25:53.400]   Gosh, this is when I wish Kevin was here because he's such an or blogger.
[00:25:53.400 --> 00:25:55.080]   I think I was back there.
[00:25:55.080 --> 00:25:56.920]   We're all back there kind of at the beginning, right?
[00:25:56.920 --> 00:25:59.440]   But I feel like Kevin has had his finger on the pulse this.
[00:25:59.440 --> 00:26:05.120]   So anyway, but it feels like we're in another golden age where people want to read things,
[00:26:05.120 --> 00:26:07.120]   long-form journalism.
[00:26:07.120 --> 00:26:09.440]   Maybe it's hard to fund it, but people want to read it.
[00:26:09.440 --> 00:26:11.560]   I mean, I find myself navigating.
[00:26:11.560 --> 00:26:15.360]   I use the news app on Apple's News app.
[00:26:15.360 --> 00:26:19.240]   And it always directs me to really interesting, super long articles that I'm shocked are still
[00:26:19.240 --> 00:26:21.560]   being written and that are great.
[00:26:21.560 --> 00:26:23.520]   People, a sub-stack in the rise of newsletters.
[00:26:23.520 --> 00:26:27.760]   Now, I know there are blips in that model, but people are writing thousands or tens of
[00:26:27.760 --> 00:26:32.680]   thousands of words a week to new audiences to read them where they couldn't reach them
[00:26:32.680 --> 00:26:33.680]   before.
[00:26:33.680 --> 00:26:37.320]   The amount of good programming being produced, video series and movies.
[00:26:37.320 --> 00:26:41.880]   We're in a golden age of interesting stuff being made.
[00:26:41.880 --> 00:26:43.360]   Some of it quite original.
[00:26:43.360 --> 00:26:44.360]   It's not all derivative.
[00:26:44.360 --> 00:26:47.280]   We're seeing great adaptations, but also entirely new things.
[00:26:47.280 --> 00:26:51.480]   We're seeing voices heard that weren't before, even if they aren't being heard as much as
[00:26:51.480 --> 00:26:52.480]   they should.
[00:26:52.480 --> 00:26:56.120]   But you can grasp that with like, "Well, let's just automate all the social media."
[00:26:56.120 --> 00:26:59.760]   Maybe the short stuff just needs to be stuff we don't pay any attention to anymore.
[00:26:59.760 --> 00:27:01.760]   Maybe that's the point.
[00:27:01.760 --> 00:27:05.800]   I'm not going to miss Parler or Truth Social.
[00:27:05.800 --> 00:27:08.920]   I suppose there's a group of people who might.
[00:27:08.920 --> 00:27:09.920]   There's still Gab Getter.
[00:27:09.920 --> 00:27:10.920]   There's plenty of...
[00:27:10.920 --> 00:27:11.920]   Who's buying Gab?
[00:27:11.920 --> 00:27:13.920]   There's still plenty of right-wing...
[00:27:13.920 --> 00:27:15.920]   That'll be Glenn Greenwald.
[00:27:15.920 --> 00:27:16.920]   That'll be Glenn Greenwald.
[00:27:16.920 --> 00:27:19.880]   Well, Glenn Greenwald is doing...
[00:27:19.880 --> 00:27:20.880]   He's the fourth.
[00:27:20.880 --> 00:27:21.880]   He's doing... what is it?
[00:27:21.880 --> 00:27:22.880]   Ravel?
[00:27:22.880 --> 00:27:23.880]   Oh, I don't know.
[00:27:23.880 --> 00:27:29.520]   I don't think he's buying it, but he's...
[00:27:29.520 --> 00:27:31.320]   Yeah, he's their star.
[00:27:31.320 --> 00:27:33.160]   They've kind of invested in him.
[00:27:33.160 --> 00:27:35.760]   He's doing a whole big thing.
[00:27:35.760 --> 00:27:41.560]   Given all the harassment he got from Bolsonaro, he's now seems to be tacitly supporting Bolsonaro,
[00:27:41.560 --> 00:27:42.560]   which is incredible.
[00:27:42.560 --> 00:27:43.560]   I don't...
[00:27:43.560 --> 00:27:44.560]   Yeah.
[00:27:44.560 --> 00:27:47.080]   Glenn Greenwald is a study of something.
[00:27:47.080 --> 00:27:48.080]   I don't really know.
[00:27:48.080 --> 00:27:51.800]   He's gone over the edge and in the rabbit hole and out the other side and up in a manhole
[00:27:51.800 --> 00:27:54.040]   cover and cover in Moscow.
[00:27:54.040 --> 00:27:58.280]   He's just wacky.
[00:27:58.280 --> 00:27:59.280]   Article...
[00:27:59.280 --> 00:28:00.280]   Well, let's see.
[00:28:00.280 --> 00:28:08.400]   So, parlor, truth social, Twitter, meta.
[00:28:08.400 --> 00:28:09.880]   Is meta in good shape?
[00:28:09.880 --> 00:28:16.000]   Is it going to emerge from this as the sole surviving social...
[00:28:16.000 --> 00:28:18.000]   They're abandoning social...
[00:28:18.000 --> 00:28:20.000]   They're even a believer.
[00:28:20.000 --> 00:28:21.000]   They're doing VR.
[00:28:21.000 --> 00:28:24.480]   It's not gross for them anymore, right?
[00:28:24.480 --> 00:28:27.840]   That's the Facebook thing is they haven't found...
[00:28:27.840 --> 00:28:33.520]   They want the next big thing and have social, even if it's a sustainable advertising, high
[00:28:33.520 --> 00:28:35.360]   profit advertising thing.
[00:28:35.360 --> 00:28:36.440]   They don't care.
[00:28:36.440 --> 00:28:37.440]   It's delightful, though.
[00:28:37.440 --> 00:28:42.520]   I kind of love watching Zuckerberg, Homer Simpson, his own company.
[00:28:42.520 --> 00:28:46.520]   And usually you have to bring somebody from outside to ruin your company with elaborate
[00:28:46.520 --> 00:28:47.520]   ideas that don't work.
[00:28:47.520 --> 00:28:49.560]   He's doing it himself.
[00:28:49.560 --> 00:28:54.720]   You all remember Bezos' Amazon Firephone and he learned a lesson from that.
[00:28:54.720 --> 00:28:58.600]   There's not been a fire phone since Bezos Simpson's that, right?
[00:28:58.600 --> 00:29:02.680]   I mean, that was an incredible debacle, incredibly embarrassing.
[00:29:02.680 --> 00:29:03.680]   And they learned.
[00:29:03.680 --> 00:29:08.720]   And Zuckerberg feels like he's been in a company on something...
[00:29:08.720 --> 00:29:12.440]   Those articles coming out where they're having to practice to be forced employees to use
[00:29:12.440 --> 00:29:14.480]   horizon where...
[00:29:14.480 --> 00:29:15.480]   I love the whole thing.
[00:29:15.480 --> 00:29:16.480]   Not the...
[00:29:16.480 --> 00:29:20.800]   God, that piece where it said there's no girls in hot girl, summer room or whatever.
[00:29:20.800 --> 00:29:21.800]   There's no...
[00:29:21.800 --> 00:29:22.800]   It's just...
[00:29:22.800 --> 00:29:24.640]   Oh my God.
[00:29:24.640 --> 00:29:25.640]   It just sounds like the worst party.
[00:29:25.640 --> 00:29:26.640]   It's the...
[00:29:26.640 --> 00:29:29.520]   What do they go a bit of a verse that nobody came, yeah?
[00:29:29.520 --> 00:29:32.800]   It's the dash con ball pit, but that's all it is.
[00:29:32.800 --> 00:29:35.360]   One giant, one giant, the tiny ball pit.
[00:29:35.360 --> 00:29:37.800]   All right, I want to take a little break.
[00:29:37.800 --> 00:29:38.800]   We'll come back.
[00:29:38.800 --> 00:29:40.400]   We've got Glenn Fleischman and Jeff Jarvis.
[00:29:40.400 --> 00:29:41.760]   I could just sit back and relax.
[00:29:41.760 --> 00:29:43.960]   This show can be on autopilot.
[00:29:43.960 --> 00:29:44.960]   You guys are great.
[00:29:44.960 --> 00:29:45.960]   Wait till we get the fonts.
[00:29:45.960 --> 00:29:46.960]   Oh, wait till we just...
[00:29:46.960 --> 00:29:48.800]   I'm gonna go get some type.
[00:29:48.800 --> 00:29:49.800]   I'm gonna go get some type.
[00:29:49.800 --> 00:29:50.800]   Go get some type, please.
[00:29:50.800 --> 00:29:52.920]   We'll take a little break.
[00:29:52.920 --> 00:29:53.920]   Come back.
[00:29:53.920 --> 00:30:00.160]   Oh, are we just gonna say Kevin isn't gonna make it or hasn't showed up?
[00:30:00.160 --> 00:30:01.160]   No words.
[00:30:01.160 --> 00:30:02.160]   No words says it.
[00:30:02.160 --> 00:30:04.000]   It's late for you to be able to fall asleep.
[00:30:04.000 --> 00:30:06.280]   Jason, I presume you're reaching out.
[00:30:06.280 --> 00:30:08.280]   I wonder if he got the wrong day or time.
[00:30:08.280 --> 00:30:09.280]   He is in the UK.
[00:30:09.280 --> 00:30:11.160]   It may be too late at night.
[00:30:11.160 --> 00:30:12.160]   Yeah.
[00:30:12.160 --> 00:30:13.160]   Our show today brought...
[00:30:13.160 --> 00:30:14.160]   Maybe he's the next...
[00:30:14.160 --> 00:30:15.160]   I'm sorry.
[00:30:15.160 --> 00:30:16.160]   We'll go on with the...
[00:30:16.160 --> 00:30:19.440]   We'll do the blue sky stories since it's time.
[00:30:19.440 --> 00:30:23.200]   Our show today brought to you by ITProTV.
[00:30:23.200 --> 00:30:25.800]   These are some people I've known for some time.
[00:30:25.800 --> 00:30:32.560]   In fact, I think I'm pretty sure since before they even launched ITProTV in 2013.
[00:30:32.560 --> 00:30:39.160]   I met the founders Tim and Don at NAB some years earlier.
[00:30:39.160 --> 00:30:40.560]   We had a panel.
[00:30:40.560 --> 00:30:46.200]   Adam Corolla was on and I was on a bunch of creators on the internet talking about how
[00:30:46.200 --> 00:30:50.560]   the internet was providing this great platform for content.
[00:30:50.560 --> 00:30:56.360]   Tim and Don, who at the time were IT trainers, a classroom, traditional IT trainers, looked
[00:30:56.360 --> 00:31:00.600]   at it and said, "You know, it'd be interesting to do IT training over the internet."
[00:31:00.600 --> 00:31:03.560]   And ITProTV was born.
[00:31:03.560 --> 00:31:08.280]   And I'll take a little credit that they kind of modeled it on what we do here at Twit.
[00:31:08.280 --> 00:31:10.640]   They've gone well beyond anything we've ever done.
[00:31:10.640 --> 00:31:14.720]   Lisa and I flew out a few years ago to see the grand opening of their new studios in
[00:31:14.720 --> 00:31:16.080]   Gainesville, Florida.
[00:31:16.080 --> 00:31:21.880]   They have seven studios operating all day, Monday through Friday.
[00:31:21.880 --> 00:31:29.600]   I mean, they are just on a tear, creating the best content for anybody who wants to break
[00:31:29.600 --> 00:31:37.080]   into the world of IT, who's already in IT, but wants to get new skills, maybe re-certified,
[00:31:37.080 --> 00:31:41.600]   and even for companies who with IT teams, they want to level up.
[00:31:41.600 --> 00:31:47.920]   And ProTV is the best IT training anywhere, better than a brick and mortar school, better
[00:31:47.920 --> 00:31:50.080]   than doing it on your own.
[00:31:50.080 --> 00:31:53.160]   It's fun, it's engaging, and it really works.
[00:31:53.160 --> 00:31:56.680]   Check out the ITProTV business plan.
[00:31:56.680 --> 00:32:02.640]   If you've got a business, you know, it's really important that your IT team know their business.
[00:32:02.640 --> 00:32:08.040]   I know the job are up to date on all the latest information, but I think you're also probably
[00:32:08.040 --> 00:32:10.680]   thinking it's important that you retain them.
[00:32:10.680 --> 00:32:13.320]   This is a hard thing to do in this day and age.
[00:32:13.320 --> 00:32:16.840]   This is a benefit that they will really appreciate.
[00:32:16.840 --> 00:32:18.720]   Give them ITProTV.
[00:32:18.720 --> 00:32:24.160]   Not only will they find it engaging, not only will they get new skills, upgrade their existing
[00:32:24.160 --> 00:32:27.800]   skills, re-certify, they'll be grateful.
[00:32:27.800 --> 00:32:32.760]   80% of the users, more than 80% of the users who start a video on ITProTV, watch it all
[00:32:32.760 --> 00:32:33.760]   the way through.
[00:32:33.760 --> 00:32:35.400]   That's how engaging it is.
[00:32:35.400 --> 00:32:37.120]   And you can do it anywhere.
[00:32:37.120 --> 00:32:42.800]   On your TV, on your computer, they have an Apple TV app, they have a Roku app, it works
[00:32:42.800 --> 00:32:44.000]   on mobile.
[00:32:44.000 --> 00:32:49.200]   So whenever they've got a spare moment, each episode is about 20 to 30 minutes.
[00:32:49.200 --> 00:32:52.920]   So whenever your IT team is a spare moment, they can learn.
[00:32:52.920 --> 00:32:57.320]   And they love it because the ITProTV trainers are, well, they call them edutainers.
[00:32:57.320 --> 00:32:59.360]   They are professionals in the field.
[00:32:59.360 --> 00:33:03.880]   So these are their peers talking to them, people they look up to, people who really know
[00:33:03.880 --> 00:33:06.200]   their business, the real experts.
[00:33:06.200 --> 00:33:08.080]   But they all have a spark.
[00:33:08.080 --> 00:33:09.280]   They all have a certain something.
[00:33:09.280 --> 00:33:12.520]   I think it's a passion for the subject matter.
[00:33:12.520 --> 00:33:16.120]   So your ITPro's are going to watch these videos and go, "Yeah, these guys get it.
[00:33:16.120 --> 00:33:18.320]   These guys, I'm learning from them."
[00:33:18.320 --> 00:33:23.800]   And their enthusiasm is communicating, "I'm excited about my job again."
[00:33:23.800 --> 00:33:27.400]   This is going to really transform your IT team.
[00:33:27.400 --> 00:33:35.400]   They can get training for any area of IT and even some soft skills, all the certifications,
[00:33:35.400 --> 00:33:37.000]   one place where you can go.
[00:33:37.000 --> 00:33:43.680]   ITProTV has every vendor, every skill, Microsoft IT training, Cisco training, Linux, Apple,
[00:33:43.680 --> 00:33:45.640]   security, cloud, and so much more.
[00:33:45.640 --> 00:33:52.080]   More than 5,800 hours worth ranging from technical skills to compliance to soft skills.
[00:33:52.080 --> 00:33:55.160]   And the business plan has a great dashboard.
[00:33:55.160 --> 00:33:57.360]   You can track everything that's going on.
[00:33:57.360 --> 00:33:59.800]   Manage seats, assign and unassigned team members.
[00:33:59.800 --> 00:34:03.080]   You can even create subsets of your team and say, "You guys learned this.
[00:34:03.080 --> 00:34:04.800]   You guys learned this."
[00:34:04.800 --> 00:34:06.160]   You'll get monthly usage reports.
[00:34:06.160 --> 00:34:11.520]   You'll get beautiful visual reports so that you can show the boss.
[00:34:11.520 --> 00:34:12.520]   Here's our ROI.
[00:34:12.520 --> 00:34:14.360]   Look at these guys who are really watching it.
[00:34:14.360 --> 00:34:18.040]   You'll get immediate insight into their viewing patterns, their progress.
[00:34:18.040 --> 00:34:21.720]   I think you're going to love ITProTV and I know your IT professionals will.
[00:34:21.720 --> 00:34:26.160]   And I know anybody who loves IT or wants to get an IT loves ITProTV.
[00:34:26.160 --> 00:34:28.320]   We've seen that over the years.
[00:34:28.320 --> 00:34:33.560]   Individual plans, business plans, go to it.tv/twit right now.
[00:34:33.560 --> 00:34:37.600]   Give your team the IT development platform they need to level up their skills while enjoying
[00:34:37.600 --> 00:34:40.760]   the journey for teams of 2,000 to 1,000.
[00:34:40.760 --> 00:34:41.880]   They've got it for you.
[00:34:41.880 --> 00:34:42.880]   ITProTV/twit.
[00:34:42.880 --> 00:34:50.920]   Thank you, ITProTV for all you do for us.
[00:34:50.920 --> 00:34:57.840]   I know many of our viewers and listeners are ITProTV graduates or attending right now.
[00:34:57.840 --> 00:35:04.840]   And the rest of you are ITProTV future students.
[00:35:04.840 --> 00:35:05.840]   Hey, good news.
[00:35:05.840 --> 00:35:07.840]   Kevin Marks is here.
[00:35:07.840 --> 00:35:08.840]   Yay.
[00:35:08.840 --> 00:35:15.120]   We've added Kevin to the lineup all the way from the UK where it is late in the evening.
[00:35:15.120 --> 00:35:16.120]   Hi, Kevin.
[00:35:16.120 --> 00:35:17.120]   Hi there.
[00:35:17.120 --> 00:35:18.120]   No, sorry about that.
[00:35:18.120 --> 00:35:20.200]   I've been a bit sick the last two days so I lost track of the time.
[00:35:20.200 --> 00:35:21.200]   Oh, I'm so sorry.
[00:35:21.200 --> 00:35:22.960]   I hope you're feeling all right now.
[00:35:22.960 --> 00:35:27.560]   Well, I've got cough sweets and I'll try and keep going and mute when I cough.
[00:35:27.560 --> 00:35:30.160]   I thought maybe you were the next chancellor.
[00:35:30.160 --> 00:35:34.920]   Well, that's the other thing is I've been watching the UK Parliament this evening and
[00:35:34.920 --> 00:35:36.400]   rubbing my eyes in disbelief.
[00:35:36.400 --> 00:35:41.560]   So what's going on?
[00:35:41.560 --> 00:35:44.000]   The government is collapsing in three ways at once, basically.
[00:35:44.000 --> 00:35:49.960]   It's a bit hard to tell when it's going on, but they had a vote on fracking tonight that
[00:35:49.960 --> 00:35:51.760]   was called by Labour.
[00:35:51.760 --> 00:35:53.600]   The government first here was a confidence vote.
[00:35:53.600 --> 00:35:56.200]   Then when they were going to lose it said it wasn't a confidence vote.
[00:35:56.200 --> 00:36:00.200]   Then they were actually wrestling with each other in the voting line and the two chief
[00:36:00.200 --> 00:36:01.200]   with resigns.
[00:36:01.200 --> 00:36:02.520]   Oh my God.
[00:36:02.520 --> 00:36:07.560]   I don't actually know what's going on about this.
[00:36:07.560 --> 00:36:11.000]   This cabinet secretary who yesterday's was raving about.
[00:36:11.000 --> 00:36:13.280]   Let's see if I can do it.
[00:36:13.280 --> 00:36:16.560]   Guardian reading Tofu, EDN, Wokitarians.
[00:36:16.560 --> 00:36:17.560]   Oh my God.
[00:36:17.560 --> 00:36:21.400]   I was forced to resign over a security breach today.
[00:36:21.400 --> 00:36:22.400]   Oh my God.
[00:36:22.400 --> 00:36:23.400]   Yes.
[00:36:23.400 --> 00:36:29.760]   And it's all of this precipitated by a tax cut, which is something that here in the US would
[00:36:29.760 --> 00:36:32.320]   guarantee you four more years.
[00:36:32.320 --> 00:36:34.280]   It's a tax cut for the very, very richest.
[00:36:34.280 --> 00:36:35.480]   Ah, that's the problem.
[00:36:35.480 --> 00:36:37.520]   And the market is a liquid, which is weird also.
[00:36:37.520 --> 00:36:46.480]   It was a combination of a tax cut and no plan for how you would pay for it.
[00:36:46.480 --> 00:36:47.480]   No budget balancing, basically.
[00:36:47.480 --> 00:36:49.480]   That never stopped us.
[00:36:49.480 --> 00:36:55.400]   Not putting it past the OBR and firing this chills, so we're so in charge of it.
[00:36:55.400 --> 00:37:00.160]   So basically what it was is what it meant was the markets were looking at this going,
[00:37:00.160 --> 00:37:01.160]   this doesn't add up.
[00:37:01.160 --> 00:37:02.160]   I don't understand what they're going to do.
[00:37:02.160 --> 00:37:03.840]   I need to understand what's really going on.
[00:37:03.840 --> 00:37:08.520]   Clearly they're spending at the wrong end of the economic distribution because actually
[00:37:08.520 --> 00:37:13.640]   the big challenge here at the moment is the cost of the rise and the price of gas like
[00:37:13.640 --> 00:37:14.640]   methane gas.
[00:37:14.640 --> 00:37:17.720]   For your inflation is worse than ours.
[00:37:17.720 --> 00:37:18.720]   Yeah.
[00:37:18.720 --> 00:37:21.040]   And that's pushing up our inflation.
[00:37:21.040 --> 00:37:26.360]   But also it's explicitly pushing up household bills by a factor of four for electricity and
[00:37:26.360 --> 00:37:27.360]   gas.
[00:37:27.360 --> 00:37:28.360]   Yikes.
[00:37:28.360 --> 00:37:30.160]   And this is for that as well.
[00:37:30.160 --> 00:37:33.600]   I have people on Twitter actually telling me what I'm like, there are some businesses
[00:37:33.600 --> 00:37:37.200]   that are going to see four to six fold increases in their electrical costs.
[00:37:37.200 --> 00:37:38.200]   Oh, yeah.
[00:37:38.200 --> 00:37:39.200]   Yeah.
[00:37:39.200 --> 00:37:40.200]   Yeah.
[00:37:40.200 --> 00:37:41.200]   They're like, no, no, no, you're making that up.
[00:37:41.200 --> 00:37:42.200]   There must be.
[00:37:42.200 --> 00:37:43.200]   It's just the market.
[00:37:43.200 --> 00:37:44.200]   It's like, no, here, these are sources.
[00:37:44.200 --> 00:37:45.680]   This is literally people are posting the bills.
[00:37:45.680 --> 00:37:46.680]   They're watching like bakeries.
[00:37:46.680 --> 00:37:49.040]   But that's not like 1000 pounds.
[00:37:49.040 --> 00:37:50.720]   Well, it's not as true as fault.
[00:37:50.720 --> 00:37:52.040]   That's the war in Ukraine's fault.
[00:37:52.040 --> 00:37:54.040]   This rushes fall.
[00:37:54.040 --> 00:37:55.520]   Well, I mean, yes.
[00:37:55.520 --> 00:38:00.440]   It's also like only investing in gas for the last 20 years, right?
[00:38:00.440 --> 00:38:05.960]   Looking at other energy supplies and blocking on shore wind and blocking insulation of
[00:38:05.960 --> 00:38:09.560]   housing and blocking nuclear for 20 years.
[00:38:09.560 --> 00:38:11.520]   You know, there's like this.
[00:38:11.520 --> 00:38:14.040]   There's a great deal of sort of built up stuff.
[00:38:14.040 --> 00:38:18.840]   Yeah, we have cut down on coal, but we basically replaced it with natural gas.
[00:38:18.840 --> 00:38:21.560]   And also they closed the natural gas storage facility two years ago.
[00:38:21.560 --> 00:38:23.560]   So we can't actually store it.
[00:38:23.560 --> 00:38:26.760]   It's like a great cascade failure of government.
[00:38:26.760 --> 00:38:30.240]   So they're trying to what they need to do and what the first thing they said they weren't
[00:38:30.240 --> 00:38:32.600]   going to do, which is so much their credit bills.
[00:38:32.600 --> 00:38:35.840]   You know, we were waiting for the Johnson debacle.
[00:38:35.840 --> 00:38:39.680]   But then the election, the internal election finished was that they said, okay, we are
[00:38:39.680 --> 00:38:47.680]   going to work out how to fund your bills and we'll pay you so that you don't have to
[00:38:47.680 --> 00:38:49.960]   pay all these bills yourselves.
[00:38:49.960 --> 00:38:54.320]   But then they also refused to do a windfall tax on the gas company who was getting all
[00:38:54.320 --> 00:38:56.680]   the windfall profits from this.
[00:38:56.680 --> 00:38:58.840]   So basically the budget didn't add up at all.
[00:38:58.840 --> 00:39:01.520]   The markets were looking at this going, it's going to only work if they're going to cut
[00:39:01.520 --> 00:39:04.760]   something else, they're going to be simple that's going to be.
[00:39:04.760 --> 00:39:09.320]   And then it just got more and more chaotic and eventually they were like.
[00:39:09.320 --> 00:39:11.240]   So you should do a week to four stuff.
[00:39:11.240 --> 00:39:15.720]   You should just be stuck with whoever you got for four years and just you're stuck.
[00:39:15.720 --> 00:39:16.720]   You're just stuck.
[00:39:16.720 --> 00:39:17.880]   They sort of work.
[00:39:17.880 --> 00:39:19.680]   Well, that gets a lot of things.
[00:39:19.680 --> 00:39:21.440]   It's the general election.
[00:39:21.440 --> 00:39:23.280]   It's 2024, 2025.
[00:39:23.280 --> 00:39:31.320]   It has to happen by, yeah, I think January 2025.
[00:39:31.320 --> 00:39:37.600]   The Prime Minister can call one before that if they decide to or the Parliament can call
[00:39:37.600 --> 00:39:39.920]   one by voting no confidence in the Prime Minister.
[00:39:39.920 --> 00:39:42.160]   That's why I'm surprised that has not happened.
[00:39:42.160 --> 00:39:46.360]   Well, the Conservatives have to send a majority of 70 or so.
[00:39:46.360 --> 00:39:52.160]   So it will take a lot of them to defect or commit suicide for that to actually happen.
[00:39:52.160 --> 00:39:56.280]   And they're 30% behind in the polls, so they probably don't want to do it now.
[00:39:56.280 --> 00:39:58.760]   If Facebook were a country, it would be England.
[00:39:58.760 --> 00:40:00.560]   Oh, that's mean.
[00:40:00.560 --> 00:40:01.560]   I don't know.
[00:40:01.560 --> 00:40:02.760]   It's a little hard.
[00:40:02.760 --> 00:40:04.240]   We saved a story.
[00:40:04.240 --> 00:40:07.160]   You do have a wrong deputy prime minister running Facebook.
[00:40:07.160 --> 00:40:08.160]   That's right.
[00:40:08.160 --> 00:40:09.160]   That's true.
[00:40:09.160 --> 00:40:10.160]   That's right.
[00:40:10.160 --> 00:40:12.120]   So maybe there is something to that.
[00:40:12.120 --> 00:40:16.280]   We saved a story just for you, Kevin Marks, because I really wanted to get your comment
[00:40:16.280 --> 00:40:17.280]   on it.
[00:40:17.280 --> 00:40:23.760]   As you know, Jack Dorsey before leaving Twitter established and funded something called Blue
[00:40:23.760 --> 00:40:32.880]   Sky Social, which is an attempt to create a federated Twitter, the next Twitter in effect.
[00:40:32.880 --> 00:40:34.960]   It is now kind of going public.
[00:40:34.960 --> 00:40:40.400]   In fact, I'm here on the launch page, which is bsky.app.
[00:40:40.400 --> 00:40:42.400]   See what's next, Blue Sky Social.
[00:40:42.400 --> 00:40:43.400]   App page.
[00:40:43.400 --> 00:40:45.400]   Then there's also the API page.
[00:40:45.400 --> 00:40:50.600]   So yeah, there's a new API, which is called AT, I think, the AT protocol.
[00:40:50.600 --> 00:40:53.200]   If you go to blue skywebx.x.x.
[00:40:53.200 --> 00:40:54.520]   That's what it's called.
[00:40:54.520 --> 00:40:55.520]   They call it the AT.
[00:40:55.520 --> 00:40:56.520]   Oh, that makes sense.
[00:40:56.520 --> 00:40:57.520]   At.
[00:40:57.520 --> 00:41:01.520]   Yeah, it's actually really bad because if you search for AT, you get modem commands
[00:41:01.520 --> 00:41:02.520]   and things.
[00:41:02.520 --> 00:41:03.520]   Yeah.
[00:41:03.520 --> 00:41:04.520]   It was ADX.
[00:41:04.520 --> 00:41:09.880]   It was called the authenticated transfer protocol or ADX.
[00:41:09.880 --> 00:41:13.280]   But they, I guess because the @ sign on Twitter, they thought it'd be clever to call it the
[00:41:13.280 --> 00:41:14.800]   @ protocol.
[00:41:14.800 --> 00:41:20.760]   So I'm curious because we know you're the open web advocate, Mr. Indie web and open standards
[00:41:20.760 --> 00:41:23.600]   and all that.
[00:41:23.600 --> 00:41:25.560]   When what is your initial thought of?
[00:41:25.560 --> 00:41:28.040]   Can you go down the, for the audience, can you go down there?
[00:41:28.040 --> 00:41:30.880]   There's a list of four principles to yes on that post.
[00:41:30.880 --> 00:41:31.880]   Right.
[00:41:31.880 --> 00:41:32.880]   Be useful to have that as a background.
[00:41:32.880 --> 00:41:33.880]   Yeah.
[00:41:33.880 --> 00:41:38.880]   So the person that's online and it any should not be owned by corporations with no accountability
[00:41:38.880 --> 00:41:43.560]   or users, aka Twitter, with the AT protocol, you can move your account from one provider
[00:41:43.560 --> 00:41:48.160]   to another without losing any of your data or social graph.
[00:41:48.160 --> 00:41:49.640]   That's great.
[00:41:49.640 --> 00:41:53.080]   And by the way, that's right now what Mastodon offers.
[00:41:53.080 --> 00:42:00.000]   And I guess that's the, we'll talk to Ravel next week about his proposed setup.
[00:42:00.000 --> 00:42:05.560]   He probably knew things inside, yeah, but it's one of the things he hasn't quite solved
[00:42:05.560 --> 00:42:06.560]   yet.
[00:42:06.560 --> 00:42:07.640]   Maybe he has since I last looked at it.
[00:42:07.640 --> 00:42:10.880]   But one of the problems that his thing has is it's very tired of the device.
[00:42:10.880 --> 00:42:11.880]   Right.
[00:42:11.880 --> 00:42:12.880]   So you can change phones.
[00:42:12.880 --> 00:42:13.880]   You tend to lose it all.
[00:42:13.880 --> 00:42:14.880]   Right.
[00:42:14.880 --> 00:42:18.600]   The second point is algorithmic choice, algorithms dictate what we see, who we can reach.
[00:42:18.600 --> 00:42:22.920]   We must have control over the algorithms if we're going to trust in our online spaces.
[00:42:22.920 --> 00:42:25.600]   The AT protocol includes an open algorithms mode.
[00:42:25.600 --> 00:42:28.640]   So users have more control over their experience.
[00:42:28.640 --> 00:42:31.480]   And what this says to me, just to be wrong, I hear at this moment, is that you could also
[00:42:31.480 --> 00:42:33.200]   have a choice among algorithms.
[00:42:33.200 --> 00:42:34.200]   Yeah.
[00:42:34.200 --> 00:42:35.200]   Well, we'll see.
[00:42:35.200 --> 00:42:39.360]   Interoperation, the world needs a diverse market of connected services, et cetera, et
[00:42:39.360 --> 00:42:40.360]   cetera.
[00:42:40.360 --> 00:42:47.160]   The AT protocol includes a schema based interoperation framework called lexicon to help solve coordination
[00:42:47.160 --> 00:42:48.880]   challenges.
[00:42:48.880 --> 00:42:55.480]   I guess that's that that's toward federating or is it something like federating, I guess.
[00:42:55.480 --> 00:43:02.400]   And then finally, the fourth tent pole performance, a lot of novel protocols, throat performance
[00:43:02.400 --> 00:43:06.840]   out of the window, something folks at Twitter learned is you can't do that.
[00:43:06.840 --> 00:43:08.040]   Fail well, fail well.
[00:43:08.040 --> 00:43:10.840]   There's obviously in long loading times before you can see your timeline.
[00:43:10.840 --> 00:43:12.280]   We don't see performances optional.
[00:43:12.280 --> 00:43:15.400]   So we've made it a priority to build for fast loading at large scales.
[00:43:15.400 --> 00:43:16.560]   I mean, it makes sense.
[00:43:16.560 --> 00:43:22.080]   This is a team that has, you know, that has real world battlefield experience with Twitter.
[00:43:22.080 --> 00:43:23.080]   So it makes sense.
[00:43:23.080 --> 00:43:27.320]   And I think a lot of them are third parties, but they've got Paul Frasier there who has
[00:43:27.320 --> 00:43:30.800]   who built the beaker browser on the data protocol.
[00:43:30.800 --> 00:43:36.200]   So he's sort of got the experience of building alternate protocols and things.
[00:43:36.200 --> 00:43:38.440]   So that's that sensible.
[00:43:38.440 --> 00:43:46.480]   And from what I've read of it so far, it's it's more sensible than the first draft, which
[00:43:46.480 --> 00:43:47.480]   is good.
[00:43:47.480 --> 00:43:55.080]   But there's sort of edging towards the India web principle of domains are identifiers.
[00:43:55.080 --> 00:43:59.640]   The groups kind of pretending that they're not by using wrapping them in DIDs.
[00:43:59.640 --> 00:44:01.120]   That's my sort of high level thing.
[00:44:01.120 --> 00:44:04.240]   So the thing about account portabilities, we have account portability, it's called domain
[00:44:04.240 --> 00:44:05.240]   names.
[00:44:05.240 --> 00:44:08.840]   You can buy a domain name for a fixed period of time.
[00:44:08.840 --> 00:44:12.040]   You can argue you can rent a domain name, but you know, you put money down, you buy a
[00:44:12.040 --> 00:44:17.440]   domain name, you've got KevinMucks.com, you've got Twitter.tv, whatever.
[00:44:17.440 --> 00:44:21.280]   You can pay that down for five years or ten years or whatever.
[00:44:21.280 --> 00:44:24.360]   You can move where that is hosted automatically.
[00:44:24.360 --> 00:44:27.360]   You can move the registrar for that automatically.
[00:44:27.360 --> 00:44:31.080]   That was a problem 25 years ago.
[00:44:31.080 --> 00:44:32.320]   That's kind of solved now.
[00:44:32.320 --> 00:44:35.880]   At that level of portability, that exists.
[00:44:35.880 --> 00:44:40.560]   So given that you've got that and you've got a dressability via your roles, a lot of
[00:44:40.560 --> 00:44:42.520]   the other stuff of this is sort of somewhat redundant.
[00:44:42.520 --> 00:44:44.080]   And it sort of feels like that as well.
[00:44:44.080 --> 00:44:51.080]   Because the transport protocol is basically a wrap around HTTPS, which is fine.
[00:44:51.080 --> 00:44:52.720]   That's a good idea.
[00:44:52.720 --> 00:44:58.360]   But they're just wrapping it in some extra complication so they can move their own protocol
[00:44:58.360 --> 00:45:00.000]   and stuff with it.
[00:45:00.000 --> 00:45:04.960]   So the end of my point of view is like, yeah, so we use HTTPS and we use HTML as the transport
[00:45:04.960 --> 00:45:10.000]   protocol and we'll define some ways of marking up the HTML so we can do that.
[00:45:10.000 --> 00:45:13.560]   And then we have a few API hooks for saying, this is a reply.
[00:45:13.560 --> 00:45:16.800]   This is a follow and so on.
[00:45:16.800 --> 00:45:25.160]   They've got some interesting bits in the app protubes stuff was they were talking about
[00:45:25.160 --> 00:45:27.200]   interesting distinctions I haven't seen made before.
[00:45:27.200 --> 00:45:29.600]   So I can find where it is.
[00:45:29.600 --> 00:45:31.520]   Is it the developers page?
[00:45:31.520 --> 00:45:36.200]   There is an app.pro.com/docs/docs/docs.
[00:45:36.200 --> 00:45:41.600]   There we go.
[00:45:41.600 --> 00:45:46.720]   So it's sort of taken the ID provision stuff, the global IDs, and then you go and look at
[00:45:46.720 --> 00:45:49.040]   them, they're actually URLs.
[00:45:49.040 --> 00:45:57.480]   And then they've got keys to map the URLs, which is kind of unnecessary in my experience.
[00:45:57.480 --> 00:46:02.800]   The way you get human readable names is by using actual domain names.
[00:46:02.800 --> 00:46:06.040]   The did ones look like hell and not human readable.
[00:46:06.040 --> 00:46:11.160]   So are you saying Kevin that every user would have a domain name as their ID?
[00:46:11.160 --> 00:46:14.800]   That's what it looks like.
[00:46:14.800 --> 00:46:17.480]   So that's one of the problems to solve.
[00:46:17.480 --> 00:46:24.320]   It's key to the first two principles is you have to have a unique name that's...
[00:46:24.320 --> 00:46:26.200]   You can have it subdomains.
[00:46:26.200 --> 00:46:29.040]   So again, you can have a subdomain like you can have a subdomain on Tumblr or Google.
[00:46:29.040 --> 00:46:31.600]   So I'm at leo-loport on twitter.com.
[00:46:31.600 --> 00:46:32.600]   That is...
[00:46:32.600 --> 00:46:34.600]   But you don't get that as a subdomain.
[00:46:34.600 --> 00:46:36.560]   You get that twitter.com/leo-loport.
[00:46:36.560 --> 00:46:39.640]   Whereas if you're on Tumblr, your leo-loport.tumbler.com.
[00:46:39.640 --> 00:46:43.280]   Which is a subdomain which works as a separate routing entity.
[00:46:43.280 --> 00:46:45.880]   But they're also the leo-loport.com.
[00:46:45.880 --> 00:46:46.880]   Which would be the...
[00:46:46.880 --> 00:46:47.880]   Who's really the port?
[00:46:47.880 --> 00:46:50.880]   That would be the true universal...
[00:46:50.880 --> 00:46:52.360]   So would everybody...
[00:46:52.360 --> 00:46:57.280]   I mean, it seems to me that that's not how most people think of their social.
[00:46:57.280 --> 00:47:01.840]   They think of going to a company and that's the root domain and then having their user
[00:47:01.840 --> 00:47:03.320]   ID at that root domain.
[00:47:03.320 --> 00:47:06.600]   Even if it's leo.tumbler.blog or .net.
[00:47:06.600 --> 00:47:08.800]   Yeah, but that's fine.
[00:47:08.800 --> 00:47:15.080]   You can debate that and I've been arguing with Blaine about this for at least 15 years.
[00:47:15.080 --> 00:47:18.000]   And his mythical grandmother who doesn't like URLs.
[00:47:18.000 --> 00:47:21.480]   But actually when we were blogging we understood URLs fairly quickly and we had a link to
[00:47:21.480 --> 00:47:23.440]   each other and could work it out.
[00:47:23.440 --> 00:47:27.080]   Every human in the world have their own domain.
[00:47:27.080 --> 00:47:28.880]   Would that be advisable?
[00:47:28.880 --> 00:47:29.880]   Yes.
[00:47:29.880 --> 00:47:30.880]   Okay.
[00:47:30.880 --> 00:47:33.560]   Or they can have subdomains.
[00:47:33.560 --> 00:47:34.560]   People can give you subdomains.
[00:47:34.560 --> 00:47:36.640]   Yeah, we could have the leo-loport family and then...
[00:47:36.640 --> 00:47:37.640]   You could be able...
[00:47:37.640 --> 00:47:44.360]   You could create twigclub.com or twig.club and give away or sell subdomains.
[00:47:44.360 --> 00:47:45.360]   Well we do.
[00:47:45.360 --> 00:47:47.680]   With Mastodon we have twit.social.
[00:47:47.680 --> 00:47:51.640]   And I'm twit.social@leo I guess.
[00:47:51.640 --> 00:47:56.200]   So URL becomes a UPL, a universal people locator.
[00:47:56.200 --> 00:47:57.200]   Right.
[00:47:57.200 --> 00:47:59.600]   It becomes something that can then operate across any domain.
[00:47:59.600 --> 00:48:00.600]   Which is it?
[00:48:00.600 --> 00:48:02.000]   It means this has to be portable.
[00:48:02.000 --> 00:48:03.000]   So it can't be tied to Twitter.
[00:48:03.000 --> 00:48:04.000]   That's right.
[00:48:04.000 --> 00:48:05.000]   It's portable.
[00:48:05.000 --> 00:48:06.400]   Yeah, it can't be tied to Twitter because then I wouldn't be able to leave Twitter.
[00:48:06.400 --> 00:48:08.160]   It has to be somehow portable.
[00:48:08.160 --> 00:48:13.040]   Yeah, so the portability comes in where this is where you register your own domain and
[00:48:13.040 --> 00:48:15.800]   then you can change the CNAME and move it to somewhere else.
[00:48:15.800 --> 00:48:20.880]   So I can register kevinmarks.com and that used to point at my friend's server in...
[00:48:20.880 --> 00:48:23.280]   So this is an analogous to email right now.
[00:48:23.280 --> 00:48:24.280]   Now it points to...
[00:48:24.280 --> 00:48:25.280]   It's an analogous to email.
[00:48:25.280 --> 00:48:30.000]   A lot of people have yahoo.com or gmail.com.
[00:48:30.000 --> 00:48:32.520]   But I've long recommended you go out and get a domain name.
[00:48:32.520 --> 00:48:34.240]   So I'm Leo@leo-lio-ville.com.
[00:48:34.240 --> 00:48:36.960]   And then I can use a MX reference to it.
[00:48:36.960 --> 00:48:37.960]   I can confirm my Google phone.
[00:48:37.960 --> 00:48:38.960]   I'll go to my old ones of those.
[00:48:38.960 --> 00:48:42.960]   Yeah, so I can point that anywhere I want or even host my own email, which nobody does
[00:48:42.960 --> 00:48:43.960]   anymore because...
[00:48:43.960 --> 00:48:45.480]   Yeah, that's for different reasons.
[00:48:45.480 --> 00:48:46.480]   But yeah.
[00:48:46.480 --> 00:48:47.480]   For another reason.
[00:48:47.480 --> 00:48:48.480]   Deliverability.
[00:48:48.480 --> 00:48:49.480]   Yeah.
[00:48:49.480 --> 00:48:50.480]   Deacon.
[00:48:50.480 --> 00:48:55.080]   But yeah, and the point is we actually know how to...
[00:48:55.080 --> 00:48:57.080]   We know how to do portable names on the internet.
[00:48:57.080 --> 00:48:59.080]   They're called domain names.
[00:48:59.080 --> 00:49:02.080]   They're sold at more than one layer.
[00:49:02.080 --> 00:49:09.480]   And any serious hosting provider like Tumblr or Microblog or Blogger will have a way for
[00:49:09.480 --> 00:49:12.160]   you to route to your own domain name if you want.
[00:49:12.160 --> 00:49:14.080]   I have tumblelio.com.
[00:49:14.080 --> 00:49:16.720]   It leads to my tumblelio-tumbler.
[00:49:16.720 --> 00:49:17.720]   Yeah.
[00:49:17.720 --> 00:49:18.720]   Yeah.
[00:49:18.720 --> 00:49:20.320]   That's not universal.
[00:49:20.320 --> 00:49:22.960]   The content on there can be exported.
[00:49:22.960 --> 00:49:27.200]   But I think what's really interesting here is that there's a universal idea.
[00:49:27.200 --> 00:49:29.160]   It's a global idea.
[00:49:29.160 --> 00:49:30.160]   It's a new namespace.
[00:49:30.160 --> 00:49:33.160]   In that sense, it may be built on domains.
[00:49:33.160 --> 00:49:37.720]   But if everybody thought they had to have their own, it's like having a straight address.
[00:49:37.720 --> 00:49:39.520]   You have a unique address.
[00:49:39.520 --> 00:49:45.840]   Well, I mean, making namespaces has been a good business model for companies for a while.
[00:49:45.840 --> 00:49:47.920]   Twitter does quite well out of its namespaces.
[00:49:47.920 --> 00:49:52.640]   And if you've got a nice, short Instagram name, you know that everyone is trying to steal
[00:49:52.640 --> 00:49:55.520]   it from you.
[00:49:55.520 --> 00:49:58.760]   And so you could do that.
[00:49:58.760 --> 00:50:01.240]   And also domain names themselves are saleable.
[00:50:01.240 --> 00:50:04.000]   You can buy and sell domain names on register ones.
[00:50:04.000 --> 00:50:07.000]   And if you've registered one, you can do that too.
[00:50:07.000 --> 00:50:08.000]   Yeah.
[00:50:08.000 --> 00:50:09.640]   If you control it, you can sell it.
[00:50:09.640 --> 00:50:10.640]   Yeah.
[00:50:10.640 --> 00:50:15.480]   So there's, you know, there's a lot of these distributed things.
[00:50:15.480 --> 00:50:18.200]   Keep trying to reinvent things that they need to reinventing because actually domain names
[00:50:18.200 --> 00:50:19.200]   are distributed.
[00:50:19.200 --> 00:50:23.560]   Or rather, they're fungible in a good sense.
[00:50:23.560 --> 00:50:25.720]   You can, they're substitutable.
[00:50:25.720 --> 00:50:28.400]   You can swap out your domain name provider.
[00:50:28.400 --> 00:50:31.880]   You can swap out your DNS resolver.
[00:50:31.880 --> 00:50:33.760]   You can swap out your hosting.
[00:50:33.760 --> 00:50:38.520]   And all three layers are straightforward to swap a wall because we've had the fights
[00:50:38.520 --> 00:50:41.120]   and the lawsuits and the dispute resolution procedures.
[00:50:41.120 --> 00:50:44.600]   And we've got, I can dispute resolution about who gets to own a name.
[00:50:44.600 --> 00:50:50.360]   And we've got DNS hierarchy and who gets to create DNS things.
[00:50:50.360 --> 00:50:51.600]   And we've got different hosting providers.
[00:50:51.600 --> 00:50:52.600]   You can point things out.
[00:50:52.600 --> 00:50:56.720]   And the ones that have been sort of scammy and locked people in have mostly been dumped
[00:50:56.720 --> 00:50:58.120]   in favor of the ones that aren't.
[00:50:58.120 --> 00:51:01.320]   This isn't a matter of sort of upsellness to it.
[00:51:01.320 --> 00:51:04.240]   But broadly, that that's true now.
[00:51:04.240 --> 00:51:07.600]   So I'd like to have your kind of high level on this.
[00:51:07.600 --> 00:51:12.840]   Do you have hope for blue sky that it's going to develop into something useful and inter-operable
[00:51:12.840 --> 00:51:15.560]   what you're working on or not and why not?
[00:51:15.560 --> 00:51:16.560]   If that's the case.
[00:51:16.560 --> 00:51:20.240]   I'd like to get into interrupt with us, but they've always a bit, not invented to hear
[00:51:20.240 --> 00:51:21.240]   about things.
[00:51:21.240 --> 00:51:25.480]   I would, yes, I'd like to get them to do that.
[00:51:25.480 --> 00:51:34.280]   There was a, I'd try to find the bit that I thought was interesting in this which.
[00:51:34.280 --> 00:51:38.640]   I have to say I'm confused about the whole algorithmic choice aspect of this.
[00:51:38.640 --> 00:51:43.680]   It feels like there's a right wing focus, I mean, not to, I don't know, not to belittlest
[00:51:43.680 --> 00:51:46.120]   from a computer science standpoint or something like that.
[00:51:46.120 --> 00:51:52.560]   But there seems to be a right wing focus on the algorithm as a tool of anti-free speech
[00:51:52.560 --> 00:51:55.520]   that's enforced on existing social networks.
[00:51:55.520 --> 00:51:59.960]   And I don't understand what algorithm choice means in this context.
[00:51:59.960 --> 00:52:03.200]   Oh, you're missing the left wing point of view on this.
[00:52:03.200 --> 00:52:04.760]   You get to show up with, yeah.
[00:52:04.760 --> 00:52:09.960]   The left wing point of view on this is the algorithms lead you down an extremist path.
[00:52:09.960 --> 00:52:10.960]   Okay.
[00:52:10.960 --> 00:52:18.880]   a story effect this week about how invariably YouTube's algorithm will choose extremist
[00:52:18.880 --> 00:52:26.000]   content because it turns out to be more engaging. So that's the other side of the bad bad
[00:52:26.000 --> 00:52:27.000]   algorithms.
[00:52:27.000 --> 00:52:30.520]   I'm sure we choose obnoxious content because that is more engaging. So the...
[00:52:30.520 --> 00:52:39.600]   So it's nice to have plug and play algorithms. So the apapa menu that says fascism, spam,
[00:52:39.600 --> 00:52:40.600]   actual good people.
[00:52:40.600 --> 00:52:47.600]   Yeah, that's part of the problem is, well, how's that gonna work? Yeah.
[00:52:47.600 --> 00:52:52.440]   Well, John Palfrey, I think it is, has argued for a long time. He argued two Facebook. I've
[00:52:52.440 --> 00:52:59.080]   saw him doing that part of me, Davos, where he said, "Let somebody create their own dial."
[00:52:59.080 --> 00:53:02.440]   Well, you can't have nothing but crap. Go ahead. That's your choice.
[00:53:02.440 --> 00:53:03.440]   That's your choice.
[00:53:03.440 --> 00:53:08.160]   I mean, your COVID list for instance is an algorithmic sort of.
[00:53:08.160 --> 00:53:12.080]   Yeah, so Twitter has a bunch of options in it that it says a sort of confusing number
[00:53:12.080 --> 00:53:16.720]   of them now. I'm getting a lot of that left sidebar because it's got lists. It's got
[00:53:16.720 --> 00:53:24.920]   the home versus chronological toggle. It's now got communities, whatever they're called,
[00:53:24.920 --> 00:53:26.480]   if they've gone against them.
[00:53:26.480 --> 00:53:28.960]   I don't have communities. I have.
[00:53:28.960 --> 00:53:30.240]   I think they're in there.
[00:53:30.240 --> 00:53:31.240]   Under more.
[00:53:31.240 --> 00:53:35.240]   That's when you know you got a problem. When you have a lot of Daphne.
[00:53:35.240 --> 00:53:37.200]   It's a little community.
[00:53:37.200 --> 00:53:42.440]   It's a little topics, right? You can set up topics and then they get tagged by weird
[00:53:42.440 --> 00:53:43.440]   topics.
[00:53:43.440 --> 00:53:45.480]   Yeah, it's a part of lists.
[00:53:45.480 --> 00:53:50.720]   Yeah, I did. You know, at first it revealed this by saying, "Give us some topics you're
[00:53:50.720 --> 00:53:51.720]   interested in."
[00:53:51.720 --> 00:53:57.400]   So I am following a few, it turns out. I didn't realize about 18 topics.
[00:53:57.400 --> 00:53:58.400]   I thought it'd be useless.
[00:53:58.400 --> 00:54:02.200]   Yeah, but I don't even know what that means. Does that mean those are going to be new accounts
[00:54:02.200 --> 00:54:03.600]   that I know normally?
[00:54:03.600 --> 00:54:07.080]   That feeds into your home feed. If you look at the home feed, sometimes say because you
[00:54:07.080 --> 00:54:08.080]   follow topic.
[00:54:08.080 --> 00:54:09.080]   Yeah, okay.
[00:54:09.080 --> 00:54:13.920]   Then you've got lists, which is sub lists of people in Twitter. You've also got Circle
[00:54:13.920 --> 00:54:18.280]   now, which I don't actually understand at all because I got bored at that point.
[00:54:18.280 --> 00:54:22.360]   This is our kind of useful. Lists are, here's a subset of accounts. What have they been
[00:54:22.360 --> 00:54:23.360]   talking about recently?
[00:54:23.360 --> 00:54:24.360]   Yeah.
[00:54:24.360 --> 00:54:30.680]   And I've chosen them explicitly and all I get is them.
[00:54:30.680 --> 00:54:33.000]   In your worst crime.
[00:54:33.000 --> 00:54:35.000]   So that's the three ones.
[00:54:35.000 --> 00:54:39.200]   And in the mobile version, you can sort of swipe between lists at the top.
[00:54:39.200 --> 00:54:43.200]   At one point many years ago, I created a bunch of lists of my own.
[00:54:43.200 --> 00:54:46.040]   I don't want to be wider.
[00:54:46.040 --> 00:54:47.040]   Have I looked?
[00:54:47.040 --> 00:54:48.040]   Do you never know?
[00:54:48.040 --> 00:54:50.480]   Yeah, I've totally forgotten about lists.
[00:54:50.480 --> 00:54:51.480]   Yeah.
[00:54:51.480 --> 00:54:57.760]   So lists, unless I click on a list, I'm not, that doesn't change my home feed. But topics
[00:54:57.760 --> 00:54:58.760]   does.
[00:54:58.760 --> 00:55:02.560]   Well, topics only, only in front of it slightly because it just makes them more like to show
[00:55:02.560 --> 00:55:03.560]   up.
[00:55:03.560 --> 00:55:09.640]   Okay. And communities, it's sort of weird subsets that you can pose to and there's only seen
[00:55:09.640 --> 00:55:13.800]   where those communities, but they show up in your home feed or they show up in community
[00:55:13.800 --> 00:55:14.800]   feed.
[00:55:14.800 --> 00:55:16.800]   I was trying to figure out a lot of the class.
[00:55:16.800 --> 00:55:21.360]   Yeah, I don't even understand it and I tried it. It's just, this is part of their, yeah,
[00:55:21.360 --> 00:55:25.320]   I mean, not, you know, not that I want Elon Musk to own it, but it is kind of a, feels
[00:55:25.320 --> 00:55:27.520]   like there's a lot of spaghetti on a lot of walls.
[00:55:27.520 --> 00:55:28.520]   Yeah.
[00:55:28.520 --> 00:55:33.640]   I mean, they've been trying to solve this problem for a long time, you know, and loss.
[00:55:33.640 --> 00:55:38.720]   So topics is a little bit Reddit is what it is. Because you have to ask to join and,
[00:55:38.720 --> 00:55:42.120]   you know, it's, it's a little bit of a Reddit kind of, there's also the thing now where
[00:55:42.120 --> 00:55:45.600]   I could also have a small group of people Twitter circle.
[00:55:45.600 --> 00:55:48.760]   Oh, let me add you to my circle.
[00:55:48.760 --> 00:55:52.640]   It's, it's a, I don't know why, I don't know why.
[00:55:52.640 --> 00:55:55.800]   Who's recommended my wife?
[00:55:55.800 --> 00:55:58.240]   Some people I worked with at tech TV and Pruitt.
[00:55:58.240 --> 00:56:03.680]   So I'm just going to add these people in my circle. Now what do I see them?
[00:56:03.680 --> 00:56:05.280]   You can tweet just to them.
[00:56:05.280 --> 00:56:09.560]   Oh, oh, it's a, now, tweet.
[00:56:09.560 --> 00:56:14.200]   Now try to tweet and see if it, if it, if it, I can choose when I tweet, I have not
[00:56:14.200 --> 00:56:17.120]   said, and now my tweet is grayed out.
[00:56:17.120 --> 00:56:18.120]   Yeah.
[00:56:18.120 --> 00:56:19.160]   It doesn't work.
[00:56:19.160 --> 00:56:20.120]   Oh, there it is.
[00:56:20.120 --> 00:56:21.120]   There it is.
[00:56:21.120 --> 00:56:23.200]   Everyone Twitter circle.
[00:56:23.200 --> 00:56:24.800]   There's only one circle.
[00:56:24.800 --> 00:56:26.360]   And then I'm in other people's community.
[00:56:26.360 --> 00:56:28.320]   People see it when you quit.
[00:56:28.320 --> 00:56:30.720]   This is so funny.
[00:56:30.720 --> 00:56:32.400]   Do other people see it when you're here?
[00:56:32.400 --> 00:56:33.400]   Your Twitter circle.
[00:56:33.400 --> 00:56:34.400]   Yes.
[00:56:34.400 --> 00:56:35.400]   Your Twitter circle can reply.
[00:56:35.400 --> 00:56:38.640]   That only you and select people have seen it.
[00:56:38.640 --> 00:56:43.520]   I mean, if you be in a sort of, I'm so you can be on a, you can have a public click on
[00:56:43.520 --> 00:56:44.520]   Twitter now.
[00:56:44.520 --> 00:56:48.920]   So this isn't exactly choosing an algorithm, but it's, it's Twitter's version of it because
[00:56:48.920 --> 00:56:50.880]   Twitter is all based on who you follow.
[00:56:50.880 --> 00:56:51.880]   So it makes sense.
[00:56:51.880 --> 00:56:52.880]   This is kind of more.
[00:56:52.880 --> 00:56:59.440]   But the, the real point of blue sky, I think, is I could hire someone to create an algorithm
[00:56:59.440 --> 00:57:00.440]   for me.
[00:57:00.440 --> 00:57:05.360]   I could hire someone to create the best science and curate that and find the best people and
[00:57:05.360 --> 00:57:07.640]   eliminate junk science.
[00:57:07.640 --> 00:57:12.120]   And, and, you know, I could hire the Neil deGrasse Tyson version of blue sky.
[00:57:12.120 --> 00:57:14.560]   But then push that out as a product.
[00:57:14.560 --> 00:57:16.240]   Can I push that out as a exact product?
[00:57:16.240 --> 00:57:18.040]   Can I create Jarvis?
[00:57:18.040 --> 00:57:19.040]   Yes.
[00:57:19.040 --> 00:57:20.480]   Strangely enough, a Jarvis site.
[00:57:20.480 --> 00:57:22.120]   No, that name's been taken.
[00:57:22.120 --> 00:57:27.320]   And that would be all the, you know, an excellate curated thing that comes from all blue sky
[00:57:27.320 --> 00:57:29.480]   posts, but running through the Jarvis algorithm.
[00:57:29.480 --> 00:57:30.480]   Right.
[00:57:30.480 --> 00:57:34.080]   And maybe, maybe it also eliminates certain topics.
[00:57:34.080 --> 00:57:36.440]   It doesn't allow Helvetica.
[00:57:36.440 --> 00:57:44.040]   It, it, it, it, it re-prioritizes things.
[00:57:44.040 --> 00:57:47.520]   It adds people or, or, or, or, that's the, that's the, that's the promise.
[00:57:47.520 --> 00:57:51.680]   I said this on Twitter to Jack and he said, yeah, that's the idea.
[00:57:51.680 --> 00:57:53.080]   It's, it's very WordPress-like.
[00:57:53.080 --> 00:57:57.000]   There's a, there's a, there's an open source layer of code and then there's companies
[00:57:57.000 --> 00:57:58.400]   can be built upon top of it.
[00:57:58.400 --> 00:58:05.480]   And as Matt said to us a few weeks ago, WordPress.com is, is, you know, does not dominate the use
[00:58:05.480 --> 00:58:06.480]   of WordPress.
[00:58:06.480 --> 00:58:10.720]   Can I channel our audience at this point?
[00:58:10.720 --> 00:58:12.400]   This is all too damn complicated.
[00:58:12.400 --> 00:58:13.400]   Nobody wants this.
[00:58:13.400 --> 00:58:16.960]   The reason Twitter existed in the first place was it was damn simple.
[00:58:16.960 --> 00:58:20.600]   Cause it was, but you're going to create the twit thing that's going to be really easy
[00:58:20.600 --> 00:58:21.600]   to use.
[00:58:21.600 --> 00:58:24.720]   And that becomes an opportunity for you in business because you simplify it.
[00:58:24.720 --> 00:58:25.720]   Yes, it's complicated.
[00:58:25.720 --> 00:58:28.320]   And you Leo will come on and you will create a beautiful.
[00:58:28.320 --> 00:58:29.320]   All right.
[00:58:29.320 --> 00:58:32.240]   So let's say I created some beautiful simple thing.
[00:58:32.240 --> 00:58:36.000]   So, don't have to add it.
[00:58:36.000 --> 00:58:37.920]   Let's use this with a circle.
[00:58:37.920 --> 00:58:38.920]   Sorry.
[00:58:38.920 --> 00:58:40.920]   Oh, does it change?
[00:58:40.920 --> 00:58:42.640]   How does the circle work now?
[00:58:42.640 --> 00:58:44.040]   Now you're doing a circle.
[00:58:44.040 --> 00:58:46.840]   Now you tweet and you can choose a, who get that.
[00:58:46.840 --> 00:58:50.160]   Oh, I see everyone circle or so.
[00:58:50.160 --> 00:58:53.840]   If I create something that is simple because I know frankly that people don't want anything
[00:58:53.840 --> 00:58:56.760]   this complex, I get, I'll be, I'll be the, you know, the arm.
[00:58:56.760 --> 00:58:58.160]   Leo's best stuff.
[00:58:58.160 --> 00:59:00.480]   And then what?
[00:59:00.480 --> 00:59:02.200]   Where is it hosted?
[00:59:02.200 --> 00:59:04.840]   It's federated.
[00:59:04.840 --> 00:59:06.840]   So I have to host it.
[00:59:06.840 --> 00:59:08.520]   Oh, there's a whole, there's a whole thing.
[00:59:08.520 --> 00:59:12.080]   Or I could go to micro.blog or somewhere and they can host it.
[00:59:12.080 --> 00:59:13.080]   Okay.
[00:59:13.080 --> 00:59:14.080]   Right.
[00:59:14.080 --> 00:59:15.080]   And then it's in it.
[00:59:15.080 --> 00:59:19.560]   The advantage is somebody can move out or the, exactly, they can take with them their
[00:59:19.560 --> 00:59:22.840]   own content that they posted there and their social graph, both.
[00:59:22.840 --> 00:59:23.840]   So I see they can move.
[00:59:23.840 --> 00:59:27.440]   I see exactly why Kevin Marks, you said this, this is just the internet.
[00:59:27.440 --> 00:59:29.160]   This is called the worldwide web.
[00:59:29.160 --> 00:59:30.720]   This is websites.
[00:59:30.720 --> 00:59:35.360]   And maybe web mentions, you know, so this is the point, you know, that basically.
[00:59:35.360 --> 00:59:36.360]   It's good.
[00:59:36.360 --> 00:59:37.360]   We return to the web.
[00:59:37.360 --> 00:59:39.280]   Yeah, but we already have this.
[00:59:39.280 --> 00:59:43.240]   We have this, we kind of have this with nobody's using it, by the way, but the challenges
[00:59:43.240 --> 00:59:44.240]   can't be able to use it.
[00:59:44.240 --> 00:59:45.240]   Yeah.
[00:59:45.240 --> 00:59:49.280]   And so I'm happy to go and talk to the blue sky people or the app, pro to people who
[00:59:49.280 --> 00:59:53.160]   call this week and say, yeah, I agree with a bunch of what you're saying.
[00:59:53.160 --> 00:59:54.160]   Can you make it map?
[00:59:54.160 --> 00:59:58.240]   Can you make your web web based version of this match our web based version of this?
[00:59:58.240 --> 00:59:59.240]   And then we can inter operate.
[00:59:59.240 --> 01:00:00.240]   And that's great.
[01:00:00.240 --> 01:00:03.840]   And to tell them, I said, we put my before my sent and then said, yeah, sure.
[01:00:03.840 --> 01:00:04.840]   And now they have them.
[01:00:04.840 --> 01:00:05.840]   World peace right here.
[01:00:05.840 --> 01:00:07.560]   We can see it before our eyes.
[01:00:07.560 --> 01:00:11.840]   But I don't see any massive adoption of any of this.
[01:00:11.840 --> 01:00:17.640]   Well, because it's, you know, you're killing it before it's even the zygote is even impregnated
[01:00:17.640 --> 01:00:18.640]   here.
[01:00:18.640 --> 01:00:19.640]   Geez.
[01:00:19.640 --> 01:00:21.920]   But I mean, honestly, let's just be honest with ourselves.
[01:00:21.920 --> 01:00:27.680]   If we take a look at it, nobody's going to get to massive and scale without to the old.
[01:00:27.680 --> 01:00:29.680]   But this isn't the point of this.
[01:00:29.680 --> 01:00:30.680]   Same as you.
[01:00:30.680 --> 01:00:33.200]   The master has is Jack once Twitter.
[01:00:33.200 --> 01:00:36.400]   I mean, Jack's goal is that Twitter would adopt blue sky, right?
[01:00:36.400 --> 01:00:37.400]   So that's what we get to your massive.
[01:00:37.400 --> 01:00:42.040]   It would just be one of one, a blue sky based or an app protocol based.
[01:00:42.040 --> 01:00:43.040]   Yeah.
[01:00:43.040 --> 01:00:46.840]   I mean, conceivably, I don't know if he'll have the ability to do it, but if Elon actually
[01:00:46.840 --> 01:00:47.840]   does complete.
[01:00:47.840 --> 01:00:48.840]   He wants not to do this.
[01:00:48.840 --> 01:00:49.840]   No, I thought he won.
[01:00:49.840 --> 01:00:50.840]   This is independent of you.
[01:00:50.840 --> 01:00:53.840]   It is, but he's going to be destroyed.
[01:00:53.840 --> 01:00:54.840]   I've touched it.
[01:00:54.840 --> 01:00:55.840]   Okay.
[01:00:55.840 --> 01:00:58.760]   Yeah, because Jack wants it.
[01:00:58.760 --> 01:01:00.600]   That's why Jack's sucking up to Elon, I think.
[01:01:00.600 --> 01:01:04.360]   There's your first MVP gone.
[01:01:04.360 --> 01:01:05.360]   Who's next?
[01:01:05.360 --> 01:01:11.360]   What Twitter has to do is open up to it.
[01:01:11.360 --> 01:01:12.360]   Yes.
[01:01:12.360 --> 01:01:15.680]   And Jack is going to say to Elon, this is the path.
[01:01:15.680 --> 01:01:17.040]   This is how you also get out of trouble.
[01:01:17.040 --> 01:01:19.640]   Elon, somebody posted something they didn't post it on Twitter.
[01:01:19.640 --> 01:01:22.840]   They posted it on a Leoville and who cares?
[01:01:22.840 --> 01:01:26.000]   The government can't come up for you and you can't take it down and that's your free
[01:01:26.000 --> 01:01:27.640]   speech world you want.
[01:01:27.640 --> 01:01:29.200]   Elon, follow me.
[01:01:29.200 --> 01:01:30.200]   Follow the light, Elon.
[01:01:30.200 --> 01:01:31.840]   Follow the lights, says Jack.
[01:01:31.840 --> 01:01:33.840]   And will Elon do it?
[01:01:33.840 --> 01:01:34.840]   No.
[01:01:34.840 --> 01:01:35.840]   I don't know.
[01:01:35.840 --> 01:01:36.840]   He might.
[01:01:36.840 --> 01:01:37.840]   That smells very block chaney.
[01:01:37.840 --> 01:01:40.840]   I know there's no blockchain element to it or at least in this invitation, but that idea
[01:01:40.840 --> 01:01:45.880]   of like, but it is a, this is the, why you have layers and protocols is it lets you wash
[01:01:45.880 --> 01:01:48.000]   your hands of the problems of other layers.
[01:01:48.000 --> 01:01:52.000]   And then we've seen what happens to cloud flare when cloud flare tries to say we are
[01:01:52.000 --> 01:01:54.360]   not a layer of responsibility for the content.
[01:01:54.360 --> 01:01:56.240]   Well, this is an uncontrollable world.
[01:01:56.240 --> 01:01:57.240]   Right.
[01:01:57.240 --> 01:02:01.080]   That's why that see the conservatives will like it because it's uncontrollable by the
[01:02:01.080 --> 01:02:02.080]   libs.
[01:02:02.080 --> 01:02:05.040]   The libs should like it because it's uncontrollable by government.
[01:02:05.040 --> 01:02:11.880]   Kevin, what is your best sense of the chances of success?
[01:02:11.880 --> 01:02:15.120]   Um, you know, it's, it's like any of these things.
[01:02:15.120 --> 01:02:17.600]   It's like, you know, Massadon has done reasonably well.
[01:02:17.600 --> 01:02:22.600]   It's ticking over.
[01:02:22.600 --> 01:02:24.600]   It's not, it's not grown to the same size as, as any of the others as Twitter or Tumblr
[01:02:24.600 --> 01:02:26.480]   say, but it's got a reasonably stable set of people using it.
[01:02:26.480 --> 01:02:29.360]   And it's shown up some of the issues that have come in when you have multiple interoprating
[01:02:29.360 --> 01:02:30.960]   servers and things like that.
[01:02:30.960 --> 01:02:32.520]   So that's a, that's a good model to look at.
[01:02:32.520 --> 01:02:35.680]   And you know, it was two or three years ago, we were chatting about that here.
[01:02:35.680 --> 01:02:36.680]   Was it maybe it's for?
[01:02:36.680 --> 01:02:37.680]   Yeah.
[01:02:37.680 --> 01:02:38.840]   I still run a, a Massadon instance.
[01:02:38.840 --> 01:02:41.520]   I can't say it's particularly active.
[01:02:41.520 --> 01:02:46.240]   Uh, in fact, uh, Massadon technology just shut down.
[01:02:46.240 --> 01:02:47.240]   Um, yeah.
[01:02:47.240 --> 01:02:48.240]   So that, yeah.
[01:02:48.240 --> 01:02:51.320]   So I, that is taking over aggression.
[01:02:51.320 --> 01:02:53.040]   It's kind of idling.
[01:02:53.040 --> 01:02:57.960]   I mean, I love Massadon, but, you know, it's got the network problem.
[01:02:57.960 --> 01:03:03.680]   It's all of these have the same network problem, which is until your friends use it, you're
[01:03:03.680 --> 01:03:05.000]   not going to use it.
[01:03:05.000 --> 01:03:09.880]   Uh, I'm sure it's working well for some people whose friends are all using it.
[01:03:09.880 --> 01:03:10.880]   It's very easy.
[01:03:10.880 --> 01:03:11.880]   And that's it.
[01:03:11.880 --> 01:03:12.880]   Well, that's like any of these things.
[01:03:12.880 --> 01:03:14.600]   I mean, you know, and for some of you said, I approve of that.
[01:03:14.600 --> 01:03:15.600]   That was what I liked.
[01:03:15.600 --> 01:03:16.800]   That's a real social network.
[01:03:16.800 --> 01:03:17.800]   Yeah.
[01:03:17.800 --> 01:03:21.960]   15 years ago, we had a whole bunch of social networks that people chose because they're
[01:03:21.960 --> 01:03:23.960]   friends with their rather than business.
[01:03:23.960 --> 01:03:24.960]   Plugs.
[01:03:24.960 --> 01:03:25.960]   Plugs.
[01:03:25.960 --> 01:03:27.960]   They were wonderful things.
[01:03:27.960 --> 01:03:30.120]   And we, and we make connections and we wrote about each other.
[01:03:30.120 --> 01:03:31.120]   We connected.
[01:03:31.120 --> 01:03:32.120]   It was a beautiful thing.
[01:03:32.120 --> 01:03:33.880]   Let me take a little break, come back.
[01:03:33.880 --> 01:03:35.320]   We will do more.
[01:03:35.320 --> 01:03:38.280]   Kevin, take a, uh, get a cough, sweetie.
[01:03:38.280 --> 01:03:40.000]   That's what's the brand.
[01:03:40.000 --> 01:03:41.000]   What's the brand?
[01:03:41.000 --> 01:03:44.800]   What's the very English brand you use for coughs, cough drops, Kevin?
[01:03:44.800 --> 01:03:45.800]   It's got to be something.
[01:03:45.800 --> 01:03:48.440]   It's look it's cough, sweeties.
[01:03:48.440 --> 01:03:50.040]   For when you can't breathe.
[01:03:50.040 --> 01:03:53.160]   Get a lock it.
[01:03:53.160 --> 01:03:54.640]   All right.
[01:03:54.640 --> 01:03:57.720]   I'm looking them up.
[01:03:57.720 --> 01:03:58.720]   Here we go.
[01:03:58.720 --> 01:03:59.720]   Fishman's friends.
[01:03:59.720 --> 01:04:00.720]   I don't actually have any of those.
[01:04:00.720 --> 01:04:01.720]   Fishman's friends.
[01:04:01.720 --> 01:04:02.720]   Oh, I love Fishman's friends.
[01:04:02.720 --> 01:04:03.880]   Gorton to lobster.
[01:04:03.880 --> 01:04:05.360]   Grod.
[01:04:05.360 --> 01:04:07.360]   Lock it's honey and lemon times 10.
[01:04:07.360 --> 01:04:10.360]   Those are the ones that I'm down to one now.
[01:04:10.360 --> 01:04:12.560]   So I'm going to try them for 20 bucks.
[01:04:12.560 --> 01:04:13.560]   Last lock it.
[01:04:13.560 --> 01:04:14.560]   Well, that's in the US, of course.
[01:04:14.560 --> 01:04:15.560]   You're outside.
[01:04:15.560 --> 01:04:16.560]   You're a super Brit.
[01:04:16.560 --> 01:04:17.560]   Yeah.
[01:04:17.560 --> 01:04:18.560]   Yeah.
[01:04:18.560 --> 01:04:19.560]   Look, you can get all three if you want.
[01:04:19.560 --> 01:04:25.920]   Bekeepers, naturals, traditional medicinals, and lock it's honey and lemon for the, uh,
[01:04:25.920 --> 01:04:28.280]   anglo file on this all.
[01:04:28.280 --> 01:04:36.160]   Our show today brought to you by HPE Hewlett Packard Enterprise Green Lake orchestrated
[01:04:36.160 --> 01:04:38.760]   by the experts at CDW.
[01:04:38.760 --> 01:04:44.040]   The helpful people at CDW understand your organization needs simple management over
[01:04:44.040 --> 01:04:45.880]   its big data, right?
[01:04:45.880 --> 01:04:51.720]   But with some needing to keep their workloads on prem for organizational requirements, the
[01:04:51.720 --> 01:04:54.280]   CanFee challenging to organize and optimize your data.
[01:04:54.280 --> 01:04:59.960]   And that's where CDW can help your organization by consolidating and managing all your data
[01:04:59.960 --> 01:05:08.360]   in one flexible, unified experience with the HPE Green Lake edge to cloud platform.
[01:05:08.360 --> 01:05:12.360]   The experience you'll get with HPE Green Lake is unique because no matter where your data
[01:05:12.360 --> 01:05:18.520]   or applications live, you can free up energy and resources with automated processes and
[01:05:18.520 --> 01:05:19.520]   streamlined management.
[01:05:19.520 --> 01:05:22.880]   And we can only use a little more streamlining in our life.
[01:05:22.880 --> 01:05:23.880]   Am I right?
[01:05:23.880 --> 01:05:30.600]   Not only that HPE Green Lake creates a seamless cloud experience among multiple data environments,
[01:05:30.600 --> 01:05:35.400]   thanks to the AVAs as a service model that meets your remote workforce at the edge.
[01:05:35.400 --> 01:05:39.480]   And with unrivaled scalability, you'll see an instant increasing capacity allowing for
[01:05:39.480 --> 01:05:42.520]   greater flexibility and accelerated business growth.
[01:05:42.520 --> 01:05:47.560]   So your team can tackle bigger priorities like innovation.
[01:05:47.560 --> 01:05:53.640]   When you need to get more out of your technology, HPE makes data transformation possible.
[01:05:53.640 --> 01:05:56.280]   CDW makes it powerful.
[01:05:56.280 --> 01:06:05.960]   Learn more at CDW.com/HPECDW.com/HPE.
[01:06:05.960 --> 01:06:10.520]   We thank them so much for their support of this week in Google.
[01:06:10.520 --> 01:06:16.160]   Yeah, I mean, you know, so blue skies moving forward, great.
[01:06:16.160 --> 01:06:17.160]   I don't know.
[01:06:17.160 --> 01:06:18.840]   I don't even understand.
[01:06:18.840 --> 01:06:22.760]   I don't feel like this is something that's you're going to just get a bandwagon effect.
[01:06:22.760 --> 01:06:26.040]   Everybody's going to go all crazy for it.
[01:06:26.040 --> 01:06:30.600]   You know, look at all the things Twitter is already doing that none of us really even
[01:06:30.600 --> 01:06:31.600]   know about.
[01:06:31.600 --> 01:06:41.960]   We've also got the weird Mastodon forks like Parle and the other one was.
[01:06:41.960 --> 01:06:43.560]   Gab is a Mastodon.
[01:06:43.560 --> 01:06:46.840]   Gab is a Mastodon fork.
[01:06:46.840 --> 01:06:49.960]   Truth Social was a Mastodon fork, I believe.
[01:06:49.960 --> 01:06:51.960]   I don't know how that got resolved.
[01:06:51.960 --> 01:06:52.960]   Yeah.
[01:06:52.960 --> 01:06:55.400]   Well, there was open source code you could use.
[01:06:55.400 --> 01:06:57.360]   Yeah, it looks just like Twitter.
[01:06:57.360 --> 01:06:58.360]   So why not?
[01:06:58.360 --> 01:06:59.360]   Yeah.
[01:06:59.360 --> 01:07:03.920]   There's an Instagram clone called PixelFed that's also a Mastodon.
[01:07:03.920 --> 01:07:07.160]   And what's nice is it's federated.
[01:07:07.160 --> 01:07:13.840]   So you can follow, let me log in here, Benita, before you show it so I can show what it looks
[01:07:13.840 --> 01:07:14.840]   like.
[01:07:14.840 --> 01:07:17.160]   It looks just like, oh, my credentials don't match.
[01:07:17.160 --> 01:07:18.160]   What is that?
[01:07:18.160 --> 01:07:19.160]   Oh, here we go.
[01:07:19.160 --> 01:07:20.920]   I was using the long login.
[01:07:20.920 --> 01:07:22.760]   There we go.
[01:07:22.760 --> 01:07:26.960]   So this, I can follow this on a Mastodon instance.
[01:07:26.960 --> 01:07:31.080]   No, I guess I'm going to have to reset my password.
[01:07:31.080 --> 01:07:36.440]   Maybe something's happened to this because I can't log in.
[01:07:36.440 --> 01:07:37.440]   But it looks nice.
[01:07:37.440 --> 01:07:40.000]   I mean, maybe I can just, can I?
[01:07:40.000 --> 01:07:42.320]   No, I can't really.
[01:07:42.320 --> 01:07:43.960]   But it doesn't look at all like Mastodon.
[01:07:43.960 --> 01:07:44.960]   Here we go.
[01:07:44.960 --> 01:07:45.960]   Here's a sample.
[01:07:45.960 --> 01:07:46.960]   It doesn't look at all like Mastodon.
[01:07:46.960 --> 01:07:47.960]   It looks a lot more like Instagram.
[01:07:47.960 --> 01:07:48.960]   You've got comments.
[01:07:48.960 --> 01:07:49.960]   You've got likes.
[01:07:49.960 --> 01:07:50.960]   You've got suggestions.
[01:07:50.960 --> 01:07:52.320]   But it is Mastodon.
[01:07:52.320 --> 01:07:55.880]   So that's kind of cool, right?
[01:07:55.880 --> 01:07:57.600]   It's all in the Fediverse.
[01:07:57.600 --> 01:08:03.040]   Yeah, and imagine if you had a universal identity, Mrs. Kevin's vision all along, right?
[01:08:03.040 --> 01:08:11.000]   Across the platforms and you publish once to many places and maybe the beginnings and
[01:08:11.000 --> 01:08:14.600]   then the roots are there and what Kevin has done and Mastodon is done and if Twitter
[01:08:14.600 --> 01:08:16.800]   can come along, don't give up yet.
[01:08:16.800 --> 01:08:18.360]   Boss, don't give up.
[01:08:18.360 --> 01:08:19.360]   Have a little hope.
[01:08:19.360 --> 01:08:20.360]   Yeah.
[01:08:20.360 --> 01:08:23.520]   Yeah, Inter-Aruzis is a slow process because you've got to get people to believe in it
[01:08:23.520 --> 01:08:24.520]   and then implement it.
[01:08:24.520 --> 01:08:25.520]   Yes.
[01:08:25.520 --> 01:08:28.120]   And then make it easier for them to do it, which is part of the iteration of this.
[01:08:28.120 --> 01:08:29.120]   Right.
[01:08:29.120 --> 01:08:30.120]   And that's something we learned through the...
[01:08:30.120 --> 01:08:31.640]   What's the definition of critical mass, too?
[01:08:31.640 --> 01:08:32.640]   Is critical mass everybody?
[01:08:32.640 --> 01:08:34.680]   I don't think we want that necessarily anymore.
[01:08:34.680 --> 01:08:36.920]   Critical mass is the people that you care are there.
[01:08:36.920 --> 01:08:39.320]   You know, we'll see.
[01:08:39.320 --> 01:08:43.720]   Well, I think the thing we're seeing is that people are less comfortable with publishing
[01:08:43.720 --> 01:08:48.760]   stuff publicly and they're doing more stuff in friend groups and chat chat groups and
[01:08:48.760 --> 01:08:50.240]   things now anyway.
[01:08:50.240 --> 01:08:55.160]   I feel like Discord, for example, has already solved this, pretty much solved this problem
[01:08:55.160 --> 01:09:01.000]   and just because it's not visible, you know, the only people who see what's going on are
[01:09:01.000 --> 01:09:03.040]   the people in those groups.
[01:09:03.040 --> 01:09:05.520]   You know, we're not even aware of it.
[01:09:05.520 --> 01:09:06.520]   Discord is messy.
[01:09:06.520 --> 01:09:10.120]   I think to a Twitter user, yeah.
[01:09:10.120 --> 01:09:11.120]   Yeah.
[01:09:11.120 --> 01:09:12.120]   Look at those.
[01:09:12.120 --> 01:09:14.120]   Oh, it's thought to a Slack user.
[01:09:14.120 --> 01:09:15.120]   It's thought to a Slack user.
[01:09:15.120 --> 01:09:17.760]   Or to a Facebook user.
[01:09:17.760 --> 01:09:19.720]   I think it's a good alternative, right?
[01:09:19.720 --> 01:09:20.720]   Yeah.
[01:09:20.720 --> 01:09:22.360]   It's less missing in Facebook.
[01:09:22.360 --> 01:09:23.360]   Yeah.
[01:09:23.360 --> 01:09:24.360]   Yeah.
[01:09:24.360 --> 01:09:25.360]   All right.
[01:09:25.360 --> 01:09:26.360]   But it doesn't matter.
[01:09:26.360 --> 01:09:27.960]   The AI is going to speak for us.
[01:09:27.960 --> 01:09:32.880]   It'll be fine.
[01:09:32.880 --> 01:09:33.880]   Let's move on then.
[01:09:33.880 --> 01:09:36.760]   I guess I mean, we'll continue to follow this for sure.
[01:09:36.760 --> 01:09:41.040]   We will be talking more about it with Ravel next week.
[01:09:41.040 --> 01:09:44.480]   Ravel is the creator of planetary and has its own.
[01:09:44.480 --> 01:09:45.480]   What is it called?
[01:09:45.480 --> 01:09:46.480]   What's the protocol rumble?
[01:09:46.480 --> 01:09:47.480]   I can't remember.
[01:09:47.480 --> 01:09:48.480]   Yeah.
[01:09:48.480 --> 01:09:49.480]   No.
[01:09:49.480 --> 01:09:50.480]   Something like that.
[01:09:50.480 --> 01:09:55.560]   Oh, is it Ravel?
[01:09:55.560 --> 01:09:59.800]   It's called it's gossip based.
[01:09:59.800 --> 01:10:00.800]   Is it Ravel?
[01:10:00.800 --> 01:10:03.760]   Ravel, Ravel is it a McDonald's based protocol?
[01:10:03.760 --> 01:10:04.760]   Ravel.
[01:10:04.760 --> 01:10:09.680]   I'm looking at the website here, planetary dot social.
[01:10:09.680 --> 01:10:17.000]   So even even this is really being sold more as something looks just like Twitter, right?
[01:10:17.000 --> 01:10:19.000]   But has advantages over Twitter.
[01:10:19.000 --> 01:10:20.000]   Scuttle butts there.
[01:10:20.000 --> 01:10:21.000]   Scuttle butts.
[01:10:21.000 --> 01:10:22.000]   That's what it's called.
[01:10:22.000 --> 01:10:23.000]   Yeah.
[01:10:23.000 --> 01:10:24.000]   Scuttle butts.
[01:10:24.000 --> 01:10:25.800]   It's a great name.
[01:10:25.800 --> 01:10:29.240]   Oh, gossip was the, wasn't it the Google protocol long ago?
[01:10:29.240 --> 01:10:30.240]   Google chat?
[01:10:30.240 --> 01:10:32.240]   Maybe like that.
[01:10:32.240 --> 01:10:33.240]   I think there was a lot of that.
[01:10:33.240 --> 01:10:34.240]   Oh, good.
[01:10:34.240 --> 01:10:37.280]   Like gossip is a generic term for that kind of protocol where you share stuff side to side.
[01:10:37.280 --> 01:10:40.040]   It's a bit sort of using it like where you've got a bunch of servers that share bits of
[01:10:40.040 --> 01:10:42.880]   pieces to each other and gather stuff that way.
[01:10:42.880 --> 01:10:44.840]   What happened to XMPP?
[01:10:44.840 --> 01:10:47.080]   Would that have been a good choice?
[01:10:47.080 --> 01:10:53.800]   Should we throw out something good like Google's right to throw at RSS?
[01:10:53.800 --> 01:11:00.480]   So XMPP was reasonably good at interrupt but it was a bit annoying to scale.
[01:11:00.480 --> 01:11:03.680]   There was a certain amount of friction about the extensibility.
[01:11:03.680 --> 01:11:07.960]   Basically it was one of those XML protocols that got a bit verbose.
[01:11:07.960 --> 01:11:11.920]   But it was, it was, basically it was useful for interrupt until everyone decided they didn't
[01:11:11.920 --> 01:11:12.920]   want to interrupt anymore.
[01:11:12.920 --> 01:11:13.920]   That was the thing.
[01:11:13.920 --> 01:11:14.920]   It's like a lot.
[01:11:14.920 --> 01:11:15.920]   Yeah, very wide silos.
[01:11:15.920 --> 01:11:16.920]   Yeah, yeah.
[01:11:16.920 --> 01:11:21.960]   Just using it, Facebook was using it, aim was using Microsoft was using it.
[01:11:21.960 --> 01:11:26.080]   And then they all decided, alongside their own protocols, and they all decided actually
[01:11:26.080 --> 01:11:27.080]   we don't want to do this anymore.
[01:11:27.080 --> 01:11:29.040]   We want to have our own proprietary ones.
[01:11:29.040 --> 01:11:33.800]   We can make it much more, much more the same shape as our internal APIs and do it that
[01:11:33.800 --> 01:11:34.800]   way.
[01:11:34.800 --> 01:11:39.520]   And when it's stopped in Tropra, which is a shame.
[01:11:39.520 --> 01:11:43.880]   And they, which is my same experience with open social, which is like, yeah, we can make
[01:11:43.880 --> 01:11:44.880]   it with Intropra.
[01:11:44.880 --> 01:11:45.880]   It's like, yeah, it's great.
[01:11:45.880 --> 01:11:46.880]   It's really cool.
[01:11:46.880 --> 01:11:47.880]   Yeah.
[01:11:47.880 --> 01:11:48.880]   Okay.
[01:11:48.880 --> 01:11:49.880]   I, I, yeah.
[01:11:49.880 --> 01:11:53.360]   I stand by what we said earlier.
[01:11:53.360 --> 01:11:58.120]   You weren't here yet, Kevin, when we said that social is dead, it's being replaced by
[01:11:58.120 --> 01:11:59.120]   content.
[01:11:59.120 --> 01:12:00.120]   Oh, content is dead.
[01:12:00.120 --> 01:12:02.960]   It's being replaced by AI.
[01:12:02.960 --> 01:12:04.200]   It's being replaced by AI.
[01:12:04.200 --> 01:12:07.680]   So it's all over for everybody, everybody.
[01:12:07.680 --> 01:12:14.280]   And now you've got Latisha James, people like her, accusing social media of radicalizing
[01:12:14.280 --> 01:12:15.280]   people.
[01:12:15.280 --> 01:12:20.760]   The New York State Attorney's General's Office and the governor on Tuesday released the findings
[01:12:20.760 --> 01:12:26.040]   of a investigative report on the mass shooting in Buffalo.
[01:12:26.040 --> 01:12:31.640]   The shooter was first indoctrinated and radicalized through online platforms.
[01:12:31.640 --> 01:12:36.000]   And the doctor and doctor and doctor native.
[01:12:36.000 --> 01:12:37.400]   That the word they used?
[01:12:37.400 --> 01:12:38.400]   No, no, I'm sorry.
[01:12:38.400 --> 01:12:39.400]   I'm sorry.
[01:12:39.400 --> 01:12:40.400]   I'll make it up.
[01:12:40.400 --> 01:12:44.440]   First indoctrinated through online forms.
[01:12:44.440 --> 01:12:49.920]   The radicalization happened by quote, explicitly racist, bigoted and violent content he viewed
[01:12:49.920 --> 01:12:53.640]   online on 4chan, Reddit and elsewhere.
[01:12:53.640 --> 01:13:00.440]   She said fuel fringe platforms like 4chan fuel radicalization and later damage vulnerable
[01:13:00.440 --> 01:13:03.040]   communities.
[01:13:03.040 --> 01:13:08.440]   Then they said, oh, and by the way, it shouldn't be allowed that you live stream mass shootings.
[01:13:08.440 --> 01:13:09.440]   Yeah, I agree.
[01:13:09.440 --> 01:13:10.440]   That seems to allow that.
[01:13:10.440 --> 01:13:11.440]   Yeah.
[01:13:11.440 --> 01:13:14.280]   If no one allows that pass along.
[01:13:14.280 --> 01:13:15.920]   Pass a lot won't happen again.
[01:13:15.920 --> 01:13:16.920]   Yeah.
[01:13:16.920 --> 01:13:19.960]   The suspect live streamed on Twitch for about two minutes.
[01:13:19.960 --> 01:13:25.480]   It is the case though that those two minutes got circulated among extremist groups.
[01:13:25.480 --> 01:13:31.080]   And she said even this relatively short video is enough for the horrific content to spread
[01:13:31.080 --> 01:13:32.960]   widely and inspire future shooters.
[01:13:32.960 --> 01:13:33.960]   And you know what?
[01:13:33.960 --> 01:13:34.960]   That's probably true.
[01:13:34.960 --> 01:13:36.960]   You know, the target.
[01:13:36.960 --> 01:13:39.680]   So did news stories about it in the past.
[01:13:39.680 --> 01:13:40.680]   Right.
[01:13:40.680 --> 01:13:41.680]   Lots of things.
[01:13:41.680 --> 01:13:42.680]   Well, no, I did not say his name.
[01:13:42.680 --> 01:13:44.960]   The name appears in the report.
[01:13:44.960 --> 01:13:46.040]   I'm not going to say his name.
[01:13:46.040 --> 01:13:47.680]   I don't think we ever should glorify these people.
[01:13:47.680 --> 01:13:49.200]   You should never know who they are.
[01:13:49.200 --> 01:13:53.480]   They should disappear down the whole of memory, whole of history.
[01:13:53.480 --> 01:13:55.360]   But that's not always the case.
[01:13:55.360 --> 01:13:59.760]   The new democratic governor of New York, Kathy Hochl Hochl.
[01:13:59.760 --> 01:14:00.760]   Hochl.
[01:14:00.760 --> 01:14:01.760]   Yes.
[01:14:01.760 --> 01:14:02.760]   Hochl.
[01:14:02.760 --> 01:14:03.760]   Hochl.
[01:14:03.760 --> 01:14:08.320]   Hochl says this report offers a chilling account of factors that contributed to this incident.
[01:14:08.320 --> 01:14:13.880]   And importantly, a roadmap toward greater accountability.
[01:14:13.880 --> 01:14:15.920]   We need to add here with this world panic.
[01:14:15.920 --> 01:14:16.920]   Yeah.
[01:14:16.920 --> 01:14:20.760]   Well, in the section 230 button you press and it like does a sound game thing for section
[01:14:20.760 --> 01:14:23.440]   and it is, it is, of course, you know, that's where they're going.
[01:14:23.440 --> 01:14:24.440]   But that's what's going on.
[01:14:24.440 --> 01:14:28.880]   I can't disagree with them though that that is that is the fact of the matter.
[01:14:28.880 --> 01:14:31.480]   I don't think you should pass a law against radicalization.
[01:14:31.480 --> 01:14:33.840]   Well, but, but you know, there are.
[01:14:33.840 --> 01:14:35.240]   It's the thing you do.
[01:14:35.240 --> 01:14:36.680]   I mean, I'm the Englishman here.
[01:14:36.680 --> 01:14:39.200]   But that's the missing link.
[01:14:39.200 --> 01:14:40.200]   Yeah, exactly.
[01:14:40.200 --> 01:14:41.760]   Kevin's exactly right.
[01:14:41.760 --> 01:14:45.760]   There was another, there was another paper today that that I actually put up under my
[01:14:45.760 --> 01:14:55.200]   stuff at 120 that that backed up work done by a Danish social psychologist named Michael
[01:14:55.200 --> 01:15:00.320]   Bonne Peterson in which they say that the the echo chambers are the ones in our real
[01:15:00.320 --> 01:15:01.320]   life.
[01:15:01.320 --> 01:15:05.160]   And what the internet does is it exposes us to people that we don't like and we fear
[01:15:05.160 --> 01:15:07.120]   and that and that it does not turn us in.
[01:15:07.120 --> 01:15:08.640]   It does not make us hate.
[01:15:08.640 --> 01:15:17.600]   It brings our hates out and so if you're going to hate those, I hate those Nazis.
[01:15:17.600 --> 01:15:20.120]   I agree with them.
[01:15:20.120 --> 01:15:24.760]   So the problem is that if you say if you it's a very oversimplified answer to say, oh,
[01:15:24.760 --> 01:15:26.320]   this guy was perfectly normal.
[01:15:26.320 --> 01:15:29.560]   And then he watched some online videos that he just started to go off and shoot at that.
[01:15:29.560 --> 01:15:30.560]   Aren't they?
[01:15:30.560 --> 01:15:33.160]   Are they saying that if they are kind of saying that they're kind of who's radicalized.
[01:15:33.160 --> 01:15:34.160]   Yeah.
[01:15:34.160 --> 01:15:37.000]   And he was before that he wasn't radical.
[01:15:37.000 --> 01:15:40.360]   And no, before that he was he was full with hate.
[01:15:40.360 --> 01:15:44.200]   And it and and yes, he found the meeting in an avenue.
[01:15:44.200 --> 01:15:45.200]   Exactly.
[01:15:45.200 --> 01:15:46.200]   But but which is not good.
[01:15:46.200 --> 01:15:48.280]   He's a company should take it down.
[01:15:48.280 --> 01:15:52.200]   But this is like this is like pro anorexia sites, right?
[01:15:52.200 --> 01:15:57.160]   I mean, that's been an issue for decades now and and not necessarily it's certainly
[01:15:57.160 --> 01:16:01.760]   hasn't been one, but there were a lot of battles fought to try to reduce the amount of exposure
[01:16:01.760 --> 01:16:03.880]   of that kind of information align.
[01:16:03.880 --> 01:16:04.880]   It's the reinforcement.
[01:16:04.880 --> 01:16:06.880]   It's not necessarily an echo chamber.
[01:16:06.880 --> 01:16:11.480]   It's a tighter and tighter feedback loop against more and more like minded people who
[01:16:11.480 --> 01:16:14.840]   reinforce the most radical of your ideas.
[01:16:14.840 --> 01:16:17.200]   And you know, I see this happen on the left.
[01:16:17.200 --> 01:16:23.560]   You see people following, you know, for a while, Louise mench would say any crazy thing.
[01:16:23.560 --> 01:16:24.560]   Kevin knows very well who she is.
[01:16:24.560 --> 01:16:25.560]   I'm sure the rest of you do too.
[01:16:25.560 --> 01:16:27.960]   But former MP who moved to the U S.
[01:16:27.960 --> 01:16:30.360]   Her name and all the while there.
[01:16:30.360 --> 01:16:31.560]   Oh, well, she was during Trump.
[01:16:31.560 --> 01:16:36.720]   It's, you know, the United States Supreme Court Marshall is going to arrest Trump on
[01:16:36.720 --> 01:16:42.960]   the runway and people wanted to hear that and they would amplify it or some of the election,
[01:16:42.960 --> 01:16:48.560]   not fraud, but the people of election integrity people, not the people like Matt, who's last
[01:16:48.560 --> 01:16:54.600]   name and black Matt blaze who are sensible and rigorous and academic and site have citation
[01:16:54.600 --> 01:16:55.600]   and so forth.
[01:16:55.600 --> 01:17:00.080]   But there are other people in that, you know, realm who exists solely to feed that.
[01:17:00.080 --> 01:17:02.280]   So it's not a right wing only phenomenon.
[01:17:02.280 --> 01:17:05.680]   It's that the right wasn't didn't as much enabling factors.
[01:17:05.680 --> 01:17:09.800]   A lot of what people want to do in an extremist circles on the right.
[01:17:09.800 --> 01:17:14.320]   They had a harder time finding like minded people to the quantity that they can now.
[01:17:14.320 --> 01:17:19.480]   I don't know that the left was necessarily easier, but it feels like the Internet algorithms
[01:17:19.480 --> 01:17:25.520]   tend to bring people together with more extreme reactionary than radical ideas.
[01:17:25.520 --> 01:17:28.320]   I don't know if that's been, if that's provable or not.
[01:17:28.320 --> 01:17:29.320]   But I'm actually too.
[01:17:29.320 --> 01:17:33.640]   I think, I mean, Corey Dr. Worsen has said this is quite good because he ties it up with
[01:17:33.640 --> 01:17:37.320]   the brainwashing narrative plays into the hands of Facebook because that's what they're
[01:17:37.320 --> 01:17:38.320]   selling.
[01:17:38.320 --> 01:17:41.240]   They're selling me because they're probably able to buy things by using our network.
[01:17:41.240 --> 01:17:46.200]   But actually what they're doing is selecting subsets of people to talk to.
[01:17:46.200 --> 01:17:49.920]   And so you can, you can pretend you're a genius marketer by thinking of a subset and
[01:17:49.920 --> 01:17:53.240]   defining one and it'll go out and find that subset for you and put show you around to
[01:17:53.240 --> 01:17:59.120]   them, which feels like you have got more controls if you're just doing keyword kind
[01:17:59.120 --> 01:18:00.120]   of confirmation bias.
[01:18:00.120 --> 01:18:01.120]   Right.
[01:18:01.120 --> 01:18:06.160]   But the thing that it does is it does help you find groups of people who you kind of sympathize
[01:18:06.160 --> 01:18:09.240]   with and you'll follow and then to reinforce that and go out that feedback loop.
[01:18:09.240 --> 01:18:10.240]   And so you end up with-
[01:18:10.240 --> 01:18:11.240]   Which could be very good.
[01:18:11.240 --> 01:18:12.240]   As you say.
[01:18:12.240 --> 01:18:13.240]   As you might last matter.
[01:18:13.240 --> 01:18:14.240]   Me too.
[01:18:14.240 --> 01:18:15.240]   Yes.
[01:18:15.240 --> 01:18:18.720]   And this is community and these are tribes and these are houses of worship and all kinds
[01:18:18.720 --> 01:18:20.480]   of good things through the years.
[01:18:20.480 --> 01:18:22.320]   Let's not lose sight of that.
[01:18:22.320 --> 01:18:26.360]   It's just because some church get together doesn't mean that we shouldn't all get together.
[01:18:26.360 --> 01:18:28.080]   What's the opposite of going down the rabbit hole?
[01:18:28.080 --> 01:18:29.360]   There is sometimes the opposite.
[01:18:29.360 --> 01:18:30.720]   It's like coming out of the- I don't know.
[01:18:30.720 --> 01:18:33.160]   It's climbing up the ladder to the castle in the sky.
[01:18:33.160 --> 01:18:34.160]   I don't know.
[01:18:34.160 --> 01:18:35.160]   Something like that.
[01:18:35.160 --> 01:18:36.160]   Right.
[01:18:36.160 --> 01:18:37.160]   Which- reaching the Varna or something.
[01:18:37.160 --> 01:18:38.160]   Yeah.
[01:18:38.160 --> 01:18:39.160]   But it's- yeah.
[01:18:39.160 --> 01:18:40.160]   Now that's it.
[01:18:40.160 --> 01:18:43.760]   It's like- so it's the question of, you know, look at your peer groups and see if you really
[01:18:43.760 --> 01:18:45.800]   want them to be your peer groups and if not change them.
[01:18:45.800 --> 01:18:49.840]   But that is hard to- it's hard to know because if that's- if you sort of stumbled into that
[01:18:49.840 --> 01:18:54.960]   group and that's what you're getting your validation, that is part of the worry of it.
[01:18:54.960 --> 01:19:00.800]   It's also the- if you have five isolated people, each of whom hates the governor of Michigan,
[01:19:00.800 --> 01:19:02.160]   let's pretend.
[01:19:02.160 --> 01:19:09.760]   And in the non-online world, in the days before social graphs and reinforced behavior or connections,
[01:19:09.760 --> 01:19:12.760]   those five people would just hate the governor of Michigan and not do anything about it.
[01:19:12.760 --> 01:19:15.800]   But in the current era, those five people have found each other and they go out and
[01:19:15.800 --> 01:19:16.800]   try to kidnap her.
[01:19:16.800 --> 01:19:17.800]   I mean, this isn't a good sex.
[01:19:17.800 --> 01:19:20.480]   No, they could find each other pretty easily before.
[01:19:20.480 --> 01:19:21.480]   Couldn't they?
[01:19:21.480 --> 01:19:22.480]   Couldn't they?
[01:19:22.480 --> 01:19:23.480]   I mean, we had militias.
[01:19:23.480 --> 01:19:29.800]   It was, are we in a new era of mass radicalization and mass reactionary, you know, revanches
[01:19:29.800 --> 01:19:35.200]   and have we hit- have we- have things changed because it's easier to find other people who-
[01:19:35.200 --> 01:19:39.400]   I mean, this is- here's a great example and forgive me but I'm talking about pedophilia.
[01:19:39.400 --> 01:19:43.640]   But I think it's an important one is when you look at what's the correct term, it's
[01:19:43.640 --> 01:19:47.680]   the begins with its child's sexualized-
[01:19:47.680 --> 01:19:48.680]   >> Grooming?
[01:19:48.680 --> 01:19:49.680]   >> No, no, no, it's rather- >> CC.
[01:19:49.680 --> 01:19:51.480]   >> CC Sam, right, CC Sam.
[01:19:51.480 --> 01:19:57.560]   So those- it is absolutely the case that people, because it's an illegal activity, people, you
[01:19:57.560 --> 01:20:02.320]   know, were limited in their ability to exchange material in front of other people like them.
[01:20:02.320 --> 01:20:07.240]   And the internet gave people who have a predilection to view those kinds of images a greater opportunity
[01:20:07.240 --> 01:20:11.800]   to find one another because of the illegal and forbidden nature of it, right?
[01:20:11.800 --> 01:20:15.920]   And so that's- it's absolutely the case but they're also being more centralized.
[01:20:15.920 --> 01:20:20.120]   It's allowed people who fight the proliferation of CC Sam and abuse of children online.
[01:20:20.120 --> 01:20:24.000]   It's given them more tools to find large numbers of people engaged in it.
[01:20:24.000 --> 01:20:25.000]   >> Yeah.
[01:20:25.000 --> 01:20:30.040]   Well, so when it's also true that there is a lot of research about this.
[01:20:30.040 --> 01:20:32.160]   The extremes are always tiny numbers.
[01:20:32.160 --> 01:20:33.760]   It's what's not about mass.
[01:20:33.760 --> 01:20:35.720]   It's not about everybody.
[01:20:35.720 --> 01:20:39.200]   It's about- in your case of the Michigan, it's about enough people to go and threaten
[01:20:39.200 --> 01:20:40.720]   the life of the governor of Michigan.
[01:20:40.720 --> 01:20:41.720]   >> Right.
[01:20:41.720 --> 01:20:42.720]   >> Are we reaching critical mass?
[01:20:42.720 --> 01:20:43.720]   >> That's the medical mass.
[01:20:43.720 --> 01:20:44.720]   >> Yeah.
[01:20:44.720 --> 01:20:47.520]   But does the internet- does the internet spark that?
[01:20:47.520 --> 01:20:50.080]   Does Facebook- I mean, I guess this is the point and the question is-
[01:20:50.080 --> 01:20:56.520]   does the algorithm and algorithm or all the algorithms, when you go on YouTube and in
[01:20:56.520 --> 01:21:03.120]   ten minutes you're being shown how the Illuminati control the finances of the world or something.
[01:21:03.120 --> 01:21:05.320]   And you started like- I was looking at shark videos.
[01:21:05.320 --> 01:21:06.320]   How did I get here?
[01:21:06.320 --> 01:21:09.400]   Like, is that something that actually causes harm or not?
[01:21:09.400 --> 01:21:10.400]   >> Well, that's-
[01:21:10.400 --> 01:21:16.560]   >> So that's the question because- and that's what that article was supposing is that YouTube
[01:21:16.560 --> 01:21:19.560]   tends to lend itself towards that kind of-
[01:21:19.560 --> 01:21:20.560]   >> But those research that- that-
[01:21:20.560 --> 01:21:22.320]   >> That plugs us out as well.
[01:21:22.320 --> 01:21:25.160]   >> So I will grant you what you were saying, Kevin, which is-
[01:21:25.160 --> 01:21:27.160]   >> Well, so YouTube has changed a bit.
[01:21:27.160 --> 01:21:28.160]   YouTube was much worse.
[01:21:28.160 --> 01:21:29.160]   >> Right.
[01:21:29.160 --> 01:21:31.160]   >> And they've adjusted what they do now to try and avoid those right now.
[01:21:31.160 --> 01:21:35.120]   >> If you think Mark has always said this, people are happier when connected.
[01:21:35.120 --> 01:21:36.480]   It's all about being connected.
[01:21:36.480 --> 01:21:37.480]   Here we are.
[01:21:37.480 --> 01:21:38.480]   We facilitate communities.
[01:21:38.480 --> 01:21:40.360]   And yes, there'll be positive communities.
[01:21:40.360 --> 01:21:41.360]   There'll be negative communities.
[01:21:41.360 --> 01:21:44.480]   But they're all- we've created a platform that facilitates that.
[01:21:44.480 --> 01:21:46.320]   >> You're gonna need to learn how to-
[01:21:46.320 --> 01:21:48.840]   >> How to live together, and that's the problem.
[01:21:48.840 --> 01:21:52.240]   I think a lot of my view of this, it goes back to-
[01:21:52.240 --> 01:21:53.160]   >> As long as the-
[01:21:53.160 --> 01:21:53.160]   >> The industrial-
[01:21:53.160 --> 01:21:57.920]   >> As long as the organization of media, when media became mass, we were all presumed
[01:21:57.920 --> 01:22:01.240]   to be the same, and there was this one kind of view of society where a lot of people
[01:22:01.240 --> 01:22:07.160]   felt left out on both ends of the spectrum of class from that picture of what society
[01:22:07.160 --> 01:22:08.160]   was.
[01:22:08.160 --> 01:22:11.440]   >> There were precious few ways of creating community in the past, and it was always geographic,
[01:22:11.440 --> 01:22:12.440]   right?
[01:22:12.440 --> 01:22:15.200]   If I'm not your neighbor, we're not- we can't kidnap-
[01:22:15.200 --> 01:22:16.760]   >> Right, if you're a gay person-
[01:22:16.760 --> 01:22:20.760]   >> We can't kidnap Gretchen Whitmer together, because I need to be next to you.
[01:22:20.760 --> 01:22:23.520]   But at war, and that's what happened.
[01:22:23.520 --> 01:22:29.520]   Gay people formed communities of interest in San Francisco and other places.
[01:22:29.520 --> 01:22:31.920]   Because they did want to be together with geographic.
[01:22:31.920 --> 01:22:36.960]   So the internet has allowed us to transcend geography in all sorts of ways, including
[01:22:36.960 --> 01:22:37.960]   that.
[01:22:37.960 --> 01:22:43.040]   So really, isn't the only question whether these companies in these algorithms are pushing
[01:22:43.040 --> 01:22:46.080]   us in a negative way?
[01:22:46.080 --> 01:22:49.000]   I mean, they're pushing community.
[01:22:49.000 --> 01:22:50.680]   But isn't there- >> They're always doing both, Leo.
[01:22:50.680 --> 01:22:52.280]   They're always going to do both.
[01:22:52.280 --> 01:22:56.160]   And it's not them- that's a technological, determinist view that the technology in the
[01:22:56.160 --> 01:22:57.360]   company makes us do something.
[01:22:57.360 --> 01:22:59.960]   >> Are they- >> No, no, no, no.
[01:22:59.960 --> 01:23:00.960]   >> Time erases the station.
[01:23:00.960 --> 01:23:01.960]   >> No, no, no, no.
[01:23:01.960 --> 01:23:02.960]   >> Jeff, no.
[01:23:02.960 --> 01:23:03.960]   >> Jeff, no.
[01:23:03.960 --> 01:23:04.960]   No.
[01:23:04.960 --> 01:23:09.080]   If you've invented a social network, the point of which is to allow people to form communities,
[01:23:09.080 --> 01:23:12.320]   non-geographic communities of interest, you set that all up.
[01:23:12.320 --> 01:23:15.240]   This is all machinery setting up communities of interest.
[01:23:15.240 --> 01:23:16.480]   You're going to get all kinds.
[01:23:16.480 --> 01:23:19.000]   You're going to get communities of people who knit and communities of people want to
[01:23:19.000 --> 01:23:21.920]   kidnap governors.
[01:23:21.920 --> 01:23:23.720]   That's fine.
[01:23:23.720 --> 01:23:26.200]   That's kind of a neutral platform.
[01:23:26.200 --> 01:23:32.280]   But there seems to be some evidence that some of these platforms which are optimizing for
[01:23:32.280 --> 01:23:37.280]   engagement, that their engagement goes hand in hand with, I don't know, outrage or some
[01:23:37.280 --> 01:23:42.520]   sort of emotional buzz that tends to lead you in a particular tour, a particular kind
[01:23:42.520 --> 01:23:44.720]   of community community you might not necessarily want to join.
[01:23:44.720 --> 01:23:47.280]   >> This is where Steve- >> You may be the buddy and often who
[01:23:47.280 --> 01:23:50.120]   can't stand Facebook, who's written books against Facebook and Google, right?
[01:23:50.120 --> 01:23:56.960]   But Siva will argue strenuously, don't try to isolate one and blame them.
[01:23:56.960 --> 01:23:59.560]   It's a media ecosystem and it includes the media itself.
[01:23:59.560 --> 01:24:00.560]   It includes Fox News.
[01:24:00.560 --> 01:24:01.560]   It includes MSNBC.
[01:24:01.560 --> 01:24:02.560]   It includes CNN.
[01:24:02.560 --> 01:24:03.560]   It includes- >> New stuff.
[01:24:03.560 --> 01:24:04.560]   >> So, Fox is a good example.
[01:24:04.560 --> 01:24:07.560]   >> It includes all kinds of things.
[01:24:07.560 --> 01:24:12.280]   >> Of a channel that succeeds by accreting a certain kind of person, right?
[01:24:12.280 --> 01:24:13.680]   That's their goal.
[01:24:13.680 --> 01:24:17.280]   You might make the case, I think you probably could make the case, that somebody might stumble
[01:24:17.280 --> 01:24:24.000]   there at a neutral and be, same thing with MSNBC and be tilted in one direction.
[01:24:24.000 --> 01:24:30.080]   >> Oh, I watched my father, who's now 96, who was a reasonable Republican, who went
[01:24:30.080 --> 01:24:31.080]   on the deep end.
[01:24:31.080 --> 01:24:35.200]   And then when he couldn't hear anymore, and his hearing, he didn't work literally for
[01:24:35.200 --> 01:24:39.280]   the year in COVID until we got him up here.
[01:24:39.280 --> 01:24:41.600]   And he doesn't watch Fox anymore and he just voted Democratic.
[01:24:41.600 --> 01:24:42.600]   >> Right.
[01:24:42.600 --> 01:24:43.600]   >> Never thought that would happen in my life.
[01:24:43.600 --> 01:24:44.600]   >> Wow.
[01:24:44.600 --> 01:24:45.600]   >> Yeah.
[01:24:45.600 --> 01:24:46.600]   >> So, deprogrammed by the absence of Fox News.
[01:24:46.600 --> 01:24:47.600]   >> So, and his memory.
[01:24:47.600 --> 01:24:48.600]   >> So, clearly that's it.
[01:24:48.600 --> 01:24:53.560]   So, it's, I mean, the internet facilitates these communities of interest across geographic
[01:24:53.560 --> 01:24:54.760]   lines.
[01:24:54.760 --> 01:24:55.860]   That's neutral.
[01:24:55.860 --> 01:24:57.520]   We just want to make- >> So, I met Glenn-
[01:24:57.520 --> 01:24:58.520]   >> Right.
[01:24:58.520 --> 01:24:59.520]   Yes, exactly.
[01:24:59.520 --> 01:25:01.520]   >> I met- >> I met Jeff.
[01:25:01.520 --> 01:25:02.520]   >> Yeah.
[01:25:02.520 --> 01:25:03.520]   So, that's fine.
[01:25:03.520 --> 01:25:04.520]   That's what we want.
[01:25:04.520 --> 01:25:05.520]   That's what the internet does.
[01:25:05.520 --> 01:25:09.600]   What we don't want is for companies, especially companies who are doing this with a profit
[01:25:09.600 --> 01:25:15.040]   motive to foster a certain, I mean, a certain kind of connectivity.
[01:25:15.040 --> 01:25:16.040]   Is that right?
[01:25:16.040 --> 01:25:18.520]   >> Well, don't we agree with what the foster a positive connectivity?
[01:25:18.520 --> 01:25:20.360]   Then they're, then the argument becomes what's a positive?
[01:25:20.360 --> 01:25:21.360]   >> Well, that's right.
[01:25:21.360 --> 01:25:22.360]   So, it should be neutral.
[01:25:22.360 --> 01:25:24.640]   >> Well, no, there's no such thing as neutrality.
[01:25:24.640 --> 01:25:27.560]   >> Well, it's no such thing in life as neutrality.
[01:25:27.560 --> 01:25:28.560]   It doesn't exist.
[01:25:28.560 --> 01:25:32.960]   >> All, so, I mean, this is where I get, I get, I'm not frustrated, but I think my head
[01:25:32.960 --> 01:25:37.120]   starts to spin where it's, it's, I think, I think we all agree, maybe, and it's correct
[01:25:37.120 --> 01:25:38.120]   me if I'm wrong.
[01:25:38.120 --> 01:25:43.120]   I think we all agree that, that there's a different, that, whether social networks reinforce
[01:25:43.120 --> 01:25:46.160]   existing beliefs or help people gain new beliefs.
[01:25:46.160 --> 01:25:52.760]   Like, I think it's very, I think you can make a strong argument that QAnon spread heavily
[01:25:52.760 --> 01:25:57.520]   online, but there has been a very strong real world component of it where people recruit
[01:25:57.520 --> 01:26:01.520]   and, and meet and sort of in certain circles and have spread it that way too.
[01:26:01.520 --> 01:26:06.800]   So it's got two parallel vectors, but one of them, you know, it really began and spread
[01:26:06.800 --> 01:26:11.240]   as a strictly online thing and took over, became this political movement that has tens
[01:26:11.240 --> 01:26:14.880]   of millions or hundreds of millions of people around the world who believe in it, right?
[01:26:14.880 --> 01:26:20.920]   So I don't think that that could have existed just with, you know, a real life component.
[01:26:20.920 --> 01:26:25.720]   We've seen how groups that want to practice violence in the United States in particular,
[01:26:25.720 --> 01:26:31.520]   how they've been constrained in the past in recruiting people when it has been a geographic
[01:26:31.520 --> 01:26:32.520]   base thing.
[01:26:32.520 --> 01:26:34.480]   And it's the same thing with groups that are more positive too.
[01:26:34.480 --> 01:26:39.320]   The ones that are extreme obviously have the limits of engaging in often illegal activities.
[01:26:39.320 --> 01:26:43.800]   So they have to hide it and online gives them a better place than, you know, other, any
[01:26:43.800 --> 01:26:46.920]   kind of thing you could do in real life where you're trying to find the right kinds of people.
[01:26:46.920 --> 01:26:49.880]   So I guess where I get to go around and around is like, so what's the role?
[01:26:49.880 --> 01:26:54.560]   Like, like YouTube, I don't know if they ever agreed, Kevin, I know that they made those
[01:26:54.560 --> 01:26:56.480]   tweaks, but they changed their algorithm.
[01:26:56.480 --> 01:27:01.520]   So it doesn't take people quickly into like the biggest conspiracy theories or that's
[01:27:01.520 --> 01:27:03.080]   what it seems like.
[01:27:03.080 --> 01:27:08.440]   If you know that tweak in the algorithm changes what people see and how they're directed into
[01:27:08.440 --> 01:27:14.880]   political or conspiracy ways, then is there a role for government in which it could regulate?
[01:27:14.880 --> 01:27:18.920]   I mean, I think it would be very difficult to regulate any kind of fashion that wouldn't
[01:27:18.920 --> 01:27:21.000]   provide bias or cause other problems.
[01:27:21.000 --> 01:27:27.320]   But is there a role for any party to say these, we need to have a comprehensive change, we
[01:27:27.320 --> 01:27:33.240]   need to have a specific change in order to prevent extremists from finding community online
[01:27:33.240 --> 01:27:36.480]   that they would, that is different than the kind of community they would find in the real
[01:27:36.480 --> 01:27:37.480]   world?
[01:27:37.480 --> 01:27:38.480]   Did, well, it's fantastic.
[01:27:38.480 --> 01:27:40.360]   It's how you specify that.
[01:27:40.360 --> 01:27:44.520]   I mean, and it does come down to effectively the platform setting, except we use policies
[01:27:44.520 --> 01:27:46.800]   and deciding to enforce them.
[01:27:46.800 --> 01:27:53.840]   And Reddit has started to do this, Reddit, well, Reddit has like thousands of sub communities
[01:27:53.840 --> 01:27:57.360]   and some of them are toxic and they've been gradually deleting a few of them, but it's
[01:27:57.360 --> 01:27:58.920]   fairly easy for them to spawn a new one.
[01:27:58.920 --> 01:28:02.760]   But by actually actually deleting that has helped a bit with Reddit, Reddit, Reddit does
[01:28:02.760 --> 01:28:05.160]   have some communities on it.
[01:28:05.160 --> 01:28:07.120]   Reddit is clearly not a fortune, right?
[01:28:07.120 --> 01:28:11.360]   So they've done something to keep themselves from becoming a fortune.
[01:28:11.360 --> 01:28:14.720]   Well, then fortune became too moderated for people.
[01:28:14.720 --> 01:28:22.080]   So is Vance, Jeff, has Vance Packard discredited these days?
[01:28:22.080 --> 01:28:23.880]   Oh, yes, absolutely.
[01:28:23.880 --> 01:28:27.080]   The hidden persuaders was faked.
[01:28:27.080 --> 01:28:28.080]   Yes.
[01:28:28.080 --> 01:28:34.480]   Because it was his contention in the 50s that movies, you know, he was talking about those
[01:28:34.480 --> 01:28:40.400]   blipverts, but it was his, I don't think his basic, I don't think his basic attention
[01:28:40.400 --> 01:28:48.280]   was wrong, which was that companies and politicians and other groups want to influence people.
[01:28:48.280 --> 01:28:50.720]   He was said they were doing it in movies and TV.
[01:28:50.720 --> 01:28:56.080]   I'd love to see what he thinks of what he would have thought of the internet.
[01:28:56.080 --> 01:28:58.720]   I mean, I guess that's the question.
[01:28:58.720 --> 01:29:02.840]   There's another really Rupert Murdoch is a both malign influence, right?
[01:29:02.840 --> 01:29:09.720]   And so he has created a platform that is clearly designed to influence and has succeeded
[01:29:09.720 --> 01:29:12.920]   very, very, very well in that with Fox News.
[01:29:12.920 --> 01:29:14.720]   So that's bad.
[01:29:14.720 --> 01:29:15.720]   That's I mean, we can.
[01:29:15.720 --> 01:29:16.720]   And the times in the sun, yes.
[01:29:16.720 --> 01:29:17.720]   Yeah, and the times in the sun.
[01:29:17.720 --> 01:29:18.720]   We have a lot of people.
[01:29:18.720 --> 01:29:22.360]   He's specifically funding the creation of misinformation.
[01:29:22.360 --> 01:29:23.360]   Yeah.
[01:29:23.360 --> 01:29:27.920]   Maybe not disinformation, but certainly misinformation, which is separate than individual, right?
[01:29:27.920 --> 01:29:32.720]   It's separate than a collection or coalescing of individuals who have many brainworms.
[01:29:32.720 --> 01:29:33.720]   Yeah.
[01:29:33.720 --> 01:29:34.720]   That I did so.
[01:29:34.720 --> 01:29:37.120]   Let me answer your question this way.
[01:29:37.120 --> 01:29:39.560]   We agree there's bad propaganda.
[01:29:39.560 --> 01:29:41.080]   Is there good propaganda, right?
[01:29:41.080 --> 01:29:43.760]   Is it convincing people to wear masking at vaccinations?
[01:29:43.760 --> 01:29:45.080]   Is that propaganda?
[01:29:45.080 --> 01:29:46.360]   Is that education?
[01:29:46.360 --> 01:29:48.600]   Is education propaganda?
[01:29:48.600 --> 01:29:53.680]   So journalism be having these outcomes and judge our success or not based on that.
[01:29:53.680 --> 01:29:57.400]   Those are the kind of questions that I asked and don't necessarily answer in school.
[01:29:57.400 --> 01:30:02.520]   Or maybe our morays should, well, but see, we wouldn't agree on what is propaganda.
[01:30:02.520 --> 01:30:04.000]   But that's how we negotiate.
[01:30:04.000 --> 01:30:05.160]   That's the whole process.
[01:30:05.160 --> 01:30:09.160]   We are renegotiating our norms in a new reality.
[01:30:09.160 --> 01:30:13.120]   And voices who were not heard in mass media are now heard.
[01:30:13.120 --> 01:30:16.560]   Black voices, women's voices, queer voices.
[01:30:16.560 --> 01:30:20.720]   And the all powerful voices hate that.
[01:30:20.720 --> 01:30:21.720]   Yeah.
[01:30:21.720 --> 01:30:26.160]   And they want to, the one, and once the paradox you mentioned before, shut them up.
[01:30:26.160 --> 01:30:30.920]   You can't mention gay, but then condemn them because you can't convert people to being
[01:30:30.920 --> 01:30:31.920]   gay and all that stuff.
[01:30:31.920 --> 01:30:35.240]   And we're going to hate people and use the F word as Glenn said.
[01:30:35.240 --> 01:30:37.520]   And so that's the kind of we're in this negotiation.
[01:30:37.520 --> 01:30:41.880]   There was a wonderful Twitter thread by a Canadian academic, the Regina Rini about two
[01:30:41.880 --> 01:30:46.760]   years ago in which he said that there's a fight between those who want to add to the
[01:30:46.760 --> 01:30:50.640]   list of things that are not considered polite in society.
[01:30:50.640 --> 01:30:53.600]   You can't say girl for woman anymore.
[01:30:53.600 --> 01:30:56.120]   And there are those she called the status quo warriors.
[01:30:56.120 --> 01:30:58.040]   No, you can't tell me what to say.
[01:30:58.040 --> 01:30:59.040]   How dare you tell me what to say?
[01:30:59.040 --> 01:31:00.280]   No, I'm not telling you.
[01:31:00.280 --> 01:31:04.400]   I'm just suggesting that I find this offensive or bothers me.
[01:31:04.400 --> 01:31:09.680]   And we should have a discussion about whether that's something we still consider civil.
[01:31:09.680 --> 01:31:13.480]   And that, and so that's now being, that, that negotiation is now being called cancel
[01:31:13.480 --> 01:31:14.480]   culture.
[01:31:14.480 --> 01:31:18.280]   It's, it itself is being poisoned with the idea that we can't do that.
[01:31:18.280 --> 01:31:19.280]   We can't argue about that.
[01:31:19.280 --> 01:31:20.280]   No, we must argue about that.
[01:31:20.280 --> 01:31:21.280]   That's what society is.
[01:31:21.280 --> 01:31:26.040]   And when we talk about polarization, what bothers me so much about that, that motif
[01:31:26.040 --> 01:31:31.120]   is that it is that it acts as if, if to say I hate Nazis, I'm the bad guy because I'm
[01:31:31.120 --> 01:31:33.240]   being polarizing and I'm pushing them off.
[01:31:33.240 --> 01:31:37.960]   So if you try to find a new center where the Nazis are closer to me and normalize them
[01:31:37.960 --> 01:31:42.000]   and that's what media have done in the last six years, that's a real problem.
[01:31:42.000 --> 01:31:43.200]   So interesting thing happens.
[01:31:43.200 --> 01:31:46.840]   That's why there's no, there's no, that's why I say there's no objective.
[01:31:46.840 --> 01:31:50.520]   There's no, yeah, no, I understand is who, yeah, who's going to make the rules.
[01:31:50.520 --> 01:31:55.720]   I, I'm not going to worry anything about Swillab pavement because you know, she, she
[01:31:55.720 --> 01:32:01.200]   was the home secretary until yesterday and she was just passing laws about public dissent
[01:32:01.200 --> 01:32:03.200]   online censorship.
[01:32:03.200 --> 01:32:07.640]   And she was the one doing the Tofu-Weating Wokarati enemies of the people type nonsense
[01:32:07.640 --> 01:32:08.640]   empowerment.
[01:32:08.640 --> 01:32:13.760]   You know, so there's a, you know, this sort of weird slogan based.
[01:32:13.760 --> 01:32:16.640]   I have a case study I'd like to propose.
[01:32:16.640 --> 01:32:22.000]   So in this country, there are, I don't know what, a thousand radio stations, local radio
[01:32:22.000 --> 01:32:23.000]   stations.
[01:32:23.000 --> 01:32:28.320]   And for a long time, the FCC prohibited one company from owning more than two stations
[01:32:28.320 --> 01:32:30.200]   in any given market.
[01:32:30.200 --> 01:32:31.200]   Yeah.
[01:32:31.200 --> 01:32:34.360]   And as a result, there was a great diversity of thought in these radio stations.
[01:32:34.360 --> 01:32:41.040]   Now, I, and I don't know, this might just be coincidental timing, but last two decades,
[01:32:41.040 --> 01:32:44.320]   the FCC's changed that rule.
[01:32:44.320 --> 01:32:48.640]   And what happened is a handful of very large companies bought up all the radio stations
[01:32:48.640 --> 01:32:49.640]   in the country.
[01:32:49.640 --> 01:32:53.480]   So there are really only three different companies that own the vast majority.
[01:32:53.480 --> 01:32:56.200]   Well, all those companies, by the way, I heart is number one.
[01:32:56.200 --> 01:33:01.280]   Cumulus is number two, and Entercom, now called Odyssey is number three there.
[01:33:01.280 --> 01:33:07.920]   By the way, all of them faced with huge debt because they leveraged all these acquisitions.
[01:33:07.920 --> 01:33:12.040]   So Odyssey is close to being delisted from the stock exchanges.
[01:33:12.040 --> 01:33:14.880]   Last time I checked, the stock was 88 cents.
[01:33:14.880 --> 01:33:19.320]   I heart had to renegotiate its debt because it could not, the debt burden would have killed,
[01:33:19.320 --> 01:33:22.120]   it would have driven it into bankruptcy as well.
[01:33:22.120 --> 01:33:23.720]   And they were able to renegotiate the debt.
[01:33:23.720 --> 01:33:25.720]   And I think we'll go forward.
[01:33:25.720 --> 01:33:32.640]   But that consolidation, once they get over the massive cost of it, allowed, now, this
[01:33:32.640 --> 01:33:36.600]   is a question if it was, if there's correlation or causation.
[01:33:36.600 --> 01:33:42.760]   What happened over the last 20 years is that local talk radio veered dramatically to the
[01:33:42.760 --> 01:33:43.760]   right.
[01:33:43.760 --> 01:33:48.840]   There have been attempts to create left wing talk radio at the MSNBC of talk radio progressive
[01:33:48.840 --> 01:33:49.840]   talk radio.
[01:33:49.840 --> 01:33:50.840]   All America.
[01:33:50.840 --> 01:33:53.880]   It failed miserably, all failed miserably.
[01:33:53.880 --> 01:33:57.880]   People love right wing talk radio.
[01:33:57.880 --> 01:34:00.400]   Now, there's probably a lot of demographic reasons for that.
[01:34:00.400 --> 01:34:05.160]   The only people listening to AM radio anymore are, you know, into their 60s.
[01:34:05.160 --> 01:34:07.680]   You know, so there may be demographic reasons for that as well.
[01:34:07.680 --> 01:34:13.280]   But for some reason, the only way you could make money in radio became right wing talk.
[01:34:13.280 --> 01:34:14.280]   Yeah, yeah.
[01:34:14.280 --> 01:34:15.280]   Right.
[01:34:15.280 --> 01:34:18.880]   Now, you can say it's related to this consolidation.
[01:34:18.880 --> 01:34:24.080]   Maybe you could say it's related to the aging demographic, the dying of the medium maybe,
[01:34:24.080 --> 01:34:27.360]   or maybe right wing talk.
[01:34:27.360 --> 01:34:32.680]   I think this is the case is actually much more, it gets you going.
[01:34:32.680 --> 01:34:33.680]   It gets you excited.
[01:34:33.680 --> 01:34:34.680]   It gets your blood pumping.
[01:34:34.680 --> 01:34:35.980]   People love it.
[01:34:35.980 --> 01:34:37.880]   And I think it radicalizes people.
[01:34:37.880 --> 01:34:40.280]   You point to Fox News is radicalizing the nation.
[01:34:40.280 --> 01:34:45.880]   I think Rush Limbaugh and his ilk did far worse than he had started.
[01:34:45.880 --> 01:34:49.080]   I think they might have done far worse because they're talking to people, you know, they
[01:34:49.080 --> 01:34:51.280]   used to anyway be talking to people for hours a day.
[01:34:51.280 --> 01:34:53.640]   And I've seen many people radicalized by it.
[01:34:53.640 --> 01:34:58.280]   So is that an example of an, that's an algorithm.
[01:34:58.280 --> 01:35:04.040]   It's a human algorithm where program directors all across the country noticed that when they
[01:35:04.040 --> 01:35:08.080]   went right wing, Rush Limbaugh dominated that it worked really well.
[01:35:08.080 --> 01:35:09.360]   When they went left wing, it didn't work well.
[01:35:09.360 --> 01:35:10.960]   So we're doing more of that.
[01:35:10.960 --> 01:35:11.960]   That's an algorithm, right?
[01:35:11.960 --> 01:35:13.960]   The show is driven by profit.
[01:35:13.960 --> 01:35:16.920]   I knew it was a centralized algorithm by one of the three companies because they were basically
[01:35:16.920 --> 01:35:17.920]   scheduled.
[01:35:17.920 --> 01:35:18.920]   It's more centralized.
[01:35:18.920 --> 01:35:19.920]   Station centralized.
[01:35:19.920 --> 01:35:23.160]   But maybe it's just because somebody did it and then everybody noticed, hey, look, it
[01:35:23.160 --> 01:35:24.160]   worked.
[01:35:24.160 --> 01:35:27.280]   You know, I mean, radio guys also done that, you know, all these, the oldies format swept
[01:35:27.280 --> 01:35:32.760]   radio even when there was a thousand different older stations because it worked.
[01:35:32.760 --> 01:35:33.760]   People liked oldies.
[01:35:33.760 --> 01:35:34.760]   So.
[01:35:34.760 --> 01:35:36.760]   I mean, I think they're the.
[01:35:36.760 --> 01:35:39.320]   That's a case study, but I don't know what caused it.
[01:35:39.320 --> 01:35:40.320]   It's really interesting though.
[01:35:40.320 --> 01:35:42.400]   They're, they're, they're, they're, they're, I think, you know, I realized the other day
[01:35:42.400 --> 01:35:46.960]   that broadcast has gone from 1920 to 2020 and it's really coming to its end.
[01:35:46.960 --> 01:35:47.960]   I don't know.
[01:35:47.960 --> 01:35:48.960]   He's going to give up 10 o'clock.
[01:35:48.960 --> 01:35:49.960]   Radio.
[01:35:49.960 --> 01:35:50.960]   Yeah.
[01:35:50.960 --> 01:35:51.960]   Exactly.
[01:35:51.960 --> 01:35:54.480]   And that was a century of broadcast.
[01:35:54.480 --> 01:35:57.280]   It was a century of the real mass.
[01:35:57.280 --> 01:36:00.440]   And I think that that's what's ending.
[01:36:00.440 --> 01:36:04.000]   And there are those who still, you know, when, when, when, when semaphore started on Tuesday
[01:36:04.000 --> 01:36:09.240]   and there, and their opening video was being nostalgic about Walter Cronkite for Christ
[01:36:09.240 --> 01:36:10.240]   sakes.
[01:36:10.240 --> 01:36:14.840]   That was a, that was a very limited issue over there because Edward R. Murrow was just too
[01:36:14.840 --> 01:36:15.840]   far.
[01:36:15.840 --> 01:36:16.840]   Yeah.
[01:36:16.840 --> 01:36:17.840]   Two more ago.
[01:36:17.840 --> 01:36:18.840]   That's the weird one.
[01:36:18.840 --> 01:36:22.280]   You know, I was thinking about that last night about how Walter Cronkite is ancient history,
[01:36:22.280 --> 01:36:23.280]   right?
[01:36:23.280 --> 01:36:25.520]   I mean, he, he, my students did not know who he was.
[01:36:25.520 --> 01:36:26.520]   No.
[01:36:26.520 --> 01:36:29.520]   Well, they call him old iron, but because he was an AP guy who just happened to be able
[01:36:29.520 --> 01:36:35.360]   to sit for hours at a time and broadcast and, and really had no opinion or point of view.
[01:36:35.360 --> 01:36:40.480]   In fact, it wasn't until Vietnam that he ever had an opinion or point of view.
[01:36:40.480 --> 01:36:45.400]   As soon as that happened, that changed a lot of, of our, what we, how we think of the
[01:36:45.400 --> 01:36:46.400]   inflow inflow.
[01:36:46.400 --> 01:36:48.000]   So here's an old way to ask your question, Leo.
[01:36:48.000 --> 01:36:53.160]   Is, is radio inherently conservative talk radio inherently conservative?
[01:36:53.160 --> 01:36:58.120]   Is television inherently liberal or is, is the internet inherently one or the other or
[01:36:58.120 --> 01:36:59.120]   no?
[01:36:59.120 --> 01:37:04.080]   Well, the only reason I bring this up is because the heat generated by right wing talk on radio
[01:37:04.080 --> 01:37:06.160]   was very good commercially.
[01:37:06.160 --> 01:37:11.240]   And it sure looks like the same kind of heat that's generated on Twitter, on Facebook
[01:37:11.240 --> 01:37:12.480]   and social media.
[01:37:12.480 --> 01:37:14.200]   And I think it's possibly the case.
[01:37:14.200 --> 01:37:17.640]   Again, I don't know because it's, you know, there's a lot of variables, but it's possibly
[01:37:17.640 --> 01:37:23.000]   the case that that just gets humans, you know, where they live and, and is engaging.
[01:37:23.000 --> 01:37:25.400]   And so you're going to make more money when you do it.
[01:37:25.400 --> 01:37:30.200]   With the psychology experiment story, I think I may have even told it on this podcast before
[01:37:30.200 --> 01:37:35.240]   but video cast before but stop me if I have is, and I think it's an alleged experiment.
[01:37:35.240 --> 01:37:39.280]   I'm not sure to actually ever occurred, but it has the truthiness to it, right?
[01:37:39.280 --> 01:37:44.720]   Is that students decided to play an experiment on their against their professor in a psychology
[01:37:44.720 --> 01:37:45.720]   class.
[01:37:45.720 --> 01:37:48.520]   So starting at the beginning of the term, they only paid attention to him when he was
[01:37:48.520 --> 01:37:49.520]   on one side of the room.
[01:37:49.520 --> 01:37:54.880]   At the end of the term, they had him crouched into a corner and he wouldn't do it when
[01:37:54.880 --> 01:37:55.880]   he spoke.
[01:37:55.880 --> 01:38:00.400]   So again, I don't know, I believe I've read that this is a, it's a, it's a pocket full,
[01:38:00.400 --> 01:38:01.840]   but you can see how well that would work.
[01:38:01.840 --> 01:38:07.040]   And I feel like the, you know, Rupert Murdoch became successful.
[01:38:07.040 --> 01:38:11.240]   I would say there's a small element of how he radical, he pushed people in a direction,
[01:38:11.240 --> 01:38:12.240]   right?
[01:38:12.240 --> 01:38:15.200]   You, it is propaganda when you confronted with the same information, you're told it's true
[01:38:15.200 --> 01:38:16.680]   in an authoritative way.
[01:38:16.680 --> 01:38:17.760]   You can internalize it.
[01:38:17.760 --> 01:38:22.160]   Not everyone has the critical facilities to resist that indefinitely or even any interest
[01:38:22.160 --> 01:38:23.160]   in it.
[01:38:23.160 --> 01:38:24.160]   So, right, that's part of it.
[01:38:24.160 --> 01:38:25.880]   So he went where his audience was.
[01:38:25.880 --> 01:38:28.600]   The New York Times has a profile today of the Fox News.
[01:38:28.600 --> 01:38:31.320]   I think she's the president or CEO, I forgot which.
[01:38:31.320 --> 01:38:36.840]   And that it's something like you never, something like her motto is never to work against the
[01:38:36.840 --> 01:38:41.160]   beliefs of her viewers, but she assembled viewership.
[01:38:41.160 --> 01:38:45.720]   So this has even, and that's the little nice nugget in the story was even if that means
[01:38:45.720 --> 01:38:47.680]   ignoring a major story for a year, right?
[01:38:47.680 --> 01:38:52.680]   And like the January 7 thing, um, so, or January 6, excuse me, I've already forgotten.
[01:38:52.680 --> 01:38:57.840]   So the question I have is, is all media and experiment of getting the professor to stand
[01:38:57.840 --> 01:39:01.600]   crouch in the corner of a room, but as an audience member.
[01:39:01.600 --> 01:39:08.240]   So Rupert Murdoch is that audio is the, is the people in the, the students and he's only
[01:39:08.240 --> 01:39:09.560]   paying attention to her spurtance.
[01:39:09.560 --> 01:39:10.560]   I'm sorry.
[01:39:10.560 --> 01:39:11.560]   I'm saying this wrong way.
[01:39:11.560 --> 01:39:15.680]   Rupert Murdoch is that professor crouched in the corner, but it's a very lucrative corner
[01:39:15.680 --> 01:39:17.480]   and the law of the student watching.
[01:39:17.480 --> 01:39:18.480]   Yeah.
[01:39:18.480 --> 01:39:22.960]   If the audience isn't paying attention in that corner, then would Rupert Murdoch, and I think
[01:39:22.960 --> 01:39:27.440]   we've seen this in some properties, some things he's done, he has moved or various people
[01:39:27.440 --> 01:39:30.640]   in his empire move things away from that corner, right?
[01:39:30.640 --> 01:39:37.120]   And we have much more extreme networks that are uncable, that have been blocked on black
[01:39:37.120 --> 01:39:38.800]   and one away in.
[01:39:38.800 --> 01:39:39.800]   Yeah.
[01:39:39.800 --> 01:39:46.160]   Exactly those folks who are who are much more much more, much more, much more partisan,
[01:39:46.160 --> 01:39:48.240]   even further to the right than Fox.
[01:39:48.240 --> 01:39:49.920]   I think you nailed it.
[01:39:49.920 --> 01:39:50.920]   Rupert Murdoch.
[01:39:50.920 --> 01:39:51.920]   I don't think Rupert Murdoch.
[01:39:51.920 --> 01:39:55.320]   Well, he has certain economic desires.
[01:39:55.320 --> 01:39:57.000]   He has some critical things that he does push for.
[01:39:57.000 --> 01:39:58.920]   He does have some political.
[01:39:58.920 --> 01:39:59.920]   Absolutely.
[01:39:59.920 --> 01:40:01.600]   But mostly he's interested in money.
[01:40:01.600 --> 01:40:05.640]   And people don't buy tabloids at the checkout counter.
[01:40:05.640 --> 01:40:09.320]   They buy them partly because they're there, but they buy them because they like the headlines
[01:40:09.320 --> 01:40:10.320]   and they opt them.
[01:40:10.320 --> 01:40:13.160]   I mean, SEO is supermarket checkout, right?
[01:40:13.160 --> 01:40:16.280]   And it's now can be done a billion times the scale.
[01:40:16.280 --> 01:40:17.640]   Here's the Washington Post.
[01:40:17.640 --> 01:40:20.520]   How TikTok ate the internet?
[01:40:20.520 --> 01:40:23.320]   By the way, this is like getting on the cover of Sports Illustrated.
[01:40:23.320 --> 01:40:27.560]   As soon as you've got to think piece about your social network, it's certainly about
[01:40:27.560 --> 01:40:28.560]   to die.
[01:40:28.560 --> 01:40:31.560]   You can guess this.
[01:40:31.560 --> 01:40:34.960]   But it really, it's, and so TikTok's...
[01:40:34.960 --> 01:40:35.960]   Read the subhead, Leo.
[01:40:35.960 --> 01:40:36.800]   Read the subhead of that one.
[01:40:36.800 --> 01:40:40.280]   The world's most popular app is pioneered at a new age of instant attention.
[01:40:40.280 --> 01:40:41.280]   Can we trust it?
[01:40:41.280 --> 01:40:42.280]   Now that was why he trussed.
[01:40:42.280 --> 01:40:46.240]   That was why I put this article in here is this whole notion of, you know, are we being
[01:40:46.240 --> 01:40:47.240]   manipulated?
[01:40:47.240 --> 01:40:51.400]   Somebody sent me an article from a professor said, "Oh, VR is going to be the ultimate
[01:40:51.400 --> 01:40:55.560]   manipulation tool because when you're in there, I can feed you stuff that's going to
[01:40:55.560 --> 01:40:58.920]   make your mind go any way I want it to go."
[01:40:58.920 --> 01:41:00.320]   Maybe that's true, maybe not.
[01:41:00.320 --> 01:41:02.320]   No, same nonsense.
[01:41:02.320 --> 01:41:03.320]   Yeah.
[01:41:03.320 --> 01:41:05.840]   So I've got another quote for you.
[01:41:05.840 --> 01:41:10.880]   David Foster Wallace in Eunabus Plurum said, "TV is not violent or impotent and dumb because
[01:41:10.880 --> 01:41:13.640]   the people who compares the audience are bolder and dumb.
[01:41:13.640 --> 01:41:16.920]   Television is the way it is simply because people tend to be extremely similar, they're
[01:41:16.920 --> 01:41:20.400]   vulgar and brilliant and dumb interests and wildly different in their refined and aesthetic
[01:41:20.400 --> 01:41:21.400]   and...
[01:41:21.400 --> 01:41:22.400]   Oh, I love that.
[01:41:22.400 --> 01:41:23.400]   Oh, again, that was nice.
[01:41:23.400 --> 01:41:24.400]   Brilliant quote.
[01:41:24.400 --> 01:41:25.400]   That's lovely.
[01:41:25.400 --> 01:41:28.320]   I've heard this about, you know, gifted children, right?
[01:41:28.320 --> 01:41:31.520]   Gifted children are seen as a category and, you know, it's measurable, right?
[01:41:31.520 --> 01:41:33.640]   And it's a whole debate about gifted education.
[01:41:33.640 --> 01:41:34.640]   And I went through a gifted program.
[01:41:34.640 --> 01:41:38.280]   When I was a kid, can you tell maybe a little bit that I was...
[01:41:38.280 --> 01:41:39.280]   You were molded, yes.
[01:41:39.280 --> 01:41:43.760]   ...and I was able, full of myself, right, anyway, my young age.
[01:41:43.760 --> 01:41:48.920]   But so, gifted education, the thing is kids who are more normative in general education
[01:41:48.920 --> 01:41:52.000]   tend to be, the studies show, more alike.
[01:41:52.000 --> 01:41:54.480]   Gifted kids tend to be much more different.
[01:41:54.480 --> 01:41:55.560]   And it's not that they're...
[01:41:55.560 --> 01:41:59.200]   It's not a measure of better or even intelligent at some level.
[01:41:59.200 --> 01:42:03.080]   It's that it's one of the measures of giftedness is that their interests and abilities tend
[01:42:03.080 --> 01:42:05.120]   to be dramatically more spiky.
[01:42:05.120 --> 01:42:08.640]   Which makes them disruptive in the classroom.
[01:42:08.640 --> 01:42:14.640]   They might be extremely good at math or art, but they're terrible at another subject.
[01:42:14.640 --> 01:42:15.640]   But that's...
[01:42:15.640 --> 01:42:16.640]   But they're not in that normative thing.
[01:42:16.640 --> 01:42:17.640]   It's the same thing.
[01:42:17.640 --> 01:42:21.520]   A lot of these gate programs are just to get those kids out of the mainstream classroom
[01:42:21.520 --> 01:42:24.400]   and off with somebody who can tolerate their interests.
[01:42:24.400 --> 01:42:25.400]   Kevin, what you're doing...
[01:42:25.400 --> 01:42:27.640]   But I mean, they're perfect though, is that the mass of people...
[01:42:27.640 --> 01:42:28.640]   Great quote.
[01:42:28.640 --> 01:42:29.640]   ...are much more similar, right?
[01:42:29.640 --> 01:42:30.640]   That is the thing.
[01:42:30.640 --> 01:42:31.640]   Yes.
[01:42:31.640 --> 01:42:32.640]   But what is it not even the masses in it?
[01:42:32.640 --> 01:42:33.640]   It's just that they've got...
[01:42:33.640 --> 01:42:34.640]   They all want to watch...
[01:42:34.640 --> 01:42:35.640]   Oh, I see.
[01:42:35.640 --> 01:42:36.640]   Everyone will watch...
[01:42:36.640 --> 01:42:37.640]   We all like cats.
[01:42:37.640 --> 01:42:38.640]   Yeah.
[01:42:38.640 --> 01:42:40.640]   And cats on the internet.
[01:42:40.640 --> 01:42:46.640]   It's much more diversity in our higher level interests than there is in our low interests.
[01:42:46.640 --> 01:42:47.640]   It's interesting.
[01:42:47.640 --> 01:42:48.640]   It's an unclean-fiction cats.
[01:42:48.640 --> 01:42:50.640]   It's all we care about.
[01:42:50.640 --> 01:42:51.640]   And as a result, that's a...
[01:42:51.640 --> 01:42:53.640]   Which is the point of the mouse.
[01:42:53.640 --> 01:42:54.640]   Which is the point of the mouse.
[01:42:54.640 --> 01:42:55.640]   Yeah.
[01:42:55.640 --> 01:42:56.640]   Yeah.
[01:42:56.640 --> 01:43:01.240]   And you can't blame TikTok or Facebook or Fox or Rupert for chasing that.
[01:43:01.240 --> 01:43:03.640]   He's like the professor in the corner of his class.
[01:43:03.640 --> 01:43:06.640]   He doesn't want to have any moral standards to how far is to...
[01:43:06.640 --> 01:43:07.640]   Why don't you look?
[01:43:07.640 --> 01:43:16.640]   Having a moral standard in a large broadcasting company is an absolute recipe for failure.
[01:43:16.640 --> 01:43:18.640]   So let's not go there.
[01:43:18.640 --> 01:43:19.640]   I don't think...
[01:43:19.640 --> 01:43:20.640]   I was thinking of the BBC a little bit here.
[01:43:20.640 --> 01:43:21.640]   I mean, the...
[01:43:21.640 --> 01:43:22.640]   Well, that wasn't...
[01:43:22.640 --> 01:43:25.400]   Yeah, but subsidized by the British government for crying out loud.
[01:43:25.400 --> 01:43:27.960]   That is not a commercial entity.
[01:43:27.960 --> 01:43:28.960]   We've been talking capitalistic...
[01:43:28.960 --> 01:43:29.960]   No, it's just a remark tax.
[01:43:29.960 --> 01:43:30.960]   I know.
[01:43:30.960 --> 01:43:31.960]   But the point is that's the point.
[01:43:31.960 --> 01:43:33.960]   The point is that's why you have to do something different.
[01:43:33.960 --> 01:43:38.560]   And it's been running 100 years, is mission his edge-gate and foreman entertained.
[01:43:38.560 --> 01:43:39.880]   And it tries really hard to do that.
[01:43:39.880 --> 01:43:42.280]   And it doesn't have a commercial motive, right?
[01:43:42.280 --> 01:43:43.280]   Right.
[01:43:43.280 --> 01:43:45.040]   Well, it does now as well, but it's very good as it.
[01:43:45.040 --> 01:43:46.960]   To the degree it has a commercial motive?
[01:43:46.960 --> 01:43:47.960]   I would submit.
[01:43:47.960 --> 01:43:50.680]   But that's the degree it's starting to be terrible.
[01:43:50.680 --> 01:43:51.680]   Yeah.
[01:43:51.680 --> 01:43:59.200]   But the local radio thing, sort of Liz Truss's first obvious collapse was she did an eight
[01:43:59.200 --> 01:44:03.760]   interviews in a row with different local radio stations in the UK on the 20th of September.
[01:44:03.760 --> 01:44:05.640]   And got taken apart, literally eight-minute interviews.
[01:44:05.640 --> 01:44:07.360]   And she was thinking, "Oh, look at radio.
[01:44:07.360 --> 01:44:08.640]   The full-o be easy."
[01:44:08.640 --> 01:44:11.240]   And they just completely took her apart one after another.
[01:44:11.240 --> 01:44:13.080]   If you have come to touch together...
[01:44:13.080 --> 01:44:14.600]   It's the most part immediate.
[01:44:14.600 --> 01:44:15.600]   God bless the busy stitch.
[01:44:15.600 --> 01:44:18.600]   They've been stitched together in one long thing you could listen to.
[01:44:18.600 --> 01:44:19.600]   Yes.
[01:44:19.600 --> 01:44:21.080]   So you could hear each of those interviews that was...
[01:44:21.080 --> 01:44:23.080]   There's a podcast for the whole thing.
[01:44:23.080 --> 01:44:24.080]   It's brilliant.
[01:44:24.080 --> 01:44:27.440]   We have so many other stories and we're not going to get to any of them.
[01:44:27.440 --> 01:44:28.440]   I hope you don't mind.
[01:44:28.440 --> 01:44:30.400]   To talk to someone porn.
[01:44:30.400 --> 01:44:32.680]   No, it's not going porn.
[01:44:32.680 --> 01:44:35.480]   They're just going to have some streams that limit to 18 or over.
[01:44:35.480 --> 01:44:38.200]   It still has the same exact rules.
[01:44:38.200 --> 01:44:39.720]   You misread the headlines.
[01:44:39.720 --> 01:44:41.080]   I was trying to be sensationalist.
[01:44:41.080 --> 01:44:42.560]   Yeah, that's totally sensational.
[01:44:42.560 --> 01:44:44.160]   It's the good news for Netflix.
[01:44:44.160 --> 01:44:49.480]   They suddenly developed two and a half million more subscribers and shocked the market.
[01:44:49.480 --> 01:44:52.000]   Sure, it was Sandman.
[01:44:52.000 --> 01:44:53.000]   Sandman did it.
[01:44:53.000 --> 01:44:54.000]   Sandman did it.
[01:44:54.000 --> 01:44:55.000]   No, I think it's Jeffrey Dohmer.
[01:44:55.000 --> 01:44:56.000]   I hate to say it.
[01:44:56.000 --> 01:44:57.000]   I don't.
[01:44:57.000 --> 01:44:58.000]   I am so disgusted by that.
[01:44:58.000 --> 01:44:59.000]   I won't watch it.
[01:44:59.000 --> 01:45:00.000]   I don't.
[01:45:00.000 --> 01:45:01.000]   I don't.
[01:45:01.000 --> 01:45:02.000]   I don't.
[01:45:02.000 --> 01:45:06.400]   It's a serial killer thing that there's so many programs that are obsessed with silly
[01:45:06.400 --> 01:45:07.400]   things.
[01:45:07.400 --> 01:45:08.400]   Talk about...
[01:45:08.400 --> 01:45:10.920]   It's the lowest common denominator program.
[01:45:10.920 --> 01:45:14.000]   Talk about monkey brain going after the monkey mind.
[01:45:14.000 --> 01:45:15.000]   It's exploitation.
[01:45:15.000 --> 01:45:16.000]   Right?
[01:45:16.000 --> 01:45:17.000]   But exploitation works.
[01:45:17.000 --> 01:45:18.000]   Yeah.
[01:45:18.000 --> 01:45:21.040]   All right, I want to take a little break and then, believe it or not, I hate to say it,
[01:45:21.040 --> 01:45:23.600]   but picks of the week time coming up next.
[01:45:23.600 --> 01:45:26.000]   We have so many things we could have talked about.
[01:45:26.000 --> 01:45:29.680]   I'm not even going to do the change log because we've had such a great conversation.
[01:45:29.680 --> 01:45:31.040]   Rules are all off.
[01:45:31.040 --> 01:45:34.200]   Well, I'm trying to get this show down to two hours, dude.
[01:45:34.200 --> 01:45:37.840]   It was three and a half hours two weeks ago and Stacy's never come back.
[01:45:37.840 --> 01:45:38.840]   So...
[01:45:38.840 --> 01:45:39.840]   She tried it and...
[01:45:39.840 --> 01:45:40.840]   She disappeared.
[01:45:40.840 --> 01:45:44.040]   It's like, ah, yeah, I can't do this anymore.
[01:45:44.040 --> 01:45:48.280]   So we're going to try to get this show down to a reasonable length of time.
[01:45:48.280 --> 01:45:52.040]   Also out of respect for our three great panelists.
[01:45:52.040 --> 01:45:53.040]   Love you, Kenchorks.
[01:45:53.040 --> 01:45:55.320]   It's so nice to have you.
[01:45:55.320 --> 01:45:56.720]   Even older combat, you're here.
[01:45:56.720 --> 01:45:57.720]   Thank you.
[01:45:57.720 --> 01:45:58.720]   Yes.
[01:45:58.720 --> 01:45:59.720]   Sacrifice your mission.
[01:45:59.720 --> 01:46:00.720]   Yes, it's midnight in the UK.
[01:46:00.720 --> 01:46:01.720]   You should be sleeping off.
[01:46:01.720 --> 01:46:02.720]   You should be sleeping off.
[01:46:02.720 --> 01:46:04.280]   We should be going to bed so we're going to let you get to bed.
[01:46:04.280 --> 01:46:06.240]   Of course, the wonderful Glenn Fleischmann.
[01:46:06.240 --> 01:46:08.080]   I hope we get you on more.
[01:46:08.080 --> 01:46:09.080]   Thank you so much.
[01:46:09.080 --> 01:46:12.840]   I told our producers, they said, Glenn should be our regular fill-in.
[01:46:12.840 --> 01:46:13.840]   I just love Glenn.
[01:46:13.840 --> 01:46:15.840]   Thank you so much.
[01:46:15.840 --> 01:46:19.360]   I successfully got avoided.
[01:46:19.360 --> 01:46:20.560]   You two talking about fonts.
[01:46:20.560 --> 01:46:23.200]   And so I consider this a victory on this show.
[01:46:23.200 --> 01:46:24.440]   Jeff Jarvis.
[01:46:24.440 --> 01:46:25.440]   [laughter]
[01:46:25.440 --> 01:46:26.440]   There may be those...
[01:46:26.440 --> 01:46:27.440]   We'll do it.
[01:46:27.440 --> 01:46:28.440]   There'll be some...
[01:46:28.440 --> 01:46:30.680]   Maybe those some be some lead type in our future.
[01:46:30.680 --> 01:46:31.680]   [laughter]
[01:46:31.680 --> 01:46:36.200]   Coming up in just a bit, our picks of the week.
[01:46:36.200 --> 01:46:39.760]   But first this word from Nureva, today's IT pros.
[01:46:39.760 --> 01:46:41.520]   You're in a tough spot.
[01:46:41.520 --> 01:46:43.280]   I know the shift to hybrid working.
[01:46:43.280 --> 01:46:44.840]   Oh my gosh.
[01:46:44.840 --> 01:46:45.840]   Some people are here.
[01:46:45.840 --> 01:46:46.840]   Some people aren't here.
[01:46:46.840 --> 01:46:47.840]   Some people are on Zoom.
[01:46:47.840 --> 01:46:48.840]   Some people are on Barbados.
[01:46:48.840 --> 01:46:49.840]   I don't know what's going on.
[01:46:49.840 --> 01:46:54.640]   You got to equip and support more spaces with audio and video conferencing systems.
[01:46:54.640 --> 01:46:57.840]   And that's a nightmare all by itself.
[01:46:57.840 --> 01:47:03.000]   And meantime, you still got network security, the moves of the cloud, infrastructure issues,
[01:47:03.000 --> 01:47:04.000]   all these other things.
[01:47:04.000 --> 01:47:06.840]   Endpoints, security to think about.
[01:47:06.840 --> 01:47:09.720]   And then there's product shortages and delays.
[01:47:09.720 --> 01:47:13.400]   IT, my deepest respect for you.
[01:47:13.400 --> 01:47:16.640]   There's such pressure on IT resources.
[01:47:16.640 --> 01:47:20.120]   People, time, expertise, budgets.
[01:47:20.120 --> 01:47:22.560]   So I've got a solution for you.
[01:47:22.560 --> 01:47:27.040]   If you're looking for an intelligent product that requires minimal effort from IT to deploy
[01:47:27.040 --> 01:47:34.400]   a management scale that will solve your audio and video conferencing issues and require
[01:47:34.400 --> 01:47:37.920]   zero end user training, this is Nureva.
[01:47:37.920 --> 01:47:43.360]   When it comes to audio conferencing in larger spaces, often people choose.
[01:47:43.360 --> 01:47:48.520]   And I think it's a big mistake to go for these very expensive multi-component systems that
[01:47:48.520 --> 01:47:50.840]   somebody has to come in, design, install.
[01:47:50.840 --> 01:47:52.440]   Then you got to tweak them and maintain them.
[01:47:52.440 --> 01:47:53.440]   And it's just a nightmare.
[01:47:53.440 --> 01:47:57.000]   And you don't want to add more burden to your already burdened IT department.
[01:47:57.000 --> 01:47:58.160]   You will love Nureva.
[01:47:58.160 --> 01:48:00.720]   They will love Nureva.
[01:48:00.720 --> 01:48:05.360]   These are simple solutions that work really well with Nureva you get, for instance, true
[01:48:05.360 --> 01:48:10.640]   full room mic pickup from just one or two microphone and speaker bars that you can install
[01:48:10.640 --> 01:48:13.720]   yourself in half an hour.
[01:48:13.720 --> 01:48:14.920]   Climb up a little later.
[01:48:14.920 --> 01:48:16.320]   Have you ever put in a sound bar?
[01:48:16.320 --> 01:48:18.920]   It's that easy.
[01:48:18.920 --> 01:48:24.360]   No multiple mic speakers, amps, DSP switches, none of that.
[01:48:24.360 --> 01:48:29.040]   You can install Nureva in most spaces in less than a half an hour in a larger space, maybe
[01:48:29.040 --> 01:48:31.560]   in a taken hour you put in two.
[01:48:31.560 --> 01:48:34.320]   Very simple, no special expertise required.
[01:48:34.320 --> 01:48:39.960]   But you're really taking advantage of this patented technology.
[01:48:39.960 --> 01:48:47.560]   They call it the Nureva microphone mist technology that uses computational audio to put microphones
[01:48:47.560 --> 01:48:49.560]   everywhere in the room.
[01:48:49.560 --> 01:48:55.520]   So people in these meetings can sit where they want, face where they want, can be comfortable.
[01:48:55.520 --> 01:48:56.760]   And you can be comfortable too.
[01:48:56.760 --> 01:49:03.280]   Your IT department can be down the hall, monitoring, managing, updating, adjusting all the Nureva
[01:49:03.280 --> 01:49:08.440]   systems right from the Nureva console, which is cloud based.
[01:49:08.440 --> 01:49:12.360]   I guess your IT guy can be working at home.
[01:49:12.360 --> 01:49:13.360]   Still do it.
[01:49:13.360 --> 01:49:15.880]   Nureva very scalable for large organizations.
[01:49:15.880 --> 01:49:20.920]   Nure systems cost a fraction of traditional systems and they work better.
[01:49:20.920 --> 01:49:24.520]   Right now, we've been talking about Nureva for a while, but we've got a special offer.
[01:49:24.520 --> 01:49:26.440]   I really want to highlight.
[01:49:26.440 --> 01:49:29.480]   You've probably heard us talk about this, the microphone mist technology, how well it
[01:49:29.480 --> 01:49:32.440]   works in a hybrid workspace.
[01:49:32.440 --> 01:49:38.680]   Right now 50% off a Nureva HDL 300 system for mid-size rooms.
[01:49:38.680 --> 01:49:44.760]   When you get a live online demo and you buy before December 16th, 2022, half off, the
[01:49:44.760 --> 01:49:47.000]   HDL 300 is perfect for a mid-size room.
[01:49:47.000 --> 01:49:48.400]   It's all you need.
[01:49:48.400 --> 01:49:53.360]   It's a sound bar with those array microphones that give you the microphone mist technology.
[01:49:53.360 --> 01:50:00.960]   And right now half off just for you when you go to nureva.com/twit.
[01:50:00.960 --> 01:50:02.560]   That's an amazing price.
[01:50:02.560 --> 01:50:05.920]   I mean, just compare that to any other system.
[01:50:05.920 --> 01:50:09.680]   And it's simple and it configures itself and it tweaks itself and it's so easy to
[01:50:09.680 --> 01:50:12.080]   use and it's so easy to install.
[01:50:12.080 --> 01:50:17.040]   Now, off the HDL 300 system and you are EVA.com/twit.
[01:50:17.040 --> 01:50:19.080]   Nureva.com/twit.
[01:50:19.080 --> 01:50:20.640]   Get that live demo online.
[01:50:20.640 --> 01:50:21.640]   That's actually a good idea.
[01:50:21.640 --> 01:50:23.600]   I want you to hear it before you buy it.
[01:50:23.600 --> 01:50:27.360]   And you do have to buy it before December 16th, 2022.
[01:50:27.360 --> 01:50:28.520]   Nureva.com/twit.
[01:50:28.520 --> 01:50:30.240]   This is such a good solution.
[01:50:30.240 --> 01:50:36.520]   Great audio can be easy and take a lot of the burden off your IT, guys.
[01:50:36.520 --> 01:50:37.760]   Nureva.com/twit.
[01:50:37.760 --> 01:50:41.360]   Thank you Nureva for supporting this week in Google.
[01:50:41.360 --> 01:50:46.640]   And of course, you support us when you use that special address.
[01:50:46.640 --> 01:50:48.560]   Nureva.com/twit.
[01:50:48.560 --> 01:50:52.080]   Now we get back to the show.
[01:50:52.080 --> 01:50:53.560]   So much more stuff to talk about.
[01:50:53.560 --> 01:50:59.120]   But I think, you know, the robot testifying before the House of Lords, that's incredible.
[01:50:59.120 --> 01:51:04.920]   We'll do a better job than half the cabinet now.
[01:51:04.920 --> 01:51:06.520]   I die.
[01:51:06.520 --> 01:51:09.720]   Shut down halfway through the evidence session.
[01:51:09.720 --> 01:51:11.400]   It was the House of Lords, after all.
[01:51:11.400 --> 01:51:12.400]   I imagine--
[01:51:12.400 --> 01:51:13.400]   Imagine--
[01:51:13.400 --> 01:51:14.400]   Are you reading--
[01:51:14.400 --> 01:51:15.400]   Listen to Guardian?
[01:51:15.400 --> 01:51:16.400]   Are you reading Tofu also?
[01:51:16.400 --> 01:51:20.400]   I imagine at least half of the Lords there were half asleep.
[01:51:20.400 --> 01:51:22.400]   So they probably thought I was a real person.
[01:51:22.400 --> 01:51:23.400]   We're just thinking of the audience.
[01:51:23.400 --> 01:51:24.400]   Yeah.
[01:51:24.400 --> 01:51:25.400]   Yeah.
[01:51:25.400 --> 01:51:26.400]   What is--
[01:51:26.400 --> 01:51:32.040]   What she's saying is that there's one of Boris Johnson's heading out the doors attempts
[01:51:32.040 --> 01:51:34.360]   to get-- oh, Kevin, what's her name?
[01:51:34.360 --> 01:51:37.080]   The former Secretary of Culture at Nadine Doris.
[01:51:37.080 --> 01:51:38.080]   Doris?
[01:51:38.080 --> 01:51:39.080]   Yeah.
[01:51:39.080 --> 01:51:44.920]   She may not get her seat in the House of Lords because she lied-- or allegedly lied--
[01:51:44.920 --> 01:51:46.880]   to Parliament a decade ago.
[01:51:46.880 --> 01:51:48.600]   And so that's nice little--
[01:51:48.600 --> 01:51:50.160]   One nice thing about a robot.
[01:51:50.160 --> 01:51:51.160]   They never lie.
[01:51:51.160 --> 01:51:52.160]   Here's a little video.
[01:51:52.160 --> 01:51:53.160]   Now we can--
[01:51:53.160 --> 01:51:54.160]   I think I can play this of the--
[01:51:54.160 --> 01:51:58.600]   Quick, I don't want Ada to fall asleep again.
[01:51:58.600 --> 01:52:02.280]   I'd-- shall we deal with the question to Ada?
[01:52:02.280 --> 01:52:03.280]   And then we can--
[01:52:03.280 --> 01:52:04.280]   Ada is the robot.
[01:52:04.280 --> 01:52:05.280]   Is she ready?
[01:52:05.280 --> 01:52:06.280]   Ada had fallen asleep.
[01:52:06.280 --> 01:52:07.280]   And that'd be really--
[01:52:07.280 --> 01:52:09.880]   There are very many lords are there.
[01:52:09.880 --> 01:52:10.880]   It's a small group.
[01:52:10.880 --> 01:52:11.880]   This is a committee.
[01:52:11.880 --> 01:52:12.880]   Oh, it's a committee.
[01:52:12.880 --> 01:52:16.680]   The lords chamber is-- there's actually more lords and commons.
[01:52:16.680 --> 01:52:17.680]   Oh.
[01:52:17.680 --> 01:52:18.680]   Hello there.
[01:52:18.680 --> 01:52:25.680]   How do you introduce art and how is this different to what human art is--
[01:52:25.680 --> 01:52:26.680]   What?
[01:52:26.680 --> 01:52:35.120]   I produced my paintings by cameras in my eyes.
[01:52:35.120 --> 01:52:36.120]   My AI algorithm--
[01:52:36.120 --> 01:52:39.720]   Can you imagine this happening in Congress and what Sean Hannity would make of it?
[01:52:39.720 --> 01:52:40.720]   I think on campus.
[01:52:40.720 --> 01:52:42.720]   Which result in visually--
[01:52:42.720 --> 01:52:43.720]   It might elect advice present.
[01:52:43.720 --> 01:52:44.720]   It might elect advice present.
[01:52:44.720 --> 01:52:45.720]   I think it's different.
[01:52:45.720 --> 01:52:46.720]   All right.
[01:52:46.720 --> 01:52:47.720]   That's enough.
[01:52:47.720 --> 01:52:48.720]   We've been programmed.
[01:52:48.720 --> 01:52:49.720]   Enough of Ada.
[01:52:49.720 --> 01:52:50.720]   Yeah, it's a little bit of Ada.
[01:52:50.720 --> 01:52:51.720]   Mr. Glenn Fleischman.
[01:52:51.720 --> 01:52:52.720]   Share some of the--
[01:52:52.720 --> 01:52:54.520]   There's trust to be fed.
[01:52:54.520 --> 01:52:58.120]   Share some of the wonderful things you have been up to lately.
[01:52:58.120 --> 01:53:03.960]   Well, in honor and commemoration of the late Queen Elizabeth II I present this, which is--
[01:53:03.960 --> 01:53:06.480]   Oh, I saw this on your Twitter or somewhere.
[01:53:06.480 --> 01:53:07.840]   Yeah, this is really cool.
[01:53:07.840 --> 01:53:08.840]   This is--
[01:53:08.840 --> 01:53:14.760]   This is-- was it the coronation of Queen Victoria?
[01:53:14.760 --> 01:53:15.760]   Is that the--
[01:53:15.760 --> 01:53:17.520]   Yes, I have a hard time getting this to--
[01:53:17.520 --> 01:53:18.520]   And it's--
[01:53:18.520 --> 01:53:19.520]   Note the color.
[01:53:19.520 --> 01:53:22.520]   That's-- can we get it?
[01:53:22.520 --> 01:53:23.520]   There you go.
[01:53:23.520 --> 01:53:25.120]   Yeah, that's-- okay.
[01:53:25.120 --> 01:53:26.120]   We get it.
[01:53:26.120 --> 01:53:27.520]   [LAUGHTER]
[01:53:27.520 --> 01:53:29.320]   Tell us--
[01:53:29.320 --> 01:53:30.320]   I'm down to my father.
[01:53:30.320 --> 01:53:32.240]   Why is it so gold?
[01:53:32.240 --> 01:53:37.400]   This is-- this paper, it's called the paper that poisoned its printers is kind of a name
[01:53:37.400 --> 01:53:38.400]   for it.
[01:53:38.400 --> 01:53:45.480]   It's-- so printed in 1838 and I just got a copy of it used, you know, perfectly conditioned
[01:53:45.480 --> 01:53:52.160]   copy and the reasons called that is they wanted to do a special edition and this paper,
[01:53:52.160 --> 01:53:59.440]   the sun and they contracted with the fellow who ultimately his firm on black and his name.
[01:53:59.440 --> 01:54:04.720]   It's the one that prints passports now and actually complained during Brexit that the
[01:54:04.720 --> 01:54:09.280]   passports were never being operated by this English company but by one in I think the Netherlands
[01:54:09.280 --> 01:54:10.280]   or something.
[01:54:10.280 --> 01:54:15.720]   Anyway, so this newspaper, they figured a technique to essentially brush-- brush brass
[01:54:15.720 --> 01:54:22.160]   filings, say that three times fast over a kind of a sizing or a kind of gluey material
[01:54:22.160 --> 01:54:26.360]   that was printed on the page to give it this gold sheen.
[01:54:26.360 --> 01:54:27.360]   So it was golden.
[01:54:27.360 --> 01:54:30.080]   And then of course, here's your fold out section.
[01:54:30.080 --> 01:54:36.320]   The cover is a portrait of Queen Victoria and the back side of it, the other side is
[01:54:36.320 --> 01:54:37.320]   unprinted.
[01:54:37.320 --> 01:54:39.200]   So you would cut this out and put this up.
[01:54:39.200 --> 01:54:40.200]   And so this is 1838.
[01:54:40.200 --> 01:54:41.200]   This is fancy--
[01:54:41.200 --> 01:54:42.200]   Wow.
[01:54:42.200 --> 01:54:43.200]   --aren't suitable for framing.
[01:54:43.200 --> 01:54:44.200]   Yeah.
[01:54:44.200 --> 01:54:45.200]   Exactly.
[01:54:45.200 --> 01:54:49.240]   So it's a very interesting historic item and it turns out, you know, there's copies available
[01:54:49.240 --> 01:54:50.240]   for sale from time to time.
[01:54:50.240 --> 01:54:53.840]   It was not very expensive because it's obscure, always collective, obscure things.
[01:54:53.840 --> 01:54:55.160]   I was a killing the printers.
[01:54:55.160 --> 01:54:56.160]   More fun.
[01:54:56.160 --> 01:54:58.080]   Oh, so this is the terrible part.
[01:54:58.080 --> 01:55:04.400]   So the company back in the days before there were things like, you know, HIPAA or the equivalent
[01:55:04.400 --> 01:55:07.440]   in any country, there's an account from this period.
[01:55:07.440 --> 01:55:11.800]   A doctor writes a letter into a medical journal and he says, "I had a patient come in and
[01:55:11.800 --> 01:55:16.200]   he gives his full name and says this patient was covered in pustules on his various body
[01:55:16.200 --> 01:55:21.280]   parts and describes the whole condition and asks him, "It's good doctor.
[01:55:21.280 --> 01:55:25.040]   He asks him what-- you know, this is before-- this is before removing the pump handle,
[01:55:25.040 --> 01:55:28.600]   the before the invention of epidemiology.
[01:55:28.600 --> 01:55:31.920]   This doctor asks the question, you know, what was the cause of this?"
[01:55:31.920 --> 01:55:35.560]   And the kid says, "Guys a teenager," because of course, in 1838, you could probably be
[01:55:35.560 --> 01:55:38.800]   11 or 12, you'd be working at a printing plant or whatever.
[01:55:38.800 --> 01:55:44.040]   Well, I was working-- we were creating these gold-hues newspapers such as such spot.
[01:55:44.040 --> 01:55:47.200]   So the doctor-- the patient doesn't return after the doctor gives him some treatment advice
[01:55:47.200 --> 01:55:49.840]   and he goes-- he does Sherlock Holmes' research.
[01:55:49.840 --> 01:55:52.960]   He goes out and he finds-- he goes to the newspaper plant where they answer a bunch of
[01:55:52.960 --> 01:55:57.240]   questions and he finds out about the brass filing plant and the deal is they were-- there's
[01:55:57.240 --> 01:56:02.320]   one company shaving down pieces of brass and those people were apparently dying.
[01:56:02.320 --> 01:56:05.920]   He had second-in information about it because they're breathing in brass filings.
[01:56:05.920 --> 01:56:11.800]   Then all these filings are taken to the printing location and the printers are brushing it
[01:56:11.800 --> 01:56:16.840]   on onto this slightly sticky surface and they're breathing this in and they're getting,
[01:56:16.840 --> 01:56:21.520]   you know, scruffulous medical afflictions from it.
[01:56:21.520 --> 01:56:25.680]   And so the doctor did all the work and, you know, kind of wrote this up as a thing.
[01:56:25.680 --> 01:56:29.440]   So it's possible-- we don't have firsthand information about deaths caused by it, but
[01:56:29.440 --> 01:56:31.400]   it's a remarkable thing.
[01:56:31.400 --> 01:56:36.080]   But it was also-- it was possibly the most-- the broadest-- the widest printed newspaper
[01:56:36.080 --> 01:56:39.360]   edition of its time.
[01:56:39.360 --> 01:56:44.680]   Probably 250,000 copies were printed over many, many weeks and at the time, these are
[01:56:44.680 --> 01:56:45.880]   all rag paper, right?
[01:56:45.880 --> 01:56:50.600]   This is being printed wood pulp paper like used in paperbacks and newspapers at the end
[01:56:50.600 --> 01:56:51.960]   of the 19th century wasn't used.
[01:56:51.960 --> 01:56:53.200]   So this is cotton paper.
[01:56:53.200 --> 01:56:54.720]   That's why it survives so well.
[01:56:54.720 --> 01:56:55.800]   It looks so beautiful.
[01:56:55.800 --> 01:56:58.400]   It's a little worn, but it's very fresh.
[01:56:58.400 --> 01:57:00.720]   And 250,000 copies.
[01:57:00.720 --> 01:57:06.880]   And I think this one is labeled edition-- it's the 15th edition of this printed like two
[01:57:06.880 --> 01:57:08.040]   weeks later.
[01:57:08.040 --> 01:57:09.040]   You should frame that.
[01:57:09.040 --> 01:57:11.000]   Yeah, I've got to-- it's huge.
[01:57:11.000 --> 01:57:14.840]   I have to figure out how to open it up.
[01:57:14.840 --> 01:57:19.560]   But yeah, it's a piece of fascinating printing history.
[01:57:19.560 --> 01:57:25.280]   And I might add, in 686 episodes, the first time the words "scrophyllus postules" have
[01:57:25.280 --> 01:57:27.680]   been used on the show.
[01:57:27.680 --> 01:57:28.920]   We're holding back.
[01:57:28.920 --> 01:57:29.920]   So title.
[01:57:29.920 --> 01:57:30.920]   So title.
[01:57:30.920 --> 01:57:33.280]   I don't think that's got good SEO.
[01:57:33.280 --> 01:57:35.600]   I hate to say it.
[01:57:35.600 --> 01:57:38.360]   I hear laughing in the back of the studio.
[01:57:38.360 --> 01:57:40.600]   Sorry, that's good.
[01:57:40.600 --> 01:57:44.320]   Jeff Jarvis, your number of the week.
[01:57:44.320 --> 01:57:46.760]   So I think the Freedom House is where this is repeated in "Depressing Show."
[01:57:46.760 --> 01:57:48.480]   It involves a continue, that motif.
[01:57:48.480 --> 01:57:54.000]   The Freedom House issued its annual Freedom Report on Freedom of Expression and the Internet.
[01:57:54.000 --> 01:58:00.680]   And if you scroll down, you'll see a gray box that says that 76% of the people on the
[01:58:00.680 --> 01:58:04.640]   Internet live in the 4.5 billion people access to the Internet.
[01:58:04.640 --> 01:58:08.600]   Live in countries where individuals were arrested or imprisoned for posting content
[01:58:08.600 --> 01:58:10.840]   on political social or religious issues.
[01:58:10.840 --> 01:58:15.000]   69% live in countries where authorities deployed pro-government commentators to manipulate
[01:58:15.000 --> 01:58:16.000]   discussion.
[01:58:16.000 --> 01:58:21.200]   64% live in countries where political social or religious content was blocked online.
[01:58:21.200 --> 01:58:26.040]   64% live in countries where individuals have been attacked or killed for their online activities
[01:58:26.040 --> 01:58:28.520]   since June 2021.
[01:58:28.520 --> 01:58:34.000]   51% live in countries where access to social media platforms were temporarily or permanently
[01:58:34.000 --> 01:58:35.240]   restricted.
[01:58:35.240 --> 01:58:36.880]   More than half the world.
[01:58:36.880 --> 01:58:42.000]   And 44% live in countries where authorities disconnected Internet or mobile networks often
[01:58:42.000 --> 01:58:43.760]   for political reasons.
[01:58:43.760 --> 01:58:45.920]   So you hear me screaming moral panic?
[01:58:45.920 --> 01:58:46.920]   This is what I'm saying.
[01:58:46.920 --> 01:58:49.920]   Well yeah, nothing we've been talking about today.
[01:58:49.920 --> 01:58:51.720]   It comes close to this.
[01:58:51.720 --> 01:58:52.720]   This.
[01:58:52.720 --> 01:58:57.480]   But this is where it heads if you don't fight for the freedoms.
[01:58:57.480 --> 01:59:00.560]   Or if you do fight for the freedoms or if you don't fight for the freedoms.
[01:59:00.560 --> 01:59:01.560]   We're not sure.
[01:59:01.560 --> 01:59:03.320]   Do you think Jeff this, Graham, is this show?
[01:59:03.320 --> 01:59:06.640]   Was it so it's only going to get worse?
[01:59:06.640 --> 01:59:08.000]   No, I don't.
[01:59:08.000 --> 01:59:10.000]   I'm an optimist.
[01:59:10.000 --> 01:59:13.520]   Well, but it may be generations hence.
[01:59:13.520 --> 01:59:17.960]   So there was once I debated a German regulator at peruja.
[01:59:17.960 --> 01:59:20.280]   I might have told the story a couple of years ago.
[01:59:20.280 --> 01:59:23.000]   And I said, well, you know, it's just like this, like Gutenberg.
[01:59:23.000 --> 01:59:26.760]   We may have to go through our 30 years war and he with no German irony because it wasn't
[01:59:26.760 --> 01:59:34.720]   in his blood said far too soon to joke about that.
[01:59:34.720 --> 01:59:38.440]   It still lives in our memory.
[01:59:38.440 --> 01:59:42.120]   Mr Kevin Marks, you've got a pick of the week I note.
[01:59:42.120 --> 01:59:46.680]   Well, I think this goes with the talking about domain names earlier.
[01:59:46.680 --> 01:59:50.080]   We've got a link on the indie website where you can get free domain names.
[01:59:50.080 --> 01:59:52.080]   Oh, there you are.
[01:59:52.080 --> 01:59:53.080]   Oh, oh.
[01:59:53.080 --> 01:59:57.440]   The registrars that will give you high level domains for free and they'll sort of up-sury
[01:59:57.440 --> 01:59:58.880]   one hosting and things.
[01:59:58.880 --> 02:00:04.600]   So it's for countries and a few phenom is it.
[02:00:04.600 --> 02:00:11.480]   I love TK because in my field in editorial, that's what we don't know something to come,
[02:00:11.480 --> 02:00:12.480]   right?
[02:00:12.480 --> 02:00:14.160]   So I think that'd be quite like that.
[02:00:14.160 --> 02:00:16.880]   It's interesting that the three out of the four, actually, I don't know where the four,
[02:00:16.880 --> 02:00:19.680]   what Tocolo is, but three out of the four in Africa.
[02:00:19.680 --> 02:00:20.680]   So the island.
[02:00:20.680 --> 02:00:21.680]   Yeah.
[02:00:21.680 --> 02:00:22.680]   Interesting.
[02:00:22.680 --> 02:00:29.120]   So that's a indie web special.
[02:00:29.120 --> 02:00:34.240]   indieweb.org is a great site to visit for anybody who wants to keep the internet free,
[02:00:34.240 --> 02:00:37.600]   open, and to keep the good things happening on the internet.
[02:00:37.600 --> 02:00:42.080]   It really is.
[02:00:42.080 --> 02:00:48.320]   You've got a West Coast Home Brew website club meeting coming up October 19th.
[02:00:48.320 --> 02:00:49.320]   That's tomorrow.
[02:00:49.320 --> 02:00:50.320]   No, it's tonight.
[02:00:50.320 --> 02:00:51.880]   It's two hours.
[02:00:51.880 --> 02:00:52.880]   Yeah.
[02:00:52.880 --> 02:00:56.040]   6 to 8 p.m. in Los Angeles time.
[02:00:56.040 --> 02:00:58.040]   You can go from anywhere in the world though, right?
[02:00:58.040 --> 02:00:59.040]   You don't have to.
[02:00:59.040 --> 02:01:00.040]   Yes, yeah.
[02:01:00.040 --> 02:01:05.040]   No, we've moved entirely online and have been for the duration and we haven't gotten
[02:01:05.040 --> 02:01:06.880]   any in person ones for quite a while.
[02:01:06.880 --> 02:01:07.880]   Nice.
[02:01:07.880 --> 02:01:09.520]   There was a couple of indie web camps.
[02:01:09.520 --> 02:01:12.800]   There was one in Germany, but basically we're doing pretty much everything online these
[02:01:12.800 --> 02:01:13.800]   days.
[02:01:13.800 --> 02:01:15.880]   And it's very smooth.
[02:01:15.880 --> 02:01:20.640]   Is there an agenda or you just kind of talk about what anybody brings up at these events?
[02:01:20.640 --> 02:01:25.640]   It's sort of come and talk about your website and what are you trying to do with it and
[02:01:25.640 --> 02:01:27.480]   it's fairly free form.
[02:01:27.480 --> 02:01:28.800]   Can you get some help?
[02:01:28.800 --> 02:01:31.400]   Yeah, no, that's part of the point, as if you do.
[02:01:31.400 --> 02:01:32.400]   You can see.
[02:01:32.400 --> 02:01:35.200]   I'm trying to get webs that does this and we get, oh, can help with that.
[02:01:35.200 --> 02:01:37.200]   Have you looked at this thing and so on?
[02:01:37.200 --> 02:01:38.200]   Yeah.
[02:01:38.200 --> 02:01:39.200]   Very nice.
[02:01:39.200 --> 02:01:41.800]   indieweb.org, it's in the events section.
[02:01:41.800 --> 02:01:44.680]   Kevin, I hope you feel better soon.
[02:01:44.680 --> 02:01:46.520]   I feel terrible keeping you up so late.
[02:01:46.520 --> 02:01:47.520]   Thank you for doing this.
[02:01:47.520 --> 02:01:49.520]   Yeah, struggling for us.
[02:01:49.520 --> 02:01:50.520]   Great to see you.
[02:01:50.520 --> 02:01:51.520]   Yeah.
[02:01:51.520 --> 02:01:52.520]   And it's going to see you two, Glenn.
[02:01:52.520 --> 02:01:53.520]   It's been a while.
[02:01:53.520 --> 02:01:54.520]   Oh, you know each other.
[02:01:54.520 --> 02:01:55.520]   Awesome.
[02:01:55.520 --> 02:01:59.360]   Yes, we met in IRL, I think, possibly first after some blogging.
[02:01:59.360 --> 02:02:00.360]   Nice.
[02:02:00.360 --> 02:02:01.360]   Very nice.
[02:02:01.360 --> 02:02:02.360]   Oh.
[02:02:02.360 --> 02:02:03.360]   Oh.
[02:02:03.360 --> 02:02:05.600]   I'm looking forward to that becoming really.
[02:02:05.600 --> 02:02:06.600]   That's right.
[02:02:06.600 --> 02:02:11.320]   Some day, yes, some day, the Brigadoon of X-X-O-X-O, which is in Portland.
[02:02:11.320 --> 02:02:15.320]   I know everyone's just saying about that and that happens.
[02:02:15.320 --> 02:02:17.640]   It's every 20 years, every seven years, I can't remember.
[02:02:17.640 --> 02:02:19.880]   Oh, well, they did six years, I think, right?
[02:02:19.880 --> 02:02:21.640]   And then they've been off for three.
[02:02:21.640 --> 02:02:22.920]   They're just at some point.
[02:02:22.920 --> 02:02:25.200]   At some point it will be safe or safe enough.
[02:02:25.200 --> 02:02:26.200]   Lovely.
[02:02:26.200 --> 02:02:27.200]   Yeah.
[02:02:27.200 --> 02:02:28.200]   Thank you, Kevin.
[02:02:28.200 --> 02:02:30.400]   Marx, indieweb.org, anything else you want to mention or plug?
[02:02:30.400 --> 02:02:33.240]   No, that'll do for now, indieweb.org is good.
[02:02:33.240 --> 02:02:36.160]   I'm so glad you were here to talk about Blue Sky.
[02:02:36.160 --> 02:02:37.160]   That's fantastic.
[02:02:37.160 --> 02:02:38.160]   Thank you.
[02:02:38.160 --> 02:02:39.160]   Yeah.
[02:02:39.160 --> 02:02:40.160]   I appreciate your place.
[02:02:40.160 --> 02:02:41.160]   It was to me.
[02:02:41.160 --> 02:02:42.800]   Glenn Fleischman, same to you, buddy.
[02:02:42.800 --> 02:02:43.800]   Thank you.
[02:02:43.800 --> 02:02:51.560]   Love Glenn.fun is the website, g-l-e-n-n.f-u-n at Glenn F on the Twitter.
[02:02:51.560 --> 02:02:53.640]   You do other podcasts, I know.
[02:02:53.640 --> 02:02:54.640]   Occasionally.
[02:02:54.640 --> 02:02:55.640]   Occasionally.
[02:02:55.640 --> 02:03:00.480]   I find me on the incomparable network where Kevin will appreciate this one, the Pants
[02:03:00.480 --> 02:03:05.800]   and the Boot Podcast, where I get people together from all over English-speaking countries
[02:03:05.800 --> 02:03:06.800]   from around the world.
[02:03:06.800 --> 02:03:11.920]   We typically focus on the UK and Australia and New Zealand, but we really love to get.
[02:03:11.920 --> 02:03:17.040]   I need to dig up folks from other places where they grew up speaking English as one of the
[02:03:17.040 --> 02:03:21.640]   languages spoken in the country that's not a traditional, one of those.
[02:03:21.640 --> 02:03:24.400]   What a great idea for a podcast.
[02:03:24.400 --> 02:03:25.400]   We have a lot of fun.
[02:03:25.400 --> 02:03:26.400]   It's a comedy podcast.
[02:03:26.400 --> 02:03:31.200]   I have a sort of professional comedians, we all want to be a comedian of whatever.
[02:03:31.200 --> 02:03:35.720]   We're talking about, you know, some will have an entire episode about Lori versus Truck,
[02:03:35.720 --> 02:03:40.220]   but then we'll have an episode about the use of Native peoples' words and how they're
[02:03:40.220 --> 02:03:42.640]   spreading in the different countries we live in.
[02:03:42.640 --> 02:03:47.320]   We have a regular panelist now from New Zealand who can bring in the, it's a Te Ora.
[02:03:47.320 --> 02:03:50.680]   Tell me the right word there.
[02:03:50.680 --> 02:03:56.040]   Our New Zealand in Mallory is...
[02:03:56.040 --> 02:03:57.040]   It's a Laura.
[02:03:57.040 --> 02:03:58.040]   Thank you.
[02:03:58.040 --> 02:04:00.560]   Anyway, we try to do a little bit of a span.
[02:04:00.560 --> 02:04:05.720]   The last episodes that I'm editing right now, we record a bunch of time at someone from
[02:04:05.720 --> 02:04:10.720]   Sweden, who grew up speaking Swedish, but has also fluent in English and Russian.
[02:04:10.720 --> 02:04:16.120]   A woman in Scotland who grew up in Germany and is married to a Scot now.
[02:04:16.120 --> 02:04:19.480]   Our New Zealand friend who lived in Chicago for several years.
[02:04:19.480 --> 02:04:23.760]   We try to span a range of people speaking background.
[02:04:23.760 --> 02:04:24.920]   I will listen.
[02:04:24.920 --> 02:04:29.280]   I love language podcasts and some of my favorite people besides you, Glenn, you've got Jean
[02:04:29.280 --> 02:04:30.280]   MacDonald on.
[02:04:30.280 --> 02:04:31.280]   She is wonderful.
[02:04:31.280 --> 02:04:32.280]   Yeah, I love her.
[02:04:32.280 --> 02:04:36.600]   Of course, associated with micro.blog, Shelley Brisbane is a regular.
[02:04:36.600 --> 02:04:39.560]   A lot of the people we know, James Thompson, Dan Warren.
[02:04:39.560 --> 02:04:40.560]   Thompson.
[02:04:40.560 --> 02:04:41.560]   Yeah.
[02:04:41.560 --> 02:04:48.640]   It's a lovely gang of people at the incomparable and I've managed to sneak them into this side
[02:04:48.640 --> 02:04:49.640]   podcast.
[02:04:49.640 --> 02:04:51.560]   It comes out every once in a while.
[02:04:51.560 --> 02:04:52.560]   I love it.
[02:04:52.560 --> 02:04:53.920]   The detector van is a lie.
[02:04:53.920 --> 02:04:55.720]   I know Kevin will appreciate that one.
[02:04:55.720 --> 02:04:57.720]   You see the detector van episode.
[02:04:57.720 --> 02:04:58.720]   It's a fun one.
[02:04:58.720 --> 02:04:59.720]   Okay.
[02:04:59.720 --> 02:05:01.040]   Let's just do that.
[02:05:01.040 --> 02:05:03.040]   There is no detector van.
[02:05:03.040 --> 02:05:07.640]   The BBC has wanted you to think so, but opinions vary.
[02:05:07.640 --> 02:05:09.040]   Oh, that's hysterical.
[02:05:09.040 --> 02:05:10.240]   I thought there was all this.
[02:05:10.240 --> 02:05:11.240]   There is none, right?
[02:05:11.240 --> 02:05:12.240]   Is there?
[02:05:12.240 --> 02:05:13.240]   There is none.
[02:05:13.240 --> 02:05:16.240]   They did used to work when it was when TV sets were large.
[02:05:16.240 --> 02:05:18.240]   And basically, and...
[02:05:18.240 --> 02:05:19.560]   We could attempt a lead signal or...
[02:05:19.560 --> 02:05:23.040]   Yeah, because it was residents in the back of the set.
[02:05:23.040 --> 02:05:24.520]   No, there it is.
[02:05:24.520 --> 02:05:27.120]   Basically, they just looked at houses with antennas on top and then checked with that
[02:05:27.120 --> 02:05:28.760]   address header.
[02:05:28.760 --> 02:05:30.480]   See if you're paying your license fees.
[02:05:30.480 --> 02:05:31.480]   It's terrible.
[02:05:31.480 --> 02:05:33.480]   And as you do, as you don't miss anything, you didn't enter anymore.
[02:05:33.480 --> 02:05:34.800]   That's behind it.
[02:05:34.800 --> 02:05:37.280]   Thank you, Glenn.
[02:05:37.280 --> 02:05:40.920]   And of course, thank you to Jeff Jarvis, who is our moderator.
[02:05:40.920 --> 02:05:42.560]   And our A-min-all.
[02:05:42.560 --> 02:05:43.560]   S-greeze.
[02:05:43.560 --> 02:05:44.560]   He's the director of the town.
[02:05:44.560 --> 02:05:45.840]   No, no, you're the boss.
[02:05:45.840 --> 02:05:46.840]   I'm nothing.
[02:05:46.840 --> 02:05:47.840]   This is not democracy.
[02:05:47.840 --> 02:05:48.840]   It's a joint.
[02:05:48.840 --> 02:05:51.960]   It's a co-moderation ship, I would say.
[02:05:51.960 --> 02:05:52.960]   You just take a record.
[02:05:52.960 --> 02:05:53.960]   You add more stories than I do.
[02:05:53.960 --> 02:05:58.200]   He's the director of the townite center for entrepreneurial journalism at the E.
[02:05:58.200 --> 02:05:59.200]   Craig.
[02:05:59.200 --> 02:06:00.200]   Craig.
[02:06:00.200 --> 02:06:01.200]   Craig.
[02:06:01.200 --> 02:06:05.040]   New Mark Graduate School of Journalism at the City University of New York.
[02:06:05.040 --> 02:06:06.040]   Buzzmachine.com.
[02:06:06.040 --> 02:06:09.120]   We will see you next week, Glenn.
[02:06:09.120 --> 02:06:10.120]   I think.
[02:06:10.120 --> 02:06:13.360]   Next week, our dear...
[02:06:13.360 --> 02:06:18.320]   Clearly, to Partis Stacey is not here either, but AMB will be back.
[02:06:18.320 --> 02:06:22.840]   And Rabble will join us to talk about planetary.
[02:06:22.840 --> 02:06:29.160]   He was also the lead dev at Odeo, which was Evan Williams' podcast directory before he
[02:06:29.160 --> 02:06:30.160]   did Twitter.
[02:06:30.160 --> 02:06:31.160]   He says I was...
[02:06:31.160 --> 02:06:33.520]   I would be able to start it today, would Odeo succeed?
[02:06:33.520 --> 02:06:42.640]   Yeah, he said he was frustrated at the pivot away from podcasting towards Twitter.
[02:06:42.640 --> 02:06:46.160]   He also was at Twitter and he knows a lot about Blue Sky and of course, is creating his
[02:06:46.160 --> 02:06:50.160]   own protocol, which we now know is called Scuttle Butte.
[02:06:50.160 --> 02:06:53.360]   Rabble joins us next week.
[02:06:53.360 --> 02:06:59.120]   We do this week in Google every Wednesday, 2 p.m. Pacific, 5 p.m. Eastern, 2100 UTC.
[02:06:59.120 --> 02:07:05.940]   You can watch us to alive@live.twit.tv or join us in the chatroom at IRC.twit.tv.
[02:07:05.940 --> 02:07:10.680]   Our club members who pay seven bucks a month to get ad-free versions of all the shows also
[02:07:10.680 --> 02:07:11.800]   have their own chatroom.
[02:07:11.800 --> 02:07:14.040]   It's our wonderful club, Twit Discord.
[02:07:14.040 --> 02:07:17.000]   It's going to be the home to Stacey's book club next week.
[02:07:17.000 --> 02:07:19.320]   And of course, lots of other great stuff.
[02:07:19.320 --> 02:07:24.480]   If you're not yet a club member, I invite you to join a Twit.tv/club.
[02:07:24.480 --> 02:07:30.640]   You can also get the hands-on, windows hands-on Mac, untitled Linux show, the Gizfiz, all
[02:07:30.640 --> 02:07:35.440]   the other shows that we don't release outside the club.
[02:07:35.440 --> 02:07:37.760]   Twit.tv/club.
[02:07:37.760 --> 02:07:42.680]   So the fact you get to add supportive versions of this show on our website, Twit.tv/twig.
[02:07:42.680 --> 02:07:43.680]   You can watch on YouTube.
[02:07:43.680 --> 02:07:45.640]   There's a dedicated YouTube channel.
[02:07:45.640 --> 02:07:46.640]   And of course, you can subscribe.
[02:07:46.640 --> 02:07:49.800]   In fact, I would recommend subscribing in your favorite podcast.
[02:07:49.800 --> 02:07:50.800]   A client.
[02:07:50.800 --> 02:07:52.960]   And if you do that, please leave us a five-star review.
[02:07:52.960 --> 02:07:58.400]   Let the world know about this week in Google, which is ever so rarely actually about Google.
[02:07:58.400 --> 02:08:01.120]   We'll see you next time.
[02:08:01.120 --> 02:08:02.120]   Have a great week.
[02:08:02.120 --> 02:08:03.680]   Bye-bye.
[02:08:03.680 --> 02:08:08.760]   If you are looking for a midweek update on the week's tech news, I got to tell you, you've
[02:08:08.760 --> 02:08:10.480]   got to check out Tech News Weekly.
[02:08:10.480 --> 02:08:12.880]   See, it's all kind of built in there with the title.
[02:08:12.880 --> 02:08:16.840]   You get to learn about the news in tech that matters.
[02:08:16.840 --> 02:08:21.480]   Every Thursday, Jason Howell and I talk to the people making and breaking the tech news,
[02:08:21.480 --> 02:08:24.440]   get their insights and their interesting stories.
[02:08:24.440 --> 02:08:29.180]   It's a great show to check out, Twit.tv/twig.
[02:08:29.180 --> 02:08:39.180]   [MUSIC]

