;FFMETADATA1
title=Illegal Use of Whipped Cream
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2023-05-11
track=715
language=English
genre=Podcast
comment=<p>Google IO, Pixel Fold, AI Search</p>\

encoded_by=Uniblab 5.3
date=2023
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.040]   It's time for Twig this week at Google and there's a lot of Google this week. Stacey Hagan-Botham's here, Ant-Pruit, Jeff Jarvis
[00:00:06.040 --> 00:00:10.100]   We'll talk about all the things Google talked about at Google I/O and
[00:00:10.100 --> 00:00:16.400]   whether Google I/O's keynote was a success or failure plus a little bit of other news
[00:00:16.400 --> 00:00:20.500]   But really it's a it's a Google week this week on this week in Google. Stay tuned
[00:00:20.500 --> 00:00:25.760]   Podcasts you love from people you trust
[00:00:25.760 --> 00:00:28.920]   This is Twig
[00:00:28.920 --> 00:00:40.940]   This week in Google episode 715 recorded Wednesday, May 10th, 2023
[00:00:40.940 --> 00:00:44.640]   illegal use of whipped cream
[00:00:44.640 --> 00:00:48.880]   This week in Google is brought to you by Melissa
[00:00:48.880 --> 00:00:57.620]   More than 10,000 clients worldwide rely on Melissa for full-spectrum data quality and ID verification software
[00:00:57.840 --> 00:01:04.240]   Make sure your customer contact data is up to date get started today with 1,000 records clean for free at
[00:01:04.240 --> 00:01:06.920]   Melissa.com/twit
[00:01:06.920 --> 00:01:12.600]   And by Twit thank you for listening as an ad supported network
[00:01:12.600 --> 00:01:17.120]   We're always looking for new partners with products and services that will benefit our audience
[00:01:17.120 --> 00:01:24.840]   99% of our audience listens to most or all of our shows grow your brand with authentic ad reads that always
[00:01:25.120 --> 00:01:31.080]   resonate with our audience reach out to advertise at twit.tv and launch your campaign now
[00:01:31.080 --> 00:01:38.460]   It's time for twig this week in Google and today of all days
[00:01:38.460 --> 00:01:41.960]   What what makes today a special day of the year?
[00:01:41.960 --> 00:01:48.160]   Boys and girls will talk about that with Jeff Jarvis who's been here since early morning hours it seems
[00:01:48.160 --> 00:01:53.360]   Was machine.com. He's tired of me. He's bored with bees fed up with me already. I love you
[00:01:53.360 --> 00:01:59.600]   Are you kidding? Jeff is the Leonard town professor for journalistic innovation at the Craig Newmark
[00:01:59.600 --> 00:02:07.760]   Graduate School of pigeons at the City University of New York author of the Gutenberg parenthesis
[00:02:07.760 --> 00:02:11.760]   Available for you. What are now at Gutenberg parenthesis.com
[00:02:11.760 --> 00:02:14.520]   Thank you
[00:02:14.520 --> 00:02:22.640]   Also hear from hands-on photography twit.tv/hop a man who is desperate for questions for tomorrow's ask me anything
[00:02:22.640 --> 00:02:28.200]   Alex Wilhelm will come up with some for you and get your pencil. I'm sure I'm sure you will
[00:02:28.200 --> 00:02:33.120]   You know what it's like living in Leo's childhood home
[00:02:33.120 --> 00:02:36.440]   He does you know did you know that?
[00:02:36.440 --> 00:02:41.200]   Yes, I did. All right. Just what don't I mentioned the address because we don't want to dox them. No
[00:02:41.200 --> 00:02:48.320]   Do that so we're to it weird coincidence, but he's also a great financial reporter rights for tech crunch
[00:02:48.880 --> 00:02:54.520]   There's lots if you just asked get him started on you know what's going on with the economy
[00:02:54.520 --> 00:02:58.640]   And I think you got two or three of us right there will be there two hours right at the gate
[00:02:58.640 --> 00:03:04.000]   Exactamente that's for club to it members tomorrow. What is it 9 a.m. Again?
[00:03:04.000 --> 00:03:10.560]   9 a.m. Pacific time crazy man only in our club twit discord. Yep. Gotta be there quit
[00:03:10.560 --> 00:03:13.040]   Discord be there or be square
[00:03:14.880 --> 00:03:19.040]   Also with a stacey Higginbotham who was prepared to begin much later today
[00:03:19.040 --> 00:03:24.600]   Thank you for your patience. Stacy Stacy. Yana. Just stock up on the waffles. Stacy. Oh
[00:03:24.600 --> 00:03:27.840]   I don't want waffles right now. I just
[00:03:27.840 --> 00:03:35.040]   Does her and have a temperature are you okay? I'm gonna be sad and pathetic and I'm gonna sniff a lot
[00:03:35.040 --> 00:03:38.040]   She got a duck like this. I'm sorry cold to the worst
[00:03:39.040 --> 00:03:46.240]   No, no don't like them. They're not the one answer. Yeah, there's much worse. You're right. What am I saying?
[00:03:46.240 --> 00:03:52.160]   They're just you know, they're they're annoying. They're just mildly irritating. Yeah, they're annoying. Yeah, no
[00:03:52.160 --> 00:03:57.240]   No, what have I done to this show everybody on this show thinks I hate you? I
[00:03:57.240 --> 00:04:02.840]   Don't I don't you're not none of you. You're all wonderful
[00:04:02.840 --> 00:04:07.080]   We are what gets me is everybody's is like oh boy
[00:04:07.080 --> 00:04:11.880]   It's gonna be a late show and then miss Stacy is gonna get tired and need our waffles
[00:04:11.880 --> 00:04:18.180]   But everybody is totally looking over the fact that you've been there at the studio just as early as myself and mr
[00:04:18.180 --> 00:04:22.360]   Jammer be oh, yeah, you're here. You're here. Did punchy. I do
[00:04:22.360 --> 00:04:25.400]   I am already punchier
[00:04:25.400 --> 00:04:31.480]   You're right. Did you notice that? Yeah, I'm punchy. Yeah, what are you talking about?
[00:04:31.480 --> 00:04:36.400]   Actually, you know, Jeff and I watched the Google event because Google I always this morning
[00:04:37.040 --> 00:04:39.040]   We watched the Google event
[00:04:39.040 --> 00:04:42.040]   And at the time I'm thinking
[00:04:42.040 --> 00:04:46.960]   Googles really lost their mojo. I mean, I thought that the last few Google I/Os
[00:04:46.960 --> 00:04:51.880]   But it just seemed disjointed they spent an hour and 20 minutes
[00:04:51.880 --> 00:05:00.120]   Basically saying nothing about a that was their AI. Wait, no, no, they they said AI a lot
[00:05:04.120 --> 00:05:08.320]   Really appreciated how they were like, you know what people think we suck at AI
[00:05:08.320 --> 00:05:12.560]   We're gonna just show them all the ways that it has been a part of our product and
[00:05:12.560 --> 00:05:16.160]   We're gonna apply to start you know what some of it was good
[00:05:16.160 --> 00:05:20.560]   And I actually thought of Jeff when I saw duets for work. Was it duets? Yeah for workspace
[00:05:20.560 --> 00:05:24.560]   I decided by some of it. He thought of it too. He was saying I bet I don't even get that
[00:05:24.560 --> 00:05:31.280]   Yeah, well, well, this was what I was gonna finish the thought which is at the time
[00:05:31.280 --> 00:05:33.760]   It really felt like a disjoint. It was kind of disjointed
[00:05:33.760 --> 00:05:39.480]   It was disproportionately devoted to a lot of hand waving like no, no, we got a high we got no
[00:05:39.480 --> 00:05:44.680]   No, we got it. We got it. We're not good. Give it to you yet, but we got it. We've had it for a long time
[00:05:44.680 --> 00:05:49.560]   Now we're in 20 minutes of that then there was it felt like an hour
[00:05:49.560 --> 00:05:51.880]   But it was really only eight or nine minutes on wallpaper
[00:05:59.600 --> 00:06:05.680]   You know, they're trying to show all the new features of the next Android, but it's like we're there's nothing new in any phone
[00:06:05.680 --> 00:06:12.760]   Almost everything they showed was catching up with look you touched the pole the poop emoji and it moves. Oh god
[00:06:12.760 --> 00:06:14.440]   It was just terrible
[00:06:14.440 --> 00:06:18.000]   And then they finally in the last half hour showed new products
[00:06:18.000 --> 00:06:23.200]   Actually some interesting new products. They showed the the new tablet. They finally released it
[00:06:23.200 --> 00:06:25.880]   It's available today for pre-order ships next month
[00:06:25.880 --> 00:06:32.200]   And it's the one that has the dock that I thought was pretty cool when they showed that included months ago and the docks included in the
[00:06:32.200 --> 00:06:36.560]   499 price for 128 gigs of RAM. It's a real tablet
[00:06:36.560 --> 00:06:42.120]   That ends up there you're disappointing. Oh, you're you disappointed the price when we get there?
[00:06:42.120 --> 00:06:46.440]   No, not the price. I'm disappointed with the tablet. Oh, we can talk about that. Oh, we'll get there
[00:06:46.440 --> 00:06:48.040]   We'll get there. We'll get there. We'll get there
[00:06:48.040 --> 00:06:51.720]   They also showed the folding phone and that's you know
[00:06:52.240 --> 00:06:57.640]   $800 bucks, but we're gonna throw in a watch because we couldn't sell those anyway and here have one of the pixel watches
[00:06:57.640 --> 00:07:01.120]   And then and then we're over bye-bye
[00:07:01.120 --> 00:07:07.920]   It was so I felt like this didn't this wasn't great, but then what coming here live. Yes, there's a but
[00:07:07.920 --> 00:07:16.640]   Because then I'm sitting in Windows weekly and there's press release after press release after press release and there's a ton of good stuff
[00:07:16.640 --> 00:07:22.200]   Really? Yeah, and I and actually this more underscore
[00:07:22.440 --> 00:07:28.600]   My feeling that they just did not know how to deliver a decent keynote. They like yeah need to get this thing in hand
[00:07:28.600 --> 00:07:33.560]   Because in fact, there's some very oh, I forgot to mention also the 7a they which you know
[00:07:33.560 --> 00:07:35.560]   I mean nothing they announced we didn't know about
[00:07:35.560 --> 00:07:37.720]   but
[00:07:37.720 --> 00:07:41.040]   Yeah, I you know actually like it's better than I thought
[00:07:41.040 --> 00:07:49.320]   It seemed like the keynote was more about trying to appease the shareholders and the board by just saying AI
[00:07:49.320 --> 00:07:51.800]   50 times an hour
[00:07:51.800 --> 00:07:55.760]   Just just so this shareholder's know well Google's working on AI
[00:07:55.760 --> 00:08:00.800]   So my money's probably gonna be okay. That's that's what it sounded like to me nothing that
[00:08:00.800 --> 00:08:08.720]   Us quote normal folks would really care about well in the developers conference Stacy if you were developer
[00:08:08.720 --> 00:08:10.920]   Would you be disappointed?
[00:08:10.920 --> 00:08:13.000]   That you spent an hour 20 minutes
[00:08:13.000 --> 00:08:17.560]   Oh, yeah, if I was the developer, I mean because it really didn't feel like it
[00:08:17.560 --> 00:08:22.080]   It's not I mean Google cloud is a developer conference. I always just they're like
[00:08:22.080 --> 00:08:26.400]   Roll. I mean they wanted to be like the keynote for WWDC
[00:08:26.400 --> 00:08:31.920]   Yeah, right right yeah, my Christmas build is coming up apples
[00:08:31.920 --> 00:08:34.680]   WWC's command those are developer conferences
[00:08:34.680 --> 00:08:41.680]   Google feels like they lost their mojo. I really a million times that was that was Apple
[00:08:41.680 --> 00:08:45.880]   Yeah, yeah, that was a couple of three years ago. This is this is their equivalent with AI AI
[00:08:47.080 --> 00:08:49.080]   I'm G. Yeah
[00:08:49.080 --> 00:08:52.880]   All right, well, let's okay. So Stacy some of the things you saw were
[00:08:52.880 --> 00:08:56.400]   Pretty cool and the key I'll start with the keynote
[00:08:56.400 --> 00:09:00.120]   So the keynote I thought was I guess
[00:09:00.120 --> 00:09:05.720]   Probably because I was doing other things while I was watching it. I actually thought it was pretty
[00:09:05.720 --> 00:09:10.320]   I wish I had been I should have brought across. Yeah, like you make a problem
[00:09:10.320 --> 00:09:14.960]   It was good. No, I was I was writing up my podcast post and editing some stuff
[00:09:14.960 --> 00:09:20.200]   I mean, I was just working, you know just had it on kind of some dar talking about whatever but like
[00:09:20.200 --> 00:09:25.520]   You know, I thought I thought it was important for them to emphasize that they've been doing AI for a while
[00:09:25.520 --> 00:09:29.200]   And they did a good job. I thought of that. I know we don't care about that, but it's important
[00:09:29.200 --> 00:09:36.000]   I liked the the fact that you could pull your photos. I thought of you and like being able to generate
[00:09:36.000 --> 00:09:38.000]   auto generate
[00:09:38.000 --> 00:09:39.840]   additional tools
[00:09:39.840 --> 00:09:42.760]   Yeah, I thought that was like really nice. That was a really good
[00:09:42.760 --> 00:09:45.960]   Let me see if I can find it. There's showed a picture of a kid with some balloons
[00:09:45.960 --> 00:09:50.720]   Except as shot the balloons are off, you know, partly off camera and the kids not centered
[00:09:50.720 --> 00:09:56.840]   Which by the way happens all the time is what you want. It's the time, but you also
[00:09:56.840 --> 00:10:00.120]   Nobody wants I mean
[00:10:00.120 --> 00:10:03.920]   Artistically, you don't want to put that doesn't matter in the middle of the picture anyway
[00:10:03.920 --> 00:10:11.480]   He wasn't in the middle in the school part so they stretch they stretch they move the kid over and the bench and the balloons
[00:10:12.000 --> 00:10:17.040]   Are auto generated stretched out that it fills it in that was pretty cool
[00:10:17.040 --> 00:10:21.560]   Yeah, they cut and and I thought it was really cool. They were like you can change the sky
[00:10:21.560 --> 00:10:26.440]   And the lighting effect will change and I'm I want to see this in real life
[00:10:26.440 --> 00:10:33.480]   I want to get ants opinion on it once we've got it in our hands, but like that's the kind of practical stuff people love
[00:10:33.480 --> 00:10:36.160]   I don't know how they're gonna charge for it
[00:10:36.160 --> 00:10:42.160]   And I actually thought it was super compelling how they were pulling all of these integrations
[00:10:42.160 --> 00:10:44.800]   That's a yeah
[00:10:44.800 --> 00:10:50.800]   New theme song. Yeah, I'm like, yes, so I have to go back. I have to point out
[00:10:50.800 --> 00:10:53.000]   that
[00:10:53.000 --> 00:10:56.400]   This is not this is plenty of apps on Android that'll do this
[00:10:56.400 --> 00:11:03.800]   Yes, right am I wrong now is native though, but now it's native and presumably it'll be better
[00:11:03.800 --> 00:11:06.280]   You don't have to sit through ads or pay for it
[00:11:06.280 --> 00:11:09.840]   But the other thing is the confusion will put in any sky you want
[00:11:09.840 --> 00:11:16.000]   I prefer not to do that because it becomes pretty obvious that you faked the sky, but okay. I guess in a snapshot
[00:11:16.000 --> 00:11:23.480]   That's what Google saying it'll make it less obvious that you're fake in the sky and also my grandma is not gonna be right
[00:11:23.480 --> 00:11:26.440]   Yeah
[00:11:26.440 --> 00:11:33.000]   But the integrations with other Google stuff was really compelling and I actually I've been playing with Bard
[00:11:33.200 --> 00:11:35.200]   Maybe I've just not
[00:11:35.200 --> 00:11:38.560]   Like being able to export stuff into Google sheets was
[00:11:38.560 --> 00:11:43.840]   The side kick stuff was amazing. I
[00:11:43.840 --> 00:11:51.000]   Really want to play with that. I can't wait. I'm like like and I loved how they emphasized I
[00:11:51.000 --> 00:11:54.120]   Understand why they did this but it as a
[00:11:54.120 --> 00:11:58.440]   Like a Kickstarter they called it what do they call it a jump start?
[00:11:58.440 --> 00:12:03.040]   They use the word jump start so many times the idea being that it jump starts are kick starts your
[00:12:03.400 --> 00:12:10.320]   Creativity well they showed us how which I think is important what I interpret that as is please don't use this for your content
[00:12:10.320 --> 00:12:11.200]   I
[00:12:11.200 --> 00:12:13.520]   Know I know why they did it
[00:12:13.520 --> 00:12:20.480]   But I also think it's important that you see people like showing you how to to make this additive right like
[00:12:20.480 --> 00:12:23.320]   Especially for people who aren't gonna like if you're a school teacher
[00:12:23.320 --> 00:12:29.120]   Dude, you're not gonna be playing with this in your spare time necessarily you're tired right? But if you can
[00:12:29.760 --> 00:12:36.360]   If something like this comes along and it's like here. Let me help you show your students how to use this in a more responsible way
[00:12:36.360 --> 00:12:41.120]   That's really important. Here's a syndrome. Pichai demonstrating this new
[00:12:41.120 --> 00:12:43.760]   technique
[00:12:43.760 --> 00:12:50.640]   Parent you always want your kid at the center of it all and it looks like the balloons got cut off in this one
[00:12:50.640 --> 00:12:53.240]   So you can go ahead and reposition the birthday boy
[00:12:53.240 --> 00:12:56.240]   magic editor
[00:12:56.240 --> 00:12:59.440]   Automatically recreates parts of the bench and balloons
[00:12:59.440 --> 00:13:03.140]   fake news in that while now I
[00:13:03.140 --> 00:13:10.920]   Know and you're gonna pixel peep this and you're gonna say well actually right now the color is off just a touch
[00:13:10.920 --> 00:13:13.320]   Yeah, it can be fixed over time in the bench
[00:13:13.320 --> 00:13:19.680]   Smeared and but you know grandma ain't gonna notice grandma's gonna go one. No, that's cute
[00:13:19.680 --> 00:13:25.600]   I think they did a fine job with that for something to do it right there on the phone for
[00:13:26.000 --> 00:13:33.320]   Anybody to be able to do it not shit not just people that are used to opening up content aware field inside of Photoshop and I have to say
[00:13:33.320 --> 00:13:35.960]   credit to them for
[00:13:35.960 --> 00:13:41.080]   Doing sewing something that people really would want and use as opposed to you know
[00:13:41.080 --> 00:13:47.360]   Just some you know look how I can take your table setting and put it in a spreadsheet or whatever it was they were doing or
[00:13:47.360 --> 00:13:52.800]   Or talking about classes and inheritance and well, it's a developer conference
[00:13:52.800 --> 00:13:55.520]   Developers like that kind of thing
[00:13:55.880 --> 00:13:59.240]   You know I think we owe you and I just got a couple of the bed it appears
[00:13:59.240 --> 00:14:05.380]   No, cuz look at this present to present her who couldn't bought managed to stand up so they
[00:14:05.380 --> 00:14:14.200]   Her arms cuz she was so tired that she had a lean on the
[00:14:14.200 --> 00:14:17.080]   When you brought that up
[00:14:17.080 --> 00:14:21.880]   Maybe she has other issues now maybe okay fine. You're right
[00:14:21.880 --> 00:14:23.880]   He was the one with issues here
[00:14:23.880 --> 00:14:34.480]   You have floppy hands maybe she has floppy elbows she could be like
[00:14:34.480 --> 00:14:39.320]   Like having you know long COVID who knows yeah
[00:14:39.320 --> 00:14:42.960]   I've been in TV long enough to know that a director
[00:14:42.960 --> 00:14:50.520]   She did it without the box and the director's going crazy because the phones moving around and the camera can't hold and they could get her an apple box
[00:14:50.520 --> 00:14:52.940]   And put her elbows on it and so they have a solid
[00:14:52.940 --> 00:14:58.880]   She was in fact several presenters and this was the other thing and I have to give them some
[00:14:58.880 --> 00:15:06.100]   Slack for remember this is the first one where they're really coming back from COVID after three years of like
[00:15:06.100 --> 00:15:12.720]   We're gonna present this at a coffee table in our living room and everybody and everybody's gonna be in their bare feet
[00:15:12.720 --> 00:15:16.160]   Which they literally did with one of their pixel announcements
[00:15:17.320 --> 00:15:23.960]   So at least two of them said oh it's tough being in front of this such a big crowd like they haven't been in public in a while
[00:15:23.960 --> 00:15:28.360]   So okay, I'll cut him some slack in Google
[00:15:28.360 --> 00:15:32.640]   I mean I know if you're gonna be an executive you do have to have presentation skills
[00:15:32.640 --> 00:15:39.320]   But like Google sometimes pulls up some really deep deep cuts on the executive team and you know
[00:15:39.320 --> 00:15:43.520]   They're also pretty anyway. I like I'm gonna give people a slack
[00:15:43.520 --> 00:15:47.480]   This is all positive she's a nice person and she's you know in a way
[00:15:47.480 --> 00:15:52.360]   I want to agree with you because see after I saw the press releases Google had a lot to talk about
[00:15:52.360 --> 00:15:56.600]   I think the only complaint I have is that the present that the keynote as a whole
[00:15:56.600 --> 00:16:03.280]   Wasn't very well thought for instance one of the demos they not polished it wasn't very polished one of the demos
[00:16:03.280 --> 00:16:09.120]   You're saying to Leo is it didn't have a strategic thread that went through it mostly. It's that I can forgive polish
[00:16:09.120 --> 00:16:11.680]   There's a lot of unpolished keynotes. That's normal
[00:16:12.080 --> 00:16:17.600]   You know apples raised the bar, but most companies are you know, but I wanted to see
[00:16:17.600 --> 00:16:20.680]   This and this is where I think a failure of leadership
[00:16:20.680 --> 00:16:24.200]   There should be a vision in a through thread through the whole thing
[00:16:24.200 --> 00:16:29.440]   This is who we are and and what you said you stand for responsible AI exactly span
[00:16:29.440 --> 00:16:34.040]   We will do it right. You can trust us something like that. That was the message
[00:16:34.040 --> 00:16:39.800]   They were trying to get but I don't think they came but they didn't come through. Oh, I thought they did some I
[00:16:41.040 --> 00:16:44.000]   Thought the ideas that they had were pretty strong
[00:16:44.000 --> 00:16:48.960]   They uttered like if I had been there and you know, you could interrupt a keynote ask a question
[00:16:48.960 --> 00:16:49.880]   I would have been like I'm sorry
[00:16:49.880 --> 00:16:56.600]   How are you gonna ask other people to showcase their meditator or make sure they put their fake watermarking in there?
[00:16:56.600 --> 00:17:01.280]   They talked about detecting fake watermarking. I would have loved to see that demo
[00:17:01.280 --> 00:17:06.600]   The they have a lot of things where I feel like I really felt like Google's like oh crap
[00:17:07.120 --> 00:17:13.000]   Say I stuff. I know we're not doing evil anymore or we're not we're okay with evil
[00:17:13.000 --> 00:17:18.280]   But we probably want to do this like I really thought that that came through in a way, but
[00:17:18.280 --> 00:17:21.280]   also it underscored how
[00:17:21.280 --> 00:17:28.320]   How little they can do without any sort of big overarching federal legislation or like
[00:17:28.320 --> 00:17:35.520]   How are they having this industry? I've heard this tune before from Google year after year
[00:17:35.520 --> 00:17:40.880]   They show stuff and they sing their praises and never release it or release it many years later
[00:17:40.880 --> 00:17:43.880]   watered down, I mean
[00:17:43.880 --> 00:17:50.960]   I'm not they didn't convince me now there was one thing and I will say this was really the strong suit
[00:17:50.960 --> 00:17:55.160]   They did bring out somebody they've appointed as the senior vice president
[00:17:55.160 --> 00:17:58.360]   Who reports directly to Sundar Pichai?
[00:17:58.360 --> 00:18:00.920]   Essentially for AI
[00:18:00.920 --> 00:18:02.920]   responsibility and ethics yeah
[00:18:03.480 --> 00:18:06.200]   Good sake, yeah, James Van Yika and he is
[00:18:06.200 --> 00:18:11.760]   Real heavy. He's been he's worked in the Obama administration worked for the UN
[00:18:11.760 --> 00:18:14.320]   He's a was a partner at McKinsey
[00:18:14.320 --> 00:18:20.840]   I mean he is a real heavyweight and presumably has the ear of Pichai and is brought in really to
[00:18:20.840 --> 00:18:26.320]   Think about the impacts on society of AI so his presentation was pretty good
[00:18:26.320 --> 00:18:30.960]   I thought that was kind of what we stay on that for one second sure I think I think it is really important
[00:18:30.960 --> 00:18:37.280]   I think that could have been the thread that went through yes and what he presented was stuff that this information people
[00:18:37.280 --> 00:18:38.720]   I asked for myself
[00:18:38.720 --> 00:18:44.520]   I've been at Google News guys and every year we say a session that I started what should Google do because he's got it
[00:18:44.520 --> 00:18:46.520]   It's a plug for my book and
[00:18:46.520 --> 00:18:51.560]   Every year I say give us the provenance of images
[00:18:51.560 --> 00:18:57.720]   Let us know the first time you saw this image so we can know whether it's really new really old where it came from and so on
[00:18:57.720 --> 00:19:02.400]   Let me show you that and let me show you the clip because this is exactly what he was talking about
[00:19:02.400 --> 00:19:08.440]   Do you have his audio you'll be able to see important information such as
[00:19:08.440 --> 00:19:11.840]   When and where similar image let me jump back so we get the idea
[00:19:11.840 --> 00:19:17.360]   Oh now I've lost it shoot I
[00:19:17.360 --> 00:19:24.520]   Apologize here we go one area that is top of mind for us is misinformation
[00:19:25.640 --> 00:19:30.040]   Generative a on makes it easier than ever to create new content
[00:19:30.040 --> 00:19:35.000]   But it also raises additional questions about his trustworthiness
[00:19:35.000 --> 00:19:41.080]   That's why we're developing and providing people with tools to evaluate online information
[00:19:41.080 --> 00:19:43.320]   for example
[00:19:43.320 --> 00:19:52.000]   Have you come across a photo on a website or one shared by a friend with very little context like this one of the moon landing
[00:19:52.000 --> 00:19:57.600]   So this is of the staged moon landing they've got the lunar lander and they've got a master
[00:19:57.600 --> 00:20:04.960]   But then they have you know enough fake lunar landscape and a bunch of directors and producers and camera people who are faking it right and
[00:20:04.960 --> 00:20:07.080]   fund yourself wondering is
[00:20:07.080 --> 00:20:09.160]   This reliable I
[00:20:09.160 --> 00:20:11.760]   Have and I'm sure many of you have as well
[00:20:11.760 --> 00:20:17.920]   In the coming months. We're adding two new ways for people to evaluate images
[00:20:18.720 --> 00:20:26.480]   First without about this image tool in Google search you'll be able to see important information such as
[00:20:26.480 --> 00:20:30.160]   When and where similar images may have first appeared?
[00:20:30.160 --> 00:20:39.280]   Where else the image has been seen online including news fact checking and social sites and what you learn of course is that that image is a mid journey
[00:20:39.280 --> 00:20:41.520]   AI generated image
[00:20:41.520 --> 00:20:48.200]   And and there's enough you know background material to show that now here's a drawback
[00:20:48.200 --> 00:20:54.400]   You had to do a Google image search to find that out right well, but but there's a few things one is it also shows
[00:20:54.400 --> 00:20:58.280]   You when you ask about an image using lens they're gonna use it
[00:20:58.280 --> 00:21:02.880]   I can tell you this thing was generated by and so on so forth. So they're gonna add it to let's yeah
[00:21:02.880 --> 00:21:07.320]   It's it's first let me it's it's for I
[00:21:07.320 --> 00:21:10.880]   Think at one level. It's not for everybody
[00:21:10.880 --> 00:21:16.160]   It's for researchers and journalists to be able to say to fact check and say this is where this came from
[00:21:16.160 --> 00:21:21.480]   We know we have a new tool yeah, but it can be for everybody to and I argue that we're all gonna have more
[00:21:21.480 --> 00:21:24.000]   Responsibility for figuring out what's true and what's false out there?
[00:21:24.000 --> 00:21:29.840]   And this is another tool to do that the other part of this too is that they also talked about he also talked about
[00:21:29.840 --> 00:21:34.800]   Watermarking images and I presume it's a point text too
[00:21:34.800 --> 00:21:39.960]   So we can have more sense of the provenance of where this stuff comes from is everybody screaming about oh my god
[00:21:39.960 --> 00:21:45.440]   There's gonna be all this information manufactured by the machine. Yes, there will be but this was a moment of great
[00:21:45.760 --> 00:21:50.920]   responsibility that Google was finally responding to what information this information researchers have wanted and
[00:21:50.920 --> 00:21:57.640]   The underlying messages we're gonna try to do AI right we're gonna try to do it responsibly
[00:21:57.640 --> 00:22:03.160]   What do we succeed? But this is how we're trying to do it. I think that was just by far the best part of it
[00:22:03.160 --> 00:22:08.360]   Sorry Stacy. No, that's right and they actually even when they like talked about bar doing code
[00:22:08.360 --> 00:22:12.360]   They actually if you do code if you have it generate code for you
[00:22:12.360 --> 00:22:16.880]   it's like it actually annotates the code and says hey this was generated by
[00:22:16.880 --> 00:22:20.200]   I don't know if I bard but whatever and
[00:22:20.200 --> 00:22:25.360]   Again, you can strip that out, but those are the kind of things that
[00:22:25.360 --> 00:22:30.840]   We need to be looking for and yes, it'd be great if the whole industry does it
[00:22:30.840 --> 00:22:34.720]   But it's also kind of cool like you know how we people associate Apple with privacy
[00:22:34.720 --> 00:22:40.360]   Google might have a chance to come in here and we search Google to make sure our information is accurate and that's
[00:22:40.800 --> 00:22:42.800]   They could be like snopes
[00:22:42.800 --> 00:22:46.080]   Again, I wouldn't that be wonderful wouldn't that be amazing?
[00:22:46.080 --> 00:22:52.720]   Yeah, you know the other thing too is that is that they're finally talking about about AI and search and I've been arguing that
[00:22:52.720 --> 00:22:58.040]   Microsoft is doing this terribly irresponsibly and Google by trying to chase Microsoft is being irresponsible
[00:22:58.040 --> 00:23:01.760]   Word assembly machines are not good at facts
[00:23:01.760 --> 00:23:06.800]   But the way that Google showed AI and search and I want to play with it a lot more and learn a lot more about it
[00:23:06.880 --> 00:23:10.280]   But it was rather than saying it didn't say here's a paragraph
[00:23:10.280 --> 00:23:15.160]   But then it showed here's where we got the information each of those paragraphs and it and was more
[00:23:15.160 --> 00:23:21.760]   Interitive and saying okay, you search for this now. You probably want this then you're gonna want a list of that and that's a clever
[00:23:21.760 --> 00:23:26.600]   Or use of AI then simply let me regurgitate words back to you
[00:23:26.600 --> 00:23:30.880]   If you again, they didn't present it very well. Yeah, if you're interested
[00:23:30.880 --> 00:23:33.960]   Yeah, it was very disjointed and you know, we have to work
[00:23:34.600 --> 00:23:42.880]   Boil it down to find those nuggets in the drawers. There's a lot of draws this by the way if you want to try all of these things
[00:23:42.880 --> 00:23:46.320]   There many of them are gonna be in the labs g.co
[00:23:46.320 --> 00:23:51.440]   Slash labs and the dress center got wrong by the way g.co
[00:23:51.440 --> 00:23:58.960]   Labs and then you can you'll have to have the appropriate app on your phone and all of that
[00:23:58.960 --> 00:24:02.760]   But some of this stuff you can use right away including it was pretty funny
[00:24:02.880 --> 00:24:06.200]   This project tailwind which they even admitted yeah
[00:24:06.200 --> 00:24:10.360]   We got a bunch of guys together and they put this they cobbled this together in five days
[00:24:10.360 --> 00:24:14.680]   It's like you weren't you knew that the Iokino was coming right
[00:24:14.680 --> 00:24:20.780]   But five days ago. They got some guys leadership five days or five people I couldn't there was five days
[00:24:20.780 --> 00:24:29.000]   That's Google that's part of that like I don't know let's get some engineers. Let's see what happens
[00:24:30.200 --> 00:24:34.840]   That's exactly what I'm saying. Why is that acceptable? That's my problem
[00:24:34.840 --> 00:24:37.480]   because
[00:24:37.480 --> 00:24:39.480]   They're trying they're
[00:24:39.480 --> 00:24:47.720]   Google is an engineering they don't have team right Google's known like Apple is the polished like they would Apple would Apple would never
[00:24:47.720 --> 00:24:53.320]   Oh god. Yeah, they haven't announced anything yet, right? Yeah, that's really true. You're really true
[00:24:53.320 --> 00:24:58.940]   Engineering buddies. We're just gonna see what happened well, and that's how they sold it forever like look
[00:24:58.940 --> 00:25:02.140]   How amazing these tools are we were able to get this together in five days
[00:25:02.140 --> 00:25:08.940]   Actually, this was one of the things that Jeff and I both thought oh, that's actually pretty cool project tailwind will take
[00:25:08.940 --> 00:25:13.960]   One of the things they said is look the AI is better if it's in a you know a kind of a limited
[00:25:13.960 --> 00:25:16.700]   Knowledge area
[00:25:16.700 --> 00:25:20.620]   So is an example project tailwind takes your Google Docs
[00:25:20.620 --> 00:25:27.980]   like Jeff's notes for all of his books and then assembles them into a notebook where you can ask questions of
[00:25:28.420 --> 00:25:32.880]   Your own research and that kind of does make sense. I guess
[00:25:32.880 --> 00:25:38.680]   It's kind it's taking off on a very popular idea called Zettlkosten in fact
[00:25:38.680 --> 00:25:45.060]   You'll notice if you look at the project tailwind animated gift you can do on your research a reading quiz
[00:25:45.060 --> 00:25:53.600]   Which means they expect students to use this right to to take notes and then and then test their knowledge on the notes for the final and
[00:25:54.020 --> 00:26:00.220]   New ideas now. This is the one I have some questions about one of the reasons you'll do Zettlkosten or some sort of note-taking
[00:26:00.220 --> 00:26:06.780]   Methodology is because when you have all these disparate notes and you start making connections you get new ideas
[00:26:06.780 --> 00:26:13.100]   But if you let the machine do it for you a it ain't gonna be a very interesting new idea and be you're not doing it
[00:26:13.100 --> 00:26:20.020]   So I don't know how valuable that's gonna be but Jeff you think you thought this would be kind of cool for your notes
[00:26:20.020 --> 00:26:25.180]   Say on the on the Gutenberg book. Yeah, yeah, and I think well, I've already written that book about the internet book
[00:26:25.180 --> 00:26:28.980]   I desperately need I got pick I got files and files and files and files. Yeah, that's a challenge
[00:26:28.980 --> 00:26:31.660]   You do all these interviews and all this research. I'd eat tie it all into a
[00:26:31.660 --> 00:26:38.940]   So I think that there's a lot there to play with that's really interesting and
[00:26:38.940 --> 00:26:44.580]   What I also liked about it is that it's concentrating on limited sets of data
[00:26:44.580 --> 00:26:49.500]   that rather than and this is what to met goo brew gebrew and
[00:26:49.900 --> 00:26:53.860]   Margaret Mitchell and company in the stochastic parents paper said
[00:26:53.860 --> 00:27:00.980]   Margaret Mitchell's been very big on that and Emily the vendor has been very big on this saying stop boys with trying to get
[00:27:00.980 --> 00:27:03.380]   Size matters when it comes to your learning set
[00:27:03.380 --> 00:27:09.300]   It's it's it's unproductive. It's harder to monitor. It doesn't really work
[00:27:09.300 --> 00:27:16.580]   What you've got to go for is limited sets of data that the system can learn on and be reliable and learning on it
[00:27:16.580 --> 00:27:22.020]   And you know where it came from then you can monitor it and audit it and you can verify things
[00:27:22.020 --> 00:27:25.860]   And that's a much better way to go so when you get down to the tiniest of the tiny
[00:27:25.860 --> 00:27:32.180]   And it's going on just the data in your phone or just the data in your Google Docs or just the data in your company
[00:27:32.180 --> 00:27:37.720]   That becomes a much more interesting use of the capabilities of
[00:27:37.720 --> 00:27:39.900]   LLM's
[00:27:39.900 --> 00:27:44.980]   To me and this we have all the knowledge of the world and it's gonna destroy humanity. Yes
[00:27:45.900 --> 00:27:47.900]   Yeah as a journalist
[00:27:47.900 --> 00:27:49.580]   like I
[00:27:49.580 --> 00:27:52.060]   Love like Project Hellman to me is like
[00:27:52.060 --> 00:27:55.700]   It is basically a better Google brain
[00:27:55.700 --> 00:28:01.340]   I always joke that I would search my articles and like my brain is either in my inbox or my brain is in my
[00:28:01.340 --> 00:28:05.740]   It's in my I call it the morgue, but it's not really a morgue because it's an online thing
[00:28:05.740 --> 00:28:08.420]   It's not a place where my old clips are but
[00:28:10.020 --> 00:28:16.020]   Having being able to put all of my notes. I would feel weird about just because some of it's under embargo or secret like that
[00:28:16.020 --> 00:28:18.020]   That gets a little dicey
[00:28:18.020 --> 00:28:24.220]   But if it's a new machine if you knew it stayed on my machine, but it's connected to the internet so
[00:28:24.220 --> 00:28:30.900]   You're still nervous. I mean, I don't really get it. I got security stories, but you know, that's a legitimate concern
[00:28:30.900 --> 00:28:32.900]   And that's one of the things they kind of tried to address
[00:28:32.900 --> 00:28:38.820]   Early on is privacy, but again, I think they could have made them more coherent
[00:28:39.820 --> 00:28:43.940]   Statement of their commitment to keeping your data private on device
[00:28:43.940 --> 00:28:47.540]   Making it safe for somebody like you to use
[00:28:47.540 --> 00:28:50.820]   But we can't just be able to say like oh
[00:28:50.820 --> 00:28:57.560]   How did I define peering? How did I do this or right? Can you to have something sum up here's my questions?
[00:28:57.560 --> 00:28:59.900]   Can you trust it?
[00:28:59.900 --> 00:29:05.980]   If it's only on my data. Yeah, because I've written that and fact checked it already and you could fact you could check your own
[00:29:05.980 --> 00:29:07.980]   Did it again you can look it up?
[00:29:08.220 --> 00:29:13.340]   So I love that idea. It would be yeah, cuz I get it half of my job
[00:29:13.340 --> 00:29:21.860]   When I'm writing something new especially about the news is just summarizing the stuff like these six years of everything that has happened before
[00:29:21.860 --> 00:29:24.620]   so
[00:29:24.620 --> 00:29:27.980]   That's kind of me. You know again
[00:29:27.980 --> 00:29:33.020]   As always with Google I/O I look at this stuff some of this stuff you could do right now
[00:29:33.260 --> 00:29:38.560]   Some of the stuff you can do later some of the stuff you may never be able to do and it's not always clear. What's what?
[00:29:38.560 --> 00:29:44.140]   So it's it so I always think of everything we see as a demo and and maybe
[00:29:44.140 --> 00:29:47.660]   It's a good idea, but you won't really know till you try it
[00:29:47.660 --> 00:29:55.700]   Maybe maybe you'll get some insights. Maybe you won't though. I mean maybe I mean the problem with a it's just confidently wrong
[00:29:55.700 --> 00:29:58.380]   It's so confident
[00:29:58.380 --> 00:30:01.300]   Just I don't know if it's gonna be that useful
[00:30:03.100 --> 00:30:09.060]   Well, it's trained on your data then I mean it kind of depends on what you're asking
[00:30:09.060 --> 00:30:14.900]   Yes, it's a better. It's a better. It's not a large language model. It's a Stacy language model
[00:30:14.900 --> 00:30:18.060]   Yeah, and I trust Stacy language, right?
[00:30:18.060 --> 00:30:25.540]   Here's Sundar talking about some of the features in Gmail this they say is real. Let's get started
[00:30:25.540 --> 00:30:30.380]   Seven years into our journey as an AI first company
[00:30:30.740 --> 00:30:34.240]   We are an exciting note by the way see we've been doing this for seven years
[00:30:34.240 --> 00:30:36.240]   We've been out of you know
[00:30:36.240 --> 00:30:47.100]   Opportunity to make AI even more helpful. It's true people for businesses for communities for everyone
[00:30:47.100 --> 00:30:53.480]   We've been applying AI to make our products radically more helpful for a lot because I thought that was a very
[00:30:53.480 --> 00:31:00.280]   AI kind of interesting with the bold all our core products including search
[00:31:00.280 --> 00:31:03.320]   You will hear more later in the keynote
[00:31:03.320 --> 00:31:10.600]   Let me start with few examples of how generative AI is helping to evolve our products
[00:31:10.600 --> 00:31:13.200]   starting with Gmail
[00:31:13.200 --> 00:31:22.040]   In 2017 we launched smart reply. Do you use smart reply Stacy? I do yeah, I've used I don't
[00:31:22.680 --> 00:31:25.960]   mean sometimes if they're appropriate yeah, I use them
[00:31:25.960 --> 00:31:31.660]   Like me they're more useful in texting to me than they are in in mail
[00:31:31.660 --> 00:31:34.000]   But I use them on Apple messages
[00:31:34.000 --> 00:31:39.240]   Yes on the phone and on my watch sometimes I'll get a message and it suggests because I'm not gonna do a lot of typing
[00:31:39.240 --> 00:31:41.680]   I watch but it'll suggest right and I'll use that
[00:31:41.680 --> 00:31:48.080]   Sometimes it makes me sound a little robotic. It's either as polite or as nor as firm as Mr. Pruitt
[00:31:48.080 --> 00:31:52.160]   So this is a step exactly. This is a step farther watch this watch this
[00:31:52.440 --> 00:31:55.760]   Short responses you could select with just one click
[00:31:55.760 --> 00:31:58.720]   Next came smart compose
[00:31:58.720 --> 00:32:02.080]   Which offered writing suggestions as you type?
[00:32:02.080 --> 00:32:07.880]   Smart compose led to more advanced right this all exist by AI. I always hate
[00:32:07.880 --> 00:32:13.200]   I was hate when it's proposed in the way that I was going to run 180 billion times in the past year alone
[00:32:13.200 --> 00:32:20.400]   And now with a much more powerful generative model. We are taking the next step in Gmail with help me write
[00:32:21.640 --> 00:32:25.360]   Let's say you got this email interesting that your flight was canceled
[00:32:25.360 --> 00:32:30.480]   The airline has sent a voucher, but what you really want is a full refund
[00:32:30.480 --> 00:32:33.320]   You can use help me write
[00:32:33.320 --> 00:32:36.400]   Just type in the prompt of what you want and
[00:32:36.400 --> 00:32:44.640]   For this cancel for this cancel create and a full draft appears okay, but this is the first you can see it
[00:32:44.640 --> 00:32:49.040]   conveniently pulled in flight details from the previous email and
[00:32:49.480 --> 00:32:52.120]   It looks pretty close to what you want to send
[00:32:52.120 --> 00:32:55.000]   I understand you're offering a voucher as a gesture of goodwill
[00:32:55.000 --> 00:33:00.280]   But I'd be prefer to be reimbursed for the cost of my ticket. I appreciate your understanding
[00:33:00.280 --> 00:33:02.280]   Maybe you wanted to find it further
[00:33:02.280 --> 00:33:07.920]   In this case a more elaborate email might increase the chances of getting the refund
[00:33:07.920 --> 00:33:17.480]   However, I am very disappointed with the way my recent flight was handled
[00:33:17.600 --> 00:33:22.000]   This caused me a great deal of inconvenience. I believe a full refund is the only fair way
[00:33:22.000 --> 00:33:27.880]   It's this is good at writing an angry letter, right until until the airline gets a hundred of these yeah
[00:33:27.880 --> 00:33:31.760]   Well, but they won't all be the same. That's one thing at least
[00:33:31.760 --> 00:33:35.920]   Generative AI is good at is not repeating itself so much, right?
[00:33:35.920 --> 00:33:39.600]   Maybe maybe maybe if you sent out a thousand
[00:33:39.600 --> 00:33:43.520]   Did only cover story you cancel that many flights you might end up
[00:33:44.080 --> 00:33:48.640]   You would end up with that with people anyway, yeah, it's pretty believable. Go ahead, Jeff
[00:33:48.640 --> 00:33:53.880]   I filed a free information request some years ago with the federal communications Commission because they they
[00:33:53.880 --> 00:33:57.480]   imposed what was then the largest fine in their history to Fox
[00:33:57.480 --> 00:34:02.120]   entertainment for illegal use of whipped cream. I'll spare you the details and
[00:34:02.120 --> 00:34:11.240]   Thousands what's an illegal use of whipped cream? I was somehow sexual whipped cream in prime time and it was gonna corrupt America
[00:34:11.400 --> 00:34:14.200]   Okay, so supposedly there were thousands of responses
[00:34:14.200 --> 00:34:20.360]   This is why the FCC had to act and had to do the most the biggest fine ever in history until Howard Stern later and
[00:34:20.360 --> 00:34:28.120]   I got all of the other responses all of them and it turned out that all but two were were from the same
[00:34:28.120 --> 00:34:37.080]   Was the parents don't have a pencil. Yeah, right. Yeah, so that meant that only three Americans had taken the time to actually write a letter
[00:34:37.600 --> 00:34:43.480]   Complaining, but it didn't matter because thousands of the FCC used it. Yeah. Yeah, yeah
[00:34:43.480 --> 00:34:51.000]   The FCC now puts those when you make the comment. They're online and you could I mean you can actually see yeah, it's because of me
[00:34:51.000 --> 00:34:54.660]   Oh, yeah, neutrality. You're like yeah boom
[00:34:54.660 --> 00:35:00.920]   And by the way, we now have a show title and the illegal use of whipped cream. So thank you for that
[00:35:00.920 --> 00:35:04.480]   You're welcome. You know, I always love it
[00:35:04.640 --> 00:35:08.640]   When what I what comes out of my mouth my accident ends up at the show night
[00:35:08.640 --> 00:35:13.440]   I don't know that just makes me very happy feels like a little bit of posterity there. No
[00:35:13.440 --> 00:35:19.880]   All right, let's go on with Cinderella. So he's written a really nasty note
[00:35:19.880 --> 00:35:23.220]   The next example is mass
[00:35:23.220 --> 00:35:26.440]   since the early days of Street View
[00:35:26.440 --> 00:35:31.480]   We've actually seen what was really cool
[00:35:32.240 --> 00:35:35.520]   Yeah, I don't care about that you can stop that. Yeah, what was really cool?
[00:35:35.520 --> 00:35:41.080]   When they were talking about like listing colleges and then this was part of the kind of export to other Google things
[00:35:41.080 --> 00:35:44.440]   Where they're like show me on a map because what I'm like, oh shoot
[00:35:44.440 --> 00:35:48.280]   I need the following like as long as his colleges are real
[00:35:48.280 --> 00:35:51.840]   Okay, Leo I get that you think
[00:35:51.840 --> 00:36:00.840]   Okay, this again is the jumpstart
[00:36:00.840 --> 00:36:03.520]   That's why they emphasized the jumpstart
[00:36:03.520 --> 00:36:09.760]   That's all this is and you know what you have to do this and it's a much easier way to if I could spend
[00:36:09.760 --> 00:36:17.240]   10% of my time on the early phase of any research project as opposed to spending a quarter of my time and then validating
[00:36:17.240 --> 00:36:19.440]   Why wouldn't I do that? Okay
[00:36:19.440 --> 00:36:29.080]   Validation's always a step. I'm not an expert in this. So it's maybe you have to release it to the public and let them bang on it
[00:36:29.920 --> 00:36:37.080]   But maybe you could also write something that instead of having absolutely no care for the for the
[00:36:37.080 --> 00:36:39.720]   Factuality of what it's writing
[00:36:39.720 --> 00:36:45.960]   Also had a step of saying let's make sure this is real and we're not making up stuff and
[00:36:45.960 --> 00:36:54.360]   Neither Microsoft nor Google with bard seems to have yet figured out a way to say this should be factual
[00:36:54.360 --> 00:36:57.840]   And I think that that's gonna be problematic about
[00:36:58.520 --> 00:37:03.760]   So he taught Sundar Pichai talked about training the models initially on
[00:37:03.760 --> 00:37:09.160]   Mathematical and physics data to give it a basis in like logic in facts
[00:37:09.160 --> 00:37:12.440]   You can't when you when you train something
[00:37:12.440 --> 00:37:22.760]   From the internet you're gonna get wacky things just like I was taught by a crazy seventh grade teacher and I have in my head a whole
[00:37:22.760 --> 00:37:24.760]   years worth of
[00:37:25.240 --> 00:37:27.240]   Weird
[00:37:27.240 --> 00:37:30.080]   From this all seven the grade good point
[00:37:30.080 --> 00:37:36.480]   Good point. I mean you're you're gonna encounter wrong information in your search
[00:37:36.480 --> 00:37:39.320]   Well fine
[00:37:39.320 --> 00:37:45.960]   Then that's my question again. I'm not an expert in this but is that necessary or yes, nothing is authoritative
[00:37:45.960 --> 00:37:50.360]   No
[00:37:50.360 --> 00:37:52.360]   Well from now
[00:37:52.360 --> 00:37:54.360]   Does not make mistakes
[00:37:54.360 --> 00:37:56.360]   Well from alpha is a math engine
[00:37:56.360 --> 00:37:57.880]   Okay
[00:37:57.880 --> 00:38:03.000]   Math is like which as Sundar said they're starting with math there there ever something there
[00:38:03.000 --> 00:38:11.160]   I got a point out either chat GPT or Mard does math correctly so they're not even doing this you know base
[00:38:11.160 --> 00:38:13.080]   of this yeah
[00:38:13.080 --> 00:38:17.000]   Yeah, but there so maybe they should have or function well
[00:38:17.000 --> 00:38:21.840]   I know the core function has nothing to do with accuracy. However, maybe it should
[00:38:22.600 --> 00:38:29.760]   Especially if you're gonna give people information about what colleges are out there with these courses if you've paid no attention to the
[00:38:29.760 --> 00:38:34.040]   Actual veracity of the material it seems like that's a bad
[00:38:34.040 --> 00:38:39.800]   Ideas if that's the case that's why you're like saying we got a bill
[00:38:39.800 --> 00:38:43.720]   We got a build uh, you know, we got to build cars that
[00:38:43.720 --> 00:38:46.640]   Emmett poison his gas first
[00:38:47.360 --> 00:38:52.920]   To see if it kills people and then we can put out cars that aren't well. No, there's no one's doing that
[00:38:52.920 --> 00:38:57.580]   So what they're like as a journalist. You're sort of a journalist. So we'll use this I
[00:38:57.580 --> 00:39:01.760]   Have a I have a story. I'm gonna come up with something
[00:39:01.760 --> 00:39:05.880]   I'm gonna start with the simple Google search before I talk to any experts
[00:39:05.880 --> 00:39:09.320]   I'm just gonna try to wrap my head around what I'm trying to figure out
[00:39:09.320 --> 00:39:11.880]   So let's say it's 6g to be like, okay 6g
[00:39:11.880 --> 00:39:13.360]   What is it? Let it look like okay?
[00:39:13.360 --> 00:39:17.120]   And I'm gonna go through my searches and some of them are gonna look authoritative and some of them aren't
[00:39:17.360 --> 00:39:23.240]   And then I'm gonna call people who know and then I'm gonna report something that's factual to me
[00:39:23.240 --> 00:39:28.880]   What they're doing with like the college search or any of this jumpstart stuff is simply
[00:39:28.880 --> 00:39:35.480]   The same thing I would do anyway on Google. It's just a little bit better and it's gonna be better organized for my
[00:39:35.480 --> 00:39:38.040]   consumption, right?
[00:39:38.040 --> 00:39:40.560]   point was
[00:39:40.560 --> 00:39:43.320]   Because it's coming out of the mouth of this computer
[00:39:43.760 --> 00:39:48.800]   People give it more import and trust it and say it's accurate and that's very
[00:39:48.800 --> 00:39:55.200]   Just making the point they made across I know but we have to do that across all
[00:39:55.200 --> 00:39:57.320]   Not just in information
[00:39:57.320 --> 00:40:03.320]   We have to do that in terms of like our politics when we talk about things being data-driven. That's stupid
[00:40:03.320 --> 00:40:10.760]   We still have like data. It's the same thing. We're always learning as people which is data can lie experts can lie
[00:40:10.760 --> 00:40:12.760]   We have to validate for ourselves
[00:40:12.760 --> 00:40:15.400]   And Leo to your point about the car
[00:40:15.400 --> 00:40:22.840]   Yeah, you're gonna start driving cars before you realize the impact of parking lots and pollution and all that and in essence
[00:40:22.840 --> 00:40:27.300]   We sped up and so the other two announcements today that were that were critical here
[00:40:27.300 --> 00:40:29.960]   is that
[00:40:29.960 --> 00:40:40.640]   Chat GPT open AI says they're building a system to understand how their system operates, right? Because it kind of got away from them and
[00:40:42.040 --> 00:40:48.920]   Anthropic is building the Constitution for their AI and they're doing that and I think that that's
[00:40:48.920 --> 00:40:54.680]   Important that they are trying to reverse engineer back in
[00:40:54.680 --> 00:41:00.000]   Sense and ethics and things is it too late should they stop for six months? No, that's ridiculous
[00:41:00.000 --> 00:41:05.040]   But is there a chance to learn as you go? Yeah, I think so
[00:41:05.040 --> 00:41:11.160]   I just saw a fascinating paper that came across from a Kurt Gray a UNC professor
[00:41:11.160 --> 00:41:13.160]   Just just on Twitter
[00:41:13.160 --> 00:41:18.080]   That that looked at the moral judgments. They got out of chat GPT
[00:41:18.080 --> 00:41:25.800]   3.5 and they put all kinds of questions to them versus there's data on what people judged of these things and it was
[00:41:25.800 --> 00:41:32.480]   95% the same which is to say the chat GPT spits back what we think and
[00:41:32.480 --> 00:41:36.640]   So obviously we got to blame ourselves a lot. I
[00:41:38.040 --> 00:41:43.520]   Mean, you know, I guess I like Wikipedia a lot and there's plenty of
[00:41:43.520 --> 00:41:46.160]   Contrefactual stuff in Wikipedia
[00:41:46.160 --> 00:41:48.680]   It just seems much
[00:41:48.680 --> 00:41:51.160]   enough that
[00:41:51.160 --> 00:41:53.520]   Enough that if I if you
[00:41:53.520 --> 00:42:00.640]   Wrote it without checking you you might quote miss you. Yeah, that's risky. Yeah, but you should never quote
[00:42:00.640 --> 00:42:06.740]   But you shouldn't I mean yeah, any one thing that but there is a difference. I think when you're doing search results versus
[00:42:06.740 --> 00:42:16.020]   You know, right. I mean don't we trust search results? No, God with the spamming and the manipulation of search results
[00:42:16.020 --> 00:42:19.100]   Please no, and there's also the larger concern that these
[00:42:19.100 --> 00:42:27.100]   Engines these tools make it possible to create massive amounts of misinformation very rapidly. So
[00:42:27.100 --> 00:42:30.260]   We've kind of weaponized misinformation
[00:42:31.260 --> 00:42:39.060]   In the same way that we weaponized social media and now we're gonna have 10x 100x the amount of misinformation
[00:42:39.060 --> 00:42:48.460]   You know, it's it's manageable when it's Wikipedia and you can check how manageable is it if if all of a sudden the stuff is spewing forth everywhere?
[00:42:48.460 --> 00:42:49.540]   I
[00:42:49.540 --> 00:42:51.540]   Think this was a reasonable concern that
[00:42:51.540 --> 00:42:58.460]   Tim Nick is a reasonable concern, but to push back and make that your if that is your primary concern
[00:42:59.780 --> 00:43:05.420]   We need to say okay. Well, how do we deal with this? I just just throwing out the baby with the bow
[00:43:05.420 --> 00:43:08.740]   Oh, no, I'm saying that I've had what I'm saying is no
[00:43:08.740 --> 00:43:11.620]   No, what I'm so there are people saying oh, yeah
[00:43:11.620 --> 00:43:19.340]   I gotta stop this because it's gonna be sky net and take over the world and that's completely missing the point the real danger of this is not that
[00:43:19.340 --> 00:43:23.900]   the real danger of this is it's just gonna flood the zone with crap and
[00:43:25.180 --> 00:43:31.860]   I think it's not inappropriate for companies like Microsoft and Google and open AI and throw up again the rest to
[00:43:31.860 --> 00:43:39.020]   To kind of think about that consider that and maybe instead of just pushing out something that is so bad at
[00:43:39.020 --> 00:43:43.300]   Creating factual material. They should maybe have
[00:43:43.300 --> 00:43:49.900]   Gone the extra step to make it more reliable. I don't how hard is that to do? Maybe it's this is where I don't know
[00:43:49.900 --> 00:43:54.060]   Maybe it's not possible. Maybe you can't in which case I can't look at the open a me
[00:43:54.060 --> 00:43:56.860]   I mean the opening I story and
[00:43:56.860 --> 00:44:03.740]   You got Sam saying how incredibly difficult it is what they're looking at literally is neurons
[00:44:03.740 --> 00:44:09.940]   They're saying when the word dollar is recommended. It looks at what other things flash up in one connection
[00:44:09.940 --> 00:44:14.460]   It doesn't know context. It doesn't know what it is. So they don't even know how that operates
[00:44:14.460 --> 00:44:16.700]   They're they're learning things about how their own machine
[00:44:16.700 --> 00:44:19.660]   I would slow down a little bit then I
[00:44:19.660 --> 00:44:22.580]   Mean you want to stop for six months you
[00:44:23.580 --> 00:44:28.740]   Know I don't like the six-month hold but I wish these companies had been a little bit more and I you know
[00:44:28.740 --> 00:44:31.140]   I thought Google was gonna be a little bit more circumspect
[00:44:31.140 --> 00:44:38.180]   Maybe we're saying that they are being circumspect there's I think they're being circumspect around things that make sense
[00:44:38.180 --> 00:44:42.260]   Which is annotation being able to watermark what they can do
[00:44:42.260 --> 00:44:47.060]   I think that they should be also making advocating for like a big federal push for this or no no no
[00:44:47.060 --> 00:44:48.940]   I don't want the feds to come in in fact
[00:44:48.940 --> 00:44:54.220]   That's that's the argument for them doing it themselves because if they don't then then there's the risk
[00:44:54.220 --> 00:44:59.780]   The feds are gonna come in and they're gonna missandle it there is definitely rules like I think there's rules for auditing
[00:44:59.780 --> 00:45:04.940]   I think there's rules for making sure because they're always gonna be crappy people in companies and
[00:45:04.940 --> 00:45:10.780]   Government organizations who don't have budget to throw people out of the loop on important AI-bade decisions
[00:45:10.780 --> 00:45:14.140]   And that's gonna cause a lot of problems. Do you think having a AI?
[00:45:15.100 --> 00:45:19.020]   Search will be better than having just plain old Google page rank based search
[00:45:19.020 --> 00:45:23.900]   So I am really intrigued by this is a person who's running a media company
[00:45:23.900 --> 00:45:30.260]   Kevin and I were talking about SEO and what this means because it kind of changes the nature of the content that I would produce for some
[00:45:30.260 --> 00:45:35.060]   Search terms like we got a lot of search terms because we wrote very early on about shuddy
[00:45:35.060 --> 00:45:39.740]   With mesh routers you've got five gigahertz Wi-Fi and 2.4 gigahertz Wi-Fi
[00:45:39.740 --> 00:45:45.140]   But a lot of smart home devices only have 2.4. So if you've got a mesh system
[00:45:45.140 --> 00:45:47.580]   Sometimes it's like your device freaks out
[00:45:47.580 --> 00:45:52.860]   So we got it we wrote an article explaining that and then talk about how to avoid that in some routers
[00:45:52.860 --> 00:45:55.540]   And that's like one of our most search for things
[00:45:55.540 --> 00:46:01.140]   there would be a benefit for us to actually keep that more up to date because
[00:46:01.140 --> 00:46:03.540]   We're gonna
[00:46:03.540 --> 00:46:05.540]   Over time it's become you know
[00:46:06.020 --> 00:46:09.700]   There are routers that are no longer relevant right? It was like your real fives
[00:46:09.700 --> 00:46:15.700]   And so there's a benefit for us to if we want to have authority to keep our content
[00:46:15.700 --> 00:46:21.140]   Continuously fresh on hot topics and to add more keywords over time
[00:46:21.140 --> 00:46:25.660]   That you know, we're not doing today. I don't know if we're ever gonna do that
[00:46:25.660 --> 00:46:30.540]   But it's something to think about and AI others better for that than Google's
[00:46:31.340 --> 00:46:38.140]   Page rank. Yeah, I mean if you're searching for if you search for that today in Google like why doesn't mice
[00:46:38.140 --> 00:46:43.740]   You know, whatever my 2.4 gigahertz IOT device not connect. I don't know if my article come up there or not
[00:46:43.740 --> 00:46:49.260]   But you know, you get a lot of like stupid you get my site might come up
[00:46:49.260 --> 00:46:54.620]   And I feel like it's authoritative and it's not scammy with ads or you get like wiki how
[00:46:55.460 --> 00:47:02.500]   You obviously a lot of wiki how out there that earth's sort of well and look what's seen it was doing generating in fact
[00:47:02.500 --> 00:47:08.140]   Red ventures with all of their properties like bank rate is doing they're generating link bait
[00:47:08.140 --> 00:47:11.900]   Because with a I was today to do it really quickly and cheaply
[00:47:11.900 --> 00:47:19.100]   12% credit study 12% of all ads online are going to AI manufactured made for advertising sites
[00:47:19.100 --> 00:47:25.220]   So we're already there even before chatting people really takes off. There's a lot of stuff. That's just purely generated
[00:47:25.460 --> 00:47:27.460]   We'll multiply that by 10
[00:47:27.460 --> 00:47:33.780]   Well, and that's what you know what bothered me the most about today's presentation was the PowerPoint stuff the sheets stuff is
[00:47:33.780 --> 00:47:36.300]   that
[00:47:36.300 --> 00:47:42.420]   You know PowerPoint already ruined human thinking enough and turned it into simple stupid little thoughts
[00:47:42.420 --> 00:47:49.740]   Right and now the machine is gonna make the PowerPoint and all the illustrations on it and the talking notes on it
[00:47:49.740 --> 00:47:52.060]   And so nothing's real right right?
[00:47:52.060 --> 00:47:57.180]   Right in my name Matthew Kirschenbaum from the University of Maryland wrote a piece for the Atlantic a few weeks ago about the text
[00:47:57.180 --> 00:48:02.540]   Pocalypse what you're saying is there's gonna be so much text text becomes absolutely meaningless and
[00:48:02.540 --> 00:48:05.420]   devalued and I think it's true
[00:48:05.420 --> 00:48:09.820]   Let's watch real briefly. Let's watch yeah, the Google sheets
[00:48:09.820 --> 00:48:14.780]   Most popular use cases is the trusty job description
[00:48:14.780 --> 00:48:20.140]   Every business bigger small weight cuz those sheets are slides a good
[00:48:20.700 --> 00:48:22.700]   Yeah, make all the difference
[00:48:22.700 --> 00:48:25.260]   Here's how Docs has been helping
[00:48:25.260 --> 00:48:32.300]   Say you run a fashion boutique and need to hire a textile designer. Oh this is not started. I mean let me let me
[00:48:32.300 --> 00:48:35.460]   Yeah, this is sheets not slides. Let me find the there is the slides
[00:48:35.460 --> 00:48:41.980]   It's the cheese on do you have a cheat the pizza cheese on do pizza that was horrible? Yeah, I don't know
[00:48:41.980 --> 00:48:45.380]   I was like why am I not tipping my pizza in cheese? Thanks AI
[00:48:47.180 --> 00:48:52.340]   She's I said on the show today. There'll be there'll be tick-tocks with recipes by tonight
[00:48:52.340 --> 00:48:58.300]   Is it
[00:48:58.300 --> 00:49:04.420]   This is the mystery a mermaid cove. I don't want to do that. I'm not that again. Yeah, I'm sorry
[00:49:04.420 --> 00:49:09.700]   I hope you've held your thoughts Stacy because why don't you go ahead and I will try to find this okay?
[00:49:09.700 --> 00:49:12.900]   So I'm gonna counter like as someone who writes speeches I
[00:49:12.900 --> 00:49:15.460]   actually thought this was super helpful because
[00:49:16.020 --> 00:49:20.340]   When I'm preparing I hate preparing slides, I would rather just get up and talk to people
[00:49:20.340 --> 00:49:26.260]   But everyone wants some sort of slide. I love the fact that my slides are super usually really text-heavy
[00:49:26.260 --> 00:49:28.900]   They act almost as my notes like oh, this is the bullet point
[00:49:28.900 --> 00:49:31.220]   I want to make it then I keep going so I
[00:49:31.220 --> 00:49:37.220]   Love the fact that I could actually come up with better illustrations for things that are pretty esoteric
[00:49:37.220 --> 00:49:41.700]   So that's cool for me and I never make speaker notes
[00:49:42.340 --> 00:49:48.100]   So it's kind of like it was auto generating speaker notes. That was kind of cool. Yeah, I was like
[00:49:48.100 --> 00:49:54.780]   I am very excited to be here. Yeah, well though. I don't so I don't read I
[00:49:54.780 --> 00:49:59.220]   Mean my speaking style is very like hey everybody
[00:49:59.220 --> 00:50:04.140]   What's up? And then I'm kind of but I am glad to get my slides to make sure that I'm staying on target right point
[00:50:04.140 --> 00:50:06.540]   but I and I
[00:50:06.540 --> 00:50:10.260]   Like slides they help me think I am not a very like
[00:50:12.100 --> 00:50:19.380]   It helps me organize my thinking in ways that make it accessible to people like not everybody's gonna sit down and read like
[00:50:19.380 --> 00:50:25.780]   Maintain right but you might read a PowerPoint of his points and feel like god. That's depressing
[00:50:25.780 --> 00:50:35.500]   I think the core features that people are striving for like when they they talk about things like that I
[00:50:35.500 --> 00:50:38.060]   Think I don't want to have to read anything
[00:50:38.060 --> 00:50:42.460]   Just give me the highlights so I can sound so don't be an elitist people
[00:50:42.460 --> 00:50:49.780]   It for themselves and they can get there and they don't have to read that and spend that to get there
[00:50:49.780 --> 00:50:55.540]   Yeah, I mean spend no time thinking. That's the last thing you want to do. They are thinking
[00:50:55.540 --> 00:50:59.060]   They're just thinking in bullet points. Yes
[00:50:59.060 --> 00:51:02.300]   They're thinking for conversation
[00:51:06.140 --> 00:51:11.980]   It's beautiful, but it's also a lot. There's a lot. It's a lot of montane
[00:51:11.980 --> 00:51:18.380]   I haven't read your valuable. Yeah, here's the here's the here's how you're want to use your
[00:51:18.380 --> 00:51:21.020]   Google sheets in the future
[00:51:21.020 --> 00:51:23.500]   in a slide deck
[00:51:23.500 --> 00:51:28.060]   Everyone does their bit happy 50th anniversary have more pizzazz
[00:51:28.060 --> 00:51:34.980]   Let's pick one of the slides and he was the poem on there as a prompt for image generation
[00:51:34.980 --> 00:51:42.140]   Mom loves your pizza mom loves her pizza cheesy and true while dad's favorite treat is a warm part of fondue
[00:51:42.140 --> 00:51:45.860]   Let's hit create and see what it comes up with a better poem
[00:51:45.860 --> 00:51:49.940]   I hope behind the scenes that quote is sent as an input to our text image models
[00:51:49.940 --> 00:51:53.180]   And we know it's unlikely that the user will be happy with just one option
[00:51:53.180 --> 00:51:58.540]   So we generate about six to eight images so that you have the ability to choose and refine
[00:51:58.540 --> 00:52:00.940]   Most of them are pizza
[00:52:00.940 --> 00:52:02.940]   Fun news
[00:52:02.940 --> 00:52:10.300]   Now this style is a little too cartoony for me, so I'm gonna ask it to try again
[00:52:10.300 --> 00:52:15.460]   Let's change the style to photography and give it a whirl
[00:52:15.460 --> 00:52:18.980]   It's more than a whirl
[00:52:18.980 --> 00:52:26.220]   So I don't know what they're applauding it's lukewarm, but it is pictures of pizza
[00:52:26.860 --> 00:52:32.980]   Being dipped into fondue meanwhile the discord Stacy. I have pizza dipped in fondue
[00:52:32.980 --> 00:52:38.620]   In the disc one tick tock from tick tock either discord I put it to the discord there's a
[00:52:38.620 --> 00:52:46.420]   Cheese you found you found it action cuz you said this is gonna be a tick tock
[00:52:46.420 --> 00:52:49.220]   Did I put it the wrong one this way Google?
[00:52:49.220 --> 00:52:53.820]   I don't know where you put it. No you put it in tweet news put it in quick news cuz I was over the septune
[00:52:53.820 --> 00:52:58.060]   Okay, so now and this week here it is this we got it now we got to watch this and then I'm gonna take a break
[00:52:58.060 --> 00:53:03.540]   Because you got it. You got a marley not here. We go pizza. That doesn't work. You gotta go to the lake
[00:53:03.540 --> 00:53:06.860]   Because of yeah
[00:53:06.860 --> 00:53:08.980]   No, not okay. That's all right
[00:53:08.980 --> 00:53:15.740]   You can jump forward a little bit or a lot
[00:53:17.820 --> 00:53:23.660]   If it plays we'll take a break cuz I'm I'm really not that I try I try to add
[00:53:23.660 --> 00:53:26.700]   Try
[00:53:26.700 --> 00:53:29.500]   It's pretty disgusting when you get when you actually don't take tock fail
[00:53:29.500 --> 00:53:37.180]   What a surprise let's take a break and we got a lot more still to come about what Google is talking about
[00:53:37.180 --> 00:53:39.420]   And you know what I have to say Stacy you're right I
[00:53:39.420 --> 00:53:42.260]   This is all gonna be
[00:53:42.260 --> 00:53:44.260]   useful. I'm sure I
[00:53:44.260 --> 00:53:46.620]   just I feel like
[00:53:46.620 --> 00:53:52.540]   We're rushing headlong into this and I'm just I feel like we did this before with Twitter and
[00:53:52.540 --> 00:53:59.380]   Facebook and and a lot of stuff and we did and we are and we always will that's what we're doing
[00:53:59.380 --> 00:54:05.540]   Yeah, that's what capitalism is what I'm arguing for I don't know some thought I guess you're right
[00:54:05.540 --> 00:54:06.060]   It's not gonna
[00:54:06.060 --> 00:54:11.260]   And we are thinking I mean but you also the best way to
[00:54:11.740 --> 00:54:20.020]   Like to think fully about something is to experience it now should we apply it and I'm sure I wouldn't have any of these I would not have any of these
[00:54:20.020 --> 00:54:22.820]   cavails if I hadn't
[00:54:22.820 --> 00:54:30.660]   Yeah, and yeah, and the other thing is it's iterative. It's not like a physical piece of hardware that we're buying
[00:54:30.660 --> 00:54:37.500]   It's not like it's now this should not be part of like infrastructure yet, but I don't think it's going to be
[00:54:37.500 --> 00:54:40.740]   Yeah, like well, that's not true. I think some people will try
[00:54:40.860 --> 00:54:46.180]   Like those PE firms buy hospitals. They're probably like oh Met Tom
[00:54:46.180 --> 00:54:51.140]   I need to hire that today. Yeah Google what oh, yeah, have we tested that who cares?
[00:54:51.140 --> 00:54:58.940]   Excuse me. Can we can we talk about one of our sponsors and then get back to the conversation Stacey?
[00:54:58.940 --> 00:55:05.420]   I go bought them Stacey on IOT.com and the IOT podcast with Kevin Tofill now with Linkbait
[00:55:09.620 --> 00:55:13.300]   So me oh it's to me. I'm sorry Jeff Jarvis
[00:55:13.300 --> 00:55:21.180]   Professor at large buzz machine.com catches new book the Gutenberg parenthesis at a bookstore near you
[00:55:21.180 --> 00:55:24.700]   soon and
[00:55:24.700 --> 00:55:32.020]   From high on song photography our club twit community manager to mr. Emperor twit.tv/hop
[00:55:32.020 --> 00:55:37.540]   Great to have all three of you. I will try to be less cranky. I'm gonna be less cranky
[00:55:37.820 --> 00:55:43.860]   I'm pretty much more positive. I don't believe it. I don't believe it. You're as you're as credible as chat GPT
[00:55:43.860 --> 00:55:54.500]   Your heart our episode they brought to you by Melissa the address
[00:55:54.500 --> 00:55:59.900]   experts address verification that's hot right now, right because well you may have
[00:55:59.900 --> 00:56:05.380]   Regulatory compliance issues that you have to you know, you know your customer rules things like that
[00:56:05.980 --> 00:56:08.580]   It's also important for business success
[00:56:08.580 --> 00:56:14.660]   What can accurate addresses do to help your business with about 63% of shopping journeys?
[00:56:14.660 --> 00:56:17.020]   Begin online
[00:56:17.020 --> 00:56:20.180]   63% 20% of shipping addresses
[00:56:20.180 --> 00:56:27.180]   Oh contains spelling mistakes incorrect postal codes or house numbers formatting errors
[00:56:27.180 --> 00:56:35.620]   That means all those nice shopping journeys begun online may end up in tears having solutions like an address auto complete service
[00:56:35.620 --> 00:56:40.980]   Can ensure new and returning customers always get their packages on time and in the right place?
[00:56:40.980 --> 00:56:45.580]   And on a complete service helps lower cart abandonment always a problem
[00:56:45.580 --> 00:56:51.260]   I'm not shopping sites because it speeds up the buying process for the customer you've experienced that on nice sites
[00:56:51.260 --> 00:56:54.420]   You start entering your house number and it says oh you mean this yes
[00:56:54.420 --> 00:57:00.380]   The average large-sized ease commerce site can gain a 35% increase in conversion rates
[00:57:00.380 --> 00:57:03.180]   just by improving checkout design and
[00:57:03.700 --> 00:57:10.020]   We know you know when your customer service reps are entering data or your customers are any data
[00:57:10.020 --> 00:57:18.140]   They're gonna there's gonna be typos. There's gonna be mistakes having that auto fill just you know gets the correct address in first time every time
[00:57:18.140 --> 00:57:23.300]   At the core of quick accurate delivery reliable clean data
[00:57:23.300 --> 00:57:33.220]   It's important to your customers 41% of consumers say fast delivery is the most critical aspect of their online shopping experience
[00:57:33.220 --> 00:57:35.900]   I tell you I I ordered a product
[00:57:35.900 --> 00:57:40.860]   I wanted a walking stick to get before our trip and it didn't get to me
[00:57:40.860 --> 00:57:41.820]   I don't know where it ended up
[00:57:41.820 --> 00:57:48.260]   It wasn't mine and you know yeah, I got a refund for it so that they merchant lost the sale
[00:57:48.260 --> 00:57:52.900]   But also I was unhappy because I didn't get the thing I wanted before my trip
[00:57:52.900 --> 00:57:57.200]   Not just fast but accurate delivery and guess what?
[00:57:57.200 --> 00:58:01.420]   56% of shoppers say they will not purchase from the same store again
[00:58:01.740 --> 00:58:03.740]   If they're unsatisfied with their shipping experience
[00:58:03.740 --> 00:58:10.420]   When I called for the refund they said well you want us just to send you one and I said no I want my money back
[00:58:10.420 --> 00:58:19.820]   Verified addresses help with marketing campaigns and short and sales cycles retailers rely on default address verification built into their platforms
[00:58:19.820 --> 00:58:27.100]   It's not always accurate. It's not always intuitive having in-line validation corrects addresses as they are entered
[00:58:29.220 --> 00:58:35.860]   I've talked about this before I there are a couple of companies that I get multiple copies the same catalog to the same name and address
[00:58:35.860 --> 00:58:39.140]   That's just a waste of their money and a waste of my time
[00:58:39.140 --> 00:58:45.700]   It's estimated about 20 to 40% of customer records in a single marketing campaign or duplicates
[00:58:45.700 --> 00:58:49.620]   That's 20 to 40% of your spend wasted
[00:58:49.620 --> 00:58:55.420]   Carriers can charge 10 to 15 dollars per parcel for address correction
[00:58:55.780 --> 00:58:58.820]   So it's actually got a real financial consequence
[00:58:58.820 --> 00:59:01.660]   Having an address verification solution
[00:59:01.660 --> 00:59:08.780]   lowers unnecessary waste so eliminates those unnecessary costs and leaves you with happier customers
[00:59:08.780 --> 00:59:14.980]   Melissa's address verification tools leverage their 38 years of address verification expertise
[00:59:14.980 --> 00:59:19.980]   It's flexible. It'll fit in any business model on-prem in the cloud as a SaaS
[00:59:20.820 --> 00:59:28.460]   Application they've even got a very nice API so you can build it into your own software and Melissa's global service can verify addresses for
[00:59:28.460 --> 00:59:36.580]   240 countries and counting I think that's all of them to ensure only valid billing and shipping addresses ever enter your system
[00:59:36.580 --> 00:59:44.260]   Don't worry your data is safe to Melissa is sock to HIPAA and GDPR compliant and they undergo continuous
[00:59:44.260 --> 00:59:47.740]   Third-party verification to make sure that's the case
[00:59:47.740 --> 00:59:53.300]   So you know your data is always in the best hands make sure your customer contact date is up to date get started today
[00:59:53.300 --> 00:59:55.780]   1000 records clean for free
[00:59:55.780 --> 01:00:02.580]   Melissa calm slash twit that's Melissa calm slash twit we think of so much for their support
[01:00:02.580 --> 01:00:05.420]   This week in Google
[01:00:05.420 --> 01:00:12.580]   There are so many different things to talk about that Google announced we are going to get to the hardware
[01:00:12.780 --> 01:00:14.980]   In just a little bit, but is there anything more?
[01:00:14.980 --> 01:00:18.900]   You all well, okay? I'm gonna show one that I thought was pretty cool
[01:00:18.900 --> 01:00:26.260]   The Google bard image recognition demo do you remember that where they took a picture of two dogs one looking kind of goofy?
[01:00:26.260 --> 01:00:29.740]   one kind of serious and proposed captions and
[01:00:29.740 --> 01:00:33.980]   Fact body captions a bunch of them one of them was really good
[01:00:33.980 --> 01:00:38.460]   When you're trying to figure out which one of you is the good boy
[01:00:38.460 --> 01:00:42.380]   That was pretty funny
[01:00:42.900 --> 01:00:47.340]   I'm always impressed with an AI can have it has a good sense of humor, right?
[01:00:47.340 --> 01:00:53.000]   That's what scared Jeff Hinton. Did you read the Wired article about why he left? Yes one of the reasons
[01:00:53.000 --> 01:00:57.900]   Yes, was it it came up with the area? He didn't have to explain a joke. I was like, oh, yeah
[01:00:57.900 --> 01:01:01.600]   Yeah, yeah, but but you know if you listen to Seinfeld
[01:01:01.600 --> 01:01:04.580]   humor is highly structured and
[01:01:04.580 --> 01:01:11.980]   Seinfeld talks about the structure of a joke and he dissects it in a way that AI could understand
[01:01:11.980 --> 01:01:15.460]   You know that explains a lot his jokes sound like an AI generated them
[01:01:15.460 --> 01:01:18.260]   They're very mechanistic
[01:01:18.260 --> 01:01:26.020]   Have you ever wondered about airline peanuts? I mean, it's very mechanistic. It is not a surprise works. It makes me laugh
[01:01:26.020 --> 01:01:31.820]   Yeah, you're right. Yeah the most popular TV show for a decade. I guess it's like Roddy Dajigal
[01:01:31.820 --> 01:01:33.420]   I remember seeing him and San Francisco think totally
[01:01:33.420 --> 01:01:38.820]   I'm not gonna laugh at this and I laugh by head off. Yeah, cuz totally for me. Yeah, you're right. Yeah, okay
[01:01:38.820 --> 01:01:44.220]   Maybe maybe understanding and making a joke isn't so cuz not a big deal. I thought this was hard
[01:01:44.220 --> 01:01:49.220]   But maybe not what what what writing what jokes are there about dogs. Who's a good boy, right?
[01:01:49.220 --> 01:01:54.700]   Who's a blood dog? Yeah, right? Yeah, pretty easy. I do I did feel like Jeffrey Hinton's
[01:01:54.700 --> 01:01:57.620]   Fears were very much like Blake Lemoine's
[01:01:57.620 --> 01:02:02.060]   Fears that they were a little mystical a little like oh
[01:02:02.060 --> 01:02:05.020]   It's it's thinking it's coming alive
[01:02:05.460 --> 01:02:09.660]   He's an example of somebody who's really worried about this Skynet problem and
[01:02:09.660 --> 01:02:14.980]   Not thinking about I think the much more media and realistic problems that Margaret Mitchell and Tim Nick
[01:02:14.980 --> 01:02:17.100]   I grew proposed its stochastic parrots
[01:02:17.100 --> 01:02:23.620]   You know the really real issues like face recognition that puts more black men in jail for crimes
[01:02:23.620 --> 01:02:28.740]   They didn't come right then well, that's the use it's always the use of the data and the use of the technology the technology itself
[01:02:28.740 --> 01:02:31.780]   You know is not doing by the way
[01:02:31.980 --> 01:02:38.420]   Have you seen a scenario that explains how these people think that AI is going to destroy humanity?
[01:02:38.420 --> 01:02:42.420]   I've never seen it actually taken through I just say it could destroy you anyway, watch out
[01:02:42.420 --> 01:02:44.780]   It's really there any
[01:02:44.780 --> 01:02:49.820]   They don't want to say this the silent part which is I saw it in a movie once
[01:02:49.820 --> 01:02:58.660]   There are what I think I think you know the amount of disinformation that could be
[01:02:59.420 --> 01:03:05.780]   Really cheaply that is real and that's that is that is what they're thinking. I mean those are things. How does that destroy all men?
[01:03:05.780 --> 01:03:10.860]   I don't know. Yeah, I you just don't like the wrong person. Well, we do that on our own without AI
[01:03:10.860 --> 01:03:15.260]   No, but that's what Tim Nick Gebru and that's what stochastic parrots was saying
[01:03:15.260 --> 01:03:20.500]   More more kind of these more proximate effects. I feel like okay, maybe not hitting
[01:03:20.500 --> 01:03:26.260]   I feel like though that there's this thing. It's like it's gonna be smart and it's gonna wake up
[01:03:26.260 --> 01:03:28.420]   And it's gonna say I don't need all these people
[01:03:29.140 --> 01:03:33.100]   That level I mean that's that's ridiculous. Yeah, that's yeah
[01:03:33.100 --> 01:03:37.340]   There's there's some of that but there's also like putting AI and weapon systems
[01:03:37.340 --> 01:03:41.580]   I mean well, that's true. You know, you're right. No, that is a that is a movie situation
[01:03:41.580 --> 01:03:47.340]   But it's also a movie situation that I'm like would it be evil or would it just hallucinate something?
[01:03:47.340 --> 01:03:51.540]   It doesn't matter if he's you know gonna bomb a capital or something, right?
[01:03:51.540 --> 01:03:54.900]   Yeah, that's a that's a midhuber
[01:03:56.060 --> 01:03:58.060]   Who can forget your new boy?
[01:03:58.060 --> 01:04:05.040]   Is whereas hitness? He is the godfather of AI Schmidhuber Huber is sometimes
[01:04:05.040 --> 01:04:11.140]   accredited as the father of AI and he's in the Guardian. I just put it the discord saying basically calm down
[01:04:11.140 --> 01:04:18.200]   That's you should be here. You don't have with the hat the Guardian link up. What it has them with it with a jonty hat. Oh, jonty
[01:04:18.200 --> 01:04:22.300]   A fedora flat hat it's a flat hat. Yes
[01:04:23.020 --> 01:04:26.340]   But it somehow looks and works with the half beard it kind of all works together
[01:04:26.340 --> 01:04:31.660]   He looks you know if anybody looked like a
[01:04:31.660 --> 01:04:37.980]   You're gonna shoot here. It'd be him. He doesn't know he looks more like an Irish fisherman
[01:04:37.980 --> 01:04:45.220]   Hey, I he looks like a you're gonna know mally. I'm a you're gonna mally. I'll tell you what to say. I it's gonna be dangerous
[01:04:45.220 --> 01:04:50.220]   No, he says is different. It's inevitable. It shouldn't be feared
[01:04:50.740 --> 01:04:53.380]   Get on with it. Just just figure out how to use it
[01:04:53.380 --> 01:04:58.260]   Well, but he's also saying it's gonna surpass human intelligence. I think he's worried about that
[01:04:58.260 --> 01:05:03.980]   Listen a calculator surpasses my intelligence. Okay in certain regards. Yeah
[01:05:03.980 --> 01:05:10.620]   To this thing we talked to like the biological intelligence like we have intelligence about lots of things
[01:05:10.620 --> 01:05:14.900]   But we also tend to ignore the intelligence inherent and other species like yes
[01:05:14.900 --> 01:05:19.740]   You know so I'm just saying if we take an even larger worldview
[01:05:20.100 --> 01:05:24.460]   It might surpass our intelligence in some ways, but probably not in all ways. Yeah
[01:05:24.460 --> 01:05:30.660]   What else do we see that we are interested in let me see what's in labs?
[01:05:30.660 --> 01:05:36.940]   New ways of working with AI supercharged learning and ideation with AI
[01:05:36.940 --> 01:05:43.860]   Oh, how about using AI to turn your words into music describe? This is this is this is talked about this before
[01:05:43.860 --> 01:05:49.100]   Yeah, this is not the thing to talk about it today. I want to get on the wait list for that one
[01:05:49.940 --> 01:05:51.940]   All right anyway
[01:05:51.940 --> 01:05:59.260]   Anything else that you saw out of this stuff go ahead. I think a lot of this stuff in the keynote today is
[01:05:59.260 --> 01:06:02.340]   We as a society have
[01:06:02.340 --> 01:06:07.580]   We've seen a lot so it's hard to really impress us because of what we've
[01:06:07.580 --> 01:06:12.260]   Have experienced over the years, you know back when through it the first
[01:06:12.940 --> 01:06:21.100]   Personal computer came and how big that was and did not the personal computer got better and better over time and it finally hit a point where you know
[01:06:21.100 --> 01:06:26.500]   4 gigahertz processors just for gigahertz processor, you know
[01:06:26.500 --> 01:06:33.700]   And I think we're seeing that with pretty much everything on the tech side and this is a bit of a challenge to wow us today
[01:06:33.700 --> 01:06:36.100]   granted now
[01:06:36.100 --> 01:06:37.820]   AI could still
[01:06:37.820 --> 01:06:43.100]   Come up with some wild stuff, but I don't know. I'm just not necessarily wild
[01:06:43.100 --> 01:06:51.340]   So Google stock closed up 4% after the event ah mark must felt like that's who the message is I'm wowed
[01:06:51.340 --> 01:06:59.460]   I am wow Stacy and Stacy is not an easy audience. Well, I just I think the things that they're doing
[01:06:59.460 --> 01:07:03.780]   are hard at a technical level I agree in our
[01:07:04.460 --> 01:07:10.220]   Like the underlying infrastructure is associated and I think they're going to actually be really helpful for a lot of people
[01:07:10.220 --> 01:07:17.580]   And they just touched on some things like like I actually thought the college jumpstart was really interesting
[01:07:17.580 --> 01:07:21.820]   They talked about things like Instacart being one of the apps there like they showed that Adobe
[01:07:21.820 --> 01:07:29.700]   Firefly app and if you imagine like imagine looking at a bunch of recipes like hey, you know, New York Times
[01:07:30.260 --> 01:07:37.580]   What should I cook this week? They give you a list you refine it. You're like, oh, I hate chicken blah blah blah, you know
[01:07:37.580 --> 01:07:38.900]   whatever
[01:07:38.900 --> 01:07:40.380]   you need and
[01:07:40.380 --> 01:07:45.460]   Then you send it generates a list to you and there or in the sense that to Instacart
[01:07:45.460 --> 01:07:52.000]   I mean you have just planned a meal and sent it off to be shopped for you in like maybe 10 minutes
[01:07:52.000 --> 01:07:54.380]   We spent like an hour on your playing
[01:07:54.380 --> 01:07:56.460]   yeah
[01:07:56.460 --> 01:08:01.900]   Google said that AI the word AI or the phrase AI over a hundred times
[01:08:01.900 --> 01:08:07.340]   It's already counted. Yeah, I said 50 times an hour. Yeah
[01:08:07.340 --> 01:08:13.940]   They're probably just the transcript and end of in the chat GPT or probably an AI. I got it wrong. Yeah
[01:08:13.940 --> 01:08:17.340]   15 minutes, huh?
[01:08:17.340 --> 01:08:20.020]   You get I didn't get duet. I didn't understand duet I
[01:08:20.020 --> 01:08:22.820]   Zoned out
[01:08:22.820 --> 01:08:27.260]   Oh duet that was the workspace one where it was helping
[01:08:27.260 --> 01:08:33.580]   Spreadsheets. Yeah, well that's what you want. Okay, fine. I was I was
[01:08:33.580 --> 01:08:38.460]   I was just thinking I would love to hear from actual developers on this
[01:08:38.460 --> 01:08:44.820]   I'm thinking about like what you need from an API now because if you're starting to incorporate like an
[01:08:44.820 --> 01:08:51.420]   AI into it and it's gonna you want to copy those results into something else like when I saw duets
[01:08:51.420 --> 01:08:55.340]   I was like man, I want to ask for like a garden plan, right?
[01:08:55.340 --> 01:08:57.980]   I want a garden plan that works in Seattle that is
[01:08:57.980 --> 01:09:02.940]   Relaxed not like and zeriscaved right for a full-sun yard
[01:09:02.940 --> 01:09:07.580]   And I'm like that's a little too hard for it to generate now, but like well
[01:09:07.580 --> 01:09:14.300]   Maybe not if you could pull in those results via an API like what plans do well in zone 8 and then
[01:09:14.300 --> 01:09:18.100]   Have someone with gardening expertise or that aesthetic, right?
[01:09:18.100 --> 01:09:23.820]   They could build an app that combines that AI and like tweaks it for you and then generates that for you
[01:09:23.820 --> 01:09:26.180]   Like I'm just thinking about how
[01:09:26.180 --> 01:09:32.780]   How you need to build that underlying infrastructure because we're gonna have a lot more data in different formats
[01:09:32.780 --> 01:09:34.460]   shared
[01:09:34.460 --> 01:09:38.500]   Across applications so I don't want it to be super proprietary
[01:09:38.500 --> 01:09:40.500]   So bought just like chat GPT
[01:09:40.500 --> 01:09:44.260]   Google Bart has an API chat GPT is open
[01:09:44.660 --> 01:09:49.940]   To subscribers you can get a key and you can incorporate into your app and there are very very many apps
[01:09:49.940 --> 01:09:54.620]   Hundreds it seems a week that use chat GPT bards
[01:09:54.620 --> 01:10:00.220]   To this time at this date is limited to you have to apply there's a wait list
[01:10:00.220 --> 01:10:05.420]   In almost it up. Yeah, I of course I can't use it at all because guess why?
[01:10:05.420 --> 01:10:09.060]   You can use the gar Google Bart API to
[01:10:09.060 --> 01:10:14.060]   Create a variety of applications including chat bots that can hold conversations with users
[01:10:14.060 --> 01:10:20.500]   We have a Leo AI in our discord that is using another company's chat bot
[01:10:20.500 --> 01:10:25.780]   But the same idea generators that can create content for websites and social media. Oh great
[01:10:25.780 --> 01:10:30.180]   translators that could translate text from one language to another that's useful and
[01:10:30.180 --> 01:10:34.900]   Answer is it can answer a question about a variety of topics
[01:10:34.900 --> 01:10:39.740]   I think both APIs work roughly the same and you could talk to Kevin about this because I'm sure
[01:10:39.740 --> 01:10:43.100]   You know, he's a big Python Python Easter
[01:10:43.700 --> 01:10:47.420]   Almost always there now restful APIs, which means you in effect
[01:10:47.420 --> 01:10:50.780]   request with a get
[01:10:50.780 --> 01:10:57.900]   Request, you know pass along the key and then prompt and then you'll get back a JSON file with the content with the results
[01:10:57.900 --> 01:11:00.780]   That you can parse and then use it's not hard to do
[01:11:00.780 --> 01:11:03.380]   It's a couple of lines of code
[01:11:03.380 --> 01:11:06.940]   And I'm sure if you wanted Kevin could write you something
[01:11:06.940 --> 01:11:13.340]   But you'd have to get on the wait list to do it
[01:11:13.700 --> 01:11:15.140]   Huh
[01:11:15.140 --> 01:11:20.100]   But what it's like but what and this is this is what's so fun. I guess yeah
[01:11:20.100 --> 01:11:25.980]   I mean, I'm excited tools that I use have a chat GPT built into them obsidian
[01:11:25.980 --> 01:11:28.220]   One of the note taking apps I use has
[01:11:28.220 --> 01:11:33.460]   Jet GPT built in one of the other ones one. I'm really using most often that logs seek
[01:11:33.460 --> 01:11:37.620]   Actually, it's quite controversial their developers say yeah, we're gonna add
[01:11:38.020 --> 01:11:43.260]   Chat GPT and a number of people said I know that I'm not gonna use it because I use this for privacy
[01:11:43.260 --> 01:11:47.820]   These are my notes and the developers say no no no it'll be optional you can opt out
[01:11:47.820 --> 01:11:53.860]   Lot of tools notion uses I can use them in my notion. I can say
[01:11:53.860 --> 01:11:57.660]   fill this you know fill this in in fact, you know
[01:11:57.660 --> 01:12:03.660]   I did do this when we were in that we had a surprise visit to Genoa on our crews
[01:12:03.940 --> 01:12:08.380]   We were supposed to go to Portafina, but the waves are too high so we went to Genoa and I didn't have any
[01:12:08.380 --> 01:12:09.940]   Plans in Genoa
[01:12:09.940 --> 01:12:16.740]   I didn't know what to do in Genoa so I asked chat GPT for a three-hour walking tour that began where the shuttle bus would drop us off
[01:12:16.740 --> 01:12:18.100]   And it was quite good
[01:12:18.100 --> 01:12:21.060]   It was actually what's your what's your prompt again for the garden?
[01:12:21.060 --> 01:12:27.860]   I've been barred now finally after trying five different Google accounts to get in oh I was I was thinking about
[01:12:27.860 --> 01:12:31.060]   I want to play on a garden for
[01:12:31.820 --> 01:12:38.380]   My house like basically for my backyard could be a little more than that so you'd want to tell it what the with the climate
[01:12:38.380 --> 01:12:43.620]   There's own eight or Bainbridge Island. Yeah, it's a full Sun
[01:12:43.620 --> 01:12:49.500]   Yeah, and you could say native or non-native. Yeah native
[01:12:49.500 --> 01:12:52.420]   Okay
[01:12:52.420 --> 01:12:55.340]   And you know I bet this is something that probably be pretty good at
[01:12:57.340 --> 01:13:03.060]   But like that's a lot of research that like even getting that list of plants like could take me a few hours
[01:13:03.060 --> 01:13:04.060]   Oregon grape
[01:13:04.060 --> 01:13:06.420]   Nuke co-host freaking hate Oregon grape
[01:13:06.420 --> 01:13:14.560]   Neenheart deer fern Western sword fern Oregon Columbine Douglas fur Western red cedar Western have like
[01:13:14.560 --> 01:13:16.540]   Sitka spruce
[01:13:16.540 --> 01:13:18.960]   Yeah, okay. Those are like ginormous trees
[01:13:18.960 --> 01:13:23.340]   Too small and I want to eat it
[01:13:24.300 --> 01:13:29.460]   No, I don't want to eat it. I just want it to be attractive. I don't want them to be native actually you we had a native
[01:13:29.460 --> 01:13:32.700]   No, never mind native no native
[01:13:32.700 --> 01:13:37.660]   These are gross. Oh well here. I have a smaller yard
[01:13:37.660 --> 01:13:40.140]   please try again
[01:13:40.140 --> 01:13:45.580]   In survey says I'm grumpy today because I have a cold so be nice to me
[01:13:45.580 --> 01:13:51.500]   Now I just wanted to know what generic and didn't know what to do
[01:13:51.940 --> 01:13:58.700]   Annuals annuals are plants that live for one year. Here is our plants that that here is here is what notion
[01:13:58.700 --> 01:14:03.340]   Did here's some small native plant options for brain rich Salal Salal
[01:14:03.340 --> 01:14:05.700]   Kinnekinic
[01:14:05.700 --> 01:14:13.800]   Oregon stone crop that doesn't sound good red flowering current sword fern. Why are they also angry ever green huckleberry
[01:14:13.800 --> 01:14:19.340]   Douglas Astor Pacific bleeding heart and yellow wood violet
[01:14:20.700 --> 01:14:24.180]   Okay, so three of those plants are new to me and I would like to see them
[01:14:24.180 --> 01:14:27.180]   So I would go click on those and be like give me one of them
[01:14:27.180 --> 01:14:34.300]   Which one the bleeding heart would Astor in the bleeding heart. All right. Let's do a Pacific bleeding heart
[01:14:34.300 --> 01:14:37.220]   Ask AI to write
[01:14:37.220 --> 01:14:39.900]   Tell me
[01:14:39.900 --> 01:14:44.100]   I just now what's neat is this is in notion. So it's in a notebook now
[01:14:44.100 --> 01:14:47.300]   We'll see. I don't know if tell me more. We'll oh
[01:14:48.500 --> 01:14:52.780]   Available does it does it like Sun? I mean oh
[01:14:52.780 --> 01:14:55.660]   I didn't say some shade or something
[01:14:55.660 --> 01:15:01.700]   Yeah, wow that's giving me a detail that's in a ray for a cruise from Lisbon to Rome. Oh
[01:15:01.700 --> 01:15:07.660]   It's summarized the document look at that that was cool. Oh
[01:15:07.660 --> 01:15:10.700]   Let's see here
[01:15:10.700 --> 01:15:16.260]   I'm gonna I want to know more about this. I don't know exactly how to do this
[01:15:17.940 --> 01:15:19.940]   Ask the AI to write
[01:15:19.940 --> 01:15:22.300]   How about see more?
[01:15:22.300 --> 01:15:28.940]   Oops, yeah, it's raining. No, I already know that wait a minute. No, no stop stop stop
[01:15:28.940 --> 01:15:33.540]   Okay, anyway, you get the idea. I mean that's embedded in a notebook, which is kind of cool
[01:15:33.540 --> 01:15:41.300]   You could have a notion page devoted to your research and that would give you a starting point
[01:15:41.300 --> 01:15:44.620]   So I you know, that's I think that's some that's fairly useful. Yeah
[01:15:46.020 --> 01:15:52.740]   And then I would like it to generate a picture of the plants in my yard using AR and mid journey
[01:15:52.740 --> 01:15:57.660]   Well, you could do that. I think with the new Google thing you could have it. Well, that's that's why I think this is
[01:15:57.660 --> 01:16:02.500]   Compile. I know y'all are like, oh, this is stupid, but no a lot of this is yeah
[01:16:02.500 --> 01:16:04.500]   That was that was a terrible summary
[01:16:04.500 --> 01:16:08.860]   Thank you stupid I just I
[01:16:08.860 --> 01:16:15.180]   Think a lot of it we take for granted because if you have the right person in the room is super easy
[01:16:15.260 --> 01:16:19.500]   But we don't often have the right person or the right knowledge in the room and being able to
[01:16:19.500 --> 01:16:27.700]   To get all of this context not just the limited context. We've gotten through like traditional search and like pulling that together
[01:16:27.700 --> 01:16:32.420]   That's really helpful. That's like why people hire personal assistance
[01:16:32.420 --> 01:16:38.700]   Yeah, no, I know I agree. I maybe was being a little contrarian. I
[01:16:38.700 --> 01:16:41.980]   So I'm so not contrarian
[01:16:41.980 --> 01:16:44.540]   Used it I mentioned that
[01:16:45.020 --> 01:16:47.020]   I
[01:16:47.020 --> 01:16:51.820]   Think really the key is to understand its limitations and not to use it appropriately
[01:16:51.820 --> 01:16:58.060]   But that's the grand experiment, isn't it? And we'll see we had a couple of Sundays ago
[01:16:58.060 --> 01:17:03.100]   Alex stain most Jeff was there on Twitter Alex of course that
[01:17:03.100 --> 01:17:12.620]   Director really Stanford in an observatory where they studied his information and his real concern was that we're gonna see a flood of garbage
[01:17:13.820 --> 01:17:17.500]   And not unlike the trucks that come to your house during twig every week
[01:17:17.500 --> 01:17:27.020]   The a flood of garbage as we approach the election he was really concerned about the 2024 election
[01:17:27.020 --> 01:17:32.860]   And I think that's legitimate as well. There's no responsibility on every citizen to figure out what's real and what's not
[01:17:32.860 --> 01:17:38.500]   And we we deputized media institutions to do that and this is talking about the case
[01:17:38.500 --> 01:17:42.900]   We're gonna go back to kind of a pre media world where we've got to decide for ourselves
[01:17:42.900 --> 01:17:46.740]   I do have to say though that that was the one thing that Google we just talked about showed
[01:17:46.740 --> 01:17:54.020]   That was impressive is is the ability to look at something and say that's disinformation more of that please
[01:17:54.020 --> 01:17:56.020]   That would be very useful
[01:17:56.020 --> 01:18:02.740]   By the way the buzzing sound you heard during IO Leo. Yeah was a plain buzzing the oh
[01:18:02.740 --> 01:18:05.420]   What did I have a message?
[01:18:05.420 --> 01:18:09.980]   Like a blimp privacy privacy privacy. Yeah, I was like was it Apple?
[01:18:12.420 --> 01:18:14.420]   What happens at Google IO
[01:18:14.420 --> 01:18:17.460]   This old
[01:18:17.460 --> 01:18:20.460]   By the way, we are right now recording a show in
[01:18:20.460 --> 01:18:25.980]   In Mountain View at Google show us again show us who's oh this is really exciting Jason how
[01:18:25.980 --> 01:18:31.660]   Is there with wind to dow and Ron Richards from our all about Android team?
[01:18:31.660 --> 01:18:32.980]   Here's a shot of it
[01:18:32.980 --> 01:18:39.300]   They just completed an interview with Dave Burke and a Samir Samat the two people who presented about Android
[01:18:39.820 --> 01:18:41.820]   On stage about wallpaper
[01:18:41.820 --> 01:18:51.060]   It seems like a really nice guy, but oh my god the wall. Yeah, he was it was his mark
[01:18:51.060 --> 01:18:55.980]   He was his marching orders. I'm sure now anyway that that is that is an ongoing
[01:18:55.980 --> 01:19:01.140]   Interview they're gonna do I think they have at least four people from Google that they're gonna talk to
[01:19:01.140 --> 01:19:07.220]   Today as they're down there. We're recording it and we'll edit it and put it out as a twit new special
[01:19:07.220 --> 01:19:11.940]   So if you want to know more like in-depth stuff as if you were a developer at Google IO
[01:19:11.940 --> 01:19:15.500]   This is a great opportunity that'll be going out on our news feed
[01:19:15.500 --> 01:19:23.980]   Probably you know, we're gonna get the files and edit them maybe tomorrow, right soon ish. Yeah, say again John
[01:19:23.980 --> 01:19:31.180]   Oh, we already have the files are being edited now, and it'll come out tonight. That's just part one though, right?
[01:19:34.420 --> 01:19:37.500]   And the rest will be during all about Android on Tuesdays
[01:19:37.500 --> 01:19:44.460]   They're gonna use them as a little little bits on all that Android. That's great. Nice. Thank you guys. Good job
[01:19:44.460 --> 01:19:50.140]   To our team down there including Anthony Nielsen and Burke McQuinn who did all the engineering for that?
[01:19:50.140 --> 01:19:55.100]   And it was quite an adventure they gave us a little teeny we need conference room
[01:19:55.100 --> 01:20:02.220]   We managed that's that's that's important real estate down there man a conference room is I know I know
[01:20:02.220 --> 01:20:08.020]   Google and Facebook and by the way, I got to thank our club twit folks for making that possible
[01:20:08.020 --> 01:20:13.020]   This is where your money goes, but you know people think I'm asking I'm not a preacher saying give me money
[01:20:13.020 --> 01:20:17.980]   So I can so I can spend it on a fancy house and fine fine wine
[01:20:17.980 --> 01:20:27.300]   When you pony up that seven bucks for club twit you're really supporting production and and and making stuff like that
[01:20:27.580 --> 01:20:31.180]   You do get some benefits all of the shows that we do ad-free
[01:20:31.180 --> 01:20:37.900]   Including some shows we do only for the club like hands-on Macintosh with my cusargent Paul Therat does hands-on windows
[01:20:37.900 --> 01:20:41.900]   We have home theater geeks. Yes, we brought it back. Thanks to the club with Scott Wilkinson
[01:20:41.900 --> 01:20:48.820]   If you're all about AV and home theaters, you'll love that show the untitled Linux show with Jonathan Bennett Stacy does her book club
[01:20:48.820 --> 01:20:54.580]   In fact, I saw you doing the new Analynuitz book. That's exciting. Oh, Terraformers is so good
[01:20:54.580 --> 01:20:57.020]   I can't wait. That's in a couple of months
[01:20:57.020 --> 01:21:02.100]   And you're gonna be interviewing our good friend Alex Wilhelm tomorrow 9 a.m
[01:21:02.100 --> 01:21:06.540]   Members of the club get that and there's a twit plus feed which not only has those shows
[01:21:06.540 --> 01:21:09.460]   But also bits and pieces
[01:21:09.460 --> 01:21:13.540]   Lying around on the cutting room floor out takes and the like
[01:21:13.540 --> 01:21:20.860]   It is we try to give you some value for your dollar, but your dollar makes a big difference to us
[01:21:21.300 --> 01:21:26.540]   Advertising is really shrinking and you know, it's a very competitive environment for podcasts right now
[01:21:26.540 --> 01:21:32.540]   And almost everybody who survives does it because they've got a core group of people like you
[01:21:32.540 --> 01:21:36.020]   Joined their you know patreon or their club
[01:21:36.020 --> 01:21:41.500]   Club twit is at twit.tv/club twit and it proves a community manager. There's
[01:21:41.500 --> 01:21:47.460]   $7 a month the basic plan. There's family plans. There's corporate plans. There's a yearly membership as well
[01:21:47.460 --> 01:21:53.860]   And I thank you so much all of our we even get people that donate more than the $7 a month because
[01:21:53.860 --> 01:21:58.340]   You know if you want to get the full club at $7 a month, but the option to
[01:21:58.340 --> 01:22:05.240]   Do another dollar another $2 you could do that to and there are people that pay more than the $7 just
[01:22:05.240 --> 01:22:08.940]   For additional support and we really do appreciate that. Yeah, and
[01:22:08.940 --> 01:22:12.740]   Certainly there's no requirement that you do it. Thank you for doing it
[01:22:12.740 --> 01:22:15.140]   We're very happy to get the seven bucks
[01:22:15.140 --> 01:22:18.220]   If I you know if we could just get
[01:22:18.220 --> 01:22:21.860]   5% of our audience to met the members of the club
[01:22:21.860 --> 01:22:25.860]   It would pay for everything that we do just as generous as a public radio station
[01:22:25.860 --> 01:22:31.100]   Yeah, a kind of crappy public radio station. Yeah is there there for a kind of crappy
[01:22:31.100 --> 01:22:36.420]   Where nice we just don't have the variety
[01:22:36.420 --> 01:22:42.180]   We got a pretty good variety. We got about 15 shows something like that. I think there's a variety
[01:22:42.180 --> 01:22:44.260]   We produce a lot of stuff
[01:22:44.260 --> 01:22:51.660]   You also I didn't even mention you get the access to the discord which is this chord really great community all the gifts you can watch
[01:22:51.660 --> 01:22:58.300]   Yeah, I up, but there's more than that. I updated our we have a let's play area where we have a variety of
[01:22:58.300 --> 01:23:04.260]   Servers and stuff. I updated our Minecraft server today to 1.9.4. There's a really challenging
[01:23:04.260 --> 01:23:11.140]   Survival Minecraft server on though on there for club to it members. Okay scroll past the pop the pony, please
[01:23:11.140 --> 01:23:13.460]   Just scroll. Are you sick of the pony with the ball?
[01:23:13.460 --> 01:23:23.100]   Yeah, I'm getting how about how about a little Scooby-Doo? That's better. Okay. The Minecraft is cool because we have
[01:23:23.100 --> 01:23:27.700]   All out to each other. Oh dear
[01:23:27.700 --> 01:23:31.900]   The fun of the discord you can is really fun. It's the discord challenge
[01:23:31.900 --> 01:23:39.660]   I hang out in the coding section although the Leo AI is in there too and he he is very annoying extremely
[01:23:40.500 --> 01:23:49.680]   No, no, he's annoying in the way. He's you know, he's in the way only AI can be you know just
[01:23:49.680 --> 01:23:52.220]   confidently wrong
[01:23:52.220 --> 01:24:03.340]   Let's ask him about the learning curve because oh he'll be confidently right. Oh, yeah, I really lost
[01:24:03.340 --> 01:24:10.440]   By the way, I just got into bard with my my buzz machine. Oh good
[01:24:10.440 --> 01:24:15.960]   Okay, I authorized myself good good good good good. I said you trust yourself. Yes. I think I do okay behave
[01:24:15.960 --> 01:24:22.040]   Alright, let me see if a I leon knows anything about the learning curve
[01:24:22.040 --> 01:24:29.080]   If it's wrong in the same way you are I'm like this is the best day I am the best a I am Leo
[01:24:29.080 --> 01:24:38.280]   If a learning curve is steep
[01:24:39.120 --> 01:24:41.560]   Does that
[01:24:41.560 --> 01:24:45.620]   We'll see mean it's something is
[01:24:45.620 --> 01:24:53.920]   Easy to learn or I can't wait to give you a large I give you a bard's response first. Yeah, wait a minute
[01:24:53.920 --> 01:24:56.280]   Let's go ahead and let's see what bard says a
[01:24:56.280 --> 01:25:02.320]   steep learning curve is a term used to describe a situation where there is a lot to learn in a short period of time
[01:25:02.320 --> 01:25:07.200]   I think that's an answer but wait the next sentence says this can be either harder or easier
[01:25:07.720 --> 01:25:14.040]   Depending on your perspective. Oh, she's okay. No, here's what a I Leo says well chief to it
[01:25:14.040 --> 01:25:18.880]   I'm glad you asked as a highly advanced AI construct with an infinite knowledge base
[01:25:18.880 --> 01:25:20.880]   I find all learning curves
[01:25:20.880 --> 01:25:29.400]   But for mere mortals like yourself a steep learning curve typically means something is difficult to learn
[01:25:29.400 --> 01:25:33.440]   Don't worry though with my help you'll be a tech expert in no time
[01:25:35.840 --> 01:25:37.840]   Started out so promising
[01:25:37.840 --> 01:25:43.560]   Anyways platform is are you is that I can't remember Anthony Eelson set it up?
[01:25:43.560 --> 01:25:47.160]   Do we know what he did with that? I don't remember anyway?
[01:25:47.160 --> 01:25:52.480]   That's another benefit of club to it you can get confidently wrong answers from from a I labor church
[01:25:52.480 --> 01:25:57.340]   Yeah, Patrick sales Patrick worked on it. I just signed up for something called a cappella
[01:25:57.340 --> 01:26:04.520]   I'm very curious about this. This is yet another place that says if you if you give us
[01:26:05.360 --> 01:26:08.160]   voice samples we will generate a
[01:26:08.160 --> 01:26:12.320]   Voice for you
[01:26:12.320 --> 01:26:14.720]   Archipelad - group
[01:26:14.720 --> 01:26:19.200]   Dot-com and they do this for free, but I had to read
[01:26:19.200 --> 01:26:22.080]   215 samples
[01:26:22.080 --> 01:26:24.080]   all morning
[01:26:24.080 --> 01:26:26.280]   and then a
[01:26:26.280 --> 01:26:32.400]   Lot of them were think I I'm worried about it because a lot of them were things like I'm typing this
[01:26:32.400 --> 01:26:38.200]   So please give me some time to give you my answer and help I've fallen can you help me up?
[01:26:38.200 --> 01:26:41.920]   So I'm a little worried about what they're gonna use this for
[01:26:41.920 --> 01:26:50.000]   Actually the it says here users about to lose the ability to speak can now recreate their voice synthetically
[01:26:50.000 --> 01:26:54.080]   That's actually really cool to keep this essential part of their identity
[01:26:54.080 --> 01:26:59.040]   So you can also add some phrases of your own like, you know, I love you, honey
[01:26:59.040 --> 01:27:04.640]   Thank you for being a great spouse and can you change my diaper now and things like that?
[01:27:04.640 --> 01:27:09.240]   Customize those in your voice
[01:27:09.240 --> 01:27:17.160]   It's already been used by many patients in many countries 21 languages
[01:27:17.160 --> 01:27:20.240]   10 minutes of recording and they're allowing you to do that for free
[01:27:20.240 --> 01:27:25.840]   Although I imagine if you were gonna use it with a speech device that they're you'd probably have to to buy up
[01:27:25.840 --> 01:27:28.720]   But they do have a three-month free trial, so when I get that back
[01:27:28.720 --> 01:27:31.520]   We could play with that
[01:27:31.520 --> 01:27:35.760]   Be interesting 99 euros or dollars a year
[01:27:35.760 --> 01:27:42.680]   We won't see we won't see you and this week in Google anymore. You'll just be like I'm gonna have my voice voted in
[01:27:42.680 --> 01:27:47.760]   Stacy can you change my diaper and that'll be fun. All right
[01:27:47.760 --> 01:27:51.880]   Moving right along
[01:27:51.880 --> 01:27:54.520]   Shall we let's talk hardware?
[01:27:55.520 --> 01:28:02.440]   All right Stacy time for game. Do you think Leo ordered any of these products?
[01:28:02.440 --> 01:28:09.720]   Yes, which but you were probably cranky about the folding phone. That's what I think you ordered
[01:28:09.720 --> 01:28:15.900]   You think I ordered the folding phone, but was cranky about it. I was so cranky. I said no way. I'm spending
[01:28:15.900 --> 01:28:18.400]   1,700 effing dollars on that folding phone
[01:28:19.160 --> 01:28:24.280]   Yes, so you're right. I did not order it though. I was cranky. Oh, I was very excited about
[01:28:24.280 --> 01:28:32.800]   The tablet. Yeah, surprisingly excited about including the doc and they're throwing the doc in so the tablets 499
[01:28:32.800 --> 01:28:34.840]   120 gigs of RAM
[01:28:34.840 --> 01:28:38.560]   I'm trying to get a ram a hundred bucks more you get more RAM 256
[01:28:38.560 --> 01:28:43.560]   But I love it that I was relieved frankly that they're throwing in the doc because I think this is a good idea
[01:28:43.560 --> 01:28:47.120]   It's a normal, you know Android tablet 11 inches
[01:28:47.560 --> 01:28:49.560]   But with the doc
[01:28:49.560 --> 01:28:54.520]   You know you it becomes like a nest hub, right?
[01:28:54.520 --> 01:29:02.040]   But it doesn't okay. Tell me I was disappointed. Oh good. Tell me what I did wrong. So no you didn't do it
[01:29:02.040 --> 01:29:08.280]   I like I am super confused as to who this tablets for I think that it's an I like I love the doc idea
[01:29:08.280 --> 01:29:11.880]   but I think Google just took it halfway and
[01:29:12.520 --> 01:29:17.640]   It doesn't make sense to me because I think that it doesn't solve that big of a problem
[01:29:17.640 --> 01:29:19.080]   Well, it's always like you know
[01:29:19.080 --> 01:29:23.420]   They made up the problem that you have a tablet but you always forget it put it in the door and then it's not charged
[01:29:23.420 --> 01:29:27.080]   They're never me me me me. So I don't think that's that was a problem
[01:29:27.080 --> 01:29:32.040]   Like when we all got tablets like 10 years ago, but we all figured out that we just have charging stations
[01:29:32.040 --> 01:29:36.360]   I keep my head charged. I absolutely do I have two iPads and I keep it charged
[01:29:36.360 --> 01:29:41.840]   But I also I have to say I have three Google nest hubs two big ones and two little ones
[01:29:41.840 --> 01:29:46.760]   And this will not replace them if what you value in your Google nest hub is
[01:29:46.760 --> 01:29:52.280]   The like all of the thing. Oh, I can't say pay hub
[01:29:52.280 --> 01:29:56.600]   Set a timer for 12 minutes for green beans. I can't do that
[01:29:56.600 --> 01:30:06.120]   When it is in the docking mode if the tablet is there you can oh good, but and I can say turn off the lights because I use it for that
[01:30:07.240 --> 01:30:11.880]   But if someone has your tablet then that's gone well, he's gonna take my damn
[01:30:11.880 --> 01:30:21.400]   So it has hub mode but it only has hub mode when it is it only behaves as a smart home device when it's docked
[01:30:21.400 --> 01:30:23.400]   Well, that's right at least it does that
[01:30:23.400 --> 01:30:28.840]   At well at least but I already have a nest device that does that and it doesn't have a thread radio
[01:30:28.840 --> 01:30:31.640]   Oh the dock itself doesn't have any microphones
[01:30:31.640 --> 01:30:35.680]   So it doesn't do anything like the dog without the tablet is nothing
[01:30:35.680 --> 01:30:40.280]   Right and it doesn't have like it does have ultra wideband
[01:30:40.280 --> 01:30:44.840]   But it's not using solely or anything for like presence detection. It's just doing kind of range stuff
[01:30:44.840 --> 01:30:47.200]   like I just
[01:30:47.200 --> 01:30:56.280]   To me I wanted this to be like a full value smart home device and a tablet because for five hundred dollars. It's a lot and
[01:30:56.280 --> 01:31:02.040]   For the main thing it does not look if you the main thing it does not do is
[01:31:03.640 --> 01:31:10.680]   Act as a smart home device all the time when it's attached when it's not I don't know why it wouldn't why it could be odd
[01:31:10.680 --> 01:31:13.040]   It turns into a tablet
[01:31:13.040 --> 01:31:19.480]   Yeah, so that's just to me. It's like eh, yeah, and that dock becomes completely useless
[01:31:19.480 --> 01:31:26.400]   Like it'd be cool if that dock had a microphone so you could keep issuing voice commands to the dock
[01:31:26.400 --> 01:31:30.960]   Right or it had a thread radio. So it's a border router. Yeah, I don't see why it couldn't
[01:31:31.720 --> 01:31:36.920]   And I don't see why the tablet shouldn't be able to you know work. That's what does I don't get yeah, I agree
[01:31:36.920 --> 01:31:38.680]   Well, that's why I'm disappointed with this
[01:31:38.680 --> 01:31:44.560]   So so that's right and when I asked Google because I was on the briefings for these I was like is this
[01:31:44.560 --> 01:31:50.840]   How does this relate to the nest display products? He's like we don't you know it it does not compete with that
[01:31:50.840 --> 01:31:57.000]   It's a completely different politics the nests are running fuchsia. This is running Android
[01:31:58.040 --> 01:32:01.120]   This is more expensive the you know the nest hub max
[01:32:01.120 --> 01:32:10.860]   Which is admittedly only a seven inch screen is 229 and I have so I'm nest hub to two the bigger one
[01:32:10.860 --> 01:32:15.400]   The max used to be that big speaker. I don't mean the big speaker
[01:32:15.400 --> 01:32:22.240]   I mean the bigger okay that sorry. I'm like no the nest a max was by the names are terrible and I never oh God
[01:32:22.240 --> 01:32:25.640]   I know I hate it. I think it's the second gen nest display is I think
[01:32:26.680 --> 01:32:31.020]   Doesn't have a camera that's in the bedroom and the gym because I don't want anybody see me
[01:32:31.020 --> 01:32:33.760]   lifting weights
[01:32:33.760 --> 01:32:35.760]   Oh, no, there is a nest charge for that
[01:32:35.760 --> 01:32:49.360]   Yeah, the nest hub max so that's the one that's closest, but it's still only a seven inch screen I
[01:32:49.360 --> 01:32:55.320]   Do you know I do things like say because I have YouTube TV so I can say play YouTube TV on it
[01:32:55.320 --> 01:33:00.240]   But having an 11 inch would be a little bit nicer, but it's only 229 and you can't detach it
[01:33:00.240 --> 01:33:04.600]   It's not a tablet and then I have the little ones the nest second gen nest hub that you were talking about
[01:33:04.600 --> 01:33:07.840]   That's as I said, that's in the bedroom of the gym because it doesn't have a camera
[01:33:07.840 --> 01:33:17.200]   Right I you know this will be this this will be this will replace a next nest hub max in the kitchen
[01:33:17.200 --> 01:33:18.160]   I think
[01:33:18.160 --> 01:33:20.160]   Because it'll know no
[01:33:20.640 --> 01:33:26.600]   What is someone streaming movies and has your tablet while you're trying to cook then you're gonna not be able to set up your
[01:33:26.600 --> 01:33:28.700]   Timers plenty of tablets and TV is a
[01:33:28.700 --> 01:33:33.800]   Plenty of ways to watch TV. They're better not a normal person
[01:33:33.800 --> 01:33:39.520]   But I do think having it there like if I wanted to you know, I'm gonna watch TV
[01:33:39.520 --> 01:33:43.520]   I might want to take it and bring it with me so I can I don't know do stuff. I
[01:33:43.520 --> 01:33:45.600]   Don't know
[01:33:45.600 --> 01:33:50.160]   Yeah, you're right. It's probably I mean honestly, I wouldn't have bought it except I want to review it
[01:33:50.160 --> 01:33:52.160]   so I
[01:33:52.160 --> 01:33:57.640]   Just couldn't bring myself to buy the I have a seven so seven pro
[01:33:57.640 --> 01:34:00.840]   I and I feel like I needed a seven a but the seven a is good nice
[01:34:00.840 --> 01:34:05.920]   By the way, this be fine six a now is dropped in price at 120 bucks
[01:34:05.920 --> 01:34:10.040]   So if you were in the market for a six a now, it's even more affordable seven a is
[01:34:10.040 --> 01:34:12.080]   Pretty much
[01:34:12.080 --> 01:34:17.760]   Who was it was saying today that the seven a is getting closer and closer to the seven?
[01:34:18.320 --> 01:34:22.880]   I'll say that in our discord. Yeah today. Yeah, the capabilities are now
[01:34:22.880 --> 01:34:28.000]   You know pretty close to a seven pro and it is half the price and the prices are yeah
[01:34:28.000 --> 01:34:31.800]   So and it comes in what they call coral
[01:34:31.800 --> 01:34:35.320]   But I thought I'd ask you Stacy. What color is that?
[01:34:35.320 --> 01:34:43.120]   I would call that coral. Okay. It's like a pinky red. It's an orangey pinky red salmon
[01:34:43.120 --> 01:34:45.680]   Looks like a fish to me
[01:34:45.680 --> 01:34:48.240]   It's not sock eye
[01:34:48.240 --> 01:34:49.520]   salmon
[01:34:49.520 --> 01:34:51.520]   See you head
[01:34:51.520 --> 01:34:53.280]   charcoal
[01:34:53.280 --> 01:34:55.280]   Or snow
[01:34:55.280 --> 01:34:59.480]   I really hate that coral color. Yeah
[01:34:59.480 --> 01:35:03.720]   Because it's neither it's either this nor that it's cantaloupe
[01:35:03.720 --> 01:35:10.980]   But it's also salmon. This is a commentary on why there's really nothing new with phones when you drive a tunnel a
[01:35:10.980 --> 01:35:18.120]   Huge billboards above it all around yeah all Apple saying we have yellow phones yellow phones. Yeah
[01:35:18.120 --> 01:35:24.040]   What else even when I got when I was in Portugal. It was like all the ads are for yellow iPhones
[01:35:24.040 --> 01:35:27.360]   It is it's sad. Yes, it is
[01:35:27.360 --> 01:35:34.520]   And when they spend seven minutes on the fact that you can generate emoji wallpaper who the hell cares oh
[01:35:34.520 --> 01:35:41.160]   I don't care now. This is meanwhile line 60 Leo is Google's
[01:35:41.160 --> 01:35:44.840]   hip video for the foldable
[01:35:46.120 --> 01:35:50.360]   So Stacy you have the flip you like foldables. I think right I
[01:35:50.360 --> 01:35:57.400]   Mean I probably I don't know if I'd get another foldable and I oh interesting. Why not?
[01:35:57.400 --> 01:36:03.200]   Well cuz the price differential I mean I'm using it because you gave it to me for free and I wanted to play with it
[01:36:03.200 --> 01:36:07.160]   but the price differential is huge on those and
[01:36:07.160 --> 01:36:12.920]   I'm also not a phone stop. I don't really care about my phone. It just needs to work
[01:36:13.120 --> 01:36:19.600]   So I'm not a good man ask I don't I honestly don't think I don't really like the big foldable
[01:36:19.600 --> 01:36:23.960]   I thought the little foldable with had some merit because you can it's small enough you put it a little
[01:36:23.960 --> 01:36:29.360]   It's appealing. It's appealing the big one's just too big and I don't need a 7.2 inch
[01:36:29.360 --> 01:36:36.360]   Screen was it the NBA watch party that you want yes? Yes. Yes. Watch that. Okay. This is for sure gonna take us down
[01:36:36.360 --> 01:36:47.040]   So it's a bunch of basketball do you call them ballers?
[01:36:47.040 --> 01:36:50.320]   No
[01:36:50.320 --> 01:36:59.600]   Excellent
[01:36:59.600 --> 01:37:05.200]   They're not this is not that's the seven do you know they're going to they're going to unfold them. Oh
[01:37:05.960 --> 01:37:08.160]   Yeah, there we go. It's not that big way note
[01:37:08.160 --> 01:37:14.440]   You know first of all bad choice for a basketball player cuz what are basketball players known for big hands?
[01:37:14.440 --> 01:37:16.600]   Yeah, so you makes your phone look small
[01:37:16.600 --> 01:37:19.560]   Because they got massive hands. Yeah
[01:37:19.560 --> 01:37:26.440]   And be you know so that might have been a tactic that maybe what they're trying to do there
[01:37:26.440 --> 01:37:31.560]   I mean cuz like when I see a big phone. I'm like no. Oh, maybe they're trying to hide it that it's a big
[01:37:31.560 --> 01:37:35.840]   No, oh, this is manageable. Hmm. Um
[01:37:35.840 --> 01:37:40.840]   I think split eight. I think 1700 bucks is all is the kind of 800
[01:37:40.840 --> 01:37:42.680]   Is
[01:37:42.680 --> 01:37:44.680]   $1,999, right? Oh, you're right
[01:37:44.680 --> 01:37:51.720]   That's ridiculous. This is a Leo buys things. Oh 99. Yeah, that's why they charge. That's why they make it
[01:37:51.720 --> 01:37:58.080]   $1,999, because Leo's could say $1,700 bucks. It's $1,800 minus a penny
[01:37:58.720 --> 01:38:00.720]   Yeah
[01:38:00.720 --> 01:38:03.240]   It really looks a lot like a Z
[01:38:03.240 --> 01:38:07.160]   Actually, this was a good piece from the verge because they showed the Z fold now
[01:38:07.160 --> 01:38:12.720]   The Z fold has a thigh gap and I didn't I don't like that. Mm-hmm
[01:38:12.720 --> 01:38:19.520]   But I put mine in a case so you can't see the thigh gap Google to their credit. We please not call it a thigh gap
[01:38:19.520 --> 01:38:22.000]   just for so many reasons
[01:38:22.000 --> 01:38:25.600]   It's gross
[01:38:26.440 --> 01:38:33.200]   It's also a little offensive. Yeah, okay. Yeah. No, thank you. What what do you propose a butthole?
[01:38:33.200 --> 01:38:41.280]   It's called a gap dude. He's working too long speaking of buttholes by the way. I told you punchy
[01:38:41.280 --> 01:38:44.840]   No, this is a I think a reasonable
[01:38:44.840 --> 01:38:49.360]   commentary on the new logo for Google Assistant
[01:38:49.360 --> 01:38:52.200]   Have you seen it? I?
[01:38:52.200 --> 01:38:55.680]   Don't recall. I don't like where this is going at all
[01:38:55.680 --> 01:38:57.680]   I don't need to watch out
[01:38:57.680 --> 01:39:02.840]   Yeah, the studio get the punchy thing ready
[01:39:02.840 --> 01:39:11.720]   Let me see if I can find it because they they've changed the light the logo. Let me see
[01:39:11.720 --> 01:39:22.040]   Maybe if I search for it I'm gonna logo butthole it'll come right up and it does
[01:39:22.160 --> 01:39:24.160]   Wow
[01:39:24.160 --> 01:39:31.360]   They may oh, it's the authenticator. Sorry. So the original authenticator nice. It looks like a safe right? It's got bolts
[01:39:31.360 --> 01:39:34.920]   The new one I
[01:39:34.920 --> 01:39:40.600]   Guess you think it looks it's it's sphincter ish
[01:39:40.600 --> 01:39:44.320]   Man
[01:39:44.320 --> 01:39:47.360]   Reach come on. Yeah, that's an asterisk
[01:39:48.000 --> 01:39:53.800]   You know what this is why I shouldn't get my in for my material from Twitter. Yeah
[01:39:53.800 --> 01:39:56.360]   Yeah, that's becoming
[01:39:56.360 --> 01:39:59.080]   That was my error. Yeah apologies everyone
[01:39:59.080 --> 01:40:01.960]   So let's see what else the fold
[01:40:01.960 --> 01:40:11.240]   You know to their credit the pixel is doesn't have a gap of any kind it looks nice and thin they say it's thinner in fact
[01:40:11.240 --> 01:40:13.640]   the fold
[01:40:13.640 --> 01:40:16.800]   It's funny talking to hardhead this morning about it
[01:40:17.440 --> 01:40:22.480]   He says that phone looks nice, but man, that's thick and I had to explain to him
[01:40:22.480 --> 01:40:25.280]   I said dude you not played with phones long enough
[01:40:25.280 --> 01:40:31.280]   That's actually pretty much what phones used to be like anyway far as that thickness goes and that's not very thick
[01:40:31.280 --> 01:40:38.920]   But yeah, but I would they show it to us on the the whatever it was the press briefing
[01:40:38.920 --> 01:40:42.680]   It was real impressive like I was like
[01:40:44.920 --> 01:40:47.360]   Yeah, so you handle it
[01:40:47.360 --> 01:40:53.840]   No, no, no, it was a virtual it was like a zoom press briefing. It is a higher screen resolution slightly
[01:40:53.840 --> 01:40:58.280]   2208 by 1840 that's a little higher than the Z fold for
[01:40:58.280 --> 01:41:01.120]   How much is it way
[01:41:01.120 --> 01:41:02.320]   It weighs
[01:41:02.320 --> 01:41:07.680]   Two hundred floppy wrist contingent wants to know about ten ounces, which is not super heavy
[01:41:07.680 --> 01:41:14.480]   It's a little more it is more than the galaxy fold also bigger battery, which is good and and it has you know
[01:41:14.480 --> 01:41:16.480]   It's funny because Apple gets so much
[01:41:16.480 --> 01:41:21.520]   Material so much mileage out of the fact they make their own processors and the you know
[01:41:21.520 --> 01:41:24.720]   We got our a4 a15 and we've got the m1
[01:41:24.720 --> 01:41:29.800]   Google's been making their own processors in the since the pixels 7 right and it's the tensor g2
[01:41:29.800 --> 01:41:36.260]   Which is I think a pretty good chip, but they don't get the they don't get the love for it 12 gigs of RAM
[01:41:36.260 --> 01:41:37.880]   and
[01:41:37.880 --> 01:41:43.760]   Yeah, running a desktop computers and laptops the way Apple is doing it with all the do stuff
[01:41:43.760 --> 01:41:48.360]   Right, but I think it's as comp as as as as powerful. I don't know I think it is
[01:41:48.360 --> 01:41:56.800]   Camera, you know, it's a Google camera. So it's probably pretty good probably comparable to the Samsung the fold camera is very good. I think
[01:41:56.800 --> 01:42:00.640]   Does not have 8k video recording fold does
[01:42:00.640 --> 01:42:06.160]   It's got a fingerprint scanner in the power button. I like that. That was a good choice
[01:42:06.160 --> 01:42:10.160]   It does have face ID with your face unlock, which the fold does not
[01:42:11.440 --> 01:42:14.360]   millimeter wave and sub six gigahertz Stacy says
[01:42:14.360 --> 01:42:16.480]   Thumbs up, right?
[01:42:16.480 --> 01:42:19.020]   Wi-Fi 6E that's good
[01:42:19.020 --> 01:42:25.160]   No stylus. Yeah for a phone. Yeah, and both of both 1799 99
[01:42:25.160 --> 01:42:28.400]   It's the same stuff. I have a stylus. Yes
[01:42:28.400 --> 01:42:32.360]   The same size of the pixel tablet didn't have a stylus. Oh
[01:42:32.360 --> 01:42:37.660]   It doesn't they didn't mention a stylus. Did they? No, it actually doesn't someone asked it
[01:42:37.660 --> 01:42:43.740]   It is interesting or it just feels like a half-assed tablet. Yeah, which is what every Android tablet
[01:42:43.740 --> 01:42:49.900]   Well, certainly every pixel tablet has felt like I guess people like the Samsung Galaxy Note tablet
[01:42:49.900 --> 01:42:57.580]   Anyway, pixel fold onto when did you get your briefing? You you were all up on this already may first
[01:42:57.580 --> 01:43:02.420]   May first Wow, I was still in Italy
[01:43:02.420 --> 01:43:04.420]   No
[01:43:04.420 --> 01:43:08.740]   Share with us
[01:43:08.740 --> 01:43:16.980]   With your secrets I presume you were you were in D. A. Don't I?
[01:43:16.980 --> 01:43:23.940]   Only doing barcodes. I don't do it days, but I was under a bar go so you couldn't break in bars. You could have told us
[01:43:23.940 --> 01:43:27.140]   Yeah, you could have
[01:43:30.500 --> 01:43:33.100]   Also, I try to keep my word. I mean
[01:43:33.100 --> 01:43:40.740]   Break in embargo in an NDA bargo just means you can't write about a time midnight Tuesday or whatever, right?
[01:43:40.740 --> 01:43:47.140]   Yeah, and India is like legally I am bargain. I know is like a promise
[01:43:47.140 --> 01:43:55.360]   I might into for instance an embargo you could intimate. Yeah, I've seen it. I'll have an article on Tuesday, right?
[01:43:56.020 --> 01:44:00.860]   That wouldn't you are allowed to say you're under like I even said it last week
[01:44:00.860 --> 01:44:06.780]   I said I was under embargo for some of this stuff. Did she I missed that? Oh, well, I would have pressed you don't listen to me
[01:44:06.780 --> 01:44:08.780]   I would have pressed you hard
[01:44:08.780 --> 01:44:14.940]   One of the things Google mentioned is that and this is I think gonna be interesting
[01:44:14.940 --> 01:44:18.580]   I wish I could go to Ohio to do it Wendy's is gonna use
[01:44:18.580 --> 01:44:20.500]   Google's
[01:44:20.500 --> 01:44:27.060]   Bard as an order taker. They're gonna try it out first. Yeah in a Columbus Wendy's
[01:44:27.060 --> 01:44:33.740]   They say it's gonna shorten the lines. I think it's gonna make them longer
[01:44:33.740 --> 01:44:39.660]   Good God. It's not I have you ever met a chat that is not
[01:44:39.660 --> 01:44:42.580]   loquacious
[01:44:42.580 --> 01:44:45.980]   Maybe it'll be trained on short people like are people who are
[01:44:47.180 --> 01:44:51.980]   People it'll be very people. This is all right. I'll just tell you what the Wall Street Journal Road
[01:44:51.980 --> 01:44:56.100]   Mr. Pentagon, whoever he is says it'll be very conversational
[01:44:56.100 --> 01:45:04.340]   No, you won't know you're talking to anybody but an employee effect Wendy's mistakenly said it's smarter than our place
[01:45:04.340 --> 01:45:11.180]   Boy, oh I'd like a lemonade with no ice. Yes. Yeah lemonade is very nice. Yeah
[01:45:11.180 --> 01:45:16.380]   No, no, because they're doing a customized language model that understands. There's cars. There's noise
[01:45:16.500 --> 01:45:22.900]   There's kids in the back seat. They're gonna filter all the TikToks of Wendy's. Oh, I can't wait. Oh, man
[01:45:22.900 --> 01:45:24.220]   Tiktokers
[01:45:24.220 --> 01:45:27.020]   Converge on Columbus. We need to see this
[01:45:27.020 --> 01:45:34.100]   They when these customized language includes unique phrases Wendy's customers apparently use now
[01:45:34.100 --> 01:45:40.300]   I've been to a Wendy's I've never called it a JBC. Oh my gosh for a junior bacon cheeseburger
[01:45:40.300 --> 01:45:45.420]   I've actually heard some of those. Have you you know what a biggie bag is JB
[01:45:45.420 --> 01:45:47.420]   Yeah, I've heard I've heard those phrases
[01:45:47.420 --> 01:45:57.420]   A teenager or three running around so I actually like Wendy's the hamburgers are square. Yes, give me bacon nader all day
[01:45:57.420 --> 01:46:01.860]   Yeah, Wendy's no spicy grilled cheese salmon or spiky spicy
[01:46:01.860 --> 01:46:08.100]   Yeah, chicken sandwich. That's my goat. Oh, yeah, I love that. I was a much better chicken salad. Yeah
[01:46:08.100 --> 01:46:11.820]   For chicken
[01:46:13.820 --> 01:46:19.540]   When these causes milkshakes frosties, but the chat has to understand milkshake and frosty. Oh, no
[01:46:19.540 --> 01:46:24.940]   You may Thomas Curry and CEO of Google Cloud
[01:46:24.940 --> 01:46:29.900]   You may think driving by and speaking into a drive-through is an easy problem for AI
[01:46:29.900 --> 01:46:35.020]   But it's actually one of the hardest I believe that a lot of challenges noise
[01:46:35.020 --> 01:46:37.020]   Oh
[01:46:37.020 --> 01:46:48.140]   They have the upsell built-in
[01:46:48.140 --> 01:46:54.700]   The upsell is built-in kids. Oh, no, of course. They do was that a super large? Yeah
[01:46:54.700 --> 01:46:59.180]   Would you like a milkshake with F sorry frosty? How about a biggie bag?
[01:47:00.340 --> 01:47:03.900]   It says least this is the this is when he's CIO
[01:47:03.900 --> 01:47:11.460]   Kevin Vasconi says it's as least as good as our best customer service representative and it's probably on average bitter
[01:47:11.460 --> 01:47:17.220]   In the mail
[01:47:17.220 --> 01:47:26.380]   Yeah, he must he must actually eat it Wendy's I don't know 80% of food orders at Wendy's are made in the drive-through
[01:47:26.380 --> 01:47:28.380]   Have you ever been in a Wendy's?
[01:47:29.620 --> 01:47:30.860]   Yes
[01:47:30.860 --> 01:47:36.420]   Now you know, yes one of my kids were little yeah, that's one of you know, it's a it would be variety for me
[01:47:36.420 --> 01:47:38.140]   Instead of working
[01:47:38.140 --> 01:47:43.240]   Honestly, I typically go inside of these places because it's usually faster
[01:47:43.240 --> 01:47:46.500]   It is well and that's the whole problem. They're trying to solve us
[01:47:46.500 --> 01:47:50.540]   They want it it says the order grows correctly to the chef
[01:47:50.540 --> 01:47:57.820]   Say it was straight face say it was straight face we better get
[01:47:57.820 --> 01:47:59.820]   Okay
[01:47:59.820 --> 01:48:13.260]   Well we'll find out it'll be in Columbus, Ohio in June, please tick tockers
[01:48:13.260 --> 01:48:16.620]   fill us in
[01:48:16.620 --> 01:48:23.820]   All right other in other is there anything else from I we mentioned the 7a we mentioned the
[01:48:24.220 --> 01:48:28.460]   Set for my own that's a by the way if you get that 1799 99 phone
[01:48:28.460 --> 01:48:31.980]   You'll get a free pixel watch in with every
[01:48:31.980 --> 01:48:38.380]   That's not a pixel watch on your wrist. Yeah, no, you're right. This is the good one. Yeah
[01:48:38.380 --> 01:48:45.340]   Hey, you said the 6a was marked down. What was it marked down to I thought I saw
[01:48:45.340 --> 01:48:47.100]   49
[01:48:47.100 --> 01:48:50.220]   No 49 is the 7a. I think I saw a 6a
[01:48:50.220 --> 01:48:55.260]   I want to say 329 I saw but look I can do it for you. I'm a member
[01:48:55.260 --> 01:49:04.100]   Tux I'm not only a hair 3 99. I'm only the president of the hair club before tonight. I'm also a client
[01:49:04.100 --> 01:49:07.580]   349 okay
[01:49:07.580 --> 01:49:14.260]   That I think is a good price for a great phone. Yep, that's probably the sweet spot to be honest
[01:49:14.260 --> 01:49:20.100]   Oh, you can buy you can buy a 6a at best buy for three or 299, but it's only 128 gigs
[01:49:20.100 --> 01:49:27.140]   It's subsidized though. That's all I would need you have to probably have to sign up with 18. No best buys is unlocked. Oh nice. Okay
[01:49:27.140 --> 01:49:31.620]   Now we're talking maybe maybe it's the color. Oh
[01:49:31.620 --> 01:49:34.900]   Yeah, cuz don't
[01:49:34.900 --> 01:49:42.660]   Oh, no, you can get charcoal. It doesn't have to be sage green. Perfect. Is this for queen pruit or you? No, I'm considering another phone
[01:49:43.940 --> 01:49:48.260]   But it's only 128 gigs. Is that okay for you? Yeah, that's what photo man. Gee
[01:49:48.260 --> 01:49:54.900]   I'll tell you this right now. I don't keep all of my photos on my phone right now. So you he crazy people do
[01:49:54.900 --> 01:50:04.420]   All we need is a hundred people to join club to it right now and amp-pruit can have a pixel fold ladies and gentlemen
[01:50:04.420 --> 01:50:09.220]   All right, 100 people sign on 100 people sign up before the end of this show
[01:50:10.340 --> 01:50:13.620]   Amp-pruit gets a new phone. How about that? How about that?
[01:50:13.620 --> 01:50:18.340]   100 people are still listening this far end. That's the miracle. Oh, please
[01:50:18.340 --> 01:50:23.460]   It's not we've only been going for an hour 48. You want to get to your cat your puppy. All right quickly
[01:50:23.460 --> 01:50:28.740]   No, no, no, no somewhat somewhat related to google and all that it's not part of my own you may just blow me off
[01:50:28.740 --> 01:50:30.260]   and that's okay
[01:50:30.260 --> 01:50:31.860]   but um
[01:50:31.860 --> 01:50:33.860]   You have the secret sauce memo
[01:50:33.860 --> 01:50:36.340]   And then related to that is google
[01:50:36.340 --> 01:50:41.460]   A story of the washing post about how google was sharing its AI knowledge with the world until chat
[01:50:41.460 --> 01:50:47.060]   CPT cable long and the fewer and how it's kind of locking down. It's not as open as it was
[01:50:47.060 --> 01:50:48.420]   Yeah
[01:50:48.420 --> 01:50:51.940]   And and is google so special that memo was really interesting. It was a leaked
[01:50:51.940 --> 01:50:58.340]   Um, not memo but late post on internal internal discussion the one that says we have no more sauce here
[01:50:58.340 --> 01:51:03.860]   We have no moat, but neither does open AI that one. Yeah. Yeah, I thought it was interesting. Yeah
[01:51:04.900 --> 01:51:09.060]   Um, they're worried we know they were worried that open AI would out compete google
[01:51:09.060 --> 01:51:13.380]   Um, but the document actually said the real fear
[01:51:13.380 --> 01:51:16.740]   The real threat is not microsoft
[01:51:16.740 --> 01:51:19.700]   Or anthropic it's open source
[01:51:19.700 --> 01:51:25.940]   And if you think about it look at stable diffusion and how quickly stable diffusion went from zero to 60 in a couple weeks
[01:51:25.940 --> 01:51:29.780]   It was open source because everybody could run it on their own machine, right?
[01:51:30.260 --> 01:51:35.620]   Right. So I think that's uh an interesting point sooner per try did make the point that we're you know
[01:51:35.620 --> 01:51:39.700]   They had a bunch of names for their there was image and code image
[01:51:39.700 --> 01:51:41.060]   herb
[01:51:41.060 --> 01:51:43.060]   Gecko unicorn
[01:51:43.060 --> 01:51:51.380]   There were a bunch of animals right the uh, the animals were like well we can put a model on your phone that was the gecko
[01:51:51.380 --> 01:51:56.260]   Um, right. Yes, and the and the unicorn was the biggest right
[01:51:58.740 --> 01:52:01.060]   Well, I don't think unicorns are generally big
[01:52:01.060 --> 01:52:07.860]   No, I think unicorns are hard to get to and maybe that's it takes a virgin to sit in a voice
[01:52:07.860 --> 01:52:12.340]   I thought they were magical they're magical and unbelievable and they don't exist not real
[01:52:12.340 --> 01:52:15.140]   What the heck is the unicorn and not real?
[01:52:15.140 --> 01:52:20.900]   Uh, UFO hunters have built this is all the uh, this week in AI actually let's do it
[01:52:20.900 --> 01:52:28.340]   Um unicorn. I'm sorry UFO hunters might as well be unicorn hunters are doing an open source
[01:52:28.820 --> 01:52:33.140]   AI systems scan the sky is perfect example right sky 360
[01:52:33.140 --> 01:52:38.100]   Is a worldwide network of automated cameras see there's so many cameras now out there
[01:52:38.100 --> 01:52:40.820]   watching for
[01:52:40.820 --> 01:52:42.820]   UFOs
[01:52:42.820 --> 01:52:48.340]   Because they don't think they don't believe the air force and the federal government
[01:52:48.340 --> 01:52:51.780]   Uh that you know, they think they're sitting on this so
[01:52:51.780 --> 01:52:54.180]   uh
[01:52:54.180 --> 01:52:58.020]   They're good. They said we're gonna do our own research and we're gonna see if we can find
[01:52:58.500 --> 01:53:00.820]   Some UFOs wonder how many of those those
[01:53:00.820 --> 01:53:02.900]   uh
[01:53:02.900 --> 01:53:04.660]   cameras return
[01:53:04.660 --> 01:53:10.740]   Skylink was what starlink skylink whatever. Yeah. Yeah, when if it how many times that pops up in the result
[01:53:10.740 --> 01:53:13.380]   Yeah, all you gotta just another 30,000
[01:53:13.380 --> 01:53:17.940]   The astronomy uh the astronomy subreddit on reddit
[01:53:17.940 --> 01:53:23.220]   Uh one of the moderators said we need some automation so that every time somebody posts
[01:53:23.300 --> 01:53:30.660]   What was that weird link of list 60 straight line uh satellite lights up there? That's a UFO
[01:53:30.660 --> 01:53:34.100]   No, no, it's starlink. They need an automate that one because it happens every time
[01:53:34.100 --> 01:53:37.540]   Uh the sky 360 stations if you want to get involved
[01:53:37.540 --> 01:53:42.100]   Consistive in all sky cam and has a wide angle fish islands
[01:53:42.100 --> 01:53:44.660]   with a pan tilt focus
[01:53:44.660 --> 01:53:50.420]   And the fish eye registers all movement under relying software performs initial rough analysis
[01:53:51.220 --> 01:53:54.340]   Of whatever is going on decides whether to activate the other sense
[01:53:54.340 --> 01:53:56.340]   Sensors
[01:53:56.340 --> 01:54:01.620]   And then the pan tilt focus zooms in on the object attracts it further analyzes it
[01:54:01.620 --> 01:54:07.220]   So there's a lot of computer vision involved in them. That's awesome. Yeah, then they have a discord server
[01:54:07.220 --> 01:54:12.660]   So far 20 people have set up stations from the us to canada to the a-zores in the middle of the atlantic
[01:54:12.660 --> 01:54:15.140]   They'd like to get many many more
[01:54:15.140 --> 01:54:20.580]   Uh, yeah, I think this is awesome. What are they gonna find out? Well?
[01:54:21.380 --> 01:54:23.380]   Chinese balloons. Yeah, something
[01:54:23.380 --> 01:54:26.500]   But here's a map actually they've got quite a few
[01:54:26.500 --> 01:54:28.820]   out there
[01:54:28.820 --> 01:54:33.860]   Uh once enough of the sky 360 stations have been deployed the next step is to work toward
[01:54:33.860 --> 01:54:37.940]   Real-time monitoring drawing all the data together and analyzing it
[01:54:37.940 --> 01:54:42.180]   30 volunteer developers working on the software. It's open source
[01:54:42.180 --> 01:54:44.420]   um
[01:54:44.420 --> 01:54:46.420]   So that's yeah, I think that's cool
[01:54:46.420 --> 01:54:49.220]   That's a good use of AI
[01:54:49.220 --> 01:54:50.500]   Spotify says
[01:54:50.500 --> 01:54:56.100]   Making musics a bad use of AI they have ejected thousands of AI made songs
[01:54:56.100 --> 01:55:02.100]   They're purging fake streams and purging record labels like boomy
[01:55:02.100 --> 01:55:09.060]   Which are designed to upload AI you can make a lot of money if you can you know get the right seo
[01:55:09.060 --> 01:55:11.060]   Some people might like it. Why do they take it down?
[01:55:11.060 --> 01:55:15.620]   A boomy has uploaded the equivalent of tens of thousands of songs
[01:55:15.620 --> 01:55:18.340]   That's a lot for the store. Yeah
[01:55:18.660 --> 01:55:20.900]   Uh-huh, you know nobody's doing it
[01:55:20.900 --> 01:55:28.820]   It's got to be automatic boomy says oh no our users have done this they've created more than 14 million
[01:55:28.820 --> 01:55:31.700]   songs
[01:55:31.700 --> 01:55:33.700]   Get ready. It's like
[01:55:33.700 --> 01:55:37.380]   I would give people mad at me this but AI could make techno
[01:55:37.380 --> 01:55:45.540]   As easy as pie. Yeah, techno easy. It sounds like a I made yeah humans have to dumb themselves down to make EDM
[01:55:47.540 --> 01:55:50.340]   I'm sorry. We sound like old men don't wait. You like you
[01:55:50.340 --> 01:55:58.660]   I it's fun to dance too. Stop dancing to that synthetic music you young people need a listen to rock and roll
[01:55:58.660 --> 01:56:02.500]   Oh
[01:56:02.500 --> 01:56:05.860]   All right, let's let's get you going here because um
[01:56:05.860 --> 01:56:09.060]   You're just getting
[01:56:09.060 --> 01:56:10.420]   Man
[01:56:10.420 --> 01:56:12.820]   Parsons, you know Parsons school of design
[01:56:12.820 --> 01:56:16.420]   That's where price is right away started right Tim Gunn and all that
[01:56:16.900 --> 01:56:18.900]   Well, it's known for other things in that but go ahead
[01:56:18.900 --> 01:56:27.540]   It's a well-known fashion institute, right? Yes, it is. They have a class now. Uh, they're doing it in
[01:56:27.540 --> 01:56:30.340]   partnership with roblox
[01:56:30.340 --> 01:56:35.460]   To do an avatar clothing design course is called collab roblox
[01:56:35.460 --> 01:56:37.700]   Uh
[01:56:37.700 --> 01:56:42.980]   And they say everything's a collab these days. Yeah, our students our students want to design
[01:56:42.980 --> 01:56:46.260]   Not clothes for gucci and laren
[01:56:47.060 --> 01:56:48.660]   and burberry but
[01:56:48.660 --> 01:56:50.260]   her roblox
[01:56:50.260 --> 01:56:51.780]   and actually
[01:56:51.780 --> 01:56:56.340]   Gucci ralph florin and burberry all have roblox versions of their clothing
[01:56:56.340 --> 01:57:01.700]   So maybe there's a big business prices range from 50 roebox
[01:57:01.700 --> 01:57:06.820]   But did they mention nft's in this because I want to say that was a part of the hustle
[01:57:06.820 --> 01:57:08.580]   um
[01:57:08.580 --> 01:57:16.180]   Discussion last year year before now we've moved on to ai avatar design. I don't know
[01:57:17.060 --> 01:57:19.060]   Anyway, it's a three-hour weekly course
[01:57:19.060 --> 01:57:21.780]   for credit
[01:57:21.780 --> 01:57:25.140]   But there is a catch roblox gets 30% of every
[01:57:25.140 --> 01:57:29.140]   Every there is a catch
[01:57:29.140 --> 01:57:32.180]   Uh, you gotta be careful
[01:57:32.180 --> 01:57:35.700]   Businesses business knots can't be sexy because we got kids on here
[01:57:35.700 --> 01:57:41.700]   Uh one student tried to make a digital corset for an avatar got a rote warning from roblox
[01:57:41.780 --> 01:57:44.820]   We do not permit sexual content of any kind
[01:57:44.820 --> 01:57:46.740]   corset is sexual
[01:57:46.740 --> 01:57:51.300]   Corsets are there's a the corset sweatshirt is like one of the most like
[01:57:51.300 --> 01:57:53.460]   like
[01:57:53.460 --> 01:57:54.740]   I don't know
[01:57:54.740 --> 01:57:59.220]   High fashion designs or street fashion designs right now. Corsets aren't sexy
[01:57:59.220 --> 01:58:05.460]   How about anything candy sexy, but I think you might like this Stacy a bubblegum pink crop top with a heart cut out across the front
[01:58:05.460 --> 01:58:08.340]   And a gravity defying puffy sleeves
[01:58:08.340 --> 01:58:10.980]   Oh, okay
[01:58:11.700 --> 01:58:12.900]   You know, shame felt
[01:58:12.900 --> 01:58:16.260]   Parson student lea malendez designed that
[01:58:16.260 --> 01:58:17.940]   Uh
[01:58:17.940 --> 01:58:20.580]   Digital fashion has taken way more seriously now
[01:58:20.580 --> 01:58:26.180]   In real life the sleeves had fallen down the arms, but in roblox you don't have to worry about that
[01:58:26.180 --> 01:58:33.060]   There's a lot of stories. Let me run through these here. I got more too. I got a few more
[01:58:33.060 --> 01:58:38.660]   Defcon this year will be we'll have you know in the past they had for instance the uh, the uh,
[01:58:39.460 --> 01:58:41.460]   digital election machine
[01:58:41.460 --> 01:58:48.420]   Uh, alley or village. I guess they call it where hackers could try to hack election machines this year
[01:58:48.420 --> 01:58:52.820]   They're gonna have an ai village where hackers will be invited. Did I do this last week?
[01:58:52.820 --> 01:58:55.860]   I feel sorry. No. Oh, I did it on twit. That's why
[01:58:55.860 --> 01:58:58.180]   Uh, they're gonna hack
[01:58:58.180 --> 01:59:02.820]   Large language models built by open ai google and anthropic. There's anthropic again
[01:59:02.820 --> 01:59:08.580]   They got a good pr company. I don't know. Who that'll be august tenths through thirteenth
[01:59:09.060 --> 01:59:11.060]   And they expect around thropic
[01:59:11.060 --> 01:59:18.340]   Well in the ancient greek, it's a take off the word at throwpours and throwpots on throp
[01:59:18.340 --> 01:59:26.580]   Socrates was a man all men are Socrates therefore
[01:59:26.580 --> 01:59:29.700]   I don't know
[01:59:29.700 --> 01:59:32.340]   Fortnite is now an olympic e-sports
[01:59:32.340 --> 01:59:38.420]   What the olympics are adding uh, we're looking at anyway e-sports
[01:59:39.300 --> 01:59:44.660]   Oh, you're kidding me no olympics. Well, it won't be in the money money money money money
[01:59:44.660 --> 01:59:46.580]   It won't be in the official olympics yet
[01:59:46.580 --> 01:59:50.020]   Those are going to be in paris next year this year
[01:59:50.020 --> 01:59:57.140]   Uh, the 12 top players from the fortnite champions sheep series will uh go to singapore
[01:59:57.140 --> 01:59:59.620]   23rd to 25th of june
[01:59:59.620 --> 02:00:07.220]   Uh to join uh players in other sports archery baseball cycling sailing tyke wondo and tennis also chess but not real
[02:00:07.860 --> 02:00:09.860]   Uh online, right?
[02:00:09.860 --> 02:00:14.340]   The dance event will be just dance the racing event will be grand to rismo
[02:00:14.340 --> 02:00:19.460]   Archery will be replicated by a smartphone game called tick-tack bow
[02:00:19.460 --> 02:00:28.180]   Which combines the traditional classic pen and paper game knots and crosses with archery
[02:00:28.180 --> 02:00:30.100]   So that's got to be fun
[02:00:30.100 --> 02:00:34.100]   But the weird thing is for the longest time the IOC said no no no no shooters
[02:00:34.660 --> 02:00:39.060]   But uh, they say fortnite's okay. It's a family friendly shooter
[02:00:39.060 --> 02:00:44.740]   They have biaathletes man. Yeah, they shoot people literally ski and shoot. Yeah
[02:00:44.740 --> 02:00:51.300]   Anyway, so we'll watch watch for that olympic event. It's not yet officially you're not going to get a gold
[02:00:51.300 --> 02:00:57.460]   Metal or anything, but you know what in four more years. Who knows you get you get a fake virtual gold medal. Yeah virtual gold medal
[02:00:57.460 --> 02:01:02.020]   Uh kind of bad news, but we'll see the maybe they'll you know the other shoe will drop
[02:01:02.020 --> 02:01:06.500]   But a judge has dismissed the ftc lawsuit against court chava
[02:01:06.500 --> 02:01:09.780]   Or kochava, which is a data broker
[02:01:09.780 --> 02:01:17.060]   They were selling location information from smartphones the ftc's not the great track record here in core
[02:01:17.060 --> 02:01:25.380]   This is bad news the company collects more than 90 location data points a day from about 35 million active mobile device users
[02:01:25.380 --> 02:01:31.380]   Uh, the location coordinates can reveal where each mobile device has been approximately every 15 minutes
[02:01:31.940 --> 02:01:34.340]   Uh, the ftc filed a complaint last august
[02:01:34.340 --> 02:01:40.420]   Saying that the sale of geo location data on tens of millions of smartphones could be used to track people's visits
[02:01:40.420 --> 02:01:43.700]   To private locations like churches synagogues mosques
[02:01:43.700 --> 02:01:52.180]   abortion clinics domestic violence shelters medical centers and homeless shelters the judge didn't completely
[02:01:52.180 --> 02:01:57.540]   Throw it out. It was the united states district court for idaho
[02:01:58.900 --> 02:02:06.900]   The judge said uh the agency's claim that kochava's sale of location data was a severe intrusion on customers privacy
[02:02:06.900 --> 02:02:12.420]   And that amounted to injury the judge said no no injury here
[02:02:12.420 --> 02:02:15.060]   ah
[02:02:15.060 --> 02:02:16.420]   Uh
[02:02:16.420 --> 02:02:18.420]   But
[02:02:18.420 --> 02:02:22.260]   Uh kind of gave the ftc a way forward
[02:02:22.260 --> 02:02:25.300]   By saying you got a show
[02:02:25.300 --> 02:02:27.860]   Where there's where there's harm
[02:02:28.020 --> 02:02:34.420]   So privacy harms are really hard to prove. This is one of the big issues. I have a real yeah anyway, yeah
[02:02:34.420 --> 02:02:38.020]   Keep going
[02:02:38.020 --> 02:02:40.820]   Keep going moving right along
[02:02:40.820 --> 02:02:42.740]   and uh
[02:02:42.740 --> 02:02:45.060]   I thought this was very weird microsoft
[02:02:45.060 --> 02:02:52.340]   Has signed a deal to use fusion energy to power its operations by 2028
[02:02:53.940 --> 02:02:55.940]   The reason I think that's weird
[02:02:55.940 --> 02:03:00.900]   Is there's no such thing as fusion energy, uh right? Somebody sold about it
[02:03:00.900 --> 02:03:07.860]   Yeah bridge to or this could be kind of a way a kind of say look we're gonna we're planning on being carbon neutral
[02:03:07.860 --> 02:03:10.820]   It's just this fusion thing. They got to figure this out
[02:03:10.820 --> 02:03:16.900]   The car they have signed a deal with fusion energy company helion energy
[02:03:16.900 --> 02:03:21.460]   To purchase electricity from their first ever fusion power plant
[02:03:21.860 --> 02:03:28.660]   The company says the fusion plant is slated to begin producing 50 megawatts of clean energy starting in five years
[02:03:28.660 --> 02:03:31.540]   distributed by energy company
[02:03:31.540 --> 02:03:33.300]   constellation
[02:03:33.300 --> 02:03:35.540]   Only some you know a little small
[02:03:35.540 --> 02:03:43.460]   Issue is you know, they haven't figured out how to create fusion energy without spending more energy to generate it then it generates
[02:03:43.460 --> 02:03:49.220]   But there've been a couple experiments lately that have that have maybe shown that possible
[02:03:50.020 --> 02:03:52.900]   So if they're doing magneto inertial fusion
[02:03:52.900 --> 02:03:56.260]   How is that of the i-story?
[02:03:56.260 --> 02:03:59.780]   Oh, I finished the ai segment. Yeah, that's long ago, sir. Where you been?
[02:03:59.780 --> 02:04:05.220]   I'm doing i'm trying to run through all because I want to get out of here
[02:04:05.220 --> 02:04:08.020]   I'm trying to run through with the the rest of the stories here
[02:04:08.020 --> 02:04:14.420]   You saw the amp story. They quoted Richard gingris. They said and me too and you how to google
[02:04:14.420 --> 02:04:17.540]   tried to fix the web by taking it over
[02:04:19.620 --> 02:04:22.260]   The story titled speed trap appeared in the verge
[02:04:22.260 --> 02:04:29.060]   Google promised to create a better faster web for media companies with the new standard called amp in the end it ruined the trust
[02:04:29.060 --> 02:04:38.260]   Publishers had in the internet giant. I sure you disagree with that premise. Well, I have a I have a thread online 69 about this and
[02:04:38.260 --> 02:04:41.460]   No, publishers are it could be jerks too
[02:04:41.460 --> 02:04:44.660]   But I think google made some fundamental mistakes when this came up in finland
[02:04:44.740 --> 02:04:51.860]   Quotes be being finland raising this and the need for what was a portable newspaper where newspaper content could
[02:04:51.860 --> 02:04:55.220]   Travel with this business model attached which is the original idea I had
[02:04:55.220 --> 02:04:57.620]   um
[02:04:57.620 --> 02:05:02.740]   The one google executive who was at the newsguys didn't finland said you know nobody's got trust google to do this
[02:05:02.740 --> 02:05:08.900]   That's pretty much what came out and google I think messed up in three critical quick ways
[02:05:08.900 --> 02:05:10.580]   One
[02:05:10.580 --> 02:05:16.020]   They cashed it themselves. I'm ready. I thought they were building a walled garden and they did the cash for speed and they shouldn't have done it themselves
[02:05:16.020 --> 02:05:19.940]   too, they didn't pass it off to um
[02:05:19.940 --> 02:05:24.580]   Be truly open source with open source governance soon enough
[02:05:24.580 --> 02:05:27.300]   And I forget where the third one was
[02:05:27.300 --> 02:05:33.140]   Um, but they just made some fundamental mistakes. I think a little I know and that they they said oh
[02:05:33.140 --> 02:05:39.460]   If you're if you're if you're pages as fast as amp not necessarily amp but fast as amp then you'll get into the news carousel
[02:05:39.460 --> 02:05:45.540]   But everybody saw that as bribery to use amp so it pissed off publishers who are an easy block to piss off anyway
[02:05:45.540 --> 02:05:47.300]   and um
[02:05:47.300 --> 02:05:50.980]   They kind of ruined it the truth remains the reason this came up
[02:05:50.980 --> 02:05:56.420]   The reason that google did it the reason that david bezbrus built it is because publishers have screwed up the web
[02:05:56.420 --> 02:06:02.820]   We've made it slow and ugly and filled with promotions and filled with crap and that's still the case
[02:06:02.820 --> 02:06:05.940]   Which is too bad. It's funny because they blame you
[02:06:05.940 --> 02:06:12.740]   The verage says in may 2015 at the first newsgeist europe
[02:06:12.740 --> 02:06:20.740]   Jarvis spent time at the conference arguing for someone presumably google to build a better alternative to instant articles
[02:06:20.740 --> 02:06:28.420]   Which he said is books. Yeah, it was a useful technical prototype with all the wrong attributes an open version essentially of instant articles
[02:06:28.420 --> 02:06:34.180]   So pierce got the story right he got the sequence very right here. Bespers said, okay, let's work on that
[02:06:34.420 --> 02:06:39.780]   I did not I did not know when I argued with you about amp and what a bad idea what it was that
[02:06:39.780 --> 02:06:46.180]   It came that you had kind of we had gingress on though. Dave. Yeah, we did. Yeah, the tone to defend it
[02:06:46.180 --> 02:06:49.140]   I had the same
[02:06:49.140 --> 02:06:52.660]   I think qualms that the publishers ended up having that it really wasn't
[02:06:52.660 --> 02:06:56.900]   Really open that it was really google it is now
[02:06:56.900 --> 02:07:02.740]   Um, and and there's a guy named dave gary and who i like quite a bit and i didn't respond to me in the thread and he says
[02:07:04.020 --> 02:07:08.020]   It's still around and still being used and and publishers are still using it to get extra money
[02:07:08.020 --> 02:07:11.060]   And he's got a company that does that and you know, it's not dead
[02:07:11.060 --> 02:07:15.140]   Uh, it's just it's just google's not pushing it as much as they were. Yeah
[02:07:15.140 --> 02:07:19.060]   Um
[02:07:19.060 --> 02:07:23.300]   Good news the earth could soon be more detectable by aliens
[02:07:23.300 --> 02:07:29.780]   This is uh, it's a weird story. You know, it's it's a non-story motherboard
[02:07:29.780 --> 02:07:33.220]   It's a non-story because they said like two paragraphs said dual actually has not true
[02:07:33.380 --> 02:07:37.380]   Yeah, those two weeks. That's basically a link bait, but you know, they're going bankrupt
[02:07:37.380 --> 02:07:40.420]   They gotta do something it worked. It worked the premise is
[02:07:40.420 --> 02:07:43.860]   Right now, you know the things that we sent out
[02:07:43.860 --> 02:07:50.500]   We don't send tv signals as much as we used to or radio, but the five g stuff all you know
[02:07:50.500 --> 02:07:57.380]   Attenuates way before it gets to anywhere that people other people other aliens could be but someday
[02:07:57.380 --> 02:08:01.060]   Someday we're gonna produce something that gets there
[02:08:02.020 --> 02:08:04.660]   Stupid story when you complain about my rundown
[02:08:04.660 --> 02:08:08.980]   But no, this is part of our job is to debunk
[02:08:08.980 --> 02:08:14.180]   Oh, I I mean I debunked microsoft using fusion energy. Yeah
[02:08:14.180 --> 02:08:17.060]   Uh, anything else
[02:08:17.060 --> 02:08:19.140]   Uh
[02:08:19.140 --> 02:08:22.580]   Nearly half blob what our blob
[02:08:22.580 --> 02:08:26.260]   The twig the twig blob that we've talked about over time
[02:08:26.260 --> 02:08:31.300]   Oh, this was stacy's term for kind of your data, right your data blob
[02:08:31.300 --> 02:08:36.420]   Was no it was it was a kind of device would be would be necessarily a phone or something else and it'd just be well
[02:08:36.420 --> 02:08:38.980]   Who's yeah, but maybe it was jon donovan somebody
[02:08:38.980 --> 02:08:43.460]   Coins me. I had I you had that you coined the phrase the blob. Well, we've talked about the blob
[02:08:43.460 --> 02:08:48.820]   We all added to this idea that you didn't have a stacy though. I say no, I would never I would never
[02:08:48.820 --> 02:08:51.380]   Know something something so inelegant
[02:08:51.380 --> 02:08:57.220]   The stacy gets mad when when things that she does say don't get credit into her and would think she doesn't say get blamed on her
[02:08:57.220 --> 02:09:01.060]   I swear to god it was somebody to my right of the female persuasion
[02:09:01.780 --> 02:09:06.340]   So it was maybe when stacy was gone. I think it was me anyway, okay. Well, maybe
[02:09:06.340 --> 02:09:11.380]   Am I not a person? I'm just a person your female persuasions
[02:09:11.380 --> 02:09:13.700]   female on right on the right
[02:09:13.700 --> 02:09:15.700]   Fee before the right
[02:09:15.700 --> 02:09:19.380]   Voice on my right. That's all I know it's your movie credit
[02:09:19.380 --> 02:09:21.380]   female
[02:09:21.380 --> 02:09:23.620]   No, you have a very deep voice actually
[02:09:23.620 --> 02:09:25.620]   Did you see the
[02:09:25.620 --> 02:09:26.900]   horrible
[02:09:26.900 --> 02:09:28.900]   appalling article uh
[02:09:28.900 --> 02:09:30.900]   on uh
[02:09:30.900 --> 02:09:35.940]   Theranos uh, Elizabeth home. Oh, oh, that's oh, don't call me. I'm not Elizabeth anymore. I'm Liz
[02:09:35.940 --> 02:09:37.940]   I don't even use that low voice anymore
[02:09:37.940 --> 02:09:42.580]   New York times shame on you New York times for trying to
[02:09:42.580 --> 02:09:47.220]   Rehabilitate I got a New York Times editor going after me what I complained about and I complained about it
[02:09:47.220 --> 02:09:53.380]   It was a horrible story horrible. They were that it was this it was this hot piece that was showing how people could be taken in by her
[02:09:53.380 --> 02:09:56.740]   The reporter was putting herself in that position. I said no no, so no
[02:09:56.980 --> 02:10:01.380]   Didn't they even say like in the article the her editor was like you got rolled dude. Yeah
[02:10:01.380 --> 02:10:04.820]   As an editor if I thought my reporter got rolled
[02:10:04.820 --> 02:10:10.260]   The story but it's nuanced more nuanced than we know
[02:10:10.260 --> 02:10:14.260]   No, it's more nuanced than we know
[02:10:14.260 --> 02:10:17.940]   Trust me
[02:10:17.940 --> 02:10:20.100]   Um
[02:10:20.100 --> 02:10:22.340]   Tucker Carlson going to twitter
[02:10:23.540 --> 02:10:28.820]   All the all the best people are on twitter now. Yeah, yes the best people best people
[02:10:28.820 --> 02:10:34.580]   Americans are smuggling fruit roll-ups into israel. This must be one of yours jeff
[02:10:34.580 --> 02:10:36.580]   It is indeed
[02:10:36.580 --> 02:10:40.740]   Uh, because you can blame tick-tock and that's why it's there because there's a tick-tock thing
[02:10:40.740 --> 02:10:46.340]   If you put ice cream inside of fruit roll-up, it gets kind of crunchy and everybody loves it in israel
[02:10:46.340 --> 02:10:49.940]   But there's so they're so short there that they cost a fortune
[02:10:50.180 --> 02:10:55.860]   So people are smuggling in huge amounts of fruit roll-ups and they're getting arrested for it at the border
[02:10:55.860 --> 02:11:03.220]   I was confused why they were I guess you can't smuggle in that's right $300 worth of okay. Yeah, it's like
[02:11:03.220 --> 02:11:05.940]   Smuggling against the law
[02:11:05.940 --> 02:11:11.060]   Is it because it's a food or is it just I mean I don't I can maybe don't declare it
[02:11:11.060 --> 02:11:15.860]   We're only allowed so many fruit roll-ups. Oh my god, or I guess they're just not kosher. Yeah
[02:11:17.700 --> 02:11:21.700]   All right, let's take a break and then your picks of the week. We're not going to do a changelog this week
[02:11:21.700 --> 02:11:28.500]   We don't need to the show was about that stupid thing. Yeah, the changelog was to fix the fact that we don't do google
[02:11:28.500 --> 02:11:32.500]   But we did google so yes. Yeah, so we don't need to that's our excuse
[02:11:32.500 --> 02:11:35.220]   I'm so we've made good. I'm sticking with it
[02:11:35.220 --> 02:11:38.500]   I want to put in a pitch because we don't have an ad in this position
[02:11:38.500 --> 02:11:40.500]   This is a normal ad position
[02:11:40.500 --> 02:11:46.820]   But I want to put in a pitch to people who are watching the show who might have a business who might doing be doing marketing
[02:11:47.220 --> 02:11:52.500]   For a business who are looking for a way to promote their business or service
[02:11:52.500 --> 02:11:55.540]   And I just want to put in a pitch for what we do here at twit
[02:11:55.540 --> 02:12:01.300]   Let me tell you what our mission statement is because and this is important. It will help you understand why you should be advertising
[02:12:01.300 --> 02:12:04.020]   Onto it our mission statement. It's right here on the wall
[02:12:04.020 --> 02:12:10.340]   We are dedicated to building a highly engaged community of tech enthusiasts
[02:12:10.340 --> 02:12:16.180]   By offering them the knowledge they need to understand and use technology in today's world
[02:12:16.180 --> 02:12:18.340]   I think we do that. I think we do that really well
[02:12:18.340 --> 02:12:23.380]   And I think one of the ways from you know in the very beginning
[02:12:23.380 --> 02:12:31.700]   We realize in order to do this we need to you know do what we've done which is build a studio hire people hire talented
[02:12:31.700 --> 02:12:34.820]   hosts and co-hosts
[02:12:34.820 --> 02:12:41.460]   And we needed advertising to do this and it's worked because I think we have a really great audience half of our listeners
[02:12:41.940 --> 02:12:48.580]   Our in management positions or above 65 percent are involved in their company's decision making particularly with it
[02:12:48.580 --> 02:12:52.020]   Uh, when you advertise on twit
[02:12:52.020 --> 02:12:59.060]   Your they're all host red ads right this is one thing we do that other podcasts other advertising media do not do they
[02:12:59.060 --> 02:13:02.660]   You know they have pre-recorded ads they inject into the content
[02:13:02.660 --> 02:13:07.220]   We do the ads I do the ads and you've heard me do the ads and I and I am
[02:13:07.220 --> 02:13:10.100]   The way I think about this is
[02:13:10.740 --> 02:13:16.180]   We turn away some advertisers because we want to make sure that we're talking about something we know and can recommend
[02:13:16.180 --> 02:13:24.580]   And I feel like I'm taking you know using my integrity to introduce a product or service to our qualified audience
[02:13:24.580 --> 02:13:29.460]   It's an introduction. It's not the kind of ad where say, you know, you've got bad breath and you better get scope
[02:13:29.460 --> 02:13:32.660]   It's the kind of ad where we say here's the features. Here's the benefits
[02:13:32.660 --> 02:13:37.780]   Here's why you should take a look at something like this and it really really works
[02:13:38.420 --> 02:13:43.300]   Look just look at some of the testimonials tim broom who was the founder of it pro tv. We put them on the map
[02:13:43.300 --> 02:13:50.100]   They've been with our network since day one since they started he says quote. We would not be where we are today without the twit network
[02:13:50.100 --> 02:13:57.060]   And I I think that's true. We're very proud of that work. We've done for them mark mccurry ceo of authentic
[02:13:57.060 --> 02:14:01.540]   He's been partnering with us for 16 years. He brought us our first ads
[02:14:01.540 --> 02:14:07.060]   He said the feedback from many advertisers over those 16 years across a range of product categories
[02:14:07.460 --> 02:14:12.260]   Is that if ads and podcasts are ever going to work for a brand? They're going to work on twit shows
[02:14:12.260 --> 02:14:17.540]   We produce results. That's why many of our advertisers come back year after year after year
[02:14:17.540 --> 02:14:22.660]   There's another thing we do that nobody else does and i'm very proud of it. We have built a great team
[02:14:22.660 --> 02:14:25.540]   Lisa of course leads the team
[02:14:25.540 --> 02:14:28.900]   Ryan and max our salespeople those are the people you'll talk to
[02:14:28.900 --> 02:14:32.820]   Our continuity department with debbie and viva and Sebastian
[02:14:33.140 --> 02:14:37.220]   We've built a great team to create the gold standard and podcast advertising
[02:14:37.220 --> 02:14:39.780]   We provide all the services you need
[02:14:39.780 --> 02:14:42.340]   Because you know, especially in the early days
[02:14:42.340 --> 02:14:48.900]   They never advertised on podcasts. In fact many of our early advertisers like it pro had never advertised to anywhere
[02:14:48.900 --> 02:14:53.140]   By the way with it pro works so well. They didn't need to advertise anywhere else
[02:14:53.140 --> 02:14:59.700]   You'll get a full service continuity team supporting everything from copywriting to graphic design. You'll get embedded ads
[02:15:00.180 --> 02:15:06.500]   Not you know, they're part of the content, right? Just like this and they're unique every single time
[02:15:06.500 --> 02:15:12.980]   We do new ads every fresh every single time. We always over deliver on impressions. That's our promise to you
[02:15:12.980 --> 02:15:18.820]   We'll give you all the onboarding services. You need ad tech with pod sites. We give that free to our direct clients
[02:15:18.820 --> 02:15:21.220]   You get lots of reporting
[02:15:21.220 --> 02:15:23.540]   Uh, you get courtesy commercials
[02:15:23.540 --> 02:15:29.380]   You know the commercials that i do and and uh, jason and mica and ant do they're shareable across
[02:15:29.540 --> 02:15:31.540]   social media and landing pages
[02:15:31.540 --> 02:15:37.620]   We'll give you a lot of freebies like mentions in our weekly newsletter that goes to thousands of fans you get bonus ads
[02:15:37.620 --> 02:15:42.740]   Social media promotion and because we know you know, it's times are a little tough for everybody
[02:15:42.740 --> 02:15:46.580]   We we go the extra mile to make sure every single ad we do is
[02:15:46.580 --> 02:15:51.060]   Is going to work for you and is going to help your product or business take off
[02:15:51.060 --> 02:15:54.900]   Look if you're ready to elevate your business reach out to us
[02:15:54.900 --> 02:15:58.820]   Max or ryan or lisa will respond when you email
[02:15:58.900 --> 02:16:00.820]   advertise at twit.tv
[02:16:00.820 --> 02:16:06.900]   You'll be uh, you'll be pitching to a world-class audience. We love our audience. They're smart
[02:16:06.900 --> 02:16:09.140]   They're educated
[02:16:09.140 --> 02:16:14.260]   They're high income and their decision makers in in their businesses for the most part
[02:16:14.260 --> 02:16:21.860]   And uh, and we you'll get a great ad. I promise you that's that's my promise to you advertise at twit.tv
[02:16:21.860 --> 02:16:26.100]   Thank I just thank you for your time. I appreciate it. Lisa has all the demographics
[02:16:26.420 --> 02:16:30.740]   Survey. Oh, you've seen have seen we've got the reference all that information. Yeah
[02:16:30.740 --> 02:16:32.500]   and
[02:16:32.500 --> 02:16:37.540]   I think the other important thing is the unaided recall of a podcast ad here is tremendous
[02:16:37.540 --> 02:16:41.860]   People know the advertisers. You know, I'm I can't I've seen
[02:16:41.860 --> 02:16:46.500]   Research I can't you know people pay for research to find out
[02:16:46.500 --> 02:16:50.260]   And I've seen it. I can't say who or I can't give you any details
[02:16:50.260 --> 02:16:55.700]   It's well over 90% unaided recall in many cases. That's unprecedented on you know
[02:16:56.020 --> 02:17:04.180]   Somebody what's the recall? Oh, you saw that ad where the guy gets in a car wreck and uh, because he's doing a tiktok dance. What's the product?
[02:17:04.180 --> 02:17:12.260]   Nobody got it. Yeah, oh, don't remember but our ads really work. So yeah, I appreciate taking your time on that, but
[02:17:12.260 --> 02:17:17.060]   It's comparable to that 1968 bear ad that we were talking about that you
[02:17:19.700 --> 02:17:24.100]   That's why 1963 that's why I'm there at that's why hey Stacy
[02:17:24.100 --> 02:17:29.380]   What do you guys? I have a new name for your thing by the way. What's under Stacy's desk
[02:17:29.380 --> 02:17:36.900]   Sometimes it's to the left or to the right, but yeah, you're not wrong
[02:17:36.900 --> 02:17:44.100]   Um today. I don't have a thing. I have a reminder. Mm. It is mother's day this
[02:17:44.100 --> 02:17:49.140]   Sunday. Oh, I'll be right back. So for everybody who might be like, oh no
[02:17:49.140 --> 02:17:51.140]   Like a tablet
[02:17:51.140 --> 02:17:54.900]   So the tablet doesn't ship till june. That's my mistake kind of thing
[02:17:54.900 --> 02:18:00.260]   But if you are in a bind I have
[02:18:00.260 --> 02:18:08.100]   It here are some quick quick things, please you might be able to get help me help me
[02:18:08.100 --> 02:18:11.860]   First up if you're gonna see your mom in person
[02:18:11.860 --> 02:18:18.260]   Here's an easy idea plant a little herb garden for the lion stick them in a thing and bring that tour
[02:18:18.420 --> 02:18:20.420]   That's a great idea. Yeah
[02:18:20.420 --> 02:18:23.940]   Love that what herbs would you put in there?
[02:18:23.940 --> 02:18:27.060]   Um, I heard
[02:18:27.060 --> 02:18:30.980]   Yeah, I was like I would pick things like based on what they like
[02:18:30.980 --> 02:18:33.780]   Like my mom's a huge fan of
[02:18:33.780 --> 02:18:36.740]   Did you just say indica
[02:18:36.740 --> 02:18:38.580]   Yes
[02:18:38.580 --> 02:18:40.580]   I was just gonna gloss right over that
[02:18:40.580 --> 02:18:43.620]   A nice herb don't cook with it
[02:18:45.380 --> 02:18:49.620]   I mean, I planted I planted my mom a cocktail garden. All right. I'll just be honest
[02:18:49.620 --> 02:18:52.180]   So I put
[02:18:52.180 --> 02:18:54.660]   You know, cherries those little onions
[02:18:54.660 --> 02:18:59.220]   Olives olives olum bro
[02:18:59.220 --> 02:19:02.500]   Permanos
[02:19:02.500 --> 02:19:05.060]   Yeah
[02:19:05.060 --> 02:19:08.420]   Yes, yes, so so that's it. That's one option
[02:19:08.420 --> 02:19:13.940]   The um if you're not going to see your mom and it is a little late and you want a digital subscription
[02:19:14.980 --> 02:19:18.740]   Buy a book if your mom's strictly buy her trically book
[02:19:18.740 --> 02:19:21.860]   If she's just like a normal mom and likes normal books
[02:19:21.860 --> 02:19:26.980]   Buy or whatever and deliver it to their kindle. I've also bought my mom a kindle. That's a good
[02:19:26.980 --> 02:19:30.500]   Yeah, I got my mom a kindle some years ago. She loves that. Yep. Yep
[02:19:30.500 --> 02:19:34.660]   So and if you find something that actually makes you think of your mom
[02:19:34.660 --> 02:19:39.060]   You can even say hey, I read this and I thought of you and send it to them
[02:19:39.060 --> 02:19:41.780]   And if you can say why bonus points
[02:19:42.340 --> 02:19:47.540]   Then final thing this is actually what I asked for for this year because we don't have photos in my house because we're not allowed to have stuff
[02:19:47.540 --> 02:19:50.260]   I asked for a friend
[02:19:50.260 --> 02:19:55.620]   Does a bitter comment you just sped right by andrew doesn't like photos
[02:19:55.620 --> 02:19:59.940]   And we have two photos in our entire house
[02:19:59.940 --> 02:20:04.340]   I'm like god. He's like my office is is my office
[02:20:04.340 --> 02:20:10.740]   But the rest of our house is like what does he think you're gonna steal the soul of the person you're taking the no
[02:20:10.900 --> 02:20:15.540]   He just he hates it. He quotes. Here's his quote. That's a little busy
[02:20:15.540 --> 02:20:23.300]   Oh, we have said you would hate our house. He would hate a busy environment. We I mean, I like Lisa's office
[02:20:23.300 --> 02:20:25.860]   There's not a square inch of wall that doesn't have a picture on it
[02:20:25.860 --> 02:20:28.420]   Anyway
[02:20:28.420 --> 02:20:32.740]   A framed photo print out a good digital photo of you your kids whatever
[02:20:32.740 --> 02:20:37.300]   And you know, you can do that at walmart. You can do that wherever put it in a nice frame
[02:20:37.460 --> 02:20:41.780]   I asked for an engraving that would be a great family quote on my frame. That's a little late
[02:20:41.780 --> 02:20:44.820]   You might have to do that for christmas, but none of these are tech gifts
[02:20:44.820 --> 02:20:47.700]   but they're all like
[02:20:47.700 --> 02:20:49.220]   Things
[02:20:49.220 --> 02:20:54.820]   Most people but especially moms would like I sent my mom some tp link Wi-Fi plugs
[02:20:54.820 --> 02:20:59.540]   Recommended on this show as a matter of fact they're matter compliant
[02:20:59.540 --> 02:21:03.700]   The funny thing she's not gonna know what the hell to do with them
[02:21:05.700 --> 02:21:08.580]   Batter's easy. You just scan it. She's have the right app
[02:21:08.580 --> 02:21:12.740]   No, I walk her through it, but I think it's for things like turn on the lights
[02:21:12.740 --> 02:21:18.660]   Uh, you know, there's a lot of useful, you know start my coffee maker things like that
[02:21:18.660 --> 02:21:23.380]   But that's the truth your mom a photo of your mom. That's the other thing
[02:21:23.380 --> 02:21:30.420]   Get your photo your mom you want the photo of the kids. That's right. She knows what she looks like
[02:21:30.420 --> 02:21:32.340]   Yes
[02:21:32.340 --> 02:21:36.180]   Actually, you know, and I did not for mother's day, but just this is not a bad idea either
[02:21:36.180 --> 02:21:39.620]   When I gave her an amazon echo updated her to the new echo
[02:21:39.620 --> 02:21:44.820]   I uh associated with my account and I made and I said all the family photos
[02:21:44.820 --> 02:21:49.860]   From our whole life because we'd scanned the slides and I made that the slide show
[02:21:49.860 --> 02:21:54.420]   On the echo and she so a photo frame with a slideshow of family photos
[02:21:54.420 --> 02:21:59.540]   Especially because mom's 90 and that's really she likes thinking about the good old days and stuff
[02:22:00.340 --> 02:22:06.580]   She really loves that. I'll every time I call her. She's oh, I just saw one of you and even you're so cute
[02:22:06.580 --> 02:22:12.020]   Four years old and yeah, really, but that was a good one. Yeah. Well, happy mother's
[02:22:12.020 --> 02:22:17.700]   Visual photo friends are always happy. What's next day? Stacy. I hope you have a wonderful one. Are you planning anything?
[02:22:17.700 --> 02:22:22.660]   My mom is actually gonna be in town. Oh, which is weird
[02:22:22.660 --> 02:22:28.100]   Perfect. So we're gonna have um very nice lobster rolls and scones with clotted cream. Oh
[02:22:29.220 --> 02:22:31.220]   yummy yum
[02:22:31.220 --> 02:22:36.260]   Remember the butter goes on the inside of the sandwich not the outside just a tip
[02:22:36.260 --> 02:22:43.700]   Mr. Jeff Jarvis. Do you have a number for us? I think I'll call on our friend near at yseblatt
[02:22:43.700 --> 02:22:48.580]   And she has the seven ways that ai coverage fails. She is a
[02:22:48.580 --> 02:22:53.460]   researcher who has done a wonderful book on tech journalism tech lash
[02:22:53.460 --> 02:22:59.140]   Tech laugh is called she was on the show. What's twice? Yep. She's on twitter at dr. tech lab
[02:22:59.380 --> 02:23:00.900]   slash
[02:23:00.900 --> 02:23:02.740]   So uh
[02:23:02.740 --> 02:23:06.260]   It spells up ai panic which means that ant has to get a new panics
[02:23:06.260 --> 02:23:13.380]   Uh, so not just moral panic, but also aa panic. So it's a is ai hype and critic hype
[02:23:13.380 --> 02:23:20.420]   I is inducing simplistic binary thinking p is packed journalism a is anthropomorphizing ai
[02:23:20.420 --> 02:23:25.380]   And is a narrow focus on the edges of the debate. I is interchanging question marks
[02:23:25.540 --> 02:23:32.100]   legislation points and the c is conversing converting. I think sci-fi scenarios as credible predictions
[02:23:32.100 --> 02:23:40.420]   Hey, you know what that reminds me we should get dr. Tech lash on the show soon the next time somebody's not here
[02:23:40.420 --> 02:23:47.220]   Um, I can't tell Jason because he's busy at google doing stuff, but somebody I got you you got me aunt
[02:23:47.220 --> 02:23:53.540]   They got me he she was like a hey aunt. We haven't had her in a while and I think this you know
[02:23:53.540 --> 02:23:55.540]   I want to know what she means right now
[02:23:55.540 --> 02:24:00.660]   Because tristan harris who went all crazy about you know social media now
[02:24:00.660 --> 02:24:04.740]   He's basically making another villain which all he does is erase the word social media and put ai in
[02:24:04.740 --> 02:24:09.460]   So he's the exact same panics. Yep. And some say moral entrepreneurs are going after ai
[02:24:09.460 --> 02:24:15.620]   Uh, and the panic is even bigger the funny thing is she put this on twitter where all of the crypto bros
[02:24:15.620 --> 02:24:20.180]   Taking the same exact tweets and this changed crypto for ai
[02:24:20.820 --> 02:24:23.540]   It's a non-stop fest of ai bs
[02:24:23.540 --> 02:24:28.100]   Uh ai hype which is what the number one problem
[02:24:28.100 --> 02:24:33.380]   Over the opposite over confident techie's bragging about their ai systems or
[02:24:33.380 --> 02:24:37.540]   Overconfident doom sayers accusing those ai systems of atrocities
[02:24:37.540 --> 02:24:39.300]   Exactly
[02:24:39.300 --> 02:24:44.580]   Uh, yeah, good. There's a good media article explaining it all and do get her book tech lash and we will get her on
[02:24:44.580 --> 02:24:47.300]   soon because she's great
[02:24:47.780 --> 02:24:50.820]   And prue it what you got for us and
[02:24:50.820 --> 02:24:57.700]   I was struggling with the pic of the week. So I just went and grabbed a tgu for everyone to try
[02:24:57.700 --> 02:25:02.020]   What's a tgu? You're wondering what a tgu what is a tgu when it's at home?
[02:25:02.020 --> 02:25:06.260]   It is a turkish get up. Oh, I mean an outfit
[02:25:06.260 --> 02:25:11.860]   Oh, I don't mean an outfit. So i'm telling all of you get up off of the war
[02:25:11.860 --> 02:25:14.580]   Get off the dad gum floor
[02:25:15.540 --> 02:25:18.740]   Just try this technique get off the dad gum floor
[02:25:18.740 --> 02:25:21.380]   I can't even do it by myself
[02:25:21.380 --> 02:25:28.420]   Yeah, and you don't even have to do it with a kettlebell if you first try without anything in your hands next
[02:25:28.420 --> 02:25:33.940]   Grab yourself a gallon of milk or I could feel the katobell of corn. So he's rolling
[02:25:33.940 --> 02:25:42.500]   He's sitting up. Nope. He's lifting up the turkish kettlebell. Yeah, put it out of his hand. Yeah. Yeah, it's not a turkish kettlebell
[02:25:42.980 --> 02:25:46.900]   It's a it's a russian push to kettlebell. It's a for the put kettlebell
[02:25:46.900 --> 02:25:51.620]   He rush. Oh, look at that. Oh my god. Oh my god
[02:25:51.620 --> 02:25:59.060]   I'm already my back is killing me just watching this. This is this is all just functional movements that everyone should take into
[02:25:59.060 --> 02:26:01.300]   I should do that. I should turkish get up. Yes
[02:26:01.300 --> 02:26:07.140]   Can I wear a mustache? You don't have to have a whole bunch of expensive weight
[02:26:07.140 --> 02:26:09.300]   Fizzing a mustache for my turkish get up
[02:26:09.300 --> 02:26:11.300]   I
[02:26:11.300 --> 02:26:15.940]   Actually just want to clarify that's a that's actually a good move
[02:26:15.940 --> 02:26:20.500]   And then you do it on the other side. I presume because otherwise correct. Oh, there's good
[02:26:20.500 --> 02:26:21.380]   No
[02:26:21.380 --> 02:26:22.820]   Your hips
[02:26:22.820 --> 02:26:25.060]   I T bang your core your back
[02:26:25.060 --> 02:26:28.340]   You know the good is I think I when you go down it's it's
[02:26:28.340 --> 02:26:33.700]   It's real important though when you do the the flop down. Yeah coming down. You have to
[02:26:33.700 --> 02:26:38.900]   Tighten your hold your core. It's otherwise. It's all about the core. You're lower back. Yeah, right
[02:26:39.140 --> 02:26:44.020]   Or back. Yeah, core is so important. I'm watching him do it. I'm like he's not I can't hear him say it
[02:26:44.020 --> 02:26:46.420]   But that's super important right there. Yeah. Yeah
[02:26:46.420 --> 02:26:53.380]   So that was a youtube video, but I think if you search for turkish get up on youtube turkish get up
[02:26:53.380 --> 02:26:57.220]   you'll either get a guy a fizzing a mustache or
[02:26:57.220 --> 02:27:04.100]   Somebody that's what you get you get it. You get it. You got to do whatever the first thing you find is
[02:27:06.340 --> 02:27:11.380]   Very good one. Actually, that's a good that's nice. I might do that tonight. Yeah, I won't be here next week
[02:27:11.380 --> 02:27:17.220]   Don't have to use the weight. I can tell you right now
[02:27:17.220 --> 02:27:22.740]   It's actually you know what? I think it's easier with the weight because you can use it a little leverage or balance
[02:27:22.740 --> 02:27:25.060]   And balance to get you get you over
[02:27:25.060 --> 02:27:28.500]   It's kind of harder without a weight. Yeah, and if you can't get up
[02:27:28.500 --> 02:27:33.620]   On your own without like pressing up for the floor like if you can't get up without using your hands
[02:27:33.860 --> 02:27:37.780]   You should work on that too. Oh, that's wrong. You can't get up you say okay
[02:27:37.780 --> 02:27:43.940]   I can't get up trust me. I can't get up trust me Stacy when you get to my age
[02:27:43.940 --> 02:27:50.180]   Yeah, I will be getting up still without using my hands really by god. You think so?
[02:27:50.180 --> 02:27:53.940]   Wait till you're my age use use. I will train for that
[02:27:53.940 --> 02:27:56.500]   I'm telling that's why I
[02:27:56.500 --> 02:28:02.980]   Try to preach push-ups to people so much because it's it's not as easy as one with oh I could get up on my knees
[02:28:03.780 --> 02:28:06.820]   But then I'm stuck. Here's my Turkish
[02:28:06.820 --> 02:28:19.460]   I don't know how the discord found that so fast, but thank you
[02:28:19.460 --> 02:28:26.020]   Uh, is that it or do you anything else you you want to do there? Oh? Oh, yeah
[02:28:26.020 --> 02:28:30.340]   Uh, I want to say thank you to national preps for just for being real
[02:28:30.340 --> 02:28:32.500]   Um, we're there in the shout out
[02:28:32.500 --> 02:28:34.500]   They are a recruiting service
[02:28:34.500 --> 02:28:40.180]   Uh, um, and there's a lot of recruiting services out there and it's straight up money grab
[02:28:40.180 --> 02:28:43.540]   I've seen them they've tried to lure me in and I've told them no
[02:28:43.540 --> 02:28:47.140]   There's a lot of politics involved, but this crew right here
[02:28:47.140 --> 02:28:54.820]   Um, they're quite reputable. Okay, my uh coaches from back east were spoke highly of them
[02:28:54.820 --> 02:28:59.540]   One of their representatives is here in Sonoma county nice and um
[02:29:00.180 --> 02:29:04.580]   Has reached out to me several times and he didn't try to sell me on anything and whatnot
[02:29:04.580 --> 02:29:06.500]   And he actually tries to go
[02:29:06.500 --> 02:29:09.460]   tried to go to extra mile for hard hit because
[02:29:09.460 --> 02:29:14.580]   Hard hit whipped up on one of the teams he coaches for so oh nice
[02:29:14.580 --> 02:29:20.740]   So you that's a good way to get you want to try to help him out, you know, and I really appreciate them just being
[02:29:20.740 --> 02:29:26.980]   How is jacob's quest going? I know he I know you're trying to get some scholarship money and a good school for him
[02:29:27.620 --> 02:29:34.180]   We're still waiting around um, he had a really good week last week to help make a name for himself
[02:29:34.180 --> 02:29:39.940]   Um part of national prepsis. They have showcases around the country throughout the season
[02:29:39.940 --> 02:29:45.780]   And uh, we went to it as a quarterback and linebacker and um, which is
[02:29:45.780 --> 02:29:50.580]   I'm usually just a little bit alone. I would like to see him do a turkish get up now
[02:29:50.580 --> 02:29:57.460]   That is good man. He's got seen that's why i'm back. Are drills there. Yeah, see that's line backer
[02:29:57.460 --> 02:29:59.460]   Drills and he ended up getting the mvp
[02:29:59.460 --> 02:30:02.020]   For the linebacker
[02:30:02.020 --> 02:30:04.020]   at the camp that's where the money
[02:30:04.020 --> 02:30:08.340]   So a lot of people gave him extra recognition for that and I appreciate national preps for
[02:30:08.340 --> 02:30:13.220]   allowing the platform if you will but just a couple days before that
[02:30:13.220 --> 02:30:14.900]   he
[02:30:14.900 --> 02:30:18.900]   ran in the nbl league track and field championships here
[02:30:18.900 --> 02:30:22.660]   And defended his title as the fastest kid in the league and
[02:30:22.660 --> 02:30:27.060]   How does this kid not have a scholarship to the
[02:30:27.460 --> 02:30:29.060]   All the best
[02:30:29.060 --> 02:30:35.300]   Univeristates in the country too. He's smart. He's handsome. He's an excellent athlete and yeah, he's straight a student
[02:30:35.300 --> 02:30:38.260]   Yes, handsome
[02:30:38.260 --> 02:30:40.260]   Okay, good jeez
[02:30:40.260 --> 02:30:42.420]   Okay, okay
[02:30:42.420 --> 02:30:47.220]   Okay, let me just tell you miss miss uh female persuasion
[02:30:47.220 --> 02:30:53.940]   All the right colleges, you know, they're trying to raise money with their athletic programs
[02:30:54.260 --> 02:31:00.020]   They want some good looking people to go out shake hands with the alum they do it's a business
[02:31:00.020 --> 02:31:03.700]   You know what i'm somebody looking like me but star hey mr. alum give me a hundred
[02:31:03.700 --> 02:31:12.500]   They want some some lookers out there, right and by the way, she said look her not hook her just because this is true
[02:31:12.500 --> 02:31:15.300]   No, no, jacob is handsome in a good way
[02:31:15.300 --> 02:31:18.900]   He is he's just no he said
[02:31:20.180 --> 02:31:25.780]   Is there is there a way to be you know what i'm about to run out of battery on my headphones i'm good
[02:31:25.780 --> 02:31:29.860]   I'm not gonna ask these questions. There's no bad way to be handsome
[02:31:29.860 --> 02:31:32.580]   Well, they did very well. He broke his
[02:31:32.580 --> 02:31:35.540]   Weekend
[02:31:35.540 --> 02:31:43.780]   In the sectionals the north coast sectionals this weekend so I am I am honest. I just don't I don't forget it
[02:31:43.780 --> 02:31:46.180]   I mean I this guy should be snapped up
[02:31:46.980 --> 02:31:51.300]   How do we help so do how can we help besides telling people yeah, just
[02:31:51.300 --> 02:31:57.300]   Follow and under score prue it on instagram and then share his videos
[02:31:57.300 --> 02:32:06.260]   Let's get your a college and alum of a sports school out there. Um, that's a good way to use your cloud. Yeah, oh
[02:32:06.260 --> 02:32:10.100]   Would he be interested in the ale or maybe not
[02:32:10.100 --> 02:32:13.300]   Actually, yes, okay
[02:32:13.700 --> 02:32:16.820]   It's like he'll be interested in what i tell him he's interested in
[02:32:16.820 --> 02:32:21.140]   We've discussed the ivy league a couple of times because I think
[02:32:21.140 --> 02:32:26.980]   I'm going to call the end dar and dar and reach out don't go to dar myth. It's freezing
[02:32:26.980 --> 02:32:30.660]   Columbia would be great being a big apple
[02:32:30.660 --> 02:32:34.180]   Be in my town. Yeah, but handover in the winter
[02:32:34.180 --> 02:32:40.260]   Yeah, I'm on the part of it, but hey we have discussed it and he's he's open to those
[02:32:40.660 --> 02:32:46.020]   He should you know what is this this is about the big picture it is he's trying to get a job and no
[02:32:46.020 --> 02:32:53.460]   Those schools get you good jobs. That's really true. He could be a super hard to care me and queen prue it. That's my thing
[02:32:53.460 --> 02:32:57.780]   That's my retirement plan right there
[02:32:57.780 --> 02:33:00.980]   All right, and hey great to see you
[02:33:00.980 --> 02:33:08.260]   Join at tomorrow morning 9 a.m. Pacific noon easterns as he interviews Alex will help feed him some good questions
[02:33:08.820 --> 02:33:12.660]   Yep, there are the questions in the discord. There's a thread there in the club toward events
[02:33:12.660 --> 02:33:16.980]   That um, Alex will have his name on it just pop your questions in there and
[02:33:16.980 --> 02:33:21.380]   We will go through a handful of them and have a good o our tomorrow morning
[02:33:21.380 --> 02:33:24.660]   He's uh, you know a financial wizard you can ask about the recession
[02:33:24.660 --> 02:33:29.860]   You can ask him why tech stocks and tech companies are plummeting what's going on? Why so many layoffs?
[02:33:29.860 --> 02:33:32.740]   Ask him about crypto ask him about nft's
[02:33:32.740 --> 02:33:36.420]   Ask him about has he's he's has what's that?
[02:33:37.620 --> 02:33:45.540]   Uh f1. Oh, he's an f1 fan. Oh, I didn't know that. Yeah. Ask him who his favorite driver is
[02:33:45.540 --> 02:33:48.080]   Vamo sala
[02:33:48.080 --> 02:33:49.700]   Uh, yeah
[02:33:49.700 --> 02:33:52.660]   Yeah, just all of that stuff that it's gonna be a lot of fun
[02:33:52.660 --> 02:33:58.660]   I love Alex and do ask him what it's like to live in leo's childhood home because it's got to be a thrill for him
[02:33:58.660 --> 02:34:00.660]   Right. How did you find that out?
[02:34:00.660 --> 02:34:07.140]   He's uh, feet at the time awkward girlfriend at the time we were doing the new screensavers Alex was on the show
[02:34:07.780 --> 02:34:12.340]   and uh his girlfriend liza was studying medicine at brown
[02:34:12.340 --> 02:34:19.540]   And um, I said, oh, yeah, I grew up in providence. She said, oh, yeah, that's cool. So did I my my my family's from there
[02:34:19.540 --> 02:34:27.380]   And I said, oh, uh, that's cool. What street and she told me the street and I said, oh, that's the same street as me
[02:34:27.380 --> 02:34:29.620]   Uh
[02:34:29.620 --> 02:34:33.780]   What house were you in she told me the number I said that's my house
[02:34:34.900 --> 02:34:41.540]   And then she said well, here's the funny thing. We're living there now because my parents bought it and gave it to us and we're living there
[02:34:41.540 --> 02:34:45.460]   And uh, yeah, I went over I visited them
[02:34:45.460 --> 02:34:50.900]   Uh last summer and saw the house. Oh, did you find the little marks where little dio was growing up on the closet door?
[02:34:50.900 --> 02:34:56.340]   Oh, I didn't look for that. They pretty much fixed it up. So I doubt those are there but uh, I said
[02:34:56.340 --> 02:35:01.540]   You're right. Was it freaky to go into house childhood? It was nostalgic
[02:35:02.340 --> 02:35:07.940]   Uh, they've made it very nice. They've they've fixed some stuff, but I went into the little side room off the kitchen
[02:35:07.940 --> 02:35:09.940]   I said, oh, yeah, that's where I watched the Apollo
[02:35:09.940 --> 02:35:12.580]   Landing on the moon in 1969
[02:35:12.580 --> 02:35:16.340]   Um, and I have a picture of me as a cub scout with my
[02:35:16.340 --> 02:35:19.620]   Doing the cubs got a salute from in that very spot
[02:35:19.620 --> 02:35:24.260]   And then we went up and looked at my room and they had changed enough so that it wasn't too freaky
[02:35:24.260 --> 02:35:30.340]   It wasn't like wow, you know, emonese or scrooge going back in time. Right, but uh, it's yeah
[02:35:30.900 --> 02:35:35.700]   I was really happy to see it. It was very cool and I love them and his wife lies and they just had a baby
[02:35:35.700 --> 02:35:40.420]   And they are wonderful people. They are two of my favorite people in the world. So
[02:35:40.420 --> 02:35:44.340]   Uh, I feel like the vibes are good there. I'm very happy about that
[02:35:44.340 --> 02:35:46.980]   Except for the 15 dogs they have
[02:35:46.980 --> 02:35:52.980]   Oh boy. I can ask them about that. I didn't know about that. Okay, you know, not 15, but they sound like there's 15
[02:35:52.980 --> 02:36:00.820]   I'll throw that question in for myself. Hold on. I mean, they're great dogs. Yeah, he does all of his stuff
[02:36:00.900 --> 02:36:03.860]   out. They built a little, um, in the backyard where I used to
[02:36:03.860 --> 02:36:07.700]   It was so funny because he's right next to this giant oak tree this giant pin oak
[02:36:07.700 --> 02:36:12.740]   And I said my dad planted that when we moved into that house and I sent him a picture of my dad
[02:36:12.740 --> 02:36:16.260]   Digging the hole and putting this little tiny tree in there
[02:36:16.260 --> 02:36:18.900]   And then I sent my dad the picture of the tree now
[02:36:18.900 --> 02:36:23.300]   Talk about immortality. It's it's like it's 80 feet tall. It's huge
[02:36:23.300 --> 02:36:28.580]   Uh, and we planted that back and it must have been 1966
[02:36:29.380 --> 02:36:31.380]   Something like that
[02:36:31.380 --> 02:36:37.060]   So it's pretty no I go and see my mother but the last time seeing my mother it's it's still
[02:36:37.060 --> 02:36:41.460]   Cool to me because her house hasn't changed very is that the house you grew up in?
[02:36:41.460 --> 02:36:45.860]   Yes, the house I grew up in and she has one addition on her bedroom
[02:36:45.860 --> 02:36:52.980]   Basically just expanded her bedroom, but the rest of the house is the same other than my bedroom is now her office
[02:36:52.980 --> 02:36:57.540]   But everything else is exactly the same. Yes. See I was kind of deprived of that least his
[02:36:58.180 --> 02:37:03.060]   Parents are still here. The house she grew up in is they still live in it. Um, there's something about that
[02:37:03.060 --> 02:37:05.060]   That's kind of neat gives you roots
[02:37:05.060 --> 02:37:10.340]   Mm-hmm. But my father but I mean died. I think it moved 27 times. Yeah, that's more my life
[02:37:10.340 --> 02:37:13.780]   I went to four high schools in three states four elementary schools in three states. Yeah
[02:37:13.780 --> 02:37:17.380]   That my friends is jeff Jarvis the director of the townite center
[02:37:17.380 --> 02:37:22.180]   for entrepreneurial journalism at the craig new mark
[02:37:22.180 --> 02:37:26.420]   Graduate school journalism at the city university of new york
[02:37:26.900 --> 02:37:33.940]   He's on mastodon at jeff Jarvis and he's of course the author of a brand new book coming out in june
[02:37:33.940 --> 02:37:41.780]   Called the gutenberg parenthesis you could find out about it and even pre-order it at gutenberg parenthesis
[02:37:41.780 --> 02:37:44.500]   dot com
[02:37:44.500 --> 02:37:51.220]   Thank you jeff. Thank you boss. And I don't know why i do this today. I know. Thank you for being here this morning
[02:37:51.220 --> 02:37:56.340]   That's right. We spent a long time ago. And I I'm sorry. I should really get rid of stacy fast first
[02:37:56.820 --> 02:37:58.820]   Instead I drag it out
[02:37:58.820 --> 02:38:02.580]   I'm just gonna stop that so I should just really get rid of stacy
[02:38:02.580 --> 02:38:04.020]   long
[02:38:04.020 --> 02:38:06.020]   long boring conversation
[02:38:06.020 --> 02:38:09.540]   Waiten is like the the school day is almost all
[02:38:09.540 --> 02:38:12.180]   It's three minutes to go now
[02:38:12.180 --> 02:38:16.420]   The clock is so slowly doesn't it at the end of this week in google stacy
[02:38:16.420 --> 02:38:21.140]   I it moves the same, but it's just so long
[02:38:22.740 --> 02:38:26.900]   Started to end the show at five oh no, it's five twenty two
[02:38:26.900 --> 02:38:33.380]   I'm so sorry. I pom and oh no. I actually wanted to know how you found out that someone was living in your house because i was
[02:38:33.380 --> 02:38:35.620]   Even kind of weird. Yeah
[02:38:35.620 --> 02:38:39.460]   Uh stacy is of course is stacy on iot.com. That's her website
[02:38:39.460 --> 02:38:43.940]   Uh the iot podcast she does with kevin toffle is there comes out every wednesday
[02:38:43.940 --> 02:38:49.620]   At gigastacy thursday, sorry they record on wednesday and release some thursday
[02:38:50.260 --> 02:38:52.660]   Uh at gigastacy on the twitter
[02:38:52.660 --> 02:38:56.340]   Anything else you want to plug do you have an event coming up?
[02:38:56.340 --> 02:39:00.500]   Are you going to give a lecture somewhere is your new novel out?
[02:39:00.500 --> 02:39:05.140]   Did you write it now? I feel like an underachiever i'm like
[02:39:05.140 --> 02:39:07.620]   about the
[02:39:07.620 --> 02:39:09.620]   about the 12 theses
[02:39:09.620 --> 02:39:14.580]   Uh on luther hammering up on the I don't know no you like
[02:39:14.580 --> 02:39:18.580]   No, no, no, I haven't done any of those things
[02:39:18.580 --> 02:39:21.300]   Any pictures in my house. I just uh, I just hear
[02:39:21.300 --> 02:39:27.700]   I got nothing nothing for you. We love you stacy. Thank you for being here. Thank you all for joining us
[02:39:27.700 --> 02:39:34.500]   We do twig every wednesday at two p.m. Normally at two p.m. Pacific five p.m. Eastern 2100 utc
[02:39:34.500 --> 02:39:37.620]   There's a live audio and video stream all the time
[02:39:37.620 --> 02:39:40.260]   at twit.tv/live
[02:39:40.260 --> 02:39:45.380]   And if you go there when a show is being recorded you get to watch it happen live and
[02:39:45.780 --> 02:39:51.940]   If you're doing that you might as well chat with us at irc.twit.tv that's open to all club twit members of course have the
[02:39:51.940 --> 02:39:53.300]   the
[02:39:53.300 --> 02:39:54.660]   champagne room
[02:39:54.660 --> 02:39:56.660]   You can go to the discord and chat with us
[02:39:56.660 --> 02:39:58.500]   There
[02:39:58.500 --> 02:40:03.460]   We also have on demand versions of the show available our website twit.tv/twig
[02:40:03.460 --> 02:40:07.780]   If you go there, you'll see a link to the youtube channel dedicated to this week in google
[02:40:07.780 --> 02:40:12.260]   And you'll see the podcast players and you can click one of those links and
[02:40:12.900 --> 02:40:19.140]   Add us to your subscriptions if you would that way you'll get it automatically. Thank you everybody. I appreciate it
[02:40:19.140 --> 02:40:21.620]   We will see you next time
[02:40:21.620 --> 02:40:24.020]   Don't forget tomorrow with Alex will helm
[02:40:24.020 --> 02:40:25.780]   Sunday
[02:40:25.780 --> 02:40:30.820]   Forests the tech guys and of course follow that twit news feed for the very interesting interviews
[02:40:30.820 --> 02:40:35.540]   They just completed at google for more google. We'll see you next time. Bye. Bye
[02:40:38.820 --> 02:40:42.580]   It's midweek and you really want to know even more about the world of technology
[02:40:42.580 --> 02:40:48.260]   So you should check out tech news weekly the show where we talk to and about the people making and breaking the tech news
[02:40:48.260 --> 02:40:52.820]   It's the biggest news we talk with the people writing the stories that you're probably reading
[02:40:52.820 --> 02:40:58.020]   We also talk between ourselves about the stories that are getting us even more excited about tech news this week
[02:40:58.020 --> 02:41:03.780]   So if you're excited well, then join us head to twit.tv/tnw to subscribe
[02:41:03.780 --> 02:41:14.260]   [Music]

