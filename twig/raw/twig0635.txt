;FFMETADATA1
title=I Too Like Music Band
artist=Leo Laporte, Jeff Jarvis, Stacey Higginbotham, Ant Pruitt
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2021-10-28
track=635
language=English
genre=Podcast
comment=Earnings galore, Pixel 6 Pro review highlights, Android 12L, smart TV wars
encoded_by=Uniblab 5.3
date=2021
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.440]   Coming up on this week in Google, it's me, Jason Howell, filling in for Leo.
[00:00:03.440 --> 00:00:09.080]   We've also got Anne Pruitt, Jeff Jarvis, and Matthew Ingram from the Columbia Journalism Review.
[00:00:09.080 --> 00:00:12.440]   We talk all about, well, we start things off with earnings.
[00:00:12.440 --> 00:00:16.640]   We kind of get that out of the way, but it merges into an interesting conversation around Facebook
[00:00:16.640 --> 00:00:19.480]   and its attempt to win over the Utes.
[00:00:19.480 --> 00:00:22.520]   Also, Pixel 6 Pro Review highlights.
[00:00:22.520 --> 00:00:24.720]   We talk about Android 12L.
[00:00:24.720 --> 00:00:27.440]   That's right, the next version, not just Android 12.
[00:00:27.440 --> 00:00:29.720]   It's the next one for foldables and tablets.
[00:00:29.720 --> 00:00:36.160]   The battle over the smart TV and your living room, and so much more, coming up now on this week in Google.
[00:00:36.160 --> 00:00:51.440]   This is Twig.
[00:00:51.440 --> 00:00:57.520]   This week in Google, Episode 635, recorded Wednesday, October 27th, 2021.
[00:00:57.520 --> 00:01:00.800]   I too like music band.
[00:01:00.800 --> 00:01:04.800]   This episode of This Week in Google is brought to you by UserWay.org.
[00:01:04.800 --> 00:01:12.160]   UserWay ensures your website is accessible, ADA compliant, and helps your business avoid accessibility-related lawsuits.
[00:01:12.160 --> 00:01:17.000]   The perfect way to showcase your brand's commitment to millions of people with disabilities.
[00:01:17.000 --> 00:01:20.240]   It's not only the right thing to do, it's also the law.
[00:01:20.240 --> 00:01:27.120]   Go to UserWay.org/twit for 30% off UserWay's AI-powered accessibility solution.
[00:01:27.120 --> 00:01:29.000]   And by CrowdStrike.
[00:01:29.000 --> 00:01:37.360]   CrowdStrike harnesses the power of every click, every action, and every ally to grow stronger and stop cyber threats before they can stop you.
[00:01:37.360 --> 00:01:44.560]   Join the fight and experience the power of Falcon Platform for free today at CrowdStrike.com/twit.
[00:01:44.560 --> 00:01:47.920]   And by Code Academy.
[00:01:47.920 --> 00:01:52.960]   Join the millions of people learning to code with Code Academy and see where coding can take you.
[00:01:52.960 --> 00:02:00.720]   Get 15% off your Code Academy Pro membership when you go to codecademy.com and use the promo code TWIG.
[00:02:00.720 --> 00:02:03.840]   It's time for TWIG.
[00:02:03.840 --> 00:02:07.280]   This week in Google, Leo Laport is out.
[00:02:07.280 --> 00:02:09.280]   I usually say Leo's gallivanting.
[00:02:09.280 --> 00:02:12.640]   Right now Leo, well he's probably in Mexico at this point.
[00:02:12.640 --> 00:02:13.800]   He got up super early.
[00:02:13.800 --> 00:02:19.280]   He and Lisa got up super early this morning to fly out to Mexico and hang out with Mike Elgin.
[00:02:19.280 --> 00:02:22.000]   And so they are having a great time.
[00:02:22.000 --> 00:02:23.600]   Sure, they're gallivanting.
[00:02:23.600 --> 00:02:30.000]   So I'm here in his place and I'm always happy to be on this week in Google when I get the opportunity to do it.
[00:02:30.000 --> 00:02:32.560]   Welcoming to the show.
[00:02:32.560 --> 00:02:35.120]   And Pruitt, what's going on man?
[00:02:35.120 --> 00:02:37.120]   Good.
[00:02:37.120 --> 00:02:38.640]   I am unbelievable, Mr. Howe.
[00:02:38.640 --> 00:02:39.920]   How are you, Lisa?
[00:02:39.920 --> 00:02:40.880]   Of course you are.
[00:02:40.880 --> 00:02:42.160]   You're always unbelievable.
[00:02:42.160 --> 00:02:44.880]   And you make me feel unbelievable because you're so unbelievable.
[00:02:44.880 --> 00:02:46.000]   I'm doing good.
[00:02:46.000 --> 00:02:47.280]   It's good to see you.
[00:02:47.280 --> 00:02:50.640]   Also joining us, Jeff Jarvis.
[00:02:50.640 --> 00:02:53.920]   Who? We have to do the full introduction here and I've got it.
[00:02:53.920 --> 00:02:54.560]   It's a mouthful.
[00:02:54.560 --> 00:02:56.160]   It's become tradition, you know.
[00:02:56.160 --> 00:02:57.040]   Take a deep breath.
[00:02:57.040 --> 00:02:57.920]   Take a deep breath.
[00:02:57.920 --> 00:02:59.360]   It's a little special today.
[00:02:59.360 --> 00:03:02.960]   The Leonard Tau Professor for journalistic innovation at the...
[00:03:17.840 --> 00:03:39.480]   Oh,
[00:03:39.480 --> 00:03:44.480]   Graduate School of Journalism at the City University of New York.
[00:03:44.480 --> 00:03:45.920]   Welcome to the show, Jeff.
[00:03:45.920 --> 00:03:47.600]   Let us give credit.
[00:03:47.600 --> 00:03:48.960]   Do we have the credit ready for who did that?
[00:03:48.960 --> 00:03:49.920]   Absolutely we do.
[00:03:49.920 --> 00:03:54.720]   Jake Overton sent us this barbershop quartet version.
[00:03:54.720 --> 00:03:56.000]   You know what would be really cool?
[00:03:56.000 --> 00:03:56.560]   Outstanding.
[00:03:56.560 --> 00:04:01.040]   There's probably a lot of people that watch and listen to this show that also are musically
[00:04:01.040 --> 00:04:01.760]   inclined.
[00:04:01.760 --> 00:04:04.880]   It'd be pretty sweet if like everybody did their own little version of this.
[00:04:04.880 --> 00:04:07.120]   But anyways, Jake, the first one.
[00:04:07.120 --> 00:04:07.920]   Notable for that.
[00:04:07.920 --> 00:04:13.120]   And so Craig Newmark himself in Twitter in the response to this offer said that he had
[00:04:13.120 --> 00:04:16.000]   Craig Newmark sounds himself, but his wife wouldn't let him share them.
[00:04:16.000 --> 00:04:22.880]   I see he's still doing that crowd work in his community gig.
[00:04:22.880 --> 00:04:23.840]   In his comedy.
[00:04:23.840 --> 00:04:24.080]   Yes.
[00:04:24.080 --> 00:04:26.080]   Yes, exactly.
[00:04:26.080 --> 00:04:27.920]   Awesome.
[00:04:27.920 --> 00:04:32.480]   We finally have a tune to play so you can save your pipes.
[00:04:32.480 --> 00:04:34.320]   You don't need to sing in this week.
[00:04:34.320 --> 00:04:37.040]   Although we'll be doing a lot of talking.
[00:04:37.040 --> 00:04:37.520]   A little moment.
[00:04:37.520 --> 00:04:39.440]   Yeah, right.
[00:04:39.440 --> 00:04:42.720]   Well, maybe in the future we'll all tag along.
[00:04:42.720 --> 00:04:46.400]   Although that's kind of hard to do like do a harmony with something
[00:04:46.400 --> 00:04:47.360]   really on the internet.
[00:04:47.360 --> 00:04:48.320]   Well, on TikTok, we can.
[00:04:48.320 --> 00:04:49.760]   You know what we should do?
[00:04:49.760 --> 00:04:50.880]   We should put it on TikTok.
[00:04:50.880 --> 00:04:51.200]   Yeah.
[00:04:51.200 --> 00:04:52.480]   And see what we can do with it.
[00:04:52.480 --> 00:04:54.080]   There we go.
[00:04:54.080 --> 00:04:55.440]   Making a meme.
[00:04:55.440 --> 00:04:55.840]   Of course.
[00:04:55.840 --> 00:04:56.720]   Let's make it happen.
[00:04:56.720 --> 00:05:01.680]   Also joining us today, not Stacey Stacey's actually out this afternoon.
[00:05:01.680 --> 00:05:04.080]   We'll hope to see her again next week.
[00:05:04.080 --> 00:05:08.720]   But joining us has been a while Matthew Ingram, Columbia journalism review.
[00:05:08.720 --> 00:05:10.560]   I don't have a song for you though, Matthew.
[00:05:10.560 --> 00:05:11.120]   I'm sorry.
[00:05:12.000 --> 00:05:13.600]   Yeah, I don't know how to do his own.
[00:05:13.600 --> 00:05:14.880]   Get your phone.
[00:05:14.880 --> 00:05:15.920]   Get your phone, Matthew.
[00:05:15.920 --> 00:05:18.240]   Well, that would take a long time.
[00:05:18.240 --> 00:05:20.080]   Nobody wants to hear that.
[00:05:20.080 --> 00:05:24.720]   Yeah, it's up to everyone to sing their own song going forward.
[00:05:24.720 --> 00:05:27.280]   We'll see what happens.
[00:05:27.280 --> 00:05:28.800]   Well, Jason, you're a musician.
[00:05:28.800 --> 00:05:29.920]   All right.
[00:05:29.920 --> 00:05:33.840]   I suppose I could do something, but I'm not going to do it.
[00:05:33.840 --> 00:05:34.640]   Not right now.
[00:05:34.640 --> 00:05:35.920]   Definitely not on the spot.
[00:05:35.920 --> 00:05:41.600]   No, I'm going to leave the spotlight on Jake because he deserves the spotlight this week.
[00:05:41.600 --> 00:05:42.480]   So there we go.
[00:05:42.480 --> 00:05:42.800]   It works.
[00:05:42.800 --> 00:05:46.640]   Well, it's good to see all of you and good to have you back, Matthew.
[00:05:46.640 --> 00:05:50.560]   And, man, that was kind of working on the rundown today.
[00:05:50.560 --> 00:05:56.400]   Like normally I'm behind the scenes producing a show and pulling back the curtain a little bit,
[00:05:56.400 --> 00:06:00.160]   I can at least admit right now that often with weeks like this,
[00:06:00.160 --> 00:06:04.320]   where there's just this barrage, this mountain of Facebook news and everything,
[00:06:04.320 --> 00:06:08.800]   I'm throwing the stuff in the rundown, feeling comfortable about the fact that like,
[00:06:08.800 --> 00:06:10.560]   at least I don't have to talk about this.
[00:06:10.560 --> 00:06:12.080]   This is all on Leo in the gang.
[00:06:12.080 --> 00:06:16.240]   This is one of those weeks where I do have to talk about all the Facebook stuff.
[00:06:16.240 --> 00:06:22.640]   Oh, it's a lot to manage, but we've got a lot of stuff to talk about this week.
[00:06:22.640 --> 00:06:26.320]   I suppose we could get the earnings out of the way because it is earnings week.
[00:06:26.320 --> 00:06:29.840]   And my golly, it seems like all companies are up.
[00:06:29.840 --> 00:06:31.920]   Everybody's doing good right now.
[00:06:31.920 --> 00:06:35.200]   Except for snap, but we'll get to that.
[00:06:35.200 --> 00:06:36.320]   Oh, yeah, that's right.
[00:06:36.320 --> 00:06:37.120]   That's at the bottom.
[00:06:37.120 --> 00:06:38.160]   That's right.
[00:06:38.160 --> 00:06:39.360]   Snap, not so much.
[00:06:39.360 --> 00:06:41.840]   Google doubled their profits.
[00:06:41.840 --> 00:06:45.840]   Facebook, they're kicking it out of the park.
[00:06:45.840 --> 00:06:47.840]   Their ad revenue rose 33%.
[00:06:47.840 --> 00:06:50.480]   They're raking in billions of dollars.
[00:06:50.480 --> 00:06:54.960]   Their Oculus other bet is working pretty well.
[00:06:54.960 --> 00:06:57.360]   I mean, it's nowhere near 28.3 billion.
[00:06:57.360 --> 00:06:59.920]   It's 230 or sorry, 734 million.
[00:06:59.920 --> 00:07:07.200]   But that seems important in the realm of the fact that Zuckerberg has been making
[00:07:07.200 --> 00:07:12.560]   such a big deal about this whole metaverse thing that hinges on the success, at least in my view,
[00:07:12.560 --> 00:07:14.560]   of Oculus and what it's doing there.
[00:07:14.560 --> 00:07:17.280]   So I suppose that's good news.
[00:07:17.280 --> 00:07:21.920]   Twitter, they're up as well, 37% year over year growth.
[00:07:21.920 --> 00:07:28.240]   And that's in spite of Apple's opt-in ad tracking switch that actually lowered revenue.
[00:07:28.240 --> 00:07:32.480]   They said it would have been higher, of course, but Apple did their thing.
[00:07:32.480 --> 00:07:34.560]   And we'll see what kind of impact that has.
[00:07:34.560 --> 00:07:36.720]   And then Microsoft, I didn't quite get to
[00:07:37.360 --> 00:07:43.920]   siphon through Microsoft's earnings very deeply, but they're reporting 22% growth.
[00:07:43.920 --> 00:07:45.280]   And then Jeff, you mentioned Snap.
[00:07:45.280 --> 00:07:46.160]   What's going on with Snap?
[00:07:46.160 --> 00:07:51.440]   So Snap was the one that was most hurt by Apple's ad move.
[00:07:51.440 --> 00:07:55.680]   And so it lost a lot of equity.
[00:07:55.680 --> 00:07:58.240]   For a while, Facebook did too.
[00:07:58.240 --> 00:08:00.320]   Who was it here?
[00:08:00.320 --> 00:08:06.560]   Fortune on the 22nd said that the ad changes have wiped out $142 billion
[00:08:06.560 --> 00:08:09.280]   off Snap, Facebook, and other online giants' equity.
[00:08:09.280 --> 00:08:12.320]   I'm not going to subscribe to Fortune.
[00:08:12.320 --> 00:08:13.680]   No, so that's all I can tell you.
[00:08:13.680 --> 00:08:17.920]   But that story, you get a headline and a lead.
[00:08:17.920 --> 00:08:18.400]   That's it.
[00:08:18.400 --> 00:08:23.840]   The real funny one is when Forbes says I've reached the end of the free articles.
[00:08:23.840 --> 00:08:25.600]   Like you charge for the stuff, Forbes.
[00:08:25.600 --> 00:08:28.000]   But anyway, it's like tweet on it.
[00:08:28.000 --> 00:08:30.960]   So Apple's changes.
[00:08:30.960 --> 00:08:35.840]   The thing about it is Apple's still targeting, right?
[00:08:35.840 --> 00:08:38.720]   And Apple is targeting because it has its own data.
[00:08:38.720 --> 00:08:40.800]   And so that's really the game here.
[00:08:40.800 --> 00:08:48.000]   It's not that Apple is pure than the morning, Julie Dawn in its ethics about this.
[00:08:48.000 --> 00:08:49.040]   They're targeting ads too.
[00:08:49.040 --> 00:08:51.040]   They're just cutting off their competitors.
[00:08:51.040 --> 00:08:54.000]   And Snap was the one that was most hurt most.
[00:08:54.000 --> 00:08:56.080]   Now Google has plenty of their own data.
[00:08:56.080 --> 00:08:57.760]   Facebook has its own data.
[00:08:57.760 --> 00:09:02.720]   I watched a Twitter was hurt some, but it has a different ad structure
[00:09:02.720 --> 00:09:05.600]   where it's not quite as dependent in the same way.
[00:09:05.600 --> 00:09:10.320]   I watched a call on Next Door, which is going to go public and it's back.
[00:09:10.320 --> 00:09:14.000]   And they were asked about Apple and they said, well, we know who our people are
[00:09:14.000 --> 00:09:15.760]   because it's real real identity.
[00:09:15.760 --> 00:09:19.360]   So we have our own first party data publishers.
[00:09:19.360 --> 00:09:24.160]   I think are going to get hurt badly by the Apple move because they don't have their own first party data.
[00:09:24.160 --> 00:09:28.000]   Oddly, and for all these years, they've still in the system and seeing people as a mass.
[00:09:28.000 --> 00:09:29.680]   So the Apple move, this is just the beginning of it.
[00:09:29.680 --> 00:09:37.520]   But I think Apple will have pretty profound impact on the media industries over the next year or two.
[00:09:37.520 --> 00:09:39.200]   And we'll see how this flushes out.
[00:09:39.200 --> 00:09:44.640]   Let's remember that Google decided to get out of its sandbox and not make the changes.
[00:09:44.640 --> 00:09:46.640]   It was going to make to replace cookies.
[00:09:46.640 --> 00:09:48.960]   So I don't think we have any idea where all this is going to land.
[00:09:48.960 --> 00:09:53.200]   And what do you think about this, Matthew?
[00:09:53.200 --> 00:09:59.280]   In spite of what Apple has made with the changes here and the impacts that it has on
[00:09:59.280 --> 00:10:03.840]   these companies and not to mention all of the attention that we're also going to talk about
[00:10:03.840 --> 00:10:06.400]   later in this show, everything else that's impacted.
[00:10:06.400 --> 00:10:10.320]   When I look at Facebook and Facebook's humming along and doing okay, obviously,
[00:10:10.320 --> 00:10:15.520]   this is three months and a quarter, but the last couple of weeks have been really damaging
[00:10:15.520 --> 00:10:16.400]   for that company.
[00:10:16.400 --> 00:10:20.560]   What do you envision the impact is going to be three months from now?
[00:10:20.560 --> 00:10:25.600]   Do you think we're going to see any sort of dip or pressure based on what's happening right now
[00:10:25.600 --> 00:10:26.880]   with Facebook and the spotlight?
[00:10:26.880 --> 00:10:27.360]   What do you think?
[00:10:28.240 --> 00:10:30.720]   My bet would be no.
[00:10:30.720 --> 00:10:35.040]   Historically, this stuff happens.
[00:10:35.040 --> 00:10:41.040]   There's been, in fact, worse, I would argue for Facebook, especially in terms of actual
[00:10:41.040 --> 00:10:42.480]   congressional hearings and so on.
[00:10:42.480 --> 00:10:48.160]   And the stock doesn't just seem to be completely divorced from those sorts of things.
[00:10:48.160 --> 00:10:49.600]   It just goes up.
[00:10:49.600 --> 00:10:56.560]   No one, at least investors, don't seem to care about the kind of things we're going to be talking about.
[00:10:57.200 --> 00:11:02.000]   And Matthew, not just the stock price, which is the result of the other metrics,
[00:11:02.000 --> 00:11:04.480]   but also the user numbers and the ad numbers.
[00:11:04.480 --> 00:11:06.800]   The stock price wouldn't be down if those were down.
[00:11:06.800 --> 00:11:10.320]   And that's to say, this is talked about throughout media.
[00:11:10.320 --> 00:11:13.840]   And media is going nuts about it, but I'm not sure the rest of the world cares nearly as
[00:11:13.840 --> 00:11:15.040]   much as Joe Scarborough does.
[00:11:15.040 --> 00:11:16.960]   No.
[00:11:16.960 --> 00:11:19.760]   I think we've seen that multiple times.
[00:11:19.760 --> 00:11:22.960]   I'm sure there will be calls.
[00:11:22.960 --> 00:11:25.600]   There are calls for a Facebook boycott.
[00:11:25.680 --> 00:11:32.800]   But even if hundreds of thousands of people boycott Facebook, there's still three billion
[00:11:32.800 --> 00:11:35.200]   more people who are happy to use it.
[00:11:35.200 --> 00:11:40.480]   And I think as a number of people have pointed out, in some countries, Facebook is basically
[00:11:40.480 --> 00:11:41.120]   the internet.
[00:11:41.120 --> 00:11:46.480]   That's how the vast majority of people experience the internet.
[00:11:46.480 --> 00:11:49.600]   There was an awful tweet to Dr. Roussett.
[00:11:49.600 --> 00:11:50.080]   I don't want to do it best.
[00:11:50.080 --> 00:11:55.280]   I believe Korda said it best a couple of weeks ago about just
[00:11:56.240 --> 00:12:00.880]   the friction that comes along with trying to leave Facebook.
[00:12:00.880 --> 00:12:05.680]   Whether it's once you get off of it and then you're trying to figure out a way to communicate
[00:12:05.680 --> 00:12:10.560]   with your peers that are actually on the platform, they can't seem to get away from it.
[00:12:10.560 --> 00:12:16.080]   And you each share with them different options, whether it be slack or discord or what have you.
[00:12:16.080 --> 00:12:18.720]   And they just like, no, Facebook's easier.
[00:12:18.720 --> 00:12:23.040]   That's my challenge entirely.
[00:12:23.040 --> 00:12:25.280]   That's been my experience the past three.
[00:12:25.280 --> 00:12:31.520]   I think it's now three or four years since I officially deleted my account on Facebook.
[00:12:31.520 --> 00:12:38.560]   But I've noticed that's been one of the real big drawbacks is my interaction with a lot of
[00:12:38.560 --> 00:12:43.840]   the people who I consider friends, but I'm obviously not in the habit or the mindset to
[00:12:43.840 --> 00:12:47.680]   reach out to them on text message or an email on a regular basis.
[00:12:47.680 --> 00:12:53.520]   It's just not the same as having their lives in your face on the feed that you're checking on
[00:12:53.520 --> 00:12:59.040]   a daily basis and interacting with them in such a casual kind of way in that regard.
[00:12:59.040 --> 00:13:00.800]   That's what makes it so addictive.
[00:13:00.800 --> 00:13:02.560]   Yeah, that's what makes it so addictive.
[00:13:02.560 --> 00:13:06.800]   And that's what we're talking about when we talk about network effects.
[00:13:06.800 --> 00:13:09.840]   My being with your friends is not a bad addiction.
[00:13:09.840 --> 00:13:11.840]   No, no, no, no.
[00:13:11.840 --> 00:13:15.200]   No, but if it only comes through one platform,
[00:13:15.840 --> 00:13:18.160]   then you're kind of addicted to that platform.
[00:13:18.160 --> 00:13:24.560]   I think for me, since deleting Facebook however many years ago, it helped me to
[00:13:24.560 --> 00:13:29.360]   further see exactly who my friends are and my true friends are because the people that I
[00:13:29.360 --> 00:13:35.600]   interacted with on Facebook, there was a large percentage of them that had all of my contact
[00:13:35.600 --> 00:13:39.360]   information, including my phone numbers, so they can just shoot a text or whatever.
[00:13:39.360 --> 00:13:45.600]   And it's a tiny percentage of those folks that actually still keep in touch outside of
[00:13:45.600 --> 00:13:51.680]   Facebook. The rest were just looky-lose and just click into the lightroom and not necessarily
[00:13:51.680 --> 00:13:56.800]   taking, not necessarily taking into effect what Ant Perot was doing or what Ant Perot was
[00:13:56.800 --> 00:14:02.000]   family. I think the hard part is when it's when it's family, so one of our daughters
[00:14:02.000 --> 00:14:08.000]   deleted her Facebook account and then was forced to get back on again because she said she missed
[00:14:08.000 --> 00:14:15.520]   so much of what was happening, photos and babies and news that was just shared amongst
[00:14:15.520 --> 00:14:19.360]   all sorts of family members that she didn't find out about.
[00:14:19.360 --> 00:14:25.200]   Sadly, I think it's important lumping family with my friends on this scenario.
[00:14:25.200 --> 00:14:29.760]   I can't speak for y'all because a lot of my family, they couldn't tell you the first thing
[00:14:29.760 --> 00:14:35.600]   about me right now. All they know is I don't live in Charlotte anymore. They know I moved,
[00:14:35.600 --> 00:14:40.160]   that's about it. They don't know what I do or why I do what I do and so forth because it's not
[00:14:40.160 --> 00:14:46.800]   plastered all over Facebook. It's not rocket. It's not rocket. It's not rocket. It's not rocket.
[00:14:46.800 --> 00:14:54.960]   Is that being fair to your family and friends? If norms and structures change and you're the odd
[00:14:54.960 --> 00:14:58.720]   one out and they're there and you're not, can't they say the same thing about you that boy,
[00:14:58.720 --> 00:15:02.400]   Ant used to be around and he used to care about us but he just abandoned us.
[00:15:02.400 --> 00:15:08.400]   Oh, that's, yeah, they can definitely say that. But I can also say that for a good two years,
[00:15:08.400 --> 00:15:14.560]   I gave it a fair shake and tried to interact with my family on that platform back and forth
[00:15:14.560 --> 00:15:24.160]   pretty regularly and it was never reciprocated. So again, I started to see the true colors of people
[00:15:24.160 --> 00:15:29.280]   on that platform because a lot of people on there just for the dopamine hit, they want to see that
[00:15:29.280 --> 00:15:35.360]   like button go up. That's all I was for them. It's just somebody that could potentially hit
[00:15:35.360 --> 00:15:39.120]   the like button on something they shared.
[00:15:39.120 --> 00:15:47.760]   Yeah, definitely about Facebook. This is a whole side conversation but a friend of ours,
[00:15:47.760 --> 00:15:55.360]   her mother was dying effectively since the past away and she loved Facebook for the
[00:15:55.360 --> 00:16:02.400]   funny cat videos and stuff like that and kept her amused and so I actually started posting
[00:16:02.400 --> 00:16:08.240]   things specifically for her. So I would think about as I went through the day,
[00:16:08.240 --> 00:16:13.120]   if there was something funny, I would post it on there just so that she would have something to look at.
[00:16:13.120 --> 00:16:14.720]   That's cool.
[00:16:14.720 --> 00:16:24.800]   And that's also selfless. That's the thing. It's that's a selfless act versus what most of the
[00:16:24.800 --> 00:16:30.800]   stuff we see on any of these social media platforms is where we're a little more inward and thinking
[00:16:30.800 --> 00:16:34.480]   about our own game. And I say we because I'm included myself in it.
[00:16:34.480 --> 00:16:45.040]   Yeah. What about this and Zuckerberg pointed this out in the earnings, pointed out this decline
[00:16:45.040 --> 00:16:52.960]   in younger young adult usage, in teen usage, specifically said, you know, called out TikTok
[00:16:52.960 --> 00:16:58.960]   as one of the one of the most effective competitors we've ever faced, which seems pretty darn
[00:16:58.960 --> 00:17:04.240]   spot on TikTok is a force right now. We saw that coming a couple of years ago, but here we are.
[00:17:04.240 --> 00:17:13.360]   Also mentioned plans to shift more to video via specifically Instagram and Reels. Obviously,
[00:17:13.360 --> 00:17:19.040]   we know that he has bigger ambitions on transitioning the company into being more of a metaverse,
[00:17:19.040 --> 00:17:23.440]   whatever the heck that is, company, maybe even a name change, it's somewhere down the line. But
[00:17:26.400 --> 00:17:32.880]   is Facebook in a position where where any of us here feel like they're capable of recapturing
[00:17:32.880 --> 00:17:37.520]   that younger energy or are some of these, you know, kind of news stories? Like, are the
[00:17:37.520 --> 00:17:42.960]   are the younger kids? Well, they're probably too young to really clue into a lot of that stuff,
[00:17:42.960 --> 00:17:47.520]   but but they're not too young to clue into the fact that Facebook is let's put in an air quotes
[00:17:47.520 --> 00:17:54.720]   uncool. Like, can Facebook change that change that perception with moves like this? What do you think?
[00:17:55.280 --> 00:18:00.480]   I think it's going to be tough. Yeah, I think it's hard to be interested.
[00:18:00.480 --> 00:18:07.120]   I'll be interested to hear what Jeff thinks, but I, you know, I would never say it's impossible
[00:18:07.120 --> 00:18:12.400]   because I think they did compete with Snap pretty effectively. You know, they acquired Instagram,
[00:18:12.400 --> 00:18:17.200]   which brought in a whole bunch of young users. But if you look at the numbers,
[00:18:17.840 --> 00:18:26.480]   it's pretty bleak for them. If once you get below like 35, it's not good. And so I don't know if
[00:18:26.480 --> 00:18:32.480]   Reels is going to be enough to, you know, it's, it's fine. But is it, I don't know that it's enough
[00:18:32.480 --> 00:18:40.080]   to drag people away from TikTok. Right. I think that, yeah, well, Instagram alone, Instagram,
[00:18:40.080 --> 00:18:44.160]   as you just said, Matthew was brought in the young people. I think it was smart and was the way to go.
[00:18:46.080 --> 00:18:51.760]   I don't understand Zuck's better verse vision. He's talking tomorrow in a Facebook event. We can,
[00:18:51.760 --> 00:18:56.640]   the developers event online. And his keynote is going to be able to metaverse. I'm curious what
[00:18:56.640 --> 00:19:01.680]   he's going to say because I still don't get it as we said on the show a week ago. Since we talked
[00:19:01.680 --> 00:19:09.040]   on the show that we could go about the name change, I threw out a theory that I was half serious,
[00:19:09.040 --> 00:19:15.680]   but I'm getting more serious about it. I start to think that I don't know if there's Zuckerberg
[00:19:15.680 --> 00:19:21.680]   sees this or not, but it's time for him to kick himself upstairs. It's that's what's kind of
[00:19:21.680 --> 00:19:28.720]   can't be rescued, I think, is the current management team. And so if Zuckerberg were
[00:19:28.720 --> 00:19:35.200]   off thinking metaverse thoughts in his ex lab of Facebook, still controlling, you know,
[00:19:35.200 --> 00:19:40.560]   importantly, stock and that's the company, so he's not gone. But if he took himself out of that,
[00:19:40.560 --> 00:19:44.080]   as I saw the story this week, this is Facebook likes to think it's flat, but it's not. It all
[00:19:44.080 --> 00:19:49.760]   leads to one peek and that's Zuckerberg. If that weren't the case, if let's say Chris Cox took
[00:19:49.760 --> 00:19:54.720]   over or somebody from the outside took over Facebook as a brand and Instagram is run as a separate
[00:19:54.720 --> 00:19:59.120]   brand, which it kind of is now, that's a different question. So here's my question.
[00:19:59.120 --> 00:20:01.920]   If Zuckerberg was interested in the same thing.
[00:20:02.640 --> 00:20:06.160]   Yeah, and by the way, let me just add one thing here because I think there is something that
[00:20:06.160 --> 00:20:19.040]   is important. I saw a terrible tweet today to which a writer for Buzzfeed luckily called it what it
[00:20:19.040 --> 00:20:24.480]   is, which was which was anti-Semitism calling for Zuckerberg to be executed in a Nuremberg trial.
[00:20:24.480 --> 00:20:29.920]   I mean, it's getting ridiculous. It's getting bad on the other side of this now. So the rhetoric
[00:20:29.920 --> 00:20:36.400]   is so ridiculous and so over the top and on all sides of this. So what if Zuckerberg did kind of
[00:20:36.400 --> 00:20:41.360]   pull himself out, just as a thought experiment? What if if he really did hand over to a strong
[00:20:41.360 --> 00:20:46.720]   manager, he truly worked there, is like Larry and Sergey kind of disappears, goes off? How much
[00:20:46.720 --> 00:20:55.920]   of a difference do you think that would make in the PR regulatory view as stock equity view of
[00:20:55.920 --> 00:21:03.840]   Facebook? I don't think any. I don't think he would change the way they're still the same core of
[00:21:03.840 --> 00:21:09.120]   leadership there in place that's already. He still controls it. He still controls it.
[00:21:09.120 --> 00:21:13.920]   All the votes, the entire board, then he would just be a puppet master sort of.
[00:21:13.920 --> 00:21:19.920]   Exactly. I don't, you know, and I don't think that would change anything about
[00:21:19.920 --> 00:21:25.600]   the business model or targeting or privacy or data or any of the things that people seem
[00:21:25.600 --> 00:21:34.400]   concerned about. You were asking if there's a way to capture more of the youth demographic.
[00:21:34.400 --> 00:21:40.960]   I think that that's what reminds me of the way things are with AI. You have to look at the people
[00:21:40.960 --> 00:21:49.120]   working on the product. Like who's on the team of developers there across the Facebook platform
[00:21:49.120 --> 00:21:54.880]   that's that can relate to those younger people? I'm pretty sure those folks have almost aged out
[00:21:54.880 --> 00:21:59.920]   of that demographic by now. Right. So why would we expect them to be able to relay
[00:21:59.920 --> 00:22:04.000]   and be able to pull those younger folks into this ecosystem?
[00:22:04.000 --> 00:22:09.840]   I just keep picturing Mark Zuckerberg in the Hello fellow kids
[00:22:09.840 --> 00:22:16.480]   with the skateboard and wearing an Oculus Quest.
[00:22:17.280 --> 00:22:26.240]   Where I asked in that as well. I mean, music band.
[00:22:26.240 --> 00:22:35.760]   Is that kind of part of part of the appeal though or the potential appeal to
[00:22:35.760 --> 00:22:43.200]   younger users that like some sort of metaverse slash VR focus thing? I mean, I don't know that
[00:22:43.200 --> 00:22:49.760]   it necessarily is. I feel like metaverse in the way that I understand it, which is not very much.
[00:22:49.760 --> 00:22:56.160]   But in like my own interpretation of it, I feel like it's still a ways off. And does Zuckerberg
[00:22:56.160 --> 00:23:03.440]   think that by shifting the company towards being more of a metaverse VR, whatever company it is,
[00:23:03.440 --> 00:23:10.800]   that it also ends up appealing to the younger users, which are a part of the pipeline.
[00:23:11.840 --> 00:23:15.600]   In my view, that's even more far out than my theory. I don't think anybody's going to care
[00:23:15.600 --> 00:23:21.360]   about that. I don't think it distracts anymore. I actually think it has some potential. I know
[00:23:21.360 --> 00:23:28.160]   that Facebook has been talking mostly about workplace. You can have effectively zoom meetings,
[00:23:28.160 --> 00:23:33.280]   but with your avatar and 3D, which strikes me as incredibly boring. But
[00:23:33.280 --> 00:23:40.960]   and I only want to do that if I can be a giant eyeball or something like from second life.
[00:23:40.960 --> 00:23:47.280]   But anyway, it does seem as though there is some opportunity for, you know, I know lots of kids
[00:23:47.280 --> 00:23:53.600]   are obsessed with whether it's Minecraft or Roblox or there's lots of potential there. I think for
[00:23:53.600 --> 00:24:01.600]   kids are more used, I think, to being open to that type of environment to a fully virtual environment.
[00:24:01.600 --> 00:24:04.000]   So whether Facebook can pull that off or not, I don't know.
[00:24:06.000 --> 00:24:12.080]   There's certainly positioned in a way that, at least from a technological standpoint,
[00:24:12.080 --> 00:24:17.600]   and from having the money to kind of back it up, there's certainly in a position to be the player
[00:24:17.600 --> 00:24:23.200]   that has the most potential of making something like that happen. I just don't know if it satisfies
[00:24:23.200 --> 00:24:28.240]   kind of like what I was talking about. If it actually really energizes and gets the younger
[00:24:28.240 --> 00:24:33.440]   users really excited about Facebook again. Yeah, I agree, Jeff. I think that's much further,
[00:24:34.000 --> 00:24:39.520]   further off in the distance. And by the time they get that going, what we consider young will
[00:24:39.520 --> 00:24:44.240]   have shifted completely. Right. And the kids of today will be the adults of tomorrow.
[00:24:44.240 --> 00:24:51.760]   Hmm. So that's true. That's true. Well, it's, you know, in Matthews in my world,
[00:24:51.760 --> 00:24:57.200]   we kept on hearing, and we still hear sometimes today, "Oh, when the kids grow up, they'll start
[00:24:57.200 --> 00:25:06.640]   buying newspapers." Right. And it ain't happening. And obviously, the choices are my age or older.
[00:25:06.640 --> 00:25:10.480]   It's like record albums. They're going to start. It's going to become a whole niche.
[00:25:10.480 --> 00:25:17.200]   They're going to spin that vinyl. Right. And so I think to the kids today have such a different
[00:25:17.200 --> 00:25:22.880]   world and so many more choices and different choices. And I hope they experiment with those.
[00:25:23.440 --> 00:25:28.560]   And so yeah, here's the other thing about it. And you've heard me do this before. The internet
[00:25:28.560 --> 00:25:31.760]   is not baked. It's not finished. The current proprietors are not the forever proprietors.
[00:25:31.760 --> 00:25:38.800]   Facebook is not forever. And yeah, you guys who decided to quit it, you know, have some things
[00:25:38.800 --> 00:25:45.040]   you can't do, but your life goes on. I don't think it's that big a deal. And I think that
[00:25:45.040 --> 00:25:49.280]   there will be other things. And I think maybe Zuckerberg sees that himself. That's why he's
[00:25:49.280 --> 00:25:56.800]   grasping for the metaverse. You know, I think I've seen a dangerous trend lately. I saw two
[00:25:56.800 --> 00:26:02.160]   pieces of people I respected the last week asking whether there's too much speech. And I so hate
[00:26:02.160 --> 00:26:08.320]   that question. Because who decides what's too much? But I do think we move into a world where we need
[00:26:08.320 --> 00:26:12.160]   services that do a better job of telling us what's worth listening to, who we care about,
[00:26:12.160 --> 00:26:16.480]   what's relevant to us, what's valuable to us, what's intelligent, what's, what's accurate,
[00:26:16.480 --> 00:26:21.440]   all kinds of quality judgments where we're praying all this resources now into playing
[00:26:21.440 --> 00:26:28.480]   whackable with bad crap. Sorry, John, on Facebook. That's not going to get us very far. I said almost
[00:26:28.480 --> 00:26:35.680]   another word. What does that really gain us? It gains us nothing but a lot of stomach acid and
[00:26:35.680 --> 00:26:40.800]   and agita. Whereas if we put resources, and this is what, you know, the institution of the publisher
[00:26:40.800 --> 00:26:45.360]   and the editor and the newspaper were, what are the institutions for this age? I hope young people
[00:26:45.360 --> 00:26:50.160]   invent those institutions to find stuff worth listening to. And so it's interesting that
[00:26:50.160 --> 00:26:56.000]   Anil Dash said that he was working on something that would help surface
[00:26:56.000 --> 00:27:02.160]   good content on Facebook and Facebook shut him down and cut off access to its API.
[00:27:02.160 --> 00:27:09.600]   Wow. I didn't see that. I don't know. I'm starting point would be Facebook though.
[00:27:12.080 --> 00:27:15.200]   I mean, there's a lot of stuff on there. There is. That's true.
[00:27:15.200 --> 00:27:21.760]   Yeah, I don't know where it is, but I think there's a lot of content on the web too. It's also about
[00:27:21.760 --> 00:27:30.560]   the open web. I think we want to support. Bring back blogs and RSS. Yeah. We need to go back to blogs
[00:27:30.560 --> 00:27:36.880]   and get our models conversation. The blogroll is going with the friends.
[00:27:36.880 --> 00:27:40.080]   Let's head into the future. Let's go back to blogs. Sorry. Yeah.
[00:27:40.080 --> 00:27:44.720]   Yeah. Oh, no, I was just saying I had a general conversation over the weekend with a friend
[00:27:44.720 --> 00:27:52.880]   just about having a voice for everybody. And it's great that everybody has a voice.
[00:27:52.880 --> 00:27:57.680]   And at the same time, it could be pretty problematic that some of the stuff that comes out of folks'
[00:27:57.680 --> 00:28:03.920]   mouths lead to a lot of misinformation and turmoil and chaos and all of that.
[00:28:04.800 --> 00:28:11.280]   But I don't know. I think that beats the alternative. I do like that. Yeah.
[00:28:11.280 --> 00:28:19.520]   Those other people that didn't really have a voice have a voice now, more so than them not
[00:28:19.520 --> 00:28:24.160]   having a voice and a stiller with the stuff that we have to deal with. You know, does that make
[00:28:24.160 --> 00:28:29.840]   any sense? Yeah. Yeah. I feel empowered and supported in some way and sharing that. This
[00:28:29.840 --> 00:28:35.760]   kind of reminds me of your article, Matthew, from last week, that British MPs calling for an end
[00:28:35.760 --> 00:28:42.560]   to online anonymity and just the effects that something like that could possibly have.
[00:28:42.560 --> 00:28:48.880]   I don't know. If you want to do a little summary of that article, I'd appreciate it. But
[00:28:48.880 --> 00:28:53.600]   it seems to kind of draw on the same tug on the same cord from my perspective.
[00:28:53.600 --> 00:28:58.720]   Yeah. And I think this is something that comes up all the time. Britain has been going through
[00:28:59.520 --> 00:29:06.640]   a big debate for years about online harms and how to, you know, what action to take
[00:29:06.640 --> 00:29:12.640]   against them. There was a white paper a couple of years ago. There's a bill now called the online
[00:29:12.640 --> 00:29:21.760]   safety bill. And when this British MP was stabbed at a sort of open house, a number of MPs said,
[00:29:21.760 --> 00:29:25.840]   you know, we need to add an amendment to the safety bill that removes an amendment,
[00:29:25.840 --> 00:29:31.120]   despite the fact that as far as I can tell, there's no connection between this stabbing and the
[00:29:31.120 --> 00:29:36.960]   person who's been accused and online anonymity. So it was literally just an opportunity for
[00:29:36.960 --> 00:29:42.720]   people to kind of write a hobby horse about anonymity. And yet all the research that we have
[00:29:42.720 --> 00:29:49.120]   shows that if you got rid of anonymity and required quote unquote real identities, you would
[00:29:50.080 --> 00:29:57.040]   smother so much potentially, you know, important speech from people who, for one reason,
[00:29:57.040 --> 00:30:04.160]   another cultural or political or financial can't reveal their identities. So, but it's something
[00:30:04.160 --> 00:30:10.560]   that keeps coming up. Jeff Kossaf, who wrote the book on section 230, and he suffers on Twitter
[00:30:10.560 --> 00:30:16.000]   every day trying to correct people from their Mr. Francis about it, has a new book coming out
[00:30:16.560 --> 00:30:22.640]   very soon. Best and worst thing he ever done, right? Yeah. So he has one new book called
[00:30:22.640 --> 00:30:27.280]   the United States of Anonymous coming up very soon. I blurbed it because it's very, very good.
[00:30:27.280 --> 00:30:33.760]   And so the next attack, yes, is going to be against anonymity. And then the British
[00:30:33.760 --> 00:30:41.920]   legislation, Matthew, you've been warped it. I blogged it. No, I blurbed it. I blurbed it.
[00:30:41.920 --> 00:30:48.640]   Okay, there we go. I won't blog it, but I blurbed it. Sorry. Words are hard. Funny words of our
[00:30:48.640 --> 00:30:56.320]   language. More I see, you blurb writing is a thing. I had to go through four or five versions.
[00:30:56.320 --> 00:30:59.840]   Jeff Kossaf reads together history of legal issues in public affairs in this vital, timely,
[00:30:59.840 --> 00:31:04.480]   and highly readable book. Now, how's that for blurbies? That's fine. I've blurbed.
[00:31:04.480 --> 00:31:09.280]   And someone just suggested the blurb for me and said, is this okay? And I said, yes.
[00:31:10.320 --> 00:31:18.560]   Yeah. Yeah. So anyway, Kossaf is writing about anonymity and the British law frightens me to death,
[00:31:18.560 --> 00:31:23.440]   of legislation, frankly, to death because it goes after not just illegal speech, but legal,
[00:31:23.440 --> 00:31:27.840]   but harmful speech without defining it. It puts a chill on the speech because everybody's going to
[00:31:27.840 --> 00:31:33.760]   be scared of what to take down YouTube made a mistake recently of taking down a video. And
[00:31:33.760 --> 00:31:37.360]   there's going to be false positives more and more and more and more if we go after this.
[00:31:37.360 --> 00:31:40.400]   Then if you go after anonymity, as Matthew said, you go after the vulnerable.
[00:31:40.400 --> 00:31:46.720]   So we get less speech. This is what some institutions want. They do indeed want less speech. But as
[00:31:46.720 --> 00:31:52.720]   Ant was saying, we'll take the equation of hearing people we couldn't hear before in mass media.
[00:31:52.720 --> 00:32:00.960]   I think the risk is, if you might be okay with the UK's bill or Canada's talking about a similar
[00:32:00.960 --> 00:32:06.640]   bill, but there are lots of countries that are going to take that poll and run with it and
[00:32:06.640 --> 00:32:11.280]   bring in legislation that prevents all sorts of people from speaking. In fact, they're doing it
[00:32:11.280 --> 00:32:17.920]   right now based on things like fake news, which is whatever the government defines as something you
[00:32:17.920 --> 00:32:28.000]   can't say. Cool stuff. We've got a whole lot more coming up. We're going to take a break.
[00:32:28.000 --> 00:32:32.960]   And then we'll get right back into all this stuff. It's great to have you all here. Jeff Jarvis,
[00:32:32.960 --> 00:32:39.920]   of course, and Pruitt, Matthew Ingram. I love talking with you guys about all this stuff.
[00:32:39.920 --> 00:32:45.760]   I appreciate that you're here. Today's episode of this week in Google has brought to you
[00:32:45.760 --> 00:32:51.040]   by something really cool. This is all about accessibility. It's userway.org. And userway
[00:32:51.040 --> 00:32:58.640]   is all about bringing accessibility to the entire web. Because if you're not bringing
[00:32:58.640 --> 00:33:04.400]   accessibility to your website, you're leaving a whole lot of people out in the cold. They can't
[00:33:04.400 --> 00:33:10.960]   buy your product. They can't find out information about your product or follow what you're doing.
[00:33:10.960 --> 00:33:15.760]   If your site is not set up to appeal to everyone and to be accessible by everyone,
[00:33:15.760 --> 00:33:20.800]   then you're losing out. And they're losing out too. Every website without exception needs to be
[00:33:20.800 --> 00:33:26.240]   accessible. It's because it's out there. It's a public entity. And it's the right thing to do.
[00:33:26.240 --> 00:33:31.440]   Federal ADA law actually mandates equal access to services for all Americans,
[00:33:31.440 --> 00:33:36.880]   which means that you could actually be liable if your website does not meet ADA laws for accessibility.
[00:33:36.880 --> 00:33:42.720]   So that's where userway comes in. Has an incredible AI-powered solution that tirelessly
[00:33:42.720 --> 00:33:50.480]   enforces the hundreds of WCAG guidelines. And all you need is a single line of JavaScript code.
[00:33:50.480 --> 00:33:56.880]   It's that easy. Userway can achieve more than an entire team of developers with just that. Userway's
[00:33:56.880 --> 00:34:01.760]   AI and machine learning solutions actually power accessibility for more than one million websites,
[00:34:01.760 --> 00:34:08.640]   leading brands. The brands that you've that you know well, Coca-Cola, Disney, eBay, FedEx. That's
[00:34:08.640 --> 00:34:14.400]   just a few of them. So many more. And now userway is actually making its best-in-class enterprise
[00:34:14.400 --> 00:34:20.880]   level accessibility tools available to small and medium-sized businesses. And when you scale,
[00:34:20.880 --> 00:34:28.400]   you'll need a userway to do it. It's an accessible and compliant website is ultimately the goal.
[00:34:28.400 --> 00:34:32.960]   It isn't just the right thing to do. It also makes business sense. Like I said, it's an Achilles
[00:34:32.960 --> 00:34:40.480]   heel for websites to give everyone access to all the functions and aspects of your website.
[00:34:40.480 --> 00:34:46.720]   Registration forms, navigation menus, shopping carts. So many times these things are just not
[00:34:46.720 --> 00:34:52.480]   accessible. And that means that you're leaving millions of people out and you know, userway's
[00:34:52.480 --> 00:34:56.240]   going to make that a whole lot easier for you. And enable them to purchase your products,
[00:34:56.240 --> 00:35:00.560]   which is what you're hoping for as well. For years, userway has been on the cutting edge.
[00:35:00.560 --> 00:35:04.880]   I've been creating innovative accessibility technologies that actually push the envelope of
[00:35:04.880 --> 00:35:12.400]   what's possible with AI, machine learning, computer vision. Userway's AI automatically fixes violations
[00:35:12.400 --> 00:35:17.760]   at the code level. It's all done automatically. When you're visiting the site, this stuff happens.
[00:35:17.760 --> 00:35:21.040]   You don't even know that it's happened here. Just a couple of things that Userway can do.
[00:35:21.040 --> 00:35:27.600]   It can auto generate image alts. So it's essentially putting text to the images that you have on your
[00:35:27.600 --> 00:35:32.960]   site. If you haven't already put in those image alts, the AI can recognize, and we talked about it
[00:35:32.960 --> 00:35:36.960]   many times on this, we can Google this kind of technology. It can recognize what's going on
[00:35:36.960 --> 00:35:43.040]   inside of the image and actually turn that into text so that everybody can get those image alts
[00:35:43.040 --> 00:35:47.680]   if they can't see the image. At least they can read the text or have it read to them. It
[00:35:47.680 --> 00:35:53.920]   remediates complex nav menus, navigation menus. It ensures all pop ups are totally accessible,
[00:35:53.920 --> 00:36:00.240]   fixes vague link violations, any broken links, all that stuff. And it ensures that your website
[00:36:00.240 --> 00:36:07.440]   makes use of accessible colors, which can be very easy to overlook. And more importantly,
[00:36:07.440 --> 00:36:13.120]   you're still maintaining your brand. So it's not changing the colors of your brand,
[00:36:13.120 --> 00:36:23.680]   but it is taking any inaccessible colors, these colors that are easy for someone who's visiting
[00:36:23.680 --> 00:36:29.440]   the site and has trouble recognizing certain colors, this is going to correct those colors
[00:36:29.440 --> 00:36:33.600]   so that they can see everything. And some things are missed along the way. And it gives you a
[00:36:33.600 --> 00:36:38.080]   detailed report of all the violations that were fixed on your website, which is super useful to
[00:36:38.080 --> 00:36:46.000]   have. Userway is platform agnostic. So if you're using WordPress, Shopify, Wix, you're clear,
[00:36:46.000 --> 00:36:51.200]   userway is cost effective, it's easy to use. And those aren't the only platforms, by the way.
[00:36:51.200 --> 00:36:57.280]   I mean, you know, the sky's the limit. Same goes for AM, site core, share point. Userway actually
[00:36:57.280 --> 00:37:02.800]   integrates seamlessly with all. And you can let userway help your business meet its compliance
[00:37:02.800 --> 00:37:07.680]   goals and improve the experience for your users. Check out their free scanning tool. They have a
[00:37:07.680 --> 00:37:14.240]   free scanning tool that you can use to see if your website is ADA compliant. The Voice of Siri,
[00:37:14.240 --> 00:37:21.200]   many would consider the most popular voice assistant has a message about userway.
[00:37:21.200 --> 00:37:27.360]   Userway is trusted by more than 1 million websites and 60 million users with disabilities.
[00:37:27.360 --> 00:37:33.760]   Visit userway.org to learn how one line of code can make your website accessible.
[00:37:33.760 --> 00:37:41.600]   Userway can make any website fully accessible and ADA compliant with userway. Everyone who visits
[00:37:41.600 --> 00:37:47.040]   your site can browse seamlessly and customize it to fit their needs. It's also a perfect way
[00:37:47.040 --> 00:37:51.120]   to showcase your brand's commitment to millions of people with disabilities.
[00:37:51.120 --> 00:37:57.680]   Go to userway.org/twit and you'll get 30% off userway's AI powered accessibility solution
[00:37:57.680 --> 00:38:06.000]   userway making the internet accessible for everyone. Visit userway.org/twit today.
[00:38:06.000 --> 00:38:09.040]   And we thank userway for their support of this week in Google.
[00:38:09.040 --> 00:38:16.400]   I mean, when I'm a 95 year old, nearly deaf father up here and and and vision going to,
[00:38:16.400 --> 00:38:21.840]   I've gotten such respect for accessibility and the things that just are hard for him and hard to
[00:38:21.840 --> 00:38:25.840]   get to work for him in this plane. So accessibility is just vital and I've not paid enough attention
[00:38:25.840 --> 00:38:29.840]   to it in my career and I feel awful that it took this moment for me to see that. So this is a really
[00:38:29.840 --> 00:38:35.280]   important sponsor and not just for what it does, but for the message it sends. So I'm glad it's
[00:38:35.280 --> 00:38:41.360]   done. Absolutely. Totally agree. And it's important to shine, you know, continue shining a light on
[00:38:42.080 --> 00:38:48.080]   the ways that things are lacking from an accessibility standpoint on the internet.
[00:38:48.080 --> 00:38:53.440]   And we try to do that on these shows, but it's really easy to lose the focus of that, right?
[00:38:53.440 --> 00:38:58.400]   When these aren't problems that affect you directly, it's easy to overlook it, but super important.
[00:38:58.400 --> 00:39:06.080]   Let's see here. Do we, I mean, I feel like we kind of like this ties in with what we were talking
[00:39:06.080 --> 00:39:13.280]   about before is the whole Facebook papers thing. At the same time, I'm going to totally admit that
[00:39:13.280 --> 00:39:21.600]   I am like on Facebook revelation overload. Like I've kind of at this point just accepted the
[00:39:21.600 --> 00:39:25.920]   fact that, hey, there's a bunch of stuff that's leaked out and you know, I've read a few headlines
[00:39:25.920 --> 00:39:30.000]   and read through some articles and everything, but I'm exhausted by it. That's where I stand on
[00:39:30.000 --> 00:39:36.000]   Facebook news right now. Don't feel bad. I know I don't think though. I completely understand
[00:39:36.000 --> 00:39:42.000]   and in fact, I think, yeah, I think a lot of journalists would agree there's just too much.
[00:39:42.000 --> 00:39:47.120]   And that's one of my problems with the way that this was rolled out. I don't know who to blame
[00:39:47.120 --> 00:39:56.320]   Princess Hagen or her handlers or whoever, but to just to have to create the kind of situation where
[00:39:56.320 --> 00:40:03.680]   15 or 20 or 30 different outlets are all writing the exact same story with subtle details about
[00:40:03.680 --> 00:40:08.480]   the same five things. It seems like a kind of our way to handle.
[00:40:08.480 --> 00:40:15.200]   Well, then you can you explain the guy because I missed this too. I agree with you with you, Jason.
[00:40:15.200 --> 00:40:21.440]   I just I'm overloaded. So I missed things. One thing I missed which I bet you followed Matthew
[00:40:21.440 --> 00:40:26.480]   was the controversy about the journalist consortium over the documents and how it came together,
[00:40:26.480 --> 00:40:29.280]   that it's breaking apart. And what happened there? Can you explain that?
[00:40:30.560 --> 00:40:36.800]   So I wish I knew all I know is that there was an initial consortium and there was an initial
[00:40:36.800 --> 00:40:42.800]   embargo. And then the New York Times effectively said, embargoes don't apply to us.
[00:40:42.800 --> 00:40:50.160]   You're the New York Times. And then you're not. You know, they they said, oh, this is based on
[00:40:50.160 --> 00:40:55.360]   other stuff, not what was in the documents. And then everybody else was like, oh, okay, I guess
[00:40:55.920 --> 00:41:01.120]   it's okay for the time. So we'll just, you know, so this is a classic journalistic problem.
[00:41:01.120 --> 00:41:11.040]   Cooperation lasts up until someone thinks they can get a little extra attention. And so then what
[00:41:11.040 --> 00:41:18.880]   you get is just a dog pile of fighting over scraps and everyone trying to sort of make the most out
[00:41:18.880 --> 00:41:26.960]   of the scraps they have and not and not sort of recognize anybody else who's written about it.
[00:41:26.960 --> 00:41:31.200]   So don't link to them and don't mention that the Wall Street Journal has written about this
[00:41:31.200 --> 00:41:39.840]   already. So I think you get this just cacophony, which does not help anyone. If you're even remotely
[00:41:39.840 --> 00:41:45.520]   interested, you'll get overloaded. And if you're not remotely interested, you will just tune out.
[00:41:45.520 --> 00:41:50.720]   And so I think if you even assuming there are things here that should be paid attention to,
[00:41:50.720 --> 00:41:55.040]   and that should be called attention to, this is the worst possible way to go about it.
[00:41:55.040 --> 00:41:58.880]   This stuff went down.
[00:41:58.880 --> 00:41:59.440]   Because we'll.
[00:41:59.440 --> 00:42:01.920]   Oh, sorry. Go ahead, Mr. O.
[00:42:01.920 --> 00:42:07.280]   I was just going to say, and that's interesting because if, or it's interesting to me, because
[00:42:07.280 --> 00:42:13.440]   I know that if there was something that I had a burning desire that the world needed to know,
[00:42:13.440 --> 00:42:18.400]   I would want to broadcast that as loud and as far as possible. But it seems like that's kind
[00:42:18.400 --> 00:42:26.560]   of what's happening here. And instead of it becoming, like reinforcing the details behind it,
[00:42:26.560 --> 00:42:32.560]   it just becomes very confusing and numbing. Yeah, numbing is the right word for confusing
[00:42:32.560 --> 00:42:39.360]   slash numbing slash. And at a certain point, it's like, I'm so buried beneath this information
[00:42:40.000 --> 00:42:43.840]   that it almost feels like too much for me to like get in there and wade through it.
[00:42:43.840 --> 00:42:51.840]   And actually, Alex Stamos, former Facebook head of digital security pointed out that
[00:42:51.840 --> 00:42:58.160]   it's ironic in a way that this is happening because it's pretty much the same kind of thing
[00:42:58.160 --> 00:43:03.120]   that people complain about Facebook doing, which is to focus solely on engagement
[00:43:03.120 --> 00:43:09.520]   and clicks and attention at the expense of understanding and information and accuracy.
[00:43:09.520 --> 00:43:13.200]   Because that's our model. Facebook, I mean, Facebook obviously has got a different way,
[00:43:13.200 --> 00:43:17.920]   a different scale, all that's true. But media have no self reflection here that we're an
[00:43:17.920 --> 00:43:25.520]   attention based business model. We engage in this kind of sensationalism and attention grabbing.
[00:43:25.520 --> 00:43:31.760]   We pump up stories for that purpose. There was a story just out, I think, amidst all this today
[00:43:31.760 --> 00:43:37.760]   about how Facebook, one of the things that Facebook unleashed that surprised them, they didn't know
[00:43:37.760 --> 00:43:42.480]   what to do with was how media was going to react to and try to create more, they were going to
[00:43:42.480 --> 00:43:46.640]   create more clickbait to get the Facebook clickbait. And so Facebook helped make media worse.
[00:43:46.640 --> 00:43:48.800]   Media don't acknowledge that.
[00:43:48.800 --> 00:43:58.640]   My my beef is we spend a lot of time each and every week talking about the stuff that's going on
[00:43:58.640 --> 00:44:04.240]   with Facebook and granted, they have a gazillion dollars to help alleviate some of these issues
[00:44:04.240 --> 00:44:09.600]   and stuff. But at the same time, and this is, I noticed this totally out of left field, but this
[00:44:09.600 --> 00:44:14.080]   is the thought that I had this morning when I was speaking to one of my friends about it.
[00:44:14.080 --> 00:44:23.840]   There are bigger issues out there such as just food here in the nation. The FDA and what's going
[00:44:23.840 --> 00:44:30.320]   on with them and literally putting poison into the people that can't afford to have
[00:44:31.200 --> 00:44:36.480]   better cuts of meat and things of that nature. Why is it okay to have hormones inside of chicken
[00:44:36.480 --> 00:44:42.320]   and things like that? And why is it less expensive to go out and buy a hot dog than it is to buy
[00:44:42.320 --> 00:44:48.480]   a salad? I think problems like that deserve way more attention than the stuff that Facebook
[00:44:48.480 --> 00:44:54.960]   is getting right now from all of our leaders in Congress and stuff like that. But none of that gets
[00:44:54.960 --> 00:45:00.800]   brought up. And by the way, I think that if you can, is what we said earlier,
[00:45:00.800 --> 00:45:04.400]   Facebook's not suffering in users is not suffering in advertising. It's not suffering. It's not
[00:45:04.400 --> 00:45:09.440]   price. So there's a disconnect here. And if legislators, if you want to go after companies,
[00:45:09.440 --> 00:45:14.400]   people actually do not like go after the phone company and the cable company, we all go.
[00:45:14.400 --> 00:45:21.120]   Yeah, go there you go. But they give a lot of money, a lot, a lot of money. Yeah,
[00:45:21.120 --> 00:45:24.000]   poor Matthew's stuck up there with carrier pigeons.
[00:45:24.000 --> 00:45:36.480]   Yeah, don't we're lost cause so. Yeah, sorry for the tangent. But that was
[00:45:36.480 --> 00:45:40.400]   all good tangent was right. No, I wasn't a tangent at all. It's about trying to find
[00:45:40.400 --> 00:45:45.760]   those perspective here. Yeah, yeah, indeed. Well, then I think we can all agree that the
[00:45:45.760 --> 00:45:54.080]   Facebook files, papers, I think we're spent on that. So why don't we could if you want to have a
[00:45:54.080 --> 00:46:01.600]   little laugh there if you want to have a little laugh line 57 as my friends said on on Twitter,
[00:46:01.600 --> 00:46:07.440]   no, this is something to regulate. This is the recruiting video.
[00:46:07.440 --> 00:46:12.320]   Yeah, no, this is the this is the open enrollment. Open enrollment.
[00:46:12.880 --> 00:46:18.240]   It better. Yeah, that's right. Yeah, that was pretty funny. But I got to tell you,
[00:46:18.240 --> 00:46:23.280]   having sat through a bunch of these corporate meetings about open enrollment.
[00:46:23.280 --> 00:46:29.520]   Sadly, that was the best I've seen. It was pretty good. And I think you're going to
[00:46:29.520 --> 00:46:37.040]   go to work like comparison now. Oh gosh, I hate those meetings and it's a lot of information
[00:46:37.040 --> 00:46:40.320]   when it comes to open enrollment because you got this plane and that plane, it covers this,
[00:46:40.320 --> 00:46:45.520]   but it doesn't cover that it costs this it doesn't cost that and it's a mess. And so
[00:46:45.520 --> 00:46:52.720]   HR representatives showing up to present this information to thousands of employees as
[00:46:52.720 --> 00:46:59.520]   concise as possible. That could be challenging and seeing this video, I'm like, yeah, this is way
[00:46:59.520 --> 00:47:07.040]   better than anything. But it still don't care. This is basically a musical. I was just going to say
[00:47:07.040 --> 00:47:11.680]   this musical. Yes, I know. I don't understand your taste. I mean, I'm not getting the title.
[00:47:11.680 --> 00:47:18.960]   It's turned the title. It was it was it's no, I am not a musical fan. You're 100% correct on it.
[00:47:18.960 --> 00:47:26.640]   Oh boy. So so we have to be pretty. Think about Ben Stein trying to tell you about HMOs and
[00:47:26.640 --> 00:47:33.680]   in high deductible plans and think about that. I'd rather have the musical than Ben Stein. I love
[00:47:33.680 --> 00:47:40.640]   Ben Stein. So we've got Anne's pyramid of life at the very bottom is HR presentations.
[00:47:40.640 --> 00:47:47.280]   Slightly above that. I realize we've talked a lot about this and people in the chat are like,
[00:47:47.280 --> 00:47:52.560]   what are they even talking about? We didn't really even, you know, oh, sorry, a clip of it. So we
[00:47:52.560 --> 00:47:56.400]   might as well, I mean, we can probably show a small clip of this just to get a little bit of
[00:47:56.400 --> 00:48:02.080]   the cringe factor out there if you all want to see it. But essentially Facebook made a musical
[00:48:02.080 --> 00:48:08.400]   around its HR open enrollment. And I mean, I guess I could see something like this on TikTok.
[00:48:08.400 --> 00:48:14.160]   It would probably be done a little bit better though. It would be fun. Yeah. Yeah. A TikTok person
[00:48:14.160 --> 00:48:24.400]   would probably be just a little bit. And I can't knock any one of these people who's doing this
[00:48:24.400 --> 00:48:28.160]   performance is because they did, you know, they did a great job considering the material that
[00:48:28.160 --> 00:48:32.400]   they're working with. But it's just one of those things where as you're watching it or as I was
[00:48:32.400 --> 00:48:37.280]   watching it, it's kind of like curling my toes. It could be better if there was a C-Shanty though.
[00:48:37.280 --> 00:48:43.120]   Yes. C-Shanty would have been very, very now. Strangely. And as you're doing it,
[00:48:43.120 --> 00:48:49.120]   TikTok style. That'd be the right of Facebook now. Right. Right. The duet style on TikTok.
[00:48:49.120 --> 00:48:56.240]   So anyways, anyone who wants to hear the rest of that catchy song, you certainly can. It's floating
[00:48:56.240 --> 00:49:01.680]   out there. Look for, look for that. Did I ask you a question there, Jason? Yeah, go for it.
[00:49:01.680 --> 00:49:08.800]   If I'm, I know it's not a democracy. No, it is. Go eager after a week, a very eager after a week
[00:49:08.800 --> 00:49:14.720]   to hear what you think of your, of the, your unit of the Pixel 6 Pro. Yeah. So about that.
[00:49:14.720 --> 00:49:20.800]   About that. Well, so I don't have the Pixel 6 Pro with me right now.
[00:49:22.960 --> 00:49:32.480]   Leo has it. Yes. So he's, he has it with him. He, he came by last night and picked it up for me.
[00:49:32.480 --> 00:49:39.840]   He, he, Lisa, after all about Android. So he has that. I have the, the 6. So I'm, you know,
[00:49:39.840 --> 00:49:43.760]   I'm not left out in the cold or anything. It's actually kind of convenient because it gives me
[00:49:43.760 --> 00:49:48.560]   a chance to spend some time with this. If I have the 6 Pro, I'd be more inclined to just continue
[00:49:48.560 --> 00:49:53.440]   using it and never actually get around to using this one. So this is the regular 6. But, but yeah,
[00:49:53.440 --> 00:49:59.680]   I used the 6 Pro for the last week and a day, I'd say. And, and we talked about it a little bit on
[00:49:59.680 --> 00:50:04.320]   all about Android, actually to great length on all about Android last night, had a really great
[00:50:04.320 --> 00:50:12.880]   show. And I'd say this is without question Google's most polished device that they've created. And I
[00:50:12.880 --> 00:50:17.120]   think that was kind of, you expect that going in, right? Like everything that we've seen leading
[00:50:17.120 --> 00:50:23.680]   up to the release of the Pixel 6 and 6 Pro has, has seen, seemed like Google is really taking this
[00:50:23.680 --> 00:50:29.760]   more, even more seriously than they have the previous pixels. You know, it's, it's a fantastic
[00:50:29.760 --> 00:50:36.640]   device. It's hard for me to know things about like the tensor chip and how that compares with
[00:50:36.640 --> 00:50:42.640]   other processors because there's still, there were moments in my usage of the 6 Pro where, you know,
[00:50:42.640 --> 00:50:46.720]   random slowdown would, would happen and be like, Oh, why is it stalling right there? Is that the
[00:50:46.720 --> 00:50:51.600]   OS? Is that Android 12? Or is that the Pixel 6? Is that the tensor chip not, you know,
[00:50:51.600 --> 00:50:56.560]   not being as fast as other chips is really hard to know where to place blames for, for little moments
[00:50:56.560 --> 00:51:02.480]   like that. But I mean, the optimized Android 12 and stuff like that. Yeah, exactly. It could be a
[00:51:02.480 --> 00:51:10.080]   number of things. But, but I, it's a fantastic device. It's certainly the device that I'm going
[00:51:10.080 --> 00:51:14.320]   to be using for the next year until Google releases their next one. But that's no different from any
[00:51:14.320 --> 00:51:21.360]   pixel. That's always my choice. I think they did a great job that the 4x telephoto lens that they
[00:51:21.360 --> 00:51:27.600]   have in that phone. I really enjoyed using that. I just love having that extra extension. That's
[00:51:27.600 --> 00:51:33.280]   probably one of my favorite new features on the new device. But it had some, it had some odd,
[00:51:33.280 --> 00:51:37.920]   oddness with it too. There would be times where I'd be using the camera to take a picture with
[00:51:37.920 --> 00:51:43.760]   the 4x and I could, and the lens, depending on what was in front of the lens, I could see the
[00:51:43.760 --> 00:51:51.040]   software switching it from the optical lens to the main lens digitally zoomed to 4x. And,
[00:51:51.040 --> 00:51:55.840]   the quality of your photo between those two things is going to be wildly different, right? One's
[00:51:55.840 --> 00:52:00.080]   a digital zoom and the other one's an optical zoom that's going to look sharp and crisp. And I
[00:52:00.080 --> 00:52:05.600]   don't understand why I can't lock it in like that. A couple of random little things like that that
[00:52:05.600 --> 00:52:11.920]   I discovered in the 6 Pro in my time. But again, I only had a week with it. So it's, it's really hard
[00:52:12.560 --> 00:52:18.560]   to know what the longevity of that device is going to be. But so far, yeah, I think it's pretty great.
[00:52:18.560 --> 00:52:26.320]   I know, you pre-ordered one. Jeff, did you, Matthew, is this, are you a pixel user or what
[00:52:26.320 --> 00:52:36.400]   what, what phones do you guys use? I've got a Samsung. I had a, I've just 20 fan edition, I think
[00:52:36.400 --> 00:52:45.280]   it is. Oh, yeah, it's a solid one. I did use the Huawei. And then a number of technical difficulties
[00:52:45.280 --> 00:52:50.640]   occurred involving me dropping it. And so, what happens?
[00:52:50.640 --> 00:52:58.480]   Yeah, the pond while you were rolling, perhaps. So I have lost a number of phones in the lake.
[00:52:58.480 --> 00:53:05.120]   You have? Kayaking. But anyway, this one I just dropped. And then at one point, the case
[00:53:05.680 --> 00:53:12.000]   was the only thing holding it together. It was literally shards of glass. So yeah, so I got this
[00:53:12.000 --> 00:53:18.000]   in. I'm so good. Yeah, no, that's, and that's a, that's a solid phone. I, from what I understand,
[00:53:18.000 --> 00:53:22.320]   I haven't used it personally, but yeah, I like it. I've read it with that phone when it came out
[00:53:22.320 --> 00:53:25.920]   and, and beyond has been, you know, the Samsung. For me, the cameras, the main thing.
[00:53:25.920 --> 00:53:33.120]   Yeah. Yeah, that's one of the most important things for me too. Samsung does good with their
[00:53:33.120 --> 00:53:37.600]   cameras. That's why I got the Huawei. It's worth it. I've done good P20, because the cameras were
[00:53:37.600 --> 00:53:44.000]   amazing. Solid. Yeah. Mr. Howl, you mentioned that, you know, this is something you would do every
[00:53:44.000 --> 00:53:49.920]   year is check out the latest Pixel phone. But I got to tell you, I'm glad I'm not in your position,
[00:53:49.920 --> 00:53:56.960]   because the five, I had no interest in that phone. None. Yeah. Well, and I didn't either. I was using
[00:53:56.960 --> 00:54:03.760]   the four XL, even while I had the five in my possession. That says a lot right there.
[00:54:03.760 --> 00:54:10.080]   Yeah. Yeah. Well, and, you know, for a couple of reasons, but I really like the face scanning
[00:54:10.080 --> 00:54:15.760]   aspect on the four XL, even though people were complaining because, well, we're wearing masks
[00:54:15.760 --> 00:54:19.280]   all the time. It's like, yeah, but I'm not going anywhere. It's a little hard with masks. Yeah.
[00:54:19.280 --> 00:54:22.800]   But there were a couple of reasons that I stuck with it, but then it started doing some,
[00:54:22.800 --> 00:54:26.480]   some weird stuff. So I was like, all right, fine. I'll spend some time with the five. And I got
[00:54:26.480 --> 00:54:31.760]   used to it, but it was, it was by no means, you know, Google's best phone as far as pixels are
[00:54:31.760 --> 00:54:38.560]   concerned. I will be happy and proud to use the six pro going forward. It's, I mean, the design,
[00:54:38.560 --> 00:54:45.040]   what they've come up with that like signature look really looks nice when you have it in,
[00:54:45.040 --> 00:54:50.320]   in your hands, right? Like, like it's, it's looks interesting online, but I wondered if once I got
[00:54:50.320 --> 00:54:55.600]   it, I was going to be like, I don't know. And it turns out it's just, it's a really eye-catching
[00:54:55.600 --> 00:55:00.640]   device. So I'm looking forward to that. Jeff, did you, did you order it also?
[00:55:00.640 --> 00:55:06.320]   Well, so yeah, of course I was usual grumpy Jeff. And, and I couldn't order it while, while the,
[00:55:06.320 --> 00:55:10.240]   you were presenting with Leo or, or, or talking about that. And I,
[00:55:10.240 --> 00:55:17.600]   lost out. Then I got, I, then I came back and I managed to get the 128, but I wanted the 256.
[00:55:17.600 --> 00:55:24.320]   And I want this phone to last. And so then it came back again. I got the 256. It's coming December
[00:55:24.320 --> 00:55:29.440]   one. And I'm telling myself, calm down, Jeff, that's just fine. Your present phone works just fine.
[00:55:29.440 --> 00:55:36.400]   You can wait till December 1st. Oh, but it's so hard. So hard. It's hard. I went into best by
[00:55:36.400 --> 00:55:42.240]   today just to touch one. I didn't know was going to have that kind of Samsung-y curve, half curved
[00:55:42.240 --> 00:55:47.200]   screen. What do you think of that? Yeah, you know, that did actually didn't, didn't bug me as much as
[00:55:47.200 --> 00:55:51.520]   I thought it was going to, because I am, I am definitely a fan, more of a fan of the flat look.
[00:55:51.520 --> 00:55:56.080]   The six, the regular six has the flat display on the edges. It doesn't have the
[00:55:56.080 --> 00:56:01.680]   curviness. But, um, so, you know, so if you want the flat, if you absolutely have to have the flat,
[00:56:01.680 --> 00:56:05.120]   the six would be the one you're going to save a couple hundred dollars if you do that. But,
[00:56:05.120 --> 00:56:11.840]   I always had the device in a, in a case anyways, because I will inevitably drop that thing and it
[00:56:11.840 --> 00:56:17.360]   will break. It's just how I know that's me at this point. I accept it. I would love to be the one that,
[00:56:17.360 --> 00:56:22.560]   you know, that, that can have this, this nice unprotected phone, you know, in use all the time.
[00:56:22.560 --> 00:56:27.760]   But it's just going to fall and I know it at this point and I embrace that, that. And with the case
[00:56:27.760 --> 00:56:33.120]   on, I really didn't notice the, the curved edge on the side of the display. Because they, because
[00:56:33.120 --> 00:56:37.840]   the sides kind of raise up on the case high enough that it really doesn't matter. I mean,
[00:56:37.840 --> 00:56:42.480]   it's, it's a little curve there. Yes. But you're not getting those inadvertent clicks that you might
[00:56:42.480 --> 00:56:48.400]   get if you are, or touches. If you didn't have it in a case on the side of your finger bumped it.
[00:56:48.400 --> 00:56:54.160]   That's my, yours, your is arriving mine is probably going to arrive at the end of the show, a schedule
[00:56:54.160 --> 00:57:01.520]   for today. Oh, I already got my ticket. And I already got my case. Nice. Over there. I can't wait to hear
[00:57:01.520 --> 00:57:06.720]   what you think it was a camera. But yeah, I'm, I'm really looking forward to trying the camera out.
[00:57:06.720 --> 00:57:13.200]   I have a product photo shoot that I want to try to do with it. I've already staged it up
[00:57:13.200 --> 00:57:18.640]   down in the garage already. Lots of lights and stuff just to see what is capable of. Because a
[00:57:18.640 --> 00:57:25.760]   lot of times it, these, not just a pixel, but most of these newer smartphones, the lighting can
[00:57:25.760 --> 00:57:31.680]   make a big difference in performance. Oh, yeah. In addition to just sort of understanding
[00:57:31.680 --> 00:57:38.000]   composition. But when we look at the reviews of the five versus the reviews of the six here,
[00:57:38.000 --> 00:57:45.760]   the signal to noise ratio is supposedly night and day that is not as much noise in low light
[00:57:45.760 --> 00:57:51.600]   situations with this pixel six because of the larger sensor. And that just makes perfect sense.
[00:57:51.600 --> 00:58:01.760]   So we'll see. Yeah. And you know, the, the AI aspects of the camera, obviously, you know,
[00:58:01.760 --> 00:58:07.920]   that's, that's a big part of the pixel six story, the tensor chip, as Google has been very vocal
[00:58:07.920 --> 00:58:15.200]   about, you know, is, is, is all about kind of these extra AI on device enhancements and everything.
[00:58:15.200 --> 00:58:21.280]   I'm super curious to see what you think of some of those new camera features and because they're,
[00:58:21.280 --> 00:58:28.080]   they're pretty awesome what you can do with them doing the open exposure. I just did, in my, in my
[00:58:28.080 --> 00:58:32.320]   usage of the phone over the last week, I feel like I didn't have the right kind of examples to put
[00:58:32.320 --> 00:58:37.760]   them to the test. Like I'm not at a subway with the subway train passing behind, you know, my wife
[00:58:37.760 --> 00:58:44.320]   and I take a picture of her so I can get the motion of the camera. Yeah, actually, you know what I
[00:58:44.320 --> 00:58:49.440]   did. And we featured this last night on all about Android, I tried to replicate, do you remember
[00:58:49.440 --> 00:58:54.960]   back in Google IO 2017 where Google showed off the, the, the kid who's playing baseball and had
[00:58:54.960 --> 00:58:59.760]   the chain link fence and they were like, and soon we'll have technology to remove the chain link
[00:58:59.760 --> 00:59:04.240]   fence. And that's, that's been this ongoing joke, right? Of like, okay, and when is soon,
[00:59:04.240 --> 00:59:07.920]   when is that ever going to happen, Google, you know, apparently they could never make it work?
[00:59:07.920 --> 00:59:12.720]   Well, the magic eraser seemed like, well, you can do it in Photoshop. Of course, there are ways
[00:59:12.720 --> 00:59:18.800]   to do any in a still, they will bring that. What's that? It's still challenging in Photoshop,
[00:59:18.800 --> 00:59:26.400]   Dylan, because Photoshop Adobe has their own AI called Sensei. And if you can properly get the
[00:59:26.400 --> 00:59:33.760]   selections squared away and use the content to wear fill algorithm, it does a pretty decent job.
[00:59:33.760 --> 00:59:40.480]   But again, that's on a desktop computer or a laptop or what have you, not necessarily on a
[00:59:40.480 --> 00:59:47.840]   mobile device, a piece of silicon. Yeah, right, exactly. And you know, that is one thing that I
[00:59:47.840 --> 00:59:52.720]   kind of played around with. I was like, how difficult is this to do on Photoshop? And I'm not a
[00:59:52.720 --> 01:00:02.560]   Photoshop genius, not like you. And so I tried this. So I ended up pulling the Google, that image
[01:00:02.560 --> 01:00:07.360]   of the kid with the chain link fence and taking it into Photoshop to see if I could remove the
[01:00:07.360 --> 01:00:12.080]   fence to the degree that Google did. And I kind of gave up on it because it was so much work,
[01:00:12.080 --> 01:00:17.280]   it was very tedious. That's yeah. And that's the thing that this actually is not tedious at all,
[01:00:17.280 --> 01:00:21.680]   like the magic eraser is really just as easy as like drawing a circle around the thing. And it
[01:00:21.680 --> 01:00:26.240]   goes away. And if you don't like the way it took it away and replaced it with its own interpretation
[01:00:26.240 --> 01:00:30.480]   of what the background is, you can undo that and do it again. And within like a half a second,
[01:00:30.480 --> 01:00:37.440]   it gives you the new version of it. And I mean, the pictures were by no means perfect. Like,
[01:00:37.440 --> 01:00:42.720]   Google never said in the introduction of the magic eraser. And we'll finally allow you to
[01:00:42.720 --> 01:00:47.520]   remove chain link fences from your photos. Like they never said that. This is, I knew that this
[01:00:47.520 --> 01:00:53.360]   was going to be perfect. Can we remove like a family member that we don't want in the photos or?
[01:00:53.360 --> 01:00:59.120]   That that I think is, is really why I don't know about family member, but people? Yes, I think
[01:00:59.120 --> 01:01:03.040]   that's part of why Google did this, because if you're taking a photo and that's part of what
[01:01:03.040 --> 01:01:06.720]   their marketing has been, right, you've got two or three people in the shot and then you've got
[01:01:06.720 --> 01:01:11.120]   those people in the background, what this picture would be so much better if those people were moved
[01:01:11.120 --> 01:01:15.920]   and you draw your circle around them and they disappear. And yeah, it works pretty darn well
[01:01:15.920 --> 01:01:21.120]   doing that. I'm sure if you enlarge those images and you scrutinize it, you're going to find some
[01:01:21.120 --> 01:01:26.640]   you know, some weirdness, but with how easy it is compared to what the alternative is,
[01:01:26.640 --> 01:01:31.840]   pretty impressive. And it's all happening on device really quickly. Like when I was doing
[01:01:31.840 --> 01:01:38.160]   those images, it was like, Bam, Bam, Bam, this really fast, which makes me think that we're going to
[01:01:38.160 --> 01:01:43.200]   see a lot more advances beyond just phones in what can happen locally, you know, the same
[01:01:43.200 --> 01:01:50.160]   joke in a Chromebook part, and we could could actually make it incredible. And as my photo,
[01:01:50.160 --> 01:01:55.200]   as all of our photo guru, did you get a chance to look at the next story on the the the Wall Street
[01:01:55.200 --> 01:02:02.880]   Journal analysis of Google's claims about skin tone? I couldn't judge the photos for
[01:02:02.880 --> 01:02:11.280]   it myself. I didn't catch that, but I did listen to the conversations between them and as well as
[01:02:11.280 --> 01:02:20.640]   Adobe all talking about it. Again, some people were using the word bias a week or so ago,
[01:02:20.640 --> 01:02:26.240]   and I don't necessarily say it's bias. It's just that's just how the chemicals were back in the
[01:02:26.240 --> 01:02:34.240]   days when you were dealing with film. It it is what it is. It was a lot harder to get people of color
[01:02:34.240 --> 01:02:40.240]   to look right on film. That had nothing to do with bias. That's just the way the films were.
[01:02:40.240 --> 01:02:47.280]   And a lot of the digital photography is basically trying to simulate the way film was back in the
[01:02:47.280 --> 01:02:54.880]   days, and it's just gotten better and better over time and faster. But still, it's not something that
[01:02:54.880 --> 01:03:00.960]   was easily fixable right at the gate. It took some time to refine that whole process.
[01:03:00.960 --> 01:03:08.880]   Yeah, last night on the show, a Samsung, like we said, we looked at the Samsung phone or whatever
[01:03:08.880 --> 01:03:15.520]   phone it was that Mr. Le Port was using that I made fun of him. That was with a white person
[01:03:15.520 --> 01:03:21.760]   in the screen, Mrs. Le Port, and it didn't get it right. You know, it's it's not necessarily bias.
[01:03:21.760 --> 01:03:24.640]   It's just not necessarily easy to do.
[01:03:24.640 --> 01:03:32.480]   Which I think is part is part of why I was happy that Google, and I've said this now a
[01:03:32.480 --> 01:03:36.160]   couple of times, so apologies if you've heard me say this before, but I'm really happy that Google
[01:03:36.160 --> 01:03:44.240]   shown their light on this as something that they are committed to working on because I think
[01:03:44.240 --> 01:03:49.840]   because I think it it kind of forces them to continue working on it. Not that they wouldn't
[01:03:49.840 --> 01:03:56.800]   otherwise, but putting it so publicly out into the limelight like that kind of
[01:03:56.800 --> 01:04:00.960]   almost like forced accountability, right? Yeah, forced accountability. That's a great way to put it.
[01:04:00.960 --> 01:04:04.560]   Yeah, of course, the feature we're talking about here is called Real Tone. We actually talked about
[01:04:04.560 --> 01:04:09.680]   this also last night, our guest, Tashaka Armstrong, who came by your recommendation. And so thank you.
[01:04:09.680 --> 01:04:15.840]   Tashaka is great. Fantastic on the show. And he did a really great review of the phone
[01:04:15.840 --> 01:04:22.240]   for Android Central and spent a good chunk of the time talking about this particular feature and
[01:04:22.240 --> 01:04:28.800]   talking about the fact that he and his friend, when they're in shots, normal cameras would make
[01:04:28.800 --> 01:04:33.120]   both of their skin seem kind of like chocolatey. I think he called it like the Hershey effect.
[01:04:33.120 --> 01:04:40.880]   Hershey, yep. Yeah, the Hershey Chocolate effect. And with the Pixel 6 Pro, you can see the
[01:04:40.880 --> 01:04:47.760]   differences, the subtle but perceivable differences in their skin tone, thanks to what Google has
[01:04:47.760 --> 01:04:53.520]   done with Real Tone. So yeah, I mean, from my perspective, yeah, it's great that Google is
[01:04:53.520 --> 01:04:58.400]   committing themselves to this. And they have to be judged. That's why we'll have the Journal
[01:04:58.400 --> 01:05:03.440]   of the Story. Exactly. I amateurs view of the photos. That's why I'm eager for Anne's professional
[01:05:03.440 --> 01:05:09.120]   view. It looks like Apple just blew out what lit it up more. Just over exposed things.
[01:05:10.320 --> 01:05:15.440]   Which I don't think is sufficient, obviously. So there's a lot more subtlety to it in how it
[01:05:15.440 --> 01:05:19.920]   calculates. It'd be really interesting to hear how they're doing this and what their standards are.
[01:05:19.920 --> 01:05:27.040]   Yeah. Yeah. You know, I'm sitting here looking at, I'm seeing if I could pull it up on my screen.
[01:05:27.040 --> 01:05:32.720]   I'm looking at a shot. I had to do some headshots for myself because someone was asking for new
[01:05:32.720 --> 01:05:38.480]   headshots from use of something that's coming up that I'm working on. And I shot this with my
[01:05:38.480 --> 01:05:48.960]   DSLR. And I remember going in here and working on the post-processing and getting the skin tones
[01:05:48.960 --> 01:05:55.440]   right. My DSLR, I had to change the skin tone because it thought I looked like that.
[01:05:55.440 --> 01:06:02.960]   And that's with Canon. My skin is, yeah, I got beautiful skin, but boy, it's not that vibrant.
[01:06:04.240 --> 01:06:11.040]   So again, it's all in, this is a tough process. It doesn't matter who you are. So I had to dial it
[01:06:11.040 --> 01:06:17.920]   back a little bit. You know, that's more natural. That looks more like me. Not what the camera's
[01:06:17.920 --> 01:06:25.040]   interpretation was. Right. Ridiculously bronze looking skin that's not necessarily me. It looks
[01:06:25.040 --> 01:06:30.960]   good, but that's not me. So I mean, what is the challenge? Yeah, it reminds me of...
[01:06:30.960 --> 01:06:38.320]   Skin though. Thank you, Condos. You did. It reminds me of what we've seen, you know,
[01:06:38.320 --> 01:06:43.600]   on smartphone displays over the years where you've got the displays that are like a very flat,
[01:06:43.600 --> 01:06:49.120]   maybe a cool kind of presentation to it. And then you've got displays like Samsung has been
[01:06:49.120 --> 01:06:54.240]   totally one of the companies that, you know, when you are looking at a Samsung display,
[01:06:54.240 --> 01:06:59.360]   it's not necessarily a true representation of color. It's like a vibrant, more vibrant,
[01:06:59.360 --> 01:07:04.880]   saturated, totally. And they're making those changes. And it's kind of like, you know,
[01:07:04.880 --> 01:07:09.440]   certain headphones out there that really accentuate the low end. And there are people that really
[01:07:09.440 --> 01:07:13.840]   like that. They see a lot of that looking for true. They're looking for enhanced.
[01:07:13.840 --> 01:07:21.680]   I see a lot of that in Instagram photos, actually. People will use the filters or whatever to just,
[01:07:21.680 --> 01:07:27.920]   and it's completely blown out. The colors are just amped up to the point where it's not even
[01:07:27.920 --> 01:07:33.200]   remotely realistic. And I think that's kind of what they associate with a good photo.
[01:07:33.200 --> 01:07:40.560]   Right. Right. Or what is a time for in a photo is to not necessarily see them the way they're
[01:07:40.560 --> 01:07:46.480]   used to seeing themselves, see a new, you know, a air quotes better version of themselves or,
[01:07:46.480 --> 01:07:54.960]   you know, what? There's a time in place for that stuff. I get it as an artist. There's a time
[01:07:54.960 --> 01:08:00.960]   where you want to enhance certain features and things like that. But if someone is looking for a
[01:08:00.960 --> 01:08:08.160]   journalistic representation of me, I need to give them a true journalistic representation of me
[01:08:08.160 --> 01:08:15.920]   and make sure I dial it in the right way and not some superimposed beards and skin tones and
[01:08:15.920 --> 01:08:20.080]   muscles. And you know, because if I show up and I don't look like that picture, that's a problem.
[01:08:21.200 --> 01:08:26.000]   I think you toned it down too much though. I think you're, I think the one you showed
[01:08:26.000 --> 01:08:31.200]   I think your skin does glow more than you think. Oh, she's now better get my eyes checked in.
[01:08:31.200 --> 01:08:40.720]   I wanted to show another thing here, Mr. Jammer being Mr. LePorte took a picture of the plane.
[01:08:40.720 --> 01:08:46.400]   And that's with the Pixel 6. I want to hit and grab it out of the discord because it's there.
[01:08:46.400 --> 01:08:50.160]   And of course, it has like a yellowish quality to it, doesn't it? What is that?
[01:08:50.160 --> 01:08:53.840]   He's a shirt. Wait a second. Wait a second. What is he wearing?
[01:08:53.840 --> 01:08:59.280]   He's wearing that. You know that a pepper shirt?
[01:08:59.280 --> 01:09:06.240]   Yep. That looks like yeah. Oh, yeah. Okay. He's wearing it. The chili hat, but I just like,
[01:09:06.240 --> 01:09:13.760]   I squirrel, I had to comment on that. Good. Well, looking at this image, okay, that came from
[01:09:13.760 --> 01:09:20.560]   the Pixel device, a smartphone. He's inside of a airplane cabin. That's limited lighting
[01:09:20.560 --> 01:09:26.640]   inside of those things. So the phone should struggle a little bit. And it did. When I zoomed in,
[01:09:26.640 --> 01:09:33.680]   there's definitely a little bit of noise and grain right here. But that's not, I mean,
[01:09:33.680 --> 01:09:38.880]   that's not a knock against the Pixel, right? It's a phone. It's a tiny sensor. There's not
[01:09:38.880 --> 01:09:44.800]   enough light. That's what's going to happen. So now I hope to see what he shares, you know,
[01:09:44.800 --> 01:09:51.120]   when he's out and about in Wahaka with some better light and see what that thing looks like. But
[01:09:51.120 --> 01:09:55.200]   that right there, I'm like, yeah, that's just a typical smartphone. I can't, I wouldn't know if
[01:09:55.200 --> 01:09:59.440]   that was a Pixel. I wouldn't know if that was an iPhone or whatever, because it's just, yeah,
[01:09:59.440 --> 01:10:04.960]   an image shot. I think the two two things that camera phones have really made huge
[01:10:05.520 --> 01:10:11.760]   advances on. And the first one I noticed was the Huawei, which is why I got it was low light and
[01:10:11.760 --> 01:10:19.520]   zoom. You know, lots of cameras were taking good phones in the sunlight, you know, outside and so
[01:10:19.520 --> 01:10:26.080]   on. But you really noticed things fall off in low light. And I think all the manufacturers have made
[01:10:26.080 --> 01:10:32.800]   huge strides with both of those over the last couple of years. Yeah, I would agree. A lot of
[01:10:32.800 --> 01:10:39.040]   improvements on low light Google seems to be one of the first to really go there with gusto, you
[01:10:39.040 --> 01:10:44.480]   know, with their night site. However, many years ago, and then it seemed like that that raised up in
[01:10:44.480 --> 01:10:50.160]   in priority for for everybody else. And you know, Apple, Samsung, you know, everybody has their
[01:10:50.160 --> 01:10:56.480]   their kind of night mode now. And as a result, it's improved everybody's shots in those low light
[01:10:56.480 --> 01:11:01.760]   experiences. But to my eyes, man, Google does it does it probably near the best. You can get some
[01:11:01.760 --> 01:11:08.320]   amazing shots out of those night modes. I wanted to talk to you about the Android operating system,
[01:11:08.320 --> 01:11:18.400]   sir. Yeah. As it is, okay, six. Right. It was this version 12, right? Yeah, it's version 12. Yeah.
[01:11:18.400 --> 01:11:25.920]   Okay, so I got that update on my pixel four. And it looks fine from a functionality standpoint
[01:11:25.920 --> 01:11:32.320]   with the large tiles at the top when you swipe down and all of that. That's great. But what's
[01:11:32.320 --> 01:11:38.400]   bothering me is this color scheme that they're going with. And supposedly it reads off of whatever
[01:11:38.400 --> 01:11:45.600]   your wallpaper colors are to figure out how to scan the rest of the OS from a color scheme.
[01:11:45.600 --> 01:11:54.000]   Do I have that correct? Yeah, so that's material you, which, you know, essentially, you can see,
[01:11:54.000 --> 01:11:59.040]   like the buttons in the quick settings is one example kind of mirrors. It's like a,
[01:11:59.040 --> 01:12:04.480]   it's like an average effect of one of the dominant colors. And actually, this widget,
[01:12:04.480 --> 01:12:09.360]   you can see this clock widget. Yeah, I mean, that's my interpretation of it anyway. So I don't
[01:12:09.360 --> 01:12:16.320]   know exactly how that makes a big difference because it's not a perfect match. It's like it
[01:12:16.320 --> 01:12:20.800]   takes the general theme of the color right now. This is over blue more than it is yellow. So
[01:12:20.800 --> 01:12:25.840]   therefore, this the arms in the in the clock here are a blue hue. They're not the same blue,
[01:12:25.840 --> 01:12:31.920]   but it's but it's like a complimentary blue. If I actually move this down, you can see it just
[01:12:31.920 --> 01:12:39.280]   changed to yellow, right? And so there's different aspects throughout the OS that do that. And apps,
[01:12:39.280 --> 01:12:44.880]   you know, Google has done better this time when they did material design. It's like they released
[01:12:44.880 --> 01:12:49.680]   material design and and they said, you know, apps are going to get material design coming soon and
[01:12:49.680 --> 01:12:55.200]   it's low trickle for like two years. This time they got all their apps or the majority of their
[01:12:55.200 --> 01:13:01.120]   apps into material you land. And it's all set to kind of tie into whatever the color scheme
[01:13:01.120 --> 01:13:07.360]   that the device has pulled out of whatever your wallpaper happens to be. If I change that wallpaper,
[01:13:07.360 --> 01:13:13.760]   you know, it's, oops, how do I do that here? I got a screen that doesn't have a bunch of stuff on it.
[01:13:13.760 --> 01:13:19.360]   Right. But if I go here, I can, you know, find something else. Maybe we'll do this, you know,
[01:13:19.360 --> 01:13:23.920]   very blue. That's going to require a download. I don't know if it'll be fast enough. But essentially,
[01:13:23.920 --> 01:13:30.640]   there we go. Okay, so we're good. So it's downloaded that we'll put that to home and lock screen.
[01:13:30.640 --> 01:13:35.440]   There we go. And now, you know, it's still a blue, but it's a it's a different blue.
[01:13:35.440 --> 01:13:42.800]   It's a different. Yeah. And so yeah, I mean, you know, it's it's all kind of dependent on what
[01:13:42.800 --> 01:13:48.560]   you have your your wallpaper image, which might seem like a small thing, but along with all the
[01:13:48.560 --> 01:13:55.360]   other design choices that they've done, I like it. I was excited for it until I was excited for
[01:13:55.360 --> 01:14:01.840]   it. I decided for it until actually installed it and saw what happened. But you say that does make
[01:14:01.840 --> 01:14:08.800]   sense. Because it looks at my phone and it gives me a lot of pink. And it gives it. And a lot of
[01:14:08.800 --> 01:14:15.440]   them like a greenish yellowish every now and then because I'm dealing with a lot of Clemson.
[01:14:15.440 --> 01:14:22.000]   My screen is a Clemson stadium football stadium. So there's a lot of orange and purple and stuff
[01:14:22.000 --> 01:14:26.400]   like that. So it's averaging all of that together. And I guess, yeah, that will give you pink. And
[01:14:26.400 --> 01:14:31.040]   when I go to look at notifications, I'm like, why is my screen pink? And it's a bit annoying.
[01:14:31.040 --> 01:14:36.400]   I clearly have nothing against pink since I'm actually wearing a pink shirt right now, but I
[01:14:36.400 --> 01:14:43.200]   don't really want it on my phone. Yeah, I have a picture. Yeah, go ahead. I was just going to say
[01:14:43.200 --> 01:14:48.800]   there are ways to tweak that and everything manually as well. But yeah, what were you going to say,
[01:14:48.800 --> 01:14:55.120]   John? I have a picture of marks and angles in a statue in Berlin, which I have on there. I love
[01:14:55.120 --> 01:15:00.640]   and behind it is the beginning of fall trees. So my little horrible scalloped clock looks like
[01:15:00.640 --> 01:15:06.800]   baby couldn't help it brown. And it's really unappealing. And it's nothing I can do about it.
[01:15:06.800 --> 01:15:12.560]   I don't think right. There's no way to change the choice it made other than to change the background.
[01:15:12.560 --> 01:15:19.840]   Well, that's actually, so let's see here. So I'll go into wallpapers and then you've got wallpaper
[01:15:19.840 --> 01:15:26.240]   colors. So this is this theming, these theming options are derived from my wallpaper choice.
[01:15:26.240 --> 01:15:31.920]   And you have different different selectors down there. So you can kind of, in this case, they're
[01:15:31.920 --> 01:15:37.680]   all very similar. I would say two of my three are exactly the same. Yeah, yeah.
[01:15:37.680 --> 01:15:42.720]   I suppose you could go in here and you could decide like this is this is a color palette.
[01:15:42.720 --> 01:15:49.040]   Is this color palette tied into the wallpaper? No, it must be exactly the palette that I have
[01:15:49.040 --> 01:15:54.320]   on my screen when you go to base. So this is basic colors. So this might just be default colors.
[01:15:54.320 --> 01:15:58.800]   I haven't really played around with this that much, but there are some tweaks that you can make
[01:15:58.800 --> 01:16:05.120]   to it. But I don't know if it's a wide and open going. That's sort of thing. Yeah, unfortunately.
[01:16:05.120 --> 01:16:11.600]   All of the interesting pastel colors and stuff. So good. Maybe couldn't help it brown.
[01:16:11.600 --> 01:16:22.560]   Never heard before. So, let's take a break and thank the sponsor of this show. And then we'll be back
[01:16:22.560 --> 01:16:27.760]   into, well, more. We've got more Google and other things to talk about. First,
[01:16:27.760 --> 01:16:34.080]   this episode of this week in Google is brought to you by CrowdStrike. You've seen the headlines.
[01:16:34.080 --> 01:16:39.680]   You hear all about ransomware. I mean, ransomware is everywhere. This is ransomware attacks
[01:16:39.680 --> 01:16:45.760]   basically happening all the time and threatening businesses, holding them hostage, really. I can
[01:16:45.760 --> 01:16:50.720]   feel like if you have a business, it can feel like it's only a matter of time before that threat
[01:16:50.720 --> 01:16:57.440]   comes to you. You might then have to decide, do you pay or do you lose everything? What a
[01:16:57.440 --> 01:17:03.200]   horrible position to be in, but you do have a third option. What about defeating your adversaries
[01:17:03.200 --> 01:17:07.760]   before the fight even starts? And that's what CrowdStrike enables you to do. With CrowdStrike,
[01:17:07.760 --> 01:17:14.560]   you're not alone in the battle against ransomware. A secure future demands a shared defense. And
[01:17:14.560 --> 01:17:21.360]   that's why CrowdStrike's Falcon platform uses their threat graph power by advanced AI
[01:17:21.360 --> 01:17:28.880]   to analyze the behavior on your devices, on your servers, on your cloud workloads. And then with that,
[01:17:28.880 --> 01:17:33.680]   find the threats and then stop them before they have a chance to go any further. Their security
[01:17:33.680 --> 01:17:39.280]   platform delivers the industry's most powerful set of tools to fight today's most sophisticated
[01:17:39.280 --> 01:17:44.480]   cyber attacks, all delivered through the cloud, through a lightweight, intelligent agent.
[01:17:44.480 --> 01:17:53.680]   Forster study finds that Falcon Complete actually delivers 403% ROI. How do you like that? And in doing
[01:17:53.680 --> 01:18:00.800]   so, 100% confidence. We talked with CTO, Michael Sintones, he actually explained how the threat
[01:18:00.800 --> 01:18:07.520]   graph system is actually a collaborative platform. It's the crowd in CrowdStrike, and that's the
[01:18:07.520 --> 01:18:14.400]   concept. The regional vision was to build the fundamentals. It was to bring in all of those
[01:18:14.400 --> 01:18:20.240]   signals that telemetry and the more data we get, the more information that we have. We can use that
[01:18:20.240 --> 01:18:26.160]   to protect all of our customers in real time. CrowdStrike harnesses the power of every click,
[01:18:26.160 --> 01:18:32.720]   every action, every ally to grow stronger and stop cyber threats before they can stop you.
[01:18:32.720 --> 01:18:37.840]   Falcon Complete stops breaches every hour of every day. They've got expert management,
[01:18:37.840 --> 01:18:44.960]   threat hunting, monitoring, remediation, and backed by CrowdStrike's breach prevention warranty.
[01:18:44.960 --> 01:18:49.760]   And they're not just saying it. They guarantee it for Falcon Complete Managed Customers.
[01:18:49.760 --> 01:18:56.320]   We'll receive a warranty covering up to $1 million in the event of a breach. How about that?
[01:18:56.320 --> 01:19:02.240]   Terms and conditions apply. And by the way, Gartner Magic Quadrant named CrowdStrike a leader
[01:19:02.240 --> 01:19:08.880]   for endpoint protection platform for 2021. Congrats on that. Join the fight and experience the power
[01:19:08.880 --> 01:19:15.840]   of Falcon Platform for free today at CrowdStrike.com/twit. Make sure and go to that special URL. That
[01:19:15.840 --> 01:19:22.560]   way they know that you came via Twitch. That's CrowdStrike.com/twit. CrowdStrike, because what
[01:19:22.560 --> 01:19:28.080]   we've built together is worth defending together. And we thank CrowdStrike for their support of
[01:19:28.720 --> 01:19:36.960]   this week in Google. All right. What's some other Google stories that we can talk about here?
[01:19:36.960 --> 01:19:41.120]   Want to see if we can keep it locked in a Google for a bit? We've got, oh, actually,
[01:19:41.120 --> 01:19:46.480]   this is interesting. Okay, so what's the latest version of Android that launched?
[01:19:46.480 --> 01:19:49.680]   Officially. What is it? Is it Android 12?
[01:19:49.680 --> 01:19:51.680]   -12. -12, right? -12.
[01:19:51.680 --> 01:19:53.360]   -12. -No, wrong.
[01:19:54.320 --> 01:19:58.960]   Yeah, that's right. Android 12 came out a week ago. We already have a new version of Android on the
[01:19:58.960 --> 01:20:07.200]   horizon. Good lord. This is weird, but it totally happened today. -What did it fix?
[01:20:07.200 --> 01:20:16.400]   -Is wallpaper color? -No. -This isn't even an incremental update on bug fixes and security
[01:20:16.400 --> 01:20:23.440]   patches and everything. This is a new version of Android called Android 12L. And this was shown off
[01:20:23.440 --> 01:20:28.720]   at an Android dev summit, which happened today. So it's a developer summit that Google puts on.
[01:20:28.720 --> 01:20:36.960]   And they talked all about Android 12L, which we had heard previously that there was a potentially
[01:20:36.960 --> 01:20:41.680]   a point release that would be coming a little bit later. I don't know if... Yeah, I think on
[01:20:41.680 --> 01:20:45.360]   Twig, you guys had discussed at least to some degree that there were rumors that there was a
[01:20:45.360 --> 01:20:53.200]   possibility that Google would release a foldable device during the Pixel event. And the
[01:20:53.200 --> 01:20:58.160]   rationale around this was, okay, if that was to happen, it would have to happen by the end of the
[01:20:58.160 --> 01:21:02.160]   year. That's what some of the leaks said. And there would be a new version of Android to enable it.
[01:21:02.160 --> 01:21:06.320]   Turns out that this is the new version of Android to enable it. We still know nothing about a
[01:21:06.320 --> 01:21:16.480]   Pixel foldable, but Google showed off and kind of spilled out the roadmap for this next version
[01:21:16.480 --> 01:21:24.560]   of Android. It's all about tablets and foldables. It brings a bunch of functionality for larger
[01:21:24.560 --> 01:21:32.880]   screen devices running Android and as well, kind of usability tweaks that improve the foldable
[01:21:32.880 --> 01:21:40.240]   experience. So like a bottom of the screen taskbar, similar to what you'd see on just a regular
[01:21:40.240 --> 01:21:46.800]   desktop OS, something like that inside of Android, some enhancements to split screen and some of those
[01:21:46.800 --> 01:21:54.160]   navigating or pulling an app from your taskbar and putting it into the one screen, having your
[01:21:54.160 --> 01:22:00.080]   second screen be a completely different app, different changes to the notification panel,
[01:22:00.080 --> 01:22:06.080]   quick settings. So I don't know how much of this we're going to see. This isn't going to affect the
[01:22:06.080 --> 01:22:09.720]   OS that's running on our phones. But if you're going to get into the
[01:22:09.720 --> 01:22:14.720]   table, you might just text to be if you go to about Chromebooks.com, you'll see on the top.
[01:22:14.720 --> 01:22:23.280]   There's also speculation about what it would do to mobile apps in Chromebooks. Oh, he says, man,
[01:22:23.280 --> 01:22:32.560]   he says, he doesn't care or I think he doesn't doesn't quite believe it was going to go to change
[01:22:32.560 --> 01:22:38.960]   Commodore correctly. Yeah. Wrong here. Oh, so I'm curious to know that as well, actually,
[01:22:38.960 --> 01:22:44.640]   if that would reach into there or because I mean Chrome OS is different than Android OS and this is
[01:22:44.640 --> 01:22:52.480]   an Android version update. So I'm not I'm not entirely sure unless what what he's talking about
[01:22:52.480 --> 01:22:58.960]   is that the apps that are created with Android 12L or whatever it's going to be called in mind
[01:22:59.600 --> 01:23:03.300]   would need to also operate on Chromebooks because
[01:23:03.300 --> 01:23:08.480]   well, and also do things that that Android has probably that the Chromebooks have problems with.
[01:23:08.480 --> 01:23:10.960]   Well, I was actually that's the wrong way to put it probably.
[01:23:10.960 --> 01:23:17.760]   We Chromebook users who occasionally use Android apps would wish they would do things like resize
[01:23:17.760 --> 01:23:28.240]   smarter and do other things and and they don't necessarily right. So he's on the iOS side too with
[01:23:28.240 --> 01:23:35.680]   apps not necessarily resizing properly for iPad. So yep. Yep. It's weird. We still have the
[01:23:35.680 --> 01:23:42.400]   bifurcated OS is the computer OS and the photo OS and they haven't come together. I mean,
[01:23:42.400 --> 01:23:47.120]   just this has been a long time. It keeps saying people keep saying that they're going to and then
[01:23:47.120 --> 01:23:53.440]   it keeps not happening. Exactly. Right. And what we get when we get flying cars and paperless offices
[01:23:53.440 --> 01:24:01.040]   we'll find it. Wait for the end. Wait for the end. I mean, I think one thing that's interesting
[01:24:01.040 --> 01:24:06.000]   to me about this is that, you know, yes, it's about foldables, but it's also about tablets and I
[01:24:06.000 --> 01:24:12.800]   feel like tablets and right in tablets have not been something that that's been an experience
[01:24:12.800 --> 01:24:18.320]   an experiment that hasn't always gone very well. Except for my beloved Nexus 7.
[01:24:19.120 --> 01:24:23.840]   Well, yeah, that's kind of what I was going to see what I was actually going to follow up with
[01:24:23.840 --> 01:24:29.280]   is that there was a time when Google had a lot of energy around was putting a lot of energy into
[01:24:29.280 --> 01:24:34.800]   tablets, right? Android 3.0 is Honeycomb. That was the first version of Android designed specifically
[01:24:34.800 --> 01:24:40.160]   for tablets or or with tablets in mind. Eventually they came out with the Nexus 7 and you're like,
[01:24:40.160 --> 01:24:44.800]   okay, I like where this is headed. And then somewhere along the line, it kind of fell off a cliff and
[01:24:44.800 --> 01:24:50.160]   which is not to say that Android tablets don't exist, but Google certainly not putting a lot of
[01:24:50.160 --> 01:24:55.440]   its attention or energy into it. It just still seemed to care, which is too bad. I think they
[01:24:55.440 --> 01:25:00.160]   could have it is. I think that was a potential opportunity, but obviously they didn't think it
[01:25:00.160 --> 01:25:08.160]   was worth investing in. Scooter X and Chad is pointing out that this Android 12L is also coming
[01:25:08.160 --> 01:25:12.640]   to phones. Okay, so that's I was wondering if it was just going to be isolated to like certain
[01:25:12.640 --> 01:25:19.600]   sizes of screens or whatever, but I guess this would be all baked into 12 once that happens.
[01:25:19.600 --> 01:25:27.600]   They've got they basically spelled out the roadmap for the for the beta. And I think sometime by like
[01:25:27.600 --> 01:25:32.800]   February or March, we're probably going to see a see the version. You know, there's going to be a
[01:25:32.800 --> 01:25:38.560]   number of betas leading up to that. But it makes me wonder like, okay, so then if this is the OS
[01:25:38.560 --> 01:25:46.080]   update, that would pave the way for Google's supposed foldable pixels, of which there's been a lot of,
[01:25:46.080 --> 01:25:52.080]   I would say, credible rumors around. Maybe that means that we're going to see, you know,
[01:25:52.080 --> 01:25:57.600]   pixel foldables middle next year, something like that. Would anyone here be interested?
[01:25:57.600 --> 01:26:03.040]   Like actually be like buying buying this phone interested if Google was to put out a foldable or
[01:26:04.720 --> 01:26:10.480]   I was interested in foldable devices, the the Surface Duo 2, is that what it's called?
[01:26:10.480 --> 01:26:15.760]   Yeah, Microsoft the latest one. I was really interested in that is I thought the fall in fact
[01:26:15.760 --> 01:26:20.480]   they're made sense even with the hinge right there in the middle and splitting the screens and all
[01:26:20.480 --> 01:26:27.600]   of that. Until I saw some reviews on it and the functionality just didn't quite didn't just just
[01:26:27.600 --> 01:26:33.680]   didn't seem like it would work well, especially if you wanted to do things quickly, having to open
[01:26:33.680 --> 01:26:39.280]   and I don't know if that would be the case with the Google's version. If you'd be able to do things
[01:26:39.280 --> 01:26:44.080]   quickly from it, just like you would if you pulled a camera out, pulled your smartphone out of your
[01:26:44.080 --> 01:26:49.280]   pocket, would you need to pull it out and unfold it and unlike it and yeah, yeah, yeah, it's no.
[01:26:49.280 --> 01:26:52.240]   I saw the part of me. Yes, but another part. No.
[01:26:52.240 --> 01:26:58.720]   Maybe it's just a long time. I just don't, I don't understand why I don't see the appeal
[01:26:59.280 --> 01:27:05.520]   of a foldable phone. I just don't, I don't get it. So Matthew, I agree with you. I thought I was,
[01:27:05.520 --> 01:27:09.760]   I was laughing at it, but then I went to Best Buy to try to figure out my Chromebook situation,
[01:27:09.760 --> 01:27:16.640]   which is a whole other story. And, and, and I stopped by to see not only the, the six pro,
[01:27:16.640 --> 01:27:22.080]   but then looked at the photables again and the, and the vertical fold, which Leo likes to,
[01:27:22.080 --> 01:27:26.720]   is really appealing. I don't know why it is and it probably is awkward and probably too big for
[01:27:26.720 --> 01:27:30.720]   the, what is folded for the pocket. I don't know why. I guess I just put it in your pocket.
[01:27:30.720 --> 01:27:35.360]   Like it kind of works, but it kind of works because what you end up with is a phone.
[01:27:35.360 --> 01:27:39.200]   You end up with a phone. Yeah. Rather than where do you put it?
[01:27:39.200 --> 01:27:44.480]   I'm holding it says, you put it in your pocket because now it's a double with,
[01:27:44.480 --> 01:27:48.160]   like it's double sickness phone. Yes, it's a visible.
[01:27:48.160 --> 01:27:56.000]   Yeah, it ends up being kind of like a smaller square. Yeah. Yeah.
[01:27:56.000 --> 01:27:58.400]   Yeah. But double this anyway.
[01:27:58.400 --> 01:28:00.800]   New VPL. The kids can have it.
[01:28:00.800 --> 01:28:07.040]   There we go. Yeah. Six or six.
[01:28:07.040 --> 01:28:09.840]   They could, they could do their tick talk on it.
[01:28:09.840 --> 01:28:14.960]   That's right. And Sam said, I'll be perfectly happy if that's exactly what happens.
[01:28:14.960 --> 01:28:19.120]   I don't know. The Z Flip 3 is actually a pretty cool device, but
[01:28:20.480 --> 01:28:26.000]   which when I played around with it, and I think Leo actually has it and it kind of shares my
[01:28:26.000 --> 01:28:30.880]   opinion on it, it seems like the first foldable that's like, okay, I could see this one doing really
[01:28:30.880 --> 01:28:36.400]   well. And I'm curious now that we're a couple of months after it's been released, how it's actually
[01:28:36.400 --> 01:28:42.240]   sold. I don't know that I've seen any exact numbers as far as that's concerned, but it really
[01:28:42.240 --> 01:28:49.920]   did seem like the first foldable that had, at least in my use, in my mind, more of a consumer appeal
[01:28:50.560 --> 01:28:56.800]   for a number of reasons. So surface duo to, yeah, I'm not sure how consumer appeal,
[01:28:56.800 --> 01:29:02.080]   yeah, how much consumer appeal that that device has, but yeah, you know, we're still trying to
[01:29:02.080 --> 01:29:07.120]   figure out how where these things actually fit into place, why we need to have them, you know.
[01:29:07.120 --> 01:29:16.960]   Let's see here. What else do we got? We got talk about some collusion.
[01:29:19.840 --> 01:29:21.280]   Which collusion?
[01:29:21.280 --> 01:29:27.200]   Well, there's Jedi blue or whatever.
[01:29:27.200 --> 01:29:34.880]   Jedi blue. Okay. Jedi blue, again, falls into the category of like, holy cow, I'm drowning in this
[01:29:34.880 --> 01:29:44.000]   avalanche of stuff, but it's Google. So let's do it. Yeah, so someone's probably better to set up
[01:29:44.000 --> 01:29:50.720]   Jedi blue, but this has to do with unsealed court documents in Texas in an antitrust filing.
[01:29:50.720 --> 01:29:59.440]   Yeah, it was a quid quid pro quo between Google and Facebook, in which allegedly Facebook said it
[01:29:59.440 --> 01:30:06.480]   would not raise a stink about Google's ad market share provided it got sweetheart deals in those ad
[01:30:06.480 --> 01:30:06.960]   auctions.
[01:30:10.000 --> 01:30:17.520]   Awesome. That's awesome. This is how to get richer, you know, like you said,
[01:30:17.520 --> 01:30:24.320]   always said where Google is vulnerable is not search. It's not phones. It's it's position in
[01:30:24.320 --> 01:30:29.680]   the ad market. And they should have been hyper, hyper careful there, because that is where they have
[01:30:29.680 --> 01:30:34.880]   a near monopoly. And what can you do about that?
[01:30:37.360 --> 01:30:44.560]   They also allegedly, sorry, they also allegedly conspired or tried to conspire with other tech
[01:30:44.560 --> 01:30:49.600]   giants to delay privacy laws.
[01:30:49.600 --> 01:31:01.600]   And so this is when Apple is seen as the night in China armor, because of their privacy focus.
[01:31:03.840 --> 01:31:11.920]   Right? Yeah. And of course, privacy, Apple's concerned about your privacy, unless you're Chinese and
[01:31:11.920 --> 01:31:19.280]   live in China. Oh, yeah, then there's a Apple user and they're concerned about your privacy is
[01:31:19.280 --> 01:31:24.640]   used by others, not by Apple. Right. They have the privilege.
[01:31:24.640 --> 01:31:32.480]   Businessness. Yeah, had to do. There were a number of other things here. There was a thread
[01:31:32.480 --> 01:31:38.080]   on Twitter, by who's faster than lime? Not sure this is, but Leo had tagged this.
[01:31:38.080 --> 01:31:43.520]   He was re sharing. He was re sharing a thread that came from someone else. I'm not sure who.
[01:31:43.520 --> 01:31:49.280]   Got it. I blew it around. Like it was recorded on in back in January, I think.
[01:31:49.280 --> 01:31:54.640]   That's right. That's right. And that was just one aspect of what what this person was sharing.
[01:31:55.520 --> 01:32:02.800]   Also, that Google apparently had it set up so that it could win its own ad auctions, even when
[01:32:02.800 --> 01:32:11.360]   they aren't the highest bidder, that they were taking a 22 to 42% cut of ad spending that goes
[01:32:11.360 --> 01:32:17.360]   through the system, which was two to four times as much as as the ad exchanges it was competing
[01:32:17.360 --> 01:32:22.720]   against. Yeah. They're basically saying that Google does what what insecurities trading is
[01:32:22.720 --> 01:32:30.160]   called front running, where they basically take cuts of deals because they're the house.
[01:32:30.160 --> 01:32:37.120]   Yeah. Right. Right. Because they can. Can you explain the controversy over header bidding to
[01:32:37.120 --> 01:32:44.800]   our audience? Because I can't. Well, how much time do we have?
[01:32:46.880 --> 01:32:55.040]   Not enough. I mean, it's it isn't a real time auction. And so all the things that are potentially
[01:32:55.040 --> 01:33:02.480]   problematic with auctions, especially where one entity controls the auction, all of those things
[01:33:02.480 --> 01:33:09.520]   come into play. Basically, that's the short version. And it all occurs in hundreds of a second
[01:33:09.520 --> 01:33:16.640]   while your page is noting, which is which is, by the way, amazing. Yeah. Yeah, that's pretty
[01:33:16.640 --> 01:33:24.000]   crazy. See, you've got there. Yeah. Meanwhile, for a lighter note, I just want to be on the record
[01:33:24.000 --> 01:33:29.280]   here. I'm known for the show for being bridge phobic. I'm not crazy about this. Your Richmond
[01:33:29.280 --> 01:33:34.880]   bridge is insane. And 72. Yeah, that was a bridge video. It was crazy.
[01:33:34.880 --> 01:33:42.880]   I'm not going on that thing. No, no, the Bay Bridge collapses. The Richmond Bridge,
[01:33:42.880 --> 01:33:50.720]   things fall over on top of you. Bridges are dangerous. That was, oh, yes. Okay. I didn't see that you
[01:33:50.720 --> 01:33:56.320]   had put this in the rundown. That is insanity. So this was during the storms that we had,
[01:33:56.320 --> 01:34:02.400]   that we had swooping through here, not too long ago, like within a matter of days,
[01:34:02.400 --> 01:34:06.320]   definitely within the last week, but on the Richmond Bridge Saturday and Sunday.
[01:34:07.040 --> 01:34:12.720]   Yeah. And I guess this is just wind barreling through the bridge toppling, almost toppling,
[01:34:12.720 --> 01:34:17.680]   just a huge, well, because it would have topped completely, except it's on top of a truck.
[01:34:17.680 --> 01:34:23.760]   It's on top of another truck. Another truck. And it's still moving. That's just stunt
[01:34:23.760 --> 01:34:24.960]   driving. I think that's,
[01:34:24.960 --> 01:34:32.400]   just one on the driver of that truck. What are you doing right then? And at moment,
[01:34:32.400 --> 01:34:39.760]   you're putting my job. You're a she do. That's your cursing loudly. Oh my god. Every right.
[01:34:39.760 --> 01:34:46.240]   That that jammer would be would be dumping. Imagine. I'm really changing your draws at the
[01:34:46.240 --> 01:34:52.000]   words. Yeah, I would. I can't even imagine being that driver. Yeah. Being in that vehicle when
[01:34:52.000 --> 01:34:59.680]   that's happening. No, thank you. And and also the truck that this big semi just like, oh, yeah.
[01:35:00.720 --> 01:35:06.640]   That person too is like, what the heck just minding my business in this traffic. Wait, what?
[01:35:06.640 --> 01:35:10.320]   Crazy. Someone said truck driver couldn't help it Brown.
[01:35:10.320 --> 01:35:19.200]   Good title. Good title. Nashed potato.
[01:35:19.200 --> 01:35:28.320]   Love it. What about Stadia becoming a white label game streaming platforms? You
[01:35:29.360 --> 01:35:34.320]   follow this at all. This is this is kind of what we well, this is what I've been waiting for,
[01:35:34.320 --> 01:35:37.760]   not not like anticipating like, oh, I can't wait for this to happen. But this is what I have
[01:35:37.760 --> 01:35:41.440]   expected to happen. And I know there was there was some mention that this was probably the
[01:35:41.440 --> 01:35:47.200]   direction the stadium was going to go for. But it's also just like, man, Google like, why,
[01:35:47.200 --> 01:35:54.640]   why could Google not make Stadia more of an appealing product the way I think they intended
[01:35:54.640 --> 01:36:00.000]   to when they launched it. It's just it's so quickly seemed to evaporate. And I'm not saying that there
[01:36:00.000 --> 01:36:05.120]   aren't people out there who are ardent fans of Stadia. I know you're out there. I hear from you
[01:36:05.120 --> 01:36:11.440]   anytime I ever say anything remotely bad about Stadia. But it could be so much bigger. It could
[01:36:11.440 --> 01:36:17.040]   have made such a bigger difference in the game industry. They're undoubtedly doing great things.
[01:36:17.040 --> 01:36:22.400]   But what they need to do what they're doing right now is essentially opening up the technology behind
[01:36:22.400 --> 01:36:29.840]   Stadia to be to offer up to other companies for their efforts. In this case, it's AT&T
[01:36:29.840 --> 01:36:38.560]   to release one of their games driven in off of Stadia's technology, but not necessarily
[01:36:38.560 --> 01:36:42.240]   mentioning Stadia. So if you go to the website, you wouldn't see Stadia or Google mentioned
[01:36:42.240 --> 01:36:46.960]   anywhere. They're just kind of behind the scenes powering the experience. But
[01:36:48.400 --> 01:36:53.920]   on one hand, it also kind of seems like this is Google's strength more than it is creating a
[01:36:53.920 --> 01:36:58.560]   gaming platform. You know, is creating the technology that that powers the gaming platform.
[01:36:58.560 --> 01:37:00.720]   I had a question for you, Strow.
[01:37:00.720 --> 01:37:06.960]   What's up? Go ahead. Question for you, Mr. How. You were saying that this could have been so
[01:37:06.960 --> 01:37:12.320]   much better. Google could have made this so much better. My question is how? Yeah. Well,
[01:37:12.880 --> 01:37:21.200]   that's a really great question. Investing $20 billion. I mean, but into the infrastructure,
[01:37:21.200 --> 01:37:26.400]   into development, into what in particular? That's a really good question. I mean,
[01:37:26.400 --> 01:37:35.040]   the thing that I think is very much not appealing to me is this is just the sheer fact that Google
[01:37:35.040 --> 01:37:42.240]   has proven itself to be hard to trust when it comes to big initiatives and projects like Stadia.
[01:37:42.240 --> 01:37:47.120]   Yeah. Yeah. It comes out of the gate with something that's really cool. No question.
[01:37:47.120 --> 01:37:54.000]   This is awesome technology. And I love the concept. I love the work that they've done,
[01:37:54.000 --> 01:38:01.680]   but I still don't quite trust Google. Right. You know, there's so many examples. You could list
[01:38:01.680 --> 01:38:06.880]   them the same as me where that's happened. And then they just don't follow up and they don't
[01:38:06.880 --> 01:38:10.800]   invest. And then pretty soon, oh, yeah, we're shutting it down. And everybody's like, oh, yeah,
[01:38:10.800 --> 01:38:17.280]   I remember that thing. Yeah. It was. Yeah. Let's make promises and they don't deliver on the promises.
[01:38:17.280 --> 01:38:23.680]   Let's look at this in the perspective of the, as we like to call it, normals of society.
[01:38:23.680 --> 01:38:33.280]   I think this is similar to the way Facebook has got that lock in on people, expats in that service
[01:38:33.280 --> 01:38:38.560]   and PlayStation and that service has people locked in. You walk up to them and say, hey,
[01:38:38.560 --> 01:38:43.920]   Google has this platform or you can play this game and that game and so on and so forth. And it's
[01:38:43.920 --> 01:38:49.280]   beautiful. It's fast. You got to got to got to. They're probably still not going to walk away.
[01:38:49.280 --> 01:38:57.440]   They're just locked in, you know, but what could Google do to pull those normal gamers away?
[01:38:57.440 --> 01:39:04.800]   I mean, the only thing you can do is come up with a game that is just so beyond, you know,
[01:39:04.800 --> 01:39:06.240]   everything else.
[01:39:06.240 --> 01:39:12.000]   Loose easily. Yeah. And that, I mean, that's how those platforms did what they did.
[01:39:12.000 --> 01:39:18.400]   You have to, it doesn't have anything to do with the technology or the controller or the,
[01:39:18.400 --> 01:39:23.520]   you've got to have the game and it has to be different enough. It can't just be kind of like,
[01:39:23.520 --> 01:39:29.280]   you know, Call of Duty or kind of like, you, to me, that's where they should have invested the
[01:39:29.280 --> 01:39:34.400]   money and I could be prepared to. I would bet that most of those
[01:39:35.680 --> 01:39:42.000]   air quotes, normal gamers would have no idea about the products that Google has launched and
[01:39:42.000 --> 01:39:47.520]   kicked to the curb because they don't care. It's just they're just not in that in that world,
[01:39:47.520 --> 01:39:52.560]   if you will. But if you walked up and said, Hey, Google has something that's pretty
[01:39:52.560 --> 01:39:58.240]   dad gum good. You want to try it out? They say, I'll try it for a week for free. And they probably
[01:39:58.240 --> 01:40:03.440]   won't stick. I just, I don't know what, what can Google do to make it stick, if you will?
[01:40:04.400 --> 01:40:09.440]   Well, I mean, you know, touching on what you were, you would just mention their Matthew as far as,
[01:40:09.440 --> 01:40:16.080]   you know, creating an exclusive game like, Stadia, they were doing that. Google had, had made investments
[01:40:16.080 --> 01:40:21.520]   and created their own game studio and acquired other major game studios and major players in the
[01:40:21.520 --> 01:40:27.760]   game development industry to do exactly that. The problem is they shut it down well before they
[01:40:27.760 --> 01:40:33.840]   were able to create anything. They spent like a year with this project and then like gave up on it.
[01:40:34.400 --> 01:40:37.680]   You know, a lot of people were quick to point out, like if you're, if you're looking to create a
[01:40:37.680 --> 01:40:42.640]   triple A game with, you know, that kind of talent and something that's going to really move the needle
[01:40:42.640 --> 01:40:47.200]   as an exclusive on your platform, they need, you know, Google needed to start three years prior
[01:40:47.200 --> 01:40:52.880]   to Stadia even being a thing just so that they could do that. And they weren't able to look
[01:40:52.880 --> 01:40:59.600]   up on it. Look, look at Xbox and PlayStation. I mean, it's not like they became hugely successful
[01:40:59.600 --> 01:41:06.240]   and their games were kind of hugely popular overnight. It took years. It took years of development and
[01:41:06.240 --> 01:41:11.600]   pushing and pushing and billions of dollars. You can't, that's something that just can't happen.
[01:41:11.600 --> 01:41:16.320]   It's like saying, let's build a movie studio and then we'll release a blockbuster next year
[01:41:16.320 --> 01:41:22.640]   and boom, we'll be a movie studio. We did it. Yeah, it's probably not going to happen that way.
[01:41:22.640 --> 01:41:28.400]   And in that light, it kind of seems like Google really, it almost seems like Google really didn't
[01:41:28.400 --> 01:41:34.560]   understand what game it was getting into. No pun intended, right? Like it, they didn't understand
[01:41:34.560 --> 01:41:39.520]   the playing field enough to know that like what they were setting themselves up to do
[01:41:39.520 --> 01:41:45.360]   wasn't going to cut it. And they're, you know, getting rid of that studio and then now doing
[01:41:45.360 --> 01:41:49.600]   this white label approach kind of kind of makes it seem like, you know, at a certain point, they
[01:41:49.600 --> 01:41:53.520]   were like, why are we dumping all this money into this? We aren't certain that there's going to be
[01:41:53.520 --> 01:41:58.000]   any sort of, you know, success on the other side of all of this effort. But we do know we have a good
[01:41:58.000 --> 01:42:00.880]   technology and why we offer this technology to others.
[01:42:00.880 --> 01:42:05.600]   And you think it makes a lot of sense? Yeah. Like I think that that makes sense for them.
[01:42:05.600 --> 01:42:10.240]   It's a good route for Google to go. This is essentially licensed. They're all not open. Yeah.
[01:42:10.240 --> 01:42:16.160]   Yeah. Yeah. So they're still going to make somebody off of a potentially. Okay. Absolutely.
[01:42:16.160 --> 01:42:19.120]   They're going to make some money. I don't know what they, yeah, I don't know what kind of money
[01:42:19.120 --> 01:42:22.720]   they're making on a deal like this. And this is only the first one. I have to imagine there's
[01:42:22.720 --> 01:42:27.840]   there's going to be others. And, you know, will we know that Stadia is powering these others? I
[01:42:27.840 --> 01:42:34.640]   don't even know. You know, this one was discovered before it was announced. So, you know, and acknowledged.
[01:42:34.640 --> 01:42:41.520]   Is this about like how it was with Chromecast? I'm sorry for scratching on camera. Is this about
[01:42:41.520 --> 01:42:48.320]   like how if it is you got a scratch? Because how else do you keep that beautiful sheen
[01:42:49.200 --> 01:42:55.040]   right for your for your camera? You can't go itchy. It's going to it's going to twitch. It's just not
[01:42:55.040 --> 01:42:59.600]   going to look good. Yeah. If it's just even more now, I know we keep talking about it. It's really
[01:42:59.600 --> 01:43:05.440]   okay. I think I'm good now. I think I'm going to scratch it. But yeah, I remember when Chromecast
[01:43:05.440 --> 01:43:12.560]   came out and how cool that was. Granted, it had to had its glitchy moments and whatnot. But then,
[01:43:12.560 --> 01:43:18.080]   you know, a year or so later, it seems like you see that little cast logo on everything. It doesn't
[01:43:18.080 --> 01:43:24.480]   necessarily say Chromecast. It just says Cast or something like that. Is this a similar situation?
[01:43:24.480 --> 01:43:28.480]   Then again, I don't even know if Google came up with that technology.
[01:43:28.480 --> 01:43:36.160]   I, you know, I don't know. I haven't I haven't played it's about man Arkham Knight is the game
[01:43:36.160 --> 01:43:40.960]   that AT&T was offering. And I don't even know, you know, how long it's offered. It's like a free
[01:43:40.960 --> 01:43:46.640]   thing that AT&T was offering 1080p streaming, that sort of thing. I do know from what I've read
[01:43:46.640 --> 01:43:51.760]   about it that there was no real indication anywhere that they were using anything from Google.
[01:43:51.760 --> 01:43:58.240]   It was somebody looking at the source on the page or something like that and discovered a line
[01:43:58.240 --> 01:44:03.680]   of code that mentioned a code name that had previously been known to be associated with Stadia.
[01:44:03.680 --> 01:44:09.200]   And that was what prompted AT&T and Google to even acknowledge that it exists that there was a
[01:44:09.200 --> 01:44:14.560]   relationship there. So, okay. So seemingly, this all happens underneath the radar. And maybe that's
[01:44:14.560 --> 01:44:19.360]   just the way it's going to be. And, you know, I don't know what Google ends up earning on a deal
[01:44:19.360 --> 01:44:26.560]   like this. I don't I wouldn't be surprised at all if we see a whole lot more of this. But I
[01:44:26.560 --> 01:44:32.960]   also don't know what that means for what Stadia is right now, because, you know, the big downside
[01:44:32.960 --> 01:44:38.320]   for me, like I probably wouldn't buy a game for Stadia because of what I know about Google and
[01:44:38.320 --> 01:44:45.200]   their, you know, their their ability to pivot away from things when I like them. But also,
[01:44:45.200 --> 01:44:50.640]   like, if I'm paying 50 or 60 bucks for a game and it only exists in the cloud and then Google
[01:44:50.640 --> 01:44:55.120]   changes its mind, like there's no guarantee there that I even own anything at that point.
[01:44:55.120 --> 01:45:00.160]   And, you know, so that's going to keep me away. And I know I'm not alone in that. So,
[01:45:00.160 --> 01:45:11.600]   that's that's a big hurdle for Google to have to overcome. Yeah. So, yes. And then we're we're
[01:45:11.600 --> 01:45:15.440]   kind of talking about living room stuff. So we could probably talk a little bit about this whole
[01:45:15.440 --> 01:45:23.840]   Google, Google TV, YouTube, Roku, actually, there seems to be a whole thing with smart TVs and the
[01:45:23.840 --> 01:45:29.680]   and the smart, you know, smart home smart TVs, that sort of thing. So, Google is is shifting
[01:45:29.680 --> 01:45:36.240]   Google TV to be a bigger priority in the information how to report. That said, Pichai is really saying
[01:45:36.240 --> 01:45:42.800]   that connected television is a big priority for Google right now. They're paying partners more to
[01:45:42.800 --> 01:45:48.320]   use Google TV. So they're paying anywhere between 10 to $15 per unit for partners. Roku's paying
[01:45:48.320 --> 01:45:54.320]   and then there's Roku paying $7 to $8. That ties into, you know, the fact that Google and Roku have
[01:45:54.320 --> 01:46:01.440]   been battling it out and supposedly YouTube is apparently going to drop off of Roku. In December,
[01:46:01.440 --> 01:46:06.320]   this all has to do with, you know, like a search deal that that Google wanted Roku to give it,
[01:46:06.320 --> 01:46:14.480]   give its YouTube property kind of prime search placement, its own carousel in the experience.
[01:46:14.480 --> 01:46:19.920]   Roku says, Hey, that's affecting our search. And we don't want to do that. And so now Google's,
[01:46:19.920 --> 01:46:25.280]   you know, pulling YouTube, I don't know, I don't know if Google's pulling YouTube or Roku's kicking
[01:46:25.280 --> 01:46:29.120]   it off. I doubt they're kicking it off. It doesn't matter. It's all negotiation. Yeah, it's it's all
[01:46:29.120 --> 01:46:35.840]   negotiations and and and puffing up to to try and win in the negotiation, I suppose they've got
[01:46:35.840 --> 01:46:40.800]   Comcast. They have their own smart TV that's coming out now. It's going to be available at Walmart.
[01:46:40.800 --> 01:46:45.920]   It's powered by their own OS. And then Amazon has their own smart TV launching today,
[01:46:45.920 --> 01:46:51.120]   the Fire TV Omni series that you can find at Amazon and Best Buy. Suddenly, it seems like the
[01:46:51.120 --> 01:46:56.320]   living room's a really big deal. And it's just interesting to me because Google's had Android TV
[01:46:56.320 --> 01:47:03.040]   for quite a while for for years. Now that we're in the Google TV era, suddenly, it seems like Google
[01:47:03.040 --> 01:47:08.240]   is taking the living room more seriously. And others obviously are too. Why is that? So why is
[01:47:08.240 --> 01:47:13.600]   it very important? We went in a pandemic two years ago, three years ago either. Yeah, that's a good
[01:47:13.600 --> 01:47:17.280]   point. But it's also the changing economics. I think I think you're right, Ant. I think that
[01:47:17.280 --> 01:47:23.040]   changed a lot. Our stream behavior changed, but the market changed too, right? The power of Netflix,
[01:47:23.040 --> 01:47:30.240]   so on and so forth. So the TV maker, the set maker, they've had the dumb box like the dumb wire
[01:47:30.240 --> 01:47:35.600]   all these years, right? And suddenly was with smart TV coming along. So I got my father, my
[01:47:35.600 --> 01:47:42.400]   95 year old father who's up here in New Jersey now. And he just his retirement community
[01:47:42.400 --> 01:47:46.560]   has 60 channels. That's it. It's all they need. You got the golf channel? All right, so that's all I
[01:47:46.560 --> 01:47:52.000]   need. And so, and the Fox News channel, oh, no, Paul, they don't have the Fox News channel. No,
[01:47:52.000 --> 01:47:59.200]   no, no, you can't get that here. You can't lie to your own father. Anyway, so I just wanted a TV
[01:47:59.200 --> 01:48:05.440]   where he can watch TV. I go and buy a Visio at Costco. I come back, I put it in. I'm tearing my
[01:48:05.440 --> 01:48:11.200]   hair up. I cannot get to the channels. It does nothing but want to sell me Hulu and sell me Netflix
[01:48:11.200 --> 01:48:16.560]   and because it makes a commission on all of that. In addition, Visio, a company we used to like,
[01:48:16.560 --> 01:48:23.760]   we own Visio TVs, they also have been some, some little minor PR hot water because they're, they are
[01:48:23.760 --> 01:48:29.760]   perhaps one might say violating your privacy. They are using data to try to target advertising.
[01:48:29.760 --> 01:48:34.640]   And so you find that the television set, which was what we old folks used to call it,
[01:48:35.360 --> 01:48:42.560]   is itself now part of the stack and they're trying to grab their piece of it. So that's why
[01:48:42.560 --> 01:48:47.600]   I think you have Comcast doing its own OS and its own TVs. You have Google saying, hold on,
[01:48:47.600 --> 01:48:52.320]   we're the giant of the internet. We can't lose out on this and we got YouTube and we got to worry
[01:48:52.320 --> 01:48:57.760]   that you got Roku saying, well, no, no, we're the add on that makes everything smart. You got Hulu
[01:48:57.760 --> 01:49:05.520]   and Netflix and all those saying, we just want volume. And then you got advertisers coming in saying,
[01:49:05.520 --> 01:49:10.160]   well, this whole targeting is getting to be a mess on the web. What can we do on TVs? So it's
[01:49:10.160 --> 01:49:18.320]   suddenly a roiling, fascinating, probably very irritating market. I returned to Visio TV. I got
[01:49:18.320 --> 01:49:23.840]   an LG TV. I never set up the web stuff. And all it does is go to 60 channels. It's like kind of
[01:49:23.840 --> 01:49:30.080]   going back in time. So my father, we got a big remote with big buttons so we can go to 38,
[01:49:30.080 --> 01:49:35.280]   which is a golf TV. And that's all it needs. But that's the rarity, obviously. And so in a streaming
[01:49:35.280 --> 01:49:41.520]   world and a home war world, as Ann said, I think as market changes in fascinating ways.
[01:49:41.520 --> 01:49:45.520]   Yeah, I think the streaming, I was going to say the same thing that streaming
[01:49:46.480 --> 01:49:53.920]   I think really started to take off. Then Roku, I think was kind of not that people didn't notice,
[01:49:53.920 --> 01:49:59.040]   but nobody thought that was going to be a big deal. First they had the little boxes and then,
[01:49:59.040 --> 01:50:04.080]   okay, it's now it's in your TV. But then all of a sudden you watch the streaming numbers,
[01:50:04.080 --> 01:50:09.040]   you watch Netflix's growth, and then COVID comes everybody's spending all the time inside.
[01:50:09.040 --> 01:50:12.080]   All of a sudden, our TVs look like a pretty great business.
[01:50:13.280 --> 01:50:19.120]   I'm not kidding. Well, I'm looking forward to Google TV heading more TV sets at least,
[01:50:19.120 --> 01:50:24.480]   because Google TV is a good interface. I think Google has done has made some really great changes
[01:50:24.480 --> 01:50:30.560]   to what was Android TV still don't really exactly know the difference between Android TV and Google
[01:50:30.560 --> 01:50:36.080]   TV. I was going to ask you anything with a new UI, you know, like, it's kind of confusing.
[01:50:36.080 --> 01:50:43.280]   I think the newer ones were it's basically like a fire stick. I have that plugged into an old TV,
[01:50:43.280 --> 01:50:50.160]   and I was thinking about getting a new TV, and I asked one of our kids works at Best Buy. I said,
[01:50:50.160 --> 01:50:55.600]   "Can I get a stupid TV? Can I get one that has no smart features?" And I can just plug the Chromecast
[01:50:55.600 --> 01:50:59.440]   in. Yeah, you can't do that. You can't buy them.
[01:51:00.320 --> 01:51:07.840]   Yeah. That's on the LG. I purposely didn't go and put in any Wi-Fi information so that it
[01:51:07.840 --> 01:51:15.840]   couldn't be smart. Robotic Discord. Robotic Discord says, "Every TV is a dumb TV when it doesn't
[01:51:15.840 --> 01:51:26.240]   know the Wi-Fi password." That's true. True. That's true. You're still potentially dealing with,
[01:51:26.240 --> 01:51:30.880]   you know, weirdness in the interface and everything. Oh, man, I have a Samsung. We have a Samsung
[01:51:30.880 --> 01:51:36.080]   smart TV, and yeah, the little ads that it puts in the dock down there, just like, "I'll kill it with
[01:51:36.080 --> 01:51:43.200]   fire." I can't take it. But it is what it is. It is what it is. I wish I had Google TV on that
[01:51:43.200 --> 01:51:49.440]   screen instead. Someday, maybe. That's one of those interesting stories. "Can I ask Matthew a
[01:51:49.440 --> 01:51:59.680]   question?" Yeah, go for it. Yeah. Line 68. Reed Hoffman, George Soros, investing in outright liberal
[01:51:59.680 --> 01:52:07.520]   media. What have you said about this, Matthew? So I got in a little trouble on Twitter as I
[01:52:07.520 --> 01:52:11.520]   often like to do. I know you did. That's why I put it in your back in trouble now.
[01:52:12.560 --> 01:52:25.120]   Yeah. You're welcome, Matthew. Thanks. I sort of offhandedly said, you know, if right-wing billionaires
[01:52:25.120 --> 01:52:32.080]   did the identical thing, everyone would be very mad. And of course, everybody responded
[01:52:32.080 --> 01:52:38.480]   by dunking on me and saying right-wing billionaires have done that, which was exactly my point.
[01:52:40.080 --> 01:52:46.000]   If you... This is supposed to be okay because it's about disinformation
[01:52:46.000 --> 01:52:53.600]   and it's about progressive news. But fundamentally, you know, they're investing in...
[01:52:53.600 --> 01:53:02.160]   acronym was a hugely problematic kind of progressive lobbying effort that created
[01:53:02.160 --> 01:53:09.600]   local news sites or what purported to be local news sites and didn't really disclose very well
[01:53:09.600 --> 01:53:16.080]   who ran them or what they were trying to do. And you know, that's... To me, that's not a great
[01:53:16.080 --> 01:53:23.200]   idea when what you're trying to do is get people to trust your information. And then we got into
[01:53:23.200 --> 01:53:29.920]   an argument about disinformation and is it in the eye of the beholder? You know, everyone,
[01:53:29.920 --> 01:53:36.240]   disinformation is whatever someone says that you disagree with. There's no easy way to
[01:53:37.200 --> 01:53:43.760]   sort of define it. So Reed Hoffman wants you to think that his information is going to be better.
[01:53:43.760 --> 01:53:50.480]   I just find the whole thing problematic. Like, if you want to invest in local news, then
[01:53:50.480 --> 01:53:57.120]   invest in local news. Like, don't create a like shell company that runs kind of quasi or
[01:53:57.120 --> 01:54:03.200]   theoretically local news sites. And you know what I mean? I just don't think it's bad.
[01:54:06.960 --> 01:54:10.000]   Thank you. I... I defer to you. I've got nothing on that.
[01:54:10.000 --> 01:54:13.040]   I did not read that story.
[01:54:13.040 --> 01:54:21.920]   What do you say we do a little bit of change log actions? It's feeling like a change log time.
[01:54:21.920 --> 01:54:24.800]   Yeah. It's feeling like change log time. Let's do it. Sound the horns.
[01:54:24.800 --> 01:54:27.840]   I think we need a barbershop quartet.
[01:54:36.480 --> 01:54:38.960]   It would sound a million times better than that. That's for sure.
[01:54:38.960 --> 01:54:50.720]   Google Chrome has some work that's doing into combining tab groups and bookmarks, apparently.
[01:54:50.720 --> 01:54:56.720]   Android police is not happy. Not happy about it. They're so...
[01:54:56.720 --> 01:55:00.400]   They're screwing with it. Yeah. 95 power bookmarks.
[01:55:01.120 --> 01:55:04.720]   They want to combine all those three things into one. But when you're...
[01:55:04.720 --> 01:55:11.440]   I'm using bookmarks. I'm storing stuff for some future research. I don't want them to mess with it.
[01:55:11.440 --> 01:55:18.560]   I agree. Yeah. Don't move my cheese. Yeah, exactly. Get off my lawn, Google.
[01:55:18.560 --> 01:55:24.560]   You can enable this feature with a flag. If you go to the Android police article,
[01:55:24.560 --> 01:55:27.920]   they give you the flag and then you just restart your browser and you can check it out for yourself.
[01:55:27.920 --> 01:55:35.520]   But yes, power bookmarks, bookmarks, tab groups, recent searches all combined into a single thing.
[01:55:35.520 --> 01:55:38.560]   When you call something power, you're probably trying too hard.
[01:55:38.560 --> 01:55:45.760]   Yeah. That's true. That's true. So yeah, I have no experience with that directly.
[01:55:45.760 --> 01:55:48.480]   I'll probably test it out and never use it.
[01:55:48.480 --> 01:55:54.080]   I'm scared to try it. Yeah, not part of my usage. We'll see.
[01:55:54.080 --> 01:55:59.840]   If you have a nest hub... I haven't booked that a lot though. In recent years,
[01:55:59.840 --> 01:56:05.680]   I've done a lot of bookmarks. It seems like the story of stored history. It just saves it there.
[01:56:05.680 --> 01:56:11.440]   And do you have your history deleted? You know how Google gives you the tools to have your history
[01:56:11.440 --> 01:56:16.720]   deleted after a certain amount of time? Does that affect us at all? It's periodic. But I go to the
[01:56:16.720 --> 01:56:21.440]   same handful of sites throughout the world. Sites all the time. That's true. So I kind of read it.
[01:56:21.440 --> 01:56:29.120]   It's true. Yeah, I don't know. I mean, a handful of bookmarks every once in a while, but just
[01:56:29.120 --> 01:56:36.080]   something that I need to have in my tool bar in my browser as a go to. For instance, the dock
[01:56:36.080 --> 01:56:40.880]   for best dubs because I'm in the midst of creating our best dubs for the end of the year.
[01:56:40.880 --> 01:56:45.360]   And I don't want to do such a good job. You know that URL off top of your head, Mr. Howe.
[01:56:46.160 --> 01:56:52.160]   Twit.tv/bestof if you want to submit, which I'll just go ahead and say like no one's
[01:56:52.160 --> 01:56:57.440]   submitted this year. It's all entirely on the producers this time around. So hopefully you like
[01:56:57.440 --> 01:57:06.480]   what you get. Come on folks. Help these poor producers out. It's okay. It's a Christmas gift.
[01:57:06.480 --> 01:57:11.760]   We've got systems. You don't have to do our work for us. We work here for a reason. That's cool.
[01:57:12.560 --> 01:57:18.160]   Nest Hub. If you have a Nest Hub smart display, you're going to get an app drawer here pretty
[01:57:18.160 --> 01:57:24.000]   soon. I don't know if this is rolling out immediately or coming soon, but it will give you the ability
[01:57:24.000 --> 01:57:29.760]   to get quick access to some of the favorite functions. I don't have a smart display. I ended
[01:57:29.760 --> 01:57:34.960]   up not bringing a smart display on our home. When they were first launching, I think a couple of
[01:57:34.960 --> 01:57:41.360]   years ago because my kids were young enough to not be able to control themselves if they saw a
[01:57:41.360 --> 01:57:49.440]   vector for YouTube. I'm not opening that door. Now they're a little bit older. Now I think they
[01:57:49.440 --> 01:57:56.560]   can control themselves maybe. I don't have one of these. Does anyone here see all have a smart
[01:57:56.560 --> 01:58:01.920]   display? Do you love it? No. Has anybody got a Doom running on it yet?
[01:58:01.920 --> 01:58:07.120]   That's a good question. I have to imagine Doom runs on everything, doesn't it?
[01:58:08.640 --> 01:58:14.640]   I would think so. I can't go running on the display on their dryer. I think it was.
[01:58:14.640 --> 01:58:24.080]   Wow. Apparently. Hold on. Hold on. I mean, since you asked here, I'll go ahead and put
[01:58:24.080 --> 01:58:30.400]   underneath this story. Jammer B is a YouTube link. If you open this up, you will see from, oh,
[01:58:30.400 --> 01:58:38.080]   so for a while now, this was a video from June 8th, 2019, someone running Doom on their Nest Hub.
[01:58:38.080 --> 01:58:43.760]   I don't know how they get it going, but if you scroll to about, oh, you know what, they browse
[01:58:43.760 --> 01:58:50.640]   through the Internet Archive. So if you go to about, so that's kind of a cheat. That's the browser.
[01:58:50.640 --> 01:58:54.240]   It's not running on it. I mean, like, yeah, it's cheating.
[01:58:54.240 --> 01:59:00.000]   Yeah, that's the cheat. That's through the browser, but still. I suppose it depends on how
[01:59:00.000 --> 01:59:08.000]   you define it. There you go. That's better than nothing. Google is accepting requests
[01:59:08.000 --> 01:59:18.400]   for parents or for people to remove images of minors. So if you have kids under the age of 18
[01:59:18.400 --> 01:59:24.560]   and their images on a Google search result, you can go to a Google support site and request the
[01:59:24.560 --> 01:59:33.680]   removal of that image. Google will do it, apparently. So that is happening. How do you all feel about
[01:59:33.680 --> 01:59:39.280]   because I know this messes with the permanence of the Internet and everything, but I tend to think
[01:59:39.280 --> 01:59:49.680]   this is a good call. Am I missing something? Depends on the parent. I think about my boys,
[01:59:49.680 --> 01:59:54.880]   and I remember years ago when they were in middle school and they were like 12, 13 years old,
[01:59:54.880 --> 02:00:01.120]   and there was this letter that the school sent out that it was a waiver, that you had to sign
[02:00:01.120 --> 02:00:07.280]   that says, "Okay, we can use your child's image in promotion information for the school,
[02:00:07.280 --> 02:00:12.640]   so on and so forth." And I had no problem signing it because they were athletes,
[02:00:12.640 --> 02:00:19.440]   and local newspapers comes to all of those games, and my kids were going to be in the
[02:00:19.440 --> 02:00:24.720]   paper, so I didn't think it was any different. So it's like whatever, just use it. So I think it
[02:00:24.720 --> 02:00:31.120]   depends on the parent. Yeah, on whether you feel comfortable with that being the case or not.
[02:00:31.120 --> 02:00:38.000]   I guess what this reminds me of is the right to be forgotten, kind of ties into that, which
[02:00:38.000 --> 02:00:43.520]   comes up on the show from time to time. And I remember at the time that the right to be forgotten
[02:00:43.520 --> 02:00:50.480]   was such a hot topic, there were a lot of reasons for and against it. I guess when I look at this
[02:00:50.480 --> 02:00:57.920]   as a parent, I appreciate having a tool. If I feel like I need to, it's nice to know that I can.
[02:00:57.920 --> 02:01:05.440]   Yeah, it's what's one matter to have a convicted felon saying, "Take my stuff down so I can be
[02:01:05.440 --> 02:01:12.240]   following this again." It's another matter for parents to say, "I made a mistake putting my
[02:01:12.240 --> 02:01:18.480]   kids picture up or it's been misused and I'm feeling walking about that. It's my kid. I'm more
[02:01:18.480 --> 02:01:25.520]   sympathetic to that." Yeah, I agree. Whereas too, it was also a case where Google was ready to be
[02:01:25.520 --> 02:01:30.960]   forgotten. Google is ruling what maybe remembered or not. Put it in a position that didn't want
[02:01:30.960 --> 02:01:38.400]   by the court case, but it's there. In this case, it's the parent saying, "Can you take this down
[02:01:38.400 --> 02:01:43.840]   here?" Google was saying, "Okay." Google's not really ruling in that case. They're just saying,
[02:01:43.840 --> 02:01:49.760]   "It's a feature you can exercise." Right. Cool. All right. I'm not missing anything.
[02:01:49.760 --> 02:01:58.320]   Good news there. Some changes come into Gmail. And specifically, these changes have to do with
[02:02:00.800 --> 02:02:09.520]   the 2, the CC, the BCC, the blind carbon copy fields. Just some changes. For instance,
[02:02:09.520 --> 02:02:15.440]   right-click menu, you can view a recipient's full name and email. You can edit their name,
[02:02:15.440 --> 02:02:20.240]   their contact name, copy the email address. What's an avatar chip? Do you have any idea what that
[02:02:20.240 --> 02:02:27.280]   means? Have a touch chip. Is that just a small image of that recipient? Is it what the vaccine
[02:02:27.280 --> 02:02:32.560]   puts in your bloodstream? I have no idea. You got it implanted. You got it implanted.
[02:02:32.560 --> 02:02:39.680]   Your avatar appears automatically. I'm guessing reading this that has nothing to do with vaccine,
[02:02:39.680 --> 02:02:48.320]   but that it also has something to do with it. I know I know. An avatar chip, I would guess that
[02:02:48.320 --> 02:02:53.680]   that's like a small, that little picture of you that you normally see when you log into Gmail,
[02:02:53.680 --> 02:03:01.440]   that maybe that's attached to the two fields. When you select this person, if their image is tied
[02:03:01.440 --> 02:03:07.040]   to their account, it will also mess up in your Gmail. It looks like they've got a new message,
[02:03:07.040 --> 02:03:12.800]   and everybody's in there. It shows up in their tab. So you know that you've got the right person.
[02:03:12.800 --> 02:03:19.680]   Right. Recipient avatar. Okay. And now I found a Forbes article that actually shows some examples
[02:03:19.680 --> 02:03:26.680]   of this. The Google write-up didn't show any examples, so I put that for you, J
[02:03:26.680 --> 02:03:30.320]   R.B. There we go. I think I hit my little bit of free Forbes article. No, that's right.
[02:03:30.320 --> 02:03:36.240]   Sorry. I didn't mean to put salt in that wound. Apologies.
[02:03:36.240 --> 02:03:46.400]   Flagging external recipients. So email recipients within a company. Gmail is going to flag anyone
[02:03:46.400 --> 02:03:53.920]   who breaks that pattern with a deep yellow color banner at the bottom to say, hey, or and associated
[02:03:53.920 --> 02:03:58.640]   with that contact in your two field. And I think that's just a visual representation for you to
[02:03:58.640 --> 02:04:02.000]   know like, Oh, hey, wait a minute. The information in this email might be going outside of our
[02:04:02.000 --> 02:04:09.920]   organization. Is that okay? Little changes like that. Yeah, it all has to do with your two fields.
[02:04:09.920 --> 02:04:16.720]   So you can check that out. Look that up and see how your Gmail experience is going to be changing
[02:04:16.720 --> 02:04:25.120]   very soon. And then finally, the call screen feature that we hear in the US, and I'm assuming
[02:04:25.120 --> 02:04:30.880]   Canada, I actually don't know for sure if Canada has the pixel call screening feature to date,
[02:04:30.880 --> 02:04:36.000]   but definitely here in the US, that's broadening out to seven additional countries.
[02:04:37.920 --> 02:04:43.120]   Let's see here. So we're going to have it in UK, France, Germany, Australia, Ireland, Italy, and
[02:04:43.120 --> 02:04:48.960]   Spain. And that's, yeah, that's a, that's a cool feature. It's a, it's a cool feature that I don't
[02:04:48.960 --> 02:04:54.240]   really use a whole lot. I end up when a, when a phone call comes through on my, on my phone,
[02:04:54.240 --> 02:04:59.760]   and I don't recognize the number, I'm just, I'm just equipped to like, you know what, if it's really
[02:04:59.760 --> 02:05:04.720]   important, you're going to leave me a message and, or you're going to send me a text message.
[02:05:04.720 --> 02:05:09.360]   Like doing the call screen is even more work that I want to do with that, that random call.
[02:05:09.360 --> 02:05:14.640]   If it doesn't, my rule is if there's no name, if my phone doesn't know who it is,
[02:05:14.640 --> 02:05:21.920]   I just won't answer it. I don't, it doesn't matter who it is. Yeah. Dead to me, whoever you are.
[02:05:21.920 --> 02:05:30.240]   Samsung has the same thing. It will show you if a number is suspected spam or suspected fraud,
[02:05:30.240 --> 02:05:39.520]   and you can confirm if it is or not. Right, right. All right. And I think that is the Google change
[02:05:39.520 --> 02:05:48.080]   law. We are going to do a picks, tips, tricks, whatever you got here after a quick break. We'll
[02:05:48.080 --> 02:05:53.040]   thank the sponsor and then we'll get to that. So get those ready. This episode of This Week in
[02:05:53.040 --> 02:05:59.680]   Google is brought to you by Code Academy. There has never been a better time to become a programmer
[02:05:59.680 --> 02:06:05.120]   and so many people. I mean, you know, we've had so much time to ourselves and had the opportunity
[02:06:05.120 --> 02:06:10.080]   to really reflect and be like, you know, what do I want to learn? Who do I want to be? So many
[02:06:10.080 --> 02:06:14.960]   people are in a position to reinvent themselves right now. And with Code Academy, you can learn
[02:06:14.960 --> 02:06:20.320]   to code on your own terms, whether you're starting from scratch, or maybe you're looking to advance
[02:06:20.320 --> 02:06:26.960]   where you're already at Code Academy can help you reach your coding goal. Simply put,
[02:06:26.960 --> 02:06:33.040]   Code Academy is the best way to learn to code online. They're not only going to teach you
[02:06:33.040 --> 02:06:39.440]   job ready coding skills, but they're also going to help you build unique projects for your portfolio.
[02:06:39.440 --> 02:06:48.000]   Also earn certificates, even prep for technical interviews. And I mean, you know, it's worth just
[02:06:48.000 --> 02:06:55.840]   looking at because it's interesting to think like, I'm not I'm not a coder myself. But sometimes I
[02:06:55.840 --> 02:07:03.440]   really wish I knew that because it is it is a world of creation, a world of creativity that if you
[02:07:03.440 --> 02:07:08.640]   have that skill, if you know how to build that thing or code that thing, you know, I hear sometimes
[02:07:08.640 --> 02:07:12.320]   Leo talk about the things that he's working on and some of the guests that we have on the network,
[02:07:12.320 --> 02:07:18.240]   I'm like, man, that is a skill I wish I had because sometimes I do encounter that thing that I that
[02:07:18.240 --> 02:07:23.520]   the solution doesn't exist. And if I only knew how to pull this off, I can make it happen. Well,
[02:07:23.520 --> 02:07:29.680]   Code Academy could be the window into making that happen with Code Academy. You get qualified
[02:07:29.680 --> 02:07:35.280]   for in demand jobs in as little as two months, you can learn at your own pace, your own level. So
[02:07:35.280 --> 02:07:40.800]   really doesn't matter what what level you're coming in at. You can choose what you learn from
[02:07:40.800 --> 02:07:47.360]   building websites to analyzing data and everything else you could possibly want wrapped up inside
[02:07:47.360 --> 02:07:51.840]   there. No matter what your experience level, you're going to be writing real working code.
[02:07:52.720 --> 02:07:55.920]   And it's not going to take very long, you're going to be doing it in a matter of minutes,
[02:07:55.920 --> 02:08:05.520]   languages like Python, HTML, CSS, SQL, JavaScript, and so much more. Code Academy is going to point
[02:08:05.520 --> 02:08:10.240]   you in the right direction too. If you have no idea where you want to begin, you're going to get
[02:08:10.240 --> 02:08:15.760]   that information with Code Academy. Get instant feedback. Your code is actually tested as soon
[02:08:15.760 --> 02:08:21.680]   as you submit it. So you're going to know right away, if you're on the right track, you get tools,
[02:08:21.680 --> 02:08:28.480]   cheat sheets to help those ideas really stick and to see them to fruition and test your knowledge
[02:08:28.480 --> 02:08:34.240]   with tailor made quizzes just for you. They have an interactive platform that really helps you
[02:08:34.240 --> 02:08:41.200]   to learn in the process by doing you're not just passively watching, you're engaged, you're doing,
[02:08:41.200 --> 02:08:46.720]   you're putting through this code in real time actively and you get help from other learners as
[02:08:46.720 --> 02:08:52.640]   well in their forum, or you can connect with people near you in your local Code Academy chapter and
[02:08:52.640 --> 02:08:59.440]   be part of Code Academy's community of more than 50 million people. So you can build your portfolio
[02:08:59.440 --> 02:09:04.080]   and get a certificate of completion. That's going to make yourself even more marketable for future
[02:09:04.080 --> 02:09:09.600]   employers. And then hopefully you land your dream job, wherever it happens to be web development,
[02:09:09.600 --> 02:09:15.760]   programming, computer science, data science, and so much more. Join the millions of people
[02:09:15.760 --> 02:09:22.560]   learning to code with Code Academy and see where coding can take you. Get 15% off your Code Academy
[02:09:22.560 --> 02:09:29.600]   Pro membership when you go to code Academy.com and make sure and use that promo code Twig.
[02:09:29.600 --> 02:09:36.160]   That's promo code Twig for this week in Google TWIG at code Academy.com. You do that, you'll get
[02:09:36.160 --> 02:09:44.480]   15% off Code Academy Pro, the best way to learn. I'll spell it out for you. C-O-D-E-C-A-D-E-M-Y
[02:09:44.480 --> 02:09:51.440]   code Academy.com, promo code Twig. And we thank them for their support of this show and for teaching
[02:09:51.440 --> 02:09:59.680]   so many people how to code. Pretty awesome stuff. All right, this is tips, tricks, picks, all that
[02:09:59.680 --> 02:10:04.320]   fun stuff that we do at the end of the show. Jeff, why don't we start with you? What you got?
[02:10:04.320 --> 02:10:13.200]   All right, I'll do this one. Evelyn Dweck, who's a brilliant law scholar, a young scholar at Harvard,
[02:10:13.840 --> 02:10:19.760]   gave a talk at Stanford Cyber Center. And she started off with a slide where she said,
[02:10:19.760 --> 02:10:28.000]   "During the one hour of my talk today, these things will occur. Facebook will take down 615,417
[02:10:28.000 --> 02:10:34.400]   pieces of content. YouTube will take down 271, 440,000 channels, videos, and comments.
[02:10:34.400 --> 02:10:42.720]   TikTok will take down 18,870 videos. The Facebook oversight board will receive 48 petitions to appeal.
[02:10:42.720 --> 02:10:47.360]   This does not include the number of decisions to leave up content or appeals or other content
[02:10:47.360 --> 02:10:53.680]   moderation decisions. And then as Daphne Keller, who tweeted this, said, "Meanwhile, the Supreme
[02:10:53.680 --> 02:11:00.000]   Court has decided about 246 First Amendment cases ever. All of this is to say, as our friend
[02:11:00.000 --> 02:11:05.440]   Mike Masnick often points out, deciding that you should be able to moderate content, that is to
[02:11:05.440 --> 02:11:11.440]   say, moderate the conversation of the world at scale is hard." That's all.
[02:11:11.440 --> 02:11:18.880]   Indeed. Now, moderation's easy. You just say, "I like it or I don't." You move on.
[02:11:18.880 --> 02:11:24.400]   Just take the junk gun. Come on. Yeah. Yeah. Just remove all the disinformation.
[02:11:24.400 --> 02:11:30.320]   Yeah, that's all you got to do. Yeah. Then everything will be okay. Then we won't be racist,
[02:11:30.320 --> 02:11:35.600]   misogynist, hateful pigs anymore. It won't be fun. Right.
[02:11:35.600 --> 02:11:42.320]   I just want to call out also, you had another one in here that was near and dear to my heart.
[02:11:42.320 --> 02:11:49.840]   20th, is it an anniversary or a birthday of the iPod? 20 years ago, the iPod began.
[02:11:49.840 --> 02:11:55.920]   And started to change every-- It was really an important thing. I mean, changed for a whole
[02:11:55.920 --> 02:12:02.720]   view of what you could hold in your hand. Absolutely it did. I love the wheel. I remember seeing--
[02:12:02.720 --> 02:12:09.360]   Oh, I love the wheel. I remember a co-worker, or maybe it was one of my superiors at one of
[02:12:09.360 --> 02:12:14.720]   my former jobs. They were looking at a magazine and it had a picture of a hard drive that was the
[02:12:14.720 --> 02:12:24.640]   size of a quarter. It just blew my mind to see, "Wow, storage is that small. This is 20 years ago," or
[02:12:24.640 --> 02:12:29.440]   whatever. Thinking storage is that small. And then next thing you know, stuff like this
[02:12:29.440 --> 02:12:35.680]   iPod is out. And it's using tiny, tiny storage like that. Did you see the--
[02:12:35.680 --> 02:12:42.160]   Yeah. Scooter expert in the chap. But there was an image of the original prototype.
[02:12:42.160 --> 02:12:51.680]   And it's the size of a 12-inch tablet. It's quite hilarious to look at it. Oh, wow. Okay.
[02:12:52.720 --> 02:12:59.920]   Oh, no way. Oh, yeah. It's trying. They've got a real iPod next to it for comparison.
[02:12:59.920 --> 02:13:11.680]   Wow. I put it in line 168 at the far, far right. I put a link to that. Yeah. And I just heard
[02:13:11.680 --> 02:13:18.160]   Jamerby jump in there real quick and mentioned it. So the first iPad was 20 Megs. That's how much
[02:13:18.160 --> 02:13:25.840]   storage was on that first iPad. Is that right? iPod. Sorry, not iPad. iPod. Is that what you said?
[02:13:25.840 --> 02:13:34.640]   I thought I heard you say that. Oh, Jamerby. Oh, the size of the quarter. Okay. Okay. The hard drive.
[02:13:34.640 --> 02:13:40.400]   Yeah. I was just saying it's just like tiny size. It was, you know, they're this small. Storage is
[02:13:40.400 --> 02:13:46.160]   this small when storage used to be-- That was the big size. Okay. Storage used to be like that.
[02:13:46.160 --> 02:13:53.280]   Well, this is a hard drive I destroyed. But what was the name of the Microsoft version?
[02:13:53.280 --> 02:14:00.480]   Zoom. Yeah. Zoom. Yeah. The Zoom plays. It's South by Southwest. And I remember Kevin Rose
[02:14:00.480 --> 02:14:07.360]   was on the stage of the party. And and zoom was a sponsor of their show. And he was trying to
[02:14:07.360 --> 02:14:12.080]   give away zoons. The audience practically hooted at it like, who would that? Who wants that?
[02:14:13.360 --> 02:14:18.800]   Dignation, right? Wasn't that a show? Dignation. Yeah. Yeah. Dignation. That's right. Yeah.
[02:14:18.800 --> 02:14:21.920]   There's another number I just might mention real quick if I may. Yeah. Yeah. That's a
[02:14:21.920 --> 02:14:28.560]   right. Is Stripe our sponsor? Yes. Yes. Okay. So Stripe a Stripe a sponsor. You're a right
[02:14:28.560 --> 02:14:33.040]   sponsor. I need to be going to say that. So they put out a little report about the
[02:14:33.040 --> 02:14:39.120]   the the the the creator economy, which we'd love to talk about, which either gives me hope or says
[02:14:39.120 --> 02:14:45.040]   we are into huge overdose fast. But across 50 platforms that Stripe serves,
[02:14:45.040 --> 02:14:52.960]   the creators will will get $10 billion in aggregate earnings 2020 saw a jump in new creators.
[02:14:52.960 --> 02:14:58.560]   And it wasn't a one time spike. They're still coming on a record clip, a whopping 48% year
[02:14:58.560 --> 02:15:06.720]   over year. In total, these platforms have on on board to 668,000 creators. See earlier discussion
[02:15:06.720 --> 02:15:12.320]   about some folks saying there's too much speech. Does that does that include only fans?
[02:15:12.320 --> 02:15:21.520]   Yeah. Yeah. The stripes are a little bit of a no. So it's just, you know, as whole bloggers,
[02:15:21.520 --> 02:15:28.320]   I think see some value in that, but but will there be too many email newsletters? Yeah.
[02:15:30.160 --> 02:15:37.920]   Will all of them make money and make a living? Sorry. No, no, sadly, not everyone. Not not being a
[02:15:37.920 --> 02:15:48.080]   creator. Yeah. Crazy. Let's see here. And what you got? Well, I got to a couple of things. But
[02:15:48.080 --> 02:15:54.320]   first I did get the delivery of my Pixel 6 Pro. Look at you.
[02:15:55.520 --> 02:15:59.200]   I will do the honor of taking the paper off the screen.
[02:15:59.200 --> 02:16:06.560]   Worshidey. They all round the edge. I will be playing with that in a little while, but it is
[02:16:06.560 --> 02:16:13.680]   definitely rounded. This feels like one of those iPhones. One of the ones that I've heard on the
[02:16:13.680 --> 02:16:19.840]   edge. Yeah, I'm still a flat edge phone, you know, but that is definitely round. I'm glad I got
[02:16:19.840 --> 02:16:25.200]   the screen that's rounded, which threw me. And that's going to, yeah, that's that slip
[02:16:25.200 --> 02:16:30.640]   inducing there. So I'm glad I have a case for it. Yeah. Yeah. Well, one thing you might notice is
[02:16:30.640 --> 02:16:38.160]   that the camera bump on the back makes a nice little ridge for your finger. So it is slippery,
[02:16:38.160 --> 02:16:41.280]   but at least you have a little ridge to kind of like throw your finger. What about when you put
[02:16:41.280 --> 02:16:46.960]   the case in? Does the case eliminate the ridge? Because it does. I'm curious to see that. I hope
[02:16:46.960 --> 02:16:52.320]   it does. I have a speaking case. I'm not sure if it will. It's over there in another corner.
[02:16:52.320 --> 02:16:58.400]   I'll get to it at some point. But yeah, I kind of get the phone. I kind of resent paying all this
[02:16:58.400 --> 02:17:05.600]   money for a shiny phone, which is so shiny that I have to put a case. I know. I know. I feel the
[02:17:05.600 --> 02:17:14.640]   same way. I got a clear case. My case is clear, so I'm good. Just get $900 phone and put a $699 case
[02:17:14.640 --> 02:17:21.600]   on it. Yeah. Yeah. Hey, I mean, yeah, that is the best thing though, is the clear case, then at least
[02:17:21.600 --> 02:17:26.480]   you get a little bit of that phone style shining through. But you know, if I don't have that case
[02:17:26.480 --> 02:17:30.640]   on there, I'm just going to drop it. That's just the way it is. I make it slippery. So don't make
[02:17:30.640 --> 02:17:37.040]   it slippery. You know? Yeah. Yeah. I'll tell that. There's something. Yeah. See how that goes.
[02:17:37.760 --> 02:17:46.400]   Yeah. Yeah. Congrats. You got your mic. Thank you, sir. My pick is I've been watching television.
[02:17:46.400 --> 02:17:51.840]   So I finally I'm trying to play catch up on all the popular shows out there. And I finally got
[02:17:51.840 --> 02:17:59.600]   through sex education. And now I'm checking out the Wonder Years, the reboot. I believe it's on Hulu.
[02:17:59.600 --> 02:18:05.600]   And I remember watching the Wonder Years umpteen years ago with Fred Savage. He is now directing
[02:18:05.600 --> 02:18:12.560]   this show. But it gives you the version of it from a black family's perspective. And what I'm
[02:18:12.560 --> 02:18:18.720]   enjoying about it is number one, the narration is Don Cheeto. But the stories are really, really
[02:18:18.720 --> 02:18:24.720]   captivating and they're funny. And yes, it took time took place back in the 60s with all of the
[02:18:24.720 --> 02:18:31.680]   civil unrest going on here in the US. But it's not a heavy handed dose of this is racism happening
[02:18:31.680 --> 02:18:37.120]   right here. It's still pretty entertainment because quite frankly, I'm sick of being reminded of racism.
[02:18:37.120 --> 02:18:44.400]   I live it. I know it's there. Sometimes I just want to watch TV. But they do do a really good job of
[02:18:44.400 --> 02:18:48.960]   balancing that out. Not necessarily just throwing it out the window. Let me know it is there. But
[02:18:48.960 --> 02:18:54.080]   they do tell a good story. And it's pretty entertaining. I think it's on Hulu. But that's the Wonder
[02:18:54.080 --> 02:19:00.800]   Years rebooted. And apparently, Mr. Jarvis did a review of the original Wonder Years at some point.
[02:19:00.800 --> 02:19:10.320]   Is that correct? Love it. Love it. Yeah, a plus. A plus. I used to love that show. Man, I love that
[02:19:10.320 --> 02:19:15.600]   show back when was my generation. I mean, that was my eight. That was a great show. Great show.
[02:19:15.600 --> 02:19:25.120]   Right. And then my next pick is is a shout out and denied to the hardhead who battled through a
[02:19:25.120 --> 02:19:32.720]   groin injury. Who's he still suffering from a groin injury and had a kick return in the game
[02:19:32.720 --> 02:19:40.560]   last week. So two of the last three touchdown kick returns have been by Pruitt boys of the
[02:19:40.560 --> 02:19:51.200]   Wow. Wow. And I was so impressed and proud of him because I know he was hurting, but he still
[02:19:51.200 --> 02:19:57.120]   could outrun these cats. So it just it just made old that proud. And some of the games are
[02:19:57.120 --> 02:20:02.960]   live streamed. Some of them are. And so his older brother, who is now up in Oregon and in college,
[02:20:02.960 --> 02:20:08.080]   not at OU, but he's at a college in Oregon. He says, Oh, that was great. But he didn't get my
[02:20:08.080 --> 02:20:16.400]   record. That's the first thing. So his brother has the record of 95 yards on the kick return for a
[02:20:16.400 --> 02:20:25.120]   touchdown. Now hardhead sophomore, Jacob, he his was I think it was 92 yards. So it's close. But
[02:20:25.120 --> 02:20:28.640]   never keep trying. Yeah, no, keep trying.
[02:20:28.640 --> 02:20:37.840]   For 96. Go for 96. Yeah, 96 would be the one. And lastly, I want to plug Mr. Rick Salmon has a
[02:20:37.840 --> 02:20:44.400]   book out. I've had Mr. Rick Salmon on our show hands off photography. He's such an amazing human
[02:20:44.400 --> 02:20:51.520]   being in addition to being an amazing photographer. He's a cannon explorer of light. He's a prolific
[02:20:51.520 --> 02:20:59.520]   offer author. I believe he's gotten about 40 books written to date regarding photography and just
[02:20:59.520 --> 02:21:06.400]   mindfulness and things of that nature. And this latest book is about passive income as a
[02:21:06.400 --> 02:21:13.200]   photographer, how to make money in your sleep as a photographer. And I got a couple pages in it.
[02:21:13.200 --> 02:21:19.200]   So I wanted to plug that and show him some love and just to say thank you to Mr. Salmon for reaching
[02:21:19.200 --> 02:21:25.280]   out to me and allowing me the opportunity to share some of my information about passive income.
[02:21:25.280 --> 02:21:31.680]   Because this pandemic has taught a lot of us about survival. And you know, there are some things
[02:21:31.680 --> 02:21:36.960]   that you can do to help keep the bills paid. And passive income is one of those ways. You know,
[02:21:36.960 --> 02:21:42.640]   you go to bed and you're still making money, you know, if you can figure it out. So that's
[02:21:42.640 --> 02:21:49.520]   on Amazon and Mr. Howl will have links in our show notes. Yes, indeed. Nice. That is awesome.
[02:21:49.520 --> 02:21:59.440]   Let's see here. Matthew, what you got? So my thing is it's called the Jetson One.
[02:21:59.440 --> 02:22:06.480]   I think it just came out earlier this week. And the great brand. So the headline says it all
[02:22:07.520 --> 02:22:13.520]   for the price of a Tesla model as you can buy a flying car. It's not actually a car. I don't
[02:22:13.520 --> 02:22:19.680]   know why they said that. It doesn't have wheels, but it's defined as an ultra light. So you don't
[02:22:19.680 --> 02:22:25.760]   need a license. And I think it goes up to like 60 miles an hour. I'm trying to remember the
[02:22:25.760 --> 02:22:33.760]   but the video is extremely cool. Yeah, this thing is awesome. And it has a parachute. It's amazing.
[02:22:35.120 --> 02:22:39.680]   And it has a parachute crucial. I think it goes up to like 4,000 feet.
[02:22:39.680 --> 02:22:47.520]   That is 4,000. What? Crazy looking. Yeah. Isn't that amazing?
[02:22:47.520 --> 02:22:57.040]   Can you imagine that's. Oh, that looks so fun. Get your orders in now. Do you hear a buzz over
[02:22:57.040 --> 02:23:03.760]   Petaluma? It's going to be ant. Oh, yeah. Just don't give one to Mr. LaPorte is he'll find a
[02:23:03.760 --> 02:23:08.960]   way to crash that too. I'm sure that's true. That's a good point. Yeah. The cargo is a lot.
[02:23:08.960 --> 02:23:16.000]   And it only weighs about 90 pounds. The thing.
[02:23:16.000 --> 02:23:21.360]   Yeah. You went it up. How far do you go with the battery? That's what I didn't see.
[02:23:21.360 --> 02:23:27.920]   Yeah. So it says that it's good for 20 minutes of hovering. So I don't know how long it is.
[02:23:27.920 --> 02:23:31.120]   That ain't good. Probably not. That's a pretty short trip. That ain't.
[02:23:31.120 --> 02:23:34.560]   That'll improve. That'll improve. Yeah. It's pretty cool.
[02:23:34.560 --> 02:23:37.760]   So I've got one on delivery. Should be here.
[02:23:37.760 --> 02:23:44.960]   You'll make your way to the Bay Area 20 minutes at a time.
[02:23:44.960 --> 02:23:51.520]   Have to stop every 20 minutes and charge it. We'll see you soon. We'll see you next year.
[02:23:51.520 --> 02:23:57.360]   Oh, that is so cool. I saw a video that a couple of days ago. I was like, I want that.
[02:23:57.360 --> 02:24:02.640]   That looks like the future right there. Everybody blasting around those things. Pretty awesome stuff.
[02:24:02.640 --> 02:24:10.000]   Mine. Let's see here. So I have two things. First of all, this was a story that we talked about a
[02:24:10.000 --> 02:24:15.440]   little bit on all about Android last night. But sometimes I like to bring a tip to the show.
[02:24:15.440 --> 02:24:20.320]   And I guess I can probably show this. I don't think I'm revealing anything by showing this.
[02:24:20.320 --> 02:24:27.440]   So on Android 12, one of the changes that happened is you will notice in the quick settings that
[02:24:27.440 --> 02:24:35.600]   you used to have a Wi-Fi and a mobile internet button in your quick settings. That would allow you
[02:24:35.600 --> 02:24:43.440]   to, and I did this a lot, there would be times where I wanted to force my mobile internet.
[02:24:43.440 --> 02:24:48.080]   And my Wi-Fi was on. And the only way I could think to do that was to turn off
[02:24:48.080 --> 02:24:54.640]   Wi-Fi and then it would toggle over to my mobile internet. And the connection quality would clear
[02:24:54.640 --> 02:24:59.680]   up. Or whatever the problem was I was trying to solve. And Google made this change, which is,
[02:24:59.680 --> 02:25:04.640]   a lot of people who have gotten Android 12 have said, well, this is no good. Because now if I want
[02:25:04.640 --> 02:25:09.840]   to make any changes, I have to tap there. Then that brings up my internet box. And then I have
[02:25:09.840 --> 02:25:16.560]   to deactivate my Wi-Fi from here. And why should I do that? And it turns out that Google didn't
[02:25:16.560 --> 02:25:21.840]   really communicate very well exactly what's going on here. What they did is, and I don't know that
[02:25:21.840 --> 02:25:27.040]   this necessarily makes it easier, but what they're trying to do is they noticed in their studies
[02:25:27.040 --> 02:25:30.960]   that people would turn off Wi-Fi and then they forget that they turned it off. And so it would
[02:25:30.960 --> 02:25:35.280]   stay off and then they're turning through their mobile data over time. Like, well, how can we
[02:25:35.280 --> 02:25:41.200]   prevent that from happening? Or at least give users a tool that allows them to not have that
[02:25:41.200 --> 02:25:47.520]   happen. And so with this, it's totally not intuitive at all how they intended for this to be used.
[02:25:47.520 --> 02:25:52.240]   So I'm really surprised that they don't signal this better. But essentially what they've done is,
[02:25:52.240 --> 02:25:58.880]   if you tap on your mobile internet, it says, Wi-Fi won't auto connect for now. It temporarily,
[02:25:58.880 --> 02:26:05.280]   oh, but did you see it? Just totally did. It did. It just totally did. That's a Google moment right
[02:26:05.280 --> 02:26:09.040]   there. I suppose to be able to do that to turn that off temporarily and then it would turn it and
[02:26:09.040 --> 02:26:15.280]   then it would reconnect later. But that's so funny. It's like, oh, what am I going to do without Wi-Fi?
[02:26:15.280 --> 02:26:20.960]   Anyways, that's supposed to be the feature. But as you saw, it really wanted to connect to
[02:26:20.960 --> 02:26:26.400]   Wi-Fi. So maybe it's not a tip. Maybe it's a maybe it's pointing out for you. Yeah.
[02:26:26.400 --> 02:26:30.880]   You found the bug Google. Thanks a lot. That could be a bug more than anything. But anyway,
[02:26:30.880 --> 02:26:35.840]   Justin Barris, the God of Android here, Google, not cool. Not cool.
[02:26:38.320 --> 02:26:43.040]   It's all good. This is how it works. When you do demos, nine times out of 10, they're going to
[02:26:43.040 --> 02:26:51.840]   fail. Let's just say it again. Yes. You're lucky if it doesn't fail. And then my other thing is just
[02:26:51.840 --> 02:26:56.320]   a mention of something that I decided a couple of days ago. I've actually considered participating
[02:26:56.320 --> 02:27:01.680]   in Movember for years, but I've never done it. This year I decided I'm going to do it
[02:27:02.320 --> 02:27:08.720]   for two reasons. One, just to shine a light on men's health and mental health, especially.
[02:27:08.720 --> 02:27:14.400]   I've done a lot of work on my own personal growth and mental health over the last three years.
[02:27:14.400 --> 02:27:20.480]   And I feel like a better, better, more alive person because of it. And so it's an important
[02:27:20.480 --> 02:27:28.320]   thing to shine a light on. Everybody can actually find help for themselves and reach a better place.
[02:27:28.320 --> 02:27:35.520]   So that's part of it. But it's also because in my entire life, I have never grown out my facial hair
[02:27:35.520 --> 02:27:42.640]   more than maybe I'd say like a week. And even at a week, I hardly have anything. That's why I've
[02:27:42.640 --> 02:27:47.840]   never grown it out because I've been like, well, what's the point? I don't grow facial hair like
[02:27:47.840 --> 02:27:52.080]   everybody else does. So I'm curious to see what's going to happen. So I've already started,
[02:27:52.080 --> 02:27:57.520]   even though it starts in November, I started a couple of days ago. And I apologize in advance
[02:27:57.520 --> 02:28:03.600]   because it could look really weird and gross and strange. But it's a journey. And I hope that you'll
[02:28:03.600 --> 02:28:10.240]   forgive me for taking this journey over the course of the next month. And as a prostate cancer
[02:28:10.240 --> 02:28:17.280]   veteran, I thank you, sir. Yeah, absolutely. I'm so thrilled about the number causes and gentlemen.
[02:28:17.280 --> 02:28:24.800]   We just lost an important actor last week of 59 years old prostate cancer. Get tested.
[02:28:24.800 --> 02:28:32.320]   Yeah. And I want you to grow a big like twirly, like snidely wet flash kind of
[02:28:32.320 --> 02:28:39.520]   I'm not sure my wife wants that, but we'll see. We'll see how it goes. I'm honey. It's totally
[02:28:39.520 --> 02:28:44.720]   November. That's true. That's the thing. Like she totally supports it. Like she's like, oh,
[02:28:44.720 --> 02:28:48.640]   it's it's it's for a cause. Okay. I'm like, you don't know what you're getting yourself into. This
[02:28:48.640 --> 02:28:53.760]   could be the gross mustache you've ever seen. Like, I could look really bad with a mustache, but
[02:28:53.760 --> 02:28:58.800]   I'm willing to try and see what happens. So I'm really kind of scared. I did it. I've done
[02:28:58.800 --> 02:29:06.880]   November twice. Yeah. The last time I did it, I'd let it grow out, but I ended up cutting it to
[02:29:06.880 --> 02:29:13.200]   where it looked like I had some kind of weird design on my face. But I stopped doing it because
[02:29:13.200 --> 02:29:17.920]   it wasn't raising enough money in my opinion to help out with the cause. And I'm walking out looking
[02:29:17.920 --> 02:29:25.280]   pretty stupid. But who knows? Who knows the you? Mr. I hope you can continue to raise awareness
[02:29:25.280 --> 02:29:30.560]   and raise a lot of cash for this reason. I mean, I'm confident with the with the platform that we
[02:29:30.560 --> 02:29:34.960]   have through Twitter and everything that we can we can raise some money for for all the causes
[02:29:34.960 --> 02:29:42.560]   that November raises for. So, uh, where's Casey use? Where's Casey look like a cop from like a 70s
[02:29:42.560 --> 02:29:53.280]   body movie. Like Tom Lennon from, um, you know, 911. Oh man. I, you know, I can only hope that I look
[02:29:53.280 --> 02:29:58.880]   like any sort of normal once I once I have this, this mustache or whatever it is. There he goes,
[02:29:58.880 --> 02:30:06.720]   or whatever. There we go. There we go. Yeah. Yeah. Uh, yeah. Grow up my Salvador Dali stash. Yeah.
[02:30:09.200 --> 02:30:13.600]   So we'll see how that goes. Anyways, we reached the end of this episode of this week in Google,
[02:30:13.600 --> 02:30:18.560]   always a lot of fun. And I'm happy to say that I'm going to be here next week as well. Leo returns
[02:30:18.560 --> 02:30:22.960]   from Mexico next Wednesday. So I'm looking forward to that. You're not getting rid of me yet. Uh,
[02:30:22.960 --> 02:30:28.080]   but it's always a pleasure to hop on the show with you all. And thank you for always being so
[02:30:28.080 --> 02:30:33.520]   open and welcoming me to the show when I am. Uh, Jeff, uh, what do you want people to know? Buzz
[02:30:33.520 --> 02:30:42.640]   machine.com, anything else? Uh, no, no, no, no, no, just here. One quick. There's Jeff just there.
[02:30:42.640 --> 02:30:47.920]   And Buzz machine.com. Always great to hang out with you, Jeff. And then Ant, uh, hands-on
[02:30:47.920 --> 02:30:51.600]   photography, twit.tv/hop. Have you got anything else in the cook or you want to talk about?
[02:30:51.600 --> 02:30:57.840]   Well, yeah, again, make sure you're checking out hop because there's a lot of good information
[02:30:57.840 --> 02:31:07.520]   coming up this week. Uh, I'm not gonna. People have been asking about NFTs. I'm not going to talk
[02:31:07.520 --> 02:31:12.160]   about NFTs this week, but it's right now with the stuff that's going on with crypto. Yeah.
[02:31:12.160 --> 02:31:17.440]   NFT topic has been pretty hot, but yeah, just stay tuned. I'm not talking about NFTs this week,
[02:31:17.440 --> 02:31:22.640]   maybe next week, but yeah, just stay tuned. It's it's hop has been a lot of fun creating this
[02:31:22.640 --> 02:31:27.280]   content and being able to talk with different photographers. But this week, it's going to be a
[02:31:27.280 --> 02:31:33.040]   lot of fun with Jefferson Graham. You may have heard of him. He's a travel photographer, so we'll
[02:31:33.040 --> 02:31:39.920]   sit down and have a chit chat. And I found that picture by the way for November. Oh, did you?
[02:31:39.920 --> 02:31:49.360]   Oh, wow. Look at that. Nice. So that we fork off. Is it like a fishtail?
[02:31:51.120 --> 02:31:58.240]   It's so good. That is pretty bizarre. Oh gosh. I won't do that anymore. I promise. I love that.
[02:31:58.240 --> 02:32:05.440]   I love it. No, do it again. I think it's great. All for a good cause. That's right. That's right.
[02:32:05.440 --> 02:32:10.640]   Thank you, and Matthew, always a pleasure to get in the chance to do a podcast with you, sir.
[02:32:10.640 --> 02:32:16.560]   Really appreciate it. Columbia journalism reviews. Anything you want to point people to on your way
[02:32:16.560 --> 02:32:24.720]   out? No, really. No, just glad to be on the love of being on the show. I'm sorry that he usually
[02:32:24.720 --> 02:32:29.280]   involves Stacy not being here because I'd love to be on with her too. And I hope she feels better.
[02:32:29.280 --> 02:32:37.760]   Yeah. Yeah, me too. Thank you. Yeah, Stacy. Hopefully, Stacy will be back next week.
[02:32:37.760 --> 02:32:41.280]   She had a little bit of a migraine. And so it's just like, you know, don't worry about it.
[02:32:41.280 --> 02:32:47.520]   Like, when that happens, just, yeah, that's this. It's painful. It's no good. And it's not not necessary
[02:32:47.520 --> 02:32:52.960]   to have to like struggle to go through that. So I'm happy that she took the day off. We'll hopefully
[02:32:52.960 --> 02:33:01.040]   see her next Wednesday. This week in Google, we do the show every Wednesday, twit.tv/twig
[02:33:01.040 --> 02:33:06.320]   is the place to go. If you want to subscribe to the show, if you haven't already subscribed,
[02:33:06.320 --> 02:33:12.240]   that's where you can find all the information that you need. Audio, video, podcatchers, YouTube,
[02:33:12.240 --> 02:33:17.280]   it's all there. That's the place to go. And of course, we do record, like I said, every Wednesday,
[02:33:17.280 --> 02:33:25.600]   2 p.m. Pacific, 5 p.m. Eastern. So, you know, you can go to twit.tv/live, hang out with us there.
[02:33:25.600 --> 02:33:32.800]   We do have ClubTwit, real quick, twit.tv/clubtwit, ad-free versions of all of our shows, plus the
[02:33:32.800 --> 02:33:40.400]   Discord and the Twit Plus extra podcast feed. Lots of cool stuff there. So if you're not a member,
[02:33:40.400 --> 02:33:45.920]   go check that out, twit.tv/clubtwit. But that's it. We've reached the end of this episode.
[02:33:45.920 --> 02:33:50.240]   We'll see you next time on this week in Google. Thank you so much for watching and listening.
[02:33:50.240 --> 02:33:56.240]   Bye, everybody. If you find yourself talking to those virtual assistants in your house quite often,
[02:33:56.240 --> 02:34:00.080]   or maybe you can make your light turn on and off with the touch of a button, well,
[02:34:00.080 --> 02:34:05.360]   Smart Tech Today is the show for you. Join Matthew Casanelli and myself, Micah Sargent,
[02:34:05.360 --> 02:34:16.000]   every week as we talk all about smart stuff and the fun that comes along with it.
[02:34:16.000 --> 02:34:22.080]   [Music]

