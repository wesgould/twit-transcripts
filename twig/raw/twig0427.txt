;FFMETADATA1
title=Wig Radar
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=427
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:03.740]   Time for Twig this week at Google Stacey Higginbotham is here so as Jeff Jarvis
[00:00:03.740 --> 00:00:07.940]   We'll talk about the secret chip hidden in the new Pixel 2 phone
[00:00:07.940 --> 00:00:14.380]   Google's AI writing its own code and teaching itself to play go and the train in Sweden
[00:00:14.380 --> 00:00:17.700]   Name Trainee McTrainface. It's all next
[00:00:17.700 --> 00:00:23.980]   Netcast you love from people you trust
[00:00:27.780 --> 00:00:34.000]   This is Twig bandwidth for this week in Google is provided by cash fly
[00:00:34.000 --> 00:00:36.980]   C A C H E F L Y
[00:00:36.980 --> 00:00:38.980]   Dotcom
[00:00:38.980 --> 00:00:43.940]   This is Twig this week in Google episode
[00:00:43.940 --> 00:00:50.080]   427 recorded Wednesday October 18th 2017 wig radar
[00:00:50.080 --> 00:00:57.420]   This week at Google is brought to you by Lighthouse Lighthouse is the only security camera powered by the same
[00:00:57.420 --> 00:00:59.420]   Technology that's in self-driving cars
[00:00:59.420 --> 00:01:07.740]   Visit light.house/twit to sign up for 15% off Lighthouse when they ship and a chance to win a free Lighthouse plus a year of service
[00:01:07.740 --> 00:01:12.420]   C site for contest rules and by video blocks by story blocks
[00:01:12.420 --> 00:01:16.380]   Uncage your creativity get all the stock video you need for only
[00:01:16.380 --> 00:01:24.340]   $149 a year visit video blocks.com/twig to save on millions of studio quality clips from video blocks
[00:01:24.860 --> 00:01:32.300]   And by Sonic twigs 10 gigabit fiber internet service provider join Sonics internet revolution as they bring fast
[00:01:32.300 --> 00:01:40.940]   affordable internet phone and TV to homes and businesses all over California visit sonic.com/twit to sign up for service and
[00:01:40.940 --> 00:01:43.100]   receive your first month free
[00:01:43.100 --> 00:01:47.980]   It's time for twig this week in Google the show where we cover the latest Google isms and
[00:01:48.260 --> 00:01:55.940]   Google ishness and there's lots of Google ishness in Silicon Valley Stacy Higginbotham is here from Stacy on IOT.com and the
[00:01:55.940 --> 00:01:58.260]   IOT podcast high stacy
[00:01:58.260 --> 00:02:06.100]   Hello, I got a I got a direct message from Om Malek to that felt so proud saying I want to talk about cameras
[00:02:06.100 --> 00:02:10.780]   Deal that fits yeah, he's really in photography now, isn't he?
[00:02:10.780 --> 00:02:13.420]   He's traveling the world taking pictures of it
[00:02:13.620 --> 00:02:19.300]   We mentioned that because Stacy for years was a gig of Om as was her friend Matthew Ingram who has a new job
[00:02:19.300 --> 00:02:25.260]   He does the CJ are which is fantastic. He is he's there media and
[00:02:25.260 --> 00:02:32.460]   Well social media media reporter Columbia. He's basically Matthew at CJ. I love it. That's how he should be
[00:02:32.460 --> 00:02:38.900]   Also here Jeff Jarvis professor of journalism at the City University of New York blogger at buzz machine.com
[00:02:39.340 --> 00:02:43.380]   prolific author and public speaker who's traveling the world
[00:02:43.380 --> 00:02:48.300]   Where are you gonna be next week? You're home. I know it's amazing next week. I'm in Chicago
[00:02:48.300 --> 00:02:51.260]   That's why I can't be on the show because I got a I'm
[00:02:51.260 --> 00:02:53.980]   Advising the Christian Century magazine
[00:02:53.980 --> 00:02:59.260]   I'm joining advisory group for them, which is a beer then I'm going to Salt Lake City for a media thing
[00:02:59.260 --> 00:03:01.260]   Was it last century the Christian century?
[00:03:01.260 --> 00:03:04.220]   Well, that's one of the things I wanted to discuss
[00:03:04.220 --> 00:03:07.820]   That's kind of
[00:03:07.820 --> 00:03:13.260]   We are in the new century now. It's like last year was the American century last century was the American century now
[00:03:13.260 --> 00:03:15.260]   I don't know what
[00:03:15.260 --> 00:03:18.380]   Pixel - oh, I got it by the way. I just want to show you
[00:03:18.380 --> 00:03:21.260]   Did my ship
[00:03:21.260 --> 00:03:29.020]   Tell us you got to be here tomorrow. You got the little one. I got the little one. Yeah, I think the people who ordered the
[00:03:29.020 --> 00:03:33.900]   Excel I think are not getting theirs for a while. I'm not getting on the 26th lunch ships off
[00:03:34.940 --> 00:03:40.380]   So you're soon it's gonna be available in Verizon. My my tomorrow is a shipping till November now
[00:03:40.380 --> 00:03:47.660]   Wow, that's when mine's coming no mines like Halloween. I think I canceled and then reordered like you did so I got a lot
[00:03:47.660 --> 00:03:51.180]   But I did get this so I got my case
[00:03:51.180 --> 00:03:59.260]   Shipped but it won't be here until forever. So so years look I can it looks great
[00:03:59.260 --> 00:04:04.060]   I got one of those live cases. This is one with my picture on it. Actually, we did
[00:04:04.060 --> 00:04:06.540]   That's what you did on the show. I came out great
[00:04:06.540 --> 00:04:12.300]   And at least see I'm looking it looks like I'm trapped in the phone and then the cameras right there
[00:04:12.300 --> 00:04:17.260]   I think it looks good. I like pretty good, but see at least now I know how big the phone's gonna be
[00:04:17.260 --> 00:04:23.420]   I could practice squeezeable. Yeah practice squeeze. It's the weird. That's the weirdest feature
[00:04:23.420 --> 00:04:29.420]   No, I think you know what as I as I read the reviews because all the reviews got an unembargot yesterday
[00:04:29.420 --> 00:04:32.140]   Yeah, this is what it's gonna look like
[00:04:32.300 --> 00:04:33.820]   as I read
[00:04:33.820 --> 00:04:40.380]   It's like a it's like a dummy so I can see how big yeah, that's nice if it's that's good practice putting my finger on the
[00:04:40.380 --> 00:04:46.380]   reader all the reviews said that the squeeze actually was a gives you a feedback tactile feedback it goes
[00:04:46.380 --> 00:04:49.500]   which is good and it's surprisingly useful and
[00:04:49.500 --> 00:04:55.340]   Was it was a dider bone? I think right now in the verge who said it's just very natural I'm reaching into my pocket
[00:04:55.340 --> 00:04:58.540]   Actually squeezes I'm pulling it out and the assistance ready by the time I get it
[00:04:59.420 --> 00:05:04.700]   Out the big complaint right now and we talked about this other couple of weeks ago is this screen
[00:05:04.700 --> 00:05:10.620]   It's the same screen as in on the lg v 30 lg not known for its oleads
[00:05:10.620 --> 00:05:11.660]   You know
[00:05:11.660 --> 00:05:16.780]   Samsung makes is gonna make apples oleads that make the oleads for the note of course and the s8
[00:05:16.780 --> 00:05:21.820]   The lg's apparently have kind of a blotchy grayness when they're turned to low dimness
[00:05:21.820 --> 00:05:24.860]   And we've started to see pictures of that come out now. So
[00:05:24.860 --> 00:05:27.820]   however, everybody's raving about the camera
[00:05:29.260 --> 00:05:32.620]   And google google did a funny thing they uh they kind of uh
[00:05:32.620 --> 00:05:40.220]   They were they sandbagged us a little bit turns out they didn't even mention this at the launch. There's a custom chip
[00:05:40.220 --> 00:05:46.060]   Oh, can I say I told you so you knew that you did we talked about it on the show
[00:05:46.060 --> 00:05:52.940]   I said they must have done something custom here. You're so smart. They didn't announce it. You're so smart. Wow
[00:05:52.940 --> 00:05:55.580]   It's called the pixel on the show. Yes
[00:05:55.580 --> 00:05:58.300]   It's called the pixel visual core
[00:05:58.940 --> 00:06:05.260]   It's a it's google's first custom system on a chip for consumer products and its total job
[00:06:05.260 --> 00:06:07.340]   is
[00:06:07.340 --> 00:06:09.340]   camera stuff
[00:06:09.340 --> 00:06:12.780]   Accelerating the hdr plus and so forth and it's not on
[00:06:12.780 --> 00:06:19.660]   When you get your new phone, it will be it's not activated until uh later in a couple of months
[00:06:19.660 --> 00:06:24.380]   Probably with 8.1 as my guess of oil
[00:06:25.420 --> 00:06:30.620]   So well in the way that's cool jeff because you'll get your phone pictures are going to look great every image
[00:06:30.620 --> 00:06:32.540]   I've seen so far looks fabulous
[00:06:32.540 --> 00:06:36.140]   And at some point it will suddenly get better even more or faster or something
[00:06:36.140 --> 00:06:39.180]   It's an eight core
[00:06:39.180 --> 00:06:43.020]   System on a chip with its own ddr for ram
[00:06:43.020 --> 00:06:46.940]   This is crazy
[00:06:46.940 --> 00:06:52.380]   So people just for that one function. Yeah people of course watch watch it's gonna go on your batteries gonna go
[00:06:53.340 --> 00:06:58.940]   Well, that's interesting. They call it an ipu or image processing unit
[00:06:58.940 --> 00:07:02.300]   and
[00:07:02.300 --> 00:07:08.940]   Oh, what wasn't this gonna be that there was there was there was there was processing for what's their new photo thing called hdr
[00:07:08.940 --> 00:07:18.620]   In our portrait no no no no no no no no no no the software um, oh, um, oh, uh, uh, uh, uh, chat room
[00:07:18.620 --> 00:07:19.580]   chat room
[00:07:19.580 --> 00:07:21.580]   It was announced at i/o
[00:07:21.580 --> 00:07:26.300]   And right now one i don't know no no no no no no
[00:07:26.300 --> 00:07:30.220]   It's the it's the photo processing and some of that processing was gonna happen locally
[00:07:30.220 --> 00:07:34.060]   Right. Oh, you mean for the little camera that there's side of the clip
[00:07:34.060 --> 00:07:38.220]   No that there was various
[00:07:38.860 --> 00:07:40.860]   Tensor i/o
[00:07:40.860 --> 00:07:44.060]   Oh, that's their ai a machine that goes being
[00:07:44.060 --> 00:07:46.940]   Chatroom on the chat room yet. No
[00:07:46.940 --> 00:07:49.500]   Chatroom helped me
[00:07:49.500 --> 00:07:53.420]   They don't know what you're talking about. They don't know there was yeah, there's no you'll know it when you hear it
[00:07:53.420 --> 00:07:56.460]   You'll say oh, that's what jeff meant. It's not the ai processor
[00:07:56.460 --> 00:08:01.260]   It was it was it was photo functionality that they announced at i/o
[00:08:01.260 --> 00:08:03.740]   Doesn't matter what they name it. Yes. This must be it
[00:08:03.740 --> 00:08:07.340]   That was gonna do look at and part of what the magic it was gonna do
[00:08:08.620 --> 00:08:13.420]   Was locally processed we couldn't figure out the time. Well, how the hell they gonna do that? This is how they couldn't do that
[00:08:13.420 --> 00:08:14.780]   Yeah
[00:08:14.780 --> 00:08:18.700]   And whatever that function is through the name i cannot remember one of the reviews i read
[00:08:18.700 --> 00:08:23.100]   Said oh, it's kind of now. That's probably why
[00:08:23.100 --> 00:08:25.500]   pixel uh
[00:08:25.500 --> 00:08:27.980]   Obviously pixel two required for this and
[00:08:27.980 --> 00:08:34.860]   It will uh enable the pixel pixel visual core as a developer option in the preview of oreo 8-1
[00:08:34.860 --> 00:08:40.380]   So if you're already, you know as as many of us got on the preview just to get uh oreo 8
[00:08:40.380 --> 00:08:43.660]   A little early on our pixel phones if you're still on that stay on it
[00:08:43.660 --> 00:08:49.260]   Because eight one should come out pretty soon probably roughly the same time you get your pixel two
[00:08:49.260 --> 00:08:51.980]   Except for stacy who's getting hers tomorrow
[00:08:51.980 --> 00:08:55.020]   so josh
[00:08:55.020 --> 00:09:01.500]   Uh google also says the hdr plus is only the first application to run on the pixel visual core
[00:09:01.980 --> 00:09:06.540]   In time we should expect to see more imaging and machine learning enhancements added
[00:09:06.540 --> 00:09:11.980]   Uh, I love it. Apple's done this too. Apple's new phones
[00:09:11.980 --> 00:09:17.900]   Have a lot of extra capability headroom the bionic 11 chip a 11 bionic chip that they put in there
[00:09:17.900 --> 00:09:20.300]   Is way more powerful than you need and
[00:09:20.300 --> 00:09:22.860]   We've been speculating that that's because
[00:09:22.860 --> 00:09:26.540]   There are new capabilities coming to these phones. They overbuilt them
[00:09:26.540 --> 00:09:29.100]   for ar or
[00:09:29.100 --> 00:09:31.900]   Other stuff this would could easily be part of an ar engine
[00:09:31.900 --> 00:09:35.900]   So that's good. I love it. That that's kind of nice
[00:09:35.900 --> 00:09:37.660]   Google lens
[00:09:37.660 --> 00:09:39.020]   in google lens
[00:09:39.020 --> 00:09:40.060]   Ah
[00:09:40.060 --> 00:09:40.620]   The lens
[00:09:40.620 --> 00:09:45.260]   Sorry, yes, how did it do my ureco? Yes lens. That was lovely
[00:09:45.260 --> 00:09:50.940]   I was gonna say the other thing to hear. Oh, oh, there's just what my memory wants. That's what it happens
[00:09:50.940 --> 00:09:53.980]   Yeah, so tech crutch said
[00:09:53.980 --> 00:09:56.540]   Google lens still has a long way to go
[00:09:57.260 --> 00:10:03.100]   Ah, because I was gonna do the localized processing and figuring out what the photo was and the photo becomes the search query
[00:10:03.100 --> 00:10:08.380]   It's not the funny thing is the tricky part about all that is not the processing. It's the data
[00:10:08.380 --> 00:10:14.780]   So that's true. I don't know how having a new product. I don't understand. Well, I don't understand much
[00:10:14.780 --> 00:10:19.740]   So that's uh the data going back to the cloud a lot of this if it can be processed on the machine remember
[00:10:19.740 --> 00:10:23.180]   They're also doing things like maybe yeah
[00:10:23.180 --> 00:10:25.660]   well
[00:10:25.660 --> 00:10:28.780]   And I don't know the specs of this chip, but if there's
[00:10:28.780 --> 00:10:34.140]   Generally even on a really tiny chip you can run a little bit of like
[00:10:34.140 --> 00:10:40.940]   Three to five models, which is recognition for three to five things. This is very broadly speaking
[00:10:40.940 --> 00:10:42.860]   This is very generalized
[00:10:42.860 --> 00:10:49.580]   But so with something this is way more powerful. So you could probably do quite a bit especially with things like
[00:10:49.580 --> 00:10:54.380]   Uh recognition of a person that can all be stored here on that
[00:10:55.020 --> 00:10:57.020]   um and now your dogs
[00:10:57.020 --> 00:11:01.740]   I was gonna say your particular dog not just dog in general
[00:11:01.740 --> 00:11:05.180]   Hmm so
[00:11:05.180 --> 00:11:07.180]   So
[00:11:07.180 --> 00:11:12.620]   You can also go to a pop-up store in New York or Los angeles, but verizon will have them now
[00:11:12.620 --> 00:11:16.460]   I guess to look at and available for sale on thursday
[00:11:16.460 --> 00:11:22.220]   But you have to deal with verizon and they're stupid is a 20 or 35 dollar activation fee
[00:11:23.420 --> 00:11:30.060]   Which is just basically like give us a little extra money. So yeah, so we can have you pay us money forever
[00:11:30.060 --> 00:11:32.940]   For this phone has no
[00:11:32.940 --> 00:11:35.900]   headphone jack it also doesn't have wireless charging
[00:11:35.900 --> 00:11:43.340]   Uh, but the circuit breaker vlads of off says the real problem with a pixel two is that darn screen
[00:11:43.340 --> 00:11:46.780]   So what's so bad about the screen
[00:11:46.780 --> 00:11:52.380]   Well, I you know, I I have to say i'm gonna withhold judgment until I actually have it
[00:11:52.460 --> 00:11:58.860]   It may not affect me. I think a lot of times I noticed this on reddit threads and among android fanatics
[00:11:58.860 --> 00:12:04.140]   When they really start to pay attention to this stuff they go wow it's blotchy
[00:12:04.140 --> 00:12:08.220]   Stuff that you wouldn't notice if you didn't really try to pay attention to it
[00:12:08.220 --> 00:12:12.860]   So the now this is more about a photography the the left is the iphone
[00:12:12.860 --> 00:12:15.660]   8 plus for those of you watching the video
[00:12:15.660 --> 00:12:20.620]   It's what's wrong. What actually this is poorly screened. I don't know what's going on here
[00:12:20.620 --> 00:12:22.300]   um
[00:12:22.860 --> 00:12:24.380]   I don't know
[00:12:24.380 --> 00:12:29.820]   So I guess what they're saying here is that this the iphone makes the photo look brighter than it actually is
[00:12:29.820 --> 00:12:32.780]   Oh, I see why it looks so weird. They're taking a picture of the screen
[00:12:32.780 --> 00:12:37.020]   Oh, oh with the polarization. Yeah, and then the pixel two
[00:12:37.020 --> 00:12:40.540]   Looks greener than it looks in real life
[00:12:40.540 --> 00:12:45.020]   See I don't this is a very bad way to judge anything. I don't
[00:12:45.020 --> 00:12:51.420]   Uh, well, and this is only on the excel. So mine will not have this issue. Yeah, because you got the baby food
[00:12:52.380 --> 00:12:54.380]   Okay, I'm gonna call it the petite foam
[00:12:54.380 --> 00:13:00.380]   Like the petite filet because by golly you got actually nothing baby about those bezels
[00:13:00.380 --> 00:13:02.700]   You got the big bezel buddy
[00:13:02.700 --> 00:13:09.660]   I'm I'm fine with bezels. I am not looking at my phone to be a fashion plate. Yeah, it'll be okay. Yeah
[00:13:09.660 --> 00:13:14.780]   You're gonna you're gonna buy the end of the year you're gonna say god that phone looks like it came from the 50s
[00:13:14.780 --> 00:13:17.660]   Who thought that was a good idea?
[00:13:18.540 --> 00:13:21.500]   Hey right now. I'm on an iPhone 6. Oh, it
[00:13:21.500 --> 00:13:24.380]   Everything will be better when I'm not
[00:13:24.380 --> 00:13:27.500]   Everything will be better
[00:13:27.500 --> 00:13:29.500]   Everything my whole world will improve
[00:13:29.500 --> 00:13:32.780]   So that's that on the
[00:13:32.780 --> 00:13:39.020]   Google pixel. I don't think there's anything much else to say. I thought that that chip though was really an interesting revelation and uh
[00:13:39.020 --> 00:13:42.460]   I don't know why because I love being right. Yeah, you were
[00:13:42.460 --> 00:13:46.940]   You really you really pegged it. You nailed it. You said they must have a job in there
[00:13:47.180 --> 00:13:49.180]   Must have some hardware for that
[00:13:49.180 --> 00:13:53.900]   Very although I did think it was gonna be also in the clip, but apparently
[00:13:53.900 --> 00:14:00.460]   You did you think it was image processing hardware or AI hardware? I thought it was something
[00:14:00.460 --> 00:14:08.620]   I think I called it AI for imaging, but I think you did. I did think that rings a bell. Yeah, okay. So you I remember
[00:14:08.620 --> 00:14:12.540]   But yes, I wanted it to be
[00:14:12.540 --> 00:14:16.300]   Something special because I I knew that google was working on their own chips
[00:14:16.300 --> 00:14:18.380]   They'd hired so many silicon designers
[00:14:18.380 --> 00:14:25.660]   And it felt like with what they were talking about that they had some special some special sauce somewhere in there
[00:14:25.660 --> 00:14:29.260]   It's really interesting how both apple and google see their future
[00:14:29.260 --> 00:14:34.140]   Uh as doing highly customized down to the chip hardware
[00:14:34.140 --> 00:14:36.700]   That that makes total sense
[00:14:36.700 --> 00:14:38.700]   You have to be
[00:14:38.700 --> 00:14:43.660]   To control your own destiny both in the features you want to offer and product differentiation
[00:14:43.660 --> 00:14:47.660]   You need to develop your own hardware also with battery life being so important
[00:14:47.660 --> 00:14:51.100]   The other side of that is it allows you to
[00:14:51.100 --> 00:14:58.540]   Handle your uh security and upgrade cycles for a longer period of time if you can control those chips. Yep
[00:14:58.540 --> 00:15:05.420]   Sorry, I don't know if that was everything you're gonna say very much so and uh actually more than I was gonna say so thank you
[00:15:05.420 --> 00:15:08.300]   Uh, we quote it paulth the rock quoted allen k
[00:15:08.860 --> 00:15:15.100]   On windows weekly, uh who said famously people who are really serious about software should make their own hardware
[00:15:15.100 --> 00:15:19.420]   and that was uh something steve jobs took very seriously
[00:15:19.420 --> 00:15:24.540]   Allen k was a is what I guess he was an apple fellow. I think he's an imaginary now
[00:15:24.540 --> 00:15:27.580]   But a brilliant thinker and I think that's kind of the point is yeah
[00:15:27.580 --> 00:15:29.580]   You have to tightly integrate those stacks
[00:15:29.580 --> 00:15:33.820]   It has another advantage though because and this is the thing I don't like from the point of view of consumer
[00:15:33.820 --> 00:15:36.940]   It pushes people into ecosystems into silos
[00:15:38.620 --> 00:15:40.140]   and um
[00:15:40.140 --> 00:15:42.300]   But you gotta have a differentiator. I don't mind that at all
[00:15:42.300 --> 00:15:46.060]   I don't I think you would agree stay so you don't want to see ai silos
[00:15:46.060 --> 00:15:49.900]   And this is the this is a number of people are worried that was it?
[00:15:49.900 --> 00:15:54.460]   I think was on sunday. We talked about this google's hiring all the ai people
[00:15:54.460 --> 00:15:58.140]   There, you know, they they're they're hard custom hardware
[00:15:58.140 --> 00:16:04.620]   Tensorflow all of this is kind of designed to to get all of the stuff in google's court. Do you agree?
[00:16:04.620 --> 00:16:07.820]   um
[00:16:07.820 --> 00:16:09.820]   Yes to a certain extent
[00:16:09.820 --> 00:16:16.380]   Tensorflow is really actually a way to economically do ai in google's cloud. It's open. Um
[00:16:16.380 --> 00:16:19.660]   Right, it is but it is but they want you to go
[00:16:19.660 --> 00:16:26.540]   Yes, now you can still use just like there's like kuda for invidious stuff and torch and cafe
[00:16:26.540 --> 00:16:31.100]   All of those things you can still you like the other ai frameworks
[00:16:31.100 --> 00:16:36.620]   You can still use on tensorflow the tpu's sorry on the the tpu's
[00:16:37.020 --> 00:16:39.420]   So they may not run quite as efficiently
[00:16:39.420 --> 00:16:43.660]   I'm less worried about
[00:16:43.660 --> 00:16:47.340]   The hardware integration on the ai side and maybe I will be proven
[00:16:47.340 --> 00:16:54.860]   Tragically wrong in a couple decades, but I think more problematic is control of the data
[00:16:54.860 --> 00:16:58.220]   And the ability to gather all that data
[00:16:58.220 --> 00:17:03.020]   And limit others people's access to it because that's where right now
[00:17:03.100 --> 00:17:07.660]   We're going to see the rubber meeting the road. So like the google photos that you put in there
[00:17:07.660 --> 00:17:12.620]   They become part of google's enormous data set that just makes it even better
[00:17:12.620 --> 00:17:15.820]   and that's
[00:17:15.820 --> 00:17:20.220]   That's going to make it hard for anyone else to compete. So those are the things I would be looking at
[00:17:20.220 --> 00:17:24.380]   Well, what do you do you say oh google? I mean, I don't
[00:17:24.380 --> 00:17:30.940]   They could they collect this data in the process of their business. I don't know how you can stop them
[00:17:31.740 --> 00:17:33.740]   I I don't in this is this is where
[00:17:33.740 --> 00:17:38.460]   This is where we'll I see I think we're going to talk about
[00:17:38.460 --> 00:17:42.780]   In the coming years, hopefully and we're already starting
[00:17:42.780 --> 00:17:46.380]   how to measure competition in a world where
[00:17:46.380 --> 00:17:51.900]   A monopoly isn't just being able to charge a lot of money for something
[00:17:51.900 --> 00:17:57.580]   It a monopoly is much more about being able to develop far
[00:17:58.780 --> 00:18:04.380]   Far beyond your capability or I guess far beyond your competition because of the inherent advantages
[00:18:04.380 --> 00:18:08.780]   Right
[00:18:08.780 --> 00:18:09.820]   Right
[00:18:09.820 --> 00:18:15.260]   Well, it's you know, we've talked before in the show about the doctrine being not the gathering of data but the use of data
[00:18:15.260 --> 00:18:22.300]   And in a sense, that's what the GDPR the the general data protection regulations going in effect in europe and may
[00:18:22.300 --> 00:18:28.700]   Try to do but but but the problem with that is that you can't anticipate every use and get permission for every use
[00:18:28.700 --> 00:18:33.900]   In the future, we've talked about in the show in the past. So it's really yeah. How do you how do you regulate? How do you limit?
[00:18:33.900 --> 00:18:36.620]   Where are the dangers?
[00:18:36.620 --> 00:18:37.820]   They're open
[00:18:37.820 --> 00:18:42.220]   They're open data sets. So, you know, it would be really interesting if
[00:18:42.220 --> 00:18:44.620]   In google's not going to do this
[00:18:44.620 --> 00:18:48.700]   But like there there've been efforts around autonomous cars to say look
[00:18:48.700 --> 00:18:55.100]   Here's data sets for driving in streets and situations and making those open to the community
[00:18:55.100 --> 00:18:57.740]   and I don't know if
[00:18:57.740 --> 00:19:02.700]   There's a way to to create like a friend for data sets, right? I'm not sure
[00:19:02.700 --> 00:19:05.340]   How that might look or a licensing pool
[00:19:05.340 --> 00:19:11.580]   Remember those used to be so big if you're google you fight that tooth and nail course because that really is their secret sauce
[00:19:11.580 --> 00:19:16.780]   And I don't see why apple should have google's data any more than google should have apple's data
[00:19:16.780 --> 00:19:19.500]   So
[00:19:19.500 --> 00:19:22.540]   Yeah, that's
[00:19:22.540 --> 00:19:26.620]   Giving google my photos google. I don't know how many people are aware
[00:19:26.620 --> 00:19:33.820]   It I don't know if people are aware that they're always they're giving google their photos or how that
[00:19:33.820 --> 00:19:38.140]   How that percolates through the rest of the ecosystem, right?
[00:19:38.140 --> 00:19:43.580]   Like how that gives google an advantage over, you know, let's
[00:19:43.580 --> 00:19:51.340]   The next hot photo startup. I don't know what that would be so I mean people don't think they don't make decisions in terms of
[00:19:52.220 --> 00:19:57.580]   Competition policy. That's not what individual consumers do. That's why we have governments who get involved
[00:19:57.580 --> 00:20:06.460]   Actually, it's interesting you should mention that because today at adobe max adobe announced a revamp of its lightroom program program
[00:20:06.460 --> 00:20:13.100]   Photographers use and one of the things they announced is oh and when you subscribe you're going to get a terabyte of free storage
[00:20:13.100 --> 00:20:19.900]   In fact, you don't need to keep your photos on your computer anymore. Why just keep them in our cloud. How about that? Now?
[00:20:21.500 --> 00:20:23.500]   I don't know if that's the plan
[00:20:23.500 --> 00:20:26.780]   Certainly they should tell us if they're going to use you know
[00:20:26.780 --> 00:20:32.300]   I think they are because they say and we are going to be able you're going to be able to categorize photos now by key
[00:20:32.300 --> 00:20:40.300]   You know, we'll be able to search through your photos for pets and people and keywords very much like apple does with its photos and google does with its photos
[00:20:40.300 --> 00:20:45.660]   Photographers by the way are really up at arms over this good in fact, it's such a
[00:20:46.380 --> 00:20:56.300]   Utter redesign of the of the tool that most pro photographers use to manage their photos that adobe is going to continue to offer their old version as lightroom classic
[00:20:56.300 --> 00:21:03.580]   And then which hasn't been updated in a few years and then adobe creative cloud adobe lightroom cc
[00:21:03.580 --> 00:21:11.100]   Will be a brand new very different version and one of the things I you know, I bought it immediately because I wanted to take a look at it
[00:21:11.100 --> 00:21:12.620]   I use lightroom
[00:21:12.620 --> 00:21:18.780]   Avidly if this is a very good example. This is the preference setting if you look at the preference settings in lightroom
[00:21:18.780 --> 00:21:25.500]   Today, it's page after page after page of complicated settings. This they don't let you do nothing
[00:21:25.500 --> 00:21:27.740]   It's like very straightforward
[00:21:27.740 --> 00:21:32.620]   This they're very this is cloud. This is all cloud. It's no, but it's software on your computer too
[00:21:32.620 --> 00:21:37.580]   They just don't want you can if you if you insist you can keep your originals on your
[00:21:38.300 --> 00:21:43.820]   Computer and pros will terabyte's not enough to store even all of my photos let alone a professionals
[00:21:43.820 --> 00:21:46.460]   Well, you don't want to mask him. Does this work on chrome? No
[00:21:46.460 --> 00:21:48.860]   Uh it will
[00:21:48.860 --> 00:21:56.460]   With the android app for Stacy no, no the whole point of this is that you can then use adobe lightroom mobile
[00:21:56.460 --> 00:21:59.980]   iOS or android and
[00:21:59.980 --> 00:22:06.700]   You can even pick off where you left off editing so you can edit on your desktop and then it will the edits will automatically be secret
[00:22:07.020 --> 00:22:10.700]   Synchronize this is where we had this big sense Stacy's gonna want to make fun of me
[00:22:10.700 --> 00:22:17.340]   But well, yeah, so in that respect it does kind of make sense, but boy photographers who are used to really a very local process
[00:22:17.340 --> 00:22:25.180]   Ah, I don't know. They're gonna kind of I'm a little freaked out and once you once you move your catalog over to the new version
[00:22:25.180 --> 00:22:27.980]   That's that you're you're in and it even costs more money
[00:22:27.980 --> 00:22:29.820]   so
[00:22:29.820 --> 00:22:33.980]   It's it's interesting. We'll see what we'll see what the reaction they just
[00:22:33.980 --> 00:22:36.940]   it clearly
[00:22:36.940 --> 00:22:38.940]   adobe is
[00:22:38.940 --> 00:22:45.100]   Trying to woo that that google photos and apple photos crowd. I don't know. That's if that's where they their market is
[00:22:45.100 --> 00:22:47.180]   But that's that's what they want to do
[00:22:47.180 --> 00:22:50.060]   Uh
[00:22:50.060 --> 00:22:54.700]   So you know what it is a cause I don't is it just my imagination or is it really?
[00:22:54.700 --> 00:23:00.460]   Uh picked up steam this notion of companies really creating verticals and silos
[00:23:00.460 --> 00:23:05.020]   For a while the whole thing was you know, we were hoping it was going to be more open
[00:23:05.580 --> 00:23:08.540]   You know, you'd be able to use whatever you wanted to use
[00:23:08.540 --> 00:23:13.260]   That's kind of was microsoft windows era where you'd buy the platform windows
[00:23:13.260 --> 00:23:21.180]   But you'd have all these third party applications that people would write on top of the platform and you could use anybody's your data state on your computer
[00:23:21.180 --> 00:23:23.500]   It was yours and and now
[00:23:23.500 --> 00:23:26.300]   Everybody google apple
[00:23:26.300 --> 00:23:28.620]   Microsoft they're all trying to build silos adobe
[00:23:28.620 --> 00:23:35.180]   Uh, where if you use their stuff, you're you gonna eventually get lock in, you know, and I understand why from a business point of view
[00:23:35.180 --> 00:23:38.140]   They do it, but boy search sure feels bad as a customer
[00:23:38.140 --> 00:23:43.740]   Okay, i'm off my off my soapbox
[00:23:43.740 --> 00:23:48.460]   Let's take a break. We're going to talk more about uh, the supreme court
[00:23:48.460 --> 00:23:54.220]   We're going to talk lots of supreme supreme court guy went it's the what was it second tuesday in october
[00:23:54.220 --> 00:23:58.540]   They just uh, they're sitting again there accepting cases a number of them to apply
[00:23:58.540 --> 00:24:03.180]   Including that microsoft case keeping email overseas
[00:24:03.500 --> 00:24:05.500]   But I want to welcome right now a new sponsor
[00:24:05.500 --> 00:24:11.340]   To this week in google and you know what they're a sponsor because of you stacy because you said what I
[00:24:11.340 --> 00:24:15.820]   I will quote when I went out and bought the nest IQ cams. Oh you doofus
[00:24:15.820 --> 00:24:24.540]   And as a warm and loving doofus and I said well wait what what should I buy and you said oh
[00:24:24.540 --> 00:24:27.020]   You gotta check this out
[00:24:27.020 --> 00:24:29.020]   This is the lighthouse
[00:24:29.340 --> 00:24:35.420]   And this is the coolest thing ever now it's not out yet, but you can go to light dot house
[00:24:35.420 --> 00:24:37.820]   slash twit
[00:24:37.820 --> 00:24:41.900]   To uh, I think you can you pre-order there? No, just give me your email and you'll get on the list
[00:24:41.900 --> 00:24:45.900]   It'll be out any minute now. I think there were only a shirt bit away
[00:24:45.900 --> 00:24:50.780]   You'll get 15 off when they ship and a chance to win a free lighthouse plus a year of service
[00:24:50.780 --> 00:24:53.260]   So lighthouse looks like a security camera
[00:24:53.260 --> 00:24:58.940]   It is so much more than a security camera and by the way number one
[00:24:59.580 --> 00:25:02.540]   The reason the other ones are out of the house and the lighthouse is
[00:25:02.540 --> 00:25:09.260]   The lighthouse turns on only when you're not home if you want you can have it on all the time and you may want to because it's got
[00:25:09.260 --> 00:25:12.460]   Amazing ai built into this thing
[00:25:12.460 --> 00:25:16.380]   It is you can query it like you would syri or google
[00:25:16.380 --> 00:25:17.900]   You could say for instance
[00:25:17.900 --> 00:25:21.820]   I want to see all the time that humans walked by with pets in you know
[00:25:21.820 --> 00:25:26.380]   It knows pets from humans and it will automatically give you all of those videos
[00:25:27.740 --> 00:25:30.380]   So one of the things that this was a must for lisa
[00:25:30.380 --> 00:25:35.020]   Whenever the owners are home the camera is not on so it doesn't give us a no
[00:25:35.020 --> 00:25:37.260]   uh
[00:25:37.260 --> 00:25:38.380]   You train it
[00:25:38.380 --> 00:25:42.540]   No, I don't think it's train train it. I think it's the app, but it might I might not be so it's explicit
[00:25:42.540 --> 00:25:43.500]   Yeah
[00:25:43.500 --> 00:25:48.060]   So I think when you come in the house and and either join the Wi-Fi or it sees you by a bluetooth
[00:25:48.060 --> 00:25:53.980]   You know, I should find out. I'm not sure. Oh, right right. Sorry. Sorry, but it does train. Oh, there's lots of training
[00:25:54.060 --> 00:25:58.140]   Look at this. This is so cool. So first of all, uh, because we're not home
[00:25:58.140 --> 00:26:02.700]   It was on and an alert was triggered. I just got an alert. Can you zoom in? I don't know if you can see that
[00:26:02.700 --> 00:26:04.940]   But somebody was walking through the living room
[00:26:04.940 --> 00:26:11.740]   Uh, it's actually our assistant, but it but now look at that. I said call 911 or I could say all okay
[00:26:11.740 --> 00:26:17.100]   I can review the video. I'm gonna say all okay now. It says do you want to disarm the home? No, let's stay armed
[00:26:17.100 --> 00:26:20.540]   So this is a live video of our living room
[00:26:20.540 --> 00:26:23.420]   I can see a daily recap
[00:26:24.140 --> 00:26:29.340]   As people walk in and out and go through isn't that cool? You see how it outlines people
[00:26:29.340 --> 00:26:31.500]   Um
[00:26:31.500 --> 00:26:33.420]   The oranges pets
[00:26:33.420 --> 00:26:36.460]   So I could say for instance. Oh, I just want to see all the pet activity
[00:26:36.460 --> 00:26:41.900]   Were there any pets here? These are pets actually that's that's there's the pet
[00:26:41.900 --> 00:26:45.820]   Sometimes people with pets walking through our house
[00:26:45.820 --> 00:26:49.100]   This is amazing
[00:26:49.100 --> 00:26:52.060]   You can see the faces and this is what you were talking
[00:26:53.260 --> 00:26:57.260]   About stacy. I can see it says okay. Here's all the images of you
[00:26:57.260 --> 00:27:01.980]   That and then it says here's some images are these you
[00:27:01.980 --> 00:27:07.260]   That's me. That's me. That's me. So I'm gonna say yeah. Yep. That's me
[00:27:07.260 --> 00:27:13.020]   Uh, oh, that's not me. So I'm gonna say that's me. That's me, but this one. That's not me
[00:27:13.020 --> 00:27:17.980]   So actually that's uh, that's uncle joe, but that's fine. So he's it's okay if he's in the house
[00:27:17.980 --> 00:27:22.940]   This has a nightlight night camera. So it's got in you know, he can see in the dark
[00:27:23.740 --> 00:27:26.860]   But this is the most exciting thing that's different from everything else
[00:27:26.860 --> 00:27:31.020]   Besides the ai it's got a depth sensor a 3d depth sensor
[00:27:31.020 --> 00:27:36.620]   Uh, so it has a better sense of why
[00:27:36.620 --> 00:27:44.860]   What is that do what is that do stacy tell me what it does a 3d depth sensor makes
[00:27:44.860 --> 00:27:46.060]   Uh
[00:27:46.060 --> 00:27:49.740]   One of the challenges with cameras and computers is for computer vision
[00:27:50.140 --> 00:27:57.580]   You can spoof things just by showing a picture of your face. That's why for instance the nest thought that the mylar balloons were people
[00:27:57.580 --> 00:28:01.100]   Right, okay
[00:28:01.100 --> 00:28:06.140]   It did not know it warned me I can talk to that makes sense right the depth sensor
[00:28:06.140 --> 00:28:09.980]   Just like face recognition on an apple phone. It just makes it a more accurate recognition
[00:28:09.980 --> 00:28:13.260]   They use different sensors so the iphone uses
[00:28:13.260 --> 00:28:17.660]   Uh, I can't remember a structured light sensor. I believe in this uses
[00:28:18.300 --> 00:28:20.940]   I can't remember they tell me to but I can't remember brain
[00:28:20.940 --> 00:28:25.420]   Nope school. It's so cool. Yeah, hold on
[00:28:25.420 --> 00:28:29.020]   And then but the ai so that's so so that's the camera part
[00:28:29.020 --> 00:28:35.340]   So it can see what's going on in the dark. It sees during the day. It has depth sensing so it recognizes people it recognizes pets
[00:28:35.340 --> 00:28:37.180]   But then the ai
[00:28:37.180 --> 00:28:39.980]   Is so amazing. It's natural language queries
[00:28:39.980 --> 00:28:44.220]   So you can say things like what did the kids do when I was out yesterday?
[00:28:44.860 --> 00:28:49.180]   You could say did you see someone with the dog yesterday afternoon while I was out
[00:28:49.180 --> 00:28:51.580]   So what's that?
[00:28:51.580 --> 00:28:53.580]   You can just have it. It can notify
[00:28:53.580 --> 00:29:00.380]   Lisa when I get home if he says it or I could say if you don't see michael by four o'clock
[00:29:00.380 --> 00:29:03.340]   In the afternoon. Let me know if he doesn't come home on time
[00:29:03.340 --> 00:29:06.140]   It will it will ping you
[00:29:06.140 --> 00:29:10.220]   Oh, and then the wave thing is so cool. Do you know about the wave things? Stacy?
[00:29:10.220 --> 00:29:13.020]   I do not know about the wave thing so
[00:29:13.900 --> 00:29:15.900]   if if uh, so
[00:29:15.900 --> 00:29:18.860]   The kids don't have another fun. They can walk up to the camera
[00:29:18.860 --> 00:29:21.660]   And they wave at the camera
[00:29:21.660 --> 00:29:26.780]   And that pings me. It says michael's waving and you can and you can open it on your phone and say there like that
[00:29:26.780 --> 00:29:30.380]   You can say hi michael. What's up? They open up a two-way talk
[00:29:30.380 --> 00:29:33.180]   Oh, that's awesome. Is that not awesome?
[00:29:33.180 --> 00:29:38.060]   They're basically pinging you by just waving at the camera
[00:29:38.060 --> 00:29:39.180]   Wow
[00:29:39.180 --> 00:29:43.340]   If you have an elderly parent, you can say things like if mom doesn't get up by 7 a.m
[00:29:43.340 --> 00:29:50.460]   Let me know if you don't see any motion in the house. It's a 1080p live stream two-way talk night vision
[00:29:50.460 --> 00:29:52.860]   You get a 30-day video history
[00:29:52.860 --> 00:29:57.020]   I love the privacy and that that was kind of uh
[00:29:57.020 --> 00:30:01.900]   Table stakes for Lisa. She said I don't want a camera that's on when we're home
[00:30:01.900 --> 00:30:06.140]   But that's fine. I don't care. I don't want to see what's going on when we're home. I know what's going on
[00:30:06.460 --> 00:30:08.700]   So when we are home, it turns off
[00:30:08.700 --> 00:30:12.300]   So that you get real privacy. Of course, it's encrypted on the way
[00:30:12.300 --> 00:30:18.620]   Uh, they do firmware updates automatically. It's encrypted in place. So you have all the privacy you want you can have
[00:30:18.620 --> 00:30:21.740]   Permission settings you have owners. That's me
[00:30:21.740 --> 00:30:25.660]   You have a member which would be anybody with the app, but you can also have guests
[00:30:25.660 --> 00:30:28.700]   So if you have like you're going to vacation and you say oh, you know
[00:30:28.700 --> 00:30:32.540]   Sally's gonna come over and look at when I'm a vacation you can add her
[00:30:32.540 --> 00:30:35.500]   and then remover
[00:30:35.980 --> 00:30:37.980]   There are a variety of gestures
[00:30:37.980 --> 00:30:40.060]   now the pre-orders are sold out
[00:30:40.060 --> 00:30:41.660]   but
[00:30:41.660 --> 00:30:44.540]   They're they're manufacturing like crazy. They're gonna be shipping very soon
[00:30:44.540 --> 00:30:48.700]   And I know you want this thing if if mostly I wanted to tell you
[00:30:48.700 --> 00:30:53.900]   Don't this is it. You want this is the one you want. Don't be a doofus like me
[00:30:53.900 --> 00:30:56.620]   You get uh, you get an amazing
[00:30:56.620 --> 00:31:00.060]   sophisticated system using the best AI
[00:31:00.060 --> 00:31:03.180]   And if you go to light.house/twit
[00:31:03.900 --> 00:31:08.700]   Uh, and you sign up for 15 off lighthouse when they ship automatically and you'll be in the end
[00:31:08.700 --> 00:31:13.500]   The contest to win your very own lighthouse in a year of service free. That's worth 400 bucks
[00:31:13.500 --> 00:31:16.460]   I love this
[00:31:16.460 --> 00:31:22.540]   I finally found a camera that's that's smart and does exactly what I need and I love it that if you have pets
[00:31:22.540 --> 00:31:27.980]   You could the fact that you could fire it up and say just show me when the show me of you know when
[00:31:27.980 --> 00:31:30.780]   The doggy shows up
[00:31:30.780 --> 00:31:32.780]   What did the dog do while I was gone?
[00:31:33.740 --> 00:31:35.980]   PING me if you see the kids with the cat
[00:31:35.980 --> 00:31:38.700]   PING me if you don't see the cat by 10 p.m
[00:31:38.700 --> 00:31:43.820]   Tell me if you don't see anyone with a dog from noon to 2 p.m. On weekdays while I'm gone
[00:31:43.820 --> 00:31:46.780]   It's that sophisticated and you do it in speech. You don't type it
[00:31:46.780 --> 00:31:50.300]   Unbelievable
[00:31:50.300 --> 00:31:53.660]   Tell me when the kids get home today
[00:31:53.660 --> 00:31:56.940]   And that's it and now it knows
[00:31:56.940 --> 00:31:59.980]   Got it notifying you of children today
[00:31:59.980 --> 00:32:02.540]   done
[00:32:02.540 --> 00:32:06.300]   Your ping has been created and I can see what's going on right now live
[00:32:06.300 --> 00:32:10.700]   All right light dot house slash twit
[00:32:10.700 --> 00:32:16.220]   They are I think they're shipping the next few weeks. I'm not sure but uh you'll get 15 percent off
[00:32:16.220 --> 00:32:22.780]   Which is if you sign up and a chance to win your very own lighthouse. It's a really great deal light dot house
[00:32:22.780 --> 00:32:25.580]   Slash twit see site for contest rules
[00:32:25.580 --> 00:32:29.340]   Love it
[00:32:29.340 --> 00:32:35.100]   You can say cool. I know I so what's interesting so do you know better than I do stacey, but he came from
[00:32:35.100 --> 00:32:36.860]   I
[00:32:36.860 --> 00:32:40.140]   I grew up a challenge. Yes. That's right. He was one of the groups
[00:32:40.140 --> 00:32:45.340]   And the sensor is so there are three types of depth sensors just for the tech nerds out there
[00:32:45.340 --> 00:32:50.780]   Lidar which we all know in love from cars wait and cost 11 thousand dollars per unit
[00:32:50.780 --> 00:32:54.060]   Okay gone and has moving parts. Yes time of flight
[00:32:54.060 --> 00:32:56.700]   And that's what's in this kind of time of flight camera
[00:32:56.940 --> 00:33:02.060]   What that does is it shoots out little things of lasers unlike light are which is like sonar for lasers
[00:33:02.060 --> 00:33:06.060]   a time of flight camera shoots out the lasers and measures
[00:33:06.060 --> 00:33:11.420]   How it measures the difference between each different pulse of a laser
[00:33:11.420 --> 00:33:13.980]   to figure out
[00:33:13.980 --> 00:33:18.300]   The shape of things around it and then there is the structured light camera, which is what's in the iPhone
[00:33:18.300 --> 00:33:22.460]   Time of flight time of flight or light time of light
[00:33:23.100 --> 00:33:27.580]   Time of light time of light. Sorry. Yeah. Oh, maybe it is time of flight. Hold on. I think it might be flight
[00:33:27.580 --> 00:33:33.900]   This is yeah, it might be flight. That's the same time of flight. It's so cool. Yes. This is like wild technology
[00:33:33.900 --> 00:33:37.420]   It's fun. Yeah
[00:33:37.420 --> 00:33:39.420]   Very cool. Anyway, thank you
[00:33:39.420 --> 00:33:41.580]   enough
[00:33:41.580 --> 00:33:45.020]   Sometimes sometimes we get an advertiser and I can't stop talking
[00:33:45.020 --> 00:33:47.660]   It's just really
[00:33:47.660 --> 00:33:49.820]   I really love it. So
[00:33:49.820 --> 00:33:52.940]   Lidar is direct. Lidar is a type of laser camera
[00:33:52.940 --> 00:33:57.420]   I'm just answering someone in the chat room. So lidar the beam is continuous
[00:33:57.420 --> 00:34:00.540]   That's the rotating thing you see on top of self-deriving cars
[00:34:00.540 --> 00:34:04.460]   Yes, and a time of flight camera just shoots out little bits of infrared
[00:34:04.460 --> 00:34:09.420]   And you need a lidar to drive because you're continually updating your model of the world around you
[00:34:09.420 --> 00:34:16.460]   This is just this is better. This is more for recognition of the objects around you and it could tell pets from humans for instance
[00:34:16.460 --> 00:34:18.780]   So that's pretty impressive
[00:34:19.260 --> 00:34:21.260]   Really cool
[00:34:21.260 --> 00:34:26.860]   Soscotus a bunch of scotus stories here
[00:34:26.860 --> 00:34:30.620]   Supreme Court of the United States
[00:34:30.620 --> 00:34:39.740]   Uh, they have agreed to review the DOJ versus Microsoft, but this goes back to uh
[00:34:39.740 --> 00:34:42.700]   What is it GDPR?
[00:34:42.700 --> 00:34:48.060]   Your data and if it's in the us or if it's in uh outside our shores
[00:34:48.460 --> 00:34:50.460]   Can the DOJ get it?
[00:34:50.460 --> 00:34:55.180]   And Microsoft has data. I guess on an irish servers
[00:34:55.180 --> 00:34:59.260]   And this is pretty let me let me get the actual facts of the case
[00:34:59.260 --> 00:35:02.380]   This this is this is uh, oh, why?
[00:35:02.380 --> 00:35:07.180]   Supreme Court has agreed to hear the case. We're pro back here. It's been going on for more than a year
[00:35:07.180 --> 00:35:11.260]   Microsoft says that data concerning non-us persons
[00:35:11.260 --> 00:35:16.300]   That's important non-us persons stored in non-us servers
[00:35:17.100 --> 00:35:21.100]   Should not be subject to subpoena by the Department of Justice
[00:35:21.100 --> 00:35:28.700]   The DOJ says no you're an american company doesn't matter if it's a us person doesn't matter if it's overseas
[00:35:28.700 --> 00:35:31.900]   So
[00:35:31.900 --> 00:35:35.100]   This is a big deal because if you're microsoft or apple or google
[00:35:35.100 --> 00:35:41.500]   Uh, you don't want to lose all your overseas customers because the minute they use you
[00:35:41.500 --> 00:35:45.420]   Suddenly they're subject to us law enforcement
[00:35:46.220 --> 00:35:54.300]   If this if uh, this is an article from extreme tech if scotus declares that the us government can reach into cloud databases
[00:35:54.300 --> 00:36:00.380]   Located on servers and other nations and pluck out any information on any private citizen of another country at any time
[00:36:00.380 --> 00:36:08.540]   Then the trust europeans will have in any us provider of cloud or email services will drop to zero real quick
[00:36:08.540 --> 00:36:12.700]   No wonder microsoft's fighting this one
[00:36:14.780 --> 00:36:22.060]   No idea how the supreme court will go on this one just it's completely this is so different from any case they've seen before
[00:36:22.060 --> 00:36:25.020]   Uh
[00:36:25.020 --> 00:36:27.020]   Any thoughts?
[00:36:27.020 --> 00:36:31.660]   The internet makes us all follow the same rules or but it doesn't
[00:36:31.660 --> 00:36:36.700]   How is that gonna work in practice? I mean, we're gonna need a treaty I guess for this and that's gonna be
[00:36:36.700 --> 00:36:40.620]   That's gonna be danger us. Yes, it is
[00:36:41.580 --> 00:36:48.140]   I heard a politician say in europe. I won't say where an event off the record event, but I heard a politician say
[00:36:48.140 --> 00:36:52.540]   Cautioning the people in the room. It's where he said we're ones
[00:36:52.540 --> 00:36:59.180]   Terrorist attack away from legislation to ban anonymity. Yeah, that's probably true
[00:36:59.180 --> 00:37:03.900]   God help us minutes. It's it's it's and the same politician was being
[00:37:03.900 --> 00:37:06.780]   Blut with us saying
[00:37:06.780 --> 00:37:09.340]   You don't want government to do this. We don't know what we're talking about
[00:37:10.620 --> 00:37:12.620]   um
[00:37:12.620 --> 00:37:14.620]   And yet
[00:37:14.620 --> 00:37:19.340]   You know people the reason we have these rules now is because of 9/11 and people will cry out saying
[00:37:19.340 --> 00:37:21.100]   uh
[00:37:21.100 --> 00:37:23.100]   Protect us
[00:37:23.100 --> 00:37:25.580]   That's your job protect us
[00:37:25.580 --> 00:37:30.540]   But it's an emotional protect us. It's it's you know, what what's this actually going to do?
[00:37:30.540 --> 00:37:33.420]   um
[00:37:33.420 --> 00:37:40.060]   And and and I'm always concerned about the lowest common denominator freedom highest common denominator of highest watermark of
[00:37:40.380 --> 00:37:41.660]   of
[00:37:41.660 --> 00:37:47.340]   Regulation that once the process is set up so that a nation can demand x
[00:37:47.340 --> 00:37:51.420]   Then every nation will demand that including the worst of nations
[00:37:51.420 --> 00:37:54.860]   Supreme court on monday
[00:37:54.860 --> 00:37:58.620]   Declined to review this is goodness for google
[00:37:58.620 --> 00:38:04.060]   I think a petition asserting that the term google has become too generic and then is not qualified for trademark
[00:38:04.060 --> 00:38:06.540]   protection
[00:38:06.540 --> 00:38:08.540]   Google has not is
[00:38:08.940 --> 00:38:14.220]   Has not fallen victim to genera side and that is not so basically I think that means
[00:38:14.220 --> 00:38:16.940]   since the judges refuse to hear it
[00:38:16.940 --> 00:38:19.340]   That google is
[00:38:19.340 --> 00:38:20.700]   trademarkable
[00:38:20.700 --> 00:38:27.900]   A guy chris chalespia registered 763 domain names with the word google in it google claimed trademark infringement
[00:38:27.900 --> 00:38:32.780]   For scolespia to forfeit the domains he sued to invalidate the trademark
[00:38:33.420 --> 00:38:38.940]   A federal appeals court ruled last year that even though the word google lowercase g has become
[00:38:38.940 --> 00:38:44.620]   Synonymous for searching the internet the trademark should still be valid. It's not Kleenex. It's not Xerox
[00:38:44.620 --> 00:38:47.340]   Because google is more than a search engine
[00:38:47.340 --> 00:38:50.380]   Uh
[00:38:50.380 --> 00:38:57.660]   That's the ninth us circuit court of appeals ruling and uh and then galesby who must have very deep pockets appealed to the supreme court
[00:38:57.660 --> 00:39:01.100]   Yep, he's done, but he's done
[00:39:01.660 --> 00:39:05.980]   So the lower court the circuit court ruling holds
[00:39:05.980 --> 00:39:10.220]   That's that's works for now. That seems fair
[00:39:10.220 --> 00:39:11.900]   Yeah
[00:39:11.900 --> 00:39:15.660]   Is Kleenex is still a trademark Xerox is still a trademark
[00:39:15.660 --> 00:39:20.940]   For the same reason they spend the fortune with lawyers protecting them. Yeah means more than a tissue or a
[00:39:20.940 --> 00:39:24.700]   photocopy that it's it's it's bigger. It's bigger than just that
[00:39:24.700 --> 00:39:29.340]   All right, that's it for scotus news
[00:39:30.140 --> 00:39:32.140]   I think
[00:39:32.140 --> 00:39:34.620]   I think so. Yeah
[00:39:34.620 --> 00:39:37.820]   Do you want to talk about jeff fake news ads?
[00:39:37.820 --> 00:39:40.860]   google served ads
[00:39:40.860 --> 00:39:44.220]   Uh that was pretty funny
[00:39:44.220 --> 00:39:47.820]   Platonly fake to polit effect and snopes a place people go
[00:39:47.820 --> 00:39:50.060]   to check
[00:39:50.060 --> 00:39:51.900]   facts
[00:39:51.900 --> 00:39:52.940]   Oops
[00:39:52.940 --> 00:39:55.740]   No, melania trump is not leaving the white house. No
[00:39:56.460 --> 00:40:00.780]   HGTV star joanna gains is not a bandit or husband and her show no
[00:40:00.780 --> 00:40:03.660]   Joel austin is not leaving his wife those were
[00:40:03.660 --> 00:40:07.260]   fake news
[00:40:07.260 --> 00:40:10.460]   But is it fake by the way that we have a fake melania
[00:40:10.460 --> 00:40:16.860]   What have you seen that I saw that you seen that what yeah, what do you mean fake melania?
[00:40:16.860 --> 00:40:21.260]   Let me just circle this here. See this is the
[00:40:22.060 --> 00:40:24.060]   This is a google ad
[00:40:24.060 --> 00:40:29.500]   On an article. It says why melania isn't staying at the white house. She's this was old obviously she's staying in york
[00:40:29.500 --> 00:40:33.180]   So polit effect is talking about that. This is a vogue article right at the top
[00:40:33.180 --> 00:40:40.060]   Obviously somebody anxious to I don't know do what so from both this idea so confusion
[00:40:40.060 --> 00:40:47.100]   Bon and ad saying hey that'd be a good place to buy an ad and google let him but this is the problem with programmatic ad advice, right? I mean
[00:40:47.100 --> 00:40:50.140]   It's all automatic
[00:40:50.700 --> 00:40:53.740]   The thing that I've I've been thinking lately about about advertising
[00:40:53.740 --> 00:40:57.340]   I don't know if I said this initial last week or not if I did stop me but but
[00:40:57.340 --> 00:41:03.660]   blogs and the web democratized and opened up the content and bad guys followed
[00:41:03.660 --> 00:41:08.300]   Yes, advertising is also democratized and bad guys followed
[00:41:08.300 --> 00:41:13.580]   Yes, and we're used to a world where the whole world was edited in the first time somebody used a bad word in the internet
[00:41:13.580 --> 00:41:16.700]   We thought they've schmuts to the whole internet. It's ruined
[00:41:17.420 --> 00:41:20.940]   As if someone put a bad word in the new york times. Yeah, same thing on advertising
[00:41:20.940 --> 00:41:27.580]   Somebody put a bad ad online the whole internet is ruined. Well, no, we just have an a completely new reality
[00:41:27.580 --> 00:41:31.980]   We got to figure out which means we need new rules and new structures and and that's all true
[00:41:31.980 --> 00:41:34.860]   but
[00:41:34.860 --> 00:41:36.700]   Uh
[00:41:36.700 --> 00:41:38.700]   We shouldn't be acting so shocked
[00:41:38.700 --> 00:41:44.860]   That people are gaming these systems. I don't know if it's if it's even gaming if you're gonna buy that ad you're gonna put it on
[00:41:44.860 --> 00:41:47.740]   Snub simple effect. That's the perfect place to put it
[00:41:47.740 --> 00:41:49.900]   uh
[00:41:49.900 --> 00:41:52.060]   And now you know why people use ad blockers
[00:41:52.060 --> 00:41:58.620]   Uh, goop they were using google ad sense. It's automatic you buy the ad you buy the you buy the
[00:41:58.620 --> 00:42:01.900]   The site can you can buy a site directly jeff? I guess you can
[00:42:01.900 --> 00:42:04.140]   Um
[00:42:04.140 --> 00:42:09.020]   Depends no usually you buy a word right or a search. Yeah, usually yeah
[00:42:09.020 --> 00:42:10.380]   Yeah, I think what that's why point what you do
[00:42:10.380 --> 00:42:14.060]   No, you can't buy the site because that would undercut the direct sales of the site, right?
[00:42:14.620 --> 00:42:19.340]   So when the new york times ran google ads for the first time way way way back when I asked the executives
[00:42:19.340 --> 00:42:24.060]   I said what how can you do that? I said well no nobody can buy the new york times through this side door
[00:42:24.060 --> 00:42:28.460]   They can only buy keywords. They can only buy certain characteristics and only buy audience
[00:42:28.460 --> 00:42:32.140]   So yeah, I think if you if you're clever enough and how you put the ad buy in
[00:42:32.140 --> 00:42:38.860]   Then you'll end up on a fact checking sites by the way google does not like this and they call it tab
[00:42:38.860 --> 00:42:41.100]   they call it tabloid cloaking
[00:42:41.100 --> 00:42:43.020]   buying
[00:42:43.020 --> 00:42:47.020]   Ads for tabloid fake tabloid stories on legitimate news sites
[00:42:47.020 --> 00:42:53.660]   Uh, it says google says these types of scammers use timely topics and ads made to look like new website headlines
[00:42:53.660 --> 00:42:58.140]   Google said it's spent in more than 1,300 advertiser accounts in 2016 for doing it
[00:42:58.140 --> 00:43:03.900]   This month's yeah, this month google said it had introduced additional controls to help publishers
[00:43:03.900 --> 00:43:07.100]   Filt out sensation cut their out sensation mark tabloid ads
[00:43:07.100 --> 00:43:10.220]   So they put it on the on the publisher to kind of block that stuff
[00:43:10.860 --> 00:43:16.860]   Could they also deal with the grossly inaccurate health ads because those are everywhere everywhere?
[00:43:16.860 --> 00:43:19.340]   they're
[00:43:19.340 --> 00:43:21.340]   They're actively harmful in
[00:43:21.340 --> 00:43:25.820]   Yeah, they say they're going after it, but but it has been good enough facebook's got the same problem
[00:43:25.820 --> 00:43:27.900]   I see those ads all the time on facebook
[00:43:27.900 --> 00:43:32.380]   I mean i'm talking i'm not talking about things like, you know get rid of belly fat
[00:43:32.380 --> 00:43:37.580]   I'm talking about things like ingest crazy poisons to make your energy levels rise. No, that's not good
[00:43:39.020 --> 00:43:43.820]   I've got to say this. I'm sorry. This is going to sound a little political. It's not but I just i'm just
[00:43:43.820 --> 00:43:49.500]   I'm this is too much. So, um, evidently info wars sells
[00:43:49.500 --> 00:43:51.420]   um
[00:43:51.420 --> 00:43:53.420]   some kind of
[00:43:53.420 --> 00:43:55.420]   Uh
[00:43:55.420 --> 00:44:00.860]   supplement vitamin supplements. Yes. Yes. Alex Jones has a supplement. And they contain sperm damaging lead
[00:44:00.860 --> 00:44:03.580]   Oh, nice. I'll let you write the jokes
[00:44:03.580 --> 00:44:06.540]   nice nice
[00:44:07.100 --> 00:44:12.300]   The chemicals were what was found in info wars caveman paleo formula
[00:44:12.300 --> 00:44:15.740]   Don't buy it
[00:44:15.740 --> 00:44:21.980]   I have to say this is a long standing tradition in radio as well. In fact, one of the things that makes it hard for me. Oh, oh
[00:44:21.980 --> 00:44:25.420]   Kids came on notification kids came home. Yeah
[00:44:25.420 --> 00:44:30.060]   Well, one of the things that makes uh makes this hard
[00:44:30.060 --> 00:44:31.180]   Uh
[00:44:31.180 --> 00:44:36.140]   For me to sell my weekend radio shows at many radio stations across the nation no longer have
[00:44:37.100 --> 00:44:41.260]   Programming on the weekends. They sell the entire yes weekend
[00:44:41.260 --> 00:44:45.740]   and oftentimes it's a dubious products
[00:44:45.740 --> 00:44:50.380]   But you buy it, you know, it's very lucrative for the radio stations. It's been a
[00:44:50.380 --> 00:44:53.260]   $5,000 for a half hour
[00:44:53.260 --> 00:44:59.820]   And still supplements, uh, and they sound like real radio ads. So this is this is a long standing problem
[00:44:59.820 --> 00:45:02.860]   Let the buyer beware. I guess I don't know
[00:45:04.460 --> 00:45:08.780]   Really so should I mean win the best way to handle this to be have the fda regulate
[00:45:08.780 --> 00:45:11.740]   It's anything you put in your mouth
[00:45:11.740 --> 00:45:14.780]   But of course it doesn't because
[00:45:14.780 --> 00:45:21.660]   The supplement makers lobbied the fda saying oh, it's a it's a food. It's not it's not us. It's not a medicine
[00:45:21.660 --> 00:45:24.620]   And uh, so they have lower standards that you know
[00:45:24.620 --> 00:45:27.820]   It's too bad
[00:45:27.820 --> 00:45:29.820]   Well, if you can't believe
[00:45:29.820 --> 00:45:34.300]   That you have only one first lady than what can you so all right tell us what's this? What's what's what?
[00:45:34.380 --> 00:45:36.380]   There's a there's a I put it on the rundown
[00:45:36.380 --> 00:45:41.580]   Oh, come on. So if you go down if you go down there's a new york magazine
[00:45:41.580 --> 00:45:43.900]   See I have to tell you this is bad
[00:45:43.900 --> 00:45:49.100]   People are looking at that video and saying that's not long. Yeah, they're putting pictures of long. Yeah, it's big
[00:45:49.100 --> 00:45:51.980]   Actually, you know it doesn't look like millennia
[00:45:51.980 --> 00:45:56.300]   Right. No, the lips look different. It looks like a wig the lips different just right exactly
[00:45:56.300 --> 00:45:59.340]   It's it's fake blog. Yeah, so
[00:45:59.900 --> 00:46:04.780]   People are having too entirely too much fun with this now. So as as uh,
[00:46:04.780 --> 00:46:07.820]   Isn't that a wig that's a wig?
[00:46:07.820 --> 00:46:10.540]   I don't know not even a good wig
[00:46:10.540 --> 00:46:13.900]   We don't have like a gene that don't you have wig?
[00:46:13.900 --> 00:46:16.460]   I thought you had a wig right?
[00:46:16.460 --> 00:46:21.260]   I'm like, I own a wig, but I do not know. I mean, yeah, don't know
[00:46:21.260 --> 00:46:27.020]   I always ask my wife if somebody's had work done. She seems to know
[00:46:28.220 --> 00:46:33.180]   Yeah, there's I can't I mean that's that's a skill that's developed over time and
[00:46:33.180 --> 00:46:37.900]   continual consumption of people and entertainment. She can't work done. Oh, yeah. She's had work done
[00:46:37.900 --> 00:46:41.180]   I can't tell look at the lips. Oh, yeah, they are large
[00:46:41.180 --> 00:46:43.740]   That's work
[00:46:43.740 --> 00:46:49.340]   Anyway, I don't yeah the problem and the problem with doing stuff like that. Maybe it's true
[00:46:49.340 --> 00:46:51.580]   I don't know. I don't know what you do with it
[00:46:51.580 --> 00:46:55.180]   But the problem with that is it distracts from much more serious topic
[00:46:55.740 --> 00:47:01.580]   Event or Rico doing lately by the way. Yeah, exactly. I've been thinking about that all the stuff today about the calls and this and that
[00:47:01.580 --> 00:47:07.180]   News is doing all that you're right. They're not talking about Puerto Rico. They're not talking about about issues that matter
[00:47:07.180 --> 00:47:09.020]   You're absolutely right
[00:47:09.020 --> 00:47:11.020]   And they can justify it saying we're covering the White House
[00:47:11.020 --> 00:47:14.940]   They are and they need to but the huge issues are going but
[00:47:14.940 --> 00:47:17.900]   A twitter account called Alex Trimboli
[00:47:17.900 --> 00:47:22.460]   Which I think is Nicole cliff said if you do not choose to believe in the existence of fake melania
[00:47:22.460 --> 00:47:25.580]   I encourage you to find more room in your heart for joy and whimsy today
[00:47:25.580 --> 00:47:35.820]   But there is and I think twitter has exacerbated this there's you know, there's always been gotcha journalism, right
[00:47:35.820 --> 00:47:40.460]   Uh, and I think it's twitter has brought it to a fine art
[00:47:40.460 --> 00:47:47.500]   Oh, oh, yeah, look at al michaels who I think said one of I don't know tell me if i'm wrong the most innocuous
[00:47:47.500 --> 00:47:50.300]   Thing you could say on sunday night football. He said
[00:47:51.020 --> 00:47:54.940]   The Giants are having a worse week than uh, uh harvey wine stein
[00:47:54.940 --> 00:48:00.300]   And and people were calling on twitter calling from to be fired fired
[00:48:00.300 --> 00:48:06.060]   Uh, I don't even think that's tasteless. Maybe it is but uh
[00:48:06.060 --> 00:48:11.500]   There is this kind of very fine and twitter is such an outrage engine
[00:48:11.500 --> 00:48:16.700]   That everything rises to this very high pitch and as a result nothing matters
[00:48:20.140 --> 00:48:21.820]   Right or am I wrong?
[00:48:21.820 --> 00:48:26.140]   Well, that's only I mean that's only if you use twitter is your end all be al barometer
[00:48:26.140 --> 00:48:28.300]   But notice that the news media does
[00:48:28.300 --> 00:48:35.340]   I I take issue with that some news media may and they do report on things happening on twitter
[00:48:35.340 --> 00:48:40.940]   Maybe to a greater extent than they probably should that's hard. You know, Puerto Rico is still in the new york times
[00:48:40.940 --> 00:48:46.620]   Uh, see it in is still running stories on these things that matter like health care
[00:48:47.340 --> 00:48:53.180]   And ways to figure out what to do after obama or obama uh trump's canceling subsidies
[00:48:53.180 --> 00:48:59.500]   I mean, these are all stories now that the things people talk about on twitter are obviously going to be
[00:48:59.500 --> 00:49:05.180]   The fun the silly the less nuanced stuff because no one really wants to get in a
[00:49:05.180 --> 00:49:09.900]   Health care debate and 140 characters right no or 280
[00:49:09.900 --> 00:49:14.860]   Uh, but here's the prodigy. See I I know now that newsrooms across the world
[00:49:15.420 --> 00:49:19.500]   Have now full-time jobs called trending editors. I know
[00:49:19.500 --> 00:49:21.900]   Is going to twitter
[00:49:21.900 --> 00:49:25.980]   They go into twitter, which is leo's point and they say well, well, we gotta have that too
[00:49:25.980 --> 00:49:28.780]   We gotta have that too snooze it's a follow-on to the old seo
[00:49:28.780 --> 00:49:33.740]   And and it's a waste of a resource. It's a waste of of attention
[00:49:33.740 --> 00:49:39.340]   Um, it's not really journalism. Uh, it's what the business model pushes him to do
[00:49:39.340 --> 00:49:42.780]   Right. I mean, I remember in at fortune
[00:49:42.780 --> 00:49:48.620]   We had we jumped on those stories or they pressed us to jump on those stories and some of us were like no
[00:49:48.620 --> 00:49:51.820]   but that was that was part of
[00:49:51.820 --> 00:49:57.020]   The business model we had to get that and those traffic those stories did
[00:49:57.020 --> 00:50:04.060]   Good traffic even though they were utter crap. So you're proving what I just said, which is yes you are whatever reason
[00:50:04.060 --> 00:50:08.220]   There and I I think you can say some of the stems from twitter
[00:50:08.620 --> 00:50:15.180]   We've become this gacha nation because it drives traffic and although I and I read this quote from george carlin
[00:50:15.180 --> 00:50:21.180]   Yesterday, uh, i'm gonna read it again. I have to find it. It's on. Uh, it's a great instagram
[00:50:21.180 --> 00:50:23.260]   Um
[00:50:23.260 --> 00:50:28.540]   A count called niche that has great pictures of people and their quotes
[00:50:28.540 --> 00:50:33.820]   George carland says there's one thing you might have noticed I don't complain about and that's politicians
[00:50:33.820 --> 00:50:35.900]   Everybody complains about politicians
[00:50:35.900 --> 00:50:39.820]   Everybody says they suck. Well, where do people think these politicians come from?
[00:50:39.820 --> 00:50:43.980]   They don't fall out of the sky. They don't pass through a membrane from another reality
[00:50:43.980 --> 00:50:50.780]   They come from american parents and american families american homes american schools american churches american businesses and american universities
[00:50:50.780 --> 00:50:55.340]   And they are elected by american citizens. This is the best we could do folks
[00:50:55.340 --> 00:51:00.940]   This is what we have to offer. It's what our system produces garbage in garbage out if you have selfish
[00:51:00.940 --> 00:51:05.580]   Ignorant citizens are going to get selfish ignorant leaders term limits ain't gonna do any good
[00:51:05.580 --> 00:51:09.020]   You're just going to end up with a brand new bunch of selfish ignorant
[00:51:09.020 --> 00:51:15.020]   Americans so maybe maybe maybe it's not the politicians who suck maybe something else sucks around here
[00:51:15.020 --> 00:51:19.020]   And I'd say it's not just politicians. It's news. We get the news. We deserve
[00:51:19.020 --> 00:51:22.380]   The stuff that's so
[00:51:22.380 --> 00:51:24.380]   That's true. I will
[00:51:24.380 --> 00:51:32.300]   I have written I mean my whole job for a long time covering things like tech policy was to deliver actual nuanced
[00:51:33.020 --> 00:51:35.020]   news for people and
[00:51:35.020 --> 00:51:40.300]   It it didn't get read that was frustrating and then
[00:51:40.300 --> 00:51:46.940]   I mean it's true and i'm not saying that I am the best writer because I am certainly that is not
[00:51:46.940 --> 00:51:51.020]   What i'm great at but
[00:51:51.020 --> 00:51:58.060]   The people who did read it it did make its way into places where decisions were made
[00:51:58.780 --> 00:52:06.220]   So while the mass market may not consume in-depth policy research or deep technically reported stories
[00:52:06.220 --> 00:52:12.860]   You know that there are people who are making decisions that do look at that. So
[00:52:12.860 --> 00:52:18.060]   I don't there's there's two audiences for news. There's the
[00:52:18.060 --> 00:52:23.900]   Entertainment kind of quick distractions and then there's people who are actually trying to find out
[00:52:24.460 --> 00:52:29.500]   What's really happening and get real insights and those people are often the people making actual decisions
[00:52:29.500 --> 00:52:33.340]   and that's worth thinking about as
[00:52:33.340 --> 00:52:39.180]   As we figure out like what role the media plays and who's paying attention to it
[00:52:39.180 --> 00:52:46.620]   You know, you're absolutely, you know, you've got high integrity. You're absolutely right and but I you know, and I and you're we shouldn't despair
[00:52:46.620 --> 00:52:51.740]   But you you got to admit pumpkin spice is always going to get more clicks
[00:52:52.860 --> 00:52:54.860]   uh, than you know, uh
[00:52:54.860 --> 00:52:57.420]   Tax policy
[00:52:57.420 --> 00:53:02.860]   Well, sure, but I mean, what do you talk about with people? You talk about pumpkin spice the challenges
[00:53:02.860 --> 00:53:07.820]   When we talk about tax policy, we don't currently have a
[00:53:07.820 --> 00:53:10.220]   report
[00:53:10.220 --> 00:53:11.660]   Repatorial
[00:53:11.660 --> 00:53:17.340]   cohort that can actually break those issues down for people and so what happens is that's maybe a good point
[00:53:17.340 --> 00:53:19.660]   That's Jeff's problem. That's your fault. Jeff
[00:53:21.340 --> 00:53:23.340]   You need a breed better journalists
[00:53:23.340 --> 00:53:25.660]   so
[00:53:25.660 --> 00:53:29.420]   Go ahead. Let's let Jeff respond. I can see this
[00:53:29.420 --> 00:53:35.820]   When I was in London, I saw a play called ink about uh, rootboard rock and the creation of the sun
[00:53:35.820 --> 00:53:42.940]   Uh, really well done play and and the the the motif through it to begin at the beginning and end
[00:53:42.940 --> 00:53:44.940]   was
[00:53:44.940 --> 00:53:46.700]   starts with with
[00:53:46.700 --> 00:53:48.700]   the five w's who what would wear y
[00:53:48.700 --> 00:53:50.940]   uh plus how
[00:53:50.940 --> 00:53:51.740]   And
[00:53:51.740 --> 00:53:57.340]   The argument was from the editor murvock hired to start the sun or the remade sun
[00:53:57.340 --> 00:54:01.740]   Uh, was a lot why is more and why does about it anymore when you get to why the story ends
[00:54:01.740 --> 00:54:05.100]   So the what what we care about now is what next
[00:54:05.100 --> 00:54:11.660]   And that's what we do right? It's it's this happened and and this is happening next and we can predict what's going to happen
[00:54:11.660 --> 00:54:14.380]   And and it's all just what happened what happened what happened what happened?
[00:54:14.380 --> 00:54:20.620]   It's not moving past and on the way back. I I read a book a little book about um truth
[00:54:21.500 --> 00:54:25.740]   And the complications of figuring out truth by a philosopher bookstore. I picked up in london
[00:54:25.740 --> 00:54:27.340]   and
[00:54:27.340 --> 00:54:32.700]   truth is hard truth is not easy. So i'm not saying truth is relative but but but truth is not absolute
[00:54:32.700 --> 00:54:39.260]   And and truth is difficult and we have this view that we in journalism are here to find the truth and spread the truth
[00:54:39.260 --> 00:54:43.660]   No, I actually think i'm coming more and more to think that our job is to find peace
[00:54:43.660 --> 00:54:50.540]   Is to is to enable society to be able to have conversations your rights tasey conversations
[00:54:50.780 --> 00:54:54.940]   truth because truth is often divisive and angering and causes
[00:54:54.940 --> 00:54:58.220]   friction not
[00:54:58.220 --> 00:55:04.300]   Resolution and and we're in this age of emotions, but the emotions we have are the ones that are all charged up by media
[00:55:04.300 --> 00:55:07.900]   Rather than emotions of empathy and understanding and concern
[00:55:07.900 --> 00:55:11.740]   And and and human decent emotions like that
[00:55:11.740 --> 00:55:14.460]   And so, you know, I think journalism's job
[00:55:14.460 --> 00:55:20.060]   Is to feed the public conversation to convene communities in conflict into conversation?
[00:55:20.140 --> 00:55:26.300]   Yes information as a role in that absolutely of course it was it didn't used to be the media's job media's job used to be truth
[00:55:26.300 --> 00:55:29.260]   And the politicians job was to lead
[00:55:29.260 --> 00:55:33.340]   I think you're just this is a promise. There's a vacuum
[00:55:33.340 --> 00:55:39.500]   From the people are supposed to do their job bringing the nation together to have these tough conversations to come to resolution
[00:55:39.500 --> 00:55:43.420]   To find a solution that works for everybody. They're not doing that
[00:55:43.420 --> 00:55:46.540]   So you're saying the media should take over basically
[00:55:46.540 --> 00:55:49.100]   Well, I'm not that we're trying to do so
[00:55:49.900 --> 00:55:53.580]   Yeah, we're we're driven by pop. I mean we're driven by profit
[00:55:53.580 --> 00:55:56.220]   So I I know nobody wants to be
[00:55:56.220 --> 00:56:03.740]   I love your optimism stacy. I think we're in any early. I'm the we have actually hidden theocracy. It's over
[00:56:03.740 --> 00:56:07.740]   Screwed
[00:56:07.740 --> 00:56:11.820]   I'll be the I'll be the I'll be the despair. I'll be despair for the day
[00:56:11.820 --> 00:56:14.380]   You guys could be uh, you guys could be optimism
[00:56:14.380 --> 00:56:18.700]   If you but if you really believe that that's a very nihilistic way to
[00:56:19.340 --> 00:56:23.020]   I don't know what I think sometimes the truth you have to say this is what is
[00:56:23.020 --> 00:56:27.260]   I mean, I'd like to I'll work against it. I'm not going to just give up
[00:56:27.260 --> 00:56:28.380]   I'll work against it
[00:56:28.380 --> 00:56:30.540]   But I think we've hit that and I think that
[00:56:30.540 --> 00:56:34.060]   the and the reason we cover it on this show is because it's
[00:56:34.060 --> 00:56:37.660]   Just to a great degree because of the rise of social media
[00:56:37.660 --> 00:56:41.660]   Mm-hmm. Well, well, well
[00:56:41.660 --> 00:56:46.300]   I wouldn't go too overboard there and lay even before facebook
[00:56:46.300 --> 00:56:51.980]   I could tell you that you know, I used to work at a business journal and when we had our when we started with the web
[00:56:51.980 --> 00:56:54.220]   We would put certain stories
[00:56:54.220 --> 00:57:00.540]   Clicks we got the most clicks about restaurants opening and you know anything involving a puppy
[00:57:00.540 --> 00:57:06.540]   I don't know people. I'm I don't blame people for what one any see pictures of puppies. That's those are cute
[00:57:06.540 --> 00:57:09.900]   So I quote from the spectator
[00:57:09.900 --> 00:57:13.900]   I go to England. I get to actually read things. It's wonderful. The great bookstores there
[00:57:14.460 --> 00:57:23.020]   The leader the editorial inspector this week, but the web was always going to be no more or less moral or vicious than the people who used it
[00:57:23.020 --> 00:57:32.220]   Right it's it's back to your back to your George Carlin line that it is us. We have met the internet. It is us. It's made of people
[00:57:32.220 --> 00:57:35.100]   Yeah, so why
[00:57:35.100 --> 00:57:37.820]   Actually, I kind of like this twitter
[00:57:37.820 --> 00:57:40.140]   Ted Cruz your senator
[00:57:40.140 --> 00:57:42.700]   God, I didn't realize this but apparently
[00:57:43.340 --> 00:57:46.380]   There was a conspiracy theory that he was the zodiac killer
[00:57:46.380 --> 00:57:50.460]   Which is apparently which is demonstrably false by the way. He's not
[00:57:50.460 --> 00:57:54.940]   Funny, but he likes apparently thought it was funny because look what he tweeted
[00:57:54.940 --> 00:58:01.660]   It's good to have people for those who cannot see
[00:58:01.660 --> 00:58:08.780]   That is that is zodiac killer letter. That's the encrypted letter that he sent to the newspapers
[00:58:08.780 --> 00:58:10.940]   one of them
[00:58:10.940 --> 00:58:14.380]   And Ted Cruz without comment. He's responding to a ben sassy's
[00:58:14.380 --> 00:58:19.020]   tweet. I was wearing my lee harvey oswald was framed t-shirt
[00:58:19.020 --> 00:58:22.300]   And then Ted
[00:58:22.300 --> 00:58:28.780]   responds with these without comment doesn't say who would think that he has a sense of humor who would amount that's the sense of humor
[00:58:28.780 --> 00:58:33.420]   And that's also a little effort. He's got to go find the letter. He's got a copy of
[00:58:33.420 --> 00:58:36.300]   Oh, I suspect he has some more to do. He's got it lying around
[00:58:36.700 --> 00:58:42.140]   Once someone says you're the zodiac killer, you know, you've got that just it's like meme-able. It's right there
[00:58:42.140 --> 00:58:47.420]   This was
[00:58:47.420 --> 00:58:53.660]   This is pretty funny. It's the first time Cruz has acknowledged this this maybe not a conspiracy theory. Maybe it's a joke
[00:58:53.660 --> 00:58:58.860]   Pretty funny
[00:58:58.860 --> 00:59:00.860]   And I don't think Ted Cruz's father
[00:59:01.740 --> 00:59:07.180]   Newly harvey oswald or had anything to do with the sass nation. What is well, that's another thing
[00:59:07.180 --> 00:59:10.620]   That's another muddled headed thing. We've got ourselves into is
[00:59:10.620 --> 00:59:13.820]   conspiracy theories
[00:59:13.820 --> 00:59:19.260]   There've always been conspiracy theories just the people who share them can now find each other easier
[00:59:19.260 --> 00:59:26.700]   More easily on the internet and then they can get these yeah, cool. Yeah, I just got a book called fantasy land
[00:59:27.500 --> 00:59:31.260]   Uh that is about the history. I think if I mentioned this last week, I think I did
[00:59:31.260 --> 00:59:36.460]   It's about the how america went haywire a 500 year history
[00:59:36.460 --> 00:59:39.660]   of conspiracy theories by uh kurt annerson
[00:59:39.660 --> 00:59:47.260]   And uh, and it says you know, this has been conspiracy theories have been since since the very beginning
[00:59:47.260 --> 00:59:53.980]   Uh, he wrote down he don't go ahead. Oh, go ahead. I was just gonna say he wrote true believers as well
[00:59:54.860 --> 00:59:58.460]   And uh, he found it spy magazine, which means he has a sense of humor
[00:59:58.460 --> 01:00:02.140]   One of those one of those harvard lampoon guys
[01:00:02.140 --> 01:00:06.620]   Smotty pants smotty pants
[01:00:06.620 --> 01:00:13.020]   I'm looking forward to listening to this. Although I have a uh boy. I have my book my bedside table is starting to pile up
[01:00:13.020 --> 01:00:16.700]   My it's my digital bedside table because I don't actually
[01:00:16.700 --> 01:00:21.580]   Read books. Although I did order the new waterproof famous on kendall
[01:00:23.260 --> 01:00:29.100]   I lost my kendall you guys in alaska airlines is keeping it hostage. I will never see it again. They won't give it to you
[01:00:29.100 --> 01:00:32.220]   No
[01:00:32.220 --> 01:00:37.180]   They they can't pro idea authorized it when I left it on a plane so I people could not buy books on my account
[01:00:37.180 --> 01:00:41.020]   And then they were like well, we can't identify it as yours. So I will never see it
[01:00:41.020 --> 01:00:42.860]   They admit they have it, but we can't give it to you
[01:00:42.860 --> 01:00:45.820]   They admitted that they they gave
[01:00:45.820 --> 01:00:49.420]   They sent it to the baggage claim in the san diego airport
[01:00:50.140 --> 01:00:55.580]   And I didn't catch it before they sent it to the central baggage processing place and once it's there
[01:00:55.580 --> 01:01:01.500]   It is a lot better than that my kendall. I left it in the seat back and I'm sure somebody just took it. I never got it back
[01:01:01.500 --> 01:01:04.860]   Well, the end result is the same
[01:01:04.860 --> 01:01:11.100]   Yeah, I just had to call a couple people and they pretended to look for it or they were like
[01:01:11.100 --> 01:01:14.460]   You shouldn't have deauthorized it. I was like, oh, thank you
[01:01:14.460 --> 01:01:18.780]   So I uh, I bought well, you should get this too. That's a little pricey
[01:01:19.180 --> 01:01:22.700]   This is the oasis. It's uh seven inches a little bigger
[01:01:22.700 --> 01:01:25.260]   300 dpi water proof
[01:01:25.260 --> 01:01:30.140]   Uh, they have one with 32 gigs enough storage to put audio books and your kendall books on it
[01:01:30.140 --> 01:01:36.060]   And you can play the audio through a bluetooth speaker so you can read and listen which I like because I like audiobooks as you know
[01:01:36.060 --> 01:01:41.340]   I'll get it on Halloween and I'll show you and you can see do you need a new kendall?
[01:01:41.340 --> 01:01:44.140]   I am gonna get a new kendall
[01:01:44.140 --> 01:01:47.820]   I could probably send you my old kendall. I have a paper white if you want
[01:01:48.780 --> 01:01:51.900]   I will take your paper. I will I will uh, let me get your uh address
[01:01:51.900 --> 01:01:58.060]   And I will send you my old paper white if I can find it because yeah, why should yeah, I'll but I'll deauthorize it
[01:01:58.060 --> 01:02:03.260]   So you don't that was good. Actually, don't okay. I want to deauthorize it. Yeah, I think you see all the books
[01:02:03.260 --> 01:02:05.420]   I was reading it'll be the gift to keep something giving
[01:02:05.420 --> 01:02:08.460]   Exactly. I was like and buy more. I hope you like
[01:02:08.460 --> 01:02:13.580]   I read a book a week. So do you I I didn't realize I have been subscribing to amazon unlimited for a year
[01:02:13.580 --> 01:02:15.420]   I didn't even realize it
[01:02:15.420 --> 01:02:17.420]   Oh, I did it
[01:02:17.740 --> 01:02:24.140]   That's like 120 bucks. I'll never see again. Is it good? Is it worth it? This is the one where I mean do they have decent books on unlimited?
[01:02:24.140 --> 01:02:26.940]   Okay, so if you like
[01:02:26.940 --> 01:02:31.500]   Airport reading is that I think of that's what I think of it too. And that's why I don't think I want it
[01:02:31.500 --> 01:02:37.180]   Or if you have a kid there's actually some fun kid books. So I yeah, I got it during
[01:02:37.180 --> 01:02:40.460]   Uh the chris they have a special during like
[01:02:40.460 --> 01:02:46.700]   Not prime day, but black that's probably when I bought it because I think it's exactly almost exactly a year
[01:02:46.700 --> 01:02:48.700]   That's probably when I bought it
[01:02:48.700 --> 01:02:53.500]   Yeah, so so they it was like half off. So I subscribed and
[01:02:53.500 --> 01:03:01.260]   Is there I mean there's there's a lot of older books like there's some Michael is it palan
[01:03:01.260 --> 01:03:06.620]   The omnivorous dilemma and all those are on there. Oh, I like him. That's good. All right. I like his stuff
[01:03:06.620 --> 01:03:12.140]   But I use it. I find a lot of esoteric stuff. Yeah, the stuff I want is probably not gonna be there
[01:03:13.100 --> 01:03:17.820]   What's a short history of the truth? Oh, I like it. I don't know Julia baggies truth
[01:03:17.820 --> 01:03:23.980]   Oh dear. It's just by everything that truth in the name another one called post truth
[01:03:23.980 --> 01:03:27.100]   Um what the what?
[01:03:27.100 --> 01:03:33.900]   And then the the breadth's a to z of modern manners. I thought that would be a nice little look at civility. Wow
[01:03:33.900 --> 01:03:39.660]   Let me let me see if there's any truth on the uh amazon kindle unlimited store
[01:03:39.660 --> 01:03:42.220]   truth
[01:03:42.220 --> 01:03:48.620]   Uh speaking the truth in love a response to christian universalism the naked truth about sex and marriage
[01:03:48.620 --> 01:03:53.420]   the merciful truth the book two of the mercy kill patrick series
[01:03:53.420 --> 01:03:58.540]   book three of the soul stone mage series mountain of truth
[01:03:58.540 --> 01:04:03.820]   The truth about ta that yeah, I think it's not the same kind of truth as you're looking for
[01:04:03.820 --> 01:04:07.420]   No, it's a different truth. Here's this is this is the truth book i'm gonna buy
[01:04:07.420 --> 01:04:08.620]   It's a
[01:04:08.620 --> 01:04:14.060]   Donovan legacy book don emtor. Let us not mock let us not mock romance novels. Wait a minute though
[01:04:14.060 --> 01:04:17.980]   It's not just a romance is a temporary christian romance temporary christian romance
[01:04:17.980 --> 01:04:22.380]   Does that mean they don't have sex? I would imagine not
[01:04:22.380 --> 01:04:28.700]   As he touched her crucifix and said let's get married and have 12 children
[01:04:28.700 --> 01:04:31.660]   The end you're gonna get in trouble
[01:04:31.660 --> 01:04:35.900]   but seriously art romance novels really just
[01:04:37.820 --> 01:04:40.140]   erotica in cheap's clothing
[01:04:40.140 --> 01:04:45.020]   Uh, I don't read a lot of them. I'm not asking you stacy
[01:04:45.020 --> 01:04:50.140]   No, I'm like, I'm like, don't think i'm being sexist here. I'm not asking you. I'm asking them
[01:04:50.140 --> 01:04:54.060]   I think there are people who read them because they're
[01:04:54.060 --> 01:05:00.460]   They're easy reading they're like column bodice rippers for a reason. Yeah, but they're like the lee. What is it?
[01:05:00.460 --> 01:05:06.460]   Reacher jack reacher books like that feels to me like ultimate male fantasy. Yeah, no, you're right
[01:05:06.460 --> 01:05:08.460]   Like easy and i'm awesome. Yeah
[01:05:08.460 --> 01:05:14.220]   I am beautiful and my son bann wants me and they will treat me well and
[01:05:14.220 --> 01:05:18.940]   You know, that's as soon as I get my new kennel the very first book i'm getting is this
[01:05:18.940 --> 01:05:22.220]   truth
[01:05:22.220 --> 01:05:26.540]   Donovan legacy book one. He doesn't even look like he has a penis
[01:05:26.540 --> 01:05:34.140]   So all these other romance novels they've got that guy with a long hair and it'll bear a chest
[01:05:35.340 --> 01:05:37.580]   This guy's wearing a white t-shirt
[01:05:37.580 --> 01:05:41.580]   They both have their arms folded
[01:05:41.580 --> 01:05:43.580]   That he has good pecs though
[01:05:43.580 --> 01:05:48.220]   Yeah, but you know, that's the universal symbol for you're not getting any till marriage
[01:05:48.220 --> 01:05:53.100]   I'm sorry. We should cut that whole segment out right there. I've
[01:05:53.100 --> 01:05:57.580]   Got the deep trouble. I found a book for you jeff it says true sin
[01:05:57.580 --> 01:06:00.780]   Yeah
[01:06:00.780 --> 01:06:02.780]   Sorry
[01:06:03.660 --> 01:06:09.740]   Uh, I must be uh, I must my uh, my meds war off. I think um, I have no excuse
[01:06:09.740 --> 01:06:16.860]   Moving right along google announces new education initiatives a billion dollars in global grants to non-profits
[01:06:16.860 --> 01:06:24.140]   See this is the kind of thing that doesn't get clicks. I'm just saying
[01:06:24.140 --> 01:06:26.940]   Oh, it doesn't yeah. I don't care about that
[01:06:26.940 --> 01:06:28.940]   Let's talk
[01:06:28.940 --> 01:06:39.740]   Can we talk about the self-learning AI? I mean, can we talk about something fun? Yeah, let's take a break
[01:06:39.740 --> 01:06:47.420]   And then we'll talk about that quantum computing self-learning AI and why google maps no longer has tiny donuts
[01:06:47.420 --> 01:06:52.780]   And my new job is cooking tiny cupcakes. I'm sorry job. I want the job you want
[01:06:52.780 --> 01:06:55.340]   The job you've got
[01:06:55.500 --> 01:06:57.500]   That's looking at it's in here
[01:06:57.500 --> 01:06:59.500]   everybody knows
[01:06:59.500 --> 01:07:02.220]   That a website a podcast
[01:07:02.220 --> 01:07:05.340]   Uh movie that
[01:07:05.340 --> 01:07:08.780]   The quality of the imagery makes a big difference. We are visual
[01:07:08.780 --> 01:07:14.380]   If you need sound effects for your podcast production a video background for your website a hero image on your blog
[01:07:14.380 --> 01:07:16.540]   You're going to want to go
[01:07:16.540 --> 01:07:19.180]   To the stock video marketplace
[01:07:19.180 --> 01:07:23.900]   I want to make a recommendation a new place we found called story blocks
[01:07:23.980 --> 01:07:29.340]   It's video blocks by story blocks. It's at video blocks.com/twig
[01:07:29.340 --> 01:07:31.420]   Get this
[01:07:31.420 --> 01:07:33.420]   It's an all you can eat plan
[01:07:33.420 --> 01:07:39.500]   All the content royalty free commercial personal fine you you own it forever forever
[01:07:39.500 --> 01:07:46.460]   115,000 studio quality hd videos after effects templates motion backgrounds and more
[01:07:46.460 --> 01:07:49.580]   New clips all the time. So there's always something fresh to download
[01:07:51.420 --> 01:07:55.420]   We for this we paid hundreds of dollars a month for this in the past
[01:07:55.420 --> 01:08:02.860]   Video blocks by story blocks is 149 dollars a year a year once you pay a year
[01:08:02.860 --> 01:08:05.500]   And you've got this access to this all year long
[01:08:05.500 --> 01:08:11.100]   And you also get exclusive discounts on their marketplace. I love the marketplace
[01:08:11.100 --> 01:08:17.500]   That's where they bring you together with artists making videos five million additional videos
[01:08:18.060 --> 01:08:24.220]   You pay the artists directly the artist gets 100 and because you're a member you get 40 off
[01:08:24.220 --> 01:08:28.620]   So video blocks doesn't take a cut of this. This is just they just establish a marketplace
[01:08:28.620 --> 01:08:32.460]   It's just a way to get you even happier about the deal you're getting video blocks
[01:08:32.460 --> 01:08:35.020]   dot com slash
[01:08:35.020 --> 01:08:42.940]   Twig 90,000 customers including the best biggest nbc national geographic the history channel the travel channel
[01:08:43.340 --> 01:08:48.140]   Uh, you don't go out. You know, you need to hover a drone footage of the beach
[01:08:48.140 --> 01:08:53.180]   You need helicopter footage of downtown you need explosions and flames
[01:08:53.180 --> 01:08:59.580]   Don't shoot it. It's all there in in beautiful high def quality
[01:08:59.580 --> 01:09:02.220]   studio quality. Look at that
[01:09:02.220 --> 01:09:04.700]   Look at that. That's gorgeous
[01:09:04.700 --> 01:09:08.380]   Sure, you could you could go to san diego and put a drone up in the air
[01:09:08.380 --> 01:09:12.300]   But why do that one for 149 dollars a year unlimited access?
[01:09:13.260 --> 01:09:18.380]   And by the way, your rights to use it are yours forever video blocks dot com slash
[01:09:18.380 --> 01:09:20.140]   Twig
[01:09:20.140 --> 01:09:24.860]   This is a this was a discovery when we found this it saves us a lot of money from the folks's story blocks
[01:09:24.860 --> 01:09:31.340]   So good. I'm really sad. I didn't get this feature in google maps
[01:09:31.340 --> 01:09:36.460]   Uh, and and now it's not either. I really wanted it. I guess it was a test right
[01:09:36.460 --> 01:09:41.420]   So what they you would ask for directions at google maps and it would say if you walked
[01:09:42.380 --> 01:09:46.620]   You would be able to eat this many tiny cupcakes. Did you get it?
[01:09:46.620 --> 01:09:50.540]   Stacy I did not get it, but this is the sort of thing
[01:09:50.540 --> 01:09:57.900]   I like i'll just tell everybody I had an eating disorder in high school and college and
[01:09:57.900 --> 01:10:02.540]   What people say about it being triggering as much as i'm kind of like, oh really?
[01:10:02.540 --> 01:10:08.620]   Like my 11 year old is constantly triggered by things. I'm like, okay, stop, but there is a very real
[01:10:10.140 --> 01:10:14.140]   Okay, I want to be very distressing. I have family members who have had eating disorders
[01:10:14.140 --> 01:10:17.020]   I myself have an eating disorder in the sense that I can't stop
[01:10:17.020 --> 01:10:21.740]   Uh eating so I understand I don't mean to make light of eating disorders
[01:10:21.740 --> 01:10:26.300]   So that's one of the reasons I stopped is is the community tried it and said you know what?
[01:10:26.300 --> 01:10:32.460]   This is these tiny cupcakes are triggering so you would you would you might have found this triggering when you were in you were a teenager
[01:10:32.460 --> 01:10:34.700]   I don't know
[01:10:34.700 --> 01:10:39.660]   It's actually more like I would find it in triggering as day. I would find it
[01:10:40.300 --> 01:10:43.420]   It's an extra thing to think about yeah
[01:10:43.420 --> 01:10:48.380]   It's it's one extra thing that I don't need it's not a piece of information
[01:10:48.380 --> 01:10:55.500]   I want to see and it would force my brain to make calculations and decisions that it probably shouldn't it shouldn't go there
[01:10:55.500 --> 01:10:59.020]   So Stacy what about what about all the fitness trackers?
[01:10:59.020 --> 01:11:06.540]   So that's it was at the domino clature. Yeah, what what what was the so the fitness tracker? I
[01:11:08.460 --> 01:11:12.220]   I wear one and I I actually have set rules for myself
[01:11:12.220 --> 01:11:20.540]   But that is that is a place I expect to think it and that's that's where I want that information and I look at it when I want that information
[01:11:20.540 --> 01:11:24.780]   And I don't think about it except when I'm doing it if that makes sense
[01:11:24.780 --> 01:11:26.780]   So it's kind of like
[01:11:26.780 --> 01:11:30.220]   Someone popping up in a place that you don't expect and going
[01:11:30.220 --> 01:11:35.820]   Think about your food and eating and calories and you're like, oh I see okay
[01:11:37.420 --> 01:11:40.460]   So here's a tweet here's a tweet from Kate Bond
[01:11:40.460 --> 01:11:45.660]   Uh, who's a New Zealander? I guess uh, sct Dr. Kate Bond on twitter
[01:11:45.660 --> 01:11:53.180]   Google Maps now includes calorie estimates and I really don't need this kind of judgment right now the average person burns 56 calories by walking a kilometer
[01:11:53.180 --> 01:11:55.340]   It's kind of so google's you know
[01:11:55.340 --> 01:12:02.780]   Thought was oh this is good because this will let people know that if they walked they would you know it'd be good for fitness
[01:12:02.780 --> 01:12:05.740]   but um
[01:12:05.740 --> 01:12:06.860]   Okay
[01:12:06.860 --> 01:12:12.460]   I you know I look I it's not going to be the end of the world if we don't have it and if it bothers some people fine
[01:12:12.460 --> 01:12:20.220]   And I think it's a you know what I can see it being an awesome feature like what if I could put in like
[01:12:20.220 --> 01:12:22.460]   crispy cream donuts
[01:12:22.460 --> 01:12:27.100]   Like at the end of the day google can tell me how many crispy cream donuts and that's like an optional thing
[01:12:27.100 --> 01:12:29.020]   Or wish that should be something you choose
[01:12:29.020 --> 01:12:33.980]   Right because there are plenty of things where you're like, oh crap
[01:12:34.540 --> 01:12:42.060]   You know and again what does it know is it the cupcakes that we're bad or was it just the kind of the nannying saying that's all I'm asking
[01:12:42.060 --> 01:12:45.660]   Yeah, oh it's it's the nannying. It's it's the idea that
[01:12:45.660 --> 01:12:51.660]   You should be thinking about calories all the time. Yeah, you're right. I get it
[01:12:51.660 --> 01:12:55.660]   So somebody who's anorexic for instance is constantly worried
[01:12:55.660 --> 01:13:00.140]   And there's no reason to to they're just looking for directions to say oh by the way
[01:13:01.660 --> 01:13:04.460]   Because that's just that's triggering now. I understand it's you know
[01:13:04.460 --> 01:13:10.620]   The world is going to be triggering you can't eliminate all triggers, but this doesn't really add that much
[01:13:10.620 --> 01:13:15.580]   Well, it's it's not to the world. This isn't making the world a better place
[01:13:15.580 --> 01:13:19.420]   No, and I it's more
[01:13:19.420 --> 01:13:25.020]   Again, I hate the word triggering. I really do it's it's a loaded word that doesn't
[01:13:25.020 --> 01:13:31.500]   It's just it's making something into a choice that beforehand and that honestly was probably google
[01:13:31.500 --> 01:13:34.860]   Intent is to make you think about should I walk or should I try?
[01:13:34.860 --> 01:13:36.220]   All I want is directions
[01:13:36.220 --> 01:13:42.220]   I don't want to be told how many calories it's going to consume that isn't what that map is designed to do
[01:13:42.220 --> 01:13:45.260]   If I want a calorie counter, I'll install a calorie counter
[01:13:45.260 --> 01:13:50.460]   I think in anorexia and eating disorders are about control right and
[01:13:50.460 --> 01:13:58.140]   When you're this is a reminder that you could control this to an even greater extent. So why aren't yes?
[01:13:58.300 --> 01:14:05.660]   Why aren't you walking every little yeah? No, I completely agree with that and and really more to the point it's adding it's really it's it's
[01:14:05.660 --> 01:14:11.340]   Perpendicular to the purpose of maps. It doesn't it's not it's something
[01:14:11.340 --> 01:14:17.020]   It's not what maps is supposed to be doing. So it's not it's not a huge loss
[01:14:17.020 --> 01:14:25.340]   I mean, it's when that doesn't app the apple watch have that thing trying to make you stand up every
[01:14:26.060 --> 01:14:28.060]   That off because it yeah
[01:14:28.060 --> 01:14:34.620]   Yeah, it's stupid. I mean I option I have mine on my Fitbit. It notifies
[01:14:34.620 --> 01:14:38.140]   And that's what you're going to fit fit to do
[01:14:38.140 --> 01:14:40.540]   right
[01:14:40.540 --> 01:14:42.700]   So so yeah, yeah
[01:14:42.700 --> 01:14:46.060]   I mean, I understand
[01:14:46.060 --> 01:14:49.260]   On the one hand you can't eliminate all the triggers from the world
[01:14:50.380 --> 01:14:56.860]   But you know things are triggering, you know, I have friends who can't go to violent movies is very because of PTSD
[01:14:56.860 --> 01:14:59.340]   It's very triggering for them. So they don't go to violent movies
[01:14:59.340 --> 01:15:05.180]   But it's but if you were to thrust a violent movie in their face that would be a bad thing to do to them
[01:15:05.180 --> 01:15:07.740]   So I understand that
[01:15:07.740 --> 01:15:12.700]   And do we really need tiny cupcakes in fact, I'm feeling guilty already. I should have walked here today
[01:15:12.700 --> 01:15:18.780]   So I was like yeah, this is not a hill I would die on but it is still up the same way exactly
[01:15:19.180 --> 01:15:23.500]   I do that's not exercise. I know it's not you so I use it now. We were
[01:15:23.500 --> 01:15:25.180]   always a bit used it
[01:15:25.180 --> 01:15:28.380]   Oh, the kids use it. I use it once in a while because it's fun. It's really fun
[01:15:28.380 --> 01:15:32.700]   But yeah, you're right. In fact, I was tempted by an electric bicycle and I thought no
[01:15:32.700 --> 01:15:36.380]   I want the exercise when I ride a bike. I don't want an electric bicycle
[01:15:36.380 --> 01:15:39.180]   Not that we have huge chills here if we had huge chills, maybe I would
[01:15:39.180 --> 01:15:44.300]   Uh google photos now recognizes your pets as people
[01:15:44.300 --> 01:15:47.340]   Well, we talked about that. Oh, we already did
[01:15:47.340 --> 01:15:49.340]   We mentioned that
[01:15:49.340 --> 01:15:53.420]   On this show or a previous show just just earlier
[01:15:53.420 --> 01:15:56.140]   Yeah, it was a it was a google photos
[01:15:56.140 --> 01:16:03.900]   I went to it and it doesn't do it for me yet. No. Oh, oh, I can't use google photos because I'm not on my pixel too
[01:16:03.900 --> 01:16:08.300]   Well, you can go to photos.google.com
[01:16:08.300 --> 01:16:10.300]   And then when you go to
[01:16:10.300 --> 01:16:15.340]   When you go to photos.google.com it shows you people's you're gonna use the web
[01:16:15.980 --> 01:16:17.260]   We web
[01:16:17.260 --> 01:16:21.260]   And when you look at people, I got a lot of people. I have to say this is pretty impressive
[01:16:21.260 --> 01:16:25.180]   Notice that I only care about the first row or two of people
[01:16:25.180 --> 01:16:27.820]   After that, I haven't labeled anybody
[01:16:27.820 --> 01:16:33.260]   Holy hannah cra you have got so many people in your pictures. It's ridiculous
[01:16:33.260 --> 01:16:40.060]   That is ridiculous. I don't even have that. You know what I thought if um, I thought oh, you know, it's cool about this
[01:16:40.060 --> 01:16:45.740]   Um, if I got alzheimer's they could use this as like a book. Now. Who's that?
[01:16:46.460 --> 01:16:49.420]   Um, and then I could practice
[01:16:49.420 --> 01:16:54.060]   So I don't think that's how all summers works. No. Oh, okay
[01:16:54.060 --> 01:16:58.940]   I was at a mental hospital once saw somebody doing that. So I just thought that's maybe what you do
[01:16:58.940 --> 01:17:01.660]   Anyway, if you need it, it's here john
[01:17:01.660 --> 01:17:06.540]   Look at the people but I don't have any aminals in there
[01:17:06.540 --> 01:17:11.820]   Actually, there's a picture of my daughter when she was a baby. That's pretty good
[01:17:12.460 --> 01:17:14.060]   Aww
[01:17:14.060 --> 01:17:16.700]   Google photos is there anything you can't do
[01:17:16.700 --> 01:17:19.660]   Well, that is a cute baby
[01:17:19.660 --> 01:17:25.020]   It doesn't know the difference between uh, baby abby and grown-up abby
[01:17:25.020 --> 01:17:28.780]   It doesn't no
[01:17:28.780 --> 01:17:30.780]   But that's really good
[01:17:30.780 --> 01:17:36.220]   It it was able so I have a picture of my daughter at the age of like 18 months and it knew that
[01:17:36.220 --> 01:17:40.380]   Or maybe she was a year old. It recognized her there to
[01:17:41.180 --> 01:17:45.820]   Well, she's 11 so our face is probably still stacy. What are your daughters 25 then see?
[01:17:45.820 --> 01:17:49.180]   No, no, it's not gonna happen
[01:17:49.180 --> 01:17:56.460]   And married she will always be 11 and living in matriole then see
[01:17:56.460 --> 01:18:02.220]   No, not living in your backyard. No, no, I was I did the I went the other way with that
[01:18:02.220 --> 01:18:06.700]   Google AI. This is the one stacey really wanted to do
[01:18:06.700 --> 01:18:10.540]   Can create better machine learning code than humans
[01:18:11.260 --> 01:18:13.260]   That
[01:18:13.260 --> 01:18:18.140]   Cody in class you're taking forget it never mind stop don't do it
[01:18:18.140 --> 01:18:21.980]   Uh, yeah, this is a little misleading
[01:18:21.980 --> 01:18:26.060]   Google has a system called auto ml
[01:18:26.060 --> 01:18:31.980]   Auto so this wasn't the story. Oh, oh, it's not the one you're talking about. Oh, it's not the story
[01:18:31.980 --> 01:18:37.260]   Well, it's just talking about but that is that is that is that is auto learning to code
[01:18:37.500 --> 01:18:41.420]   So that is also related, but I was talking about the alpha go zero
[01:18:41.420 --> 01:18:47.020]   Research paper that came out today. Oh, I think it's in there. Did I put it in there? I didn't see it there. No
[01:18:47.020 --> 01:18:50.300]   Oh, no, what if they didn't
[01:18:50.300 --> 01:18:53.020]   Alpha goes zero learns on its own. It's under alphabet
[01:18:53.020 --> 01:18:59.820]   Uh, it's the last item so well same idea, right the same idea is not writing software, but uh,
[01:18:59.820 --> 01:19:02.460]   It's able to create knowledge about itself
[01:19:03.260 --> 01:19:07.660]   But isn't that what wait a minute isn't that though a learning system is doing neural networks
[01:19:07.660 --> 01:19:09.660]   That's the whole idea of a neural network
[01:19:09.660 --> 01:19:15.820]   No, so if you're doing depending on the type of learning that it's doing
[01:19:15.820 --> 01:19:19.980]   a person a data scientist actually
[01:19:19.980 --> 01:19:27.340]   Helps train the model so it's it's saying it's nudging it. It's like oh, you know
[01:19:28.060 --> 01:19:32.300]   This is your your more right here and then it's like it adapts
[01:19:32.300 --> 01:19:38.540]   This is doing it without any human intervention whatsoever. So this is like what mine did with
[01:19:38.540 --> 01:19:45.900]   Learning how to play video games. You basically give it a goal. You say here's what we want you to get to figure out how to do it
[01:19:45.900 --> 01:19:55.100]   So here's the here's the example that the guardian says previous versions of alpha go learned their moves by training on thousands of games by strong players
[01:19:56.060 --> 01:20:01.660]   Which yeah, as you say we're fed to it alpha go zero had no such help instead it learned
[01:20:01.660 --> 01:20:05.580]   purely by playing itself with a logic millions of times over
[01:20:05.580 --> 01:20:12.940]   So it just played go at random and and the goal was to to win by taking over
[01:20:12.940 --> 01:20:19.820]   Territory but swiftly improved as a discovered winning strategies the interesting thing about that is it might learn to play better
[01:20:19.820 --> 01:20:25.100]   Because humans might have a style of play that's influenced by each other, but it's not necessarily the right style
[01:20:26.060 --> 01:20:31.260]   And so it might be learning from humans that are imperfect instead it's learning by actual experience
[01:20:31.260 --> 01:20:39.340]   Takes a lot longer and what was kind of fun is that it figured out some really difficult things very quickly and then some very simple things
[01:20:39.340 --> 01:20:43.260]   It took a while so it's learning in a different way than we learned which
[01:20:43.260 --> 01:20:49.020]   I guess makes sense because it's a computer and we're people but still kind of cool. Yeah, and i'm not sure that the
[01:20:49.020 --> 01:20:51.820]   Replicating the human brain is the old
[01:20:52.540 --> 01:20:56.860]   So this is um, so they use a rating system the yellow rating system
[01:20:56.860 --> 01:21:02.140]   I they use it in chess. I guess they use it and go as well. This is a video of how alpha go
[01:21:02.140 --> 01:21:07.340]   Make a little higher how alpha go learned it started at zero like it knew nothing
[01:21:07.340 --> 01:21:13.180]   No knowledge of the game, but look how fast and it's uh, it's not a straight up. It's up and down up and down
[01:21:13.180 --> 01:21:20.460]   But in the long run it got to a very strong three days. It got to uh, stronger than the original alpha go
[01:21:21.260 --> 01:21:25.420]   Now it starts to taper off of course because it can't grow as fast in three weeks
[01:21:25.420 --> 01:21:31.100]   It reached the level that defeated the 60 top professionals online and the world champion
[01:21:31.100 --> 01:21:33.900]   Three out of three games last year and now it's better
[01:21:33.900 --> 01:21:41.180]   It's off the charts in 40 days. It's better than all of their versions of alpha many times to the play to get there
[01:21:41.180 --> 01:21:45.660]   Oh, that's a great question. It must have been hundreds of millions of games, right?
[01:21:45.660 --> 01:21:48.860]   Because it can play a lot faster
[01:21:49.660 --> 01:21:51.900]   It puts those 10,000 hours ideas. It just
[01:21:51.900 --> 01:21:53.820]   Yeah
[01:21:53.820 --> 01:21:56.220]   Now go is it go is a very rigorous
[01:21:56.220 --> 01:21:59.980]   You know and rigid structure, right? So
[01:21:59.980 --> 01:22:06.700]   You know for instance, I had for years and my kids love this as a screensaver something called breathe walker, which is a very
[01:22:06.700 --> 01:22:08.940]   popular
[01:22:08.940 --> 01:22:11.420]   kind of artificial intelligence thing it was a
[01:22:11.420 --> 01:22:13.980]   four-legged creature
[01:22:13.980 --> 01:22:18.300]   Here i'll show you i show you a video of it at work. It's a four-legged creature
[01:22:18.940 --> 01:22:20.940]   that teaches itself to walk
[01:22:20.940 --> 01:22:23.740]   uh, but it first doesn't do a very good job
[01:22:23.740 --> 01:22:26.060]   but
[01:22:26.060 --> 01:22:32.940]   Over many iterations it gets better and better and better and eventually walks, but it might take months or even
[01:22:32.940 --> 01:22:36.540]   Years because you start with nothing. I love that
[01:22:36.540 --> 01:22:44.460]   It's a the best screensaver ever. How does it define but but it is not all about the goal the goal is distance what defines good walking
[01:22:44.460 --> 01:22:45.980]   Oh distance. Okay
[01:22:45.980 --> 01:22:49.660]   So it tries different strategies at random with its four
[01:22:49.660 --> 01:22:54.620]   Articulated legs some of them are like this and they don't move anywhere
[01:22:54.620 --> 01:22:57.900]   And then till it gets somewhere and it's really interesting to see it
[01:22:57.900 --> 01:23:01.660]   But it's not nearly as of course we can't do as many iterations as fast
[01:23:01.660 --> 01:23:02.620]   So
[01:23:02.620 --> 01:23:08.300]   It's not it didn't take 40 days to become the best go player in the world. I think go is so much more structured. It might be a little bit easier
[01:23:08.300 --> 01:23:09.900]   I don't know
[01:23:09.900 --> 01:23:11.900]   It's pretty impressive
[01:23:12.060 --> 01:23:16.220]   So that's very different than a computer that writes its own code
[01:23:16.220 --> 01:23:20.380]   But it's related in this sense and this is the thing that scares humans
[01:23:20.380 --> 01:23:28.380]   And this to me is what the real singularity is you know often they talk about the singularity being when a computer mind is
[01:23:28.380 --> 01:23:35.260]   indistinguishable from a human mind. It's as you know, it's as good as or at least can't you can't tell the difference
[01:23:35.260 --> 01:23:41.500]   My singularity is when computers or artificial intelligences can start designing themselves
[01:23:42.140 --> 01:23:46.860]   Because that's the hockey that's the bend in the hockey stick because we're slow
[01:23:46.860 --> 01:23:50.700]   So as long as we have to write the code or teach the computer to play go
[01:23:50.700 --> 01:23:58.300]   It's going to take longer the minute the computer can just say let me take it from here and do a million moves a second or write its own code
[01:23:58.300 --> 01:24:00.220]   the
[01:24:00.220 --> 01:24:05.180]   Acceleration of learning just true takes off you got the the exponential elbow in the hockey stick
[01:24:05.180 --> 01:24:10.540]   That to me is the real singularity and it sounds like we might we might be getting there
[01:24:12.140 --> 01:24:16.700]   Auto mn I think that'll go ahead. So that will be important
[01:24:16.700 --> 01:24:20.700]   For times to come because we cannot as people
[01:24:20.700 --> 01:24:26.300]   Generate the code we're going to need in as flawless a manner as we have to so
[01:24:26.300 --> 01:24:33.660]   You know, I I know this is scary in some ways and we should be talking about how to audit things and
[01:24:33.660 --> 01:24:37.340]   You know how to look at outcomes and test stuff, but
[01:24:39.980 --> 01:24:41.500]   We don't
[01:24:41.500 --> 01:24:47.660]   We don't do things by hand anymore. There's so many like we don't we don't hand stitch our clothing anymore
[01:24:47.660 --> 01:24:51.100]   It's ridiculous that we should have to hand write our code
[01:24:51.100 --> 01:24:54.060]   when we're putting so much
[01:24:54.060 --> 01:25:00.460]   Of our lives in tech that was kind of not as eloquent as I wanted it to be but you get where i'm going with this
[01:25:00.460 --> 01:25:03.820]   Yeah, and I don't think that
[01:25:03.820 --> 01:25:07.980]   I think that there's there
[01:25:08.620 --> 01:25:10.620]   the two
[01:25:10.620 --> 01:25:17.980]   Issues are orthogonal. So I think there's the one issue that computer writing its own code that's separate from the
[01:25:17.980 --> 01:25:25.500]   What you don't want a computer to do is optimize for its success. That's the famous paperclip example, right?
[01:25:25.500 --> 01:25:29.100]   If you build if you build a paperclip machine
[01:25:29.100 --> 01:25:32.780]   That is trained to optimize for building paper clips
[01:25:32.780 --> 01:25:37.260]   That's all it does and success is only the number of paper clips generates
[01:25:37.500 --> 01:25:42.060]   Eventually it eats the whole world because everything is about making paper clips
[01:25:42.060 --> 01:25:50.780]   That's different in if my opinion that's orthogonal from the goal of having computers right there on software. That's two different problems. I hope
[01:25:50.780 --> 01:25:54.140]   You know that example the paperclip
[01:25:54.140 --> 01:25:59.740]   Yes machine. Is it isn't writing your own software just an extension of a learning system
[01:26:01.580 --> 01:26:06.220]   We're learning network. Yeah, sort of right. That's it's all you
[01:26:06.220 --> 01:26:11.660]   Go is writing its own software because it's saying how do I how do I win?
[01:26:11.660 --> 01:26:14.540]   At uh, at go. Yeah, you're right
[01:26:14.540 --> 01:26:21.500]   Yeah, because we heard this said at i.o. Where where you have a system that says here's the goal to
[01:26:21.500 --> 01:26:24.780]   I think I think an example it's correctly identified photos
[01:26:24.780 --> 01:26:27.180]   and
[01:26:27.180 --> 01:26:33.420]   Will create them but but but they said the software could create its own test basically its own software to do that
[01:26:33.420 --> 01:26:36.380]   More efficiently and effectively
[01:26:36.380 --> 01:26:42.540]   That would beat itself the pay it's called the paperclip maximizer. It's the canonical thought experiment
[01:26:42.540 --> 01:26:46.860]   I'm reading from the less wrong wiki, which I like the name of
[01:26:46.860 --> 01:26:49.740]   Showing how an artificial general intelligence
[01:26:49.740 --> 01:26:54.780]   Even one designed competently and without malice could ultimately destroy humanity
[01:26:56.300 --> 01:27:00.860]   Uh, this was nick bostrom proposed this in 2003
[01:27:00.860 --> 01:27:04.540]   It
[01:27:04.540 --> 01:27:11.980]   The goal is to maximize the number of paperclips in its collection if it has been constructed with roughly human level of general intelligence the AGI might collect paperclips
[01:27:11.980 --> 01:27:19.420]   Earned money to buy paperclips or begin to manufacture paperclips more importantly. However, it would undergo an intelligence explosion
[01:27:19.420 --> 01:27:26.060]   The hockey stick it would work to improve its own intelligence where intelligence is understood in the optimization power
[01:27:26.700 --> 01:27:31.100]   The ability to maximize a reward utility function in this case the number of paperclips
[01:27:31.100 --> 01:27:40.060]   So the AGI would quickly realize oh collecting paperclips is not the goal is not really how I achieved my goal. I need to improve my intelligence
[01:27:40.060 --> 01:27:44.300]   To help it to help accumulate more paperclips
[01:27:44.300 --> 01:27:51.100]   And it would continue to improve and enhance and eventually it would consume the entire world making paperclips
[01:27:51.100 --> 01:27:54.060]   And then it will go on to make a fake first lady
[01:27:54.540 --> 01:27:56.540]   hahahaha
[01:27:56.540 --> 01:27:59.420]   Which is why audit and understanding how these
[01:27:59.420 --> 01:28:03.020]   Looking at outcomes of AI is actually really important
[01:28:03.020 --> 01:28:09.340]   Yeah, because we don't understand necessarily how computers are making the decisions or get to their decision
[01:28:09.340 --> 01:28:13.660]   But well, but eventually we're not gonna be black boxes, right? If that's what I'm saying
[01:28:13.660 --> 01:28:19.500]   That's why audit and outcomes are important. Yeah in that we tend to look a lot at intent
[01:28:19.500 --> 01:28:22.700]   So that'll be kind of an interesting
[01:28:23.980 --> 01:28:25.740]   uh
[01:28:25.740 --> 01:28:30.780]   An interesting way to think about like legal issues and regulations and fun stuff like that
[01:28:30.780 --> 01:28:36.620]   Hey, did any of you get the new google calendar yet? No, I'm bummed. No, I did not
[01:28:36.620 --> 01:28:39.580]   Anybody in the chat room
[01:28:39.580 --> 01:28:45.100]   Uh, google's this is a massive update right new design
[01:28:45.100 --> 01:28:48.140]   You can book conference rooms
[01:28:48.700 --> 01:28:50.700]   You know, I was thinking about this
[01:28:50.700 --> 01:28:55.260]   I mean, I have this constant problem where I was in europe last week. I get an appointment
[01:28:55.260 --> 01:28:59.500]   I want to put it in a new york time on mobile. You can't really find the dam
[01:28:59.500 --> 01:29:06.220]   Time zone. Yeah, and and and this is because it's a thing built by a global corporation having global meetings
[01:29:06.220 --> 01:29:11.420]   Most of us aren't that way most of us just have our own clock that's with us and I want wherever I am
[01:29:11.420 --> 01:29:14.940]   I wanted it for a clock. I got the button. I got the button
[01:29:15.740 --> 01:29:23.420]   What there's a button up. Look in your calendar. Google.com use new calendar a fresh look upgrade now. Oh, there's a button
[01:29:23.420 --> 01:29:30.460]   Where I don't see it. I don't see my but I don't have a upper right hand corner. No, no
[01:29:30.460 --> 01:29:34.540]   Okay, I'm better than you guys. Ha ha I got more paper clips
[01:29:34.540 --> 01:29:39.180]   Updated design makes it even easier for you to manage your time. You can change
[01:29:39.180 --> 01:29:45.260]   Information density is responsive to your screen or compact color set modern or classic. Okay. I'm gonna go with
[01:29:45.660 --> 01:29:50.220]   The defaults that's nice. It's pretty should I make a new appointment? Let's make a new appointment
[01:29:50.220 --> 01:29:55.180]   I can't even figure out how oh there it is. I hate it when they do that red plus in the lower right hand corner
[01:29:55.180 --> 01:29:58.220]   Um, this looks similar
[01:29:58.220 --> 01:30:05.740]   I don't know if it's that different find a time. Oh, look it just finds a time in my calendar knowing what I've got to do
[01:30:05.740 --> 01:30:08.460]   You can compare multiple calendars or stuff like that. Yep
[01:30:08.460 --> 01:30:11.900]   Cool meetings
[01:30:12.380 --> 01:30:15.500]   Yeah, it's really designed around google isn't it? I mean, I don't have conference room
[01:30:15.500 --> 01:30:21.340]   I don't have to book conference rooms. Do you have to book conference rooms? Stacy
[01:30:21.340 --> 01:30:24.860]   Yes, we we
[01:30:24.860 --> 01:30:31.340]   Like i'm gonna work in the kitchen. No, I'm gonna work in the kitchen. I'm really happy not to have to book conference rooms
[01:30:31.340 --> 01:30:36.140]   Um, so all right. Yeah, it's very you know, that's that's part of the problem
[01:30:36.140 --> 01:30:40.300]   You nailed it is the problem with a lot of google stuff. It's designed for googlers
[01:30:41.020 --> 01:30:42.300]   I
[01:30:42.300 --> 01:30:44.460]   Except for the cupcakes
[01:30:44.460 --> 01:30:46.940]   No, no tiny cupcakes
[01:30:46.940 --> 01:30:54.060]   That feels kind of like somebody who likes cupcakes. That would be good. Googlers. So my new jobs. They're the new donuts. What Jeff?
[01:30:54.060 --> 01:30:57.260]   My new job. I want to be a personality designer
[01:30:57.260 --> 01:31:03.260]   What a design personalities you can design my personality help me. That's the thing. I need somebody to design mine
[01:31:03.260 --> 01:31:08.700]   I'm a designer personality. Google has a job description of personality designers
[01:31:09.260 --> 01:31:10.780]   I
[01:31:10.780 --> 01:31:13.900]   I just kind of love that. Oh for your love that
[01:31:13.900 --> 01:31:17.740]   For your assistant
[01:31:17.740 --> 01:31:22.700]   Oh, well that makes sense. They want somebody has to design that. They're gonna teach you guys a wallie
[01:31:22.700 --> 01:31:24.380]   job
[01:31:24.380 --> 01:31:25.900]   Yeah
[01:31:25.900 --> 01:31:29.180]   This this actually so this this article when you read it though
[01:31:29.180 --> 01:31:35.740]   Um, it's basically a group of people who are trying to anticipate what people want from google assistant
[01:31:35.820 --> 01:31:39.180]   Which sounds like a terrible job in some ways because
[01:31:39.180 --> 01:31:42.860]   You know the audience you'll fail infinite almost
[01:31:42.860 --> 01:31:45.340]   Yes
[01:31:45.340 --> 01:31:48.380]   You know, I wish they designed a personality for my refrigerator
[01:31:48.380 --> 01:31:51.340]   Oh
[01:31:51.340 --> 01:31:53.500]   What do you want that personality to be? Schooled in
[01:31:53.500 --> 01:31:57.340]   Oh, so you want to talk about the samson first
[01:31:57.340 --> 01:31:59.500]   Bixby is
[01:31:59.500 --> 01:32:02.300]   I'm getting bixby in my samson fridge
[01:32:03.900 --> 01:32:05.420]   Right
[01:32:05.420 --> 01:32:08.140]   So that's not so I thought this is related because
[01:32:08.140 --> 01:32:10.460]   So samson
[01:32:10.460 --> 01:32:14.940]   They had their developers conference today and they're putting bixby in the fridge and
[01:32:14.940 --> 01:32:18.300]   Well, my fridge have a bixby button like my phone
[01:32:18.300 --> 01:32:24.300]   It's right next to the smart the smart hub or the family hub giant screen that they've got
[01:32:24.300 --> 01:32:27.500]   Not just they're not just gonna put it in refrigerators. You're gonna put it everywhere
[01:32:27.500 --> 01:32:28.940]   everywhere
[01:32:28.940 --> 01:32:30.700]   everywhere
[01:32:30.700 --> 01:32:37.340]   So I added that story because I feel like in samson's falling into this and a lot of companies fall into this
[01:32:37.340 --> 01:32:41.500]   When we decide to add intelligence to products in the home
[01:32:41.500 --> 01:32:43.820]   We are
[01:32:43.820 --> 01:32:49.580]   Dumb about it. So first we were like, oh, we're gonna add technology and smarts. That means a screen
[01:32:49.580 --> 01:32:52.460]   Right now. We're like that means a voice assistant right
[01:32:52.460 --> 01:32:55.260]   Very good point
[01:32:55.260 --> 01:32:57.100]   Because that's what we know
[01:32:57.100 --> 01:33:00.300]   So what would you do you you like this barcode reader in a fridge
[01:33:00.300 --> 01:33:04.140]   So the barcode reader was just like getting it online because that is a huge
[01:33:04.140 --> 01:33:04.860]   That's also a problem
[01:33:04.860 --> 01:33:10.140]   But what I loved about it was this fridge collects like 122 pieces of data and only two of them
[01:33:10.140 --> 01:33:14.220]   Are actually consumer facing the rest goes back to kenmore
[01:33:14.220 --> 01:33:21.260]   Because they want to be able to fix things when they go wrong and have the right parts and that's actually yeah
[01:33:21.260 --> 01:33:24.460]   Yeah, is this world changing? Are you gonna notice it as a consumer?
[01:33:25.340 --> 01:33:29.580]   Only if your fridge breaks and the person comes with the right part, but isn't that awesome?
[01:33:29.580 --> 01:33:37.180]   Yes, because I've had my fridge break and the problem with fridge breaking is you lose all your food and the longer it goes the worse it gets
[01:33:37.180 --> 01:33:40.700]   And the guy comes and he says well, I think your compressor died
[01:33:40.700 --> 01:33:46.140]   You know after tinkering with it because he didn't he didn't know and then I said well. Do you have one?
[01:33:46.140 --> 01:33:48.620]   No
[01:33:48.620 --> 01:33:50.620]   That's not good news
[01:33:50.620 --> 01:33:53.180]   So this is where i'm like
[01:33:53.980 --> 01:33:56.300]   Come on guys. We don't have to add
[01:33:56.300 --> 01:33:59.580]   Like a computer to everything. We just have to use
[01:33:59.580 --> 01:34:06.540]   Computing to make it smart useful. Yeah better. Yeah, so yeah, I don't want to I agree with you
[01:34:06.540 --> 01:34:08.860]   No, that's a very good announcement. I don't want to talk to my fridge
[01:34:08.860 --> 01:34:13.100]   On the other hand if the fridge could buy itself read barcodes and know
[01:34:13.100 --> 01:34:18.540]   What's in it and uh help me order like make a shopping list ahead of time
[01:34:18.540 --> 01:34:21.260]   We're getting there though a lot of my recipe programs
[01:34:22.060 --> 01:34:27.180]   If I tell it what I have will make a recipe the next step would be for it to know what I have automatically
[01:34:27.180 --> 01:34:32.300]   I don't want to turn my house into like a las vegas mini bar
[01:34:32.300 --> 01:34:35.180]   Where every time you remove something
[01:34:35.180 --> 01:34:41.500]   Or when you remove it it goes to your google maps and tells you how long you have to watch
[01:34:41.500 --> 01:34:47.660]   You know why that's why we nipped that tiny cupcakes in the bud because that was the next there you go
[01:34:48.620 --> 01:34:53.660]   I see you just ate a giant crispy cream leo. How about we take a walk now?
[01:34:53.660 --> 01:34:57.020]   Not gonna open your car
[01:34:57.020 --> 01:35:03.900]   Not gonna open your car. I'm not gonna open the refrigerator. Sorry. Sorry. We'll be locked for the next 48 hours. Dave
[01:35:03.900 --> 01:35:06.780]   Dave. I'm sorry. Dave
[01:35:06.780 --> 01:35:14.380]   Here's uh, oh, go ahead. Oh, go. I was just looking at the comments and someone was talking about making a grocery list
[01:35:14.380 --> 01:35:18.460]   Um with a voice activated fridge, which feels like a great idea
[01:35:18.460 --> 01:35:23.100]   That in today's closed ecosystems. Yeah, it's I had that uh amazon wand
[01:35:23.100 --> 01:35:26.700]   Yeah, it's still stuck there on my fridge. I never use it
[01:35:26.700 --> 01:35:33.900]   You know you scan the barcodes. You can make up a shopping list never use it. You know why I don't eat food with barcodes on it
[01:35:33.900 --> 01:35:37.820]   In fact, that's leo's new diet
[01:35:37.820 --> 01:35:40.780]   Fewer barcodes
[01:35:40.780 --> 01:35:45.020]   You shouldn't eat foods with this is easy. This is easy. Don't eat foods that have barcodes
[01:35:45.020 --> 01:35:47.740]   Right because those are manufactured
[01:35:48.700 --> 01:35:50.700]   Fresh food don't have barcodes
[01:35:50.700 --> 01:35:54.700]   Pizza doesn't have barcodes
[01:35:54.700 --> 01:36:01.340]   What pizza? I have a frozen pizza that is uh fruit and produce there they've got numbers not barcodes
[01:36:01.340 --> 01:36:03.900]   You shouldn't have you shouldn't have barcodes on your food
[01:36:03.900 --> 01:36:07.500]   New bill. I love this. I know
[01:36:07.500 --> 01:36:10.300]   Yeah, you live in New York. Everything's barcoded
[01:36:10.300 --> 01:36:15.260]   Uh, yeah, tom graves. Well, see my tattoo. You have a barcode tattoo
[01:36:16.060 --> 01:36:18.060]   Oh, that's a great idea
[01:36:18.060 --> 01:36:22.860]   Would be what number would you put it now would be it would be a watchmakald code
[01:36:22.860 --> 01:36:25.020]   Um social security
[01:36:25.020 --> 01:36:28.300]   Q away. Yeah, put a QR code on your cheek qr. Yeah
[01:36:28.300 --> 01:36:32.140]   I think it's uh in preparation for the future
[01:36:32.140 --> 01:36:36.140]   Mm-hmm. Yeah, I for one welcome my new masters
[01:36:36.140 --> 01:36:39.980]   Although a couple of major security issues
[01:36:40.780 --> 01:36:47.980]   One is uh the infinion chip that's used in a lot of devices to generate public keys public and private keys and crypto
[01:36:47.980 --> 01:36:50.940]   Apparently has a major flaw. It's called the roka
[01:36:50.940 --> 01:36:52.860]   flaw
[01:36:52.860 --> 01:36:57.740]   and uh many uh devices that generate like pin chips and
[01:36:57.740 --> 01:37:01.740]   Uh, the worst thing is your tpm chip and your laptop
[01:37:01.740 --> 01:37:04.300]   Um, this is you know, uh
[01:37:04.300 --> 01:37:08.300]   These are the estonian id cards that I was all excited about
[01:37:09.340 --> 01:37:12.700]   Uh, the problem is they're using these infinionships which are crackable
[01:37:12.700 --> 01:37:16.380]   And so your public key is uh is breakable
[01:37:16.380 --> 01:37:19.660]   Estonia's government
[01:37:19.660 --> 01:37:26.620]   Warned that 750 000 digital id's I i'm really glad i didn't get one issued since 2014 are vulnerable to attack
[01:37:26.620 --> 01:37:33.020]   Because they use this infinion chip many tpm modules and pcs use the infinion chip
[01:37:33.020 --> 01:37:37.500]   So if you were to put a barcode on your head with your public key
[01:37:38.220 --> 01:37:40.780]   Which it seems on the face of it to be a very good idea
[01:37:40.780 --> 01:37:44.540]   And you might you might regret it
[01:37:44.540 --> 01:37:48.300]   You have to amend it
[01:37:48.300 --> 01:37:53.420]   The roka, uh, does not affect software generated pgp keys for instance. I checked all my uh,
[01:37:53.420 --> 01:37:59.980]   pgp keys, uh, they were all generated by open gpg and no problem at all there is a
[01:37:59.980 --> 01:38:01.820]   roka
[01:38:01.820 --> 01:38:04.460]   We talked about this insecurity now yesterday if you want the you know
[01:38:05.020 --> 01:38:10.620]   High-end details and there is a site to test whether your keys are flawed
[01:38:10.620 --> 01:38:13.900]   um
[01:38:13.900 --> 01:38:15.420]   Let's see if I can
[01:38:15.420 --> 01:38:17.260]   find that
[01:38:17.260 --> 01:38:21.260]   So I can give you the it was down the other day a key chest dot net
[01:38:21.260 --> 01:38:25.580]   Key chest dot net slash roca
[01:38:25.580 --> 01:38:28.940]   So you copy the public key to the clipboard
[01:38:29.980 --> 01:38:37.340]   And it will tell you if there's an issue it takes x five and nine certificates ssh keys rsa pem keys
[01:38:37.340 --> 01:38:44.860]   pgp public keys raw rsa modulus keys or s mime keys actually have an s mime queue. I should check in there too
[01:38:44.860 --> 01:38:51.180]   The other vulnerabilities really even scarier although steve talked me off
[01:38:51.180 --> 01:38:54.460]   the ledge on the crack attack
[01:38:56.140 --> 01:39:01.180]   Key reinstallation attacks breaking w to p a two by force matti van huff
[01:39:01.180 --> 01:39:04.620]   a security researcher discovered this attack
[01:39:04.620 --> 01:39:11.500]   It is uh, it is so so let's be I want to be really clear about this is steve schooled me yesterday on security now
[01:39:11.500 --> 01:39:13.980]   This is really an attack
[01:39:13.980 --> 01:39:16.140]   not on base stations
[01:39:16.140 --> 01:39:23.580]   But on devices that join base stations in other words iot devices are one of the
[01:39:24.620 --> 01:39:27.020]   Places that would be vulnerable any laptop
[01:39:27.020 --> 01:39:31.260]   vulnerable any uh phone potentially vulnerable
[01:39:31.260 --> 01:39:36.060]   So that you don't necessarily need a patch for your uh, Wi-Fi access point
[01:39:36.060 --> 01:39:41.740]   Although if you have a mesh router a Wi-Fi access point that joins other Wi-Fi access points to share data
[01:39:41.740 --> 01:39:46.380]   Then you would want to get an update euro is working on an update that's out in beta right now
[01:39:46.380 --> 01:39:48.700]   I imagine all the other mesh routers are doing the same
[01:39:48.700 --> 01:39:54.060]   The real issue is that there are so many iot devices that will never be updated plus many
[01:39:55.020 --> 01:39:56.540]   Android devices
[01:39:56.540 --> 01:40:00.460]   Uh, the estimate is 41 percent of all android devices ironically
[01:40:00.460 --> 01:40:05.660]   iOS and windows did in improperly implemented
[01:40:05.660 --> 01:40:11.660]   uh, the uh, wpa2 protocol and are not vulnerable because they blew it
[01:40:11.660 --> 01:40:18.700]   They didn't do it right. Maybe maybe they knew what they were doing. Uh, nevertheless my apple is pushing out a fix for that
[01:40:18.700 --> 01:40:21.420]   so, um
[01:40:22.140 --> 01:40:27.180]   God, this was scary news when it came out on monday. I mean when I read it and i because we have told everybody for years
[01:40:27.180 --> 01:40:30.140]   like 11 years
[01:40:30.140 --> 01:40:38.060]   Uh, don't use web encryption on your Wi-Fi router that's broken but wpa2 especially if you use aes is really safe
[01:40:38.060 --> 01:40:45.180]   That's what you should use everybody should turn it on protect yourself and your router and then to wake up monday morning and find out
[01:40:45.180 --> 01:40:47.180]   Oh, actually it's crackable
[01:40:47.180 --> 01:40:49.020]   Is not you know what?
[01:40:49.020 --> 01:40:51.100]   Everything's crackable. It's hard to do
[01:40:51.100 --> 01:40:54.220]   It's not an easy thing to do. So it's not and you have to be
[01:40:54.220 --> 01:41:01.660]   Proximate because it's using the handshake. Yes. You've got to be near. Um, I will give you just because we've got it
[01:41:01.660 --> 01:41:05.180]   Um, I reached out to a bunch of companies many linux
[01:41:05.180 --> 01:41:07.820]   Distros have already been updated
[01:41:07.820 --> 01:41:13.500]   Actually, there was a little bit of a confuffle because free bsd knew about this months ago and they updated prematurely and everybody was mad
[01:41:13.500 --> 01:41:16.860]   Because they broke the embargo, but they I think said quite credibly
[01:41:18.220 --> 01:41:23.660]   This is a very long period of time we had a wait and we think people are going to be vulnerable. So we're going to fix it now
[01:41:23.660 --> 01:41:28.540]   It was funny that your voice started cracking when you said everything's crackable
[01:41:28.540 --> 01:41:33.100]   Everything's crackable. Am I am I less cracking now? You're fixed it. Yes
[01:41:33.100 --> 01:41:37.340]   So this was this on your show you did the list of people
[01:41:37.340 --> 01:41:44.700]   We did we talked to so tomorrow morning you can find out or I can tell you a couple of the big ones here because you know
[01:41:44.700 --> 01:41:47.580]   Why keep information close to the best? I don't believe in that
[01:41:48.540 --> 01:41:52.220]   Um, so nest is rolling out a patch. Yep. So all of you guys
[01:41:52.220 --> 01:41:53.820]   Um
[01:41:53.820 --> 01:41:59.980]   Amazon is looking at it to eventually fix it all the echoes will have to be patched absolutely
[01:41:59.980 --> 01:42:01.020]   Yes
[01:42:01.020 --> 01:42:06.540]   Um and things like your kindle although, you know, I don't know if you really care about that data getting sent
[01:42:06.540 --> 01:42:10.380]   You mentioned google so google wifi google home all of that stuff
[01:42:10.380 --> 01:42:16.620]   Um, I did also reach out to june and I haven't heard back yet. So I don't know if my june oven is going to get patched
[01:42:17.420 --> 01:42:19.420]   Well, how much
[01:42:19.420 --> 01:42:22.540]   So so so so
[01:42:22.540 --> 01:42:26.140]   I'm like if I don't want your cooking. Yeah, they'd be like oh stacy
[01:42:26.140 --> 01:42:32.380]   Imagine how creepy I would totally do this to like prank someone actually stand outside your house and get in there and be like
[01:42:32.380 --> 01:42:34.780]   Leo it looks like your chickens
[01:42:34.780 --> 01:42:38.060]   Wouldn't mind. I'd say thank you. Let me go get that
[01:42:38.060 --> 01:42:45.260]   Yes, hey, how are we be worse if you said I noticed you're cooking cupcakes. You might want to take a walk tonight
[01:42:46.220 --> 01:42:49.820]   That I would you know, well, yeah, that would be kind of a jerk
[01:42:49.820 --> 01:42:52.300]   Rager alert
[01:42:52.300 --> 01:42:55.500]   Um, we should talk about me too. I think
[01:42:55.500 --> 01:42:58.460]   What what about you?
[01:42:58.460 --> 01:43:07.180]   No, the hashtag me too hashtag me too. Okay. Uh, I'm not familiar with that. Is that uh, well, you're not
[01:43:07.180 --> 01:43:12.460]   You're not oh, this is the
[01:43:12.460 --> 01:43:17.020]   Vi is this the viral Weinstein. This is the one like I I was I was harassed as well
[01:43:17.020 --> 01:43:24.940]   Yes, and and I was I was I woke up in a different time zone and and just saw my feed just completely and horrifyingly filled with
[01:43:24.940 --> 01:43:30.220]   I think that's a good thing. No one respects. Don't you think that's a very good thing. It says we all know people
[01:43:30.220 --> 01:43:35.980]   It just shows you and you can't hide it. I mean, yeah, I think it's really important that uh people step forward
[01:43:35.980 --> 01:43:40.380]   They don't have to say the details, but just say no, this is this is
[01:43:41.260 --> 01:43:45.340]   Ubiquitous some shows to tell horrifying stories and but Stacy
[01:43:45.340 --> 01:43:48.220]   Just because I called you honey once
[01:43:48.220 --> 01:43:50.940]   Please don't use the me too on me
[01:43:50.940 --> 01:43:55.580]   Um, I have my me too's but everybody has because you call me honey
[01:43:55.580 --> 01:44:01.580]   It's not related to me. I hope but everybody everybody every woman has a me too
[01:44:01.580 --> 01:44:07.420]   And I guess I imagine there are many men who happen as well. Oh, I've seen men in my feet as well. Yes
[01:44:07.980 --> 01:44:15.020]   But I think it was you know, it was at this time when people are blaming everything on social media and blaming everything on twitter and facebook
[01:44:15.020 --> 01:44:16.700]   This is a good thing
[01:44:16.700 --> 01:44:19.020]   This was a powerful powerful message
[01:44:19.020 --> 01:44:25.180]   Yeah, that said people you know and love and respect have been affected by this and it's not something that's just happening in the hollywood
[01:44:25.180 --> 01:44:28.460]   It's not something that's just happening in the white house. It's something that's happening next door to you
[01:44:28.460 --> 01:44:34.060]   and uh, I think that was i'll be eager to hear Stacy's take but I think that that it was a
[01:44:34.460 --> 01:44:40.620]   Powerful way for people to say this is bigger than you know, it's closer than you know, and it's not just hollywood
[01:44:40.620 --> 01:44:43.660]   It's not just the white house. It's everywhere. Yeah
[01:44:43.660 --> 01:44:48.460]   So that's a guy talking. I don't know Stacy if you want to talk about it or not
[01:44:48.460 --> 01:44:51.100]   Stacy say something. Yeah
[01:44:51.100 --> 01:44:53.100]   I don't want to talk about it. I
[01:44:53.100 --> 01:44:55.500]   It's a thing
[01:44:55.500 --> 01:44:57.020]   Yeah, that's fine
[01:44:57.020 --> 01:45:02.540]   Uh, but I think just I think it's something we that happened this week that I think we would be remiss if we didn't note it
[01:45:03.020 --> 01:45:05.980]   On the show that was a but well and the reason is I think
[01:45:05.980 --> 01:45:09.580]   We talked so much about all the bad things twitter does
[01:45:09.580 --> 01:45:17.340]   But that is an example of how twitter and social media in general can also be a very powerful tool. People can use it. Yeah, importantly. Yeah
[01:45:17.340 --> 01:45:24.060]   Uh now at the same time twitter enables uh, harassment of them and uh, that's melania
[01:45:24.060 --> 01:45:29.260]   She's just in between college and injections. Look that's melania. No, I swear to god
[01:45:31.100 --> 01:45:33.100]   She's just in between
[01:45:33.100 --> 01:45:38.540]   I don't think people really think it's not melania. Oh, it's just fun to pretend
[01:45:38.540 --> 01:45:42.860]   I I assumed we were all just joking about it, right?
[01:45:42.860 --> 01:45:46.380]   Oh my god, I don't know if it's real or not
[01:45:46.380 --> 01:45:52.460]   As I was reading on in the you might think he's a great is pretty absurd as well, right?
[01:45:52.460 --> 01:45:55.020]   Oh, they must just have been joking
[01:45:55.020 --> 01:45:57.340]   Till they come with a gun to investigate
[01:45:59.180 --> 01:46:02.860]   Um, all right moving on new bill would allow hacking fixums
[01:46:02.860 --> 01:46:06.140]   to hack back
[01:46:06.140 --> 01:46:09.420]   This is so horrible. Tom graves republican of georgia
[01:46:09.420 --> 01:46:12.700]   Kirsten sinema democrat of arizona
[01:46:12.700 --> 01:46:20.380]   Introduced acdc the acdc act stands for active cyber defense certainty
[01:46:20.380 --> 01:46:23.180]   Act that's the best they could do
[01:46:23.420 --> 01:46:30.860]   And i-o for an i-o yeah, the idea is if you would empower individuals and companies to use new defenses against cyber criminals
[01:46:30.860 --> 01:46:33.260]   if somebody hacks you
[01:46:33.260 --> 01:46:38.540]   You could hack them back. It doesn't allow counter attacks to destroy anything other than their own stolen files
[01:46:38.540 --> 01:46:45.260]   And if you're hacking back you have to notify the fbi cyber investigative joint task force
[01:46:45.260 --> 01:46:49.260]   This is such a bad idea
[01:46:50.700 --> 01:46:53.740]   I assume this is there's just no way this can become a law
[01:46:53.740 --> 01:46:55.980]   but
[01:46:55.980 --> 01:46:57.980]   I don't know. I don't know
[01:46:57.980 --> 01:47:00.540]   Yep
[01:47:00.540 --> 01:47:01.900]   like
[01:47:01.900 --> 01:47:03.900]   Hack them back
[01:47:03.900 --> 01:47:09.740]   I did see so you had a story actually in there about and I hadn't seen this yet
[01:47:09.740 --> 01:47:11.740]   So I was kind of like oh fun
[01:47:11.740 --> 01:47:17.020]   this uh guy running for is it senate who basically wants to let people
[01:47:18.700 --> 01:47:21.900]   Tell him how to vote and he's gonna vote that way even stupider
[01:47:21.900 --> 01:47:25.020]   It's the ultimate. It's gonna happen. You know what's gonna happen?
[01:47:25.020 --> 01:47:27.740]   We're gonna rename america
[01:47:27.740 --> 01:47:29.260]   america
[01:47:29.260 --> 01:47:31.260]   Mcamerica face
[01:47:31.260 --> 01:47:32.380]   Yes
[01:47:32.380 --> 01:47:35.180]   Sure. What has ever gone wrong with internet voting?
[01:47:35.180 --> 01:47:37.820]   Exactly
[01:47:37.820 --> 01:47:45.900]   So wow, I didn't know about this either. This is good. I think karsten you must have found this or maybe maybe jeff added it
[01:47:46.380 --> 01:47:50.540]   No, I didn't that's like the karsten story. So that's um
[01:47:50.540 --> 01:47:54.460]   Uh, let me let me find this is an and motherboard and vice
[01:47:54.460 --> 01:47:59.500]   Let me find the uh the article. Oh, it's a city council member. That's who it was
[01:47:59.500 --> 01:48:04.380]   So it's municipal. So that's actually kind of fun for like really truly local things
[01:48:04.380 --> 01:48:08.780]   Although I would say citizens don't always understand the impact of their votes
[01:48:08.780 --> 01:48:13.260]   This is a good game. This is so this is so bolder
[01:48:14.300 --> 01:48:15.740]   Camilo
[01:48:15.740 --> 01:48:19.820]   So bolder camilo casas is running for city council in boulder, Colorado
[01:48:19.820 --> 01:48:21.980]   I know bolder pretty when my son went to college there
[01:48:21.980 --> 01:48:25.820]   He has a an app called party dot vote
[01:48:25.820 --> 01:48:31.260]   a liquid democracy platform for participatory municipal governance
[01:48:31.260 --> 01:48:35.900]   Maybe you think this is a liquid democracy is the is the buzz buzz phrase out of a fit
[01:48:35.900 --> 01:48:41.740]   Iceland, right this might work in at a at a local level better, right? I don't know
[01:48:42.860 --> 01:48:45.580]   that's I mean, I'm kind of like i've been thinking about it because I've
[01:48:45.580 --> 01:48:49.980]   I mean, but then I think about like we just the big local drama for us
[01:48:49.980 --> 01:48:53.580]   One is a giant zoning fight and those are always fun
[01:48:53.580 --> 01:48:58.220]   But then there's also they installed speed humps on a road near me and holy cow
[01:48:58.220 --> 01:49:03.420]   Everyone is very passionate, you know, the people live on the road are like, yes speed humps
[01:49:03.420 --> 01:49:07.900]   No one will run over my children and everyone else who drives on the road is like screw you all in your children
[01:49:07.900 --> 01:49:11.980]   You have made our can be our commute so less and look so much less convenient
[01:49:12.460 --> 01:49:14.460]   so it's kind of
[01:49:14.460 --> 01:49:19.740]   Well, like I would like to see those played out in an app it would take 51 percent of the votes to change it, right?
[01:49:19.740 --> 01:49:22.780]   I don't know if that's I don't know. I think we should try it
[01:49:22.780 --> 01:49:26.700]   he says he doesn't expect to win he his goal is just to
[01:49:26.700 --> 01:49:34.060]   Tell people about liquid democracy into a to show off this party dot vote, which is open source and free
[01:49:34.060 --> 01:49:41.660]   He says later on he'd like to create a political party that will support any candidate as long as they commit to make decisions based on what their citizens want
[01:49:42.460 --> 01:49:44.780]   I think this is the big problem, right?
[01:49:44.780 --> 01:49:47.580]   Democracy isn't perfect
[01:49:47.580 --> 01:49:52.140]   Representative democracy seems like a good idea until you get to the electoral college then you go well
[01:49:52.140 --> 01:49:57.180]   What was that about democracy again one man one vote one person one vote
[01:49:57.180 --> 01:50:02.700]   One person one hack one person one hack
[01:50:02.700 --> 01:50:11.580]   So I really liked that essential phone. I thought it was pretty I felt bad for Andy Rubin the creator of android that he had so many
[01:50:11.580 --> 01:50:19.820]   Stumbles so many problems could it get it out the door then they inadvertently spammed people with other people's addresses and now they're getting sued
[01:50:19.820 --> 01:50:24.300]   By kisa
[01:50:24.300 --> 01:50:28.380]   Misa you say kisa a wireless technology company backed by
[01:50:28.380 --> 01:50:31.260]   Nest founder tony fidel. Oh
[01:50:31.260 --> 01:50:38.620]   They sued essential on monday saying well, so what happened was we engaged in conversations with essential
[01:50:39.420 --> 01:50:47.180]   In which we divulged to them proprietary technology about our wireless connectivity a little trick that lets you
[01:50:47.180 --> 01:50:50.940]   Transfer large files by holding two devices side by side
[01:50:50.940 --> 01:50:58.060]   Well, this is the uwb stuff the 60 gigahertz transfer. I guess so even did you ever talk to them?
[01:50:58.060 --> 01:51:05.420]   No, I just I felt like we talked about this on essential. Let's see. Okay. Keep talking all of which is protected under an nda
[01:51:05.500 --> 01:51:13.100]   Non-disclosure agreement the pseudo ledges that kisa deployed a team of 20 top engineers and scientists to educate essential on its proprietary
[01:51:13.100 --> 01:51:19.660]   Text sending them thousands of confidential emails hundreds of confidential technical documents dozens of confidential
[01:51:19.660 --> 01:51:22.380]   Presentations after 10 months
[01:51:22.380 --> 01:51:26.620]   Essential said never mind. We're going to use somebody else's chip
[01:51:26.620 --> 01:51:34.140]   But kisa's saying they used our techniques in their phone techniques they gleaned from our relationship despite the confidentiality
[01:51:35.100 --> 01:51:37.100]   agreement one more blow
[01:51:37.100 --> 01:51:41.420]   To essential, but the good news is it's only sold 5,000 phones. So
[01:51:41.420 --> 01:51:48.220]   It's actually you know what the all the reviewers knocked the camera. This is why I don't do
[01:51:48.220 --> 01:51:52.140]   I hate to do reviews on pre production stuff
[01:51:52.140 --> 01:51:55.660]   And I'd far prefer to do reviews after a week or two
[01:51:55.660 --> 01:52:02.060]   Essential pushed out a number of updates which fixed the camera. It actually all works really nicely now. It's a beautiful little phone
[01:52:02.460 --> 01:52:04.460]   I wish it had a headphone jack
[01:52:04.460 --> 01:52:11.580]   And I wish they sold more than 5,000 because that means they'll never be any other accessories or you know that the little connector that they use
[01:52:11.580 --> 01:52:13.820]   I think that's the kisa technologies that connector
[01:52:13.820 --> 01:52:16.940]   Oh, nobody's gonna do more of that
[01:52:16.940 --> 01:52:19.340]   oh
[01:52:19.340 --> 01:52:25.260]   I am not saying that they're that kisa's writer essentials right on this, but it's just one more thing
[01:52:25.260 --> 01:52:27.740]   what just piling on one more
[01:52:27.740 --> 01:52:32.060]   Problem for Andy Ruben's essential. Do you think they'll do uh stacey the home?
[01:52:32.780 --> 01:52:34.780]   Hub that they promised
[01:52:34.780 --> 01:52:36.300]   Uh
[01:52:36.300 --> 01:52:41.340]   They were they were supposed to talk about it in november so they might I mean if that's his real money
[01:52:41.340 --> 01:52:44.460]   Yes
[01:52:44.460 --> 01:52:46.380]   Yeah
[01:52:46.380 --> 01:52:47.660]   It's bad
[01:52:47.660 --> 01:52:52.380]   The home is actually ripe for some interesting things. I gotta be honest because now everybody
[01:52:52.380 --> 01:52:58.380]   I talked to somebody who does an iot device. They said it's really hard to work with apple on home kit
[01:52:58.780 --> 01:53:04.620]   And they oh my god. Yes, that is so true. That's what everybody says. Yeah, and they far prefer to work with amazon amazon's easy
[01:53:04.620 --> 01:53:11.820]   Uh amazon's starting to tighten the screws a little bit according to the people I talked to but it's still way way
[01:53:11.820 --> 01:53:14.300]   Way easier and
[01:53:14.300 --> 01:53:17.420]   apple is just apples difficult because
[01:53:17.420 --> 01:53:26.220]   They were trying to create a perfect ecosystem. They took longer. They had some technical difficulties early on and then now they just
[01:53:28.220 --> 01:53:34.780]   They want to control more of the onboarding and access to the app
[01:53:34.780 --> 01:53:38.060]   So they want to kind of make it so you don't have to have all these apps on your phone, which
[01:53:38.060 --> 01:53:42.780]   Is awesome for the consumer, but the guy is making the stuff or kind of like
[01:53:42.780 --> 01:53:45.020]   Uh, I'm sorry. What do I get out of this?
[01:53:45.020 --> 01:53:48.780]   Just selling a whole bunch of hardware because that's not going to work for me
[01:53:48.780 --> 01:53:53.980]   I I don't know. It's a matter of people should listen to stacey on iot
[01:53:54.300 --> 01:53:58.300]   We're actually subscribed to newsletter. Listen to the iot podcast because this is a this is a
[01:53:58.300 --> 01:54:03.420]   Sector and total flux and you don't want to invest a lot of money in the dead end
[01:54:03.420 --> 01:54:08.380]   I did buy those sylvania those new sylvania bulbs with zigbee in them
[01:54:08.380 --> 01:54:11.260]   Zigbee or bluetooth zigbee
[01:54:11.260 --> 01:54:13.100]   Okay
[01:54:13.100 --> 01:54:21.980]   Um, are you going to buy the or did you order the amazon echo plus which also has zigbee in x as a home hub or do you have your own zigbee hub?
[01:54:23.180 --> 01:54:25.180]   Uh
[01:54:25.180 --> 01:54:28.060]   Lios like I don't know
[01:54:28.060 --> 01:54:30.860]   Echo plus, huh? I guess I get better get that real soon
[01:54:30.860 --> 01:54:33.900]   So you need a zigbee hub?
[01:54:33.900 --> 01:54:36.780]   Yes, otherwise your zigbee lights are not going to work
[01:54:36.780 --> 01:54:39.420]   Uh, huh
[01:54:39.420 --> 01:54:44.620]   They will either come with a hub now. Sylvania makes a bluetooth bulb that will work with your phone
[01:54:44.620 --> 01:54:47.820]   And then you don't need a hub
[01:54:47.820 --> 01:54:52.220]   But I want to be able to control everything with echo right that's really the goal, isn't it?
[01:54:53.020 --> 01:54:55.020]   Well, you can
[01:54:55.020 --> 01:55:02.060]   So this comes out halloween 150 bucks. It's the echo silver that we saw on saturday night live
[01:55:02.060 --> 01:55:06.700]   Can I say anastasia turn off the lights?
[01:55:06.700 --> 01:55:09.660]   Alexandria
[01:55:09.660 --> 01:55:14.220]   I will say that mine is coming and that's right before the show, but I guess you're not going to be there
[01:55:14.220 --> 01:55:18.300]   So i'll be here and i'll show us i'll order it. I'm going to order right now
[01:55:18.300 --> 01:55:21.740]   It says it'll come on tuesday october 31st. Yeah
[01:55:22.380 --> 01:55:25.820]   Yes, right before the show and i'm also getting that new
[01:55:25.820 --> 01:55:29.580]   Kindle that day halloween's going to be a big day
[01:55:29.580 --> 01:55:31.740]   trick or treat
[01:55:31.740 --> 01:55:33.740]   trick or treat smell my feet
[01:55:33.740 --> 01:55:39.340]   Uh, let's take a break come back with picks because I want to wrap this puppy up put a ribbon on it
[01:55:39.340 --> 01:55:43.420]   Our show today literally brought to you by sonic
[01:55:43.420 --> 01:55:50.620]   Our internet service provider we have this is this is such a luxury 10 gigabit
[01:55:51.580 --> 01:55:53.020]   fiber
[01:55:53.020 --> 01:55:54.140]   to our
[01:55:54.140 --> 01:55:55.500]   switchroom
[01:55:55.500 --> 01:56:00.940]   From sonic the world's best in it. Well at least america's best internet service provider
[01:56:00.940 --> 01:56:07.500]   It's pretty clear. I think anybody listens to this show and pays attention that the internet infrastructure in the United States is a mess
[01:56:07.500 --> 01:56:12.140]   It's a mess too many people paying too much for terrible cable internet
[01:56:12.140 --> 01:56:14.060]   sonic
[01:56:14.060 --> 01:56:19.340]   wants to do it right now. This is the bad news. They're not available everywhere. In fact, they're really only available in
[01:56:19.900 --> 01:56:21.900]   the northern california area
[01:56:21.900 --> 01:56:26.460]   So I feel really guilty telling you about this but but but I use it as a data point
[01:56:26.460 --> 01:56:30.780]   You should know because it's possible for them to make a very a very good little business
[01:56:30.780 --> 01:56:34.620]   at a delivering you gigabit to your door
[01:56:34.620 --> 01:56:37.660]   fiber to the premise
[01:56:37.660 --> 01:56:43.260]   15 email accounts a gigabyte of storage personal web hosting with a new domain
[01:56:43.260 --> 01:56:47.340]   phone service with unlimited local and long distance calling
[01:56:47.900 --> 01:56:49.900]   fax service
[01:56:49.900 --> 01:56:55.420]   And again gigabit internet all for 40 dollars a month and by the way
[01:56:55.420 --> 01:56:58.540]   No bandwidth caps
[01:56:58.540 --> 01:57:02.860]   Friendly and local customer support and they stand up for your privacy
[01:57:02.860 --> 01:57:08.620]   Green checks across the line from the electronic frontier foundation. This is one of the best ISPs in the country
[01:57:08.620 --> 01:57:16.620]   And it's ours sonic.com/twit sonic is very big in the wine country and
[01:57:17.260 --> 01:57:20.860]   There have been great pictures from their CEO dane jasper of the sonic technicians
[01:57:20.860 --> 01:57:27.180]   Rewiring all the vineyards all the homes lots of people who suffered horrific
[01:57:27.180 --> 01:57:30.060]   loss in the fires
[01:57:30.060 --> 01:57:34.060]   But their internet's coming back fast thanks to sonic. This is a great company
[01:57:34.060 --> 01:57:41.580]   Join the internet revolution see if you are eligible go to sonic.com/twit and receive your first month of sonic internet and phone service
[01:57:41.580 --> 01:57:46.460]   For free plus bundle it with dish. You'll save 120 dollars on your sonic bill
[01:57:47.420 --> 01:57:52.620]   Sonic.com/twit everybody should have internet service this good and I thank them so much
[01:57:52.620 --> 01:57:56.060]   For making you literally bringing these shows to you
[01:57:56.060 --> 01:58:02.620]   on our 10 gigabit symmetric link sonic.com/twit
[01:58:02.620 --> 01:58:05.740]   Stacy what do you got for us?
[01:58:05.740 --> 01:58:08.940]   Okay, I was going to show you
[01:58:08.940 --> 01:58:15.740]   The Amazon echo has now gives you voice prints so it will recognize people in your home
[01:58:16.700 --> 01:58:19.020]   And of course being me I tried this out
[01:58:19.020 --> 01:58:23.340]   So I am dismayed to tell you that it doesn't work so well so we're gonna try
[01:58:23.340 --> 01:58:26.700]   Because sometimes it works sometimes it doesn't
[01:58:26.700 --> 01:58:29.740]   Alexa who am I?
[01:58:29.740 --> 01:58:34.140]   I'm not sure who's speaking but you're in Stacy's account
[01:58:34.140 --> 01:58:36.460]   Damn it
[01:58:36.460 --> 01:58:37.980]   Alexa
[01:58:37.980 --> 01:58:39.980]   Who am I?
[01:58:39.980 --> 01:58:42.300]   I'm not sure who's speaking
[01:58:42.300 --> 01:58:45.980]   So how did you train it? Did you read a bunch of sentences because you could always do that right?
[01:58:45.980 --> 01:58:52.860]   Um, so you can read a bunch you read 10 sentences and then other people in your house. They have to log in on
[01:58:52.860 --> 01:58:59.820]   Their account, right and they read sentences. It's better recognizing my husband than I am or okay
[01:58:59.820 --> 01:59:02.700]   It's not better than I am. I can always recognize my husband
[01:59:02.700 --> 01:59:06.860]   But it's better at recognizing my husband as opposed to me
[01:59:06.860 --> 01:59:11.100]   So he's he's like nine times out of ten. I am currently batting like
[01:59:11.660 --> 01:59:14.380]   Is it 400? I'm bad. It's like four times out of ten
[01:59:14.380 --> 01:59:17.260]   so
[01:59:17.260 --> 01:59:20.540]   There we go. Oh, oh guys. I'm sorry. I set off your echoes
[01:59:20.540 --> 01:59:24.460]   You know what i'm really curious is if anybody
[01:59:24.460 --> 01:59:30.620]   In the in chat land if their echoes said you are stacy because that would be cool
[01:59:30.620 --> 01:59:33.740]   That would be terrifying
[01:59:33.740 --> 01:59:36.940]   Oh, you're stacy you live in austin, Texas
[01:59:38.060 --> 01:59:43.500]   You have a husband named andrew a dog named foodles. I know I forgot what your dog's name is
[01:59:43.500 --> 01:59:50.540]   That's okay. Foodles is a perfectly acceptable foodles is a great name that I just invented out of nowhere
[01:59:50.540 --> 01:59:53.260]   And I like it
[01:59:53.260 --> 01:59:58.460]   Someone wants to name their poodle foodles. Oh for it jeff jervis. Give us a number
[01:59:58.460 --> 02:00:03.660]   Well, I could cheat and say that any poll is a number and thus indeed
[02:00:04.460 --> 02:00:08.940]   Sweden has in fact officially named a train trainee Mc trainface
[02:00:08.940 --> 02:00:16.620]   Training really that's not his real name. I'm okay. They did it
[02:00:16.620 --> 02:00:23.340]   I did it my favorite part of that story. Hold on a second my favorite part of that story is that another leading candidate for the
[02:00:23.340 --> 02:00:25.500]   name
[02:00:25.500 --> 02:00:26.620]   in the poll
[02:00:26.620 --> 02:00:28.220]   was glen
[02:00:28.220 --> 02:00:33.340]   Because it's a long standing joke that everyone in gothenberg is named glen
[02:00:34.300 --> 02:00:38.140]   Glenn's good. Oh those Swedes, but trainee Mc trainface one
[02:00:38.140 --> 02:00:41.100]   They're the one and they're doing it the Swedes
[02:00:41.100 --> 02:00:48.540]   Unlike bordie McVolk face, which never really sailed. No, this is this is but anyway, I train
[02:00:48.540 --> 02:00:51.980]   It looks like trainee Mc trainface actually it does it does
[02:00:51.980 --> 02:00:55.420]   so
[02:00:55.420 --> 02:00:59.980]   For a real number piper jeffrey put out its semi-annual taking stock with teens research
[02:00:59.980 --> 02:01:02.780]   and said that um
[02:01:03.740 --> 02:01:10.700]   Teenagers in the survey 47 percent of them prefer snapchat as their favorite place to be I thought that was really
[02:01:10.700 --> 02:01:13.020]   percent. Yeah 24 percent
[02:01:13.020 --> 02:01:17.900]   Instagram
[02:01:17.900 --> 02:01:20.460]   9 Facebook
[02:01:20.460 --> 02:01:22.460]   and
[02:01:22.460 --> 02:01:24.460]   7 Twitter
[02:01:24.460 --> 02:01:27.740]   Now you can keep hearing the way
[02:01:28.540 --> 02:01:33.180]   That's a big growth for snapchat. So we'd heard that everybody's leaving snapchat, but not the teens
[02:01:33.180 --> 02:01:35.580]   It was from 39 to 47 percent
[02:01:35.580 --> 02:01:37.740]   since the last poll
[02:01:37.740 --> 02:01:42.060]   So that I thought that was really interesting and in fact that if I were snapchat, I'd rather get younger people
[02:01:42.060 --> 02:01:46.540]   Who cares? Let instagram have all this old fogies exactly
[02:01:46.540 --> 02:01:49.020]   I was talking to the media
[02:01:49.020 --> 02:01:51.740]   Yes
[02:01:51.740 --> 02:01:56.060]   I look at snapchat. I see plenty of advertising on snapchat. I mean they
[02:01:56.860 --> 02:02:01.980]   Must be advertising, right? Where where is youtube and all this? I know it's not a traditional social network
[02:02:01.980 --> 02:02:07.500]   But oh, that's tweens. I guess I was like as a tween. My daughter is just good lord
[02:02:07.500 --> 02:02:11.980]   I think it's your bones everybody under 20 tweens and teens
[02:02:11.980 --> 02:02:16.220]   But but while I'll use my son 22 as an example
[02:02:16.220 --> 02:02:21.740]   Snapchat and youtuber equal because they're different services snapchat's how he communicates
[02:02:21.740 --> 02:02:26.460]   When he sits down to watch tv even if he's in the living room
[02:02:26.780 --> 02:02:28.780]   It's youtube
[02:02:28.780 --> 02:02:35.420]   Yeah, well, I guess my daughter doesn't have a phone yet. So all of her friends communicate via google school account
[02:02:35.420 --> 02:02:39.980]   So they're on hangouts, but they but I guarantee you watch out because snapchat's coming
[02:02:39.980 --> 02:02:42.060]   How could you not by the way since we're talking about youtube?
[02:02:42.060 --> 02:02:45.740]   Let's give a plug to our friend john green whose novel turtles all the way down
[02:02:45.740 --> 02:02:48.860]   Uh just came out and got a spectacular review in the new york times
[02:02:48.860 --> 02:02:49.740]   Oh nice
[02:02:49.740 --> 02:02:53.420]   And I even I even bought bought the audio version because it's it's an excellent
[02:02:53.820 --> 02:02:58.300]   By all accounts and excellent account of ocd at once like to have the thoughts
[02:02:58.300 --> 02:03:00.860]   other go on because john himself
[02:03:00.860 --> 02:03:08.620]   Um, uh is stricken with this and that's what inspired this book. So a youtube friend of all of ours is he has a new book out
[02:03:08.620 --> 02:03:12.700]   Yeah, is he how does this relate to youtube is he my youtube friend?
[02:03:12.700 --> 02:03:17.340]   Oh, well, he and his brother hank they run it. Oh, oh, yeah
[02:03:17.340 --> 02:03:22.860]   They uh do incredible educational videos. They do vlog brothers
[02:03:23.420 --> 02:03:27.100]   Say hank. I know that oh now the greens. Yeah, I agree. Yeah
[02:03:27.100 --> 02:03:29.820]   John john hank green. Oh good for him
[02:03:29.820 --> 02:03:33.500]   Yeah, good for him as long as we're talking books
[02:03:33.500 --> 02:03:38.060]   Can did you note that george sonders won the booker prize the man booker prize for
[02:03:38.060 --> 02:03:42.140]   One of my favorite books lincoln and the bardow man if you haven't listed
[02:03:42.140 --> 02:03:48.620]   It's it's the best audiobook ever the audible version of it has so many nick offerman and so many people reading it
[02:03:48.620 --> 02:03:51.820]   And it's just I could listen to it again and again and again
[02:03:51.820 --> 02:03:54.780]   It's if you haven't read it yet. You got the new lacquer a
[02:03:54.780 --> 02:04:00.060]   Not yet talked about last week. Yes, but that is on my list. Yeah, I get two credits in a week
[02:04:00.060 --> 02:04:09.420]   On the 20 second and then I will get it. Hey, my pick is the google advanced protection program. It is now officially available to all
[02:04:09.420 --> 02:04:17.900]   This is but not all will want it. It's we all know there's a big trade-off between uh security and convenience
[02:04:18.300 --> 02:04:20.940]   And if you're willing to give up a lot of convenience
[02:04:20.940 --> 02:04:23.900]   John padesta i'm looking at you
[02:04:23.900 --> 02:04:26.700]   This is really strong security
[02:04:26.700 --> 02:04:35.500]   Locks locks you down you can only log into your google account with your login password and a physical security key and you have to have two
[02:04:35.500 --> 02:04:41.420]   Because you have one that does bluetooth le i've ordered them i i have a ubokki which
[02:04:41.420 --> 02:04:45.980]   Does the usb authentication and then you need a bluetooth le one for
[02:04:46.380 --> 02:04:49.820]   iOS devices so i've ordered that that comes tomorrow
[02:04:49.820 --> 02:04:55.980]   This isn't one of the ones with the hacked rsh chips, right? No, well you won't you know the key is
[02:04:55.980 --> 02:05:00.220]   Do not generate the public key on the ubokki
[02:05:00.220 --> 02:05:05.020]   But the good news is you don't this is google does all that uh externally
[02:05:05.020 --> 02:05:06.700]   um
[02:05:06.700 --> 02:05:11.660]   And it's and it's not using uh public key crypto. Anyway, it's using uh phido utf
[02:05:11.660 --> 02:05:13.740]   for the
[02:05:13.740 --> 02:05:15.180]   authentication
[02:05:15.180 --> 02:05:17.500]   It also does other things for instance
[02:05:17.500 --> 02:05:21.580]   Uh, it will turn off a lot of apps that use your gmail
[02:05:21.580 --> 02:05:28.460]   So it may prove to be inconvenient i may for instance find out that i can no longer access gmail with with the
[02:05:28.460 --> 02:05:33.500]   Programs or actually what i do is i get my gmail to another service
[02:05:33.500 --> 02:05:38.940]   I may not be able to do that third-party apps that want access to gmail or drive will no longer have permission
[02:05:38.940 --> 02:05:41.180]   Which like that
[02:05:41.180 --> 02:05:45.260]   Yeah, oh this makes it secure this if if the dnc had used this
[02:05:45.260 --> 02:05:47.980]   It would be secure, right?
[02:05:47.980 --> 02:05:53.900]   Um, you'll only be able to use the chrome browser to access gmail or photos. You can't use this another browser
[02:05:53.900 --> 02:06:00.620]   At least for now, although it's conceivable they could add extensions for other you can use the um, can you use the inbox app?
[02:06:00.620 --> 02:06:04.940]   Yeah, oh i'm sure you can use the inbox app, but you but uh, uh, uh, uh, uh,
[02:06:04.940 --> 02:06:08.300]   Uh, for instance apple mail won't work context calendar won't work
[02:06:08.860 --> 02:06:13.180]   Uh, you'll have to use gmail inbox. Yes or google calendar apps on ios
[02:06:13.180 --> 02:06:18.380]   So this is quite a sacrifice on the other hand. This is ultimate security
[02:06:18.380 --> 02:06:20.380]   Um
[02:06:20.380 --> 02:06:25.580]   It goes well beyond traditional two-step verification you need to sign into your account with a password and a physical key
[02:06:25.580 --> 02:06:32.460]   Uh, in fact, no other way will work anymore. So you can't say oh, I don't have my key. I lost my key
[02:06:32.460 --> 02:06:35.340]   Can I use authenticate or new can I use sms new?
[02:06:36.540 --> 02:06:41.740]   And if you do lose your key and you need to get into your account, it's a much more stringent
[02:06:41.740 --> 02:06:46.940]   A system of getting you back in because that's of course always been a weakness somebody pretending to be you
[02:06:46.940 --> 02:06:50.060]   And it takes a while. I think it takes a week to get your account back
[02:06:50.060 --> 02:06:51.980]   To slow
[02:06:51.980 --> 02:06:55.340]   Well, this is not something everybody will want to do you and probably won't want to do it
[02:06:55.340 --> 02:06:57.340]   But if you are jennifer lorence
[02:06:57.340 --> 02:06:59.500]   If you are mar a john padesta
[02:06:59.500 --> 02:07:06.060]   If you you know if if you're a celebrity or a journalist if you're you know what if you have to
[02:07:07.020 --> 02:07:13.580]   A week is too long. You have to have they have to have some sort of rapid response team that can authenticate people
[02:07:13.580 --> 02:07:16.220]   quickly
[02:07:16.220 --> 02:07:18.220]   And I will let you know
[02:07:18.220 --> 02:07:26.300]   That you don't remember when Jason on this show Jason cut himself off the thumbnail right yeah
[02:07:26.300 --> 02:07:31.980]   It was a great sacrifice. I don't think now we had heard maybe there was a charge for this
[02:07:32.060 --> 02:07:34.060]   I don't think there is a charge
[02:07:34.060 --> 02:07:38.540]   But I don't know yet because I can't go farther until I have my keys
[02:07:38.540 --> 02:07:42.620]   So you have to have two keys you have to have a usb key and a bluetooth key
[02:07:42.620 --> 02:07:48.220]   Um, I had the usb key, but I ordered a bluetooth key the one they recommend is out of stock
[02:07:48.220 --> 02:07:51.420]   They recommend one called the fatan
[02:07:51.420 --> 02:07:59.100]   Multi pass multi pass phyto security key. I ended up getting uh one from wasco that does the same thing
[02:07:59.100 --> 02:08:01.500]   It's as long as phyto utf bluetooth le
[02:08:01.500 --> 02:08:04.140]   Uh, that's fine
[02:08:04.140 --> 02:08:09.100]   I'll have a report for you. Maybe not yeah next week. I should have it all set up by next week
[02:08:09.100 --> 02:08:14.140]   But it is available now. It's it's just launched this week if you're interested in advanced
[02:08:14.140 --> 02:08:17.020]   account protection
[02:08:17.020 --> 02:08:20.540]   From google you need merely go to
[02:08:20.540 --> 02:08:26.940]   Uh, what was it? I was there and I just left the page foolishly
[02:08:28.220 --> 02:08:31.020]   landing.google.com/advancedprotection
[02:08:31.020 --> 02:08:34.140]   Friends we're out of time for this
[02:08:34.140 --> 02:08:35.340]   Faaaaaaah
[02:08:35.340 --> 02:08:37.340]   Oh, we were there. We were there at least an hour ago
[02:08:37.340 --> 02:08:40.700]   Well, that never bothers us. No
[02:08:40.700 --> 02:08:43.660]   Poor stan, oh she's snacks. She said she's snacked
[02:08:43.660 --> 02:08:46.620]   I am hungry now though. I again
[02:08:46.620 --> 02:08:53.500]   I'm burning through it. You know all that brain work. I'm doing. Oh, you're doing good brain work. Stacy is at uh, stacey on iot
[02:08:53.500 --> 02:08:57.820]   Dot com. That's her newsletter subscribe. It's free. It's great. I read it every week
[02:08:58.220 --> 02:09:02.300]   @gigastacey on twitter and of course she and kevin toffal do a great iot podcast
[02:09:02.300 --> 02:09:05.580]   Uh, you can also get that at stacey on iot.com
[02:09:05.580 --> 02:09:09.740]   Or iot podcast.com. Thank you stacey great to see you
[02:09:09.740 --> 02:09:12.860]   I'm glad to be here hashtag me too
[02:09:12.860 --> 02:09:17.260]   Uh, also thanks to uh, mr. Jeffrey Jarvis
[02:09:17.260 --> 02:09:19.980]   Who's in town about truth?
[02:09:19.980 --> 02:09:21.740]   mr. Truth
[02:09:21.740 --> 02:09:23.740]   He's post truth
[02:09:23.740 --> 02:09:26.860]   Buzz machine dot com. I bet you'll be writing about truth
[02:09:27.660 --> 02:09:30.780]   @jeff javas on the twitter and of course he's a professor of journalism at kunie
[02:09:30.780 --> 02:09:33.420]   So if you want to be one of the new's journalistic superstars
[02:09:33.420 --> 02:09:36.220]   That's the place to go
[02:09:36.220 --> 02:09:39.420]   And so I was in i was in london in front of the bbc headquarters
[02:09:39.420 --> 02:09:44.700]   And uh for a meeting on monday and a guy just comes up takes all his headphones and says professor jarvis
[02:09:44.700 --> 02:09:47.260]   Wow, somebody the bbc and he said
[02:09:47.260 --> 02:09:48.620]   twig
[02:09:48.620 --> 02:09:49.820]   Uh
[02:09:49.820 --> 02:09:54.060]   Nice guy on the street. I don't know where i think it's doing this charles as i remember very nice charcans go inside
[02:09:54.060 --> 02:09:58.700]   I sent him a meeting next to an executive from big pr company says I love twig nice
[02:09:58.700 --> 02:10:03.900]   Yeah, job. Jeff. Hey everybody in London. Oh, we love you too. Yeah
[02:10:03.900 --> 02:10:08.700]   So, well, uh, you won't see you next week jeff
[02:10:08.700 --> 02:10:13.820]   Right now you won't see me next week either. Well, see so just be me doing the show
[02:10:13.820 --> 02:10:18.780]   It's just you that's what that's what the world wants. Anyway, we just described
[02:10:18.780 --> 02:10:21.500]   So no
[02:10:21.500 --> 02:10:23.900]   You can't come up
[02:10:23.980 --> 02:10:30.300]   Well, I'm giving a I'm giving a speech for arm tech con so have fun. Sorry armed tech con
[02:10:30.300 --> 02:10:36.700]   Mike an arm arm arm tech con. Oh, oh, I thought okay embedded embedded chips
[02:10:36.700 --> 02:10:41.500]   Uh, he's armed
[02:10:41.500 --> 02:10:46.700]   So, you know what we'll get matthew engram to talk about his new job at the columbia journalism review and
[02:10:46.700 --> 02:10:50.940]   Who else we'll get somebody else kevin marks? We have lots of people want to be on this show
[02:10:51.420 --> 02:10:54.540]   Maybe danny Sullivan to tell us about his new job at google. See you'll be sorry
[02:10:54.540 --> 02:10:56.540]   Well, I want to be there for
[02:10:56.540 --> 02:11:01.820]   Yeah, that already sounds way better. Although too much testosterone
[02:11:01.820 --> 02:11:08.460]   Yeah, i'm gonna give you a hard time that me too crack. I was like, oh, oh
[02:11:08.460 --> 02:11:10.940]   I'm sorry
[02:11:10.940 --> 02:11:14.540]   I have to do that. Otherwise. I wouldn't be a privileged white male
[02:11:14.540 --> 02:11:17.580]   Do you do you do you?
[02:11:17.580 --> 02:11:19.580]   No, but I can't help it
[02:11:19.580 --> 02:11:23.900]   We it's just a flaw. I have a flawed person. I'm sorry. I am i'm a flood person
[02:11:23.900 --> 02:11:31.180]   We do this show every wednesday whether or not those other guys are here. I'll be here next wednesday at 130 pacific 430 eastern
[02:11:31.180 --> 02:11:36.780]   2030 utc you can watch live join us in the chatroom irc.twit.tv
[02:11:36.780 --> 02:11:38.300]   You can also
[02:11:38.300 --> 02:11:44.220]   Get on demand versions audio and video at our website twit.tv/twig or subscribe in your favorite podcatcher
[02:11:44.220 --> 02:11:48.220]   We would love it if you did that way you'll get it each and every week
[02:11:48.700 --> 02:11:55.660]   The dog is signaling it's time to say goodbye stay safe. Goodbye stay safe. We'll see you next time
[02:11:55.660 --> 02:11:58.140]   on twig
[02:11:58.140 --> 02:12:00.140]   you
[02:12:00.140 --> 02:12:02.140]   you
[02:12:02.140 --> 02:12:04.720]   (upbeat music)
[02:12:04.720 --> 02:12:07.300]   (gentle music)

