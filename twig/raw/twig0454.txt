;FFMETADATA1
title=The Oldsmobile of Email
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=454
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.580]   It's time for Twig this week in Google. I'm Jason Howell. I'm here with Jeff Jarvis and Matthew Ingram.
[00:00:05.580 --> 00:00:10.880]   We're gonna talk about some recent announcements from Google. We've got a new Gmail interface rolling out.
[00:00:10.880 --> 00:00:14.200]   We've got Google Tasks. Tasks is apparently coming back.
[00:00:14.200 --> 00:00:17.880]   We've also got some announcements that are possibly yet to be done.
[00:00:17.880 --> 00:00:21.360]   Announcements about a new messaging platform called Chat.
[00:00:21.360 --> 00:00:29.840]   Announcements about possibly play music going away in favor of YouTube music and a whole lot more this week in Google.
[00:00:29.840 --> 00:00:31.840]   All is next.
[00:00:31.840 --> 00:00:36.640]   Netcast you love.
[00:00:36.640 --> 00:00:38.640]   From people you trust.
[00:00:38.640 --> 00:00:43.600]   This is Twig.
[00:00:43.600 --> 00:00:47.840]   Ban with for this week in Google is provided by cash fly.
[00:00:47.840 --> 00:00:51.280]   C-A-C-H-E-F-L-Y dot com.
[00:00:55.320 --> 00:01:01.540]   This is Twig. This week in Google episode 454 recorded on April 25th,
[00:01:01.540 --> 00:01:05.040]   2018, The Oldsmobile of Email.
[00:01:05.040 --> 00:01:09.880]   This episode of This Week in Google is brought to you by Rocket Mortgage by Quick and Loans.
[00:01:09.880 --> 00:01:14.720]   Home plays a big role in your life and that's why Quick and Loans created Rocket Mortgage.
[00:01:14.720 --> 00:01:20.840]   It lets you apply simply and understand the entire mortgage process fully so you can be confident that you're getting the right mortgage for you.
[00:01:20.840 --> 00:01:24.160]   It started at Rocket Mortgage dot com slash Twig.
[00:01:24.160 --> 00:01:28.960]   It's time for Twig this week in Google.
[00:01:28.960 --> 00:01:38.000]   I'm Jason Howell filling in as best as I can anyways for Leo the porch who usually when I'm filling in for him is gallivanting once again.
[00:01:38.000 --> 00:01:39.680]   I guess I just like that word.
[00:01:39.680 --> 00:01:43.840]   I like to think of Leo gallivanting somewhere and that's exactly what he's doing
[00:01:43.840 --> 00:01:46.400]   but I'm always happy to jump on this week in Google.
[00:01:46.400 --> 00:01:50.640]   I always have a lot of fun because I get to talk with amazing folks like Jeff Jarvis.
[00:01:50.640 --> 00:01:54.280]   You know him Buzzmachine.com professor at the CUNY.
[00:01:54.280 --> 00:01:55.280]   You know what I mean?
[00:01:55.280 --> 00:01:56.280]   You know what I mean?
[00:01:56.280 --> 00:01:57.280]   Journalist.
[00:01:57.280 --> 00:01:58.280]   You tolerate him.
[00:01:58.280 --> 00:01:59.280]   How's it going Jeff?
[00:01:59.280 --> 00:02:02.640]   So the question is is Leo karaoke.
[00:02:02.640 --> 00:02:04.480]   Oh that's a good question.
[00:02:04.480 --> 00:02:13.600]   I haven't seen exactly how he's chosen to gallivant at this moment but if he's because he's in Japan right?
[00:02:13.600 --> 00:02:17.840]   If he's in Japan and he's not karaoke and is that how you actually say it?
[00:02:17.840 --> 00:02:22.400]   I was just trying to come up with something worse than gallivanting.
[00:02:22.400 --> 00:02:25.600]   Gallivanting karaoke whatever.
[00:02:25.600 --> 00:02:27.280]   It's all the same to me.
[00:02:27.280 --> 00:02:31.480]   Also joining us is Matthew Ingram chief digital writer at cjr.org.
[00:02:31.480 --> 00:02:32.480]   How you doing Matthew?
[00:02:32.480 --> 00:02:33.480]   Good.
[00:02:33.480 --> 00:02:34.480]   I'm good.
[00:02:34.480 --> 00:02:35.480]   How are you?
[00:02:35.480 --> 00:02:36.480]   I'm doing all right.
[00:02:36.480 --> 00:02:37.480]   Doing amazing.
[00:02:37.480 --> 00:02:45.640]   I'm happy to be here with you guys talking about all things Google but right before showtime
[00:02:45.640 --> 00:02:50.640]   we had some non-Google news that just kind of dropped and it's kind of an important time
[00:02:50.640 --> 00:02:55.200]   right now because Facebook's been under the microscope to say the very least the last
[00:02:55.200 --> 00:02:58.800]   couple of months and apparently they just released their earnings report.
[00:02:58.800 --> 00:03:01.200]   I didn't have a chance to read through this.
[00:03:01.200 --> 00:03:03.640]   Jeff you were the one that told me about this.
[00:03:03.640 --> 00:03:04.640]   So what's there now?
[00:03:04.640 --> 00:03:05.760]   As it comes up by bit right?
[00:03:05.760 --> 00:03:09.360]   So revenue is up 49% year on year.
[00:03:09.360 --> 00:03:12.920]   Well the bottom line is as Matthew said they're killing it.
[00:03:12.920 --> 00:03:21.160]   All the alleged scandals and all that so far is not kicking him in the groin.
[00:03:21.160 --> 00:03:26.440]   Ernie's per share are $1.69 Wall Street expected $1.35.
[00:03:26.440 --> 00:03:31.880]   Total revenue is $11.97 billion.
[00:03:31.880 --> 00:03:37.880]   Daily active users $1.45 billion in line with expectations up 13% year on year.
[00:03:37.880 --> 00:03:43.200]   So let's kill Facebook saying I think it's making a lot of impact.
[00:03:43.200 --> 00:03:57.040]   And the monthly active users also up 13% and that's $2.2 billion versus $2.19 billion expected.
[00:03:57.040 --> 00:04:01.280]   Profit $5.45 billion versus an expected $4.64 billion.
[00:04:01.280 --> 00:04:11.920]   So Facebook right now is doing just dandy.
[00:04:11.920 --> 00:04:32.280]   So that's the thing that we have and that it wouldn't have a material impact on whatsoever.
[00:04:32.280 --> 00:04:38.220]   The stock is down 18% since Cambridge Analytica broke but I suspect there'll be some folks
[00:04:38.220 --> 00:04:39.220]   buying it now.
[00:04:39.220 --> 00:04:42.500]   I don't know if Facebook stock.
[00:04:42.500 --> 00:04:43.780]   I think there's still a risk.
[00:04:43.780 --> 00:04:48.620]   I think some of the stocks sell off was an acknowledgement that there's still a risk
[00:04:48.620 --> 00:04:55.540]   of regulation that could impinge on Facebook's profits especially if it restricts what they
[00:04:55.540 --> 00:04:56.460]   can do with data.
[00:04:56.460 --> 00:05:02.180]   So I think there's still the potential for some of this stuff to impact the company but
[00:05:02.180 --> 00:05:06.620]   it feels like it's not really at the moment.
[00:05:06.620 --> 00:05:14.620]   And we have, let's see here, I mean, so you've got Facebook dealing with, you know, as best
[00:05:14.620 --> 00:05:17.740]   as it can dealing with the fallout of all the Cambridge Analytica stuff.
[00:05:17.740 --> 00:05:23.060]   Zuckerberg goes to Washington, you know, and still in the end, at least as far as we can
[00:05:23.060 --> 00:05:29.460]   tell based on these earnings, not a very big material effect on their bottom line.
[00:05:29.460 --> 00:05:36.940]   Google had its, or rather, Alphabet had its earnings report for Q1 and there again, big
[00:05:36.940 --> 00:05:45.540]   tech strong revenue grew 26% year over year to $31.6 billion in the first quarter.
[00:05:45.540 --> 00:05:51.660]   It's actually, Alphabet is growing faster this time or this quarter compared to this quarter
[00:05:51.660 --> 00:05:53.260]   last year.
[00:05:53.260 --> 00:05:54.660]   Then it had grown by 22%.
[00:05:54.660 --> 00:05:58.260]   Now it's growing at a 26% rate.
[00:05:58.260 --> 00:06:01.780]   And yeah, there's just, there's no signs of any of this slow.
[00:06:01.780 --> 00:06:09.180]   And obviously some of the biggest, you know, potentially impactful things happening in
[00:06:09.180 --> 00:06:17.500]   the public sphere that would have its users maybe question their usage habits or doubt
[00:06:17.500 --> 00:06:22.180]   the intentions of these companies making absolutely no difference.
[00:06:22.180 --> 00:06:26.580]   So apparently we've just all kind of succumbed to the fact that this is how we live our lives
[00:06:26.580 --> 00:06:27.980]   and we're okay with it.
[00:06:27.980 --> 00:06:28.980]   Well, yeah.
[00:06:28.980 --> 00:06:31.380]   And, you know, again, let me do a full disclosure.
[00:06:31.380 --> 00:06:35.260]   So I accepted money from Facebook at the school to start the news integrity initiative.
[00:06:35.260 --> 00:06:38.500]   I received no money personally from Facebook or any platform and we are independent of
[00:06:38.500 --> 00:06:40.380]   Facebook and of disclosure.
[00:06:40.380 --> 00:06:46.380]   Now, but you did put a new wing on your house, didn't you?
[00:06:46.380 --> 00:06:48.380]   We're flying and flying with it.
[00:06:48.380 --> 00:06:55.220]   No, but the vacation to peruse was wonderful, wasn't it Matthew?
[00:06:55.220 --> 00:07:00.940]   So, you know, the thing I keep on saying is that is that if you go through your own feed
[00:07:00.940 --> 00:07:03.780]   in Facebook, show me the Nazis, right?
[00:07:03.780 --> 00:07:04.780]   They're not there.
[00:07:04.780 --> 00:07:05.780]   Yeah, it's true.
[00:07:05.780 --> 00:07:09.260]   You know, so there's all this argument, oh my God, the world is falling apart.
[00:07:09.260 --> 00:07:11.580]   Everything is falling chicken a little.
[00:07:11.580 --> 00:07:17.580]   The moral panic, as I like to say on the show, that I believe is legitimately occurring right
[00:07:17.580 --> 00:07:18.580]   now.
[00:07:18.580 --> 00:07:23.140]   I mean, I think it's legitimately called a moral panic is a media narrative and a political
[00:07:23.140 --> 00:07:24.740]   narrative now that's going on.
[00:07:24.740 --> 00:07:27.820]   It just isn't showing up in people's lives.
[00:07:27.820 --> 00:07:32.100]   And if you look at your Facebook feed and your Twitter feed and your Instagram and your
[00:07:32.100 --> 00:07:34.580]   Google searches, you're not seeing the world fall apart.
[00:07:34.580 --> 00:07:36.260]   You're seeing it was the same as it was a year ago.
[00:07:36.260 --> 00:07:37.260]   And you know what?
[00:07:37.260 --> 00:07:38.260]   It's pretty damn cool.
[00:07:38.260 --> 00:07:46.060]   Yeah, I guess I feel like certainly talking to friends and family, you know, I've tried
[00:07:46.060 --> 00:07:48.100]   to explain Cambridge Analytica.
[00:07:48.100 --> 00:07:51.220]   I've tried to explain what the issues are.
[00:07:51.220 --> 00:07:54.660]   I don't think it really impacts a lot of people in their day to day.
[00:07:54.660 --> 00:08:00.260]   And so to them, Facebook is just, you know, it's something you use and you accept the
[00:08:00.260 --> 00:08:01.860]   fact that you get something for nothing.
[00:08:01.860 --> 00:08:08.300]   And so maybe they're doing something with your data, but you don't really, I think, appreciate
[00:08:08.300 --> 00:08:10.780]   what it is exactly they're doing.
[00:08:10.780 --> 00:08:16.140]   And I'm not saying people are stupid or just saying it's a complex issue.
[00:08:16.140 --> 00:08:18.020]   It takes a lot of time to explain.
[00:08:18.020 --> 00:08:20.900]   It's extremely boring in some ways.
[00:08:20.900 --> 00:08:25.820]   And so I think a lot of people just move on with their lives and it doesn't impact them
[00:08:25.820 --> 00:08:26.820]   directly.
[00:08:26.820 --> 00:08:29.220]   That's not to say it's not important.
[00:08:29.220 --> 00:08:30.220]   So I think that's the deal.
[00:08:30.220 --> 00:08:31.220]   Yeah, I agree with you.
[00:08:31.220 --> 00:08:32.220]   Yeah.
[00:08:32.220 --> 00:08:33.220]   There's a lot that needs to be done.
[00:08:33.220 --> 00:08:34.220]   Yeah.
[00:08:34.220 --> 00:08:35.420]   And there are, I agree with that.
[00:08:35.420 --> 00:08:42.180]   It have to be done by governments or by regulators or by whoever to protect people.
[00:08:42.180 --> 00:08:47.420]   I mean, it's hard to discuss, you know, the poisoning of the environment or climate change
[00:08:47.420 --> 00:08:50.300]   or people would much rather just get on with their day.
[00:08:50.300 --> 00:08:53.060]   But that doesn't mean those things aren't important.
[00:08:53.060 --> 00:08:55.420]   Yeah, I'm working on a project.
[00:08:55.420 --> 00:08:58.940]   Matthew and I were just in the International Journalism Festival in Perusion, which is
[00:08:58.940 --> 00:09:04.460]   the greatest, I don't want to say it's a junket, but it's a great event.
[00:09:04.460 --> 00:09:08.700]   It's a wonderful journalism event and the past is spectacular and the people are great.
[00:09:08.700 --> 00:09:10.340]   But there's a lot of art.
[00:09:10.340 --> 00:09:11.340]   Let's be honest.
[00:09:11.340 --> 00:09:12.340]   Yeah.
[00:09:12.340 --> 00:09:13.340]   Oh, yeah.
[00:09:13.340 --> 00:09:14.340]   Oh, yeah.
[00:09:14.340 --> 00:09:15.340]   Oh, yeah.
[00:09:15.340 --> 00:09:16.340]   Where are the hair shirt?
[00:09:16.340 --> 00:09:17.340]   Yeah.
[00:09:17.340 --> 00:09:23.380]   And I ran a panel there about the moral implications and imperatives of the decisions being made
[00:09:23.380 --> 00:09:26.100]   by platforms, especially also media companies.
[00:09:26.100 --> 00:09:30.260]   And another one, when Campbell Brown from Facebook did not come, so I was going to interview
[00:09:30.260 --> 00:09:31.260]   her.
[00:09:31.260 --> 00:09:35.340]   So instead I had four people on stage about what should Facebook do for news.
[00:09:35.340 --> 00:09:39.780]   And what struck me was is that when you get down to the details, there is far from unanimity
[00:09:39.780 --> 00:09:40.780]   here, right?
[00:09:40.780 --> 00:09:42.740]   One person on the panel says, well, Facebook should hire an editor.
[00:09:42.740 --> 00:09:47.020]   The next person on the panel says, the last thing Facebook should do is hire an editor.
[00:09:47.020 --> 00:09:50.580]   Get around about, I've been going and doing some interviews for a project and working
[00:09:50.580 --> 00:09:53.180]   on this moral basis question.
[00:09:53.180 --> 00:09:58.180]   And the only in the strikes piece so far is how there's not agreement.
[00:09:58.180 --> 00:10:01.940]   Even about what the problem is, what the solution is, what the expectations are.
[00:10:01.940 --> 00:10:05.020]   It's a complex, nuanced topic.
[00:10:05.020 --> 00:10:09.020]   Yeah, I would agree.
[00:10:09.020 --> 00:10:10.580]   Yeah.
[00:10:10.580 --> 00:10:12.300]   I get confused even.
[00:10:12.300 --> 00:10:19.740]   I work in this kind of stuff every day, I get confused to figuring out and really understanding
[00:10:19.740 --> 00:10:22.100]   how I feel about all this stuff.
[00:10:22.100 --> 00:10:26.340]   I keep going back and forth because I stepped away from Facebook almost a year and a half
[00:10:26.340 --> 00:10:27.980]   now at this point.
[00:10:27.980 --> 00:10:33.060]   But little pieces here and there, I start dipping my toe back in because for very specific
[00:10:33.060 --> 00:10:34.060]   reasons.
[00:10:34.060 --> 00:10:37.340]   But then I have this guilt that sets in where I'm like, wait a minute.
[00:10:37.340 --> 00:10:40.940]   I stepped away from Facebook because this, this, this, and this, and this, and this, this
[00:10:40.940 --> 00:10:43.540]   mean that I'm okay with it.
[00:10:43.540 --> 00:10:45.260]   But then, and it feels very hypocritical.
[00:10:45.260 --> 00:10:51.340]   There's actually an article in here on the Wall Street Journal from Christopher Mims who
[00:10:51.340 --> 00:10:57.940]   wrote basically asking the question why we aren't talking about Google in the same conversation
[00:10:57.940 --> 00:11:02.700]   as, you know, what everybody's been talking about with Facebook as far as harvesting data
[00:11:02.700 --> 00:11:04.900]   and what they're doing with your personal data.
[00:11:04.900 --> 00:11:05.900]   Yeah.
[00:11:05.900 --> 00:11:09.660]   Like I said, I feel very hypocritical about it because on one hand, I stepped away from
[00:11:09.660 --> 00:11:14.860]   Facebook because I, because I saw things that were alarming to me as far as the potential
[00:11:14.860 --> 00:11:19.540]   use of data and it felt, I felt very manipulated by, you know, some of the things that were
[00:11:19.540 --> 00:11:21.900]   happening at them at the time that I stepped away.
[00:11:21.900 --> 00:11:28.180]   But then at the same time, I spend my life here on Twitch talking all about Google and
[00:11:28.180 --> 00:11:33.780]   being all in on Android and everything when, you know, the reality is Google is tracking
[00:11:33.780 --> 00:11:40.260]   and harvesting and manipulating that data as much, if not even more than, than Facebook
[00:11:40.260 --> 00:11:41.260]   is.
[00:11:41.260 --> 00:11:45.860]   And so it's a kind of a struggle, a point that I'm at that I'm like trying to figure it out.
[00:11:45.860 --> 00:11:48.020]   I think that's what Jason, I haven't written about this yet.
[00:11:48.020 --> 00:11:49.500]   Sorry, Matthew, go ahead.
[00:11:49.500 --> 00:11:51.460]   I think that's what makes it so complex.
[00:11:51.460 --> 00:11:59.300]   Like Jeff was saying, these are, these are large conglomerations of services that we
[00:11:59.300 --> 00:12:03.540]   all use that are integrated into our daily lives, Google in particular.
[00:12:03.540 --> 00:12:09.940]   I've, you know, got Android, I use Gmail, I'm a Google fan, but that just means, you
[00:12:09.940 --> 00:12:12.740]   know, I'm handing over more and more of my data to them.
[00:12:12.740 --> 00:12:13.740]   Yeah.
[00:12:13.740 --> 00:12:15.820]   Facebook, I use all the time to connect with family and friends.
[00:12:15.820 --> 00:12:16.820]   It's a great service.
[00:12:16.820 --> 00:12:22.740]   So it's not that, that either one of these is inherently evil or inherently good.
[00:12:22.740 --> 00:12:24.980]   It has good and bad aspects.
[00:12:24.980 --> 00:12:30.700]   And I think we have to think about the implications of, you know, our sort of connection to them
[00:12:30.700 --> 00:12:32.900]   and what that means.
[00:12:32.900 --> 00:12:34.540]   So let me tell you about something else I just did this week.
[00:12:34.540 --> 00:12:35.900]   I haven't written about this yet.
[00:12:35.900 --> 00:12:39.460]   There's a company called Axiom, ACX IOM.
[00:12:39.460 --> 00:12:41.180]   That's one of the, oh, geez, I'm sorry.
[00:12:41.180 --> 00:12:44.660]   Can you guys lighten up on your end with a lot of up in playing with this like crazy?
[00:12:44.660 --> 00:12:47.380]   And I'm looking like I'm a ghost.
[00:12:47.380 --> 00:12:49.780]   You look like you're CGI at this point.
[00:12:49.780 --> 00:12:50.780]   There you go.
[00:12:50.780 --> 00:12:51.780]   Yeah.
[00:12:51.780 --> 00:12:52.780]   No, it's still not good.
[00:12:52.780 --> 00:12:53.780]   I'm sorry.
[00:12:53.780 --> 00:12:54.780]   I'm not.
[00:12:54.780 --> 00:12:55.780]   That's okay.
[00:12:55.780 --> 00:12:57.780]   Are you artificial intelligence?
[00:12:57.780 --> 00:12:58.780]   Are you a robot?
[00:12:58.780 --> 00:13:00.780]   Are we talking to the machine?
[00:13:00.780 --> 00:13:01.780]   Yeah.
[00:13:01.780 --> 00:13:02.780]   The Jarvis.
[00:13:02.780 --> 00:13:04.420]   So we'll work on this.
[00:13:04.420 --> 00:13:09.740]   So, so anyway, so Axiom has been around when I was at Time Inc. starting in '81, we used
[00:13:09.740 --> 00:13:16.820]   companies like Axiom to be able to do individualized user data with your name and your address
[00:13:16.820 --> 00:13:19.300]   and your social security numbers and everything.
[00:13:19.300 --> 00:13:20.300]   So I wanted to Axiom.
[00:13:20.300 --> 00:13:26.060]   And now ask what your data is and mind you, it's a lot less specific and a lot less telling
[00:13:26.060 --> 00:13:28.340]   than what you get out of the platforms.
[00:13:28.340 --> 00:13:31.780]   But because they'll tell, they'll say, we know this about you, but they won't say how
[00:13:31.780 --> 00:13:33.420]   they know it or why they know at what level.
[00:13:33.420 --> 00:13:37.260]   But then I got a further report and it's, it's pretty amazing.
[00:13:37.260 --> 00:13:39.740]   This is, this has nothing to do with the internet folks.
[00:13:39.740 --> 00:13:41.860]   This is marketing and media world out there.
[00:13:41.860 --> 00:13:42.860]   They know my asset.
[00:13:42.860 --> 00:13:46.220]   They know how, they know the range of how much I have in assets.
[00:13:46.220 --> 00:13:48.940]   They have a good guess as to my income.
[00:13:48.940 --> 00:13:52.700]   They know what kind of brokers I use.
[00:13:52.700 --> 00:13:57.260]   They know that I have a checking account balance.
[00:13:57.260 --> 00:14:01.820]   They know what kind of investment I do.
[00:14:01.820 --> 00:14:04.860]   They know that I'm not likely to use a discount broker.
[00:14:04.860 --> 00:14:08.420]   They know what my discretionary spending is.
[00:14:08.420 --> 00:14:12.420]   They put me in an economic spectrum.
[00:14:12.420 --> 00:14:19.580]   They have a car information about me, gifts I buy, where I travel, all this stuff.
[00:14:19.580 --> 00:14:20.580]   There's huge amounts.
[00:14:20.580 --> 00:14:23.980]   You know, if somebody's going crazy, getting their data from Facebook and Google, go get
[00:14:23.980 --> 00:14:25.140]   this stuff.
[00:14:25.140 --> 00:14:29.140]   And this is again, this is tied to your name and your address and your social security
[00:14:29.140 --> 00:14:30.140]   number.
[00:14:30.140 --> 00:14:32.380]   Now at the same time, they also get crap wrong.
[00:14:32.380 --> 00:14:33.380]   Right?
[00:14:33.380 --> 00:14:35.580]   Because where I live, they think I'm Republican.
[00:14:35.580 --> 00:14:36.580]   Ha!
[00:14:36.580 --> 00:14:40.940]   Now, did they make that determination as far as you know, because of where you live?
[00:14:40.940 --> 00:14:41.940]   Like that's just a blanket.
[00:14:41.940 --> 00:14:42.940]   I don't know.
[00:14:42.940 --> 00:14:43.940]   That's the thing.
[00:14:43.940 --> 00:14:44.940]   They don't reveal.
[00:14:44.940 --> 00:14:45.940]   We don't know how they come up with this.
[00:14:45.940 --> 00:14:48.060]   Google reveals a lot more about the how.
[00:14:48.060 --> 00:14:49.060]   Right.
[00:14:49.060 --> 00:14:50.780]   Amazon reveals their presumptions about the how.
[00:14:50.780 --> 00:14:51.980]   You don't get the how out of these guys.
[00:14:51.980 --> 00:14:54.100]   But these guys know a tremendous amount.
[00:14:54.100 --> 00:15:00.140]   And I would argue in ways that violate privacy more when you consider that on Facebook, what
[00:15:00.140 --> 00:15:03.860]   you're really doing is sharing.
[00:15:03.860 --> 00:15:08.060]   You're not doing a private transaction with the auto dealer that suddenly ends up here.
[00:15:08.060 --> 00:15:11.820]   And there's also the sort of voluntary nature.
[00:15:11.820 --> 00:15:16.900]   I mean, Facebook, no one reads the 85 page terms of service, but theoretically you agree
[00:15:16.900 --> 00:15:17.900]   to do those things.
[00:15:17.900 --> 00:15:18.900]   True.
[00:15:18.900 --> 00:15:19.900]   Accurate.
[00:15:19.900 --> 00:15:20.900]   Yeah.
[00:15:20.900 --> 00:15:22.740]   Databases are accumulated without your knowledge.
[00:15:22.740 --> 00:15:27.780]   And I totally agree that if there's one thing we could get across, it's that Google and
[00:15:27.780 --> 00:15:34.500]   Facebook are a tiny proportion of this much larger problem, which is that the entire economy
[00:15:34.500 --> 00:15:43.140]   is built on data, transfer, hoarding, knowledge, understanding, mining and so on.
[00:15:43.140 --> 00:15:45.980]   And they're just two very large companies.
[00:15:45.980 --> 00:15:51.620]   But there's a massive, massive kind of infrastructure of companies that do this all the time with
[00:15:51.620 --> 00:15:53.820]   our data.
[00:15:53.820 --> 00:15:58.180]   The funny thing given in our context here is that they also get some things really wrong.
[00:15:58.180 --> 00:16:03.100]   Like worse than calling me Republican, is they say that I prefer iPhones and blackberries.
[00:16:03.100 --> 00:16:07.900]   Well, how'd you come up with that one?
[00:16:07.900 --> 00:16:11.060]   And I'm not a show call this week in Google anyways.
[00:16:11.060 --> 00:16:15.940]   Like look at, look at China's attempts to try and track people's social behavior and
[00:16:15.940 --> 00:16:21.580]   then, you know, give them, like, allow them to fly or use the train or get medical services
[00:16:21.580 --> 00:16:24.340]   based on their kind of social performance.
[00:16:24.340 --> 00:16:29.700]   If there's, if all this data is being used in ways that we barely understand and lots
[00:16:29.700 --> 00:16:34.380]   of it is wrong, decisions are going to be made that impact on us and we won't even know
[00:16:34.380 --> 00:16:36.900]   about it until it's too late.
[00:16:36.900 --> 00:16:43.900]   Yeah, definitely a lot of my own, it might qualify as techno panic, I suppose.
[00:16:43.900 --> 00:16:49.880]   But my fears about all this stuff, when I read about how this is how this is actually
[00:16:49.880 --> 00:16:54.940]   happening right now, it almost feels like a black mirror, you know, you know, type of
[00:16:54.940 --> 00:16:59.820]   future in China, the way they're doing this, like, social measuring and stuff based on
[00:16:59.820 --> 00:17:03.460]   data, that's the kind of stuff that frightens the hell out of me.
[00:17:03.460 --> 00:17:08.620]   And when it's government doing it, government has power over you that Google and Facebook
[00:17:08.620 --> 00:17:10.700]   still do not have.
[00:17:10.700 --> 00:17:11.700]   Yeah.
[00:17:11.700 --> 00:17:13.700]   I don't know.
[00:17:13.700 --> 00:17:17.740]   I just, I don't know what keeps it from moving in that direction eventually.
[00:17:17.740 --> 00:17:20.460]   Like the long tail hindsight is always funny.
[00:17:20.460 --> 00:17:24.180]   You look backwards and you go, man, we didn't see it at the time.
[00:17:24.180 --> 00:17:27.780]   But this is the direction that we were headed and we were just blind to it.
[00:17:27.780 --> 00:17:29.940]   You know, the manipulation is going to occur too.
[00:17:29.940 --> 00:17:34.260]   There's a big kerfuffle going on right now around Joy Reed, MSNBC, and I'm a big fan
[00:17:34.260 --> 00:17:35.740]   of hers.
[00:17:35.740 --> 00:17:41.020]   And Glenn Reedwell went after, there was some anti-gay posts she did where she was making
[00:17:41.020 --> 00:17:45.300]   fun of her politician years ago that she apologized for and recanted and it's been
[00:17:45.300 --> 00:17:47.020]   many years since she's learned.
[00:17:47.020 --> 00:17:55.580]   So like Glenn Reedwell, this week went after her and said that there were more posts found
[00:17:55.580 --> 00:17:58.460]   and in the way back machine and it's ridiculous.
[00:17:58.460 --> 00:18:05.020]   And when her people tried to say that it was manipulated, it was hacked.
[00:18:05.020 --> 00:18:06.340]   Oh, yeah, hacked.
[00:18:06.340 --> 00:18:07.660]   Now I've just seen reports.
[00:18:07.660 --> 00:18:12.780]   I saw Joan Walsh from Salon who read her stuff for the last 17 years, says that she
[00:18:12.780 --> 00:18:17.100]   read her blog and never saw this in her staff writer blog and never saw this.
[00:18:17.100 --> 00:18:21.260]   And I read a security report that was done for Joy Reed.
[00:18:21.260 --> 00:18:28.300]   They've reported this stuff where things were added in, presumably before it went to way
[00:18:28.300 --> 00:18:29.860]   back, but I don't know.
[00:18:29.860 --> 00:18:35.900]   Point is that you have a record out there that now we see how news gets manipulated.
[00:18:35.900 --> 00:18:39.740]   If you want to get paranoid and if you want to get techno panicky and moral panicky, you
[00:18:39.740 --> 00:18:44.140]   also recognize that there are the tools here to go after individuals in ways that can be
[00:18:44.140 --> 00:18:48.060]   very hard to fight back.
[00:18:48.060 --> 00:18:51.700]   And so that's going to cause another level of panic about this stuff.
[00:18:51.700 --> 00:18:52.860]   Absolutely.
[00:18:52.860 --> 00:18:56.660]   Hard to fight back, hard to know what's true and what's not.
[00:18:56.660 --> 00:19:00.940]   Like I read that last night and yes, about what you were talking about, a lot of the
[00:19:00.940 --> 00:19:06.180]   posts that were supposedly pulled from the way back machine before they were removed
[00:19:06.180 --> 00:19:07.180]   by request.
[00:19:07.180 --> 00:19:12.780]   I mean, a lot of that was really alarming stuff and the problem is it was removed from the
[00:19:12.780 --> 00:19:13.780]   way back machine.
[00:19:13.780 --> 00:19:18.300]   It happened a long time ago and you've got some people saying that it happened and that
[00:19:18.300 --> 00:19:21.420]   she was the one that wrote it and some people saying that she wasn't.
[00:19:21.420 --> 00:19:24.700]   And there's just no way, like is there any way to know for sure?
[00:19:24.700 --> 00:19:28.180]   And so everything was seared out.
[00:19:28.180 --> 00:19:33.620]   There was a kind of forensic report that I read today that was done on behalf that was
[00:19:33.620 --> 00:19:38.660]   that relieved me because I'm a fan of hers, but she has resources.
[00:19:38.660 --> 00:19:41.980]   She has part of the reason she's a target too, but she has resources.
[00:19:41.980 --> 00:19:46.140]   If it's just poor Joe Schmoe, somebody decides to go after them.
[00:19:46.140 --> 00:19:49.980]   How do we get to a level of credibility?
[00:19:49.980 --> 00:19:54.420]   It's what Matthew and I do worry about this stuff and write about it all the time around
[00:19:54.420 --> 00:20:00.100]   the so-called fake news realm, but it's more than just news.
[00:20:00.100 --> 00:20:05.660]   And I think the thing that frightens people about Facebook in particular is the sense
[00:20:05.660 --> 00:20:14.620]   that their data is being used by these shadowy groups, some of which are tied to US intelligence,
[00:20:14.620 --> 00:20:20.660]   to affect somehow the way they perceive the world and the way they respond to things,
[00:20:20.660 --> 00:20:27.340]   to effectively kind of try and manipulate them to behave in a certain way.
[00:20:27.340 --> 00:20:30.620]   There's no question that those things happen.
[00:20:30.620 --> 00:20:33.020]   Intelligence agencies try to do that.
[00:20:33.020 --> 00:20:35.500]   Foreign governments try to do that.
[00:20:35.500 --> 00:20:41.860]   The idea that those sorts of things can be done partially with targeting based on your
[00:20:41.860 --> 00:20:50.460]   personal data that was shared without your knowledge is kind of a frightening prospect.
[00:20:50.460 --> 00:20:53.260]   For sure.
[00:20:53.260 --> 00:20:54.260]   Let's see here.
[00:20:54.260 --> 00:21:00.300]   How about we move into fun things?
[00:21:00.300 --> 00:21:04.020]   Google's got a lot of random things that are suddenly hitting and I'm reminded of the
[00:21:04.020 --> 00:21:07.780]   fact that this is the time of year where a couple of weeks out from Google I/O at this
[00:21:07.780 --> 00:21:11.940]   point, which I kind of can't believe, but we're a few weeks out.
[00:21:11.940 --> 00:21:17.780]   I always kind of forget that this period you get a lot of leaks about what you might see
[00:21:17.780 --> 00:21:23.580]   at Google I/O coming up, a lot of announcements, actual announcements from Google getting ahead
[00:21:23.580 --> 00:21:27.140]   of Google I/O so that there can either be something they can refer to from the stage
[00:21:27.140 --> 00:21:30.740]   two weeks ago, we blah, blah, blah, and you've loved it so far.
[00:21:30.740 --> 00:21:32.940]   Those kinds of comments.
[00:21:32.940 --> 00:21:37.980]   So we're perfectly fit into that period and we've got a bunch of stuff that falls right
[00:21:37.980 --> 00:21:38.980]   in there.
[00:21:38.980 --> 00:21:39.980]   We're going to talk about that.
[00:21:39.980 --> 00:21:42.900]   But I think before that, because it's a lot of them, let's take a quick break and then
[00:21:42.900 --> 00:21:45.300]   we'll jump in and we'll tackle it all.
[00:21:45.300 --> 00:21:50.500]   This episode of This Week in Google is brought to you by Rocket Mortgage, buy quick and loans.
[00:21:50.500 --> 00:21:54.260]   If you are familiar with getting a mortgage, if you've done the mortgage process yourself
[00:21:54.260 --> 00:21:59.060]   or maybe you haven't because you've heard it's complicated and it could be a challenge,
[00:21:59.060 --> 00:22:00.060]   you're not wrong.
[00:22:00.060 --> 00:22:03.660]   The mortgage experience hasn't really been keeping up with the times.
[00:22:03.660 --> 00:22:07.980]   It was dated, it needed a client-focused technological revolution and that's why quick
[00:22:07.980 --> 00:22:11.140]   and loans created Rocket Mortgage.
[00:22:11.140 --> 00:22:14.460]   Rocket Mortgage gives you the confidence that you need when it comes to buying a home or
[00:22:14.460 --> 00:22:17.140]   even refinancing your existing home loan.
[00:22:17.140 --> 00:22:21.700]   It's simple, it allows you to fully understand all the details and be confident that you're
[00:22:21.700 --> 00:22:23.420]   getting the right mortgage for you.
[00:22:23.420 --> 00:22:25.660]   That's so important when you're getting a mortgage.
[00:22:25.660 --> 00:22:29.740]   You want to understand it all and Rocket Mortgage makes sure that you do.
[00:22:29.740 --> 00:22:30.740]   It's convenient.
[00:22:30.740 --> 00:22:34.500]   The trusted partners allow you to share your financial information with Rocket Mortgage
[00:22:34.500 --> 00:22:38.900]   at the touch of a button because it's purely in the digital age.
[00:22:38.900 --> 00:22:42.180]   It's in your pocket, it's on your desktop, it's easy to use.
[00:22:42.180 --> 00:22:45.700]   It's powerful whether you're looking to buy your first home or your tenth Rocket Mortgage
[00:22:45.700 --> 00:22:50.940]   is able to perform thousands of calculations in seconds based on your income, your assets
[00:22:50.940 --> 00:22:51.940]   and credit.
[00:22:51.940 --> 00:22:57.060]   Rocket Mortgage can analyze all the home loan options for which you qualify and then find
[00:22:57.060 --> 00:23:01.460]   the one, locate the one that's just right for you in your scenario.
[00:23:01.460 --> 00:23:06.140]   Rocket Mortgage by QuickAlones applies simply, understand fully, mortgage confidently.
[00:23:06.140 --> 00:23:14.380]   To get started, go to rocketmortgage.com/twig, that's rocketmortgage.com/twig, equal housing
[00:23:14.380 --> 00:23:19.780]   lender, licensed in all 50 states, and MLS consumeraccess.org, number 3030.
[00:23:19.780 --> 00:23:24.260]   We thank Rocket Mortgage by QuickAlones for their support of this week in Google.
[00:23:24.260 --> 00:23:26.780]   All right, the fun stuff.
[00:23:26.780 --> 00:23:31.180]   Actually, today we will start with an actual announcement from Google.
[00:23:31.180 --> 00:23:36.300]   We've been hearing little rumors here and there that we might see a refreshed interface
[00:23:36.300 --> 00:23:37.300]   for Gmail.
[00:23:37.300 --> 00:23:40.660]   I've been using inbox for a couple of years now.
[00:23:40.660 --> 00:23:47.900]   I've been outside of the Gmail experience, but anyone who's been using Gmail would probably
[00:23:47.900 --> 00:23:52.580]   agree that the interface itself is really tired, really dated.
[00:23:52.580 --> 00:23:55.820]   It feels like a relic at this point or felt like one.
[00:23:55.820 --> 00:24:02.140]   Thankfully, Google felt that way too and they rolled out a huge update today.
[00:24:02.140 --> 00:24:06.580]   It's starting to hit desktop and mobile though, as you know, Google does things where they
[00:24:06.580 --> 00:24:09.740]   kind of roll it out slowly and in steps.
[00:24:09.740 --> 00:24:11.900]   So if you don't see it, you will.
[00:24:11.900 --> 00:24:13.180]   But it worked for me.
[00:24:13.180 --> 00:24:15.420]   I went into Google Gmail.
[00:24:15.420 --> 00:24:19.540]   I checked the Settings button in Gmail and sure enough at the top it said, "Try the new
[00:24:19.540 --> 00:24:20.540]   Gmail option."
[00:24:20.540 --> 00:24:21.540]   Oh.
[00:24:21.540 --> 00:24:27.100]   So I went from, in a time mobile, you're talking desktop?
[00:24:27.100 --> 00:24:28.700]   Desktop, sorry, not on mobile.
[00:24:28.700 --> 00:24:29.700]   I did this on desktop.
[00:24:29.700 --> 00:24:33.420]   All right, so, oh no, I don't have it yet.
[00:24:33.420 --> 00:24:39.500]   And are you, because I think it's also rolling out to G Suite users as well.
[00:24:39.500 --> 00:24:44.780]   So Google likes to roll out things and then leave G Suite users out in the grid.
[00:24:44.780 --> 00:24:45.780]   Yeah.
[00:24:45.780 --> 00:24:47.940]   I think they're doing it right this time.
[00:24:47.940 --> 00:24:51.020]   So you should be happy about that, Jeff.
[00:24:51.020 --> 00:24:52.540]   Once you get it anyways.
[00:24:52.540 --> 00:24:53.540]   But so big changes.
[00:24:53.540 --> 00:24:54.540]   How does it look to you?
[00:24:54.540 --> 00:24:55.540]   Sorry?
[00:24:55.540 --> 00:24:56.540]   How does it look?
[00:24:56.540 --> 00:24:59.900]   Well, it's, so what we're starting to hear about and we've got other things in here to
[00:24:59.900 --> 00:25:04.060]   kind of go along with this is I have a feeling at Google I/O we're going to hear a lot about
[00:25:04.060 --> 00:25:08.220]   the new kind of approach to material design.
[00:25:08.220 --> 00:25:11.780]   Material design now has been around for, is it three years or four years?
[00:25:11.780 --> 00:25:13.620]   It's been around for a decent amount of time.
[00:25:13.620 --> 00:25:14.820]   There have been changes.
[00:25:14.820 --> 00:25:19.220]   But we've been hearing a lot about these big updates to material design.
[00:25:19.220 --> 00:25:26.820]   I've heard material design to the sequel, the Electric Boogaloo.
[00:25:26.820 --> 00:25:31.780]   And so we're going to see a lot of what we're probably seeing here in the Gmail app, which
[00:25:31.780 --> 00:25:37.100]   is a lot of white space, a lot of rounded corners type stuff.
[00:25:37.100 --> 00:25:38.740]   Oh, I just got it.
[00:25:38.740 --> 00:25:39.740]   My other email account.
[00:25:39.740 --> 00:25:40.740]   Oh, you did.
[00:25:40.740 --> 00:25:41.740]   Okay.
[00:25:41.740 --> 00:25:43.540]   So you can look at it and kind of pick it apart.
[00:25:43.540 --> 00:25:47.060]   It does, from a design standpoint, it looks different, very different.
[00:25:47.060 --> 00:25:48.420]   And it needed to be updated.
[00:25:48.420 --> 00:25:50.300]   And I think it looks a little bit more modern.
[00:25:50.300 --> 00:25:54.220]   Bright, rounded, oval buttons, you know, all over the place.
[00:25:54.220 --> 00:25:58.380]   Elements that have movement when you're interacting with the interface, things that kind of move
[00:25:58.380 --> 00:26:03.540]   into place and out, stuff like that when you hover and drag at that whole stuff.
[00:26:03.540 --> 00:26:10.060]   One of those little, those, those, those, those mackerel, those kind of cook those French
[00:26:10.060 --> 00:26:13.100]   cookies, the pastel colors.
[00:26:13.100 --> 00:26:14.100]   Macaron.
[00:26:14.100 --> 00:26:15.100]   Macaron, right.
[00:26:15.100 --> 00:26:16.100]   Macaron.
[00:26:16.100 --> 00:26:20.180]   That, it feels like this thing is about to spew out some macarons.
[00:26:20.180 --> 00:26:21.180]   Is it delicious?
[00:26:21.180 --> 00:26:23.980]   Is it like a, well, you're a little sweet.
[00:26:23.980 --> 00:26:24.980]   Mackerels are fantastic.
[00:26:24.980 --> 00:26:27.340]   What are you talking about?
[00:26:27.340 --> 00:26:29.660]   Do you want your business email painted with macarons?
[00:26:29.660 --> 00:26:30.660]   I don't know.
[00:26:30.660 --> 00:26:31.660]   I don't know.
[00:26:31.660 --> 00:26:34.060]   It just feels a little, a little bubbly.
[00:26:34.060 --> 00:26:35.300]   It's got that bubbly kind of.
[00:26:35.300 --> 00:26:36.780]   At least it's a different.
[00:26:36.780 --> 00:26:37.780]   It's different.
[00:26:37.780 --> 00:26:38.780]   It's a change.
[00:26:38.780 --> 00:26:40.220]   I mean, it was looking pretty tired.
[00:26:40.220 --> 00:26:41.220]   Yeah.
[00:26:41.220 --> 00:26:42.220]   Yeah.
[00:26:42.220 --> 00:26:43.220]   Amen.
[00:26:43.220 --> 00:26:44.220]   It was, yeah.
[00:26:44.220 --> 00:26:48.820]   It was almost looking like old old school Google search, you know, where it's just like
[00:26:48.820 --> 00:26:50.500]   text and that's about it.
[00:26:50.500 --> 00:26:52.940]   Now they're, they're adding in more of the graphical elements.
[00:26:52.940 --> 00:26:54.580]   And you can kind of see some of this stuff.
[00:26:54.580 --> 00:26:56.220]   There's three different views.
[00:26:56.220 --> 00:27:01.180]   So you've got, which they call, you know, they're referring to the density of information.
[00:27:01.180 --> 00:27:03.420]   Default is a little bit more spacious.
[00:27:03.420 --> 00:27:05.580]   It shows attachments in the list view.
[00:27:05.580 --> 00:27:09.820]   So you can click directly on those attachments similar to what we've been doing in inbox.
[00:27:09.820 --> 00:27:11.500]   And it'll open it up full screen and everything.
[00:27:11.500 --> 00:27:16.500]   There's also comfortable, which kind of minimizes things a little bit and then compact, which
[00:27:16.500 --> 00:27:19.940]   is all about maximum density, fitting the most on the screen.
[00:27:19.940 --> 00:27:24.300]   And you don't really have direct access to those attachments that way.
[00:27:24.300 --> 00:27:30.620]   Um, also getting, when you hover over a message, it'll reveal buttons for archive, delete,
[00:27:30.620 --> 00:27:31.620]   read snooze.
[00:27:31.620 --> 00:27:33.620]   I know in inbox, I use that all the time.
[00:27:33.620 --> 00:27:36.820]   Like that makes you fly through your email.
[00:27:36.820 --> 00:27:37.820]   So that's good.
[00:27:37.820 --> 00:27:38.820]   Yeah.
[00:27:38.820 --> 00:27:39.820]   I like that.
[00:27:39.820 --> 00:27:42.180]   I like that some of the features like snoozing and the nudging even.
[00:27:42.180 --> 00:27:47.860]   Um, I have found that the nudging helps because I have a tendency to forget.
[00:27:47.860 --> 00:27:48.860]   Yeah.
[00:27:48.860 --> 00:27:52.820]   Imagine if you seen this, that the nudging, it'll, it'll put highlights at top.
[00:27:52.820 --> 00:27:56.500]   And then if I don't do anything today, it takes them out of highlights and put it back.
[00:27:56.500 --> 00:27:57.500]   So where to go?
[00:27:57.500 --> 00:27:58.500]   You see that?
[00:27:58.500 --> 00:28:04.100]   Because if you, if you're still, you'll still, that's too much.
[00:28:04.100 --> 00:28:07.860]   See, so Jeff, what you're saying is you want to be able to nudge it to a future time.
[00:28:07.860 --> 00:28:10.620]   And then still, if you don't do anything with it, stay up there.
[00:28:10.620 --> 00:28:11.620]   So it, so it doesn't leave.
[00:28:11.620 --> 00:28:12.620]   Is that what you're talking about?
[00:28:12.620 --> 00:28:18.220]   Well, what I'm saying is when, when Gmail, when inbox nudges it for me, you got this four
[00:28:18.220 --> 00:28:20.420]   days ago, you should do this or this is a highlight.
[00:28:20.420 --> 00:28:21.420]   This person went right to your own.
[00:28:21.420 --> 00:28:23.540]   And he knows because of nudges and puts it on top.
[00:28:23.540 --> 00:28:24.540]   I kind of like that.
[00:28:24.540 --> 00:28:27.780]   But then if I, if I ignore it, it's trying to learn from that and say, well, I guess we
[00:28:27.780 --> 00:28:28.780]   were wrong.
[00:28:28.780 --> 00:28:29.780]   You didn't care.
[00:28:29.780 --> 00:28:32.180]   In fact, no, I procrastinate.
[00:28:32.180 --> 00:28:35.100]   And so it disappears back into the, into the regular email again.
[00:28:35.100 --> 00:28:36.100]   And then I really lose it.
[00:28:36.100 --> 00:28:37.100]   Cause I thought, where was it?
[00:28:37.100 --> 00:28:38.100]   I was up top.
[00:28:38.100 --> 00:28:39.100]   No, it's not a company war.
[00:28:39.100 --> 00:28:40.100]   It was up top.
[00:28:40.100 --> 00:28:41.100]   He's doing a year.
[00:28:41.100 --> 00:28:42.100]   Remember it.
[00:28:42.100 --> 00:28:43.100]   No, it's not.
[00:28:43.100 --> 00:28:44.100]   I think they're afraid of irritating you.
[00:28:44.100 --> 00:28:45.100]   Right.
[00:28:45.100 --> 00:28:46.100]   I definitely find the nudging can get you by.
[00:28:46.100 --> 00:28:49.140]   Well, it should be like, like physically nudging someone.
[00:28:49.140 --> 00:28:53.500]   Like if you nudged them too much or too forcefully, it gets super irritating.
[00:28:53.500 --> 00:28:54.500]   And then.
[00:28:54.500 --> 00:28:55.500]   Yeah, I think you're right.
[00:28:55.500 --> 00:28:56.500]   It's a lot useful.
[00:28:56.500 --> 00:28:57.500]   Yeah.
[00:28:57.500 --> 00:28:58.500]   The other thing I mean, you know what I missed?
[00:28:58.500 --> 00:29:02.900]   The one thing I missed from Gmail, the one thing I missed is markers on red.
[00:29:02.900 --> 00:29:05.620]   Oh, yeah, you're right.
[00:29:05.620 --> 00:29:06.980]   Inbox doesn't really have that.
[00:29:06.980 --> 00:29:08.340]   Inbox doesn't let you do that.
[00:29:08.340 --> 00:29:09.740]   Doesn't let you do that.
[00:29:09.740 --> 00:29:11.980]   Why would you do that?
[00:29:11.980 --> 00:29:17.660]   Because I see something on top that is still that way I know that I still got to deal with
[00:29:17.660 --> 00:29:18.660]   it.
[00:29:18.660 --> 00:29:24.100]   I know exactly what you mean because I use, I will leave things on red as a reminder to
[00:29:24.100 --> 00:29:26.580]   me later to refer to it.
[00:29:26.580 --> 00:29:31.020]   And I think I've kind of worked myself out of that habit a little bit more.
[00:29:31.020 --> 00:29:36.660]   I've started to kind of trust a little bit more the, you know, hide this until tomorrow
[00:29:36.660 --> 00:29:37.660]   sort of thing.
[00:29:37.660 --> 00:29:40.540]   And that way when it reappears tomorrow, I do something with it, which is kind of what
[00:29:40.540 --> 00:29:42.020]   you were talking about, Jeff.
[00:29:42.020 --> 00:29:44.260]   But you actually have to do something with it.
[00:29:44.260 --> 00:29:48.060]   I mean, inbox really seems to be built around this idea is inbox zero.
[00:29:48.060 --> 00:29:50.140]   Get it all down, get it off your screen.
[00:29:50.140 --> 00:29:51.580]   I've never used it like that.
[00:29:51.580 --> 00:29:53.340]   I just can't do it.
[00:29:53.340 --> 00:29:54.340]   Really?
[00:29:54.340 --> 00:30:00.820]   Because I'm, if I have more than like 10 messages in the inbox, I start to get anxious.
[00:30:00.820 --> 00:30:01.820]   So, okay.
[00:30:01.820 --> 00:30:02.820]   Okay.
[00:30:02.820 --> 00:30:03.820]   Everybody.
[00:30:03.820 --> 00:30:05.220]   Start emailing Matthew.
[00:30:05.220 --> 00:30:11.380]   And I have this kind of OCD thing where if it's on red, I have to read it.
[00:30:11.380 --> 00:30:13.060]   So I will often mark things.
[00:30:13.060 --> 00:30:16.700]   Everything is red, even if I haven't read it because I just get to stir when I look at
[00:30:16.700 --> 00:30:17.700]   it.
[00:30:17.700 --> 00:30:20.060]   It's like notifications on your phone.
[00:30:20.060 --> 00:30:24.620]   I, I turn most of those off because I, I get so obsessive about it.
[00:30:24.620 --> 00:30:30.020]   I have to, you know, that then I become compulsive about making sure the bubble goes away and
[00:30:30.020 --> 00:30:32.180]   I'm no longer actually achieving anything.
[00:30:32.180 --> 00:30:35.300]   I'm just trying to get rid of the bubble.
[00:30:35.300 --> 00:30:36.300]   So when you, okay.
[00:30:36.300 --> 00:30:41.060]   So if you have the need to read them all, but you aren't equipped to deal with it now,
[00:30:41.060 --> 00:30:43.220]   do you use the snooze till later function?
[00:30:43.220 --> 00:30:44.220]   Is that how you deal with that?
[00:30:44.220 --> 00:30:45.220]   I do.
[00:30:45.220 --> 00:30:50.420]   And I also have folders and stuff that I file things into that I check regularly.
[00:30:50.420 --> 00:30:56.220]   I just, in many cases, I wind up within Buck Zero, like I would say weekly.
[00:30:56.220 --> 00:30:57.220]   Oh, no.
[00:30:57.220 --> 00:30:58.220]   Wow.
[00:30:58.220 --> 00:30:59.220]   That's kind of.
[00:30:59.220 --> 00:31:00.220]   Yes.
[00:31:00.220 --> 00:31:01.220]   I don't even know.
[00:31:01.220 --> 00:31:02.620]   I don't even know what, what that feels like.
[00:31:02.620 --> 00:31:03.620]   Yeah.
[00:31:03.620 --> 00:31:07.860]   I mean, the only way I ever experienced that is if I declare email bankruptcy, which I've
[00:31:07.860 --> 00:31:11.180]   been many times, I just wipe it all out and be like, you know what?
[00:31:11.180 --> 00:31:13.460]   The important stuff I'm going to hear back from someone.
[00:31:13.460 --> 00:31:14.460]   Right.
[00:31:14.460 --> 00:31:16.660]   I know I need three things because I know I need to.
[00:31:16.660 --> 00:31:20.500]   Everything else is red and hidden and I'm starting fresh and it always ends up back there.
[00:31:20.500 --> 00:31:22.300]   I just can't keep it.
[00:31:22.300 --> 00:31:28.980]   I can't look at my wife's email because she uses Gmail partly as a archiving and, but
[00:31:28.980 --> 00:31:30.140]   she doesn't use folders.
[00:31:30.140 --> 00:31:33.780]   It's just the inbox and the trash folder.
[00:31:33.780 --> 00:31:40.140]   So that both of them have 10 or 15,000 unread emails in them.
[00:31:40.140 --> 00:31:42.540]   And I just can't, I can't even look at it.
[00:31:42.540 --> 00:31:43.540]   Yeah.
[00:31:43.540 --> 00:31:45.740]   But you know, it's Google.
[00:31:45.740 --> 00:31:47.860]   So they give you the search function.
[00:31:47.860 --> 00:31:51.460]   That's all you need is to know how to search for a true, true.
[00:31:51.460 --> 00:31:56.540]   I have to confess here that I have turned into that horrible person where basically if it's
[00:31:56.540 --> 00:31:59.540]   important enough, you'll bug me twice or three times.
[00:31:59.540 --> 00:32:00.540]   Right.
[00:32:00.540 --> 00:32:01.540]   Yeah.
[00:32:01.540 --> 00:32:02.540]   It happens.
[00:32:02.540 --> 00:32:03.540]   And I hate myself for that, but it's true.
[00:32:03.540 --> 00:32:04.540]   Yeah.
[00:32:04.540 --> 00:32:07.580]   When you're as famous as we are, Jeff, you know, these are just all the things that come
[00:32:07.580 --> 00:32:09.780]   with the territory.
[00:32:09.780 --> 00:32:11.540]   You jet to peruja as we do.
[00:32:11.540 --> 00:32:12.540]   Right.
[00:32:12.540 --> 00:32:17.500]   Well, as far as Gmail is concerned, a bunch of changes.
[00:32:17.500 --> 00:32:20.140]   So you should definitely jump in there and check it out.
[00:32:20.140 --> 00:32:26.740]   It does have the, what you were talking about, Jeff, where they did bring over the inbox feature
[00:32:26.740 --> 00:32:31.940]   that will resurface those messages after, you know, does this need a follow up?
[00:32:31.940 --> 00:32:32.940]   Right.
[00:32:32.940 --> 00:32:34.940]   Or you emailed someone and you never heard back from them.
[00:32:34.940 --> 00:32:37.180]   Do you want to check in with them again or that sort of stuff?
[00:32:37.180 --> 00:32:40.380]   I both have the presumptive responses to, right?
[00:32:40.380 --> 00:32:41.380]   No.
[00:32:41.380 --> 00:32:43.260]   That's actually, actually they do.
[00:32:43.260 --> 00:32:44.260]   Yes.
[00:32:44.260 --> 00:32:46.740]   Gmail now has the smart replies as well.
[00:32:46.740 --> 00:32:52.740]   I must admit when I, cause I use inbox a lot, but then I go and use Gmail on, you know,
[00:32:52.740 --> 00:32:54.820]   a mobile device or the tablet.
[00:32:54.820 --> 00:33:00.540]   And it's a shock in some cases because I've got to use inbox functionality.
[00:33:00.540 --> 00:33:01.900]   And then I go back to Gmail.
[00:33:01.900 --> 00:33:03.540]   It's like going back in time.
[00:33:03.540 --> 00:33:04.540]   It is.
[00:33:04.540 --> 00:33:05.540]   It really is.
[00:33:05.540 --> 00:33:06.540]   So here's the question.
[00:33:06.540 --> 00:33:17.220]   Is it just reporters trying to stir up fear that we are there worrying that inbox might
[00:33:17.220 --> 00:33:18.220]   disappear?
[00:33:18.220 --> 00:33:24.780]   Man, I meant to do this before the show because someone, I saw someone had posted why they
[00:33:24.780 --> 00:33:27.380]   didn't think inbox was going away.
[00:33:27.380 --> 00:33:34.140]   You know, some of the features that are still in inbox that aren't quite over to Gmail yet.
[00:33:34.140 --> 00:33:35.140]   I don't know.
[00:33:35.140 --> 00:33:41.020]   I think Google is kind of holding the line of, look, inbox is a different methodology.
[00:33:41.020 --> 00:33:42.020]   It's a different idea.
[00:33:42.020 --> 00:33:44.780]   We do some more experimental stuff there.
[00:33:44.780 --> 00:33:48.860]   And it's just, you know, it's, there are a lot of similar features obviously now.
[00:33:48.860 --> 00:33:52.460]   They've, they brought a lot of those features over to Gmail, but those were good features
[00:33:52.460 --> 00:33:53.460]   to bring over.
[00:33:53.460 --> 00:33:54.460]   Right.
[00:33:54.460 --> 00:33:58.140]   Those are very useful features for any account to have.
[00:33:58.140 --> 00:34:01.100]   It feels like inbox is kind of their power user thing.
[00:34:01.100 --> 00:34:06.220]   So they can try things out in that and see what the response is and then use that data
[00:34:06.220 --> 00:34:08.140]   to roll certain things out to Gmail.
[00:34:08.140 --> 00:34:09.140]   Yeah.
[00:34:09.140 --> 00:34:10.140]   I mean, you're right.
[00:34:10.140 --> 00:34:15.260]   Matthew, but there's, there's kind of an irony in that inbox is more automatic versus
[00:34:15.260 --> 00:34:16.260]   stick shift.
[00:34:16.260 --> 00:34:17.260]   Right.
[00:34:17.260 --> 00:34:22.260]   So you think, you know, Gmail is more like using pine to me now.
[00:34:22.260 --> 00:34:23.260]   Wow.
[00:34:23.260 --> 00:34:24.260]   Fine.
[00:34:24.260 --> 00:34:26.260]   There's a flashback.
[00:34:26.260 --> 00:34:27.260]   Yeah.
[00:34:27.260 --> 00:34:32.260]   Right.
[00:34:32.260 --> 00:34:34.260]   Oh, man.
[00:34:34.260 --> 00:34:35.260]   Okay.
[00:34:35.260 --> 00:34:36.260]   Okay.
[00:34:36.260 --> 00:34:37.260]   I feel stupid.
[00:34:37.260 --> 00:34:38.260]   I need a reminder.
[00:34:38.260 --> 00:34:42.260]   Pine even Carson was laughing and I was like, fine.
[00:34:42.260 --> 00:34:45.260]   It's an email system that was developed in the 50s.
[00:34:45.260 --> 00:34:48.260]   So, you know, old people still use it.
[00:34:48.260 --> 00:34:49.260]   Oh, okay.
[00:34:49.260 --> 00:34:50.260]   Yeah.
[00:34:50.260 --> 00:34:51.260]   Yeah.
[00:34:51.260 --> 00:34:54.260]   That's the old, it's the old one be a little email.
[00:34:54.260 --> 00:34:55.260]   Yeah.
[00:34:55.260 --> 00:34:56.260]   We're cars.
[00:34:56.260 --> 00:35:00.260]   That's basically where we've got six, eight old one be a.
[00:35:00.260 --> 00:35:01.260]   Yeah.
[00:35:01.260 --> 00:35:04.060]   So I don't know if inbox is going anywhere.
[00:35:04.060 --> 00:35:07.940]   I think that was the initial fear because it seemed like a lot of the features were
[00:35:07.940 --> 00:35:10.180]   very redundant between the two products.
[00:35:10.180 --> 00:35:14.940]   But in using Gmail for a little bit, even with these new changes today versus what I'm
[00:35:14.940 --> 00:35:19.340]   used to with inbox, I realize like the, the environment is just very different.
[00:35:19.340 --> 00:35:20.340]   You know what I mean?
[00:35:20.340 --> 00:35:21.340]   It feels different.
[00:35:21.340 --> 00:35:26.100]   It's a different kind of flow to how I use inbox versus how I was using Gmail.
[00:35:26.100 --> 00:35:32.220]   And I think comparing Gmail to a stick shift versus inbox to an automatic is a really great,
[00:35:32.220 --> 00:35:34.900]   I think that's a perfect analogy with Gmail.
[00:35:34.900 --> 00:35:38.100]   Even this morning, I felt like I was doing a lot more heavy lifting myself.
[00:35:38.100 --> 00:35:42.100]   Whereas with inbox, maybe I'm just used to it, but I feel like I've got my flow and it
[00:35:42.100 --> 00:35:45.140]   does a lot of things smartly without me having to really get involved.
[00:35:45.140 --> 00:35:48.700]   So hopefully it doesn't go away because I like it.
[00:35:48.700 --> 00:35:54.980]   That should be Google's only metric is do I like it?
[00:35:54.980 --> 00:35:59.260]   But sadly, they don't do that, which is, which we'll talk about in a little bit.
[00:35:59.260 --> 00:36:04.300]   But before that, let's talk about another new product that they revealed today, which
[00:36:04.300 --> 00:36:06.500]   is Google Tasks.
[00:36:06.500 --> 00:36:09.500]   And those of you who have been on Android for a really long time, actually, those of
[00:36:09.500 --> 00:36:16.420]   you have had Gmail for a very long time would remember that Tasks has existed in the past.
[00:36:16.420 --> 00:36:21.100]   And then it really just kind of got de-emphasized to the point to where it went away.
[00:36:21.100 --> 00:36:23.260]   And there was no support.
[00:36:23.260 --> 00:36:29.300]   And now today, there's a new Google Tasks app that has launched again with this bright,
[00:36:29.300 --> 00:36:36.900]   bubbly UI that looks very familiar if you've checked out the new UI on Gmail.
[00:36:36.900 --> 00:36:39.620]   And I guess tasks, yeah, they were in calendar as well.
[00:36:39.620 --> 00:36:41.060]   But they got really de-emphasized.
[00:36:41.060 --> 00:36:44.580]   You really just kind of stopped relying on them because it didn't feel like Google
[00:36:44.580 --> 00:36:47.340]   was giving any sort of attention to it.
[00:36:47.340 --> 00:36:52.740]   But some of the other UI elements that you will probably see at I/O with Material Design
[00:36:52.740 --> 00:36:55.180]   2 is announced likely.
[00:36:55.180 --> 00:37:03.060]   Or is this idea of bottom-oriented UI elements, things that you might skip from one section
[00:37:03.060 --> 00:37:06.660]   of the app to the other being located at the bottom instead of at the top, which we've
[00:37:06.660 --> 00:37:08.580]   seen for a very long time.
[00:37:08.580 --> 00:37:11.020]   And that seems to be a direction that Google's going as well.
[00:37:11.020 --> 00:37:13.580]   So kind of sounds like we're going to see more of that.
[00:37:13.580 --> 00:37:16.580]   And you see that in Google Tasks app.
[00:37:16.580 --> 00:37:19.260]   And I really wonder how they do those meetings right now.
[00:37:19.260 --> 00:37:20.260]   Yeah, that's moving.
[00:37:20.260 --> 00:37:21.260]   I got an idea.
[00:37:21.260 --> 00:37:22.420]   Let's move it to the bottom.
[00:37:22.420 --> 00:37:23.420]   They confuse everybody.
[00:37:23.420 --> 00:37:24.420]   Brilliant.
[00:37:24.420 --> 00:37:25.420]   Let's do that.
[00:37:25.420 --> 00:37:26.420]   Company-wide.
[00:37:26.420 --> 00:37:29.100]   But except for that team and except for that team, they'll get there in six months.
[00:37:29.100 --> 00:37:30.100]   They'll get there in eight months.
[00:37:30.100 --> 00:37:32.260]   But let's the rest of us do that.
[00:37:32.260 --> 00:37:33.260]   It's the bottom year.
[00:37:33.260 --> 00:37:42.240]   Well, if you're looking at user data, changes like that lead to huge increases engagement
[00:37:42.240 --> 00:37:46.760]   because people have to spend longer figuring out how to use the damn thing.
[00:37:46.760 --> 00:37:49.100]   So it looks like they're using it a lot.
[00:37:49.100 --> 00:37:50.100]   I guess so.
[00:37:50.100 --> 00:37:51.100]   You're right.
[00:37:51.100 --> 00:37:54.200]   That's so manipulative, but you're probably absolutely right.
[00:37:54.200 --> 00:37:58.880]   Whether they intend for that or not, it's good for that engagement number.
[00:37:58.880 --> 00:37:59.880]   This too is part of--
[00:37:59.880 --> 00:38:00.880]   I have to say-- sorry.
[00:38:00.880 --> 00:38:05.520]   I have to say task and to-do lists, apps and stuff are lost on me.
[00:38:05.520 --> 00:38:09.680]   A guy, for whatever reason, I can't get myself to use them.
[00:38:09.680 --> 00:38:11.960]   I know that they're really useful lists are great.
[00:38:11.960 --> 00:38:14.320]   I know that lots of people use them effectively.
[00:38:14.320 --> 00:38:16.760]   I'm just not one of those people.
[00:38:16.760 --> 00:38:21.560]   So I email myself reminders and then forget to read them.
[00:38:21.560 --> 00:38:23.400]   I should probably try harder.
[00:38:23.400 --> 00:38:26.840]   Yeah, I feel yeah.
[00:38:26.840 --> 00:38:34.840]   I've definitely had my time using and trying to rely on task apps in order to catalog things.
[00:38:34.840 --> 00:38:40.360]   It was actually really funny logging into this Google tasks app once I installed it
[00:38:40.360 --> 00:38:46.520]   this morning because all of my previous categories were there from six years ago.
[00:38:46.520 --> 00:38:49.200]   It was like walking into a time machine.
[00:38:49.200 --> 00:38:50.200]   Like the second time, yeah.
[00:38:50.200 --> 00:38:54.840]   Happening in my life six years ago and all the things that I was tracking then.
[00:38:54.840 --> 00:38:57.600]   That was the time that I actually tracked it and tried to use it.
[00:38:57.600 --> 00:39:03.320]   Now, kind of like you, sometimes I'll email myself a reminder because I know that it'll
[00:39:03.320 --> 00:39:07.200]   arrive at my inbox and be unread and it'll be that visual reminder that I can then dismiss
[00:39:07.200 --> 00:39:10.200]   later when I'm done with it finally.
[00:39:10.200 --> 00:39:11.520]   But a lot of times I scribble it down.
[00:39:11.520 --> 00:39:16.200]   I write down this a lot more now than I ever have and it's really effective because I don't
[00:39:16.200 --> 00:39:19.720]   have to like, oh, I want to remember this quick thing.
[00:39:19.720 --> 00:39:20.720]   Unlock, open app.
[00:39:20.720 --> 00:39:22.920]   Like I can just be like, put it done.
[00:39:22.920 --> 00:39:23.920]   Move on.
[00:39:23.920 --> 00:39:25.920]   I started using awful with it.
[00:39:25.920 --> 00:39:27.320]   I started using it right.
[00:39:27.320 --> 00:39:31.720]   That was one of the first things I started doing with it because it was so quick to take
[00:39:31.720 --> 00:39:32.720]   a note.
[00:39:32.720 --> 00:39:37.560]   You just jot a few things down and then and it saves it.
[00:39:37.560 --> 00:39:42.080]   I can't, I need to do list to remind me to use the to do list.
[00:39:42.080 --> 00:39:43.080]   Yeah.
[00:39:43.080 --> 00:39:45.680]   You need a daily reminder.
[00:39:45.680 --> 00:39:46.680]   8 a.m.
[00:39:46.680 --> 00:39:49.200]   Remember to use your to do list today.
[00:39:49.200 --> 00:39:53.360]   Reminders, I never, I saw put that reminders and I ignore the reminders.
[00:39:53.360 --> 00:39:54.360]   I'm awful.
[00:39:54.360 --> 00:39:55.360]   I'm just awful.
[00:39:55.360 --> 00:39:56.560]   It's really important.
[00:39:56.560 --> 00:39:59.360]   Someone will yell at me and tell me to do it.
[00:39:59.360 --> 00:40:00.360]   Yeah, right.
[00:40:00.360 --> 00:40:03.960]   It's the whole email me three times that I'll reply to you.
[00:40:03.960 --> 00:40:08.040]   I'm mentality, but applied to time.
[00:40:08.040 --> 00:40:14.280]   So the tasks app, you know, obviously the standard stuff, create tasks, create lists,
[00:40:14.280 --> 00:40:16.960]   edit, manage, drag and drop UI.
[00:40:16.960 --> 00:40:17.960]   You can add details.
[00:40:17.960 --> 00:40:20.440]   You can also add sub tasks if you like.
[00:40:20.440 --> 00:40:23.760]   Also a due date with a reminder, but there is no time assigned.
[00:40:23.760 --> 00:40:27.320]   So you can't say this needs to be done by 10 o'clock tomorrow.
[00:40:27.320 --> 00:40:32.440]   And this I feel like is a really, this next point is a really big miss because I feel
[00:40:32.440 --> 00:40:39.520]   like this is kind of a prime example of sometimes how Google has so many irons in the fire that
[00:40:39.520 --> 00:40:44.280]   their lines just don't meet up and they've missed a great opportunity is that it doesn't
[00:40:44.280 --> 00:40:45.840]   integrate with assistant.
[00:40:45.840 --> 00:40:51.560]   Like I want when I'm at home with my Google home to say, Hey, G, create a task and it would
[00:40:51.560 --> 00:40:54.080]   be a purpose to be able to what is your task and it throw it in there.
[00:40:54.080 --> 00:40:58.560]   Instead, I did that today and it said, Sure, for that, you can talk to swell enterprises.
[00:40:58.560 --> 00:40:59.560]   Is that okay?
[00:40:59.560 --> 00:41:00.680]   It's like, No, it's not okay.
[00:41:00.680 --> 00:41:01.920]   You have a task app now.
[00:41:01.920 --> 00:41:02.920]   Do that instead.
[00:41:02.920 --> 00:41:06.320]   Here's my, here's my little bit of hell.
[00:41:06.320 --> 00:41:11.120]   So I go and I find the Google task link and your administrator has not given you access
[00:41:11.120 --> 00:41:12.280]   to this item.
[00:41:12.280 --> 00:41:19.160]   So you'd say I'm my own administrator, but I have to go, I have to go manually.
[00:41:19.160 --> 00:41:21.560]   It is a 40 step process that I forget every time.
[00:41:21.560 --> 00:41:29.280]   If I want a new app in Chrome, because I'm a G spot, I have to go and go through all these
[00:41:29.280 --> 00:41:34.360]   steps, find this really not intuitive way to say, Yes, I'm giving myself permission
[00:41:34.360 --> 00:41:36.080]   to do what I want to do.
[00:41:36.080 --> 00:41:37.560]   Oh, man.
[00:41:37.560 --> 00:41:42.560]   That's and this is the Jarvis hell that we hear about time again with the Google app.
[00:41:42.560 --> 00:41:43.560]   Sorry.
[00:41:43.560 --> 00:41:46.640]   No, I mean, I think it's, it's constantly an issue, right?
[00:41:46.640 --> 00:41:51.400]   At least you can activate it from day one, but it's not easy.
[00:41:51.400 --> 00:41:55.040]   Apparently you got, you know, and if you weren't you, the administrator, if you were
[00:41:55.040 --> 00:42:01.920]   just user on it on somebody else's account or apps account, you'd have to go through
[00:42:01.920 --> 00:42:06.120]   a lot more trouble to try and convince someone to get in there and do that.
[00:42:06.120 --> 00:42:07.760]   But at least it's possible.
[00:42:07.760 --> 00:42:11.240]   So there's the shining light, I suppose.
[00:42:11.240 --> 00:42:14.440]   I do think integrating with it with the system.
[00:42:14.440 --> 00:42:16.120]   I mean, that's got to happen, right?
[00:42:16.120 --> 00:42:21.000]   Because that's, that's going to be the way 99% of people are going to want to do this
[00:42:21.000 --> 00:42:23.200]   is by saying something.
[00:42:23.200 --> 00:42:29.120]   I mean, I've seen already friends and family with Google homes or Alexa's one of the main
[00:42:29.120 --> 00:42:37.000]   uses in addition to setting timers is shopping lists or reminders or to do lists.
[00:42:37.000 --> 00:42:41.400]   It's just a natural thing that I think people are comfortable doing.
[00:42:41.400 --> 00:42:46.080]   Well, and now, I mean, this, this actually ties in with what you're talking about is
[00:42:46.080 --> 00:42:49.120]   this change that happened last April.
[00:42:49.120 --> 00:42:54.400]   So a year ago where Google changed this so that if you're talking to your Google home
[00:42:54.400 --> 00:43:00.600]   and you try and make a shopping list, instead of putting it into keep, it puts it, it's,
[00:43:00.600 --> 00:43:05.000]   puts it what in the web somewhere you have to actually go on.
[00:43:05.000 --> 00:43:06.000]   Let me try it.
[00:43:06.000 --> 00:43:07.000]   Let me try it.
[00:43:07.000 --> 00:43:08.000]   Pardon me.
[00:43:08.000 --> 00:43:09.000]   audience.
[00:43:09.000 --> 00:43:10.000]   Really?
[00:43:10.000 --> 00:43:11.000]   Okay, Google.
[00:43:11.000 --> 00:43:12.000]   Like a separate site.
[00:43:12.000 --> 00:43:13.000]   Add a task.
[00:43:13.000 --> 00:43:14.000]   Oh, let's try to do stuff.
[00:43:14.000 --> 00:43:15.000]   That's not a do it.
[00:43:15.000 --> 00:43:16.000]   Sorry, Dave.
[00:43:16.000 --> 00:43:17.640]   Not a task.
[00:43:17.640 --> 00:43:18.880]   A shopping list.
[00:43:18.880 --> 00:43:19.880]   I'm trying to do a shopping list.
[00:43:19.880 --> 00:43:20.880]   No, I'm trying to do the task.
[00:43:20.880 --> 00:43:21.880]   Oh, yeah.
[00:43:21.880 --> 00:43:23.920]   Is there, you think that they would have integrated it already?
[00:43:23.920 --> 00:43:24.920]   No.
[00:43:24.920 --> 00:43:25.920]   Yeah.
[00:43:25.920 --> 00:43:26.920]   Even when you have it installed.
[00:43:26.920 --> 00:43:27.920]   Yeah.
[00:43:27.920 --> 00:43:31.880]   So the Google Express, I think it, I think what it does when you're trying doing a shopping
[00:43:31.880 --> 00:43:39.840]   list is that it creates a list in the Google Express interface or website or app or something.
[00:43:39.840 --> 00:43:44.720]   So anyone who is using their, their keep account to, you know, create a shopping list
[00:43:44.720 --> 00:43:47.360]   or whatever, that just kind of went away.
[00:43:47.360 --> 00:43:52.960]   And, you know, maybe with tasks that comes back, but that, I don't know.
[00:43:52.960 --> 00:43:53.960]   It's so confusing.
[00:43:53.960 --> 00:43:55.960]   As with so many things, Google, it's so confusing.
[00:43:55.960 --> 00:44:01.200]   Yeah, I was going to say this is not, this is not a surprise that some things don't work
[00:44:01.200 --> 00:44:02.200]   with other things.
[00:44:02.200 --> 00:44:03.200]   Yeah.
[00:44:03.200 --> 00:44:04.200]   Yeah.
[00:44:04.200 --> 00:44:05.200]   Or that's like life.
[00:44:05.200 --> 00:44:06.200]   Yeah.
[00:44:06.200 --> 00:44:07.200]   Yeah.
[00:44:07.200 --> 00:44:08.200]   Yeah.
[00:44:08.200 --> 00:44:09.200]   Such is life.
[00:44:09.200 --> 00:44:12.280]   Thank you for teaching us a life lesson, Google.
[00:44:12.280 --> 00:44:17.560]   And then just to kind of round out here as far as material design to is concerned, like
[00:44:17.560 --> 00:44:21.640]   I said, we're probably going to hear a lot more about this at Google I/O.
[00:44:21.640 --> 00:44:25.720]   There are a number of other products that we're starting to see this happen.
[00:44:25.720 --> 00:44:31.640]   Chrome Canary now has the whole rounded and bright UI interface, including a pill shaped
[00:44:31.640 --> 00:44:32.640]   URL bar.
[00:44:32.640 --> 00:44:35.720]   And you're going to see that more because I don't know if you guys talked about this
[00:44:35.720 --> 00:44:40.760]   on Twitter a couple of weeks ago when there was a leaked, well, there was a photo that
[00:44:40.760 --> 00:44:46.000]   Google put on one of its blog posts and then changed it to remove this part of it.
[00:44:46.000 --> 00:44:50.560]   But it basically showed the new launcher and down in the home button area, instead of being
[00:44:50.560 --> 00:44:54.520]   a home button, it was like an oblong pill button.
[00:44:54.520 --> 00:45:00.360]   And based on, you know, per people that know about this launcher, they're going to move
[00:45:00.360 --> 00:45:07.880]   more towards a gesture based kind of UI element for the launcher as opposed to the standard
[00:45:07.880 --> 00:45:13.080]   multitasking, multitasking, home button and back button.
[00:45:13.080 --> 00:45:17.120]   And so that pill shape, I think is probably going to end up being a big part of material
[00:45:17.120 --> 00:45:18.120]   design too.
[00:45:18.120 --> 00:45:19.480]   You see it in Chrome Canary.
[00:45:19.480 --> 00:45:26.480]   You see it in the Gmail, the new Gmail interface and the URL bar and a bunch of other places.
[00:45:26.480 --> 00:45:30.840]   So, but the product Sans or is it Sans or Sans?
[00:45:30.840 --> 00:45:35.520]   Product Sans font, which is the same font that Google's logo is in, that seems to be
[00:45:35.520 --> 00:45:38.200]   constant across all these things.
[00:45:38.200 --> 00:45:42.080]   There's a language building in here and they're starting to kind of trickle it out into some
[00:45:42.080 --> 00:45:46.760]   of their other apps, the Play Store, Google Feed is testing it, a bunch of other things.
[00:45:46.760 --> 00:45:51.920]   So apparently that's going to be a big deal at Google I/O in a couple of weeks.
[00:45:51.920 --> 00:45:56.480]   And I guess it should be, I mean, it's what, three, four years old might as well.
[00:45:56.480 --> 00:45:58.120]   Might as well update it.
[00:45:58.120 --> 00:45:59.120]   What else is big?
[00:45:59.120 --> 00:46:00.760]   Oh, this is interesting.
[00:46:00.760 --> 00:46:06.200]   So messaging on Android apparently is not solved.
[00:46:06.200 --> 00:46:11.160]   I think we all realize that.
[00:46:11.160 --> 00:46:12.960]   No kidding.
[00:46:12.960 --> 00:46:16.520]   Rumors now of Google's new messaging effort.
[00:46:16.520 --> 00:46:18.960]   Tell me if you've heard this before.
[00:46:18.960 --> 00:46:22.600]   Called chat, but this time it's a little different.
[00:46:22.600 --> 00:46:30.000]   Chat is not necessarily a new app, but rather a type of RCS, which stands for Rich Communication
[00:46:30.000 --> 00:46:34.320]   Services back in 2015, Google bought Jib.
[00:46:34.320 --> 00:46:38.600]   And primarily they did that to lay the groundwork for what's about to happen.
[00:46:38.600 --> 00:46:41.560]   Google's been working with carriers and manufacturers.
[00:46:41.560 --> 00:46:47.040]   Apparently they've got deals with 48 major carriers, all the major carriers in the US
[00:46:47.040 --> 00:46:51.920]   and a bunch of the NVNOs and other sub carriers, whatever.
[00:46:51.920 --> 00:46:55.760]   And then I was looking forward to this, Jason, because I figured you could explain this to
[00:46:55.760 --> 00:46:56.760]   me.
[00:46:56.760 --> 00:47:02.320]   So this is all about trying to make the link to SMS through a carrier.
[00:47:02.320 --> 00:47:03.320]   What's happening here?
[00:47:03.320 --> 00:47:04.320]   Yeah.
[00:47:04.320 --> 00:47:09.320]   So basically from what I understand about RCS is it's kind of next generation SMS.
[00:47:09.320 --> 00:47:14.560]   SMS as a platform, as a protocol, has been around a very long time.
[00:47:14.560 --> 00:47:21.320]   There's a lot of modern messaging functions that you can't do through SMS.
[00:47:21.320 --> 00:47:22.600]   You can send texts.
[00:47:22.600 --> 00:47:28.120]   You can up to a certain character limit, you can send photos, but it down-resis the photos
[00:47:28.120 --> 00:47:33.000]   and video to reach size limits.
[00:47:33.000 --> 00:47:37.400]   There's a lot of things that it doesn't allow that we're very accustomed to with modern messaging
[00:47:37.400 --> 00:47:38.400]   apps.
[00:47:38.400 --> 00:47:45.640]   So the idea behind this chat, which is RCS, is that it's called Rich Communication Services.
[00:47:45.640 --> 00:47:52.520]   So its aim is to bring some more of those features into an upgrade, more or less, to
[00:47:52.520 --> 00:47:53.520]   SMS.
[00:47:53.520 --> 00:47:59.320]   So features like read receipts, group chats, file transfers, location sharing, user presence.
[00:47:59.320 --> 00:48:03.320]   So when you're typing, the person on the other end would see typing dot dot dot or something
[00:48:03.320 --> 00:48:05.160]   along those lines.
[00:48:05.160 --> 00:48:11.560]   Kind of that dynamic quality of modern messaging apps, but through something that's handled
[00:48:11.560 --> 00:48:13.760]   or managed more on the carrier level.
[00:48:13.760 --> 00:48:18.120]   And that's why Google's been talking with all the carriers because Google has its own
[00:48:18.120 --> 00:48:20.280]   flavor of RCS.
[00:48:20.280 --> 00:48:23.240]   And apparently all the carriers kind of had their own flavor.
[00:48:23.240 --> 00:48:27.240]   But in order to get them all on the same page, Google has been working really hard to say,
[00:48:27.240 --> 00:48:31.480]   "Hey, ours is really good and you should support it," because then all Android users
[00:48:31.480 --> 00:48:36.840]   will be able to talk to each other in a consistent way using RCS.
[00:48:36.840 --> 00:48:41.120]   So now, stupid question time, number one.
[00:48:41.120 --> 00:48:45.160]   So Apple is able to do all that with its messaging because it controls the hardware.
[00:48:45.160 --> 00:48:50.720]   Yeah, and I think Apple, from what little I understand about how iMessage works on the
[00:48:50.720 --> 00:48:58.240]   back end, but from what I understand, Apple has already kind of made these deals with the
[00:48:58.240 --> 00:48:59.640]   carriers to allow for it.
[00:48:59.640 --> 00:49:00.800]   They did that a long time ago.
[00:49:00.800 --> 00:49:04.960]   They did what Google has had a really hard time doing.
[00:49:04.960 --> 00:49:13.640]   And number two, will this finally allow me to send messages seamlessly from both desktop
[00:49:13.640 --> 00:49:17.240]   and phone?
[00:49:17.240 --> 00:49:20.040]   So as far as I know, there will be a web component.
[00:49:20.040 --> 00:49:21.040]   Is that what you're asking?
[00:49:21.040 --> 00:49:27.120]   Like if there's like, "Yeah, can I ask somebody for my wife can from her Apple to my daughter?"
[00:49:27.120 --> 00:49:28.120]   Oh, I see.
[00:49:28.120 --> 00:49:30.720]   But I can't from my Chrome to Android.
[00:49:30.720 --> 00:49:36.720]   Right, from what I understand, the web interface for this at some point will be released and
[00:49:36.720 --> 00:49:38.880]   it'll be similar to what you have with Aloe.
[00:49:38.880 --> 00:49:40.680]   Have you used the web interface for Aloe?
[00:49:40.680 --> 00:49:43.720]   It's basically like a QR code thing?
[00:49:43.720 --> 00:49:46.280]   One day after I owe, then I stopped.
[00:49:46.280 --> 00:49:47.280]   You're out like everybody else.
[00:49:47.280 --> 00:49:48.280]   Right, because it's...
[00:49:48.280 --> 00:49:49.280]   For God it even existed.
[00:49:49.280 --> 00:49:54.600]   Yeah, it's not a website or a plugin that you just open up and boom, you've got access
[00:49:54.600 --> 00:49:55.600]   to it.
[00:49:55.600 --> 00:49:58.320]   You go to the site and it gives you a QR code.
[00:49:58.320 --> 00:50:03.520]   You use your phone with the app to scan the QR code and that sets up a direct link between
[00:50:03.520 --> 00:50:07.200]   your desktop computer and the data that's on your phone.
[00:50:07.200 --> 00:50:12.320]   So basically what you're doing is you're using your desktop as a kind of an extension of
[00:50:12.320 --> 00:50:14.080]   sending a message through your phone.
[00:50:14.080 --> 00:50:15.080]   Does that make sense?
[00:50:15.080 --> 00:50:18.440]   Right, third and last, I think it's last I can be lying, is what's it going to take
[00:50:18.440 --> 00:50:22.240]   to link up all of this Android world with apples?
[00:50:22.240 --> 00:50:26.400]   Well, and that's a really great question because that's one of the very big asterisks here
[00:50:26.400 --> 00:50:31.680]   is that iMessage does not, as far as we know, based on these rumors, by the way, this is
[00:50:31.680 --> 00:50:33.920]   not like fully announced.
[00:50:33.920 --> 00:50:39.320]   Based on these rumors, iMessage does not fully support or support at all this particular
[00:50:39.320 --> 00:50:40.320]   flavor of RCS.
[00:50:40.320 --> 00:50:42.760]   I don't know if it supports RCS at all.
[00:50:42.760 --> 00:50:43.760]   And will not.
[00:50:43.760 --> 00:50:46.360]   I mean, let's face it, Apple has zero.
[00:50:46.360 --> 00:50:51.480]   You know, like there's nothing pushing Apple to do that.
[00:50:51.480 --> 00:50:57.480]   iMessage, I think, is a huge kind of walled garden, something very, very powerful that
[00:50:57.480 --> 00:51:03.160]   in my case, two of my daughters moved back to Apple just so they could use iMessage.
[00:51:03.160 --> 00:51:06.640]   So they moved completely off of platform just to get iMessage.
[00:51:06.640 --> 00:51:09.680]   I mean, that's a hugely powerful thing Apple has.
[00:51:09.680 --> 00:51:14.120]   I find it hard to believe they're just going to open up and integrate with every other,
[00:51:14.120 --> 00:51:17.160]   you know, they want to keep that Apple only, I think.
[00:51:17.160 --> 00:51:23.400]   It's certainly been a very exclusive thing iMessage as far as like you say, people will
[00:51:23.400 --> 00:51:29.240]   stay on the platform, stay on the iOS in some cases because iMessage exists and because
[00:51:29.240 --> 00:51:35.360]   all their friends have iPhones or iOS devices and iMessage has those functions that work
[00:51:35.360 --> 00:51:36.360]   with those other friends.
[00:51:36.360 --> 00:51:40.920]   And if they aren't on that, then they feel like they're being left out.
[00:51:40.920 --> 00:51:48.160]   So in some ways, this, if it rolls out the way that the rumors are pointing to, this
[00:51:48.160 --> 00:51:52.640]   would be Android's equivalent to iMessage in the sense that all Android users would have
[00:51:52.640 --> 00:51:55.040]   that same functionality with other Android users.
[00:51:55.040 --> 00:52:01.000]   So iOS has their playground, Android users have their playground and they're very, very
[00:52:01.000 --> 00:52:04.120]   similar operating independently.
[00:52:04.120 --> 00:52:06.600]   Would there be any reason for those to cross?
[00:52:06.600 --> 00:52:11.280]   I mean, that would be a great world to live in because then, you know, if I'm chatting
[00:52:11.280 --> 00:52:14.720]   with someone that's on an iPhone, I would see that they're typing or whatever, that's
[00:52:14.720 --> 00:52:15.720]   sort of stuff.
[00:52:15.720 --> 00:52:19.920]   But maybe it makes a bit more of a business sense for Apple to keep it exclusive.
[00:52:19.920 --> 00:52:24.600]   It would be great to have that kind of interoperability.
[00:52:24.600 --> 00:52:30.600]   I remember the early instant messaging days when you couldn't message someone on another,
[00:52:30.600 --> 00:52:36.640]   you know, if someone was in Messenger and you had ICQ, you couldn't.
[00:52:36.640 --> 00:52:39.360]   And that was a horrible, horrible time.
[00:52:39.360 --> 00:52:43.120]   Was there a brief time when you could interoperate among those?
[00:52:43.120 --> 00:52:45.280]   So there was something called brief, really interesting.
[00:52:45.280 --> 00:52:46.280]   Yeah, truly interesting.
[00:52:46.280 --> 00:52:49.080]   A lot of the message to multiple.
[00:52:49.080 --> 00:52:53.120]   And then I think ICQ added support for a bunch of them.
[00:52:53.120 --> 00:52:58.640]   But it was a little like only being able to call people who had certain types of phones.
[00:52:58.640 --> 00:53:02.240]   And it was just a nonsensical, it makes sense from a business standpoint.
[00:53:02.240 --> 00:53:05.320]   But as a user, it's horribly irritating.
[00:53:05.320 --> 00:53:11.120]   And I can see definitely from Google's point of view, this is a smart way to kind of make
[00:53:11.120 --> 00:53:14.800]   up for the fact that they missed the sort of messaging boat.
[00:53:14.800 --> 00:53:18.040]   And in fact, they've missed it multiple times.
[00:53:18.040 --> 00:53:21.080]   You know, they probably should have bought WhatsApp.
[00:53:21.080 --> 00:53:22.080]   Maybe they tried to.
[00:53:22.080 --> 00:53:23.080]   I don't know.
[00:53:23.080 --> 00:53:26.160]   But you know, they've tried, I've lost count of the times.
[00:53:26.160 --> 00:53:27.280]   Maybe you know the number of times.
[00:53:27.280 --> 00:53:32.080]   They tried to kind of read you messaging and try again and rework.
[00:53:32.080 --> 00:53:36.920]   And this app and that app and sometimes multiple apps that do similar things.
[00:53:36.920 --> 00:53:42.280]   This seems like a smart way to kind of do an end run around it and make it more of something
[00:53:42.280 --> 00:53:46.280]   that's built into the phone as opposed to just another app that you download.
[00:53:46.280 --> 00:53:47.280]   Yeah.
[00:53:47.280 --> 00:53:51.920]   Did we talk about the self-destructing emails that Google's remember to be doing as well?
[00:53:51.920 --> 00:53:53.200]   No, you know what?
[00:53:53.200 --> 00:53:54.200]   We didn't.
[00:53:54.200 --> 00:54:00.120]   We just came across both email and various of the other communications tools the kids
[00:54:00.120 --> 00:54:02.920]   use today is this notion of self-destruction.
[00:54:02.920 --> 00:54:03.920]   Yeah.
[00:54:03.920 --> 00:54:04.920]   It's memorable.
[00:54:04.920 --> 00:54:05.920]   What we think about that?
[00:54:05.920 --> 00:54:06.920]   Mm-hmm.
[00:54:06.920 --> 00:54:07.920]   Yeah.
[00:54:07.920 --> 00:54:09.840]   I mean, I think that's a good extra feature on Gmail.
[00:54:09.840 --> 00:54:10.840]   You know, it's funny.
[00:54:10.840 --> 00:54:16.520]   I read about that in the rumors that I read about the upcoming Gmail interface.
[00:54:16.520 --> 00:54:19.640]   But I didn't see it written about today and in the release.
[00:54:19.640 --> 00:54:21.160]   I must have just completely missed it.
[00:54:21.160 --> 00:54:22.720]   I'm sure it's in there though.
[00:54:22.720 --> 00:54:28.000]   But the idea is that you could set a time like an expiration date for a message.
[00:54:28.000 --> 00:54:30.640]   You could.
[00:54:30.640 --> 00:54:33.880]   I think you could do two factor authentication for messages.
[00:54:33.880 --> 00:54:34.880]   A bunch of...
[00:54:34.880 --> 00:54:35.880]   I did see that.
[00:54:35.880 --> 00:54:37.600]   Yeah, they were going to add two factor on a per-message page.
[00:54:37.600 --> 00:54:39.720]   For a single message, right?
[00:54:39.720 --> 00:54:40.720]   Yeah.
[00:54:40.720 --> 00:54:42.520]   Let's see here.
[00:54:42.520 --> 00:54:44.560]   Oh, that's an older link, ScooterX.
[00:54:44.560 --> 00:54:47.280]   But yeah, I'm not sure what I think about that.
[00:54:47.280 --> 00:54:53.960]   So if somebody sends me a threatening email, a nasty, horrible email, and I want to save
[00:54:53.960 --> 00:54:58.840]   it for my files because they did something bad to me, I can't.
[00:54:58.840 --> 00:54:59.840]   You can't print it out.
[00:54:59.840 --> 00:55:00.840]   You can't screenshot it.
[00:55:00.840 --> 00:55:01.840]   You can't do all kinds of things.
[00:55:01.840 --> 00:55:03.000]   I guess I could take a camera to it.
[00:55:03.000 --> 00:55:06.840]   But that's kind of it because it's in these sender's control.
[00:55:06.840 --> 00:55:07.840]   Whatever.
[00:55:07.840 --> 00:55:12.320]   This is where when you put things in the sender's control, that's when you get a world of spam
[00:55:12.320 --> 00:55:14.520]   and bad manipulation.
[00:55:14.520 --> 00:55:20.600]   You put it in the recipient's control, things are better.
[00:55:20.600 --> 00:55:21.600]   It's a tough...
[00:55:21.600 --> 00:55:24.240]   That's a tough...
[00:55:24.240 --> 00:55:29.040]   I mean, all sorts cut in two directions are almost all in.
[00:55:29.040 --> 00:55:31.600]   I mean, you can see why those things would be beneficial.
[00:55:31.600 --> 00:55:38.240]   But at the same time, as you point out, there are ways that they could be misused.
[00:55:38.240 --> 00:55:44.040]   I'm thinking now, Mark Zuckerberg and other Facebook executives at one point could delete
[00:55:44.040 --> 00:55:49.800]   messages from their Facebook messenger going back in time.
[00:55:49.800 --> 00:55:55.360]   They could delete them from your inbox, not just their own.
[00:55:55.360 --> 00:56:00.480]   And I think when people mentioned that they were doing this, your response was, "Well,
[00:56:00.480 --> 00:56:02.720]   why are they doing that?
[00:56:02.720 --> 00:56:03.720]   That's wrong.
[00:56:03.720 --> 00:56:06.080]   You should be able to delete something from someone's inbox."
[00:56:06.080 --> 00:56:12.600]   Yet, you can see why they might want to, so that things from years ago don't show up
[00:56:12.600 --> 00:56:15.200]   and get used against you in some way.
[00:56:15.200 --> 00:56:20.520]   Yeah, and that's interesting from the perspective of a thread, an email thread, or a messaging
[00:56:20.520 --> 00:56:23.480]   thread, involves two people.
[00:56:23.480 --> 00:56:25.840]   So it involves two people's words.
[00:56:25.840 --> 00:56:28.760]   If my email...
[00:56:28.760 --> 00:56:33.880]   Would it be that the person that retracts the email, all of their responses disappear?
[00:56:33.880 --> 00:56:36.440]   Or is it that the entire dang thing disappears?
[00:56:36.440 --> 00:56:43.680]   Whatever I happened to write, even though it was the password to my lottery winnings vault,
[00:56:43.680 --> 00:56:47.240]   and my only one that I happened to email that person that one time, it's gone.
[00:56:47.240 --> 00:56:49.080]   I don't get access to that.
[00:56:49.080 --> 00:56:53.680]   Well, what happened with Facebook was people noticed they went back to look at earlier
[00:56:53.680 --> 00:56:57.080]   conversations with Mark Zuckerberg, and there were no responses.
[00:56:57.080 --> 00:57:01.960]   So their responses were there, but then there was just a vacuum on them.
[00:57:01.960 --> 00:57:04.400]   Oh, my goodness.
[00:57:04.400 --> 00:57:05.400]   That's very subtle.
[00:57:05.400 --> 00:57:09.400]   But who's really going back to look at that stuff?
[00:57:09.400 --> 00:57:12.200]   I guess if you had a conversation with Mark Zuckerberg, you are.
[00:57:12.200 --> 00:57:13.600]   This was interesting.
[00:57:13.600 --> 00:57:20.360]   When we're talking about social relationships and social networks, there is no such thing
[00:57:20.360 --> 00:57:22.160]   as just your information.
[00:57:22.160 --> 00:57:23.800]   Do you know what I mean?
[00:57:23.800 --> 00:57:24.800]   Bingo, Matthew.
[00:57:24.800 --> 00:57:25.800]   Exactly.
[00:57:25.800 --> 00:57:31.200]   People are talking about, "I need to control to own my data," or "I need to control what's
[00:57:31.200 --> 00:57:32.200]   done with my data."
[00:57:32.200 --> 00:57:37.320]   Well, in the case of something like Facebook or even an address book, is that my data?
[00:57:37.320 --> 00:57:38.720]   Are my friends' phone numbers?
[00:57:38.720 --> 00:57:39.720]   Do they belong to me?
[00:57:39.720 --> 00:57:40.720]   No.
[00:57:40.720 --> 00:57:41.720]   They belong to my friends.
[00:57:41.720 --> 00:57:45.440]   So why should I be able to control what happens to their phone number?
[00:57:45.440 --> 00:57:47.960]   I'm so glad you say that, Matthew.
[00:57:47.960 --> 00:57:53.000]   When you buy something from Amazon, you tell Amazon to forget, "Well, Amazon, every time
[00:57:53.000 --> 00:57:58.320]   there's a transaction, social or otherwise, one side is not in control of it.
[00:57:58.320 --> 00:57:59.520]   You're exactly right."
[00:57:59.520 --> 00:58:04.240]   I think that's why it's so complicated to come up with ways to deal with this stuff,
[00:58:04.240 --> 00:58:11.280]   because let's say Facebook had to ask everyone if they wanted their information that is their
[00:58:11.280 --> 00:58:13.320]   phone number to be shared.
[00:58:13.320 --> 00:58:19.840]   You'd literally have to ask 2 billion people times, however many, about the contacts in
[00:58:19.840 --> 00:58:20.840]   their address book.
[00:58:20.840 --> 00:58:24.120]   It's just unfeasible.
[00:58:24.120 --> 00:58:29.720]   But even on the simplest level, it's hard to deal with the way that information gets
[00:58:29.720 --> 00:58:32.080]   all intermingled and interconnected.
[00:58:32.080 --> 00:58:33.080]   Yeah.
[00:58:33.080 --> 00:58:34.080]   Yeah.
[00:58:34.080 --> 00:58:38.960]   Obviously, we haven't figured out exactly how that's supposed to go, because it's so confusing
[00:58:38.960 --> 00:58:39.960]   for them.
[00:58:39.960 --> 00:58:43.800]   No, this is the bromide we have is people should control their data.
[00:58:43.800 --> 00:58:46.560]   We'll define data and define control.
[00:58:46.560 --> 00:58:50.640]   It is not as simple by any means.
[00:58:50.640 --> 00:58:57.520]   Yeah, well, especially when you're given controls, but like permissions and capability
[00:58:57.520 --> 00:59:03.960]   of accepting or denying permissions and everything, but if you don't actually know what those
[00:59:03.960 --> 00:59:09.480]   permissions are being used for, or you're using the permissions to control your data to
[00:59:09.480 --> 00:59:14.800]   say, "Yes, I trust you in having access to my camera roll because you're doing some funny
[00:59:14.800 --> 00:59:17.040]   thing that I expect."
[00:59:17.040 --> 00:59:21.800]   Then what happens after that, or maybe contacts is a better example, in this long term, I need
[00:59:21.800 --> 00:59:23.760]   to surface the pictures of my contacts.
[00:59:23.760 --> 00:59:25.040]   So I give you permission.
[00:59:25.040 --> 00:59:30.840]   What happens after that when the company pulls a Cambridge Analytica and says, "Hey, we had
[00:59:30.840 --> 00:59:37.240]   a reason to get it in a public sense for this, but we decided we already have access to it,
[00:59:37.240 --> 00:59:39.200]   so we've decided to do this."
[00:59:39.200 --> 00:59:44.520]   I think that's where people who took that personality quiz said, "Sure, I don't mind
[00:59:44.520 --> 00:59:51.600]   sharing my friends' names or data with a personality quiz because who cares?
[00:59:51.600 --> 00:59:53.600]   It's some dumb Facebook quiz."
[00:59:53.600 --> 00:59:59.480]   And yet all of that data somehow leaks out and then companies use it for all sorts of
[00:59:59.480 --> 01:00:02.840]   nefarious things that you would never have agreed to.
[01:00:02.840 --> 01:00:08.840]   Nobody said, "I'd love for my data to be used by some shadowy organization to target voters
[01:00:08.840 --> 01:00:11.800]   or to try and rig the Kenyan election or something."
[01:00:11.800 --> 01:00:16.240]   Nobody would have agreed to those terms.
[01:00:16.240 --> 01:00:17.240]   No.
[01:00:17.240 --> 01:00:19.440]   Absolutely.
[01:00:19.440 --> 01:00:23.840]   One thing I want to jump back to chat real quick to also point out, because I think this
[01:00:23.840 --> 01:00:31.000]   is something that people have been focusing on, is that this new chat protocol does not
[01:00:31.000 --> 01:00:33.880]   have any sort of end-to-end encryption involved.
[01:00:33.880 --> 01:00:37.720]   I saw a lot of people complaining about that, rightfully.
[01:00:37.720 --> 01:00:43.360]   I feel like in this day and age, we talk so much about security.
[01:00:43.360 --> 01:00:47.720]   It almost seems like a no-brainer for messaging apps to have some sort of end-to-end encryption
[01:00:47.720 --> 01:00:55.160]   integrated should be said, however, that this is a replacement for SMS, which also has no
[01:00:55.160 --> 01:00:57.600]   end-to-end encryption.
[01:00:57.600 --> 01:01:01.000]   To that degree, the net effect is the same, I suppose.
[01:01:01.000 --> 01:01:04.200]   Not that that excuses it, but keep that in mind.
[01:01:04.200 --> 01:01:10.880]   I think end-to-end encryption, I'm not sure exactly how that is coordinated at a carrier
[01:01:10.880 --> 01:01:12.720]   to carrier level.
[01:01:12.720 --> 01:01:21.000]   It's easy for an app that's installed on my phone, and the service servers in the cloud
[01:01:21.000 --> 01:01:23.960]   to facilitate end-to-end encryption.
[01:01:23.960 --> 01:01:26.240]   Is it that easy for the carriers?
[01:01:26.240 --> 01:01:29.960]   The answer is probably that it probably is to some degree, but for whatever reason, it's
[01:01:29.960 --> 01:01:31.400]   not happening here.
[01:01:31.400 --> 01:01:33.160]   That's a fair point.
[01:01:33.160 --> 01:01:42.080]   This is much more like an upgrade to SMS than it is a app that Google has introduced.
[01:01:42.080 --> 01:01:42.760]   Let's see here.
[01:01:42.760 --> 01:01:51.400]   In other things that might change, YouTube remix or whatever they're working on, that
[01:01:51.400 --> 01:01:54.120]   would be the new YouTube music platform.
[01:01:54.120 --> 01:02:00.800]   If you are a user of, and which I am, of Google Play music, the music service, DroidLife
[01:02:00.800 --> 01:02:06.080]   says that they have a source that it's going away at some point, or that it's going away.
[01:02:06.080 --> 01:02:09.160]   Your discussion on all about Android was exactly right about this.
[01:02:09.160 --> 01:02:10.800]   I'm upset about that.
[01:02:10.800 --> 01:02:13.160]   I'm really upset about this.
[01:02:13.160 --> 01:02:15.320]   I am too, because I like Google Play music.
[01:02:15.320 --> 01:02:16.320]   Yeah, I do too.
[01:02:16.320 --> 01:02:18.320]   I use it a lot.
[01:02:18.320 --> 01:02:22.280]   And YouTube search has always sucked.
[01:02:22.280 --> 01:02:27.760]   Ironically, YouTube search has always sucked.
[01:02:27.760 --> 01:02:30.040]   Why they might want to do this?
[01:02:30.040 --> 01:02:36.400]   So that there aren't so many competing things, but Google Play is a perfectly fine service
[01:02:36.400 --> 01:02:39.560]   and useful that lots of people feel like this is--
[01:02:39.560 --> 01:02:41.680]   Ooh, I just had a flash, Matthew.
[01:02:41.680 --> 01:02:42.680]   Uh-oh.
[01:02:42.680 --> 01:02:43.680]   Because you know what?
[01:02:43.680 --> 01:02:47.000]   My way of watching shows is Google Play movies.
[01:02:47.000 --> 01:02:48.920]   Does it put that into YouTube?
[01:02:48.920 --> 01:02:51.920]   Oh, my Lord.
[01:02:51.920 --> 01:02:57.160]   You know that Google Play, that Play rebranding we did years ago, we've decided we're doing
[01:02:57.160 --> 01:02:58.160]   something different.
[01:02:58.160 --> 01:03:00.160]   We're going to brand everything YouTube.
[01:03:00.160 --> 01:03:03.480]   We're going to roll a navigation at the bottom.
[01:03:03.480 --> 01:03:05.480]   That's what the kids want.
[01:03:05.480 --> 01:03:12.080]   Yeah, I mean, to that degree, I guess, I understand from a marketing standpoint that
[01:03:12.080 --> 01:03:15.440]   YouTube is a very strong media brand.
[01:03:15.440 --> 01:03:23.840]   I mean, about as strong as you get with modern day viewing habits and stuff, YouTube's right
[01:03:23.840 --> 01:03:24.840]   at the top.
[01:03:24.840 --> 01:03:30.840]   So, okay, maybe it makes sense to move music in there.
[01:03:30.840 --> 01:03:34.200]   And I don't want to be afraid because it's new and it's changed.
[01:03:34.200 --> 01:03:39.000]   I am always trying to tell myself, don't be afraid because of change and be afraid of
[01:03:39.000 --> 01:03:41.120]   something that hasn't even happened yet.
[01:03:41.120 --> 01:03:47.320]   But man, if they get rid of my ability to keep my music library uploaded on their servers,
[01:03:47.320 --> 01:03:51.640]   that's going to be-- I mean, that could be the straw that breaks my back.
[01:03:51.640 --> 01:03:55.640]   That can be the end for me because that is one of the main things I like about it.
[01:03:55.640 --> 01:03:57.800]   I mean, I use Spotify.
[01:03:57.800 --> 01:04:02.640]   I've even used Amazon Music, but I keep coming back to Google Play.
[01:04:02.640 --> 01:04:06.920]   And the main reason is because I have all kinds of music uploaded in there and it gives
[01:04:06.920 --> 01:04:11.160]   me recommended music and other stuff that's based on my existing library.
[01:04:11.160 --> 01:04:14.880]   And I literally can't get that anywhere else in less life.
[01:04:14.880 --> 01:04:17.480]   Are you paying monthly's Matthew for all those services?
[01:04:17.480 --> 01:04:18.480]   Family.
[01:04:18.480 --> 01:04:19.480]   Yeah.
[01:04:19.480 --> 01:04:20.480]   I know.
[01:04:20.480 --> 01:04:21.480]   Did your wife know?
[01:04:21.480 --> 01:04:22.480]   She's not watching.
[01:04:22.480 --> 01:04:23.480]   I know his wife.
[01:04:23.480 --> 01:04:24.480]   I can tell her.
[01:04:24.480 --> 01:04:25.480]   Please don't.
[01:04:25.480 --> 01:04:37.480]   I just got over the fact that I was paying for Dropbox and Amazon AWS and Google Drive.
[01:04:37.480 --> 01:04:38.480]   Dang.
[01:04:38.480 --> 01:04:42.640]   We're a cloud storage baller.
[01:04:42.640 --> 01:04:44.440]   I got rid of Amazon AWS.
[01:04:44.440 --> 01:04:48.200]   Still Google Drive and Dropbox.
[01:04:48.200 --> 01:04:54.800]   Oh, so I'm a little sad if this ends up being that that's sort of a change.
[01:04:54.800 --> 01:05:01.640]   Also, you know, so we're kind of wondering what happens to the uploaded library.
[01:05:01.640 --> 01:05:04.520]   Would this add too much emphasis on video?
[01:05:04.520 --> 01:05:09.920]   That's another concern that I have because I have no interest in video music.
[01:05:09.920 --> 01:05:13.000]   I also know that it's for the kids, right?
[01:05:13.000 --> 01:05:14.560]   That's how they use YouTube.
[01:05:14.560 --> 01:05:16.760]   I watch my daughters do it.
[01:05:16.760 --> 01:05:23.400]   Their main sort of media consumption vehicle video is a huge part of the way they consume
[01:05:23.400 --> 01:05:27.960]   everything, information of all kinds, music or anything else.
[01:05:27.960 --> 01:05:33.880]   But I admit, if I want to listen to music, I want to see a bunch of music videos or stupid
[01:05:33.880 --> 01:05:35.640]   YouTube compilation things.
[01:05:35.640 --> 01:05:37.000]   I just want to listen to the music.
[01:05:37.000 --> 01:05:38.000]   Yeah.
[01:05:38.000 --> 01:05:39.000]   Yeah.
[01:05:39.000 --> 01:05:42.000]   And sometimes I hear the music from YouTube that's found on there and it's definitely
[01:05:42.000 --> 01:05:47.040]   less quality, you know, lower quality than the way you find on music services.
[01:05:47.040 --> 01:05:53.200]   I have to imagine if they were actually going the route of replacing one for the other entirely,
[01:05:53.200 --> 01:05:57.240]   that they would bring the quality of that music up to standard industry level because
[01:05:57.240 --> 01:06:01.600]   they're also competing against Spotify and, you know, all these other companies that would
[01:06:01.600 --> 01:06:04.000]   eat, you know, eat them for lunch, basically.
[01:06:04.000 --> 01:06:12.760]   It's interesting to me that if they do do this, it's going to give the RIAA even more ammunition,
[01:06:12.760 --> 01:06:17.680]   I think, to argue that they're not paying enough, which is a continual kind of fry from
[01:06:17.680 --> 01:06:18.680]   the record industry.
[01:06:18.680 --> 01:06:24.880]   That YouTube is a massive music consumption engine and it doesn't provide enough, you
[01:06:24.880 --> 01:06:29.800]   know, to copyright holders when I think there's all sorts of problems with that argument.
[01:06:29.800 --> 01:06:38.120]   But if they start to voting more and more time to YouTube as a music delivery system,
[01:06:38.120 --> 01:06:42.800]   get rid of Google Play music, then that just reinforces the idea that that's what YouTube
[01:06:42.800 --> 01:06:43.800]   is.
[01:06:43.800 --> 01:06:50.760]   It's a music discovery and consumption mechanism, in which case the RIAA's argument would be
[01:06:50.760 --> 01:06:53.680]   they should pay as much as Spotify is.
[01:06:53.680 --> 01:06:56.080]   Right.
[01:06:56.080 --> 01:06:58.560]   Another unanswered question is what happens to podcasts?
[01:06:58.560 --> 01:07:04.200]   They rolled podcasts into that app and funny you should ask because apparently Google has
[01:07:04.200 --> 01:07:09.560]   plans to change its podcast strategy and apparently saying apparently Google is enough
[01:07:09.560 --> 01:07:14.280]   to wake up assistant, go away.
[01:07:14.280 --> 01:07:15.280]   That's a new wake word.
[01:07:15.280 --> 01:07:16.280]   Who knew?
[01:07:16.280 --> 01:07:19.280]   I didn't even say the word Google.
[01:07:19.280 --> 01:07:20.280]   I know.
[01:07:20.280 --> 01:07:21.280]   Exactly.
[01:07:21.280 --> 01:07:22.280]   I'm here.
[01:07:22.280 --> 01:07:23.280]   I'm here.
[01:07:23.280 --> 01:07:26.920]   So apparently the goal with this new podcast strategy is to double the amount of podcast listening
[01:07:26.920 --> 01:07:28.920]   in the world over the next couple of years.
[01:07:28.920 --> 01:07:33.160]   That's according to Zach Renau-Wadine, who is Google podcast products.
[01:07:33.160 --> 01:07:36.040]   I'd call that God's work with you.
[01:07:36.040 --> 01:07:38.800]   This is the most important thing in the world.
[01:07:38.800 --> 01:07:42.040]   Pretty important to us, I would say.
[01:07:42.040 --> 01:07:44.280]   And let's see here.
[01:07:44.280 --> 01:07:50.840]   Zach says that Google realizes it's fallen way behind on what iOS has, which is a dedicated
[01:07:50.840 --> 01:07:55.640]   podcast app and a dedicated podcast strategy that's actually worked, pointing out that
[01:07:55.640 --> 01:08:01.320]   the average iPhone listens to over 10 times more podcasting than the average Android.
[01:08:01.320 --> 01:08:04.320]   That is a crazy statistic that I've never heard before.
[01:08:04.320 --> 01:08:06.720]   That's a market opportunity right there.
[01:08:06.720 --> 01:08:07.720]   Holy cow.
[01:08:07.720 --> 01:08:08.720]   Yeah.
[01:08:08.720 --> 01:08:09.720]   No kidding.
[01:08:09.720 --> 01:08:15.280]   I mean, Google, they must have like that number would trigger aneurysms in the courtroom,
[01:08:15.280 --> 01:08:17.280]   I'm sure.
[01:08:17.280 --> 01:08:22.440]   And I hope that it does because if that is actually the case and there are 10, there's
[01:08:22.440 --> 01:08:26.080]   10 times more podcast listening happening on iPhones versus Android.
[01:08:26.080 --> 01:08:28.120]   I mean, that's why.
[01:08:28.120 --> 01:08:29.760]   Like, that's crazy.
[01:08:29.760 --> 01:08:33.240]   Google had listened, not that it was a good app, but it had listened a long time ago.
[01:08:33.240 --> 01:08:37.560]   It had the opportunity to continue building that out and make something out of the podcast
[01:08:37.560 --> 01:08:38.560]   thing.
[01:08:38.560 --> 01:08:42.800]   I think it's definitely been a whole, like a whole in their product suite for sure.
[01:08:42.800 --> 01:08:49.160]   I mean, they've spent orders of magnitude, more resources trying to re-vivify chat in
[01:08:49.160 --> 01:08:55.480]   85 different ways and yet have spent very little time on something that's become a huge
[01:08:55.480 --> 01:08:58.320]   consumption mechanism for lots of people.
[01:08:58.320 --> 01:08:59.320]   Yeah.
[01:08:59.320 --> 01:09:05.120]   So, and Alex actually points out in chat, I think for reminding me of this, says maybe
[01:09:05.120 --> 01:09:13.040]   some of this with Android's lack of podcast strategy is due to the fact that the podcast
[01:09:13.040 --> 01:09:15.560]   section in play music is only available in the US.
[01:09:15.560 --> 01:09:19.120]   That's a constant struggle with Google and launching.
[01:09:19.120 --> 01:09:24.440]   The product hasn't launched outside of that, but apparently according to Pacific content,
[01:09:24.440 --> 01:09:29.560]   which is the medium publication that's publishing a five part series right now that dives into
[01:09:29.560 --> 01:09:35.120]   Google's podcast strategy, it could be because these changes are right around the corner.
[01:09:35.120 --> 01:09:40.200]   It kind of seems like if Google play music, you know, might have an end of life in sight.
[01:09:40.200 --> 01:09:45.400]   If those rumors are true and then this post, these posts with Pacific content, there's
[01:09:45.400 --> 01:09:50.440]   a big change, you know, a lot of change happening all at once kind of makes it seem more likely
[01:09:50.440 --> 01:09:51.440]   anyways.
[01:09:51.440 --> 01:09:56.320]   And in the case of podcasts, it sounds like, you know, based on some of these articles
[01:09:56.320 --> 01:10:03.920]   of Pacific content that they would be doing a bunch of different changes around search
[01:10:03.920 --> 01:10:05.680]   and assistant to kind of integrate it.
[01:10:05.680 --> 01:10:11.280]   So deeper integration with search, making podcasts in search a first class citizen, as
[01:10:11.280 --> 01:10:19.680]   they said, so alongside text, images, video, integrating search into podcast content somehow.
[01:10:19.680 --> 01:10:26.800]   So if we do a show on, I don't know, Google and, you know, Jeff Jarvis and Matthew Ingram
[01:10:26.800 --> 01:10:33.200]   are on that there would be some sort of knowledge on the search side so that when people are
[01:10:33.200 --> 01:10:37.480]   searching for whatever they're searching for, those pass cross and it surfaces it in an
[01:10:37.480 --> 01:10:40.080]   easy to easy to act on what.
[01:10:40.080 --> 01:10:42.680]   This is a natural opportunity for Google.
[01:10:42.680 --> 01:10:49.320]   I mean, search, you know, everyone has a favorite podcast or a couple, but they're hard to find.
[01:10:49.320 --> 01:10:51.960]   It's hard to find new ones.
[01:10:51.960 --> 01:10:53.840]   A lot of it is word of mouth.
[01:10:53.840 --> 01:10:59.160]   A lot of it is, you know, maybe Apple's recommendations, but there's a huge opportunity to sort of
[01:10:59.160 --> 01:11:05.080]   make it easier for people to find good podcasts, sort of find content within podcasts.
[01:11:05.080 --> 01:11:07.440]   And if you imagine within Jewish words, exciting.
[01:11:07.440 --> 01:11:15.280]   Imagine if that was integrated into a system, you ask your Google home, you know, play a
[01:11:15.280 --> 01:11:20.040]   podcast that's about X or find a podcast that's about Y.
[01:11:20.040 --> 01:11:24.120]   And, you know, that kind of consumption just makes a huge amount of sense.
[01:11:24.120 --> 01:11:26.520]   And Google's perfectly positioned to do that.
[01:11:26.520 --> 01:11:27.520]   Yeah.
[01:11:27.520 --> 01:11:28.520]   Right.
[01:11:28.520 --> 01:11:32.120]   By the way, that post was incredibly long and detailed.
[01:11:32.120 --> 01:11:33.720]   It's a five part series.
[01:11:33.720 --> 01:11:34.920]   The five part series.
[01:11:34.920 --> 01:11:35.920]   Yes.
[01:11:35.920 --> 01:11:37.920]   We've done three days worth now.
[01:11:37.920 --> 01:11:39.840]   They've got a few more days left.
[01:11:39.840 --> 01:11:40.840]   Yeah.
[01:11:40.840 --> 01:11:42.840]   They're stretching that out.
[01:11:42.840 --> 01:11:43.840]   Yeah.
[01:11:43.840 --> 01:11:46.640]   Oh, some people really live podcasting.
[01:11:46.640 --> 01:11:47.640]   Yeah.
[01:11:47.640 --> 01:11:49.360]   Well, I think that's cited.
[01:11:49.360 --> 01:11:50.600]   That's what it's all about, right?
[01:11:50.600 --> 01:11:51.600]   Like, what is it?
[01:11:51.600 --> 01:11:56.680]   It's a Pacific content is a podcast, something something about podcast.
[01:11:56.680 --> 01:11:57.680]   Yeah.
[01:11:57.680 --> 01:11:58.680]   Pacific.
[01:11:58.680 --> 01:11:59.680]   Like podcasts.
[01:11:59.680 --> 01:12:02.720]   So we put some podcasts in your podcast.
[01:12:02.720 --> 01:12:03.720]   Yes.
[01:12:03.720 --> 01:12:07.960]   There's a original podcast with brands and one of entrepreneurs, 100 brilliant companies.
[01:12:07.960 --> 01:12:14.400]   There, you know, the more you know, I will say podcast is one of those dumb words that's
[01:12:14.400 --> 01:12:18.680]   stuck around long after anybody remembers what it.
[01:12:18.680 --> 01:12:21.720]   Oh, no, you're going to you're going to piss off Dave Weiner.
[01:12:21.720 --> 01:12:23.840]   No, I like that.
[01:12:23.840 --> 01:12:24.840]   I like podcast.
[01:12:24.840 --> 01:12:28.960]   I think it's it's it's nice that it's retro.
[01:12:28.960 --> 01:12:29.960]   I guess.
[01:12:29.960 --> 01:12:35.480]   And an on record, I mean, the fact that he that a iPod is retro is itself charming.
[01:12:35.480 --> 01:12:36.480]   Yes.
[01:12:36.480 --> 01:12:37.480]   I know.
[01:12:37.480 --> 01:12:38.480]   I mean, we're all.
[01:12:38.480 --> 01:12:41.720]   The thing about the term movie, you know, it moves.
[01:12:41.720 --> 01:12:43.680]   So it's called a movie.
[01:12:43.680 --> 01:12:44.920]   It's a pretty dumb word.
[01:12:44.920 --> 01:12:46.480]   And yeah, we got.
[01:12:46.480 --> 01:12:48.760]   Hello, phone.
[01:12:48.760 --> 01:12:49.760]   Yeah.
[01:12:49.760 --> 01:12:50.760]   Yeah.
[01:12:50.760 --> 01:12:51.760]   Yeah.
[01:12:51.760 --> 01:12:52.760]   Yeah, true.
[01:12:52.760 --> 01:12:54.600]   Yesterday I said it's okay.
[01:12:54.600 --> 01:12:55.920]   I can videotape that.
[01:12:55.920 --> 01:12:59.800]   I, I, I said videotape that held up by phone and I was like, wait a minute.
[01:12:59.800 --> 01:13:00.800]   I don't know.
[01:13:00.800 --> 01:13:03.240]   We still talk about dialing numbers too though.
[01:13:03.240 --> 01:13:04.240]   Yes.
[01:13:04.240 --> 01:13:09.360]   Oh, anyways, exciting stuff for podcasts.
[01:13:09.360 --> 01:13:10.920]   If Google does double down on that.
[01:13:10.920 --> 01:13:11.920]   That's good.
[01:13:11.920 --> 01:13:12.920]   Yeah.
[01:13:12.920 --> 01:13:13.920]   That's something to look forward to.
[01:13:13.920 --> 01:13:18.760]   And speaking of podcasts also, by the way, Google has rolled out an update to assistant
[01:13:18.760 --> 01:13:22.560]   apparently to allow for starting and resuming podcasts between those devices.
[01:13:22.560 --> 01:13:23.880]   I also smart.
[01:13:23.880 --> 01:13:24.880]   Yeah.
[01:13:24.880 --> 01:13:28.400]   I mean, it makes a lot of sense that which basically means you can begin listening to
[01:13:28.400 --> 01:13:33.600]   a podcast on your phone, for example, pause it and then ask your assistant on Google.
[01:13:33.600 --> 01:13:34.760]   Okay, Google.
[01:13:34.760 --> 01:13:37.240]   Play the lab latest this week in Google.
[01:13:37.240 --> 01:13:42.600]   Well, meta.
[01:13:42.600 --> 01:13:46.600]   If we start echoing back to ourselves, it's going to be really weird.
[01:13:46.600 --> 01:13:50.360]   Okay, I'll stop it.
[01:13:50.360 --> 01:13:55.080]   See, and you could pick up three seconds into that podcast on another device.
[01:13:55.080 --> 01:13:58.160]   That is, that's pretty effing amazing.
[01:13:58.160 --> 01:14:02.260]   There's moments when you gotta pull back and say, wow.
[01:14:02.260 --> 01:14:03.480]   - Yeah.
[01:14:03.480 --> 01:14:04.800]   - It's cool.
[01:14:04.800 --> 01:14:05.640]   - It works.
[01:14:05.640 --> 01:14:06.480]   - I can ask for something.
[01:14:06.480 --> 01:14:08.520]   - If you wanted to instantly, it knows where I am.
[01:14:08.520 --> 01:14:09.400]   - Yeah.
[01:14:09.400 --> 01:14:12.160]   - And then it doesn't work, and your all matters.
[01:14:12.160 --> 01:14:13.240]   - And I curse.
[01:14:13.240 --> 01:14:15.480]   Yeah, well, I was just going nuts with my printer.
[01:14:15.480 --> 01:14:17.200]   - Oh don't even work.
[01:14:17.200 --> 01:14:20.120]   - Oh, printers are the words, these are the worst.
[01:14:20.120 --> 01:14:20.960]   - I made them.
[01:14:20.960 --> 01:14:22.160]   - But they are the absolute words.
[01:14:22.160 --> 01:14:23.980]   It took half an hour of it kind of,
[01:14:23.980 --> 01:14:26.760]   took the chucking, trying to figure out
[01:14:26.760 --> 01:14:27.760]   what I was doing.
[01:14:27.760 --> 01:14:28.600]   - They're screaming at it.
[01:14:28.600 --> 01:14:30.400]   - You'd think we'd have those figured out by now,
[01:14:30.400 --> 01:14:31.240]   but no.
[01:14:31.240 --> 01:14:32.080]   - They do not.
[01:14:32.080 --> 01:14:32.920]   - They are eternated.
[01:14:32.920 --> 01:14:35.360]   - They don't have to do drivers anymore, right?
[01:14:35.360 --> 01:14:36.920]   You don't have to install drivers anymore, do you?
[01:14:36.920 --> 01:14:38.240]   - Plus you're using Linux.
[01:14:38.240 --> 01:14:41.800]   - Oh, show off.
[01:14:41.800 --> 01:14:43.960]   - It took me to the better part of a day
[01:14:43.960 --> 01:14:46.640]   to get my printer working on the Linux.
[01:14:46.640 --> 01:14:47.960]   - Oh no.
[01:14:47.960 --> 01:14:49.680]   - That sounds like a fun day.
[01:14:49.680 --> 01:14:50.520]   - Yeah.
[01:14:50.520 --> 01:14:52.400]   - I bought a new laser printer just because it was,
[01:14:52.400 --> 01:14:55.040]   I had Google print in it.
[01:14:55.040 --> 01:14:55.880]   That's why.
[01:14:56.400 --> 01:14:58.360]   (laughs)
[01:14:58.360 --> 01:15:01.400]   - Has it made anything more simple for you,
[01:15:01.400 --> 01:15:02.240]   simplified your life?
[01:15:02.240 --> 01:15:03.400]   - Well, 'cause it's all I can do.
[01:15:03.400 --> 01:15:07.160]   On Chrome OS, you're not installing drivers or anything.
[01:15:07.160 --> 01:15:08.880]   You can't print directly.
[01:15:08.880 --> 01:15:10.560]   So you need to go through Google print,
[01:15:10.560 --> 01:15:13.120]   but once you do that, I can print from anywhere.
[01:15:13.120 --> 01:15:14.160]   It's up the office.
[01:15:14.160 --> 01:15:15.280]   (laughs)
[01:15:15.280 --> 01:15:16.120]   - Right.
[01:15:16.120 --> 01:15:19.040]   - It's like problem there.
[01:15:19.040 --> 01:15:21.960]   - I still remember, this is sort of tangential,
[01:15:21.960 --> 01:15:24.480]   but I remember when people's Wi-Fi,
[01:15:24.480 --> 01:15:26.760]   they would often leave it unlocked.
[01:15:26.760 --> 01:15:30.520]   And so my neighbor had his,
[01:15:30.520 --> 01:15:34.640]   he had a Wi-Fi printer, which was still relatively new.
[01:15:34.640 --> 01:15:37.360]   And I could see it from next door.
[01:15:37.360 --> 01:15:40.480]   And so I considered typing out a message,
[01:15:40.480 --> 01:15:43.240]   saying, "Hey, you should lock down your Wi-Fi
[01:15:43.240 --> 01:15:45.240]   and print it out on its printer,
[01:15:45.240 --> 01:15:47.000]   'cause I've mastered it."
[01:15:47.000 --> 01:15:49.680]   And then the next day, I told him
[01:15:49.680 --> 01:15:51.600]   that I had decided not to do that.
[01:15:51.600 --> 01:15:54.880]   And he said, "That's good, because I had like $50
[01:15:54.880 --> 01:15:57.360]   photo printer paper in there,
[01:15:57.360 --> 01:16:01.360]   and you would have printed a dollar note about my Wi-Fi.
[01:16:01.360 --> 01:16:03.200]   So I'm gonna do that."
[01:16:03.200 --> 01:16:05.520]   - And being Canadian, you apologized for something
[01:16:05.520 --> 01:16:06.880]   you didn't even do.
[01:16:06.880 --> 01:16:07.720]   - I did.
[01:16:07.720 --> 01:16:09.560]   I apologize for even thinking about it.
[01:16:09.560 --> 01:16:10.560]   - Yes.
[01:16:10.560 --> 01:16:12.320]   Although if that had printed out,
[01:16:12.320 --> 01:16:13.960]   he could have just framed it and give it to you.
[01:16:13.960 --> 01:16:15.120]   - He could have framed it, that's right.
[01:16:15.120 --> 01:16:17.120]   - Yeah, it looked really nice on your wall.
[01:16:17.120 --> 01:16:19.200]   (laughs)
[01:16:20.200 --> 01:16:22.640]   - That's like a, and you have to put it up for a year.
[01:16:22.640 --> 01:16:24.720]   That's your payback.
[01:16:24.720 --> 01:16:28.120]   Probably getting close to picks and tips
[01:16:28.120 --> 01:16:29.720]   and all that kind of stuff.
[01:16:29.720 --> 01:16:31.560]   But before I do that, are there any stories
[01:16:31.560 --> 01:16:32.760]   that we haven't talked about
[01:16:32.760 --> 01:16:34.880]   that you guys wanna jump into?
[01:16:34.880 --> 01:16:36.400]   - Hold on here, let's go look at it.
[01:16:36.400 --> 01:16:37.640]   - Yeah, I mean, there's a lot of stuff.
[01:16:37.640 --> 01:16:40.120]   - I think Facebook released its community standards.
[01:16:40.120 --> 01:16:42.920]   What it uses, I'm not supposed to go to detail.
[01:16:42.920 --> 01:16:44.400]   But I think it's a good move.
[01:16:44.400 --> 01:16:46.400]   I guess smart, the same as Google finally released
[01:16:46.400 --> 01:16:48.040]   a report on YouTube.
[01:16:48.040 --> 01:16:48.880]   - Right.
[01:16:48.880 --> 01:16:50.880]   - All this pressure is getting them to be more transparent
[01:16:50.880 --> 01:16:53.040]   about the stuff and why they do what they do,
[01:16:53.040 --> 01:16:55.880]   which is critical, I think.
[01:16:55.880 --> 01:16:57.080]   So I'm glad about that.
[01:16:57.080 --> 01:17:02.080]   And how can we leave behind the secret Amazon robot?
[01:17:02.080 --> 01:17:03.760]   - Oh yes, good.
[01:17:03.760 --> 01:17:05.920]   I'm happy that we did not leave the robot behind
[01:17:05.920 --> 01:17:08.400]   because then it would come back and kill us later.
[01:17:08.400 --> 01:17:12.600]   Code named Vesta, Amazon's Lab 126 department
[01:17:12.600 --> 01:17:13.520]   has been working on this.
[01:17:13.520 --> 01:17:15.640]   They're also, of course, responsible for the Echo,
[01:17:15.640 --> 01:17:19.320]   and the Fire, and a whole bunch of other Amazon stuff.
[01:17:19.320 --> 01:17:22.040]   These would be robots that are separate from,
[01:17:22.040 --> 01:17:24.840]   obviously separate effort from their warehouse
[01:17:24.840 --> 01:17:26.760]   and manufacturing robots,
[01:17:26.760 --> 01:17:28.400]   which are probably not nearly as cute
[01:17:28.400 --> 01:17:30.960]   as this will end up being, I'm guessing.
[01:17:30.960 --> 01:17:34.000]   Job postings, hiring of experts who are working
[01:17:34.000 --> 01:17:37.120]   in this field for a couple of years
[01:17:37.120 --> 01:17:40.920]   to create a home helper robot of some sort.
[01:17:40.920 --> 01:17:43.640]   Do we really know anything about the form factor
[01:17:43.640 --> 01:17:44.920]   or what this actually means?
[01:17:44.920 --> 01:17:48.080]   - Is it like the rumor or all, but I kind of enjoy it.
[01:17:48.080 --> 01:17:51.800]   And they say it's separate from Amazon's warehouse robotics,
[01:17:51.800 --> 01:17:54.480]   but it does make me think that just as AWS
[01:17:54.480 --> 01:17:55.760]   or something they had to do for themselves,
[01:17:55.760 --> 01:17:57.920]   they turned it into a huge business.
[01:17:57.920 --> 01:18:01.120]   Amazon has a huge expertise in robotics, totally.
[01:18:01.120 --> 01:18:06.280]   And robotics that get things and move things, right?
[01:18:06.280 --> 01:18:08.040]   That works in your house.
[01:18:08.040 --> 01:18:10.960]   Yeah, I'd love a robot to get me a beer from the fridge
[01:18:10.960 --> 01:18:11.800]   and bring it to me.
[01:18:11.800 --> 01:18:12.920]   That would be awesome.
[01:18:12.920 --> 01:18:15.520]   - And drop it on the floor as it comes into your food.
[01:18:15.520 --> 01:18:17.520]   - Ah, fall into the puddle of beer.
[01:18:17.520 --> 01:18:18.840]   Yeah, great.
[01:18:18.840 --> 01:18:20.360]   - The problem is these things don't scale,
[01:18:20.360 --> 01:18:23.080]   but you can also imagine if you could have robots
[01:18:23.080 --> 01:18:25.480]   for people who are disabled.
[01:18:25.480 --> 01:18:26.640]   - Yeah.
[01:18:26.640 --> 01:18:28.640]   - And just think like, go get something.
[01:18:28.640 --> 01:18:30.120]   I can say something and I can get it.
[01:18:30.120 --> 01:18:31.920]   That would be very cool.
[01:18:31.920 --> 01:18:34.720]   - Every time the subject of robots comes up,
[01:18:34.720 --> 01:18:38.200]   I think of this artist whose name I can't remember
[01:18:38.200 --> 01:18:42.760]   who creates robots that don't work very well.
[01:18:42.760 --> 01:18:44.400]   So she builds them herself.
[01:18:44.400 --> 01:18:45.320]   - Oh yes.
[01:18:45.320 --> 01:18:48.280]   - So she has one that pours the cereal
[01:18:48.280 --> 01:18:49.800]   and then tries to pour the milk
[01:18:49.800 --> 01:18:52.240]   and milk goes along with the table
[01:18:52.240 --> 01:18:53.880]   and cereal goes everywhere.
[01:18:53.880 --> 01:18:54.720]   Yeah.
[01:18:54.720 --> 01:18:56.160]   - It's the queen of SC robots.
[01:18:56.160 --> 01:18:59.000]   Yeah, she's Simone.
[01:18:59.000 --> 01:19:00.000]   Simone.
[01:19:00.000 --> 01:19:02.200]   - That is the one that I'd seen the cereal.
[01:19:02.200 --> 01:19:03.360]   - That's great.
[01:19:03.360 --> 01:19:06.080]   - I just saw all this one here with lipstick.
[01:19:06.080 --> 01:19:07.320]   - Yeah.
[01:19:07.320 --> 01:19:09.640]   Whenever I think about home robots,
[01:19:09.640 --> 01:19:11.880]   these are the videos that I remember.
[01:19:12.720 --> 01:19:13.640]   (laughing)
[01:19:13.640 --> 01:19:15.640]   - Hey, in the chat now.
[01:19:15.640 --> 01:19:17.160]   - Everything starts somewhere.
[01:19:17.160 --> 01:19:18.560]   I mean-- - 'Cause then the future,
[01:19:18.560 --> 01:19:21.080]   like whenever you see Star Trek or some movie,
[01:19:21.080 --> 01:19:22.800]   you know, the robots work perfectly, right?
[01:19:22.800 --> 01:19:24.440]   They do everything exactly.
[01:19:24.440 --> 01:19:25.960]   And you know that's not gonna happen.
[01:19:25.960 --> 01:19:28.440]   You know, they're gonna blow at a bunch of times
[01:19:28.440 --> 01:19:29.760]   and it's gonna be hilarious.
[01:19:29.760 --> 01:19:32.320]   - Yeah, eventually that'll happen,
[01:19:32.320 --> 01:19:34.240]   but that's a really far ways down the road.
[01:19:34.240 --> 01:19:35.080]   I have a feeling.
[01:19:35.080 --> 01:19:39.720]   And Amazon hopes to get us to Mars
[01:19:39.720 --> 01:19:41.920]   and hopes to get robots in Mars.
[01:19:41.920 --> 01:19:44.120]   - Maybe they'll be like the Boston Dynamics,
[01:19:44.120 --> 01:19:47.200]   the dog robots, the scary dogs.
[01:19:47.200 --> 01:19:51.600]   - Oh, well, I mean, I'm kinda okay with that
[01:19:51.600 --> 01:19:53.040]   'cause I really wanna see you in in person,
[01:19:53.040 --> 01:19:54.240]   but I don't know if I would wanna live
[01:19:54.240 --> 01:19:55.800]   with the Boston Dynamics robot.
[01:19:55.800 --> 01:19:57.200]   - Yeah.
[01:19:57.200 --> 01:19:59.000]   - And by the way, I don't know why I said Amazon's gonna
[01:19:59.000 --> 01:19:59.840]   get us to Mars.
[01:19:59.840 --> 01:20:02.200]   I was obviously getting them confused with the--
[01:20:02.200 --> 01:20:04.160]   - Well, no, Jeff wants to get us up there too.
[01:20:04.160 --> 01:20:05.000]   - Does he?
[01:20:05.000 --> 01:20:05.840]   - Yeah.
[01:20:05.840 --> 01:20:07.720]   - Yeah, no, don't forget, he's got a space for a rep
[01:20:07.720 --> 01:20:09.120]   who knows who wins that. - That's true.
[01:20:09.120 --> 01:20:12.840]   - Yeah, he has ambitions, space ambitions.
[01:20:12.840 --> 01:20:15.360]   Oh, and what about Amazon now delivering stuff
[01:20:15.360 --> 01:20:17.080]   to your trunk, the trunk of your car?
[01:20:17.080 --> 01:20:18.520]   What do we think of that?
[01:20:18.520 --> 01:20:20.560]   - Yeah, that's, I don't know.
[01:20:20.560 --> 01:20:21.920]   Every time one of those comes out,
[01:20:21.920 --> 01:20:24.560]   I think it's an onion article,
[01:20:24.560 --> 01:20:26.640]   like the one where they were gonna get you
[01:20:26.640 --> 01:20:28.320]   to give them access to your house,
[01:20:28.320 --> 01:20:30.800]   like a key to your house, but it's a real thing.
[01:20:30.800 --> 01:20:33.560]   - Yeah, it's like that's happening.
[01:20:33.560 --> 01:20:35.840]   - So satire is impossible now.
[01:20:35.840 --> 01:20:36.960]   - Yeah, eventually.
[01:20:37.960 --> 01:20:40.600]   As relates to technology,
[01:20:40.600 --> 01:20:42.320]   there's always at least someone out there that's like,
[01:20:42.320 --> 01:20:44.280]   "I don't know, that sounds pretty cool to me."
[01:20:44.280 --> 01:20:48.360]   - Somebody I follow said the future will be Amazon warehouse
[01:20:48.360 --> 01:20:51.200]   where you just live in an Amazon warehouse.
[01:20:51.200 --> 01:20:54.360]   It doesn't deliver anything, everything is right there.
[01:20:54.360 --> 01:20:59.560]   - Yeah, I'm at the fifth pod to the left upstairs.
[01:20:59.560 --> 01:21:00.840]   - You live in a container that--
[01:21:00.840 --> 01:21:01.680]   - Exactly.
[01:21:01.680 --> 01:21:03.360]   - You're right here that moves you around, yeah.
[01:21:03.360 --> 01:21:05.440]   - Exactly, it's everything just goes out.
[01:21:05.440 --> 01:21:07.840]   - So what we're saying here is the rumor is wrong.
[01:21:07.840 --> 01:21:09.960]   Amazon's not gonna build robots for the home.
[01:21:09.960 --> 01:21:11.320]   The robot's gonna become your home.
[01:21:11.320 --> 01:21:13.880]   - Yes, Amazon's gonna build your home
[01:21:13.880 --> 01:21:15.840]   and the robot's gonna--
[01:21:15.840 --> 01:21:16.680]   - Someone I'm--
[01:21:16.680 --> 01:21:18.400]   - Your hand is-- - You're talking about
[01:21:18.400 --> 01:21:20.520]   getting access to your home.
[01:21:20.520 --> 01:21:25.320]   One, their view was that Amazon wanted that partly,
[01:21:25.320 --> 01:21:26.800]   not just to drop out packages,
[01:21:26.800 --> 01:21:30.680]   but so that it could then offer other services in your home.
[01:21:30.680 --> 01:21:31.520]   - That makes sense. - You know,
[01:21:31.520 --> 01:21:33.480]   clean your home, whatever.
[01:21:33.480 --> 01:21:35.400]   Cook you dinner, I don't know.
[01:21:35.400 --> 01:21:36.240]   - Looked out here.
[01:21:36.240 --> 01:21:37.680]   - Fine, fine.
[01:21:37.680 --> 01:21:40.600]   I'll take it. - Sure.
[01:21:40.600 --> 01:21:41.920]   - I'm coming home in a half an hour,
[01:21:41.920 --> 01:21:43.600]   please have the pizza done.
[01:21:43.600 --> 01:21:46.040]   - And it's free with Amazon Prime.
[01:21:46.040 --> 01:21:48.720]   - You know what I'd have it make, Matthew?
[01:21:48.720 --> 01:21:49.880]   - What?
[01:21:49.880 --> 01:21:51.040]   - Kachio e peppe.
[01:21:51.040 --> 01:21:56.240]   - That only tastes-- - This is shit in Italy.
[01:21:56.240 --> 01:21:57.280]   - I think you may be right,
[01:21:57.280 --> 01:21:58.640]   I haven't found a good one here.
[01:21:58.640 --> 01:22:00.600]   It's grown up macaroni and cheese,
[01:22:00.600 --> 01:22:02.640]   it's just pasta, cheese and pepper,
[01:22:02.640 --> 01:22:04.160]   and it's the best thing in the world.
[01:22:04.160 --> 01:22:05.760]   - It's a little real.
[01:22:05.760 --> 01:22:08.440]   - It may only tastes good in Italy,
[01:22:08.440 --> 01:22:10.600]   but that's why Amazon has drones.
[01:22:10.600 --> 01:22:11.680]   They can fly it to you. - That's right.
[01:22:11.680 --> 01:22:13.400]   They can fly it for you. - Amazon.
[01:22:13.400 --> 01:22:16.480]   - The old Charlie Brown comic,
[01:22:16.480 --> 01:22:19.880]   I think it was that hot dogs don't taste right
[01:22:19.880 --> 01:22:22.440]   unless they have a baseball stadium wrapped around them.
[01:22:22.440 --> 01:22:23.960]   (laughing)
[01:22:23.960 --> 01:22:26.520]   - That's true, actually.
[01:22:26.520 --> 01:22:29.440]   - Cool, any others before we jump on?
[01:22:29.440 --> 01:22:32.800]   - I think you hit most of the--
[01:22:32.800 --> 01:22:35.240]   - There's a lot of like-- - Flicker being bought by Smugmug.
[01:22:35.240 --> 01:22:36.240]   - Yeah.
[01:22:36.240 --> 01:22:38.520]   - Yeah. - It's all right, Flicker.
[01:22:38.520 --> 01:22:40.520]   - This was my response. - So I went in,
[01:22:40.520 --> 01:22:42.920]   I had gone to Flicker in ages,
[01:22:42.920 --> 01:22:47.120]   and I had the horrible Yahoo password hell.
[01:22:47.120 --> 01:22:50.040]   - Oh yeah. - I got back in today.
[01:22:50.040 --> 01:22:52.600]   You know, it was like whiteboards from five years ago.
[01:22:52.600 --> 01:22:56.440]   Pretty much stupid stuff, I didn't care if I lost.
[01:22:56.440 --> 01:22:57.400]   - Yep.
[01:22:57.400 --> 01:23:00.840]   - But I'm glad that there, you know, it has a life.
[01:23:00.840 --> 01:23:03.000]   - I realized, so go ahead.
[01:23:03.000 --> 01:23:05.600]   - I was just gonna say that I,
[01:23:05.600 --> 01:23:09.040]   a number of years ago, I tried Smugmug,
[01:23:09.040 --> 01:23:10.360]   and it's a great service.
[01:23:10.360 --> 01:23:12.640]   I don't know, like I haven't used it recently,
[01:23:12.640 --> 01:23:16.400]   but if you were even remotely interested in photography,
[01:23:16.400 --> 01:23:21.240]   it was a great alternative to sort of the free services
[01:23:21.240 --> 01:23:23.760]   that did so much, but not enough,
[01:23:23.760 --> 01:23:25.680]   if you wanted to pay a little extra.
[01:23:25.680 --> 01:23:30.280]   Smugmug was a great service and a great business, I thought.
[01:23:30.280 --> 01:23:33.440]   So I hope, I think it's probably a good home for Flicker.
[01:23:33.440 --> 01:23:39.440]   - And yes, Smugmug is just one of those internet properties.
[01:23:39.440 --> 01:23:42.320]   I never tried, I don't even think I have a login for it.
[01:23:42.320 --> 01:23:45.400]   Was the idea behind this that it was just like high quality
[01:23:45.400 --> 01:23:48.280]   photos that you could then print on things?
[01:23:48.280 --> 01:23:51.560]   - Well, design more for if you had a sort of professional
[01:23:51.560 --> 01:23:54.000]   portfolio, if you actually wanted,
[01:23:54.000 --> 01:23:56.680]   not just collect videos to share, or photos to share,
[01:23:56.680 --> 01:24:00.240]   like Flicker, but if you wanted to do it kind of semi-perfinite
[01:24:00.240 --> 01:24:03.000]   professionally, then it looked good.
[01:24:03.000 --> 01:24:05.600]   There were different themes and stuff you could use.
[01:24:05.600 --> 01:24:09.400]   It made it very easy to kind of do it as a business in a way.
[01:24:09.400 --> 01:24:11.120]   - Yeah, okay.
[01:24:11.120 --> 01:24:12.360]   So this reminded me, so I thought,
[01:24:12.360 --> 01:24:14.240]   "Oh, well, good Flicker got rescued for now."
[01:24:14.240 --> 01:24:16.600]   Then I remembered that Delicious was rescued
[01:24:16.600 --> 01:24:19.720]   by the founder of YouTube, and I didn't realize
[01:24:19.720 --> 01:24:21.240]   that I went looking it up.
[01:24:21.240 --> 01:24:22.520]   It's dead, gone.
[01:24:22.520 --> 01:24:25.160]   - Yeah, yeah, it didn't work.
[01:24:25.160 --> 01:24:26.320]   - Goodbye. - Bye bye.
[01:24:26.320 --> 01:24:28.520]   - All those bookmarks I had there.
[01:24:28.520 --> 01:24:30.080]   - Long.
[01:24:30.080 --> 01:24:31.080]   - Yeah. - Not that I would,
[01:24:31.080 --> 01:24:32.400]   not that I missed them.
[01:24:32.400 --> 01:24:35.080]   It's like that closet you didn't clean out for two years,
[01:24:35.080 --> 01:24:38.840]   and your wife says, "Fine," and throw everything in and out.
[01:24:38.840 --> 01:24:43.040]   - I actually went back to an old RSS reader
[01:24:43.040 --> 01:24:45.320]   that I haven't used.
[01:24:45.320 --> 01:24:48.760]   I think it was, it might have been big beer or feedly,
[01:24:48.760 --> 01:24:52.000]   and I hadn't used it in probably six years,
[01:24:52.000 --> 01:24:55.640]   and it was like a time capsule.
[01:24:55.640 --> 01:24:58.640]   And so 80% of the sites that I had in there
[01:24:58.640 --> 01:25:00.800]   don't exist anymore.
[01:25:00.800 --> 01:25:04.000]   And just reading the names, it was like reading
[01:25:04.000 --> 01:25:08.200]   a list of comrades lost at sea or something.
[01:25:08.200 --> 01:25:11.280]   - What happened to the site of the day?
[01:25:11.280 --> 01:25:13.120]   Yes. - Yeah, yeah.
[01:25:13.120 --> 01:25:16.600]   - And they were all gonna change the world at one point.
[01:25:16.600 --> 01:25:18.040]   - Yeah. - Yeah.
[01:25:18.040 --> 01:25:19.920]   - Yep, they all aspire that way.
[01:25:19.920 --> 01:25:23.800]   Yeah, there've been many examples of digital time capsules
[01:25:23.800 --> 01:25:27.720]   on today's show, tasks and Flicker and all these.
[01:25:27.720 --> 01:25:28.920]   - Yeah, it all went.
[01:25:28.920 --> 01:25:30.520]   - Yeah, you open it up and you're like,
[01:25:30.520 --> 01:25:33.880]   "Oh yeah, that's what my digital life was like five years ago."
[01:25:33.880 --> 01:25:37.600]   - I'm sure we'll be saying the same thing about Google Photos
[01:25:37.600 --> 01:25:39.600]   when it goes away and--
[01:25:39.600 --> 01:25:40.680]   - We could do that.
[01:25:40.680 --> 01:25:42.520]   - I know, that would really be really sad.
[01:25:42.520 --> 01:25:44.000]   - No, it'd be not good.
[01:25:44.000 --> 01:25:47.080]   - Yeah, it took us in and ran it into YouTube.
[01:25:47.080 --> 01:25:48.600]   - Yeah. - Oh, man.
[01:25:48.600 --> 01:25:49.720]   - It's YouTube Photo.
[01:25:49.720 --> 01:25:51.320]   (laughing)
[01:25:51.320 --> 01:25:54.280]   - That sounds like a type of hell.
[01:25:54.280 --> 01:25:55.720]   - All right, I think we're good.
[01:25:55.720 --> 01:25:59.200]   I think we've made it through the big news.
[01:25:59.200 --> 01:26:00.800]   Sure, we've missed some stuff.
[01:26:00.800 --> 01:26:03.840]   But we have a few more things to show off
[01:26:03.840 --> 01:26:06.880]   and I guess we can start with a pics.
[01:26:06.880 --> 01:26:09.240]   Jeff, do you have a number?
[01:26:09.240 --> 01:26:11.120]   Some of them. - Yes, I do.
[01:26:11.120 --> 01:26:13.400]   So you missed last week.
[01:26:13.400 --> 01:26:18.120]   I both delighted, amused, amazed and disgusted.
[01:26:18.120 --> 01:26:21.720]   Your colleagues, when I told them about the naked breakfast
[01:26:21.720 --> 01:26:23.720]   taco at Taco Bell.
[01:26:23.720 --> 01:26:26.320]   Where the shell is a fried egg.
[01:26:26.320 --> 01:26:27.760]   (laughing)
[01:26:27.760 --> 01:26:29.640]   This is the thing that exists?
[01:26:29.640 --> 01:26:32.520]   - It absolutely exists, absolutely exists.
[01:26:32.520 --> 01:26:33.880]   And we discussed this last week,
[01:26:33.880 --> 01:26:35.880]   so I thought I would, even though this is new to you
[01:26:35.880 --> 01:26:36.840]   since you were on last week,
[01:26:36.840 --> 01:26:39.880]   I thought I would continue the Taco Bell theme.
[01:26:39.880 --> 01:26:44.880]   Because a college tournament contestant, Rashab Jane,
[01:26:44.880 --> 01:26:48.240]   when asked what he would do with $100,000
[01:26:48.240 --> 01:26:49.640]   if he wanted the championship,
[01:26:49.640 --> 01:26:52.720]   said that he would buy a lifetime supply of Taco Bell.
[01:26:52.720 --> 01:26:54.200]   - Oh my goodness, no.
[01:26:54.200 --> 01:26:56.600]   Sadly, tragically, he didn't--
[01:26:56.600 --> 01:26:58.040]   - It didn't win.
[01:26:58.040 --> 01:27:03.040]   - But Taco Bell sent him $500 worth of gift certificates.
[01:27:03.040 --> 01:27:10.240]   - It's a little small for the amount of publicity
[01:27:10.240 --> 01:27:11.600]   Taco Bell probably got out of that.
[01:27:11.600 --> 01:27:12.600]   - That's probably true, yeah.
[01:27:12.600 --> 01:27:13.440]   - It was better than nothing.
[01:27:13.440 --> 01:27:16.000]   Could have been nothing, so okay.
[01:27:16.000 --> 01:27:18.520]   Man, I have a lifetime supply of Taco Bell.
[01:27:18.520 --> 01:27:21.240]   That would have been a really bad idea, I'm just saying.
[01:27:21.240 --> 01:27:23.120]   - Yeah, I love Taco Bell.
[01:27:23.120 --> 01:27:24.360]   I like Taco Bell a lot.
[01:27:24.360 --> 01:27:29.360]   So there's also a study from marketing firm Stone Temple.
[01:27:29.360 --> 01:27:32.440]   And I never know how to take these marketing firm studies
[01:27:32.440 --> 01:27:37.440]   in the house seriously, but they tested 4942 queries
[01:27:37.440 --> 01:27:41.120]   against Alexa Cortana, Google Assistant,
[01:27:41.120 --> 01:27:43.680]   both home and phone and Siri.
[01:27:43.680 --> 01:27:46.640]   And Google Assistant won on the smartphone.
[01:27:46.640 --> 01:27:50.720]   The surprise here is that Cortana came in a close second.
[01:27:51.400 --> 01:27:52.600]   - Beatting expectation.
[01:27:52.600 --> 01:27:57.560]   - Siri, no surprise.
[01:27:57.560 --> 01:27:59.360]   (laughs)
[01:27:59.360 --> 01:28:01.080]   - Alexa, but yeah.
[01:28:01.080 --> 01:28:06.920]   - Well, that's interesting that Cortana beat Alexa.
[01:28:06.920 --> 01:28:09.600]   - That person gets no respect.
[01:28:09.600 --> 01:28:13.680]   - Yeah, well, they've definitely been kind of a quiet
[01:28:13.680 --> 01:28:16.080]   entrant in all of this, I would say,
[01:28:16.080 --> 01:28:18.560]   of the four of the really big ones anyways.
[01:28:18.560 --> 01:28:20.960]   Siri gets a lot of talk because it's not good.
[01:28:20.960 --> 01:28:23.440]   And so everybody talks about Siri because it's not good.
[01:28:23.440 --> 01:28:25.240]   And that's what you talk about.
[01:28:25.240 --> 01:28:28.040]   Assistant seems, by and large, I just,
[01:28:28.040 --> 01:28:29.880]   and maybe it's just because I'm so entrenched
[01:28:29.880 --> 01:28:33.400]   in Google stuff, but Assistant just always seems to give you
[01:28:33.400 --> 01:28:36.960]   what you're actually looking for the majority of the time.
[01:28:36.960 --> 01:28:38.240]   That's been my experience anyway,
[01:28:38.240 --> 01:28:39.160]   so I'm not surprised there.
[01:28:39.160 --> 01:28:42.840]   But Cortana, I really don't know very much about, and why.
[01:28:42.840 --> 01:28:47.200]   It's on Android, you could totally use it.
[01:28:47.200 --> 01:28:49.240]   You could actually replace it.
[01:28:49.240 --> 01:28:51.720]   I mean, I don't use Assistant that much.
[01:28:51.720 --> 01:28:54.160]   I use Assistant in the car to look up
[01:28:54.160 --> 01:28:57.520]   the exact same Persian restaurant time and time again
[01:28:57.520 --> 01:28:58.360]   so I can call it.
[01:28:58.360 --> 01:29:01.360]   That's all you use it for?
[01:29:01.360 --> 01:29:03.280]   This is the kind of thing I use it for,
[01:29:03.280 --> 01:29:05.160]   because I just say, okay, Google,
[01:29:05.160 --> 01:29:07.760]   search for Persian restaurants in Summit, New Jersey.
[01:29:07.760 --> 01:29:09.200]   Up it comes, and there's a button right there,
[01:29:09.200 --> 01:29:14.200]   it says call, and I ask for my hummus and chicken, come up.
[01:29:14.200 --> 01:29:16.680]   (laughs)
[01:29:16.680 --> 01:29:19.360]   You could go the next step and actually order for me,
[01:29:19.360 --> 01:29:20.520]   which would be nice.
[01:29:20.520 --> 01:29:21.360]   It's coming.
[01:29:21.360 --> 01:29:26.800]   I, man, now on hummus, you've sold it.
[01:29:26.800 --> 01:29:29.480]   And then Amazon could put it in my trunk.
[01:29:29.480 --> 01:29:30.320]   Yes.
[01:29:30.320 --> 01:29:36.920]   Maybe Taco Bell could wrap your next taco in hummus.
[01:29:36.920 --> 01:29:37.960]   I don't know.
[01:29:37.960 --> 01:29:39.000]   I'd take it.
[01:29:39.000 --> 01:29:39.840]   All right.
[01:29:39.840 --> 01:29:40.680]   I would take it.
[01:29:40.680 --> 01:29:41.520]   That would be interesting direction.
[01:29:41.520 --> 01:29:43.440]   Wait, wait, you might have just invented something.
[01:29:43.440 --> 01:29:45.800]   It's like when peanut butter
[01:29:45.800 --> 01:29:47.720]   met chocolate the first time.
[01:29:47.720 --> 01:29:48.560]   (laughs)
[01:29:48.560 --> 01:29:49.560]   - A hummus taco.
[01:29:49.560 --> 01:29:51.200]   - I don't think-- - Right, hummus taco.
[01:29:51.200 --> 01:29:55.200]   That's, that, that beats the Korean tacos, man.
[01:29:55.200 --> 01:29:56.040]   Right?
[01:29:56.040 --> 01:29:56.880]   I'm pretty sure I didn't just--
[01:29:56.880 --> 01:30:00.200]   - I'm pretty sure I just, I didn't just invent something good.
[01:30:00.200 --> 01:30:02.000]   - I mean, I did.
[01:30:02.000 --> 01:30:03.120]   - I may have invented something,
[01:30:03.120 --> 01:30:04.880]   but it's not something that anybody wants to try.
[01:30:04.880 --> 01:30:05.720]   I'm pretty positive.
[01:30:05.720 --> 01:30:06.880]   - We're a weep, man.
[01:30:06.880 --> 01:30:09.080]   - We can all invent something.
[01:30:09.080 --> 01:30:10.400]   It's just isn't any good.
[01:30:10.400 --> 01:30:12.960]   Does it actually exist?
[01:30:12.960 --> 01:30:14.960]   Apparently, vegetarian hummus tacos
[01:30:14.960 --> 01:30:16.520]   with avocado cream.
[01:30:16.520 --> 01:30:17.680]   Okay, but is--
[01:30:17.680 --> 01:30:18.520]   - Well, take it.
[01:30:18.520 --> 01:30:19.360]   - You'll find taco.
[01:30:19.360 --> 01:30:21.760]   Like you're still had Mediterranean ingredients inside.
[01:30:21.760 --> 01:30:24.840]   It's not like taco seasoned ground beans.
[01:30:24.840 --> 01:30:26.800]   - Well, we got these Korean tacos everywhere.
[01:30:26.800 --> 01:30:27.640]   - We can?
[01:30:27.640 --> 01:30:30.000]   - With blue trucks, tomatoes, avocados.
[01:30:30.000 --> 01:30:30.840]   Okay.
[01:30:30.840 --> 01:30:32.840]   - It's like, what is a sandwich?
[01:30:32.840 --> 01:30:33.680]   - That's true.
[01:30:33.680 --> 01:30:36.040]   - That's a good point.
[01:30:36.040 --> 01:30:36.880]   That's a good point.
[01:30:36.880 --> 01:30:37.720]   - Hot dog is stuck in the bottom.
[01:30:37.720 --> 01:30:39.440]   - Whatever it is, it has to have mustard.
[01:30:39.440 --> 01:30:41.160]   (laughs)
[01:30:41.160 --> 01:30:42.560]   I think we're all hungry here.
[01:30:43.720 --> 01:30:48.720]   - Matthew, do you have any tips or that says in here stuff?
[01:30:48.720 --> 01:30:49.560]   What is your stuff?
[01:30:49.560 --> 01:30:53.040]   - Well, there was one thing that happened
[01:30:53.040 --> 01:30:54.520]   that we didn't get around to.
[01:30:54.520 --> 01:30:56.920]   I don't know if you've mentioned it on other shows,
[01:30:56.920 --> 01:31:01.680]   but Amazon just closed the number of prime subscribers
[01:31:01.680 --> 01:31:05.720]   for the first time in Jeff Bezos' shareholder letter.
[01:31:05.720 --> 01:31:07.680]   A hundred million people.
[01:31:07.680 --> 01:31:12.080]   Which to me is just a mind boggling number.
[01:31:13.080 --> 01:31:16.880]   That's, I think, close to a third
[01:31:16.880 --> 01:31:19.320]   of the United States population.
[01:31:19.320 --> 01:31:22.420]   It's three times the population of Canada.
[01:31:22.420 --> 01:31:26.320]   That's just a mind boggling number.
[01:31:26.320 --> 01:31:29.600]   And you think about the services
[01:31:29.600 --> 01:31:31.640]   that Amazon is building into that.
[01:31:31.640 --> 01:31:36.920]   You know, music, product delivery,
[01:31:36.920 --> 01:31:38.440]   all the things that it's thinking about
[01:31:38.440 --> 01:31:40.120]   that we don't even know about.
[01:31:40.120 --> 01:31:45.120]   That's just an unbelievable kind of base of users
[01:31:45.120 --> 01:31:49.440]   to devoted users who paid for this monthly service
[01:31:49.440 --> 01:31:51.480]   that you can then funnel things through.
[01:31:51.480 --> 01:31:54.400]   - Man, no kidding.
[01:31:54.400 --> 01:31:55.280]   All right, yeah, that's right.
[01:31:55.280 --> 01:31:57.080]   So this was news from the '18.
[01:31:57.080 --> 01:31:59.880]   So I think it was like last week and it flew by me
[01:31:59.880 --> 01:32:02.600]   and I didn't really put it into perspective,
[01:32:02.600 --> 01:32:06.560]   but I mean, I'm not surprised Amazon is a beast.
[01:32:06.560 --> 01:32:09.600]   That prime subscription is good.
[01:32:10.440 --> 01:32:11.960]   And continues to get stronger.
[01:32:11.960 --> 01:32:13.800]   I mean, which is why people do it.
[01:32:13.800 --> 01:32:14.640]   - Yeah, exactly.
[01:32:14.640 --> 01:32:18.200]   I mean, it's popular and it's not popular
[01:32:18.200 --> 01:32:20.520]   because it's a really great value,
[01:32:20.520 --> 01:32:24.200]   even though it's expensive, like it's expensive from the top.
[01:32:24.200 --> 01:32:25.960]   It's obviously it's a great value
[01:32:25.960 --> 01:32:27.880]   because everybody understands like,
[01:32:27.880 --> 01:32:30.880]   I ship this much, so it's gonna pay for itself.
[01:32:30.880 --> 01:32:33.320]   I watch this much, so it's gonna pay for itself.
[01:32:33.320 --> 01:32:35.800]   Like there are many ways how it pays for itself
[01:32:35.800 --> 01:32:37.200]   in very short amount of time.
[01:32:37.200 --> 01:32:41.240]   And that's why I'm amazed that it doesn't cost more than it does.
[01:32:41.240 --> 01:32:44.200]   And I'm not giving you any ideas, Amazon, don't do that.
[01:32:44.200 --> 01:32:46.680]   You're making plenty.
[01:32:46.680 --> 01:32:50.240]   I thought I would show off an app
[01:32:50.240 --> 01:32:55.240]   that maybe kind of flew by the radar of this week in Google.
[01:32:55.240 --> 01:32:57.560]   I did a search in the doc and I saw that
[01:32:57.560 --> 01:32:58.840]   it hadn't been mentioned on the show.
[01:32:58.840 --> 01:33:01.400]   So if it has, I apologize.
[01:33:01.400 --> 01:33:03.240]   But it's an app by Google that you may have missed
[01:33:03.240 --> 01:33:07.120]   late last year, Google put out an app called,
[01:33:07.120 --> 01:33:09.760]   I don't know if it's data-ly or day tally.
[01:33:09.760 --> 01:33:11.680]   It's probably day tally.
[01:33:11.680 --> 01:33:12.880]   No, day to day.
[01:33:12.880 --> 01:33:14.000]   Day to day is much better day.
[01:33:14.000 --> 01:33:16.600]   Day tally sounds great on the year.
[01:33:16.600 --> 01:33:17.640]   It's gotta be day to day.
[01:33:17.640 --> 01:33:18.840]   I don't know.
[01:33:18.840 --> 01:33:19.680]   What do I do?
[01:33:19.680 --> 01:33:21.160]   (groans)
[01:33:21.160 --> 01:33:22.280]   I hope it's not.
[01:33:22.280 --> 01:33:24.640]   I don't know.
[01:33:24.640 --> 01:33:26.840]   I mean, really it's gonna go either way
[01:33:26.840 --> 01:33:28.520]   'cause they spelled it that way
[01:33:28.520 --> 01:33:30.200]   and it's open to interpretation.
[01:33:30.200 --> 01:33:33.520]   So your mileage may vary as far as how it's pronounced,
[01:33:33.520 --> 01:33:34.280]   but what is it?
[01:33:34.280 --> 01:33:39.280]   It's a data saving app, data monitoring app for Android
[01:33:39.280 --> 01:33:43.040]   and it does a couple of specific things to do that.
[01:33:43.040 --> 01:33:46.200]   It's actually pretty interesting, pretty effective.
[01:33:46.200 --> 01:33:50.000]   It kind of hinges around this data saver function,
[01:33:50.000 --> 01:33:51.200]   which is a little slider.
[01:33:51.200 --> 01:33:52.600]   Once you give it permission,
[01:33:52.600 --> 01:33:54.440]   what it's doing when I turn it on
[01:33:54.440 --> 01:33:59.440]   is it's actually activating a VPN inside the device.
[01:33:59.440 --> 01:34:01.880]   And when I say VPN, I don't mean this is a VPN
[01:34:01.880 --> 01:34:03.840]   that you connect to out in the cloud.
[01:34:03.840 --> 01:34:07.280]   It's creating a VPN that all data when this is on
[01:34:07.280 --> 01:34:09.200]   now channels through.
[01:34:09.200 --> 01:34:10.560]   And what that allows it to do
[01:34:10.560 --> 01:34:13.000]   is it allows it to analyze the data usage
[01:34:13.000 --> 01:34:15.160]   that's being employed by the apps
[01:34:15.160 --> 01:34:17.320]   that you have installed on your device.
[01:34:17.320 --> 01:34:19.240]   So you can see on the side here,
[01:34:19.240 --> 01:34:21.680]   I've got audible is locked.
[01:34:21.680 --> 01:34:23.720]   Essentially what this means is that
[01:34:23.720 --> 01:34:27.400]   when the data saver is on,
[01:34:27.400 --> 01:34:30.600]   any activity that might come from Google to use data,
[01:34:30.600 --> 01:34:33.200]   it will encounter because it's passing through that VPN
[01:34:33.200 --> 01:34:35.720]   that will encounter the fact that it's locked
[01:34:35.720 --> 01:34:40.560]   and it will not allow that app to pull on data usage
[01:34:40.560 --> 01:34:42.080]   when I'm out and about.
[01:34:42.080 --> 01:34:45.120]   It restricts based on how you set it
[01:34:45.120 --> 01:34:48.160]   so I could set any of these to not do it.
[01:34:48.160 --> 01:34:50.360]   I don't know why I would have inbox set,
[01:34:50.360 --> 01:34:53.000]   but now inbox is allowed to have mobile data.
[01:34:53.000 --> 01:34:56.840]   And if you've got high data apps or maybe apps
[01:34:56.840 --> 01:34:58.880]   that you don't trust what they're doing in the background
[01:34:58.880 --> 01:35:02.480]   or maybe they update randomly or whatever,
[01:35:02.480 --> 01:35:04.440]   you can activate that when you're out and about
[01:35:04.440 --> 01:35:07.120]   and that will make sure that you aren't burning through
[01:35:07.120 --> 01:35:09.440]   your data when you don't want to be.
[01:35:09.440 --> 01:35:11.520]   So if you want to save your data usage,
[01:35:11.520 --> 01:35:13.560]   this is one way to do it.
[01:35:13.560 --> 01:35:15.640]   And it's just kind of cool how it does it,
[01:35:15.640 --> 01:35:17.800]   activating that VPN on the device.
[01:35:17.800 --> 01:35:19.200]   I can switch it back off.
[01:35:19.200 --> 01:35:22.800]   Hold on, it's easier than it looks.
[01:35:22.800 --> 01:35:26.360]   And it's now off and my device will operate as normal.
[01:35:26.360 --> 01:35:28.360]   And then also it has this function here
[01:35:28.360 --> 01:35:31.760]   for finding Wi-Fi that's local and in the area,
[01:35:31.760 --> 01:35:33.760]   which is another way to obviously save
[01:35:33.760 --> 01:35:35.080]   on your mobile data if you're out and about.
[01:35:35.080 --> 01:35:37.560]   And you don't want to use your mobile data,
[01:35:37.560 --> 01:35:41.120]   but you need to do something that requires it,
[01:35:41.120 --> 01:35:45.360]   you can find based on your location nearby Wi-Fi that's open
[01:35:45.360 --> 01:35:46.760]   and it will point you in that direction.
[01:35:46.760 --> 01:35:48.640]   I think maybe I'm guessing there,
[01:35:48.640 --> 01:35:53.320]   they're kind of pointing to similar Wi-Fi access points
[01:35:53.320 --> 01:35:56.640]   that they already know about as trusted Wi-Fi access points
[01:35:56.640 --> 01:35:59.880]   thanks to Project Fi, which is a part of that service
[01:35:59.880 --> 01:36:03.040]   that Project Fi will know when you're in a certain area,
[01:36:03.040 --> 01:36:05.080]   when you're close to a trusted Wi-Fi
[01:36:05.080 --> 01:36:07.080]   and it will opt for that so that you save on data.
[01:36:07.080 --> 01:36:09.200]   I think that's what you're getting out of data layer,
[01:36:09.200 --> 01:36:10.320]   data layer, whatever it is.
[01:36:10.320 --> 01:36:12.360]   So anyways, if you hadn't heard about it,
[01:36:12.360 --> 01:36:14.320]   it's kind of an interesting way to save data.
[01:36:14.320 --> 01:36:17.160]   And you should check it out for Android,
[01:36:17.160 --> 01:36:21.200]   maybe save some of your data allowance every month by using.
[01:36:21.200 --> 01:36:22.320]   - Somewhere right now in Google,
[01:36:22.320 --> 01:36:23.640]   someone is screaming at us.
[01:36:23.640 --> 01:36:25.680]   - I know. - Correct pronunciation.
[01:36:25.680 --> 01:36:27.320]   - We're guaranteed to have got it wrong
[01:36:27.320 --> 01:36:28.880]   because we said it both ways.
[01:36:28.880 --> 01:36:32.440]   So they're mad no matter what.
[01:36:32.440 --> 01:36:36.480]   You guys, this is a lot of fun as it usually is.
[01:36:36.480 --> 01:36:37.560]   I love doing the show with you guys
[01:36:37.560 --> 01:36:38.640]   and I really appreciate it.
[01:36:38.640 --> 01:36:40.720]   Thanks to you both.
[01:36:40.720 --> 01:36:41.840]   - Oh, thanks for having me.
[01:36:41.840 --> 01:36:42.680]   - Absolutely. - Thank you.
[01:36:42.680 --> 01:36:44.440]   You're always, you're a great at this, Jason.
[01:36:44.440 --> 01:36:46.720]   - Yeah, thanks, it's a lot of fun.
[01:36:46.720 --> 01:36:50.600]   Matthew Ingram, chief digital writer at cjr.org.
[01:36:50.600 --> 01:36:52.200]   What do you want to leave people with?
[01:36:52.200 --> 01:36:53.280]   What are you working on?
[01:36:53.280 --> 01:36:54.880]   What can people expect from you?
[01:36:54.880 --> 01:36:58.840]   - Well, I guess the big thing I'm working on
[01:36:58.840 --> 01:37:02.840]   right now is we're going on a feature about Google
[01:37:02.840 --> 01:37:06.720]   and Facebook and their funding of journalism.
[01:37:06.720 --> 01:37:10.920]   So something I know Jeff is interested in as well.
[01:37:10.920 --> 01:37:14.800]   And just generally keeping an eye on the big platforms
[01:37:14.800 --> 01:37:18.920]   and how they're impacting media and technology.
[01:37:18.920 --> 01:37:25.200]   - Awesome, and that is cjr. Columbia journalism review
[01:37:25.200 --> 01:37:26.040]   to find that.
[01:37:26.040 --> 01:37:28.760]   When do you think that's going to be posting?
[01:37:28.760 --> 01:37:29.720]   - Coming soon.
[01:37:29.720 --> 01:37:32.080]   - Coming soon to a website near you.
[01:37:32.080 --> 01:37:34.800]   All right, on, thank you, Matthew.
[01:37:34.800 --> 01:37:36.440]   Really appreciate it. - Thanks.
[01:37:36.440 --> 01:37:38.280]   - And then of course, Jeff Jarvis,
[01:37:38.280 --> 01:37:42.120]   always so much fun, buzzmachine.com.
[01:37:42.120 --> 01:37:43.080]   What are you working on?
[01:37:43.080 --> 01:37:45.200]   What do you want to leave people with?
[01:37:45.200 --> 01:37:46.520]   - Just causing trouble.
[01:37:46.520 --> 01:37:47.480]   - Causing trouble.
[01:37:47.480 --> 01:37:51.000]   Mischief, mayhem, you're a Republican after all.
[01:37:51.000 --> 01:37:53.640]   As they'd-- - Blackberry lover.
[01:37:53.640 --> 01:37:55.240]   - You'd be careful here, yeah.
[01:37:55.240 --> 01:37:57.160]   (laughs)
[01:37:57.160 --> 01:37:59.360]   - That's true, I should be careful.
[01:37:59.360 --> 01:38:01.600]   - I see I'm also thinking, I like guns.
[01:38:01.600 --> 01:38:03.720]   - Really?
[01:38:03.720 --> 01:38:07.560]   Like it's, it's, okay, getting back to that.
[01:38:07.560 --> 01:38:08.400]   - And golf.
[01:38:08.400 --> 01:38:10.400]   - This axiom thing for a second.
[01:38:10.400 --> 01:38:14.000]   How do we find out what axiom has on all of us?
[01:38:14.000 --> 01:38:15.640]   Is that what's-- - Hold on.
[01:38:15.640 --> 01:38:20.640]   Yeah, I get your A-C-A-X-C-I-O-M.
[01:38:20.640 --> 01:38:22.600]   - You get it, basically.
[01:38:22.600 --> 01:38:24.480]   - A-X-C-I-O-M.
[01:38:24.480 --> 01:38:26.800]   - Considerative, hold on.
[01:38:26.800 --> 01:38:29.080]   There is a URL for this, I got a report it is,
[01:38:29.080 --> 01:38:30.280]   but be one second here. - Sorry, that's right.
[01:38:30.280 --> 01:38:31.720]   - So we'll be helpful.
[01:38:31.720 --> 01:38:35.000]   - I just realized, like this is interesting information.
[01:38:35.000 --> 01:38:36.360]   There aren't many times that you get to--
[01:38:36.360 --> 01:38:40.360]   - There actually is privacy policy, oh heck.
[01:38:40.360 --> 01:38:44.360]   - C-I-O-M.
[01:38:44.360 --> 01:38:48.080]   Reveal data, I don't know.
[01:38:48.080 --> 01:38:49.080]   Hey everybody, let's all see.
[01:38:49.080 --> 01:38:51.040]   - If you go to axiom at the bottom,
[01:38:51.040 --> 01:38:53.720]   I think there's a privacy link, 'cause we're all talented.
[01:38:53.720 --> 01:38:54.840]   No, I can't find that.
[01:38:54.840 --> 01:38:57.040]   Consumer data information.
[01:38:57.040 --> 01:39:00.520]   - Privacy, no, there, I found it, hold on, privacy.
[01:39:00.520 --> 01:39:02.640]   - Somewhere on their site, I'm guessing.
[01:39:02.640 --> 01:39:04.240]   - I'm gonna pop out of the car.
[01:39:04.240 --> 01:39:05.560]   - Yeah, they need a view.
[01:39:05.560 --> 01:39:07.800]   - You could also opt out, right.
[01:39:07.800 --> 01:39:10.920]   Oh, aboutthedata.com, there it is.
[01:39:10.920 --> 01:39:13.120]   - About the data that I come out of.
[01:39:13.120 --> 01:39:16.200]   - Matthew says it differently, 'cause he's Canadian.
[01:39:16.200 --> 01:39:17.200]   - What did I say?
[01:39:17.200 --> 01:39:18.920]   - You said a boot?
[01:39:18.920 --> 01:39:19.840]   - I said data.com.
[01:39:19.840 --> 01:39:23.840]   - I mean, the Americans can't, I cannot mimic the Canadian OU.
[01:39:24.720 --> 01:39:27.800]   - I thought you, the Americans make it sound Scottish.
[01:39:27.800 --> 01:39:29.280]   - It's not. - Not that.
[01:39:29.280 --> 01:39:30.200]   - No, it's not.
[01:39:30.200 --> 01:39:33.920]   It's interesting, there's a fascinating article about it.
[01:39:33.920 --> 01:39:38.600]   The Canadian, is it a dip phone?
[01:39:38.600 --> 01:39:43.600]   Anyway, it's much closer to a boat than it is to a boot.
[01:39:43.600 --> 01:39:45.960]   - Yes, it is, right.
[01:39:45.960 --> 01:39:49.520]   But it's, I can mimic a lot of it, 'cause I can't mimic it.
[01:39:49.520 --> 01:39:50.840]   And I love it.
[01:39:50.840 --> 01:39:51.680]   - That's the one thing we have.
[01:39:51.680 --> 01:39:53.680]   - Yes, you go to that site.
[01:39:53.680 --> 01:39:55.000]   - I love it.
[01:39:55.000 --> 01:39:57.680]   - And so you click on the stuff,
[01:39:57.680 --> 01:40:00.720]   you have to prove it's you, various ways, fine.
[01:40:00.720 --> 01:40:02.840]   And then, it also gives you the opportunity
[01:40:02.840 --> 01:40:04.840]   to find out about their marketing partners.
[01:40:04.840 --> 01:40:06.200]   These are the people I sit down like you.
[01:40:06.200 --> 01:40:08.680]   - I just know it's you as soon as you click on the website.
[01:40:08.680 --> 01:40:09.520]   - Exactly.
[01:40:09.520 --> 01:40:14.520]   Well, I actually, I forgot I had an account here,
[01:40:14.520 --> 01:40:16.800]   as I used to demonstrate this for students.
[01:40:16.800 --> 01:40:19.160]   When people got panicky about, you know,
[01:40:19.160 --> 01:40:21.040]   this is years ago about Facebook and stuff,
[01:40:21.040 --> 01:40:22.880]   I'd say, let me freak out now.
[01:40:22.880 --> 01:40:24.960]   I'll creep you out and I'll go to Axiom
[01:40:24.960 --> 01:40:27.440]   and I would say, give me, oh, I don't know,
[01:40:27.440 --> 01:40:31.440]   women between the ages of, you know, 18 and 25
[01:40:31.440 --> 01:40:34.360]   who live within half mile of this address
[01:40:34.360 --> 01:40:37.400]   who have a car, who have a college education or whatever.
[01:40:37.400 --> 01:40:40.560]   And then you get actual names you can pay for names
[01:40:40.560 --> 01:40:41.400]   and addresses.
[01:40:41.400 --> 01:40:42.560]   - What?
[01:40:42.560 --> 01:40:43.400]   - Yeah.
[01:40:43.400 --> 01:40:45.400]   - 'Cause you can do a direct mail campaigns.
[01:40:45.400 --> 01:40:46.400]   - Oh, right.
[01:40:46.400 --> 01:40:47.240]   Wow, that's crazy.
[01:40:47.240 --> 01:40:48.080]   - Same.
[01:40:48.080 --> 01:40:53.080]   - So it's me, that off net data world is much creepier
[01:40:53.080 --> 01:40:56.200]   and freerier than the online stuff,
[01:40:56.200 --> 01:40:59.120]   most of which is either stuff you choose to share
[01:40:59.120 --> 01:41:01.600]   or they don't have your name.
[01:41:01.600 --> 01:41:03.480]   - Wow.
[01:41:03.480 --> 01:41:06.600]   - But interesting, yeah, I hadn't heard of this site.
[01:41:06.600 --> 01:41:11.000]   Aboutthedata.com, that's like a bonus.
[01:41:11.000 --> 01:41:12.360]   - About tool.
[01:41:12.360 --> 01:41:15.760]   - About about the data.com.
[01:41:15.760 --> 01:41:17.680]   - Someone told me when I first went to the US,
[01:41:17.680 --> 01:41:21.400]   remember it's about not a boat
[01:41:21.400 --> 01:41:25.040]   and proper response to thank you is, uh-huh.
[01:41:25.040 --> 01:41:27.200]   - Uh-huh, uh-huh.
[01:41:27.200 --> 01:41:28.760]   That's good.
[01:41:28.760 --> 01:41:30.160]   Oh, and I'm so guilty of that.
[01:41:30.160 --> 01:41:32.600]   - All right.
[01:41:32.600 --> 01:41:35.480]   - Well, no, no, no, no, no, you see now actually,
[01:41:35.480 --> 01:41:38.160]   you Canadians ruined us.
[01:41:38.160 --> 01:41:41.160]   Now the response is no worries.
[01:41:41.160 --> 01:41:42.520]   - Oh, yes, I said that all the time.
[01:41:42.520 --> 01:41:43.600]   - Everybody makes you kidding.
[01:41:43.600 --> 01:41:45.120]   - That's not brilliant, Zach.
[01:41:45.120 --> 01:41:45.960]   - Is it Australian?
[01:41:45.960 --> 01:41:46.800]   - No worries.
[01:41:46.800 --> 01:41:47.640]   - No worries.
[01:41:47.640 --> 01:41:48.480]   - Yep.
[01:41:48.480 --> 01:41:50.520]   - I think it came here through Canada.
[01:41:50.520 --> 01:41:51.840]   - Probably.
[01:41:51.840 --> 01:41:55.920]   - Like, like migrating wildebeest came that way.
[01:41:55.920 --> 01:41:56.760]   - Great, great.
[01:41:56.760 --> 01:41:59.880]   - I say that all the time.
[01:41:59.880 --> 01:42:01.640]   I'm totally guilty as charged.
[01:42:01.640 --> 01:42:05.200]   I say, aha, and no worries all the time apparently.
[01:42:05.200 --> 01:42:08.560]   - So if you're interested, Atlas Obscura
[01:42:08.560 --> 01:42:10.880]   wrote a whole thing about Canadians
[01:42:10.880 --> 01:42:12.600]   and the way they say a boat,
[01:42:12.600 --> 01:42:15.000]   and it's much weirder than, yeah,
[01:42:15.000 --> 01:42:17.280]   it's a whole, it's fascinating.
[01:42:17.280 --> 01:42:20.200]   It's about two separate dip thumbs involved.
[01:42:20.200 --> 01:42:21.560]   Very uniquely Canadian.
[01:42:21.560 --> 01:42:24.560]   - Good.
[01:42:24.560 --> 01:42:25.960]   - Yeah.
[01:42:25.960 --> 01:42:26.800]   - For all the lyrics.
[01:42:26.800 --> 01:42:29.720]   - What's going on with the way Canadians say about it?
[01:42:29.720 --> 01:42:30.560]   - That's it.
[01:42:30.560 --> 01:42:33.200]   - It's not pronounced how you think it is.
[01:42:33.200 --> 01:42:34.040]   - Yeah.
[01:42:34.040 --> 01:42:35.840]   (laughing)
[01:42:35.840 --> 01:42:36.680]   - Absolutely.
[01:42:36.680 --> 01:42:38.680]   - Quit telling me how I think.
[01:42:38.680 --> 01:42:39.520]   (laughing)
[01:42:39.520 --> 01:42:40.520]   - I know, don't you hate that?
[01:42:40.520 --> 01:42:41.440]   - Yeah, I agree.
[01:42:41.440 --> 01:42:42.960]   (laughing)
[01:42:42.960 --> 01:42:45.840]   - All right, I think we're good, you guys.
[01:42:45.840 --> 01:42:47.000]   Thank you again.
[01:42:47.000 --> 01:42:47.840]   Really appreciate it.
[01:42:47.840 --> 01:42:51.040]   And oh, by the way, I will be back next week.
[01:42:51.040 --> 01:42:54.480]   So Jeff, I believe it's both you and Stacy
[01:42:54.480 --> 01:42:55.680]   will be on next week.
[01:42:55.680 --> 01:42:57.760]   - So the question, well, let's let's think about everybody
[01:42:57.760 --> 01:42:58.960]   that we can talk about details.
[01:42:58.960 --> 01:43:02.200]   - Okay, we'll talk about details after the show is done.
[01:43:02.200 --> 01:43:05.440]   I'm Jason Al, thank you for letting me crash a party.
[01:43:05.440 --> 01:43:08.120]   Once again, if you wanna check out the show online,
[01:43:08.120 --> 01:43:08.960]   you can do that.
[01:43:08.960 --> 01:43:09.800]   It's really easy.
[01:43:09.800 --> 01:43:14.800]   You can find all of the past episodes for the show there.
[01:43:14.800 --> 01:43:18.280]   You can also find there that we record live every four PM,
[01:43:18.280 --> 01:43:23.280]   Eastern, one PM Pacific, 20, 20 hundred, 20 o'clock UTC.
[01:43:23.280 --> 01:43:26.640]   And if you wanna catch the show live,
[01:43:26.640 --> 01:43:29.640]   you can do that if you go to twit.tv/live.
[01:43:29.640 --> 01:43:31.640]   We probably actually get started more
[01:43:31.640 --> 01:43:34.200]   at the half hour past, half past,
[01:43:34.200 --> 01:43:37.440]   but right around there, we'll come online.
[01:43:37.440 --> 01:43:39.800]   At some point, like we will next week.
[01:43:39.800 --> 01:43:40.800]   But I really appreciate it.
[01:43:40.800 --> 01:43:41.640]   It's always a lot of fun.
[01:43:41.640 --> 01:43:44.280]   I'll see y'all next week on another episode of
[01:43:44.280 --> 01:43:45.280]   This Week in Google.
[01:43:45.280 --> 01:43:46.440]   Take care, everybody.
[01:43:46.440 --> 01:43:49.020]   (upbeat music)
[01:43:49.020 --> 01:43:58.020]   (upbeat music)

