;FFMETADATA1
title=I Married a Stormtrooper
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=436
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:06.360]   It's time for Twig this week in Google Jeff Jarvis and Stacey Higginbothomer here and a new band
[00:00:06.360 --> 00:00:10.480]   We've got Joan Donovan from Dana Boyd's research and society research group
[00:00:10.480 --> 00:00:17.240]   She's an expert in medium manipulation. We'll talk about what you would do if you were gonna run for president in 2020 plus
[00:00:17.240 --> 00:00:23.680]   I've got the new echo spot. We'll give you a little mini first look. I'll come up next on Twig
[00:00:27.080 --> 00:00:30.280]   Netcasts you love from people you trust
[00:00:30.280 --> 00:00:36.080]   This is Twig
[00:00:36.080 --> 00:00:43.780]   Bandwidth for this week in Google is provided by cash fly C A C H E F L Y dot com
[00:00:43.780 --> 00:00:51.080]   This is Twig this week in Google episode
[00:00:51.560 --> 00:00:57.560]   After 36 recorded Wednesday December 20th 2017. I married a stormtrooper
[00:00:57.560 --> 00:01:01.040]   This week at Google is brought to you by
[00:01:01.040 --> 00:01:07.920]   Rocket mortgage from quick and loans home plays a big role in your life. That's why quick and loans created rocket mortgage
[00:01:07.920 --> 00:01:12.960]   It lets you apply simply and understand the entire mortgage process fully so you could be confident
[00:01:12.960 --> 00:01:20.920]   You're getting the right mortgage for you get started at rocket mortgage comm slash twig and by go to webinar
[00:01:20.920 --> 00:01:26.040]   A trusted webinar platform with over 55,000 customers who have hosted over
[00:01:26.040 --> 00:01:33.080]   2.7 million interactive web events to connect with their audiences for more visit go to webinar.com slash
[00:01:33.080 --> 00:01:35.640]   podcast
[00:01:35.640 --> 00:01:42.120]   It's time for Twig this week in Google the show we cover the latest from Google or we could talk about blue boxing
[00:01:42.120 --> 00:01:48.240]   Phone freaking we got an expert in house. Let's welcome Joan Donovan. Hi Joan
[00:01:48.240 --> 00:01:50.240]   She's a research fellow at data and society
[00:01:50.240 --> 00:01:55.280]   Which is Dana Boyd's research of a group, right?
[00:01:55.280 --> 00:01:58.200]   Yep, in
[00:01:58.200 --> 00:02:04.080]   New York City. I just moved here from LA. So it's all very new to me and you are not only an expert in
[00:02:04.080 --> 00:02:10.280]   Well, social engineering phone hacking, but you also like to talk about manipulating the media
[00:02:10.280 --> 00:02:13.280]   So if you feel any time that you would like to manipulate this show, please
[00:02:13.280 --> 00:02:16.640]   Be my guest
[00:02:17.200 --> 00:02:23.080]   expert hacking yeah, I feel like I've been manipulated many times as a media professional
[00:02:23.080 --> 00:02:31.840]   Also here media professional journalist professor at buzz machine.com Jeff Jarvis from the City University, New York
[00:02:31.840 --> 00:02:34.800]   Jeff brought you brought us Joan. So it's nice to thank you, Jeff
[00:02:34.800 --> 00:02:40.240]   Yeah, I should I suppose I should do a partial disclosure here because we haven't announced anything yet
[00:02:40.240 --> 00:02:46.920]   But it's very likely that news integrity initiative which I started with money from Facebook Craig Newmark in the Ford Foundation full disclosure
[00:02:47.480 --> 00:02:51.280]   is very likely to be working with data and society and Joan
[00:02:51.280 --> 00:02:57.160]   And so Joan and I were at the same conference at Penn last weekend in the bars. We have we've everybody in the bar
[00:02:57.160 --> 00:03:00.600]   Had a few too many she said I want to be on twig
[00:03:00.600 --> 00:03:06.440]   So your fan is here
[00:03:06.440 --> 00:03:11.320]   Like one dream I actually think she wants to be on twit, but she's taking this
[00:03:11.320 --> 00:03:16.440]   Well, yeah, this is the first step. It's one. It's a few few letters different. That's all one letter different
[00:03:17.240 --> 00:03:23.560]   And uh, this shows more fun. I think so Stacy Higginbotham's here from Stacy on iot.com
[00:03:23.560 --> 00:03:28.760]   You've rearranged your your room or something something's different
[00:03:28.760 --> 00:03:34.600]   I am in a completely different room in a completely different city. I am so observant
[00:03:34.600 --> 00:03:40.040]   Good. I what city are you in? I am in Houston, Texas
[00:03:40.040 --> 00:03:42.760]   Was your parents?
[00:03:42.760 --> 00:03:47.480]   I'm at my parents and Stacy would you like to do a facebook disclaimer too?
[00:03:47.480 --> 00:03:51.000]   Uh, I don't use it
[00:03:51.000 --> 00:03:58.760]   On uh, what was it was it on twit on sunday? We had uh dan gilmore who also did the facebook disclosure
[00:03:58.760 --> 00:04:03.720]   I'm starting to think everybody who's on this show is now working for the facebook research
[00:04:03.720 --> 00:04:06.200]   speaking
[00:04:06.200 --> 00:04:08.840]   Can I can I start for just a few words here jay
[00:04:09.720 --> 00:04:13.960]   So and I found I just did what I was about to apologize for because Stacy was about to say something
[00:04:13.960 --> 00:04:19.320]   Um, so last week. I just wanted to say I left the show upset because I was trying very very hard
[00:04:19.320 --> 00:04:23.880]   Not to interrupt stacey. I respect stacey. I want to make sure i'm not
[00:04:23.880 --> 00:04:27.720]   You know an obnoxious man. I'm trying to do that and and I was doing like four times
[00:04:27.720 --> 00:04:33.400]   I saw that I did it now a poor technician blames his technology. It's not easy on this lag stuff
[00:04:33.400 --> 00:04:39.000]   But uh excuses aside. I did it. I apologize people came out to me on twitter
[00:04:39.080 --> 00:04:42.920]   They were right to do so and and i'm sorry and the repartee in the back and forth
[00:04:42.920 --> 00:04:48.280]   I get caught up with it and and I wanted to make sure that that stacey you knew that I apologized
[00:04:48.280 --> 00:04:50.760]   And the audience did too, and it's never intentional
[00:04:50.760 --> 00:04:53.240]   Uh, so I just wanted to start off with that
[00:04:53.240 --> 00:05:00.200]   Well, jeff i was curious how many times did i interrupt you because i'm pretty sure we both got pretty excited
[00:05:00.200 --> 00:05:06.120]   We did we did and you know stacey. That's the other thing about this. No. Oh, no, you're not you know, you know, i'm no
[00:05:06.520 --> 00:05:10.760]   Darn it. I'm the one who could be sorry. Oh stop it. I'm sorry because i'm supposed to prevent those things from happening
[00:05:10.760 --> 00:05:17.000]   Let me say one thing before you go before you continue throwing yourself on the sword and and grinding it in
[00:05:17.000 --> 00:05:25.400]   Uh that we just did a show where with paul throughout marijo fully and the cmo of microsoft and paulin marijo were so
[00:05:25.400 --> 00:05:28.120]   careful not to
[00:05:28.120 --> 00:05:33.080]   Jump in that where there's all these long pauses that made chris very it was like
[00:05:33.080 --> 00:05:35.560]   um
[00:05:35.560 --> 00:05:37.560]   What do you think?
[00:05:37.560 --> 00:05:41.160]   Chris started to have to pick up to keep the conversation going I
[00:05:41.160 --> 00:05:46.120]   We and you can ignore twitter on this because i'll get i've for my whole career i've gotten
[00:05:46.120 --> 00:05:48.920]   tweets from people saying you're interrupting you're interrupting
[00:05:48.920 --> 00:05:52.840]   We trying to produce a show that's dynamic exciting engaging
[00:05:52.840 --> 00:06:00.840]   And it is not a politeness festival. It's a vigorous conversation. So as long as everybody feels heard
[00:06:00.840 --> 00:06:04.120]   That would be my only desire
[00:06:05.080 --> 00:06:09.160]   Now everybody's gonna be polite you see you ruined it jeff i won't be polite
[00:06:09.160 --> 00:06:11.800]   Joe
[00:06:11.800 --> 00:06:17.480]   I've been on enough conference calls in my life to know that you you gotta put yourself first
[00:06:17.480 --> 00:06:19.800]   Yeah, I mean
[00:06:19.800 --> 00:06:23.960]   I think everybody we the people we have on the shows are strong enough personalities that I can count on them
[00:06:23.960 --> 00:06:26.520]   I think I hope to assert themselves now it's always
[00:06:26.520 --> 00:06:32.440]   Tricky with with somebody who's never been on before like jump you've listened enough, but uh, it's so it is you jeff's absolutely right
[00:06:32.440 --> 00:06:36.360]   It's hard with skype because here is lag and I don't mean to blame skype
[00:06:36.360 --> 00:06:42.360]   I mean it's hard. It's tasty was very gracious and I was very grateful. I needed there'll slap. I needed that on on twitter
[00:06:42.360 --> 00:06:46.040]   Um, uh, you know, we get we're in the wrapper
[00:06:46.040 --> 00:06:48.840]   In the back and forth, you know, I gotta say this too
[00:06:48.840 --> 00:06:56.760]   I'm i'm probably exasperated at being the position of being the guy who defends the big evil companies
[00:06:56.760 --> 00:06:58.760]   You should be jeff
[00:06:58.760 --> 00:07:01.320]   So I get a little exasperated you should be shagrin
[00:07:02.280 --> 00:07:04.280]   You should be nicer
[00:07:04.280 --> 00:07:08.680]   Today's not going to be different from yesterday in that respect
[00:07:08.680 --> 00:07:12.440]   I
[00:07:12.440 --> 00:07:15.800]   He's he knows he's on the hook for
[00:07:15.800 --> 00:07:20.920]   Defending some of some of this stuff and it's it's you know
[00:07:20.920 --> 00:07:26.520]   It's a hard position to be in because I think we all I keep telling people I love the internet
[00:07:27.400 --> 00:07:32.280]   But there are things that need to change and that doesn't mean that I'm not you know
[00:07:32.280 --> 00:07:36.840]   Thinking about all of the different ways and means of communicating
[00:07:36.840 --> 00:07:38.120]   It's just that
[00:07:38.120 --> 00:07:44.520]   We've kind of grind to ground ground ourselves into a into a halt here and are looking around and I think it's important to reevaluate
[00:07:44.520 --> 00:07:48.440]   Tech when we need to um in service of society
[00:07:48.440 --> 00:07:52.760]   But it's also kind of cool to have cool things that are new and exciting and
[00:07:53.400 --> 00:07:59.400]   Sometimes, you know, we got to figure out what the features are and what that what what matters about them
[00:07:59.400 --> 00:08:04.040]   Yeah, I think jeff's I like jeff's point of view because it is important that we not
[00:08:04.040 --> 00:08:11.640]   Be luddites or or indulgent techno panic, but I think jeff we also understand that you know
[00:08:11.640 --> 00:08:14.920]   Sometimes you have to call out a technology. I mean not
[00:08:14.920 --> 00:08:18.920]   Not all technology has been mine. No, I do
[00:08:18.920 --> 00:08:22.120]   but
[00:08:23.080 --> 00:08:26.360]   On like last week you were you were throwing facebook completely over
[00:08:26.360 --> 00:08:31.080]   And calling it absolutely worthless and horrible and so I'm in the position of saying well actually no
[00:08:31.080 --> 00:08:36.680]   It's not it has some benefits and so that's that's the dynamic which I think we played out a million times on the show too
[00:08:36.680 --> 00:08:41.160]   Yeah, I've gotten more that's the problem more strident in this though because I'll be honest. I uh
[00:08:41.160 --> 00:08:44.120]   increasingly
[00:08:44.120 --> 00:08:47.080]   aware of the real dangers that facebook
[00:08:48.520 --> 00:08:50.520]   poses our republic and
[00:08:50.520 --> 00:08:55.560]   Our us as individuals and it's it's more than just uh, you know revealing our
[00:08:55.560 --> 00:09:01.320]   The state of our bowels or our kidneys. It's it's really there's there's something going on here. Don't you think?
[00:09:01.320 --> 00:09:03.960]   That is a little bit
[00:09:03.960 --> 00:09:07.880]   I think there's a risk this is a see as google and facebook get more powerful
[00:09:07.880 --> 00:09:09.960]   I think we have to really hold them to high standards
[00:09:09.960 --> 00:09:13.240]   I have always been hard on google, you know because it's
[00:09:13.720 --> 00:09:18.200]   Confused content with search. I think we have to help them with those standards rather than just
[00:09:18.200 --> 00:09:20.440]   um throwing them
[00:09:20.440 --> 00:09:24.040]   Over the overboard that's what i was trying to say last week is that I think that that it's up
[00:09:24.040 --> 00:09:29.800]   It's incumbent upon us to be specific about the expectations of them rather than just saying oh worthless
[00:09:29.800 --> 00:09:32.440]   Well, some things aren't worthless
[00:09:32.440 --> 00:09:39.560]   Do we want to actually instead of general generalizing do we want to argue and talk about specifics because I thought I actually thought of you jeff with
[00:09:40.280 --> 00:09:44.040]   Facebook's both the unfriending stuff but are not unfriending
[00:09:44.040 --> 00:09:47.320]   Sorry muting and then the facial recognition stuff that they announced this week
[00:09:47.320 --> 00:09:54.040]   So I don't know. I don't know if we want to get into talking about specifics yet, but well, let's start with this snooze button
[00:09:54.040 --> 00:09:58.280]   Is that what you're talking about the snooze one of those things? Yeah, so I actually like this
[00:09:58.280 --> 00:10:01.640]   You can mute anybody for 30 days
[00:10:01.640 --> 00:10:08.760]   It's really we need better tools than I mean the problem is all of the tools twitter and facebook offers so far are sledgehammers
[00:10:09.080 --> 00:10:12.760]   This is a little bit more subtle than just ignoring somebody forever
[00:10:12.760 --> 00:10:16.280]   It's if didn't twitter it switters got a snooze button, right?
[00:10:16.280 --> 00:10:21.640]   Is it a snooze? I thought because that's the problem is there are people i've i've i've i've muted long since
[00:10:21.640 --> 00:10:25.080]   And i've long forgotten about them and they're probably still complaining about me
[00:10:25.080 --> 00:10:28.200]   I don't know if you remember that like when ces is going on or
[00:10:28.200 --> 00:10:32.520]   You know like apple events you can mute the tech community or davos
[00:10:32.520 --> 00:10:37.800]   Do you do that by keyword stacey? I can't remember how you do that
[00:10:38.360 --> 00:10:44.600]   You know as a journalist, I never mute ongoing topics because it's my job. So I don't actually know right
[00:10:44.600 --> 00:10:49.400]   But I do feel like that's something twitter has had and now facebook has it but it's individual based
[00:10:49.400 --> 00:10:53.480]   So you can say enough for that person for 30 days. You like this?
[00:10:53.480 --> 00:10:56.920]   Yeah
[00:10:56.920 --> 00:10:59.560]   Cooling on period good
[00:10:59.560 --> 00:11:06.680]   You know, I it's it's an interesting move. I think about it as something during the holidays
[00:11:06.840 --> 00:11:08.840]   it's sometimes pretty hard to
[00:11:08.840 --> 00:11:15.160]   Hear the same things over and over again or maybe there's a very new baby
[00:11:15.160 --> 00:11:23.080]   You know, maybe i'm but i'm speaking like someone who's a little tired of certain kinds and types of posters, but
[00:11:23.080 --> 00:11:24.520]   um
[00:11:24.520 --> 00:11:29.880]   You don't so it's halfway to unfollow you don't want unfollow them you say until they get used to having a baby
[00:11:29.880 --> 00:11:31.000]   Can we just
[00:11:31.000 --> 00:11:34.120]   Joan jone or are you are you are you saying you don't like babies is that what you just said?
[00:11:34.920 --> 00:11:38.360]   Obviously, I would prefer cats dogs
[00:11:38.360 --> 00:11:41.000]   See, I'm you the cat
[00:11:41.000 --> 00:11:48.520]   I'm the babies. I'm you the cats. I'm you know, mom. Yeah, human children. I it's okay, but
[00:11:48.520 --> 00:11:51.320]   you know, some people are
[00:11:51.320 --> 00:11:58.200]   a little too expressive and then also I think maybe snooze might also have something to do with people posting during
[00:11:58.200 --> 00:12:01.960]   for instance, like a political events or
[00:12:02.840 --> 00:12:09.000]   You know, maybe that you've got someone in your timeline that's really into the Grammys and you see over and over and over again
[00:12:09.000 --> 00:12:11.800]   Maybe it's good for spoiler alerts if you want to oh
[00:12:11.800 --> 00:12:14.520]   snooze some people that are
[00:12:14.520 --> 00:12:17.480]   Yeah
[00:12:17.480 --> 00:12:22.520]   Topics and not just people just people
[00:12:22.520 --> 00:12:26.520]   But you kind of if you know those people you kind of know who some of them are
[00:12:26.520 --> 00:12:29.000]   You know, they uh
[00:12:29.000 --> 00:12:32.760]   Topics would be hard to do. It's true people are easy engineering. I don't know
[00:12:32.760 --> 00:12:36.200]   Would it be hard you say here? I mean with a keyword the last Jedi
[00:12:36.200 --> 00:12:42.920]   Or star or Jedi. Yeah, I don't I don't mind not seeing any Jedi posts. What is the hardship there?
[00:12:42.920 --> 00:12:48.840]   I would just acute Halloween costume. I I would defend by the way myself in saying
[00:12:48.840 --> 00:12:55.400]   I don't think anybody needs Facebook and I don't I think that whatever lasting benefit Facebook offers can be gotten in other ways
[00:12:55.400 --> 00:13:01.560]   I don't think we have I don't think Facebook is a if if Facebook did not exist. We would not be compelled. You don't need poetry
[00:13:02.360 --> 00:13:05.880]   Facebook is not poetry. Well, but I'm sorry
[00:13:05.880 --> 00:13:11.160]   It serves it serves a purpose for some people just like poetry serves a purpose for some people. Okay
[00:13:11.160 --> 00:13:13.880]   Now let's talk about facial recognition
[00:13:13.880 --> 00:13:19.880]   Guys this is and we talked about this on kevin and I did a segment on our show
[00:13:19.880 --> 00:13:22.920]   So, you know, you're just gonna be bored if you hear i'm here my show tomorrow
[00:13:22.920 --> 00:13:27.080]   But so i'll tell you the news is and this is kurt kurt wagner and nore code
[00:13:27.080 --> 00:13:29.240]   the news is that
[00:13:29.240 --> 00:13:35.000]   And this has always been a problem people uploading pictures of you without tagging you and you don't know it's there and you might not like it
[00:13:35.000 --> 00:13:43.880]   Facebook is now going to recognize the faces and uploads and let you know that somebody's uploaded a picture of you whether or not they tag you is that that's that's it, right?
[00:13:43.880 --> 00:13:45.480]   Yes, that's right
[00:13:45.480 --> 00:13:48.040]   And that's really exciting like as someone who like
[00:13:48.040 --> 00:13:55.240]   If you were stocked for example and you could get your picture off Facebook even if your friends don't tag you that's gonna be great
[00:13:55.720 --> 00:14:01.800]   But it does mean now that facebook is very confident that it knows what most people look like
[00:14:01.800 --> 00:14:06.440]   Even if they're not posting a lot so I saw this in
[00:14:06.440 --> 00:14:10.520]   Unfortunately right before it. I also read the usa today's story about
[00:14:10.520 --> 00:14:20.280]   Surveillance the surveillance state and image recognition used in by china in the areas to to tamp down on the weaker
[00:14:20.840 --> 00:14:26.120]   Rebellion and I don't know if you saw that story, but it was crazy scary how
[00:14:26.120 --> 00:14:32.040]   And and I thought you know if facebook has this information and awesome image recognition
[00:14:32.040 --> 00:14:34.920]   China is apparently developing this
[00:14:34.920 --> 00:14:39.720]   what's to say that facebook won't give this to people and they probably wouldn't but
[00:14:39.720 --> 00:14:43.240]   We're just giving all of this data away and so many
[00:14:43.240 --> 00:14:47.800]   Companies states are starting to have access to it and it's pretty freaking scary
[00:14:47.800 --> 00:14:51.880]   You don't have to assume though that facebook is going to give it to a government to to not like this idea
[00:14:51.880 --> 00:14:53.880]   I mean facebook now already
[00:14:53.880 --> 00:14:59.560]   Facebook collects information about everything you put on facebook and adds to that big database, but
[00:14:59.560 --> 00:15:04.520]   Face recognition means they're going to recognize everything about you from every source possible
[00:15:04.520 --> 00:15:07.000]   But and here's the other thing that is actually even a big
[00:15:07.000 --> 00:15:11.160]   Or lead it back to you correlate back to you right so this is without your
[00:15:11.560 --> 00:15:19.000]   Partition I could leave facebook but now they know enough about what I look like that I still be dumping information in facebook via other people
[00:15:19.000 --> 00:15:21.000]   They'd be putting my information but you
[00:15:21.000 --> 00:15:26.440]   You know the thing is this this the capability is there no matter what they're just coming out with it. Yes number two
[00:15:26.440 --> 00:15:29.880]   So I got I got a drawing somebody on on facebook. I respect immensely
[00:15:29.880 --> 00:15:34.920]   Rajan erazetti who's a who's a major media executive and he was
[00:15:34.920 --> 00:15:39.400]   Decrying this you know as the creepy personnel a personal thing and I said no
[00:15:39.400 --> 00:15:42.680]   I said now you can know when someone's putting a photo of yourself
[00:15:42.680 --> 00:15:44.280]   You don't know this is good
[00:15:44.280 --> 00:15:48.120]   And but it was I was in the exact same debate like we had last week is oh no facebook bad
[00:15:48.120 --> 00:15:52.040]   And I said imagine a different company did this and where you're still going to presume
[00:15:52.040 --> 00:15:57.560]   That it's bad and and I don't think it is listen the technology can be misused
[00:15:57.560 --> 00:16:03.160]   Yeah, absolutely, but but that doesn't mean that it will be you know doesn't mean that the use is bad
[00:16:03.160 --> 00:16:05.320]   Here's my here's my problem
[00:16:05.320 --> 00:16:06.360]   Jeff
[00:16:06.360 --> 00:16:12.360]   Facebook I don't trust facebook and I've seen them do stuff in the past without letting us know by accident
[00:16:12.360 --> 00:16:18.200]   Apologizing later they have proven themselves in my opinion on trustworthy in this area by the way
[00:16:18.200 --> 00:16:20.920]   When they ask now
[00:16:20.920 --> 00:16:25.880]   Okay, in order for this to work we have to grant facebook permission to use facial recognition
[00:16:25.880 --> 00:16:30.120]   They don't say specifically for this purpose. They say broadly across the service
[00:16:30.120 --> 00:16:33.080]   You're giving them now
[00:16:33.080 --> 00:16:35.320]   In order to enable
[00:16:35.320 --> 00:16:37.320]   this is it opt-in
[00:16:37.320 --> 00:16:43.720]   Facebook's changing its settings to make it easier for the company to add more facial recognition features down the line instead of ask
[00:16:43.720 --> 00:16:45.080]   This is again curd
[00:16:45.080 --> 00:16:50.920]   Set of assets is an opt-in or opt-out instead of asking users to give facebook permission to use facial recognition for tagging purposes
[00:16:50.920 --> 00:16:57.560]   Which is what the company has for now users will now be asked to grant facebook permission to use facial recognition broadly across the service
[00:16:57.560 --> 00:17:03.480]   That's what the end there excuse will be but we have to do that otherwise we won't be able to see people post pictures of you
[00:17:05.000 --> 00:17:08.040]   But they now will have permission to use it in many ways
[00:17:08.040 --> 00:17:17.080]   Yeah, and so thinking of this with my sort of hat on here thinking about it
[00:17:17.080 --> 00:17:20.200]   It's almost the signal that it's more
[00:17:20.200 --> 00:17:27.960]   um accurate in in a much larger database and perhaps much more sinister in the sense that it's
[00:17:27.960 --> 00:17:34.360]   More accurate than the current fbi database facial facial recognition software
[00:17:35.160 --> 00:17:35.880]   um
[00:17:35.880 --> 00:17:37.880]   And so I can see
[00:17:37.880 --> 00:17:44.840]   Where we can hope for the best but also I imagine that in
[00:17:44.840 --> 00:17:49.640]   The science fiction to come right the the future that's already here
[00:17:49.640 --> 00:17:52.280]   um, they're not
[00:17:52.280 --> 00:17:53.800]   entirely
[00:17:53.800 --> 00:17:58.600]   You know beholden to holding on to that data or not selling that data
[00:17:58.600 --> 00:18:02.360]   I don't even care because I don't trust facebook with that data
[00:18:02.920 --> 00:18:06.600]   I will i will you Leo you don't have to fight me. We're gonna fight
[00:18:06.600 --> 00:18:11.640]   Yeah, I mean you don't but i'm just saying you don't have to presume that they're gonna give it to the government as I said before
[00:18:11.640 --> 00:18:16.360]   The fact that facebook has is bad enough. Well, this is what i'm trying to say is that they're not
[00:18:16.360 --> 00:18:17.640]   um
[00:18:17.640 --> 00:18:24.360]   It's not always that the data is going to be improperly used that the data is there and there are lots and lots of people
[00:18:24.360 --> 00:18:32.280]   uh different different governments in a competitive space that are looking for this kind of data and looking for this kind of technology and
[00:18:33.160 --> 00:18:35.720]   One thing that makes databases both
[00:18:35.720 --> 00:18:38.600]   hard to do is that
[00:18:38.600 --> 00:18:43.960]   You can't get the actual data into them. So we have forced fed this machine
[00:18:43.960 --> 00:18:45.560]   um
[00:18:45.560 --> 00:18:50.600]   So so many terabytes of data that it's it's very very powerful at this point
[00:18:50.600 --> 00:18:55.800]   And we've put no restrictions on as a society as a country on what that
[00:18:55.800 --> 00:18:57.480]   could
[00:18:57.480 --> 00:18:59.320]   look like in terms of
[00:18:59.320 --> 00:19:01.320]   selling mining
[00:19:02.040 --> 00:19:09.720]   Inter federating data with other databases. I mean what makes data really interesting to me as a researcher is when we can link it up to other
[00:19:09.720 --> 00:19:12.520]   other forms of data
[00:19:12.520 --> 00:19:18.200]   And so I wonder then if we're headed for a kind of circle situation, right where
[00:19:18.200 --> 00:19:23.560]   It's so powerful that these are the things these end up being the tools we use to verify
[00:19:23.560 --> 00:19:27.080]   census or to verify identity with voting and
[00:19:27.640 --> 00:19:35.560]   Um, and so when we build something so loud large and so powerful and leave it in the hands of a corporation with no rules and restrictions
[00:19:35.560 --> 00:19:41.000]   Uh, we are sort of setting ourselves up for some kind of a uh failure
[00:19:41.000 --> 00:19:44.680]   Totally agree and I would add
[00:19:44.680 --> 00:19:49.480]   That one of the challenges with facial recognition is there are cameras everywhere
[00:19:49.480 --> 00:19:55.400]   This is passive data collection that you may or may not be aware of as a person and granted in facebook
[00:19:55.480 --> 00:19:58.920]   it looks like you can opt in to have this but
[00:19:58.920 --> 00:20:04.200]   having such high quality facial recognition software
[00:20:04.200 --> 00:20:06.200]   and
[00:20:06.200 --> 00:20:11.160]   being able to tie that back into a database forever and then correlate it with other things
[00:20:11.160 --> 00:20:14.440]   is basically giving someone a
[00:20:14.440 --> 00:20:20.360]   An itinerary of where you've been forever and you don't know who has access to it
[00:20:20.360 --> 00:20:24.600]   You don't know what can be done with that and if bad things happen you have no recourse
[00:20:25.160 --> 00:20:28.280]   So if your if your employer suddenly decides
[00:20:28.280 --> 00:20:33.480]   They want to you know get access to this data and it's the other thing to realize is
[00:20:33.480 --> 00:20:40.280]   Facebook is really good at it, but it publishes a lot of papers explaining how it got really good at it
[00:20:40.280 --> 00:20:47.240]   And really what's standing between other companies and this type of facial recognition is just the ability to collect data
[00:20:47.240 --> 00:20:50.200]   Which just means access to cameras
[00:20:50.200 --> 00:20:52.120]   and so
[00:20:52.120 --> 00:20:58.200]   We're entering a place where this is going to be technology available for everyone and we don't have any rules around how to use it
[00:20:58.200 --> 00:21:00.280]   much like what joma's saying so
[00:21:00.280 --> 00:21:09.240]   But we also need to account for the good things that can occur example i've used on the show often was the former head of
[00:21:09.240 --> 00:21:10.520]   um
[00:21:10.520 --> 00:21:15.960]   Consumer protection in germany said that facial recognition and geotechnology was henceforth in her word taboo
[00:21:16.520 --> 00:21:22.680]   Doesn't account for finding missing children for finding Alzheimer's patients for finding criminals and terrorists
[00:21:22.680 --> 00:21:26.040]   There are other ways to do that without facial recognition
[00:21:26.040 --> 00:21:28.840]   But but it is a way
[00:21:28.840 --> 00:21:33.640]   It is a way and it is a good use and so we have to be careful about not cutting off
[00:21:33.640 --> 00:21:36.600]   The good use is because we fear a bad use
[00:21:36.600 --> 00:21:42.440]   And this is the territory that we have gone over a million times on this show
[00:21:42.440 --> 00:21:44.760]   But we're about to go back into the rabbit hole
[00:21:45.080 --> 00:21:46.040]   uh
[00:21:46.040 --> 00:21:48.840]   Account or example that's maybe a little bit closer to home
[00:21:48.840 --> 00:21:52.840]   I call in sick to work and I go to a baseball game
[00:21:52.840 --> 00:21:58.600]   And someone in the crowd takes a picture of themselves, but i'm sitting behind them enjoying
[00:21:58.600 --> 00:22:01.000]   you know
[00:22:01.000 --> 00:22:03.000]   some popcorn or some peanuts and
[00:22:03.000 --> 00:22:10.280]   And you know and then that kind of a picture ends up circulating online with my name tag to it and whatever rules that are on
[00:22:10.280 --> 00:22:13.880]   There now doesn't necessarily mean that I don't you know, maybe I forget
[00:22:14.360 --> 00:22:17.560]   Three months out that I you know hadn't logged into facebook
[00:22:17.560 --> 00:22:20.600]   Oh, this is a funny picture it came up about the baseball game
[00:22:20.600 --> 00:22:22.440]   Oh, yeah, I was at that baseball game and then
[00:22:22.440 --> 00:22:28.600]   You know, there are all these other people looking as well, um, especially when you did something wrong
[00:22:28.600 --> 00:22:31.640]   But it doesn't mean my boss. Oh my god
[00:22:31.640 --> 00:22:38.200]   We start to see if you don't do anything wrong. What do you have to fear?
[00:22:38.200 --> 00:22:42.360]   This is it
[00:22:42.360 --> 00:22:44.360]   These these
[00:22:44.360 --> 00:22:47.400]   Jeff's afraid no
[00:22:47.400 --> 00:22:52.680]   Is protest policing. Yes, which is you have mass people that go out there. There's a better example. Yes
[00:22:52.680 --> 00:22:55.560]   They just walk from
[00:22:55.560 --> 00:23:00.840]   Already happening. I mean the trump administration is looking into people who are protested is inauguration
[00:23:00.840 --> 00:23:07.000]   Uh, yeah, and it's something that um, we have to be cognizant of because also one of the russian
[00:23:07.240 --> 00:23:14.440]   Facebook events that was tied to those russian accounts was a not my president protest that was target marketed
[00:23:14.440 --> 00:23:16.040]   to
[00:23:16.040 --> 00:23:20.040]   people within 10 miles of new york and they collected a bucket of
[00:23:20.040 --> 00:23:24.040]   Facebook profiles that was about 33,000 people
[00:23:24.040 --> 00:23:28.280]   Right, so if you can imagine layering that also onto
[00:23:28.280 --> 00:23:34.840]   Facial recognition you have a very powerful powerful tool for suppression. So then I would ask
[00:23:35.560 --> 00:23:36.680]   Jeff
[00:23:36.680 --> 00:23:41.160]   Which is bad more important that that we could have an arab spring with the help of facebook
[00:23:41.160 --> 00:23:42.840]   By the way would have happened anyway
[00:23:42.840 --> 00:23:46.200]   Or that an arab spring could be suppressed with the help of facebook
[00:23:46.200 --> 00:23:51.160]   I would i would submit that the gris much greater risk is i don't think it's binary
[00:23:51.160 --> 00:23:54.920]   I think i think it's by the way, let me just let me just answer the question this way
[00:23:54.920 --> 00:24:01.720]   As in privacy the far greater threat is not the company it is government
[00:24:03.160 --> 00:24:07.160]   Well, it's true and some of us already have some of risk fear
[00:24:07.160 --> 00:24:09.720]   individual corporations
[00:24:09.720 --> 00:24:14.280]   I think we've already shown that there's a porous membrane between the two uh, anyway
[00:24:14.280 --> 00:24:19.880]   You know, uh, and it's whoever has the power, but I would say jeff
[00:24:19.880 --> 00:24:22.440]   instead of
[00:24:22.440 --> 00:24:27.080]   Yes, technology is a tool and we can use it however we want for good or for ill
[00:24:27.080 --> 00:24:29.000]   But we need to say
[00:24:29.000 --> 00:24:33.160]   We do need to have this discussion about where the risks are and it feels like you are
[00:24:33.160 --> 00:24:39.880]   You are saying ah technopanic whenever we start discussing risks saying offering up some good cases
[00:24:39.880 --> 00:24:42.360]   I would say look at it like
[00:24:42.360 --> 00:24:44.520]   Look at it like volatimide
[00:24:44.520 --> 00:24:49.160]   So the harms there were so great that they put so in in the benefits
[00:24:49.160 --> 00:24:55.560]   Were they existed but they were very small so they put a lot of rules and regulations around
[00:24:55.800 --> 00:25:03.640]   Describing that particular drug and I think facial recognition is something very similar in its potential to harm with maybe
[00:25:03.640 --> 00:25:05.640]   Fewer
[00:25:05.640 --> 00:25:06.920]   benefits
[00:25:06.920 --> 00:25:08.920]   so
[00:25:08.920 --> 00:25:15.960]   I think and we have the time and space to have those nuanced conversations, so I think we totally should I do think it's awesome. I'm go ahead
[00:25:15.960 --> 00:25:19.400]   Don't go ahead. I just think it's ironic
[00:25:19.400 --> 00:25:22.200]   uh that we're have that we're uh
[00:25:22.840 --> 00:25:27.560]   I'm go ahead jeff. I I don't want to interrupt because you have a nice flow going and then I'll bring up the irony
[00:25:27.560 --> 00:25:33.800]   After you know after you stay seat. We're we're agreeing what I'm hearing from the two of you is
[00:25:33.800 --> 00:25:37.000]   From slial last week. It was throw out to facebook
[00:25:37.000 --> 00:25:39.480]   Right and that's what i'm objecting to
[00:25:39.480 --> 00:25:45.800]   Uh, and and I fear and you didn't say this today, but I've heard this from others is basically my god facial recognition bad
[00:25:45.800 --> 00:25:51.000]   Stop it. No, it's good. Do we need discussion about the dangers? Absolutely
[00:25:51.240 --> 00:25:56.440]   Do we also need discussions about the opportunities to protecting them? Yes. Do we need a sane?
[00:25:56.440 --> 00:25:59.160]   discussion about uh
[00:25:59.160 --> 00:26:04.760]   Standards and or regulations. Yes, I'm fine with that what I hear too often is throw out the technology
[00:26:04.760 --> 00:26:09.080]   And that's what i'm decrying. That's it. So we're agreeing
[00:26:09.080 --> 00:26:11.960]   I would say throughout the technology
[00:26:11.960 --> 00:26:12.680]   Uh
[00:26:12.680 --> 00:26:13.560]   Whole hog
[00:26:13.560 --> 00:26:18.680]   Facebook. I'm start yeah facebook I would throw out i'm starting to become very concerned seriously concerned about facebook's motives
[00:26:19.160 --> 00:26:25.160]   and abilities and uh and the dangers of facebook and the irony I think here is that facebook is proposing
[00:26:25.160 --> 00:26:29.400]   Well, we'll do this face recognition to solve a problem that facebook created
[00:26:29.400 --> 00:26:33.880]   Which is the ability for strangers to upload pictures of you to facebook and then we're all
[00:26:33.880 --> 00:26:37.640]   Hailing this says oh good now you could stop that
[00:26:37.640 --> 00:26:40.680]   But facebook created the problem in the first place
[00:26:40.680 --> 00:26:46.440]   Well, don't forget what google can do with your photos google can find you through the ages and find your kids and we say oh, that's cool
[00:26:47.640 --> 00:26:49.640]   It's not just facebook. It's it's it's listen you
[00:26:49.640 --> 00:26:54.760]   FBI it's facebook. It's yeah, it's china. It's russia russia by the way
[00:26:54.760 --> 00:26:59.240]   You got include in that group is absolutely using face recognition to suppress its people
[00:26:59.240 --> 00:27:02.520]   But I I don't think
[00:27:02.520 --> 00:27:07.560]   It's like saying uh, well, you know, we got baby Ruth candy bars, aren't they great?
[00:27:07.560 --> 00:27:11.320]   Um, yeah, but they're gonna kill you if you keep eating them. Yeah, but they're great
[00:27:11.320 --> 00:27:16.760]   I I don't I think facebook is at that level of uh of amusement and entertaining
[00:27:16.760 --> 00:27:21.800]   I don't think it is a it is all know very valuable so much or polity really
[00:27:21.800 --> 00:27:26.600]   I'll I'll quote I'll put uh, I'll put jon of unfair position and quote her boss
[00:27:26.600 --> 00:27:30.120]   I'm probably wrongly but but facebook aside
[00:27:30.120 --> 00:27:32.920]   the fact that people can
[00:27:32.920 --> 00:27:39.000]   Find each other and realize they're not alone in the world and and do things has value it depends on how you use it
[00:27:39.000 --> 00:27:45.160]   Um, obviously of course every tool does it's disconnecting from the natural ways we do that
[00:27:45.160 --> 00:27:48.040]   Who says tribal local society?
[00:27:48.040 --> 00:27:51.720]   That's natural that is natural. That's how it's been forever
[00:27:51.720 --> 00:27:57.240]   It's in creating this new digital pseudo connection. Well, how was forever is it?
[00:27:57.240 --> 00:28:03.080]   Everybody knew your business everybody knew your business. Yes, notion of privacy is very recent. I agree
[00:28:03.080 --> 00:28:06.360]   I'm not it's not the privacy thing. I'm worried about it is the very
[00:28:06.360 --> 00:28:12.760]   Uh, I don't want to use evil, but it's the very very malignant
[00:28:13.560 --> 00:28:19.480]   Power that facebook has and has and I can't I have to say has used and this year has been a very good example
[00:28:19.480 --> 00:28:26.600]   Of how facebook has been misused and I don't think that the benefit we get from facebook this pseudo connection
[00:28:26.600 --> 00:28:33.960]   Is in any way worth it. I don't you all people are connected well people have always connected that and if anything facebook's turning off
[00:28:33.960 --> 00:28:35.080]   soft to the
[00:28:35.080 --> 00:28:39.320]   benign valuable real world connections for these pseudo connections
[00:28:39.480 --> 00:28:45.320]   I don't like my neighbors. I like the people on facebook. They're lost my case. My neighbors aren't very nice actually rest my
[00:28:45.320 --> 00:28:49.800]   Some of them are none of those people on facebook are nice either. You just don't it's a you don't have a real connection with
[00:28:49.800 --> 00:28:51.320]   Oh
[00:28:51.320 --> 00:28:53.320]   You don't have to share a fence with them
[00:28:53.320 --> 00:28:55.320]   No
[00:28:55.320 --> 00:28:59.480]   Uh, no, I agree with you privacy. I'm not I'm not arguing about privacy
[00:28:59.480 --> 00:29:05.320]   I'm arguing about them. What happened about the danger? Yeah, maybe I'm but you like you. I'm very open
[00:29:05.400 --> 00:29:11.400]   I'm not that private. I'm worried much more about about how what what a power tool facebook can be
[00:29:11.400 --> 00:29:15.800]   And I don't trust them. I really don't trust them. That's really the bottom line
[00:29:15.800 --> 00:29:18.920]   See but without all this wonderful technology
[00:29:18.920 --> 00:29:22.120]   You couldn't have google double reverse
[00:29:22.120 --> 00:29:25.080]   Christmas carols
[00:29:25.080 --> 00:29:30.040]   He said changing the damn subject. Let's take a break and we'll come back with more. Hey, Joe
[00:29:30.040 --> 00:29:32.280]   We're glad to have you here and uh jump in
[00:29:33.320 --> 00:29:38.040]   It's it's I it's kind of funny that jeff brought reinforcements in uh in our attack on him
[00:29:38.040 --> 00:29:42.440]   Yeah, I think my microphone might be having some
[00:29:42.440 --> 00:29:47.640]   I hear you're on. You're good. Yep. Yep. No, um, yeah, no, you should take a break
[00:29:47.640 --> 00:29:54.280]   You might have been muted earlier, but you're you're fine. Okay. Yeah. No, joe donovan is here. She is a researcher
[00:29:54.280 --> 00:29:59.320]   Uh at uh, is it safe to say dana boids data in society or
[00:30:00.040 --> 00:30:06.360]   It's usually just data in society. It's actually a pretty big wheelhouse so dana's the founder, but she has built quite
[00:30:06.360 --> 00:30:11.960]   A large network of researchers that span the globe at this point and so
[00:30:11.960 --> 00:30:19.800]   There's about 50 of us that work in house and then we've got um, you know quite a web of affiliates and
[00:30:19.800 --> 00:30:28.600]   Yeah, and so she's uh, she's put together quite a motley crew of people that are very very committed to doing research and are
[00:30:29.320 --> 00:30:37.560]   Either academics all to academics or have had careers as technologists and so there's um, it's a quite an interdisciplinary
[00:30:37.560 --> 00:30:39.800]   Research institute
[00:30:39.800 --> 00:30:44.040]   Well, and it's one of the reasons we're having the conversation. We're having right now. This is right
[00:30:44.040 --> 00:30:46.520]   As you said in your wheelhouse
[00:30:46.520 --> 00:30:49.480]   We're so glad that we could have her. She's a joe
[00:30:49.480 --> 00:30:53.400]   Donovan is a medium manipulation research lead
[00:30:53.400 --> 00:30:57.000]   Yeah
[00:30:57.000 --> 00:30:59.000]   Don't get all the fun
[00:30:59.000 --> 00:31:08.120]   Jeff Jarvis professor of journalism, you know jeff city university the pink guy. No, no, he's he's not chank. You're red. Get mid it
[00:31:08.120 --> 00:31:13.800]   Uh, he's our red from buzz machine.com at jeff. Oh, look now. He's pink at diaries red
[00:31:13.800 --> 00:31:17.560]   Jeff Jarvis on the twitter and stacey higginbotham who is
[00:31:17.560 --> 00:31:19.880]   blue
[00:31:19.880 --> 00:31:23.640]   Stacey on iot.com. I showed they brought to you by rocket
[00:31:24.280 --> 00:31:28.280]   Mortgage don't you be blue interest rates are going up fed raised in a quarter of a point
[00:31:28.280 --> 00:31:33.080]   They say three more raises in 2018. Maybe this would be a good time to look at refinancing your
[00:31:33.080 --> 00:31:35.560]   Home loan or perhaps you're ready to buy a home
[00:31:35.560 --> 00:31:39.640]   Now's the time to get a mortgage from rocket mortgage calm
[00:31:39.640 --> 00:31:42.520]   slash twig rocket mortgage is
[00:31:42.520 --> 00:31:46.360]   Brought to you by quick and loans the best lender in the country number one
[00:31:46.360 --> 00:31:49.000]   and customer satisfaction
[00:31:49.080 --> 00:31:53.880]   From jd power year after year eight years running now for mortgage the mortgage approval process
[00:31:53.880 --> 00:31:59.080]   For consecutive years. They just got it for 2017 as well for mortgage servicing
[00:31:59.080 --> 00:32:05.000]   And one of the things quick and loans noticed because they are very technological is that the mortgage experience wasn't
[00:32:05.000 --> 00:32:07.960]   Keeping up with the times it was kind of 19th century
[00:32:07.960 --> 00:32:10.920]   We needed a client focused
[00:32:10.920 --> 00:32:16.040]   Technological revolution and quick and loans created rocket mortgage. And when you think about it, it's obvious
[00:32:16.600 --> 00:32:21.080]   Why do you need to go to the bank to meet the the bank manager and
[00:32:21.080 --> 00:32:25.960]   Beg for a loan and he'll show you all the rates and is very fancy mortgage calculator
[00:32:25.960 --> 00:32:32.120]   And then you have to go up into the attic and you go get all the paperwork and the checks statements and the paystabs when you could do that all
[00:32:32.120 --> 00:32:34.440]   Hey, we got computers now online
[00:32:34.440 --> 00:32:37.320]   That's how rocket mortgage works
[00:32:37.320 --> 00:32:42.680]   It's completely transparent. So, you know exactly what's going on. It couldn't be simpler. You don't have to go get paperwork
[00:32:42.680 --> 00:32:46.920]   You all you just answer a few basic questions once they've identified you they say this is your bank account
[00:32:46.920 --> 00:32:50.520]   Yeah, they have trusted relationships with all the financial institutions
[00:32:50.520 --> 00:32:53.560]   So they can just pull the data they need with your permission of course
[00:32:53.560 --> 00:32:58.840]   And then based on income assets and credit within a minute. They crunch the numbers and say all right
[00:32:58.840 --> 00:33:04.040]   You qualify for these home loans. What's your down payment? What's your interest rate? What's your term?
[00:33:04.040 --> 00:33:09.000]   You pick the loan you like or not, but if you like it, you say yeah that one
[00:33:10.360 --> 00:33:15.480]   And you could mortgage with confidence within a minute or two you can get approved for a home loan at rocket mortgage
[00:33:15.480 --> 00:33:19.880]   Dot com slash twig very handy if you go to a house and you say I like this
[00:33:19.880 --> 00:33:25.240]   But you don't have to go home. You don't have to go to the bank. You just go to your phone rocket mortgage dot com slash
[00:33:25.240 --> 00:33:31.160]   Twig equal housing lender licensed in all 50 states and mls consumer access dot org number 30
[00:33:31.160 --> 00:33:35.560]   30 we thank rocket mortgage by quick and loans for their support rocket mortgage
[00:33:35.560 --> 00:33:38.120]   Dot com slash
[00:33:38.120 --> 00:33:43.400]   Twig all right. Let's change the subject. We're getting Jeff down. I want to get Jeff down. Did you see this great article?
[00:33:43.400 --> 00:33:46.760]   Google maps moat
[00:33:46.760 --> 00:33:50.520]   This is from Justin
[00:33:50.520 --> 00:33:53.720]   Oh, baby. Is that his real name? I don't know
[00:33:53.720 --> 00:33:57.320]   This is this
[00:33:57.320 --> 00:33:58.680]   Justin a baby
[00:33:58.680 --> 00:34:00.680]   This is uh a comparison
[00:34:00.680 --> 00:34:04.440]   But of google maps and apple maps but also ways and other maps
[00:34:05.080 --> 00:34:11.560]   And it's very obvious in this first animated image apple maps has no building information google
[00:34:11.560 --> 00:34:14.280]   Seems to have the outlines of all the buildings
[00:34:14.280 --> 00:34:20.360]   It's even better than that. It's not just in big cities. It's in that ways doesn't have it bing doesn't have it here doesn't have it
[00:34:20.360 --> 00:34:23.720]   Tom tom doesn't have it open street map max box
[00:34:23.720 --> 00:34:28.760]   None of them have it. You know why google's got all that great satellite information
[00:34:28.760 --> 00:34:33.320]   That tells them and that's what they're doing. They're using uh again machine learning
[00:34:34.200 --> 00:34:39.720]   To figure out where things are. This is I love the animated gifts he puts in this article
[00:34:39.720 --> 00:34:46.680]   Look at here's parks. They actually have the park shelters in the park. They have trailers and you can see that they're trailers
[00:34:46.680 --> 00:34:50.040]   Uh, they if if you look at this
[00:34:50.040 --> 00:34:54.120]   3d outline on google maps of a church, you can actually see the steps
[00:34:54.120 --> 00:34:56.760]   Not just the building. It's the front steps
[00:34:56.760 --> 00:35:01.400]   You could see the cupola the cupola on a post office
[00:35:01.400 --> 00:35:03.880]   Can't you also buy satellite didn't like this?
[00:35:04.520 --> 00:35:07.800]   Yeah, I don't know why apple doesn't have it. That's really interesting. It's not just
[00:35:07.800 --> 00:35:13.960]   Is it google just showing off what you know does it have it's google certainly has the computational ability to do this
[00:35:13.960 --> 00:35:20.360]   Yeah, and one of the things just in obame is pointing out is i hope that's his name is boy. It's all
[00:35:20.360 --> 00:35:22.760]   Obir
[00:35:22.760 --> 00:35:31.640]   And e oh shoot. Oh, bear. Oh, I was I was elating the r and the m hoping it was uh, oh, bamie. I guess it's so bear
[00:35:31.640 --> 00:35:34.280]   Oh, well
[00:35:34.280 --> 00:35:38.840]   No, it wasn't a joke. I really I got it accidentally elating the r and n to make an m
[00:35:38.840 --> 00:35:40.760]   Uh
[00:35:40.760 --> 00:35:45.160]   But it's even small towns. He says even my tiny little town. Here's a town of 100 they have
[00:35:45.160 --> 00:35:50.920]   Smitty's bar it goes farther than that. No, I think some of this is just really good ai
[00:35:51.000 --> 00:35:53.160]   I mean google's really willing to apply their ai
[00:35:53.160 --> 00:35:59.560]   Uh to stuff, you know, so they're using the satellite images, but then they're also figuring out
[00:35:59.560 --> 00:36:02.280]   as we scroll down
[00:36:02.280 --> 00:36:09.560]   Uh where the commerce corridors are where the interesting neighborhoods are they're actually because they have so so much information about
[00:36:09.560 --> 00:36:12.440]   the businesses in an area
[00:36:12.440 --> 00:36:15.480]   They and apparently he says he thinks it's bars
[00:36:16.280 --> 00:36:21.240]   Restaurants they're looking at the kinds of businesses and saying oh, this is a neighborhood
[00:36:21.240 --> 00:36:26.280]   This is a uh, you know an area of interest. They can even say look they could see the baywind
[00:36:26.280 --> 00:36:29.880]   Which they do. Yeah, is that well four? Well four square is the company that has
[00:36:29.880 --> 00:36:35.000]   Really interesting data on a b2b level here because they know what what doors you've gone into right
[00:36:35.000 --> 00:36:41.480]   And how long you spent there and things like that? I think though that google especially with google places and you know the business information
[00:36:41.480 --> 00:36:43.480]   They're getting seems to be doing
[00:36:43.720 --> 00:36:51.160]   uh, you know a pretty good job and he shows how they're they're taking the satellite imagery and basically turning it into these
[00:36:51.160 --> 00:36:56.920]   Freedom and even google says that's exactly what we're doing, but I but I find that um
[00:36:56.920 --> 00:37:01.000]   This is a really interesting study
[00:37:01.000 --> 00:37:04.520]   This is uh, uh rachel and a chino and yoshang Chen
[00:37:04.520 --> 00:37:08.680]   In their master's thesis visualizing mental maps of san francisco
[00:37:08.680 --> 00:37:11.720]   They asked san franciscans and jeff you lived here for a long time
[00:37:11.720 --> 00:37:15.880]   You'll kind of recognize this to draw sketch a map of the city for memory
[00:37:15.880 --> 00:37:22.440]   And you see all the uh, the neighborhoods china town percidio lands and hays street pacific heights
[00:37:22.440 --> 00:37:29.080]   Uh, these are all these are they call them main drags in many cities commercial corridors that attract people
[00:37:29.080 --> 00:37:31.880]   google knows them
[00:37:31.880 --> 00:37:35.000]   Using zoning maps information from the interviews
[00:37:35.000 --> 00:37:39.800]   And a chino and cheng identified 27 commercial corridors within san francisco
[00:37:40.440 --> 00:37:43.640]   If you imagine if you could also take this on top of of of
[00:37:43.640 --> 00:37:47.320]   Jerry mandering and put true communities together
[00:37:47.320 --> 00:37:53.160]   Well, there you go really works together. There you go facebook could tell you where all the republicans are in san francisco
[00:37:53.160 --> 00:37:58.280]   Oh, there was actually a there's data on that. Um, yes the car data. I was just
[00:37:58.280 --> 00:38:01.480]   You know, but they own more pickups
[00:38:01.480 --> 00:38:07.800]   Well, no, uh, I'll have to find the thing but what I think is actually really powerful if you have a rifle rack
[00:38:07.800 --> 00:38:09.880]   You're a republican. Is that it? Yeah
[00:38:10.040 --> 00:38:11.160]   Um
[00:38:11.160 --> 00:38:19.160]   Democrats who tend to own subarus that is something that um, so it's it's a study that show it's the subrude f150 ratio
[00:38:19.160 --> 00:38:22.040]   Yeah, it basically
[00:38:22.040 --> 00:38:27.240]   The pre-est to f150 ratio. Yeah, yeah, it pre-est i found it here. Uh, sassy. I'll put it in the
[00:38:27.240 --> 00:38:29.560]   rundown. Oh excellent
[00:38:29.560 --> 00:38:31.720]   Well, no what i was going to say is right there you go
[00:38:31.720 --> 00:38:36.680]   What google is showing us in this maps moat that I think is maybe underappreciated is that
[00:38:36.680 --> 00:38:39.480]   this data now is
[00:38:39.960 --> 00:38:46.120]   Relatively cheap, right? You have satellite data you're we're gonna have all this data coming in from many different sources
[00:38:46.120 --> 00:38:54.360]   What's going to set different businesses apart is actually how they bring the data together and apply it to deliver useful products and insights
[00:38:54.360 --> 00:39:00.840]   And that is what google is doing here. So maps is a great case study. Another is google photos
[00:39:00.840 --> 00:39:06.760]   So it's not enough to be like I got the data everyone's like data is the new oil and i'm kind of like
[00:39:07.880 --> 00:39:12.200]   Maybe it's the new crude, but you gotta understand how to refine it and I think that's where google really
[00:39:12.200 --> 00:39:20.920]   Metaphor gone now. That was a great metaphor. I love it. I'm like, i'm in Houston. If I can make an oil metaphor, i'm gonna do it
[00:39:20.920 --> 00:39:24.840]   It's seeping into her brain
[00:39:24.840 --> 00:39:28.440]   I think too. I mean, is there a is there a question here about
[00:39:28.440 --> 00:39:32.200]   businesses that are left off the map or
[00:39:33.240 --> 00:39:36.840]   Because i'm often wondering, you know, how much of a city is actually in the cloud?
[00:39:36.840 --> 00:39:39.880]   So I do a lot of traveling and I don't always have time to
[00:39:39.880 --> 00:39:47.400]   Ask people that have been to the city before what restaurants they recommend or places they would go see and i'm wondering too
[00:39:47.400 --> 00:39:54.200]   You know, is there something to be said for having ways of inputting that are different than
[00:39:54.200 --> 00:40:00.280]   Uh, the kind of data that they're collecting from satellites or the kind of data that they're pulling from
[00:40:01.000 --> 00:40:04.360]   From just business addresses. Um, you know because i'm
[00:40:04.360 --> 00:40:09.880]   Especially in smaller towns. There's lots and lots of things that never end up
[00:40:09.880 --> 00:40:17.320]   Data-fied in the same way and so i'm thinking about does it strategically give certain businesses an advantage?
[00:40:17.320 --> 00:40:21.720]   Um, you know, and of course there's a metrics game here too, which is
[00:40:21.720 --> 00:40:25.560]   How do you how do you make sure that you're in the map?
[00:40:25.720 --> 00:40:33.560]   Is there is there a way to make sure that you're in the map and accurately described one of the things that's funny about when people look for data and society?
[00:40:33.560 --> 00:40:42.280]   For instance, is they get some some fairly funny photos of what the building is or who's affiliated with it and so um
[00:40:42.280 --> 00:40:48.680]   Yes, so i'm wondering, you know, is there is this sort of the future of the yellow pages in a way and then also
[00:40:48.680 --> 00:40:55.160]   What's left off the map that we we can't see we were very careful when we moved for instance? I
[00:40:56.120 --> 00:41:02.680]   You know did a google places thing on google maps and made sure that twits old location was deprecated
[00:41:02.680 --> 00:41:05.080]   And our new location was shown
[00:41:05.080 --> 00:41:09.240]   Which is right here and it has and i provided the business information
[00:41:09.240 --> 00:41:13.720]   So i know that that's accurate all of that pictures of the old place not the not the new place
[00:41:13.720 --> 00:41:15.480]   but
[00:41:15.480 --> 00:41:20.040]   It is you make an interesting point because in this area i know for instance
[00:41:21.240 --> 00:41:27.560]   CA is right next to us, but i don't see them showing up on this map and then you know that's a computer company
[00:41:27.560 --> 00:41:31.160]   Maybe they don't want to be on the map the restaurant some of the restaurants i
[00:41:31.160 --> 00:41:37.880]   Are but some aren't and is that just because i have an advantage because i'm i know to make sure that i appear on the map
[00:41:37.880 --> 00:41:40.360]   And these other guys don't i guess so right
[00:41:40.360 --> 00:41:45.960]   Yes, but so there's what what you're doing there is self identifying your business
[00:41:45.960 --> 00:41:49.240]   Which you know if you own a business and you're in a location, sure you should do
[00:41:49.640 --> 00:41:56.120]   But google's not just grabbing satellite and street view data. They're gathering data from any android user that pops in
[00:41:56.120 --> 00:42:02.840]   That's true. Is their location. Yes, they also have business Wi-Fi data from like oh god. What was that company?
[00:42:02.840 --> 00:42:05.000]   So they have all that
[00:42:05.000 --> 00:42:07.400]   Skyhawk street what was it something? Yes, I think it was a good
[00:42:07.400 --> 00:42:10.120]   Something okay. Okay. Okay. Yeah, so
[00:42:10.120 --> 00:42:15.800]   Hey, can you do me a favor and unplug unplug and replug your headset. It seems to be breaking up
[00:42:16.680 --> 00:42:22.760]   Did we never send a stacy? Oh, she's at her parents. That's right. It's gonna say didn't we send you a good setup
[00:42:22.760 --> 00:42:26.040]   She's better. Yeah
[00:42:26.040 --> 00:42:32.040]   These headsets after about an hour they kind of get weird they poop out you're right google has more data
[00:42:32.040 --> 00:42:39.640]   Than anybody right uh they can collect it all well apple could have this data the challenges apple is very
[00:42:39.640 --> 00:42:44.920]   Much more privacy focused right so again a disadvantage, right?
[00:42:45.800 --> 00:42:49.640]   Well, it depends on how you look at it well apple's part of reason for that
[00:42:49.640 --> 00:42:53.000]   App that's but I wouldn't argue that that's um
[00:42:53.000 --> 00:42:57.320]   Uh out of principle. It's because apple decided not to go into the ad business
[00:42:57.320 --> 00:43:00.840]   Right, so they don't use and need the data the same way the other companies do right?
[00:43:00.840 --> 00:43:05.880]   Although apple is trying to market their privacy or they've turned it into a feature
[00:43:05.880 --> 00:43:09.320]   But I think it was a bug. I have to say now that I look at this
[00:43:09.320 --> 00:43:12.280]   You could totally see what kind of cars are in the parking lot
[00:43:12.840 --> 00:43:17.400]   Are you saying that that could tell you well reason we go back to that story? Oh, sorry going back
[00:43:17.400 --> 00:43:20.280]   That's enough information
[00:43:20.280 --> 00:43:25.960]   Well, you don't read on scroll on down either side of the photos so among the findings
[00:43:25.960 --> 00:43:29.320]   It's right there on the screen bottom of the screen. There you go
[00:43:29.320 --> 00:43:34.040]   Nope go up a little bit. Nope. Nope. Nope. Nope that paragraph. Well
[00:43:34.040 --> 00:43:38.520]   Let me let me do it on my this is from city lab
[00:43:39.160 --> 00:43:43.960]   I'll do it on my computer because I had that's karsten driving. He's got other things to do here
[00:43:43.960 --> 00:43:46.200]   so so
[00:43:46.200 --> 00:43:51.000]   Black neighborhoods more strongly associated with buick old mobile and christler vehicles vehicles
[00:43:51.000 --> 00:43:56.280]   The presence of pickup trucks, Volkswagens and Aston martens indicate mostly white neighborhoods
[00:43:56.280 --> 00:44:00.040]   Toyota and honda strongly associated with asian neighborhoods
[00:44:00.040 --> 00:44:05.640]   We've known this for years though. I remember people could a guy who came in once on my radio showed 20 years ago and said
[00:44:05.800 --> 00:44:10.360]   Tell me your zip code. I could tell you what magazines you and your neighbors subscribe to what kind of cars you buy
[00:44:10.360 --> 00:44:14.680]   Yes, this is but this is this is computer
[00:44:14.680 --> 00:44:20.280]   This is computer vision generated, which means it is now scalable in a way that right?
[00:44:20.280 --> 00:44:29.480]   And then searchable and it's saved and is this nefarious? I don't know, but it's much easier to get and cheaper to get which is changes
[00:44:29.480 --> 00:44:32.200]   Thanks and gilbert, arizona
[00:44:32.760 --> 00:44:35.320]   Using the proportion of pickup trucks to sedans
[00:44:35.320 --> 00:44:40.600]   The model correctly identified the voting patterns of 58 out of 60 precincts
[00:44:40.600 --> 00:44:43.080]   90 percent accuracy
[00:44:43.080 --> 00:44:49.960]   The model indicated a city with more sedans has an 88 percent chance of voting for a democrat in the next election
[00:44:49.960 --> 00:44:55.080]   Those with more pickup trucks 82 percent more likely vote republican. You're right. I mean this data
[00:44:55.080 --> 00:44:57.800]   Google has this data
[00:44:57.800 --> 00:44:59.880]   Google knows this
[00:44:59.880 --> 00:45:01.880]   Stat, I don't know what it's doing with it
[00:45:02.280 --> 00:45:06.280]   You know who doesn't have that data's facebook, right? They don't have street view data like that
[00:45:06.280 --> 00:45:11.320]   No, and and if you want to target political ads or if you wanted to target maybe you know
[00:45:11.320 --> 00:45:15.160]   if you wanted to target the manipulation to look for cells of
[00:45:15.160 --> 00:45:23.800]   People in certain beliefs that kind of data to be helpful, wouldn't it? Well, but google facebook may know a lot more facebook's pretty good at it, right?
[00:45:23.800 --> 00:45:26.840]   Yeah, but you wouldn't
[00:45:26.840 --> 00:45:28.920]   necessarily like I mean
[00:45:29.800 --> 00:45:36.040]   It's like hard right because there's even even the incentive to let to like on facebook a honda
[00:45:36.040 --> 00:45:39.400]   Page or things. I mean you have to be a pretty big fan right
[00:45:39.400 --> 00:45:47.160]   To signal in certain ways to facebook, but they might in their photos also be able to recognize brands and then have
[00:45:47.160 --> 00:45:51.000]   Ways and means of correlating that data. Here's the difference
[00:45:51.000 --> 00:45:54.360]   Here's the difference. So this city lab
[00:45:55.400 --> 00:46:02.520]   Somebody came up with a hypothesis and then city lab analyzed it and then said oh, yeah, there's a correlation pick up trucks and sedans
[00:46:02.520 --> 00:46:06.360]   That's what I would have guessed facebook doesn't work that way at all. It's a black box
[00:46:06.360 --> 00:46:09.320]   They just have tons of data
[00:46:09.320 --> 00:46:13.880]   It may turn out the people who buy Cheerios are more likely to vote Republican
[00:46:13.880 --> 00:46:20.120]   It may turn out that if somebody who buys Cheerios and likes the honda page is as a bernie sander's democrat
[00:46:20.120 --> 00:46:23.400]   And it doesn't matter. It's not something you hypothesize
[00:46:23.640 --> 00:46:25.960]   Google just has I mean facebook has all the data
[00:46:25.960 --> 00:46:29.240]   So you know, I mean think about
[00:46:29.240 --> 00:46:34.120]   Neighborhoods and car ownership over time if you're dealing with small towns
[00:46:34.120 --> 00:46:38.600]   Maybe there is only a honda dealership or maybe there's only a toy
[00:46:38.600 --> 00:46:46.040]   Facebook has a better much better data much more useful. Yeah, and so the idea though would be if you were if you were to want to target
[00:46:46.760 --> 00:46:54.840]   uh different groups of people to influence voter behavior, you'd be looking to nudge them in a particular for a kind of
[00:46:54.840 --> 00:46:57.000]   emotional response
[00:46:57.000 --> 00:47:01.000]   And so maybe the question is do you serve them?
[00:47:01.000 --> 00:47:07.800]   Uh fake news articles about how all pickup owners are you know
[00:47:07.800 --> 00:47:10.680]   x y and z bad actors, right?
[00:47:10.680 --> 00:47:16.200]   And so you try to influence them by saying people who own pickups are republican or are democrat
[00:47:16.280 --> 00:47:19.160]   And therefore you should think this way about them
[00:47:19.160 --> 00:47:21.800]   Um, which are just
[00:47:21.800 --> 00:47:25.080]   Stereotypes that we've always had um and I know that
[00:47:25.080 --> 00:47:34.760]   You know in california cars don't rust and so I I've seen quite a few hondas driven by all manner of people
[00:47:34.760 --> 00:47:37.240]   So it doesn't seem to even hold across
[00:47:37.240 --> 00:47:43.080]   uh place and so that signifies to be that voting data is more useful than any
[00:47:43.640 --> 00:47:50.200]   correlation that may or may not be associated with car type. Yes, in fact, what kinds of correlations
[00:47:50.200 --> 00:47:56.920]   unexpected correlations do you find to um extreme political behavior?
[00:47:56.920 --> 00:48:01.720]   Uh, that's a really good question. So um
[00:48:01.720 --> 00:48:10.120]   Yeah, but unidentified correlations that would be that'd be a really good one because one of the things that we've been trying to understand is
[00:48:10.920 --> 00:48:17.640]   What is what are the the the things we're not looking for in terms of manipulation around these nudges and so
[00:48:17.640 --> 00:48:19.400]   um
[00:48:19.400 --> 00:48:26.520]   one of the things that we've found in looking at the small amount of data that we've gotten from the senate intelligence hearings
[00:48:26.520 --> 00:48:31.640]   Is that the russian pages were influencing social movements?
[00:48:31.640 --> 00:48:35.480]   And so even if you're just looking for certain bits of information
[00:48:35.480 --> 00:48:38.280]   about say what's happening in
[00:48:39.080 --> 00:48:46.040]   Activism around black lives matter for instance you might have been exposed to russian propaganda
[00:48:46.040 --> 00:48:52.600]   And so when we're trying to understand this this large body of of what is and what isn't
[00:48:52.600 --> 00:48:58.920]   Correlated to certain fringe groups. It's been really hard to look at
[00:48:58.920 --> 00:49:05.400]   that without getting mixed signals from places that we uh
[00:49:06.120 --> 00:49:12.280]   You know, we would expect obviously that certain people are looking for information about social movements and things
[00:49:12.280 --> 00:49:19.160]   Would be maybe predisposed to certain kind of fringe ideas or would be motivated to act in a certain way
[00:49:19.160 --> 00:49:22.360]   But one of the things that we didn't expect I think was that
[00:49:22.360 --> 00:49:28.280]   Other governments would be posing as not just citizens or sock puppet accounts, but posing as
[00:49:28.280 --> 00:49:31.320]   actual groups and movements and so
[00:49:32.360 --> 00:49:37.800]   Yeah, so there's the data is very hard for us to parse at this point because it's really hard to see
[00:49:37.800 --> 00:49:41.960]   Who are people and who are organizations and what their
[00:49:41.960 --> 00:49:44.760]   intentions and motivations really are
[00:49:44.760 --> 00:49:47.160]   So this leads this leads to a whole nother
[00:49:47.160 --> 00:49:55.640]   Question and i'm not going to go back to the facebook rabbit hole, please but but in trying to look at the standards and principles and practices
[00:49:55.640 --> 00:49:58.120]   um
[00:49:58.120 --> 00:50:00.120]   fake accounts and bots
[00:50:00.280 --> 00:50:04.200]   Uh, there are there are benign bots. There are good bots. There are service bots
[00:50:04.200 --> 00:50:07.000]   You know tell me when the when the train's not working. Okay, that's fine
[00:50:07.000 --> 00:50:09.560]   But but generally how could you imagine
[00:50:09.560 --> 00:50:13.000]   uh crafting a principle around
[00:50:13.000 --> 00:50:16.520]   Uh the bad use of fake accounts and bots
[00:50:16.520 --> 00:50:21.160]   So that you know facebook said for example that one of the things they're doing now is if somebody comes and harasses you
[00:50:21.160 --> 00:50:25.960]   And you block them facebook now is going to stop them from doing it again when they create a new account
[00:50:26.440 --> 00:50:32.280]   Well, hello if you're creating new accounts for the purposes of harassing people that should be what you're going after
[00:50:32.280 --> 00:50:38.040]   Uh, not that you come after me particularly. So so fake accounts and bots. What's what's what's an ethical?
[00:50:38.040 --> 00:50:40.840]   principle, uh
[00:50:40.840 --> 00:50:43.720]   The platform should be following around that
[00:50:43.720 --> 00:50:47.720]   It's yeah, it's really hard because one of the things that I think
[00:50:47.720 --> 00:50:55.240]   We all think and maybe leo has an opinion on this is that when we friend something on facebook or follow something on twitter
[00:50:55.800 --> 00:50:59.640]   That it's transparent in the sense that we know what we're looking at
[00:50:59.640 --> 00:51:02.360]   Right and because these things are
[00:51:02.360 --> 00:51:04.520]   um
[00:51:04.520 --> 00:51:09.960]   So shrouded in mystery and we don't have access to the social graph in the way that these companies do
[00:51:09.960 --> 00:51:13.320]   We are often not questioning
[00:51:13.320 --> 00:51:17.560]   That we're talking to a real person or that we're not talking to
[00:51:17.560 --> 00:51:20.760]   Uh state sponsored troll army
[00:51:21.400 --> 00:51:28.600]   Um and the problem with bots. I think is that we've just kind of crammed a bunch of miscellaneous stuff that the internet has always done
[00:51:28.600 --> 00:51:30.920]   into
[00:51:30.920 --> 00:51:34.280]   These automated accounts that amplify information
[00:51:34.280 --> 00:51:38.680]   Good bad or indifferent and so it's been hard
[00:51:38.680 --> 00:51:42.920]   Um in terms of thinking about what is the proper protocol?
[00:51:42.920 --> 00:51:48.760]   I think or the ethical use of things one thing that I think we all can agree on is that
[00:51:49.880 --> 00:51:51.000]   um
[00:51:51.000 --> 00:51:59.320]   That there needs to be more oversight and more clarity around at least the stuff that we're not choosing to see which is advertising online
[00:51:59.320 --> 00:52:03.480]   And how that stuff gets put into feeds
[00:52:03.480 --> 00:52:09.480]   Uh in particular and especially even the you know, I know google's experimented with
[00:52:09.480 --> 00:52:15.000]   Placing the ads at the top and then putting them off to the side and putting them in shadow boxes
[00:52:15.000 --> 00:52:17.960]   And I still think there's lots of clarity around
[00:52:18.600 --> 00:52:23.560]   How we are supposed to interact with and look at these things and know what they are
[00:52:23.560 --> 00:52:26.360]   um, and that's been a hard
[00:52:26.360 --> 00:52:29.320]   sell for these companies that are
[00:52:29.320 --> 00:52:34.760]   Really struggling. I think to operate at the scale that they want to
[00:52:34.760 --> 00:52:40.680]   with also being able to support the amount of staff and
[00:52:40.680 --> 00:52:47.480]   Uh people that it takes to run a platform such as you know, those big three
[00:52:48.200 --> 00:52:50.200]   and so um
[00:52:50.200 --> 00:52:54.120]   Yeah, and so one of the things about automation is though that I I welcome
[00:52:54.120 --> 00:52:57.720]   in many respects certain forms of automation, but
[00:52:57.720 --> 00:53:01.640]   um, especially when it comes to notifications around
[00:53:01.640 --> 00:53:03.800]   Simple things like
[00:53:03.800 --> 00:53:08.760]   When if the trains are going to be late, but at the same time if we're automating news in the same way
[00:53:08.760 --> 00:53:10.840]   We have to be very careful that we're not
[00:53:10.840 --> 00:53:11.880]   Um
[00:53:11.880 --> 00:53:16.280]   Inserting levers for other people to you know hack democracy or hack the markets
[00:53:16.600 --> 00:53:21.240]   Would you I mean we we would agree in fact the chat arms even saying this is the same old propaganda
[00:53:21.240 --> 00:53:26.600]   That's the same old that there's nothing new and you were reading that book jeff about the history of
[00:53:26.600 --> 00:53:30.120]   fake news there's nothing new here, but we've
[00:53:30.120 --> 00:53:37.480]   Would you agree? Is this or is this a loaded term that we've weaponized delivery in in such a way that makes it more dangerous
[00:53:37.480 --> 00:53:39.720]   Is that what's going on?
[00:53:39.720 --> 00:53:45.960]   Well, the broadcast question is I think what we're talking about when we talk about bots and when we talk about
[00:53:46.200 --> 00:53:49.320]   amplification because instead of seeing um
[00:53:49.320 --> 00:53:56.600]   For instance a the way that a telephone or a radio signal broadcast would come out from a tower
[00:53:56.600 --> 00:54:01.560]   And then you know, you have an expected radius. You have an expected distribution
[00:54:01.560 --> 00:54:09.480]   You have an expected amount of people and then in the back end in terms of serving content. You have a uh a whole network and industry
[00:54:09.480 --> 00:54:13.640]   um concerned with quality contents
[00:54:14.360 --> 00:54:18.760]   authenticity and with the internet all of those things fall apart and
[00:54:18.760 --> 00:54:23.320]   You have this nodal distribution of content that's also masquerading as
[00:54:23.320 --> 00:54:25.800]   authentic content
[00:54:25.800 --> 00:54:30.840]   And that can be very confusing, right? I mean we have all of these rules about
[00:54:30.840 --> 00:54:38.280]   automated dialers and not allowing robo calling and um, you know people need to be able to opt into
[00:54:39.480 --> 00:54:41.480]   services by telephone
[00:54:41.480 --> 00:54:48.040]   but we've done something different with the internet and we haven't inserted the levers to prevent any kind of
[00:54:48.040 --> 00:54:53.720]   Mashing a reality with advertising or with adversarial attacks
[00:54:53.720 --> 00:55:01.160]   And so I think the question of scale and automation and amplification are really important
[00:55:01.160 --> 00:55:03.640]   And you know, we also question
[00:55:04.440 --> 00:55:10.040]   In my research group and in any event, you know, what is what is the danger of amplification?
[00:55:10.040 --> 00:55:12.040]   But what are the benefits of it?
[00:55:12.040 --> 00:55:14.520]   Right and I think jeff leans towards
[00:55:14.520 --> 00:55:18.600]   Where I am in some respects, which is that um
[00:55:18.600 --> 00:55:28.360]   When we talk about amplifying things we're generally fairly happy with the content that we choose to consume online
[00:55:28.360 --> 00:55:31.400]   What are the benefits of amplification?
[00:55:31.560 --> 00:55:36.040]   Okay, so think about um all during um 2011
[00:55:36.040 --> 00:55:41.960]   Arab spring occupy not what was happening on facebook in particular, but the ability
[00:55:41.960 --> 00:55:45.720]   For people to broadcast and use live stream and youtube
[00:55:45.720 --> 00:55:47.080]   Okay
[00:55:47.080 --> 00:55:51.800]   To get images to do citizen media and citizen medias
[00:55:51.800 --> 00:55:58.920]   Really, I think one of the things that we talk about when we talk about the benefits of these platforms and the ability to
[00:55:59.720 --> 00:56:06.920]   anything at any time could you could net neutrality the the fight for net neutrality fall under kind of deep benefits of amplification
[00:56:06.920 --> 00:56:10.840]   I know I know they repealed it
[00:56:10.840 --> 00:56:13.800]   But you know getting people passionate about it and actually to call there
[00:56:13.800 --> 00:56:16.920]   I would say anything that could shoot a call your senators in
[00:56:16.920 --> 00:56:19.640]   Either way really
[00:56:19.640 --> 00:56:24.920]   Would probably also fall under that we've definitely got a galvanized electorate at least in that and many other
[00:56:25.560 --> 00:56:26.440]   uh
[00:56:26.440 --> 00:56:30.040]   Issues all of a sudden that would you know was essentially passive
[00:56:30.040 --> 00:56:36.280]   A few years ago, but but I don't I mean isn't all media amplification. Isn't that what mass media is is amplification?
[00:56:36.280 --> 00:56:39.240]   Yeah, but now I have
[00:56:39.240 --> 00:56:41.880]   In my
[00:56:41.880 --> 00:56:46.840]   Association of the amplification. Yeah, but this is in this is where we get hemmed up. I think in
[00:56:46.840 --> 00:56:49.880]   Thinking about techno utopias without thinking about
[00:56:49.880 --> 00:56:55.160]   social and cultural norms of society that have kept us from
[00:56:55.960 --> 00:56:57.960]   Um, you know
[00:56:57.960 --> 00:57:00.920]   Everything
[00:57:00.920 --> 00:57:06.680]   But you know, um, it's been it's it's a hard it's a hard thing because the benefits of amplification also
[00:57:06.680 --> 00:57:13.560]   There's this strata that we're starting to notice where if you do insert a little, you know some capital
[00:57:13.560 --> 00:57:20.920]   You can constrain other people's right to amplification or other people's access to amplification by being
[00:57:20.920 --> 00:57:23.480]   simply more present or
[00:57:23.720 --> 00:57:26.840]   Um, you know, so this is where bots come in right because if I am
[00:57:26.840 --> 00:57:33.960]   50,000 accounts on twitter instead of just boston jones then I have
[00:57:33.960 --> 00:57:37.480]   increased magnitude by orders of
[00:57:37.480 --> 00:57:40.920]   You know of amplification and also
[00:57:40.920 --> 00:57:46.840]   Probably spread myself out around many many more networks and been
[00:57:46.840 --> 00:57:50.520]   Multiple you know much more powerful and effective
[00:57:51.240 --> 00:57:57.480]   Compared to abc nbc and cbs now you have thousands of people and also it sinks in a little bit more
[00:57:57.480 --> 00:58:02.360]   It has a different kind of an impact than waltter kronkite saying we're going to lose the war in vietnam
[00:58:02.360 --> 00:58:09.160]   Uh because you when it's human nature when you hear the same thing from dozens of people
[00:58:09.160 --> 00:58:12.200]   You just assume oh must be true
[00:58:12.200 --> 00:58:17.320]   Yeah, and that's I think one of the things that people are studying around the cognitive
[00:58:17.640 --> 00:58:24.760]   Aspects of this is how many times do you have to hear something before you think it's true? Yeah, and how many times do you
[00:58:24.760 --> 00:58:32.280]   See something on uh an account where you think it's legitimate because they have 50,000 or up 500,000
[00:58:32.280 --> 00:58:37.160]   followers and you assume that someone somewhere must have met them
[00:58:37.160 --> 00:58:39.560]   They must and the platform assumes it too
[00:58:39.560 --> 00:58:44.840]   And the platform does assume it too and they you know they check market is in some cases
[00:58:45.400 --> 00:58:51.320]   And so this has been what's hard, but I mean the history of computers though is rife with fishing scams
[00:58:51.320 --> 00:58:54.440]   rife with social engineering rife with
[00:58:54.440 --> 00:59:02.200]   um this kind of both play and cyber warfare we can't get those are both parts of the
[00:59:02.200 --> 00:59:08.680]   Computer science you can study the game theory of this because what it strikes me is that these really ultimately what's happened is
[00:59:08.680 --> 00:59:13.960]   It's not merely amplification mass media amplified, but you couldn't game mass media particularly well
[00:59:14.440 --> 00:59:21.160]   But you can game this and uh it it strikes me that it's like the prisoner's dilemma
[00:59:21.160 --> 00:59:25.480]   in a way if you if you know the other guy is going to cheat
[00:59:25.480 --> 00:59:29.960]   Then then there's not a problem, you know if you already you know, so
[00:59:29.960 --> 00:59:38.760]   Having multiple voices and being able to uh martial multiple voices is a very different kind of amplification
[00:59:39.320 --> 00:59:45.000]   Then merely having a bully pulpit and this is where maybe even facebook gets
[00:59:45.000 --> 00:59:49.000]   Implicated in a sense that we've also lowered the cost of coordination
[00:59:49.000 --> 00:59:52.520]   Right. Yes. That we thought about coordinating
[00:59:52.520 --> 01:00:00.280]   2010 2011 is look at all this organic coordination that's happening. This is fantastic. I can't believe I've met these people
[01:00:00.280 --> 01:00:05.640]   I've never I've never had this much interest in you know getting money out of politics
[01:00:05.720 --> 01:00:11.480]   Let's all move forward together and the assumption built into the platforms that it's one person one accounts
[01:00:11.480 --> 01:00:16.600]   And that the groups that you then build upon those one person one account are
[01:00:16.600 --> 01:00:18.120]   authentic
[01:00:18.120 --> 01:00:23.240]   I think where we where we get led astray and some aspects of it is when people are
[01:00:23.240 --> 01:00:30.280]   operating outside the platform and co-war and doing what facebook is called coordinated in authentic participation
[01:00:30.280 --> 01:00:34.680]   Uh, which is you know your click farms and your and your like farms and your
[01:00:35.320 --> 01:00:43.400]   Yeah, you know research association whatever that Russian troll. Yeah, but then there's also people like Milo Yiannopoulos who by himself was not harmful
[01:00:43.400 --> 01:00:47.800]   It was the bot or the army whatever they were they weren't there were people I guess that he could mark
[01:00:47.800 --> 01:00:51.640]   That was the strength that he had it wasn't his single voice. It was the
[01:00:51.640 --> 01:00:54.840]   That's part of
[01:00:54.840 --> 01:00:59.240]   In one of the things that he would do is he would on his website post someone's
[01:00:59.240 --> 01:01:00.440]   uh
[01:01:00.440 --> 01:01:04.280]   Twitter handle and information or phone number or address
[01:01:05.000 --> 01:01:10.840]   And he wouldn't encourage but it was a no known that if this information were to get out that one of your
[01:01:10.840 --> 01:01:16.520]   Um, you know one of the ways that you participate in media making is that you
[01:01:16.520 --> 01:01:21.960]   Valorize the host and you and you do what other people in
[01:01:21.960 --> 01:01:29.160]   You know those media circles do and so you actually become part of the story when you're part of a coordinated harassment campaign
[01:01:29.160 --> 01:01:31.720]   So you're studying all of this kind of thing
[01:01:32.360 --> 01:01:35.880]   Oh, yeah, fascinating. What would you do? I'm gonna ask all three of you
[01:01:35.880 --> 01:01:40.280]   If you want if you were going to run for president in 2020
[01:01:40.280 --> 01:01:45.640]   Or dog catcher, but let's use president because it's a nice big national scale
[01:01:45.640 --> 01:01:51.800]   What tools would you use where what would you do to let me ask you jeff? What would you do to be
[01:01:51.800 --> 01:01:55.000]   Mona or stacy first. Okay stacy starts
[01:01:55.000 --> 01:01:59.640]   Okay, the the least social among us, um
[01:02:00.120 --> 01:02:02.760]   Yeah, because you're not even on facebook. Did you say you're not on facebook?
[01:02:02.760 --> 01:02:10.520]   I am on facebook. I just don't you know, participate ever. I yeah, my last post was like three months ago
[01:02:10.520 --> 01:02:13.080]   um
[01:02:13.080 --> 01:02:17.960]   So I would probably create in my persona much like I did with my media stuff
[01:02:17.960 --> 01:02:21.160]   accounts at all the major social media platforms
[01:02:21.160 --> 01:02:23.640]   as
[01:02:23.640 --> 01:02:27.720]   I don't know this this like presupposes a big strategy. So i'm like, oh, man
[01:02:27.720 --> 01:02:31.560]   I'm just saying you know, you know, maybe you could say in nixon's era
[01:02:31.560 --> 01:02:34.360]   You would have a media buy
[01:02:34.360 --> 01:02:37.000]   You would do debates
[01:02:37.000 --> 01:02:42.600]   I would get bopper stickers and posters and maybe years later you'd start direct mail
[01:02:42.600 --> 01:02:44.280]   Direct mail
[01:02:44.280 --> 01:02:47.800]   But nowadays, I think it's the land jeff isn't the landscape hugely different
[01:02:47.800 --> 01:02:50.760]   Yeah, I think I think god help me for saying what i'm about to say
[01:02:50.760 --> 01:02:53.320]   But I think there's a lesson to be learned from donald trump
[01:02:53.320 --> 01:02:56.760]   And and it's this no not god help you. It's clear. I mean he
[01:02:57.320 --> 01:03:01.000]   Very effective at doing and well and and so it wasn't it wasn't
[01:03:01.000 --> 01:03:04.760]   Uh, my candidate hillary clinton turned it all try to turn into a machine
[01:03:04.760 --> 01:03:12.680]   Trump was a human being of a swords himself. That's it. He used that he was a master of media right?
[01:03:12.680 --> 01:03:17.880]   Was it he could someone who is no, not really but but but could someone who is uh
[01:03:17.880 --> 01:03:24.040]   Uh, and i'm not saying myself here, but intelligent uh, well-meaning reason informed
[01:03:24.520 --> 01:03:31.880]   um, uh use social media to come off that way to gain trust to gain respect to uh, uh,
[01:03:31.880 --> 01:03:34.600]   Show people that they're that they're
[01:03:34.600 --> 01:03:37.640]   Transparent so the question is how users not the tool
[01:03:37.640 --> 01:03:41.080]   So, I mean every campaign has been using twitter and facebook and so on
[01:03:41.080 --> 01:03:45.160]   But they've been using it in an episode of ways what trump did was he just got around all of that and around media
[01:03:45.160 --> 01:03:50.520]   And just said i'm gonna say whatever the heck i want to say people loved it. We're gonna rally behind them. They still do
[01:03:51.640 --> 01:03:59.320]   No, well, you know, this is some of the stuff that we've been studying is that there's um, there's this idea of mmm medic warfare
[01:03:59.320 --> 01:04:09.480]   And that the trump memes and the and you know the story isn't here the hillary memes that the meme story here is the the battle between trump and bernie sanders
[01:04:09.480 --> 01:04:12.920]   And bernie had quite a meme
[01:04:12.920 --> 01:04:20.200]   um factory running on facebook full of dedicated people that were making memes every day
[01:04:20.840 --> 01:04:28.520]   Interesting. I didn't know that different groups of people all of the memes that you've seen related to bernie and the bird falling on him
[01:04:28.520 --> 01:04:36.440]   And all of these things are coordinated within facebook groups a lot of times they'll start working on a meme and they'll get a
[01:04:36.440 --> 01:04:44.280]   Uh, you know a picture and they'll start working on a theme together and then the meme will develop in conversation
[01:04:44.920 --> 01:04:51.320]   And then they will take and then after workshopping it they'll take it and they'll move it to other spaces like on to reddit
[01:04:51.320 --> 01:04:53.880]   For instance, there was a lot of
[01:04:53.880 --> 01:04:58.920]   strategic meme drops within um the donald reddit and then from that
[01:04:58.920 --> 01:05:08.200]   Community then people are then asked to go spread it out onto twitter and onto uh facebook for broadcast and
[01:05:08.200 --> 01:05:14.200]   And so there's quite a few ways that this would happen and i and i
[01:05:15.400 --> 01:05:21.240]   My fear with the use of technology, but it's coming and i'm not the one that came up with this strategy is essentially
[01:05:21.240 --> 01:05:25.400]   You can either pay a super pack to do sophisticated marketing
[01:05:25.400 --> 01:05:29.240]   Uh for the candidate that you like or you can pay facebook
[01:05:29.240 --> 01:05:32.360]   10 bucks and circulate the meme that you made
[01:05:32.360 --> 01:05:38.520]   And it you can select the ad targeted buckets of people and what we know is that
[01:05:39.240 --> 01:05:46.840]   Memes aren't just meant to get people to like something they can also be used in an offensive manner that is to
[01:05:46.840 --> 01:05:52.280]   trigger other communities of people into disliking something or to get
[01:05:52.280 --> 01:06:00.680]   Distracted or upset about the wrong thing. Do you think there are wizards at this who are carefully plotting this or it was kind of accidental?
[01:06:00.680 --> 01:06:04.680]   I think it's throwing spaghetti at the wall and hoping something it's cooked
[01:06:04.680 --> 01:06:07.640]   But don't you know so so for the next couple of years
[01:06:07.640 --> 01:06:12.760]   With the wall now. Yeah, well for that calls years is nothing. There's people who yeah, it's cheap to throw spaghetti
[01:06:12.760 --> 01:06:19.480]   But there's also people who are looking very carefully right now. What's spaghetti stuck and and refining it. I would presume
[01:06:19.480 --> 01:06:23.880]   Yes, no, this is may not be Cambridge Analytica. That seems to they had a meme of their own
[01:06:23.880 --> 01:06:28.520]   Well, that's interesting. So so jon and i were still at a conference where everyone
[01:06:28.520 --> 01:06:33.880]   I think virtually everyone in the room right zone just poo poo's that kabra jon ledica did anything of note
[01:06:33.880 --> 01:06:35.880]   What's what's your take on that?
[01:06:36.040 --> 01:06:43.080]   It's hard to tell right because we're not going to know I mean the the idea that you could use psychometrics and nudge people
[01:06:43.080 --> 01:06:50.200]   I would say that the only way that you're going to guarantee that they saw the content that you were using to nudge is using ad tech at this point
[01:06:50.200 --> 01:06:53.000]   And we know that donald trump was circulating
[01:06:53.000 --> 01:06:55.640]   um on peak days
[01:06:55.640 --> 01:06:57.640]   150,000
[01:06:57.640 --> 01:07:01.960]   Create pieces of creative and so that's uh
[01:07:01.960 --> 01:07:04.840]   messages online
[01:07:04.840 --> 01:07:09.560]   per day and so when people have the conversation about honest ads and
[01:07:09.560 --> 01:07:12.200]   What does it mean to monitor?
[01:07:12.200 --> 01:07:16.360]   Political campaigns. I start to wonder at the scope of things
[01:07:16.360 --> 01:07:21.720]   You know, this is this is a how many people do you need to monitor one person's campaign?
[01:07:21.720 --> 01:07:23.160]   But if you were to report hilly
[01:07:23.160 --> 01:07:27.080]   clinton's campaign and john trump's campaign hilly did was a little more old school was big
[01:07:27.080 --> 01:07:29.320]   media buys
[01:07:29.320 --> 01:07:33.000]   and uh trump channeled a smaller amount of money into
[01:07:34.040 --> 01:07:37.640]   This new media stuff and it was very very very effective
[01:07:37.640 --> 01:07:41.960]   Also perhaps because candidate trump was made for that medium
[01:07:41.960 --> 01:07:45.080]   Uh in a way that hilly clinton was not
[01:07:45.080 --> 01:07:48.680]   Yeah, but you can't discount the um
[01:07:48.680 --> 01:07:50.360]   the kind of
[01:07:50.360 --> 01:07:54.120]   fandom that goes on online fandom is an important aspect of how
[01:07:54.120 --> 01:07:56.680]   dissipate in online cultures
[01:07:56.680 --> 01:08:01.000]   And so fandom was now bernie got from zero to contender
[01:08:01.480 --> 01:08:07.000]   Right exactly exactly so one of the things that we have to be careful of is of course
[01:08:07.000 --> 01:08:12.040]   We don't want to hand over and say oh their master puppeteers look their strategy work
[01:08:12.040 --> 01:08:17.960]   But we also have to understand that he had a digital mark uh trump had a digital marketing strategy
[01:08:17.960 --> 01:08:24.360]   And hilly had movement people and when you have movement people and you have political strategists
[01:08:24.360 --> 01:08:26.360]   they're thinking in a very um
[01:08:26.760 --> 01:08:33.320]   Coordinated way but they're thinking about you know votes in the street and people on the ground and then they have a digital strategy that
[01:08:33.320 --> 01:08:36.040]   Reflex the agenda of the party
[01:08:36.040 --> 01:08:41.640]   But you can imagine when you go back and look at all of the things that were circulated that were pro trump
[01:08:41.640 --> 01:08:43.640]   But I don't even want to say pro republican
[01:08:43.640 --> 01:08:48.520]   Uh because he was definitely running a side. It's become clear. He's his own party now. Yeah
[01:08:48.520 --> 01:08:55.400]   Yeah, he he was he was speaking in multiple registers and there were so many different groups that were motivated to create
[01:08:56.200 --> 01:09:01.800]   Content on his behalf, right? This is stuff that's not he's the first meme president
[01:09:01.800 --> 01:09:09.080]   I would say yeah, I would so because even uh, we have uh, amelia acker is a amazing researcher at uty austin
[01:09:09.080 --> 01:09:14.600]   And she's been looking at that. Um, she's the steward of the social media
[01:09:14.600 --> 01:09:22.120]   Archive from the white house under obama and and there's just a remarkable difference in the amount
[01:09:22.600 --> 01:09:27.320]   in the so you know just in the in the sheer amount and volume of
[01:09:27.320 --> 01:09:33.800]   Social media that's attached to the trump administration that just wasn't present during the obama
[01:09:33.800 --> 01:09:40.280]   It's interesting because obama really reinvented presidential campaigning himself and and galvanized
[01:09:40.280 --> 01:09:43.320]   Groups that were not traditionally
[01:09:43.320 --> 01:09:49.800]   uh democrats style words. I mean this it's almost as if we've had two presidents in a row that broke the mold
[01:09:51.160 --> 01:09:55.800]   And maybe you will not be yeah, I wonder going forward because obama
[01:09:55.800 --> 01:10:00.440]   2008 was a year after the iphone, right? So he was campaigning
[01:10:00.440 --> 01:10:06.840]   As we were embracing mobile as it strikes me and i'm not a historian of uh elections, but it strikes me that
[01:10:06.840 --> 01:10:09.720]   his on the ground
[01:10:09.720 --> 01:10:16.600]   Organization and the coalitions he was able to to form and the people he's able to get off their asp to vote
[01:10:16.600 --> 01:10:20.840]   Were unique to him and I don't think it had to do with technology
[01:10:21.080 --> 01:10:24.680]   I think it was much more retail as a tool they used but it was just like
[01:10:24.680 --> 01:10:29.400]   It's like re-tale or dean used to or dean used to tool. So so stacey what what difference did you think that
[01:10:29.400 --> 01:10:33.240]   What what did the technology set in motion then for him?
[01:10:33.240 --> 01:10:38.520]   I think he did a lot of like small time small time
[01:10:38.520 --> 01:10:45.480]   Campaign donations so he got people to donate he spent a lot of time on the web all the platforms were
[01:10:45.480 --> 01:10:48.600]   very well disseminated. I think also
[01:10:49.480 --> 01:10:53.480]   More so in 2012 he did use twitter and facebook
[01:10:53.480 --> 01:10:56.440]   not the way that trumped it but
[01:10:56.440 --> 01:11:01.720]   You know to to build a coalition and to activate his voting base
[01:11:01.720 --> 01:11:08.600]   I think that was a pretty good job right there and to reach youngsters and youngsters. Did I really just say that? I did
[01:11:08.600 --> 01:11:12.920]   You're the youngster on this show, but okay. Wow
[01:11:12.920 --> 01:11:15.880]   Well, jones is now too
[01:11:15.880 --> 01:11:21.960]   Yeah, no, I wish I wish that were the case one of the things that I think also that we have to measure with technological
[01:11:21.960 --> 01:11:26.760]   Development is that people get more agile and more used to using these tools as
[01:11:26.760 --> 01:11:32.120]   We become more familiar with them and so it isn't just that new things get introduced
[01:11:32.120 --> 01:11:35.480]   We get better at using the old things and so
[01:11:35.480 --> 01:11:40.040]   Another thing that's been widely overlooked is the use of
[01:11:40.040 --> 01:11:41.800]   SMS
[01:11:41.800 --> 01:11:45.160]   Messaging in mobilizing people to vote and reminding people
[01:11:45.880 --> 01:11:50.120]   Did that very effectively yes, and but this was weaponized during the
[01:11:50.120 --> 01:11:56.760]   2016 election where there was a massive disinformation campaign to convince people that they could vote by text
[01:11:56.760 --> 01:11:59.560]   Oh my god. You're just circulating through twitter
[01:11:59.560 --> 01:12:04.040]   Where different hashtags and different people were being targeted with
[01:12:04.040 --> 01:12:11.080]   memes and pictures one very famous one of a mocked fake meme of a season. Sorry
[01:12:11.880 --> 01:12:15.480]   Showing people how to how to vote and get involved by text and so
[01:12:15.480 --> 01:12:22.680]   There's more to come I think in terms of impersonating and in phishing campaigns that
[01:12:22.680 --> 01:12:27.080]   We're going to have to be much more aware of and I think we're going to have to adopt
[01:12:27.080 --> 01:12:31.720]   A very adversarial approach to understanding political media
[01:12:31.720 --> 01:12:39.320]   In the midterm elections. There's a group called first draft right now that is doing very good work getting
[01:12:40.840 --> 01:12:43.480]   a kind of collaboration in place
[01:12:43.480 --> 01:12:49.800]   Where the people are going to be actively looking for these disinformation campaigns and not just influence ops from
[01:12:49.800 --> 01:12:55.000]   Other governments but looking at what's in the meme space? What is coming through these?
[01:12:55.000 --> 01:13:02.200]   These um pipes that we're not equipped for in order to tell the public that that's not true
[01:13:02.200 --> 01:13:10.120]   Yeah, we're going to see what's app and and similar platforms being used a lot more in columbia and brazil
[01:13:10.680 --> 01:13:17.560]   Uh, they've been major forces in election disinformation. So we're going to see stuff. We don't we can't find anymore
[01:13:17.560 --> 01:13:20.520]   This is the most interesting conversation. We've had in a while. I really think
[01:13:20.520 --> 01:13:25.880]   So 2018 is a lot sooner than the presidential election and 2018 is many different
[01:13:25.880 --> 01:13:29.400]   Smaller elections. This is where uh
[01:13:29.400 --> 01:13:32.920]   This is where this could really start to show its strength
[01:13:32.920 --> 01:13:38.280]   And i'm gonna i'm willing to bet steve bennons already indicated. He's really wants to use 2018
[01:13:39.160 --> 01:13:43.800]   Uh to marshal an army i'm gonna i'm willing to bet that he's one of the geniuses behind
[01:13:43.800 --> 01:13:47.640]   Getting uh these these meme factories working. I mean that
[01:13:47.640 --> 01:13:52.840]   He wasn't just it wasn't just the right. I mean, uh occupy democrats on the left occupy
[01:13:52.840 --> 01:13:55.480]   For that. Yep
[01:13:55.480 --> 01:14:03.240]   Um, yeah, and even in in that I think there's a natural inclination in online participatory culture to
[01:14:03.240 --> 01:14:06.840]   want to do something and one of the things that you can do is be
[01:14:07.640 --> 01:14:12.120]   Uh a creative person that that makes media political content
[01:14:12.120 --> 01:14:13.960]   Podcast
[01:14:13.960 --> 01:14:20.440]   But it's that active moment where people think if I could just you know convince them not to vote
[01:14:20.440 --> 01:14:27.560]   Or convince them or or you know these disinformation campaigns that suggest that you're polling places somewhere that it's not
[01:14:27.560 --> 01:14:32.760]   Or that uh voting's been cancelled. These are the things that we have to worry about
[01:14:32.760 --> 01:14:36.440]   Especially if they look and sound as if they're coming from official
[01:14:37.080 --> 01:14:38.360]   accounts
[01:14:38.360 --> 01:14:43.080]   Um, and so it's really going to be up to these platform companies to get their verification
[01:14:43.080 --> 01:14:45.800]   Um, you know
[01:14:45.800 --> 01:14:49.080]   Papers in order so that people can see the right signals
[01:14:49.080 --> 01:14:54.600]   From accounts and and know that it's coming from a city council or know that it's coming from
[01:14:54.600 --> 01:14:57.480]   a uh account run by
[01:14:57.480 --> 01:15:06.760]   A police department rather than hoping that i despair of the general american public being able to figure that sucker out
[01:15:07.080 --> 01:15:09.080]   Yeah, well, that's why there's many
[01:15:09.080 --> 01:15:15.160]   Verification groups in play that are trying to think about what are the appropriate signals to send
[01:15:15.160 --> 01:15:15.960]   Yeah
[01:15:15.960 --> 01:15:21.000]   More than just a blue checkmark to let people know that they're engaging with something that has been verified
[01:15:21.000 --> 01:15:27.640]   As you would if you were to flip to the municipality section of your what used to be the the white pages, right?
[01:15:27.640 --> 01:15:29.560]   Stacy go ahead
[01:15:29.560 --> 01:15:32.920]   Well, I was just saying what will be also interesting is how
[01:15:33.400 --> 01:15:39.960]   Corporate interests how this plays out with them and I bring this up because in austin for example a couple years ago
[01:15:39.960 --> 01:15:43.320]   We had a big city council vote over
[01:15:43.320 --> 01:15:46.760]   Basically, it was a referendum on uber and lift in the city
[01:15:46.760 --> 01:15:49.320]   And uber pulled out all the stops
[01:15:49.320 --> 01:15:55.640]   Including offering people rides to the polls they sent me texts they use their app to galvanize people
[01:15:55.640 --> 01:15:58.440]   and I just saw actually
[01:15:59.160 --> 01:16:05.720]   A press release from Comcast that says in light of the tax bill passing and the repeal of net neutrality
[01:16:05.720 --> 01:16:12.760]   That brian robert's the ceo of Comcast is giving $1,000 bonuses to his employees and pledging to
[01:16:12.760 --> 01:16:17.980]   Invest 50 billion in investment over the next five years and in their networks
[01:16:17.980 --> 01:16:23.080]   Stacy if I may just just add on that work on the revenue but for information point of information
[01:16:23.080 --> 01:16:24.600]   point of information
[01:16:24.600 --> 01:16:31.320]   AT&T did that first and it turns out the $1,000 bonuses were mandated a couple weeks ago by the union a b
[01:16:31.320 --> 01:16:33.560]   Guess what AT&T wants to do next?
[01:16:33.560 --> 01:16:37.880]   So there this is a thank you gift for net neutrality. Sorry. Go ahead
[01:16:37.880 --> 01:16:43.320]   No, no and I was about to say now the carriers have long played these kind of games
[01:16:43.320 --> 01:16:46.040]   but what you're seeing now is
[01:16:46.040 --> 01:16:51.960]   They usually have played this with politicians. So a lot of our broadband investment from
[01:16:52.600 --> 01:16:56.040]   the initial run into fiber was kind of
[01:16:56.040 --> 01:17:04.200]   It was it was highly politicized and the politicians, you know were they would donate money and then get
[01:17:04.200 --> 01:17:09.160]   Promises to subsidize some investments that never then actually happened
[01:17:09.160 --> 01:17:14.360]   So what's interesting here though is that they're starting to talk about this and give this out
[01:17:14.360 --> 01:17:20.760]   To the world at large and there's no no checks on this and so that then becomes
[01:17:21.960 --> 01:17:25.400]   There are checks in the form of the media actually reporting this but
[01:17:25.400 --> 01:17:27.880]   It
[01:17:27.880 --> 01:17:34.360]   You may not see what the media reports, especially if you're only listening to certain channels, right? And so it just
[01:17:34.360 --> 01:17:40.680]   The weaponization is not just from foreign states. It's also from corporate interests
[01:17:40.680 --> 01:17:45.640]   And we should be and I think that's a little bit more nefarious and it's a little harder to go after
[01:17:45.640 --> 01:17:48.680]   Yep
[01:17:48.680 --> 01:17:49.880]   Let's uh
[01:17:49.880 --> 01:17:51.880]   Take a little break
[01:17:52.760 --> 01:17:59.960]   Because you wanted to see uh rebel wilson sing google translated christmas songs, right jim? I do I do
[01:17:59.960 --> 01:18:01.880]   This is uh
[01:18:01.880 --> 01:18:04.760]   Jimmy found so I guess this is a regular bit for Jimmy they
[01:18:04.760 --> 01:18:11.320]   They take traditional christmas carols and they let google translate they put them through romanian and then back to english
[01:18:11.320 --> 01:18:16.360]   Oh, they round trip it becomes tonight the play jimmy found plays
[01:18:17.880 --> 01:18:21.720]   So we did the same thing with song lyrics some people have this rebel wilson from a
[01:18:21.720 --> 01:18:28.600]   Picture my guest so you're up first. Here's this special microphone. You will be singing the google translate version
[01:18:28.600 --> 01:18:36.520]   Okay, of deck the halls which when translated is called the homes are covered
[01:18:36.520 --> 01:18:40.280]   roots, let's give it a guy
[01:18:40.280 --> 01:18:45.480]   Such a little palette cleanser
[01:18:45.480 --> 01:18:47.480]   Oh
[01:18:47.480 --> 01:19:05.160]   All right
[01:19:05.160 --> 01:19:10.040]   Just had to have a little holiday moment
[01:19:10.520 --> 01:19:16.200]   Without google we would not have destroyed oh and god bless it god bless it everyone
[01:19:16.200 --> 01:19:19.480]   Ah
[01:19:19.480 --> 01:19:21.480]   Germany says facebook cannot
[01:19:21.480 --> 01:19:25.000]   I love this the register
[01:19:25.000 --> 01:19:26.520]   ouch
[01:19:26.520 --> 01:19:31.000]   Germany snaps facebook and it's abusive little face for limitless the amassing data
[01:19:31.000 --> 01:19:33.960]   the uh german competition authority
[01:19:33.960 --> 01:19:37.320]   Jeff you can say it bun does cartel numbed
[01:19:38.040 --> 01:19:39.320]   uh ricki
[01:19:39.320 --> 01:19:44.600]   Bundas cartel armed informed facebook on tuesday of its preliminary legal assessment
[01:19:44.600 --> 01:19:50.680]   That by forcing third-party websites and apps including the ones it owns what's app and instagram
[01:19:50.680 --> 01:19:55.880]   And anybody using a facebook api to share their data with facebook was abusing its position
[01:19:55.880 --> 01:20:01.080]   So they're they're they're going to prevent facebook from getting any information out of what's app or instagram
[01:20:01.080 --> 01:20:03.960]   using gdpr
[01:20:05.960 --> 01:20:09.880]   Why is that what you said? Yeah, oh, hey
[01:20:09.880 --> 01:20:17.640]   users cannot expect data which is generated when they use services other than facebook to be added to their facebook account to this extent
[01:20:17.640 --> 01:20:22.120]   It is all the same company
[01:20:22.120 --> 01:20:24.280]   Yeah, I was sitting here with google a while ago. Oh my god
[01:20:24.280 --> 01:20:29.880]   You're gonna use google maps. Well, yeah, it's the same company and google maps and google search are now intertwined in a way that you
[01:20:29.880 --> 01:20:33.160]   Couldn't tell them apart, but be that way germany be that way
[01:20:33.960 --> 01:20:35.960]   *sigh*
[01:20:35.960 --> 01:20:42.280]   Uh google applies machine learning to planet hunting and is discovered
[01:20:42.280 --> 01:20:44.600]   XO planet
[01:20:44.600 --> 01:20:45.560]   XO planet
[01:20:45.560 --> 01:20:47.560]   This is cool
[01:20:47.560 --> 01:20:53.800]   So yeah, you can't deny this is valuable using a data set of more than 15,000
[01:20:53.800 --> 01:20:56.200]   Kepler signals
[01:20:56.200 --> 01:21:00.200]   Kepler is the space telescope NASA launched eight years ago
[01:21:01.240 --> 01:21:05.560]   uh, they created a tensor flow model to distinguish planets from non planets
[01:21:05.560 --> 01:21:13.880]   To do this it had to recognize patterns caused by actual planets versus patterns caused by other objects like star spots and binary stars
[01:21:13.880 --> 01:21:17.160]   Then the system said all right. We got the planets
[01:21:17.160 --> 01:21:19.720]   uh
[01:21:19.720 --> 01:21:22.040]   96 accuracy rate
[01:21:22.040 --> 01:21:25.560]   Then they use the system to hunt for new planets. So how do they know it's a
[01:21:25.560 --> 01:21:28.200]   XO planet, which is an earth-like planet, right?
[01:21:30.920 --> 01:21:35.320]   Say say again, the definition of an exoplanet. I didn't know what it was. It was just some other planet
[01:21:35.320 --> 01:21:39.720]   Oh exo means just out of our solar system. Never mind. All right with 200
[01:21:39.720 --> 01:21:45.320]   I was hoping it was earth-like exoplanets, but no with 200,000 stars in the database
[01:21:45.320 --> 01:21:50.520]   They looked at 670 stars that had two or more previously discovered exoplanets
[01:21:50.520 --> 01:21:54.600]   And by doing that they learned what an exoplanet was better than I did anyway
[01:21:54.600 --> 01:21:59.160]   And discovered two new ones kepler adg and kepler 90i
[01:21:59.720 --> 01:22:03.240]   Now that's computer intelligence
[01:22:03.240 --> 01:22:10.040]   Huh two new planets. Thank you. Thank you google. Thank you google AI
[01:22:10.040 --> 01:22:15.320]   I think we've discovered a lot of new planets though like yeah, yeah thousands
[01:22:15.320 --> 01:22:20.040]   It was a big it's but recently that's a funny thing is we didn't even know there were planets outside our solar system
[01:22:20.040 --> 01:22:25.640]   We assumed there must be but we didn't know until relative that's why new tools are the best thing for science science
[01:22:26.600 --> 01:22:31.960]   All right google has said no more project tango this art core stuff. Good enough
[01:22:31.960 --> 01:22:34.920]   AR core good enough
[01:22:34.920 --> 01:22:38.360]   Tango was the very advanced hardware based
[01:22:38.360 --> 01:22:43.080]   augmented reality that required, you know a special camera and special phone
[01:22:43.080 --> 01:22:50.520]   AR core is just like apples AR kit fed was announced curiously close to the announcement of AR kit
[01:22:50.520 --> 01:22:52.280]   and
[01:22:52.280 --> 01:22:58.360]   Well, we've seen already what AR core can do because those stickers those new stickers on the pixel camera
[01:22:58.360 --> 01:23:03.160]   Yeah, that's what finally got I have never used even though I now have them. They're cool
[01:23:03.160 --> 01:23:09.400]   Oh, they are cool. I showed them off the office. That's how you use them in an office to say look what I have
[01:23:09.400 --> 01:23:11.960]   And you don't you apo stay stay works alone. She was
[01:23:11.960 --> 01:23:14.840]   Are you saying I need friends you need some friends
[01:23:14.840 --> 01:23:19.640]   You can't appreciate the goog until you guys look what I made for my daughter abby
[01:23:20.200 --> 01:23:24.600]   I made a video of floating balloons in my office, but they're not real balloons
[01:23:24.600 --> 01:23:30.600]   You can go all around them and see them, but they're not real balloons. That's AR kit
[01:23:30.600 --> 01:23:32.920]   Okay, our core
[01:23:32.920 --> 01:23:34.920]   That's kind of cool
[01:23:34.920 --> 01:23:37.880]   No, it's that's okay. It is huh
[01:23:37.880 --> 01:23:41.640]   Use it. Is that how could that be misused? Sorry
[01:23:41.640 --> 01:23:45.560]   Yeah, yeah, you know if you were to make a
[01:23:47.080 --> 01:23:54.120]   UFO land in the middle of times square, you know, it could be a problem or a porg on my desk
[01:23:54.120 --> 01:23:56.840]   Yes
[01:23:56.840 --> 01:23:58.200]   It's cool
[01:23:58.200 --> 01:24:03.480]   Started talking about this actually when pokemon go came out and the idea was
[01:24:03.480 --> 01:24:06.520]   You know, I mean the most of the stories were about you know
[01:24:06.520 --> 01:24:12.600]   People are falling off of sidewalks because they're not looking at the ground, but there is a you know
[01:24:12.680 --> 01:24:16.040]   There are many many concerns among people about
[01:24:16.040 --> 01:24:21.640]   televisual and audio hacking and the inability to distinguish truth from reality
[01:24:21.640 --> 01:24:30.680]   And this is you know long-term standing concerns that people had when the you know photograph got introduced and what does it mean to freeze someone in time?
[01:24:30.680 --> 01:24:35.880]   If you're if you're smart you look at this picture of my wife with a stormtrooper you could see
[01:24:35.880 --> 01:24:41.000]   My wife's shadow is going a different direction than the storm. Oh your wife's not real, right?
[01:24:41.240 --> 01:24:43.240]   So my wife is not real
[01:24:43.240 --> 01:24:51.160]   All that effort I've spent learning how to tell photoshopped images could start coming in handy for me. I'm married to a star trooper
[01:24:51.160 --> 01:24:56.280]   Yeah, baby a stormtrooper married to a stormtrooper that sounds like a capra movie
[01:24:56.280 --> 01:25:02.760]   I'm married a stormtrooper. Yeah, um, I don't know. I think this is kind of cool
[01:25:02.760 --> 01:25:05.800]   I actually I had a this is this is the final version
[01:25:06.200 --> 01:25:11.880]   But actually I had to position her because she was right behind him for at first and I said put your arm around him
[01:25:11.880 --> 01:25:17.480]   I said no, no, you could go to the go to the left left. No, okay other your wife
[01:25:17.480 --> 01:25:22.280]   To go to the left. No, no move over. That's actually a better picture right there
[01:25:22.280 --> 01:25:26.200]   However a little more a little more a little more
[01:25:26.200 --> 01:25:29.400]   Perfect wolf
[01:25:29.400 --> 01:25:31.400]   There you go
[01:25:31.880 --> 01:25:36.520]   Yeah, I don't I don't really come on Stacy. It's cool. I
[01:25:36.520 --> 01:25:42.120]   It's it's you're no fun Stacy. You're just no fun
[01:25:42.120 --> 01:25:47.640]   That's why we only have fun until it's you know, it's fun for a minute
[01:25:47.640 --> 01:25:56.200]   It's fun until like the state or another state gets I hold up it and then there, you know, uh, you know, it's just you know
[01:25:56.200 --> 01:26:01.800]   Well, you're a buzz kill. Yeah, jeez. Oh, yeah, it's fun until north korea gets a hold of it
[01:26:02.600 --> 01:26:05.560]   You understand what's happening in the world and so
[01:26:05.560 --> 01:26:14.440]   You know as as it becomes harder to know that you're watching a movie when you think you're watching the news or things, you know, we're we're in for
[01:26:14.440 --> 01:26:24.040]   What uh, we're already there right reality jamming right to say that he's a the chief data officer over at the new york times
[01:26:24.040 --> 01:26:29.480]   We're already there. I mean you go to you go to a movie and half the movie is not real. You don't know it
[01:26:30.200 --> 01:26:33.880]   Mm-hmm. I'm not talking about star wars. I'm talking about just like a regular everyday movie
[01:26:33.880 --> 01:26:38.360]   You know, yeah, I bet the audience actually thinks i'm a real person
[01:26:38.360 --> 01:26:44.520]   They could tell right there where your where your robot voice went a little bit of funny. That was the giveaway
[01:26:44.520 --> 01:26:50.120]   Yeah, the danger is when they automate podcasts, right? That's the well leo's done it
[01:26:50.120 --> 01:26:55.560]   There's i've been dead for four boy. I've been dead for eight years. Yeah, you're all made up
[01:26:56.600 --> 01:27:02.920]   It's just leo. It's just it's not even me. It's a clone. He's the loneliest man on earth. He just he just talks to uh
[01:27:02.920 --> 01:27:07.960]   Imaginary people. I wish I could do that. Joan has to get going
[01:27:07.960 --> 01:27:10.680]   Uh, can you give me five more minutes?
[01:27:10.680 --> 01:27:15.640]   We just because I want you get you have a good pick you have a great pick and I wanted to get that if you can
[01:27:15.640 --> 01:27:19.320]   So let me get do an ad quickly and then we'll get give me five more minutes. Can you?
[01:27:19.320 --> 01:27:21.880]   Yes, I can thank you
[01:27:21.880 --> 01:27:25.800]   I don't I won't make you. I mean if you have to go you have to go but I know i'm i yeah
[01:27:25.960 --> 01:27:29.560]   It's a seven p.m. Show up at pen station. I'll be fine
[01:27:29.560 --> 01:27:31.720]   Oh, you're fine. What are you going to see?
[01:27:31.720 --> 01:27:37.960]   We're going to see elf the musical. I don't know if it's going to be ridiculous or
[01:27:37.960 --> 01:27:43.800]   Just bet on that it could be both. That sounds awesome ridiculously awesome
[01:27:43.800 --> 01:27:46.520]   Yes, it's real feral in it. No
[01:27:46.520 --> 01:27:49.800]   No, I wish but it's you know just kicking in the holiday spirit
[01:27:49.800 --> 01:27:54.600]   All right, our show brought to you real quickly. We'll do this and then i'll get Joan's pick
[01:27:54.680 --> 01:27:57.480]   Jarshow brought to you by go to webinar
[01:27:57.480 --> 01:28:03.560]   They are amazing. I did a go to webinar helping parents protect their teens
[01:28:03.560 --> 01:28:09.960]   So what's great about that is you can give it in live and people can attend live you can have up to six presenters kind of an unlimited number of people
[01:28:09.960 --> 01:28:14.280]   Can watch it? I don't remember we had 50 or 60, but the beauty part is you can record it
[01:28:14.280 --> 01:28:20.360]   And the recorded on-demand version continues, you know as long as you want and it's just as interactive as the original
[01:28:20.840 --> 01:28:25.640]   You know you can as you're doing a go to webinar you can have 20 polls each with 20 questions
[01:28:25.640 --> 01:28:27.640]   You won't use that many but as many as
[01:28:27.640 --> 01:28:31.160]   Uh, which is nice you set up questions at the begin like for instance
[01:28:31.160 --> 01:28:36.920]   I had a poll at the beginning asking people who they were what they're what they were interested in that helps me do a better job as a presenter
[01:28:36.920 --> 01:28:39.960]   You could do questions on the fly too though if something comes to you and you go
[01:28:39.960 --> 01:28:43.320]   You know like we do on the show how you know if you were going to run for president
[01:28:43.320 --> 01:28:50.280]   How would you do it something like that? You can have polls like that and the thing is even in the on-demand version later people are watching the replay
[01:28:50.280 --> 01:28:55.160]   All those polls are live and active so it is just as interactive that engages your audience
[01:28:55.160 --> 01:28:58.520]   It keeps them awake makes it more fun and it's even better for you
[01:28:58.520 --> 01:29:03.800]   With go to webinar, it's easy to start a webinar you they have custom email invitations
[01:29:03.800 --> 01:29:06.840]   confirmation emails reminder emails
[01:29:06.840 --> 01:29:10.680]   Automated email templates, so you don't even need to do that. They just let them handle it
[01:29:10.680 --> 01:29:15.160]   They can always have your company logo and custom image on all the webinar materials
[01:29:16.200 --> 01:29:22.680]   It's also mobile friendly so you can do all of this uh schedule webinar even edit a session or track performance from your iOS or android
[01:29:22.680 --> 01:29:30.040]   Device go to webinar and I love the analytics the real-time analytics give you an idea of how you're doing
[01:29:30.040 --> 01:29:33.800]   So you can do better next time you can also get qualified leads other metrics
[01:29:33.800 --> 01:29:39.240]   End to end 128 bit AES encryption so it's secure number one in customer satisfaction
[01:29:39.240 --> 01:29:44.600]   I want you to try at go to webinar.com slash podcast turn your next presentation
[01:29:45.080 --> 01:29:51.000]   Into a conversation with go to webinar for more information go to webinar.com slash
[01:29:51.000 --> 01:29:54.040]   podcast
[01:29:54.040 --> 01:29:59.960]   Joan donovan is a researcher at data and society. She researches media manipulation
[01:29:59.960 --> 01:30:06.600]   And you had a very interesting book you were talking about before the show you want to make that your pick of the week
[01:30:06.600 --> 01:30:11.400]   Um, yeah, so one of my favorite books and i'm revisiting it
[01:30:12.200 --> 01:30:16.040]   More uh more and more is phil lapsley's exploding the phone
[01:30:16.040 --> 01:30:23.320]   And one of the reasons why I love this book is it's rife with a first person accounts from phone freakers
[01:30:23.320 --> 01:30:26.920]   About the different kinds of exploits the different kinds of
[01:30:26.920 --> 01:30:33.320]   Infrastructure all hacks that they've encountered and you know, there's stories that are a little bit more
[01:30:33.320 --> 01:30:35.000]   um
[01:30:35.000 --> 01:30:40.040]   In the vein of social engineering really the birth of social engineering happens
[01:30:40.840 --> 01:30:44.600]   with people trying to hack telephone infrastructures in order to convince
[01:30:44.600 --> 01:30:51.640]   You know operators to give them free calls. Um, and so there's lots of young
[01:30:51.640 --> 01:31:00.040]   You know experimentation going on and then there's also some foreshadowing of surveillance state type
[01:31:00.040 --> 01:31:03.320]   You know
[01:31:03.320 --> 01:31:05.720]   That there's this there's this alliance where
[01:31:06.440 --> 01:31:12.200]   AT&T is trying to understand if people are stealing phone calls so they start just recording the first
[01:31:12.200 --> 01:31:17.960]   90 seconds of any phone call without really thinking about the implications of what that might be and so
[01:31:17.960 --> 01:31:19.800]   um
[01:31:19.800 --> 01:31:25.400]   So phil lapsley's book really takes a deep dive into history but also helps us think about
[01:31:25.400 --> 01:31:30.520]   well, what are the problems that we've always known we're here with technology and
[01:31:30.520 --> 01:31:33.480]   misuse, um or
[01:31:34.200 --> 01:31:40.760]   in some cases innovative use, uh, there's some great stories about technology that was built
[01:31:40.760 --> 01:31:46.280]   the the blue box, of course, uh, tone dialers that were used to
[01:31:46.280 --> 01:31:50.120]   um, well make free phone calls, but this is
[01:31:50.120 --> 01:31:59.960]   The selling of blue boxes is infamously tied to the birth of the apple computer and getting people involved in home brew and um
[01:31:59.960 --> 01:32:02.440]   micro computing
[01:32:03.160 --> 01:32:07.800]   You know, but I don't want to call them hobbyists because they became so
[01:32:07.800 --> 01:32:10.760]   so much more than that
[01:32:10.760 --> 01:32:15.000]   um, but yeah, so it's a really great history told from
[01:32:15.000 --> 01:32:17.720]   um, a very
[01:32:17.720 --> 01:32:21.240]   Particular set of people that were doing early hacking
[01:32:21.240 --> 01:32:27.400]   Um, and they were known as phone freaks which some of the people in your audience might know about and some of them are
[01:32:27.400 --> 01:32:30.440]   I'm sure that I've known my share
[01:32:30.760 --> 01:32:36.600]   I remember was telling me about how he used to listen in to satellites, uh phone calls on the satellites
[01:32:36.600 --> 01:32:41.800]   Was never stopped why people thought all was and jobs cleaned up their act
[01:32:41.800 --> 01:32:49.080]   Uh, and after they found an apple, maybe steve jobs did but was did not and was this was his stories are legend
[01:32:49.080 --> 01:32:51.240]   legend
[01:32:51.240 --> 01:32:53.720]   There was something more exciting even as a teenager
[01:32:54.440 --> 01:33:01.000]   Accidentally picking up your wireless phone and hearing the conversation of a neighbor, right?
[01:33:01.000 --> 01:33:02.040]   Yeah
[01:33:02.040 --> 01:33:07.960]   They ended up cross frequencies and so there's you know and there's there's really great stories about
[01:33:07.960 --> 01:33:14.600]   Discovery of you know captain crunch of course and discovering that you can use whistles and joy bubbles is a
[01:33:14.600 --> 01:33:17.320]   is a young
[01:33:17.320 --> 01:33:23.560]   Blind teenager that discovers that he can whistle the tones because he has perfect pitch and so it's 600
[01:33:24.120 --> 01:33:32.200]   Um, you know at the intersection of bodies and technology and it's really great account of history of computing that I think is
[01:33:32.200 --> 01:33:36.200]   Um would have been lost if lapsley hadn't really
[01:33:36.200 --> 01:33:42.760]   Taken the time to do such an admirable job surfacing that history. Yeah, i'm glad he wrote this
[01:33:42.760 --> 01:33:46.120]   I'm gonna have to get it. This is really interesting
[01:33:46.120 --> 01:33:52.120]   And uh, I guess it will just another time i'll tell you about how I wrestled with john draper. That's a story for another day
[01:33:52.120 --> 01:33:54.120]   Okay
[01:33:54.120 --> 01:34:01.160]   Joan donovan thank you so much. It's really nice to show we will have you back very nice to have you on the show
[01:34:01.160 --> 01:34:08.440]   Forward to it. Thank you very much. It's been great talking with everyone. Yeah, malipulation research lead at data and society. Enjoy the show
[01:34:08.440 --> 01:34:15.480]   Come by anytime elf the musical. I want to review. I will I will i'll tweet it to you later
[01:34:15.480 --> 01:34:17.400]   Thanks, john
[01:34:17.400 --> 01:34:22.280]   At boston jone on twitter if you want to see her. Thank you very much. I appreciate it. Have a good one
[01:34:22.280 --> 01:34:24.440]   See you. Bye. Bye
[01:34:24.440 --> 01:34:28.680]   Jeff you got a number for us. Oh, we're already there. Oh, I thought we were just doing them for sure
[01:34:28.680 --> 01:34:33.320]   I mean, we've done an hour and a half. You want to do another hour. We easily could there's plenty to talk about
[01:34:33.320 --> 01:34:35.960]   God knows
[01:34:35.960 --> 01:34:39.160]   Um, let's see what else there is all right more stories
[01:34:39.160 --> 01:34:40.280]   Oh
[01:34:40.280 --> 01:34:43.000]   You guys she wants to go to dinner. You want to go to
[01:34:43.800 --> 01:34:50.200]   You know, I've got tickets for elf the musical I I do not I think we should have saved her from it
[01:34:50.200 --> 01:34:52.280]   I'd like to go right now
[01:34:52.280 --> 01:34:54.920]   Let me just see it was really else here
[01:34:54.920 --> 01:34:57.160]   No, there is there is lots to talk about
[01:34:57.160 --> 01:34:59.800]   Okay, but i'm gonna i'm gonna do triage
[01:34:59.800 --> 01:35:02.440]   Yeah, yeah, by all means, uh, supposed to use
[01:35:02.440 --> 01:35:06.120]   You make it sound so fancy leo triage triage
[01:35:06.120 --> 01:35:10.200]   Uh, I think we did actually most of the really interesting stuff
[01:35:10.200 --> 01:35:13.960]   We did we did a lot of the good stuff. Well, we didn't talk about twitter so so twitter's
[01:35:13.960 --> 01:35:20.280]   Um finding religion and getting rid of bad guys. Yes. So did you get purged last? I knew mike sort of it
[01:35:20.280 --> 01:35:22.600]   She's still there. Yeah, that very funny. I did not get purged
[01:35:22.600 --> 01:35:25.400]   Mike sort of it just still there
[01:35:25.400 --> 01:35:32.040]   They purged the woman who tweeted the the british woman who tweeted the uh, any muslim videos that donald trump retweeted
[01:35:32.040 --> 01:35:34.520]   She's gone
[01:35:34.520 --> 01:35:37.640]   Uh, what was her name the jade of fransans
[01:35:39.080 --> 01:35:43.240]   She was the uh, the head of the uh, ultra naturalist britain first
[01:35:43.240 --> 01:35:46.760]   She's she's gone. She's suspended. Goodbye
[01:35:46.760 --> 01:35:53.240]   Right, uh, it's ironic. She's probably thinking well how come they can suspend me, but not donald trump
[01:35:53.240 --> 01:35:56.040]   Yeah, there's some selective
[01:35:56.040 --> 01:36:01.000]   I didn't read the did you read the emails that buzzfeed surfaced?
[01:36:01.000 --> 01:36:05.160]   Uh, the internal company emails at twitter
[01:36:06.280 --> 01:36:11.320]   While they were debating what to do about mylo and the blue checkmark. No, I didn't read that
[01:36:11.320 --> 01:36:13.400]   Oh, no
[01:36:13.400 --> 01:36:15.400]   I did read about google's lasers though
[01:36:15.400 --> 01:36:21.080]   Yeah, you know, yeah, lab lab media lasers lasers is much better
[01:36:21.080 --> 01:36:25.560]   It's actually a sixth grade science fair project
[01:36:25.560 --> 01:36:31.560]   They tried whether you could transmit data over light and of course I couldn't do it with a wow
[01:36:31.560 --> 01:36:34.280]   61 bulb. Wow, that's impressive
[01:36:34.280 --> 01:36:36.920]   You could do Morse code
[01:36:36.920 --> 01:36:39.480]   Can you can you do a dash with the like yeah?
[01:36:39.480 --> 01:36:46.360]   That's data bloomburg has launched a 24-hour news channel, which appears only on twitter
[01:36:46.360 --> 01:36:52.440]   Uh twitter is doubling down on live video the new channel called tick tock
[01:36:52.440 --> 01:36:55.560]   Uh is just for the tweets
[01:36:57.960 --> 01:37:02.200]   It has a curious algal bloomberg's thumby. It's nose at the at the at the other platforms
[01:37:02.200 --> 01:37:04.680]   cheddar
[01:37:04.680 --> 01:37:09.320]   Really? What so why why what I was there? Is there something going on? I didn't know about like?
[01:37:09.320 --> 01:37:16.280]   Unno, uh, joshan smith who is a brilliant ceo bloomberg media is is one of the guys who's being tough on the platforms in terms of negotiating stance
[01:37:16.280 --> 01:37:19.960]   So this is a way that he can do something outside of facebook. Let's say
[01:37:19.960 --> 01:37:24.280]   Um, it's like donald trump's going directly to the people except yeah
[01:37:24.920 --> 01:37:30.680]   Bloomberg now directly to the twits so i'm gonna so it's this is this this is not on the home page of twitter
[01:37:30.680 --> 01:37:35.880]   No, but I saw on my twitter feed it says hey see what's live right now and they're all up
[01:37:35.880 --> 01:37:42.600]   It's a special page twitter.com slash events the company and then you get i'll mute this then you get
[01:37:42.600 --> 01:37:46.920]   This and but then it is also tweets associated with it and
[01:37:46.920 --> 01:37:54.840]   Actually, it's just the ticktocks just ticktocks tweets. Oh, no, there's other. Yeah. That's kind of cool combining video and twos
[01:37:55.160 --> 01:37:56.120]   tweets
[01:37:56.120 --> 01:37:59.240]   Yeah, it's like a front as a service. Yeah. Yeah
[01:37:59.240 --> 01:38:02.520]   Well, you know, that's I mean makes sense for bloomberg, right?
[01:38:02.520 --> 01:38:05.400]   Well, would be really interesting is building
[01:38:05.400 --> 01:38:09.640]   Like not a cms in its entirety, but a way for
[01:38:09.640 --> 01:38:17.080]   You know publishing reporters who are on the scene. Yeah publishing tools so I could come in as a verified reporter for a publication and be like
[01:38:17.080 --> 01:38:22.280]   Yeah, I just saw this and if you could actually authenticate people on the ground
[01:38:23.400 --> 01:38:27.800]   You know that that becomes really interesting too, but that's a little more far-fetched
[01:38:27.800 --> 01:38:31.080]   well, but I was talking to somebody who just went to snap and
[01:38:31.080 --> 01:38:35.320]   Uh, he was saying that that if you play with a snap map
[01:38:35.320 --> 01:38:43.240]   Uh and look at events going on you really do see you see verified people who are there and and and they're verifying each other in essence
[01:38:43.240 --> 01:38:46.760]   Oh, yeah, that's the same scene. This is anything going on. Wow all these perspectives
[01:38:46.760 --> 01:38:48.600]   um
[01:38:48.600 --> 01:38:52.440]   That was one of the original concepts that ever had for twitter was that it was a kind of
[01:38:53.000 --> 01:38:55.000]   worldwide wire service
[01:38:55.000 --> 01:39:01.880]   It is I mean that's that is actually kind of what it's that's how I use it in a lot of ways. Yeah
[01:39:01.880 --> 01:39:04.600]   Yeah, when something happens
[01:39:04.600 --> 01:39:06.600]   Have you ever played with a snap map?
[01:39:06.600 --> 01:39:13.240]   You know it existed. I did not what I did. I did. Nobody read about it. Yeah, somebody
[01:39:13.240 --> 01:39:18.920]   Wrote a really good story about snap maps and how snap maps taught them what snapchat could be
[01:39:21.320 --> 01:39:25.640]   I'm sorry. I so I'm not there's there's a page if you look up snap map
[01:39:25.640 --> 01:39:30.040]   Where you can see how to do it even when they explain it to you. I can't figure out how you
[01:39:30.040 --> 01:39:34.200]   You're old jeff. I am old. There we go. Yes. You pinch in
[01:39:34.200 --> 01:39:36.680]   You pinch in
[01:39:36.680 --> 01:39:42.280]   And then see the world see snaps of events and breaking news from around the world you pinch in on the main on the camera
[01:39:42.280 --> 01:39:44.600]   on the camera. Yeah pinch in
[01:39:44.600 --> 01:39:46.920]   Oh
[01:39:46.920 --> 01:39:49.960]   Look, there's two people snapping right now in the whole world
[01:39:51.160 --> 01:39:53.160]   What were these people?
[01:39:53.160 --> 01:39:56.360]   Me and Alex. I don't know Alex come on. I are there
[01:39:56.360 --> 01:39:58.760]   Okay, that's good
[01:39:58.760 --> 01:40:01.320]   And then I zoom out. This is the rest of the snap world
[01:40:01.320 --> 01:40:08.120]   Uh, there's the golden gate bridge. Oh, look at how hot it is in san francisco right now. It's a snap heat map
[01:40:08.120 --> 01:40:14.680]   It's the the action all the actions happening down here on pine and polk
[01:40:14.680 --> 01:40:17.960]   What does that mean?
[01:40:17.960 --> 01:40:20.760]   Tons of stuff happening really big in new brunswick
[01:40:21.400 --> 01:40:25.800]   So this is because rutkers is there right so la
[01:40:25.800 --> 01:40:30.680]   So what do I do with this so i don't what do you do with any of this leo
[01:40:30.680 --> 01:40:37.880]   It's pretty until you find a use case is pretty a lot of people snap in at universal studios hollywood apparently
[01:40:37.880 --> 01:40:43.960]   Oh, yeah, that's snap where if I chapped if I tapped the heat map. I can see all there. Yeah now I can see
[01:40:43.960 --> 01:40:47.480]   Here's people doing things at universal studios
[01:40:49.640 --> 01:40:54.360]   I could see my time my favorite sandwich in the world. I'm seeing a picture of my very favorite sandwich in the world
[01:40:54.360 --> 01:40:56.360]   It's gone. Of course it's snapchat. What was it?
[01:40:56.360 --> 01:41:00.280]   Well, uh, there's this thing in new york if you go to the the come of the outdoor
[01:41:00.280 --> 01:41:04.680]   Christmas festivals. Yeah baked cheese house h a us
[01:41:04.680 --> 01:41:07.640]   It's rakklette. Oh, I love rakklette
[01:41:07.640 --> 01:41:16.120]   It means a bread wonderful wonderful baguette. Yeah, and then the rakklette is is roasting over the shaved hot cheese
[01:41:16.200 --> 01:41:20.520]   Yeah, shaved the cheese down this beautiful goo. Yeah put a little fine
[01:41:20.520 --> 01:41:23.960]   ham a few uh corny shawl
[01:41:23.960 --> 01:41:25.720]   Mustard
[01:41:25.720 --> 01:41:29.960]   Then they shmush more cheese on the top of it. So your first bite is just a cheesy
[01:41:29.960 --> 01:41:32.600]   Wonder that was just on snap
[01:41:32.600 --> 01:41:38.440]   I got my echo spot, but I left it at home. I was going to show you have an echo spot though, right?
[01:41:38.440 --> 01:41:40.920]   Do you have an echo spot? I'm trying to destroy
[01:41:40.920 --> 01:41:44.680]   I don't want him. That's the alarm talk that watches you
[01:41:45.800 --> 01:41:48.120]   Yeah, I am not a fan not a fan
[01:41:48.120 --> 01:41:56.040]   Not in the bedroom. Mm. It's already sold out. So people it got rave reviews people love that. I can't wait
[01:41:56.040 --> 01:41:57.800]   I
[01:41:57.800 --> 01:42:01.880]   You haven't got yours yet. No, I got mine today, but I've forgotten left it at home. Oh
[01:42:01.880 --> 01:42:05.320]   Oh, is it my office? See if it's in my office. I asked to sera to bring it
[01:42:05.320 --> 01:42:12.040]   Um, marcia blackburn has a senator a representative marcia blackburn has a new rule
[01:42:12.760 --> 01:42:15.800]   Uh new law she wants to do that would uh allow
[01:42:15.800 --> 01:42:22.440]   Pad paid fast lanes and would permanently bar fcc from using title two is it's of course
[01:42:22.440 --> 01:42:27.160]   It's I guess ironically named the open internet preservation act. Oh, jeez
[01:42:27.160 --> 01:42:30.760]   Maybe not maybe she doesn't really understand irony. I don't know
[01:42:30.760 --> 01:42:34.360]   Uh, it would prohibit the fcc from using title two
[01:42:34.360 --> 01:42:38.120]   It would prohibit state governments from enacting their own net neutrality laws
[01:42:39.000 --> 01:42:42.760]   But it would ban blocking and throttling. Oh, here's my snot my spot
[01:42:42.760 --> 01:42:46.360]   Look it just arrived my snots my spot lot
[01:42:46.360 --> 01:42:50.920]   Stop lot. Stop not this is my pick of the week
[01:42:50.920 --> 01:42:54.920]   I haven't even I didn't intentionally didn't set it up last night. I could have
[01:42:54.920 --> 01:42:58.440]   But no, I wanted you guys to be the first
[01:42:58.440 --> 01:43:04.360]   To see my echo spot. So oh, it is bigger than a little bigger than I thought it's pretty
[01:43:04.360 --> 01:43:06.440]   right
[01:43:06.440 --> 01:43:13.320]   This is a amazon echo has a small round screen kind of like it's kind of like the echo shows little brother, right?
[01:43:13.320 --> 01:43:18.200]   And and this is what everybody's a little up in arms about it has a camera
[01:43:18.200 --> 01:43:23.480]   Uh
[01:43:23.480 --> 01:43:25.240]   It has uh
[01:43:25.240 --> 01:43:27.240]   audio out
[01:43:27.240 --> 01:43:31.560]   So what I will do is hook this up to my nice stereo speakers in my bedroom
[01:43:33.880 --> 01:43:39.000]   Anyway, there's not much more to say about it. You guys don't see two intrigues. So well, no, no, no, I wish we really
[01:43:39.000 --> 01:43:46.280]   You want to see video on it? All right. So john only I want to see youtube or amazon tube as it is amazon tube
[01:43:46.280 --> 01:43:50.520]   Yeah, by the way, that's that's uh, what's the latest on that amazon has uh
[01:43:50.520 --> 01:43:55.560]   Is trade market they bought the domain name a while back and then they trademarked it
[01:43:55.560 --> 01:44:01.640]   Open tube on sale right now the echo shows on sale for 150 bucks. This is a little more I think right when
[01:44:02.840 --> 01:44:07.480]   130 that was 129 this is 129 130. Okay, john's gonna plug it in
[01:44:07.480 --> 01:44:10.920]   Uh
[01:44:10.920 --> 01:44:13.960]   Yeah, and then there's you can now buy a google
[01:44:13.960 --> 01:44:20.120]   Chromecast and apple tv's on amazon again for some reason there's the screen here. I'll you went over this
[01:44:20.120 --> 01:44:22.360]   They've kissed and made up they've kissed and made up
[01:44:22.360 --> 01:44:26.680]   Amazon ran a gave gave up. It's gonna start selling them
[01:44:26.680 --> 01:44:29.320]   Echo echo
[01:44:29.320 --> 01:44:31.320]   Yeah, it's a nice looking screen
[01:44:31.800 --> 01:44:37.240]   Little it's little it's little but it's an alarm clock right goes right here. You could turn the camera off
[01:44:37.240 --> 01:44:40.840]   It's zombie. It is uh, it is very much like
[01:44:40.840 --> 01:44:43.880]   Hello, chumby
[01:44:43.880 --> 01:44:45.800]   Chumby chumby
[01:44:45.800 --> 01:44:47.480]   Hello echo spot
[01:44:47.480 --> 01:44:49.160]   english
[01:44:49.160 --> 01:44:51.160]   I could do english or german
[01:44:51.160 --> 01:44:53.640]   Oh, jeff
[01:44:53.640 --> 01:44:58.280]   tight, dutch, dutch, dutch, no do english. They don't completely never get to use it
[01:44:58.760 --> 01:45:00.760]   I
[01:45:00.760 --> 01:45:04.280]   Walking into our wifi
[01:45:04.280 --> 01:45:07.160]   See there we go
[01:45:07.160 --> 01:45:09.160]   connecting
[01:45:09.160 --> 01:45:10.280]   Connecting
[01:45:10.280 --> 01:45:14.200]   It's interesting because in the past you didn't you have to set this up with the app on your phone
[01:45:14.200 --> 01:45:16.680]   This seems to be doing it set up right on the uh
[01:45:16.680 --> 01:45:19.640]   How's it gonna know it's you?
[01:45:19.640 --> 01:45:21.720]   Welcome
[01:45:21.720 --> 01:45:24.600]   Yeah, when you buy a new amazon echo device
[01:45:25.880 --> 01:45:27.880]   It knows who you are. That's me
[01:45:27.880 --> 01:45:34.280]   Am I a pacific standard time you bet? Oh, uh, no, you just you shouldn't have clicked on that
[01:45:34.280 --> 01:45:36.280]   You should I should have next
[01:45:36.280 --> 01:45:41.720]   Jeff, you know how to oh now i'm in t1 at mexico. That's okay close enough checking for app
[01:45:41.720 --> 01:45:45.000]   The vice name leo's echo spot good enough
[01:45:45.000 --> 01:45:50.840]   Your echo spot will be updated. Oh, that's too bad. So now you're oh shoot. It's a nice screen
[01:45:51.640 --> 01:45:55.880]   You know what it's not very loud, but it's better quality than the dot
[01:45:55.880 --> 01:45:58.600]   Let me turn it up
[01:45:58.600 --> 01:46:00.600]   All the way and everything's gonna be round
[01:46:00.600 --> 01:46:07.400]   Yeah round video. Isn't that weird? That's kind of weird like the original television sets. Oh, yeah
[01:46:07.400 --> 01:46:10.280]   I should watch a girl
[01:46:10.280 --> 01:46:12.600]   Yeah, oh yeah
[01:46:12.600 --> 01:46:14.600]   Little stacy when I was a child
[01:46:18.600 --> 01:46:22.920]   Magic leap has said we've got it. We're gonna make it you could buy it
[01:46:22.920 --> 01:46:25.480]   It's gonna be a developer edition no word on price
[01:46:25.480 --> 01:46:29.560]   But I have to say it is look so much better looking than google vlogs
[01:46:29.560 --> 01:46:33.320]   Don't you can't you can't wait to wear these can you Jeff?
[01:46:33.320 --> 01:46:35.000]   Look at that
[01:46:35.000 --> 01:46:38.520]   Is I install the updates your echo spot will restart twice
[01:46:38.520 --> 01:46:43.160]   See, this sounds pretty good. Stacy. I just put one in the in the in the trap
[01:46:43.160 --> 01:46:46.440]   Magic around tb set
[01:46:47.080 --> 01:46:47.800]   Oh
[01:46:47.800 --> 01:46:51.320]   We're edger mccaton stacy to the old days the good old days
[01:46:51.320 --> 01:46:57.560]   the good old days steam powered uh tv states that we had to shovel the coal in the back
[01:46:57.560 --> 01:46:59.960]   to kind of
[01:46:59.960 --> 01:47:06.040]   Uh, we you know, I think I think we can uh we can move on everybody knows how bad people's passwords are
[01:47:06.040 --> 01:47:11.400]   How europe's internet laws threaten the freedom of expression. Yeah, we are we can feed stacy
[01:47:11.400 --> 01:47:14.440]   We could feed stacy. Let's do you have a dinner in nice. Do you see?
[01:47:15.560 --> 01:47:21.160]   Um, I don't know yet, but it's it's I just arrived here. It's more it's less than i'm hungry and more than i'm just
[01:47:21.160 --> 01:47:26.520]   I had to drive here. So it's a three hour drive and now i'm still sitting here and i'm so i'm kind of like we're almost done
[01:47:26.520 --> 01:47:32.360]   It's not we're gonna wrap it up. Are you saying what is she doing? I don't understand what she's doing. She says she's on a show
[01:47:32.360 --> 01:47:34.440]   What show what's the hot?
[01:47:34.440 --> 01:47:36.120]   I don't hear what is this. What is it?
[01:47:36.120 --> 01:47:41.960]   So my my dad watches twig or has in the past. It's a mean of us. Oh, we gotta be nice to you
[01:47:41.960 --> 01:47:44.840]   No, you just need to be nice to my dad
[01:47:45.400 --> 01:47:47.400]   He doesn't care about me
[01:47:47.400 --> 01:47:52.040]   We love your dad. We do mr. You can what you can have him come in say hi
[01:47:52.040 --> 01:47:55.800]   Um, I don't think he's home actually. I think he's
[01:47:55.800 --> 01:48:01.480]   I don't know who's home. See that's it. I want to see my family too. Yeah. No, no, no. I know you. I know you do
[01:48:01.480 --> 01:48:03.240]   Jeff give us a number
[01:48:03.240 --> 01:48:06.760]   All right number number number number number number number number number number. All right, so
[01:48:06.760 --> 01:48:09.160]   Uh, which one do I want to do?
[01:48:09.160 --> 01:48:10.920]   um
[01:48:10.920 --> 01:48:12.520]   Elon Musk
[01:48:12.520 --> 01:48:17.800]   Accidentally revealed his cell number. Yeah, he tweeted it was the oculus cell number
[01:48:17.800 --> 01:48:20.920]   I thought it was the oculus cto cell number. Oh, that would be worse
[01:48:20.920 --> 01:48:27.480]   Bad enough to feel yours. CNBC called the number and you can hear what they heard. Oh
[01:48:27.480 --> 01:48:30.360]   Okay, let's play that here's the audio
[01:48:30.360 --> 01:48:33.320]   Someday
[01:48:33.320 --> 01:48:38.360]   You know, this just is just perfect. I can never autoplay every time
[01:48:38.840 --> 01:48:42.360]   Every time except the one time I wanted to play
[01:48:42.360 --> 01:48:45.640]   Oh my god
[01:48:45.640 --> 01:48:48.120]   It's just actually if you scroll
[01:48:48.120 --> 01:48:53.160]   Here it is down you could link you can hear it. Oh, so he thought this was a dm
[01:48:53.160 --> 01:48:56.760]   Yeah, he thought this was a dm
[01:48:56.760 --> 01:49:00.680]   Go to you can hear it here, but he actually said call me here. Here is
[01:49:00.680 --> 01:49:06.040]   What?
[01:49:06.680 --> 01:49:14.760]   Somehow you found your way here to me. I offer you my congratulations and my respect
[01:49:14.760 --> 01:49:19.000]   Together we so that's what's on his uh, is that true?
[01:49:19.000 --> 01:49:21.160]   Evidently
[01:49:21.160 --> 01:49:23.400]   Dude, dude. They did it. They found our Easter egg
[01:49:23.400 --> 01:49:30.840]   Who are you? I don't know. They did the whole thing, but the so so Elon Musk when he tweeted hit the phone number
[01:49:31.160 --> 01:49:38.040]   He knew that that was not the number. I don't know but on the voicemail message you get by gods by the gods
[01:49:38.040 --> 01:49:43.480]   You've done it somehow you found your way to me. I offer you congratulations some and my respect maybe it really was
[01:49:43.480 --> 01:49:46.440]   His numbers and then he realized
[01:49:46.440 --> 01:49:51.160]   So he put the god of war. We will never know Leo. We will never know
[01:49:51.160 --> 01:49:57.000]   It's kind of weird that elan had that clip just hand lying around
[01:49:57.000 --> 01:49:59.720]   To put on his answering machine
[01:49:59.800 --> 01:50:01.960]   Unless it was kind of what I would expect of him. Yeah
[01:50:01.960 --> 01:50:04.120]   Yeah
[01:50:04.120 --> 01:50:06.120]   I'm with Jeff
[01:50:06.120 --> 01:50:13.000]   Here's uh, so we don't have that in traveling the United States, but the uk government has agreed to make high speed broadband illegal right by the year
[01:50:13.000 --> 01:50:22.280]   2020 and bligeing all internet service providers to at least offer 10 megabits down per second by the year 2020
[01:50:22.280 --> 01:50:25.880]   But brexit, but brexit
[01:50:27.800 --> 01:50:31.880]   Where would you move where would each if you if you said I don't want a little bit american anymore?
[01:50:31.880 --> 01:50:33.560]   Where would you each move?
[01:50:33.560 --> 01:50:35.560]   Amsterdam
[01:50:35.560 --> 01:50:38.200]   Ah, yeah choice. Good choice. Good choice.
[01:50:38.200 --> 01:50:40.680]   Rodband's the freedom
[01:50:40.680 --> 01:50:48.920]   That's the freedom place. Yeah, and it's lovely. Good coffee. Yes, it is. It's everything in bikes flat queso. Not so great there, but that's okay
[01:50:48.920 --> 01:50:52.120]   You can make your own
[01:50:52.120 --> 01:50:55.320]   They got right flag. It would be your business. I bet they got right. Clay's his queso
[01:50:55.960 --> 01:51:01.800]   Yeah, every place has a good melted cheese. You just have to figure out what it's called. It's what the cheese is. Yeah, they're always melting it
[01:51:01.800 --> 01:51:08.760]   I'm going to the british virgin islands. I'll get back to you. It is. I understand a great tax haven although they are at pains to deny it
[01:51:08.760 --> 01:51:12.200]   Uh, i'm hoping to stash all my loot there and come back
[01:51:12.200 --> 01:51:17.720]   I'm putting my bitcoin in the british virgin. I was bit going doing right now
[01:51:17.720 --> 01:51:20.520]   Uh, it's up and down
[01:51:20.520 --> 01:51:23.080]   Uh, I bought a thousand bucks worth. Yeah, it went
[01:51:24.280 --> 01:51:26.280]   November 12. Oh
[01:51:26.280 --> 01:51:28.360]   And so i'm more than double
[01:51:28.360 --> 01:51:34.120]   Nice that it's gone up that much since November 12. It's currently at 16,618 according to the town of it. Yeah
[01:51:34.120 --> 01:51:38.840]   Uh, I have seven and 8.85 bitcoin
[01:51:38.840 --> 01:51:43.800]   Somewhere you have seven bitcoins. Yeah, 0.85 7.85, but I
[01:51:43.800 --> 01:51:49.320]   Can't it's I have the wallet. I don't know. I can't remember the password, which is apparently a thing
[01:51:49.320 --> 01:51:51.880]   thing
[01:51:52.840 --> 01:51:54.840]   A bitcoin's may be lost
[01:51:54.840 --> 01:51:58.840]   I it's it's not lost. I know exactly where it is and sit in my desk
[01:51:58.840 --> 01:52:03.320]   But I can't get into it because I I don't I didn't write down the password
[01:52:03.320 --> 01:52:08.280]   Which usually means I used one of my usual regular everyday
[01:52:08.280 --> 01:52:11.160]   Passwords, but it doesn't seem to be any of those
[01:52:11.160 --> 01:52:18.600]   Yeah, this is it. This is the cryptocurrency equivalent of like your your ship with your gold doubloons hitting the bottom of the ocean floor
[01:52:18.600 --> 01:52:19.880]   Yeah
[01:52:19.880 --> 01:52:23.560]   Yeah, I thought I was so smart. I was gonna keep the wallet on my local computer
[01:52:23.560 --> 01:52:26.280]   That's 133,000 dollars. It's just sitting there
[01:52:26.280 --> 01:52:29.320]   Yeah
[01:52:29.320 --> 01:52:33.720]   Uh, you know
[01:52:33.720 --> 01:52:37.720]   Every once in a while. I'll enter some more passwords. See it could be this could be this
[01:52:37.720 --> 01:52:42.680]   I got a notebook of all the passwords. I've tried. I'm just gonna work my way down the list
[01:52:42.680 --> 01:52:45.960]   Someday
[01:52:45.960 --> 01:52:49.800]   I actually need it now. I bought him the new iMac Pro. I actually need the bitcoin
[01:52:49.800 --> 01:52:53.400]   I have a credit card built coming due
[01:52:53.400 --> 01:53:00.920]   Stacy even bought them does that fabulous Stacy on iot podcast every week with her friend kevin toph our friend kevin tophle too
[01:53:00.920 --> 01:53:08.280]   And as you can read her newsletter at stacey on iot.com follower on the twitter at gigastacey have a great christmas with your family
[01:53:08.280 --> 01:53:12.040]   You didn't like my thing. Did you do or say oh?
[01:53:12.680 --> 01:53:18.920]   What's your thing? I think I feel judged and found wanting no, I didn't even see your thing. What's your thing?
[01:53:18.920 --> 01:53:21.480]   Which could be a thing do your thing
[01:53:21.480 --> 01:53:25.480]   Is so noce is now available on the wink
[01:53:25.480 --> 01:53:28.440]   So for those of you who have a wink smart home hub
[01:53:28.440 --> 01:53:33.240]   If you had smart things for a while you've had sonos for a while, but there you go
[01:53:33.240 --> 01:53:35.400]   And it is
[01:53:35.400 --> 01:53:40.360]   Excellent, you can make robots that will say hey when I open the door. It will play my theme song
[01:53:40.600 --> 01:53:45.480]   Should you want it to do that? I do want that yes, see I thought you would it's very easy
[01:53:45.480 --> 01:53:49.720]   So we know stacey's is i've been working on the railroad
[01:53:49.720 --> 01:53:55.160]   That is not that's that's my recessional. That's my exit song
[01:53:55.160 --> 01:54:00.200]   I enjoy being a girl
[01:54:00.200 --> 01:54:03.800]   That is also not i came song
[01:54:03.800 --> 01:54:08.760]   My own theme song is easy. It would be it would be bitch by lily Allen. It's hard out there for a bit
[01:54:08.760 --> 01:54:10.760]   Love that song great song
[01:54:10.760 --> 01:54:14.520]   Yo, you're your theme song. I did it
[01:54:14.520 --> 01:54:28.840]   You know like that gonna fly now. That's the that's my theme song
[01:54:28.840 --> 01:54:34.440]   Whenever I come in the room. I want to hear this
[01:54:35.160 --> 01:54:37.160]   [Music]
[01:54:37.160 --> 01:54:40.680]   lazy gentlemen
[01:54:40.680 --> 01:54:43.720]   last show of the
[01:54:43.720 --> 01:54:47.800]   holiday season last show of the year you're off you flying off tomorrow
[01:54:47.800 --> 01:54:53.000]   I'm flying off tomorrow to the british virgin islands if I don't drown i'll be back with all of you
[01:54:53.000 --> 01:54:57.880]   on wednesday january 2nd 3rd 4th 5th 6th
[01:54:57.880 --> 01:54:59.640]   Oh
[01:54:59.640 --> 01:55:00.840]   Huh
[01:55:00.920 --> 01:55:05.960]   I was saying the third, but you won't be here for that one. What's the third in that a wednesday january
[01:55:05.960 --> 01:55:07.960]   Yeah, i'll be here for that one
[01:55:07.960 --> 01:55:13.240]   My calendar's all screwed up january 3rd so next week next wednesday
[01:55:13.240 --> 01:55:15.880]   We're going to do a best of twig all the best moments
[01:55:15.880 --> 01:55:24.120]   Involving stacey punching me in the head and stuff. It'll be fun. queso jokes queso jokes galore and then uh the frost
[01:55:24.120 --> 01:55:26.440]   We will be back
[01:55:27.240 --> 01:55:30.600]   We will be back in two weeks for a brand new fresh
[01:55:30.600 --> 01:55:35.560]   edition i'll be coming at you from sun city center florida nice
[01:55:35.560 --> 01:55:38.120]   Snowbird nice
[01:55:38.120 --> 01:55:44.920]   No, no, no retirement community. Yeah, you have to be 55 years old to live in the town not just in the building but in the town
[01:55:44.920 --> 01:55:50.520]   It's just right for us jeff a lot of people key exactly you know people just go there to complain
[01:55:53.880 --> 01:56:00.600]   So jeff is a city university in york where he is proudly teaching young people the merits of great journalism
[01:56:00.600 --> 01:56:03.320]   Thank god somebody's doing it. He also blogs at buzz.com
[01:56:03.320 --> 01:56:08.040]   And you will find his posts on medium as well and of course his books
[01:56:08.040 --> 01:56:12.360]   Including what would google do public parts key experience gifts and more
[01:56:12.360 --> 01:56:15.560]   jeff
[01:56:15.560 --> 01:56:22.360]   Stacey had a great holiday. It's almost there. It's optimizing its seconds away from being a real echo spot
[01:56:23.400 --> 01:56:30.280]   Wow, that's a really long update cycle. Yeah, you know you turn these devices on the first thing it's got to do is download and install
[01:56:30.280 --> 01:56:32.280]   There goes it's almost there almost there
[01:56:32.280 --> 01:56:34.280]   Almost there
[01:56:34.280 --> 01:56:38.440]   Let's play some maroculos middle inspiring
[01:56:38.440 --> 01:56:43.240]   Here it comes
[01:56:43.240 --> 01:56:45.400]   the echo spot
[01:56:45.400 --> 01:56:52.760]   So what should i so would it be bad to put this in my bedroom without telling my wife
[01:56:53.400 --> 01:56:55.400]   Oh, yeah, probably
[01:56:55.400 --> 01:57:00.280]   Oh optimizing is complete
[01:57:00.280 --> 01:57:06.920]   Checking for latest software updates
[01:57:06.920 --> 01:57:11.240]   So ladies gentlemen, you might want to plug this in on christmas eve
[01:57:11.240 --> 01:57:15.640]   In order to have it
[01:57:15.640 --> 01:57:18.600]   What what says something?
[01:57:18.600 --> 01:57:21.720]   Introducing the echo spot
[01:57:21.720 --> 01:57:25.400]   Introducing amazon echo spot sounds better much better than a dot
[01:57:25.400 --> 01:57:29.720]   With a screen that's designed to fit anywhere like on your office desk
[01:57:29.720 --> 01:57:32.680]   That's much better that sound is actually pretty good
[01:57:32.680 --> 01:57:39.160]   It is and it's pretty do more with your voice. Yeah, what what's in my calendar today? I don't know
[01:57:39.160 --> 01:57:45.800]   Today there are two events at 8 a.m. There's a call with great keeps their calendar on amazon
[01:57:45.800 --> 01:57:51.320]   There's been soccer game. Uh you can tie it to your google account, but not a really professional google account
[01:57:51.640 --> 01:57:53.640]   Right that
[01:57:53.640 --> 01:57:55.960]   Without you get up my calendar
[01:57:55.960 --> 01:57:58.680]   Actually, that's kind of you know what?
[01:57:58.680 --> 01:58:00.760]   I will tell you guys
[01:58:00.760 --> 01:58:06.440]   The calendar features a problem because ahead of christmas I had put a note a reminder note on my calendar saying
[01:58:06.440 --> 01:58:10.200]   It was for my daughters in the slime so we're doing a slime restock
[01:58:10.200 --> 01:58:12.760]   So they do it at certain times so I was like
[01:58:12.760 --> 01:58:18.040]   Put the url for the slime thing in the time it restocked as a reminder event on the calendar
[01:58:18.040 --> 01:58:20.680]   And she saw it
[01:58:21.160 --> 01:58:22.360]   Echo
[01:58:22.360 --> 01:58:25.000]   Oh, you so think you ratted me out echo
[01:58:25.000 --> 01:58:30.200]   I know and she also saw it on the tesla because apparently when I get into the car, it's like
[01:58:30.200 --> 01:58:33.080]   Thanks for the day. I'm the tesla too. Yeah
[01:58:33.080 --> 01:58:37.880]   And you can disable both of these things, but if you're not like you gotta do it. Yeah
[01:58:37.880 --> 01:58:43.400]   Yeah, because I am not by nature a super stealthy individual. You know what this is. It's like a clock radio
[01:58:43.400 --> 01:58:48.120]   It's kind of funny, but I you know, I'm actually I think this is great. I like it
[01:58:49.320 --> 01:58:51.320]   So it's like video
[01:58:51.320 --> 01:58:57.240]   I know I do my echo home all the time. Well, it's playing video. Oh, yeah. Yeah, it's still talking but this video
[01:58:57.240 --> 01:59:03.560]   The promise I have to tilt it because it's so bright so it doesn't it doesn't look as good as it could
[01:59:03.560 --> 01:59:06.120]   It looks good. It's just very bright
[01:59:06.120 --> 01:59:09.160]   Can you just skip this? Yeah
[01:59:09.160 --> 01:59:11.880]   But it's long
[01:59:11.880 --> 01:59:13.640]   Yeah, it is
[01:59:13.640 --> 01:59:17.000]   I don't know if you can I can never skip them on mine. Oh watch this
[01:59:17.800 --> 01:59:19.800]   Ah
[01:59:19.800 --> 01:59:23.240]   Now play
[01:59:23.240 --> 01:59:25.240]   loading
[01:59:25.240 --> 01:59:27.400]   Oh, I think oh, is that pretty
[01:59:27.400 --> 01:59:29.960]   It's a very expensive clock
[01:59:29.960 --> 01:59:31.880]   Yeah
[01:59:31.880 --> 01:59:33.880]   Okay, I'm have to use the a word
[01:59:33.880 --> 01:59:36.120]   everybody cover you
[01:59:36.120 --> 01:59:38.280]   Cover your ears
[01:59:38.280 --> 01:59:40.280]   Well, let's go watch
[01:59:40.280 --> 01:59:41.640]   YouTube
[01:59:41.640 --> 01:59:43.640]   What which I do what can I do?
[01:59:43.640 --> 01:59:45.640]   Currently supported
[01:59:45.640 --> 01:59:55.320]   Echo watch the marvelous mrs. Mazzell. Oh, that's it. It's a pretty good show. I like did you ever watch it Jeff?
[01:59:55.320 --> 01:59:58.360]   Echo watch
[01:59:58.360 --> 02:00:01.880]   The marvelous mrs. May's echo. Oh, that's got a lot
[02:00:01.880 --> 02:00:05.240]   Watch the marvelous mrs. Mayzel
[02:00:05.240 --> 02:00:10.600]   Here's the marvelous mrs. Micell season one episode four
[02:00:11.800 --> 02:00:14.440]   I don't know why I'm so four because it knows you've watched one through three
[02:00:14.440 --> 02:00:20.120]   It's a little dark. This is not a way to watch television
[02:00:20.120 --> 02:00:24.520]   Well, she's sitting on the fire escape
[02:00:24.520 --> 02:00:28.520]   She can't see jackbuds her dad won't let her watch jack bar in her bedroom
[02:00:28.520 --> 02:00:34.120]   So she's looking sitting on the fire escape smoking a cigarette watching the neighbors watching jackpar
[02:00:34.120 --> 02:00:37.480]   Which kind of dates it right there and then you know, you know
[02:00:38.200 --> 02:00:45.480]   You know what it looks great, but it's very small very small. You're jackpar. Okay. I'm too young to have been able to check
[02:00:45.480 --> 02:00:49.400]   Oh, no, you are not you watch jackpar. So
[02:00:49.400 --> 02:00:53.960]   I didn't even see Steve Allen. I I started now and I didn't see
[02:00:53.960 --> 02:01:01.320]   Well, Jackie was he was he was no he can't afford. Okay. Well, I'm not gonna argue. Um, and you can also
[02:01:01.320 --> 02:01:04.280]   You can also leo
[02:01:04.280 --> 02:01:07.640]   Ask it to show you your ring doorbell if you've connected echo
[02:01:08.600 --> 02:01:11.880]   I'm sorry. That's gonna show me my front door
[02:01:11.880 --> 02:01:16.840]   A few things share that name. Which one did you want?
[02:01:16.840 --> 02:01:19.880]   The front
[02:01:19.880 --> 02:01:22.360]   Echo show me where I
[02:01:22.360 --> 02:01:26.040]   Skull
[02:01:26.040 --> 02:01:29.240]   Show me my ring video doorbell
[02:01:29.240 --> 02:01:33.960]   Sorry, I didn't find my ring video doorbell
[02:01:34.760 --> 02:01:37.800]   Show me echo crud. It's got a lot
[02:01:37.800 --> 02:01:41.000]   Anastasia show me
[02:01:41.000 --> 02:01:46.760]   Etc. Sure. What what's the temperature outside? Etc
[02:01:46.760 --> 02:01:50.600]   Just go like show me my front door
[02:01:50.600 --> 02:01:55.720]   Why she doesn't know this works as worked in this thing. Sure that name. Which one did you want?
[02:01:55.720 --> 02:01:58.600]   Number one
[02:01:58.600 --> 02:02:03.800]   I don't know what they're talking. Sorry. I didn't find number one. Okay. Never mind. I'm gonna go
[02:02:04.680 --> 02:02:09.080]   Yeah, now you can't go until I show you my front door. You have to stay now
[02:02:09.080 --> 02:02:14.920]   Then you need to pull out your phone and get your app and look and see what it's called. You have to see
[02:02:14.920 --> 02:02:17.960]   My front door
[02:02:17.960 --> 02:02:22.600]   Maybe you maybe your bitcoin password is the same as your front door name. Yeah, it's probably in there
[02:02:22.600 --> 02:02:27.000]   I like this. I am gonna you know what I I understand now why people are very positive about this
[02:02:27.000 --> 02:02:31.400]   And I don't even think we're getting the full value of the speaker because it's not sitting on something
[02:02:31.640 --> 02:02:36.200]   Because the speaker's downfiring and so I think it's to gets a little more resonance from the tabletop
[02:02:36.200 --> 02:02:43.160]   So very nice very nice. Thank you everybody for joining us. Mary Chris does mary christmas happy to be here
[02:02:43.160 --> 02:02:46.360]   Uh next week with the best oven and two weeks for a brand new twig
[02:02:46.360 --> 02:02:49.240]   Have a great day
[02:02:49.240 --> 02:02:51.240]   You
[02:02:51.240 --> 02:02:53.240]   You
[02:02:53.240 --> 02:02:55.820]   (upbeat music)
[02:02:55.820 --> 02:02:58.980]   (vibrant piano music)

