;FFMETADATA1
title=Perfectly Paranoid, Yet Oddly Convenient
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=371
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2016
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:04.800]   It's time for Twig. This week in Google, I am filling in for the world traveler Leo
[00:00:04.800 --> 00:00:08.440]   Laport. We've got Jeff Jarvis, we've got Stacey Higginbotham. We're going to talk pretty
[00:00:08.440 --> 00:00:13.000]   much almost entirely Google this week. We've got Samsung's continuing mess with the battery
[00:00:13.000 --> 00:00:18.720]   explosions. We've got hardware announcement by Google announce. We've got, oh man, we've
[00:00:18.720 --> 00:00:22.720]   got so many other things. Oh, how could I even forget Aloe, the messaging app that we've
[00:00:22.720 --> 00:00:27.480]   all been waiting for, is finally released. We're going to dive deep into that app up next
[00:00:27.480 --> 00:00:42.200]   on this week in Google. Netcast you love. From people you trust. This is Twig. Bandwidth
[00:00:42.200 --> 00:00:54.080]   for this week in Google is provided by cash fly, C A C H E F L Y dot com. This is Twig
[00:00:54.080 --> 00:01:00.840]   this week in Google episode 371 for Wednesday, September 21st, 2016. Perfectly paranoid yet
[00:01:00.840 --> 00:01:07.160]   oddly convenient. This week in Google is brought to you by Casper, an online retailer of premium
[00:01:07.160 --> 00:01:12.000]   mattresses for a fraction of the price because everyone deserves a great night's sleep. Get
[00:01:12.000 --> 00:01:17.520]   $50 off any mattress purchase by visiting Casper dot com slash Twig and enter promo code
[00:01:17.520 --> 00:01:24.000]   Twig. And by Wealthfront. Wealthfront is a low cost automated investment service in
[00:01:24.000 --> 00:01:28.120]   the most sophisticated way to invest your money. Whether you've got millions or you're just
[00:01:28.120 --> 00:01:33.040]   starting out, visit Wealthfront dot com slash Twig and sign up to get your free personalized
[00:01:33.040 --> 00:01:41.560]   investment portfolio. That's www dot Wealthfront dot com slash Twig. And by Blue Apron, Blue
[00:01:41.560 --> 00:01:45.480]   Apron will send you fresh high quality ingredients to cook delicious meals with simple step by
[00:01:45.480 --> 00:01:49.720]   step instructions right to your door. See what's on the menu this week and get your first three
[00:01:49.720 --> 00:01:55.040]   meals free with free shipping by going to blue apron dot com slash Twig. That's blue apron
[00:01:55.040 --> 00:02:03.080]   dot com slash Twig. It's time for this week in Google Twig. I love it when Leo goes out
[00:02:03.080 --> 00:02:07.000]   of town. I know this sounds weird. It's not because I don't like enjoy him being here,
[00:02:07.000 --> 00:02:10.720]   but it usually means that I get to fill in on this week in Google and besides he's having
[00:02:10.720 --> 00:02:15.440]   a lot more fun than any of us right now on his travels vacation around the world. I'm
[00:02:15.440 --> 00:02:21.480]   Jason Howell of filling in for Leo and I'm super psyched to be here joined as always and
[00:02:21.480 --> 00:02:27.760]   really happy to talk once again to Jeff Jarvis. How's it going Jeff? Hey, I'm gonna be back.
[00:02:27.760 --> 00:02:34.080]   I was going for two weeks. But I'm here. What you like it or not? I like it. I do not
[00:02:34.080 --> 00:02:41.680]   choose not. I choose like it. Where were you? Working. I think I was I went to the online
[00:02:41.680 --> 00:02:49.600]   news association in Denver. And I had something else I forgot what it was. Okay. Well, now
[00:02:49.600 --> 00:02:54.040]   you're exciting. Life I lead. I don't even remember what I do. That's my life every single
[00:02:54.040 --> 00:02:57.440]   day. It's like I get through the weekend. They're like, how was your weekend? I don't
[00:02:57.440 --> 00:03:02.280]   think it was good. I don't know what I did, but it was good. Also joining me on the show
[00:03:02.280 --> 00:03:07.720]   Stacey Higabotham. How's it going Stacey? It's going great. I'm excited here. Yeah, it's
[00:03:07.720 --> 00:03:12.560]   that I haven't done Twig with you since you've since you've become part of the Twig family.
[00:03:12.560 --> 00:03:16.320]   So it's really nice to do this with you. Well, you're in for a treat, Bill. Excellent. Well,
[00:03:16.320 --> 00:03:22.840]   I know I know that I've podcasted in forms, I think on tech news today with Stacey in
[00:03:22.840 --> 00:03:29.200]   the past at least once or twice. Yeah. So I'm feisty. You got to be careful. She's also
[00:03:29.200 --> 00:03:35.400]   excitable. I appreciate both both qualities. We've got a lot of stuff to be excitable about
[00:03:35.400 --> 00:03:41.120]   this week. What do you guys think? We do indeed. This has been kind of a crazy week for news.
[00:03:41.120 --> 00:03:44.600]   And this time around, I mean, there's tons of Google stuff to talk about this week, which
[00:03:44.600 --> 00:03:49.160]   is perfect for a show called this week in Google. I think we kind of have to start with
[00:03:49.160 --> 00:03:54.280]   the obvious one though. The thing that as of last night when I wrapped up doing one of
[00:03:54.280 --> 00:03:59.280]   my other shows, Android, Apparina, the very last app I reviewed on that show is usually
[00:03:59.280 --> 00:04:04.520]   reserved for like the big app of the week. And I picked wrong because Alo wasn't released
[00:04:04.520 --> 00:04:09.400]   yet. It's going to release this afternoon. So it's already outdated. Basically,
[00:04:09.400 --> 00:04:16.320]   Oh, well, that's a Jason. I'm going to leave my app pick for the end of the show because
[00:04:16.320 --> 00:04:22.800]   that's my pick a week because I could find anything else. But a close second. Actually,
[00:04:22.800 --> 00:04:28.280]   it's first. It bests it is the release of Alo. This happened last night. Alo is Google's
[00:04:28.280 --> 00:04:34.200]   kind of smart chat app. And it is now a thing that you can download on Android and iOS.
[00:04:34.200 --> 00:04:38.480]   Just go to the Play Store, no more waiting on the wait list pre, you know, they had a
[00:04:38.480 --> 00:04:43.360]   pre release thing that you could sign up for and get notified when it was done. It's out.
[00:04:43.360 --> 00:04:48.240]   And I feel like everybody has been using it and talking about it all morning long. What
[00:04:48.240 --> 00:04:52.880]   are your thoughts? Where do you guys come down on this new chat app, this new chat effort
[00:04:52.880 --> 00:04:53.880]   from Google?
[00:04:53.880 --> 00:04:55.200]   Stay to see your first.
[00:04:55.200 --> 00:05:01.880]   Okay, I think it's fun. I love having everything integrated in there because I am the worst,
[00:05:01.880 --> 00:05:05.040]   the second I switch from one app to another screen to find something or look something
[00:05:05.040 --> 00:05:08.920]   up. I immediately forget whatever I was doing and focus on something completely different.
[00:05:08.920 --> 00:05:14.880]   So this is nice. I'm a little worried about Google kind of backtracking on the ability
[00:05:14.880 --> 00:05:22.400]   to kind of delete information or move chats to keep some of the chat information off their
[00:05:22.400 --> 00:05:26.800]   servers. So I'm kind of like, oh, dang it, opt into encryption and the way to do it's
[00:05:26.800 --> 00:05:32.840]   a little awkward. And so far it's not retroactive. We tried to do that. So if you start a conversation
[00:05:32.840 --> 00:05:37.740]   and suddenly things get sensitive, you're like, oh, hold on, I got to start a new one
[00:05:37.740 --> 00:05:40.520]   in incognito mode.
[00:05:40.520 --> 00:05:44.280]   You think that that was a policy change or a technology limit?
[00:05:44.280 --> 00:05:51.320]   I'm guessing it was probably a policy change based on like keeping the government placated.
[00:05:51.320 --> 00:05:55.760]   Plus it's also going to help Google develop a better product. I mean, the more information
[00:05:55.760 --> 00:05:58.800]   they can slur the better.
[00:05:58.800 --> 00:06:04.280]   For sure, especially when it comes down to kind of the smart kind of AI stuff that's
[00:06:04.280 --> 00:06:08.000]   happening underneath, obviously, and I've got I've got the interface up here. If you
[00:06:08.000 --> 00:06:13.360]   want to take it, Carson, when you get replied, you know, or when you're sent a message, you
[00:06:13.360 --> 00:06:17.800]   get those little smart replies down at the bottom that appear similar to what you might
[00:06:17.800 --> 00:06:22.640]   get an inbox or whatever, I found them to be super accurate. So obviously Google knows
[00:06:22.640 --> 00:06:27.160]   what it's doing in analyzing how I talk to people because it usually says exactly what
[00:06:27.160 --> 00:06:31.280]   I'm thinking about saying. So you just tap it and it sends it right off. But in order
[00:06:31.280 --> 00:06:38.200]   for it to do that, it needs to have unencumbered access to your conversation, both for the
[00:06:38.200 --> 00:06:42.320]   word that you might want to say at that moment and for the context that preceded that in
[00:06:42.320 --> 00:06:46.560]   order to get there. And so I think that's Google's rationale anyway is is, well, how
[00:06:46.560 --> 00:06:50.680]   else are we going to bring you this really cool, neat kind of predictive stuff if we
[00:06:50.680 --> 00:06:55.040]   don't then also have access to your conversation so we can analyze it and give you the things
[00:06:55.040 --> 00:07:00.080]   that we think you need or that you want. But it is. It might have been. I was going
[00:07:00.080 --> 00:07:05.600]   to say it might have been totally on point so far with the smart reply. Kevin and I were
[00:07:05.600 --> 00:07:11.480]   Kevin Tofel and I were chatting back and forth and it gave me. It wasn't actually right because
[00:07:11.480 --> 00:07:16.280]   we overlapped on our texting, but it was right based on the context of the words that
[00:07:16.280 --> 00:07:24.200]   we said. That makes sense. I think so. Yeah. And I mean, Google at IO had said that all
[00:07:24.200 --> 00:07:33.120]   conversations would be stored in an unidentifiable way. And basically, I mean, if I don't know,
[00:07:33.120 --> 00:07:36.120]   I don't know why that changed. I don't know if it's a policy thing like, like you were
[00:07:36.120 --> 00:07:41.800]   saying or maybe Google just thinks it allows them to enables them to make a better product
[00:07:41.800 --> 00:07:47.040]   that will satisfy the needs of people wanting to use it. But I'm pretty disappointed in
[00:07:47.040 --> 00:07:52.560]   that too. I feel like the trend right now with messaging is more secure, more secure.
[00:07:52.560 --> 00:07:57.480]   And this feels like a big step backwards. So there's basically. So one you can do an
[00:07:57.480 --> 00:08:01.520]   incognito, you can do an encrypted doesn't appear anywhere chat, right? But you have
[00:08:01.520 --> 00:08:06.520]   to do it in advance. You can. Yes, you can. The second question is, can you as you can't
[00:08:06.520 --> 00:08:13.440]   encrypt the history, which I kind of get technically, but Stacy, your further suggestion is could
[00:08:13.440 --> 00:08:18.920]   you erase? You can't erase a chat if it's not encrypted. So you can erase a chat. You
[00:08:18.920 --> 00:08:23.680]   can erase your whole history. Like I could delete our previous chats right here. But
[00:08:23.680 --> 00:08:29.040]   can you erase one chat? I don't know if I can erase one chat. Let's see if I can erase
[00:08:29.040 --> 00:08:29.520]   just that one.
[00:08:29.520 --> 00:08:34.000]   See to help some things. I'm not sure that you can. Like I'm tapping and holding on some
[00:08:34.000 --> 00:08:38.320]   of the ones. Let's see if I can tap and hold on the last one that I dropped, which was
[00:08:38.320 --> 00:08:42.080]   me showing off how the text you can make it bigger and smaller. And there's nothing I
[00:08:42.080 --> 00:08:43.440]   can do with that.
[00:08:43.440 --> 00:08:49.160]   I can delete an entire thread. So I just deleted the entire conversation Kevin and I had.
[00:08:49.160 --> 00:08:53.520]   Yeah. So you can delete the conversations for sure. You go out to your main list and
[00:08:53.520 --> 00:09:00.000]   is can you leave for Kevin as well? That's a good question. That's a really good question.
[00:09:00.000 --> 00:09:08.120]   Let's see if he responds. Shame to be. Well, yeah. So I'm curious to know that actually.
[00:09:08.120 --> 00:09:11.680]   Obviously, if you send him a new message, he'll probably see it and that would be a new thread.
[00:09:11.680 --> 00:09:17.040]   But if I delete that, that conversation, does it then disappear from Kevin's list, let's
[00:09:17.040 --> 00:09:21.200]   say? That is a really good question.
[00:09:21.200 --> 00:09:29.880]   Well, but yeah, sorry. Yeah. Okay. All right. Well, we'll hear about that. I mean, basically
[00:09:29.880 --> 00:09:35.560]   as far as this whole security thing, you know, is concerned motherboard, Edward Snowden even
[00:09:35.560 --> 00:09:42.560]   has basically said stay far away from Aloe. Google easing up on the encryption protection
[00:09:42.560 --> 00:09:47.720]   basically is very bad for security. Of course, this has, you know, been the drum that Snowden
[00:09:47.720 --> 00:09:54.200]   has been beating for a few years now. I don't know. Is this I mean, but I guess my question
[00:09:54.200 --> 00:09:59.960]   there is, is this anything more than what Google is already doing? You know, it already needs
[00:09:59.960 --> 00:10:04.720]   all this access to our emails, let's say, and we share potentially we share way more about
[00:10:04.720 --> 00:10:08.600]   ourselves in email than we do in chat or is that mistaken?
[00:10:08.600 --> 00:10:13.480]   I don't think that's true for like young people. I'm also going to tell you that Kevin got back
[00:10:13.480 --> 00:10:18.200]   and he said that our old thread is still in his chat. So I could delete all my phone
[00:10:18.200 --> 00:10:23.480]   and not his. Oh, so the point is that if you were trying to, having just done this
[00:10:23.480 --> 00:10:29.720]   dastardly perfect murder Stacy, I didn't know this about you Stacy. How did you know?
[00:10:29.720 --> 00:10:34.480]   Things give more interest to the molecules. She's dialogically, you can be sure of it.
[00:10:34.480 --> 00:10:39.960]   Right. So you, we also so it's deleted from your view. We don't know those deleted from
[00:10:39.960 --> 00:10:43.320]   Google's database and it certainly isn't deleted. Well, obviously is it because Kevin still
[00:10:43.320 --> 00:10:49.440]   has it? Right. So so either you have to encrypt going in or you're F'd.
[00:10:49.440 --> 00:10:56.160]   Basically. But when you do that, of course, you don't get any of the extra bells and whistles
[00:10:56.160 --> 00:11:02.360]   that won't get our replies on my murder, my murder help. I'm thinking of dissolving
[00:11:02.360 --> 00:11:05.640]   a body and lie. Google, I've got a solution for you.
[00:11:05.640 --> 00:11:11.040]   So I told you Jason, do not cross her. Do apparently not. I'm going to be really careful
[00:11:11.040 --> 00:11:17.160]   in this show. So what did Google promise that I owe? So what is what is the backtracking
[00:11:17.160 --> 00:11:23.200]   here? Well, the Google basically promised from what I can remember that by default conversations
[00:11:23.200 --> 00:11:29.800]   were not going to be trackable to you that they were going to store conversations in
[00:11:29.800 --> 00:11:35.280]   what for for access within the app, but that it wouldn't be trackable to you in some way
[00:11:35.280 --> 00:11:40.280]   that they would make it less identifiable, let's say. And they also said they would store
[00:11:40.280 --> 00:11:49.520]   the messages transiently, right? So it was they promised end to end encryption in not
[00:11:49.520 --> 00:11:58.680]   in the egg. I cannot say this word in cognito mode. And then the story messages for a limited
[00:11:58.680 --> 00:12:03.120]   amount of time is supposed to forever. And now they're saying they're going to store
[00:12:03.120 --> 00:12:10.840]   all non incognito messages by default. And it's unclear if it's going to be identifiable.
[00:12:10.840 --> 00:12:21.800]   Right. Hmm. Yeah, so I don't know how I feel. I mean, this is going, I imagine it's just
[00:12:21.800 --> 00:12:27.000]   going to make those who don't like the fact that Google has lots and lots of information
[00:12:27.000 --> 00:12:32.040]   about you based on your usage of those products. It's going to make those people not want to
[00:12:32.040 --> 00:12:35.480]   use this. And there's going to be a whole other subset of people that are like, yeah,
[00:12:35.480 --> 00:12:39.120]   well, whatever, that's that's what there's going to be a lot of. There'll be a lot of
[00:12:39.120 --> 00:12:43.160]   people caught out. And if you start using a cognito mode, people are going to be like,
[00:12:43.160 --> 00:12:48.160]   well, why? Yeah, that's a good way. I mean, that's that is, that's the whenever you make
[00:12:48.160 --> 00:12:55.000]   these things opt in as opposed to default. Well, yes, it make it a choice to go private,
[00:12:55.000 --> 00:13:00.880]   like, why are you going private? Right. What have you got to hide? Are you about to tell
[00:13:00.880 --> 00:13:07.240]   me about the body that you just buried? Or I just told all of our listeners. So clearly,
[00:13:07.240 --> 00:13:11.320]   I'm not worried. Yeah, they're friends. They're friends. They are. It would never give me
[00:13:11.320 --> 00:13:16.920]   up. They deserve to know. Oh, they love you. So the other part of Alo, of course, well,
[00:13:16.920 --> 00:13:22.280]   I mean, we're talking about it kind of tangentially, but the Google Assistant hooks. And what can
[00:13:22.280 --> 00:13:26.320]   you do with Google Assistant? When you first load up the app, and I've got this up again
[00:13:26.320 --> 00:13:32.720]   here, you enter into a conversation with Google Assistant. And it allows you to do things
[00:13:32.720 --> 00:13:40.240]   like I played a game that I was very bad at identifying movies based on emoji, essentially.
[00:13:40.240 --> 00:13:48.840]   So you can play games, you can, you know, solve riddles. They have quiz doodle games,
[00:13:48.840 --> 00:13:55.160]   different different functions around assistant, like getting to know one another essentially.
[00:13:55.160 --> 00:14:00.840]   Basically, I mean, what we heard about it at IO that I that that Alo would allow you
[00:14:00.840 --> 00:14:05.920]   to chat with Google Assistant. So it wasn't very important for me. So I just put it, I
[00:14:05.920 --> 00:14:10.720]   put it, I was downtown, I found it for when I put in lunch question mark. It responded,
[00:14:10.720 --> 00:14:13.720]   let's find you something. By the way, what kinds of food do you like? I'll remember
[00:14:13.720 --> 00:14:20.000]   and give you better options. So I answered burgers, Mexican, Italian fish. Oh, I didn't
[00:14:20.000 --> 00:14:24.360]   quite catch that. Oh, no, what kind of food do you like? Okay, needs a sentence. So I
[00:14:24.360 --> 00:14:30.740]   like burgers, Mexican, Italian fish, still same response. Commas are their commas in
[00:14:30.740 --> 00:14:36.920]   burgers, comma, there's commas. Okay. Maybe you should have just stuck with I like burgers,
[00:14:36.920 --> 00:14:41.040]   or just burgers. Yeah. That's the thing. Do I do it four times? Right. But one of their
[00:14:41.040 --> 00:14:46.600]   examples you like, one of their examples to me was multiple things. I guess it just wasn't
[00:14:46.600 --> 00:14:52.840]   the noted anything else. Let me try this. So I see it. There we go. French. No, I don't
[00:14:52.840 --> 00:15:00.360]   like French. Well, I do, but Mexican Mexican is my favorite. Oh, come to Texas. Are you
[00:15:00.360 --> 00:15:10.120]   about? And I said Mexican and it said noted anything else. So I'm gonna try Italian French.
[00:15:10.120 --> 00:15:16.520]   I like burgers noted anything else. It gave me I like burgers as a no, it's okay. Auto
[00:15:16.520 --> 00:15:26.600]   complete. Oh, what is it? I'm gonna try fish. It got it. I don't understand what happened
[00:15:26.600 --> 00:15:33.280]   to you. What's this? So is it actually giving you options? And it gave me bubble gum shrimp
[00:15:33.280 --> 00:15:39.960]   company. Hey, Google, I got better taste than that. I'm not a tourist. It should know this
[00:15:39.960 --> 00:15:45.040]   about you, Jeff. It's been here. I live here. Yeah, I'm getting red lobster and bubble gum
[00:15:45.040 --> 00:15:49.720]   shrimp company. Jesus, Google. Surely if you know me this well, you know, I'm a classier
[00:15:49.720 --> 00:15:55.680]   guy than that. It's like I already disappointed in your disappointment in me Google. Can they
[00:15:55.680 --> 00:16:00.320]   pay for that? That's a good question. If you're red lobster, can you pay to get better features
[00:16:00.320 --> 00:16:05.760]   in Aloe? Good question. Yeah, that is a good question. Now, how do I want you? But it's
[00:16:05.760 --> 00:16:10.920]   so so so it's got bubble gum shrimp company and La Bernadine, which is the the the lower
[00:16:10.920 --> 00:16:15.400]   opposites of culture in the world, right? You know, pick one and if it sees you're eating
[00:16:15.400 --> 00:16:20.280]   it one or the other, then it'll give you maybe better recommendations going forward.
[00:16:20.280 --> 00:16:26.560]   A Bernadine, here's a brief. I got Applebee's and I hop. So, you know, I'm not going to
[00:16:26.560 --> 00:16:32.400]   try anything now. I'm like, he's terrible. I mean, I also got some other ones, Namaste
[00:16:32.400 --> 00:16:38.000]   Kitchen, Cafe, Geo, Giostra. Never heard of that one Brazil barbecue. But yeah, I hop
[00:16:38.000 --> 00:16:41.440]   in Applebee's, which I believe are like right around the corner from the new studio. So maybe
[00:16:41.440 --> 00:16:44.160]   that's more purely based on location than anything.
[00:16:44.160 --> 00:16:50.520]   And use it as my default. So I like so I we're gonna get the voice of Leo in a second.
[00:16:50.520 --> 00:16:54.560]   This is a good place. Excellent. So as soon as I got Aloe, I'm sitting in the conference
[00:16:54.560 --> 00:17:00.240]   and I and I I am noxiously I know he's on vacation, but I am noxiously go to Leo. And
[00:17:00.240 --> 00:17:06.960]   I say, do you have Aloe yet? And he goes back, how'd you get it? I didn't see you on
[00:17:06.960 --> 00:17:12.960]   your iOS, but then I'm in France makes feelings about that now. And never mind, I just got
[00:17:12.960 --> 00:17:20.120]   a text on my six P five to the rescue. So he comes in in another account and Leo goes
[00:17:20.120 --> 00:17:28.440]   berserk. He's immediately the master, the ninja. France, man, I got Aloe. See, I hope
[00:17:28.440 --> 00:17:30.640]   this I haven't played this. Here's audio.
[00:17:30.640 --> 00:17:37.600]   What is Google playing at? I can't use it as my default text messenger on my next six
[00:17:37.600 --> 00:17:44.560]   P question mark. It's just like he's here. He's obviously using the voicemail feature
[00:17:44.560 --> 00:17:48.600]   as the voice entry feature. And there's which there are two different things. They see you
[00:17:48.600 --> 00:17:53.720]   were talking about this in our chat. And then so then I say there are other way to stock
[00:17:53.720 --> 00:17:58.320]   home for the crews. So I said, I love Stockholm. You have to go to the store off, which I'm
[00:17:58.320 --> 00:18:00.800]   trying to push him to, but he doesn't want to go because that's herring. But it says
[00:18:00.800 --> 00:18:05.240]   not just herring. So then he, you know, the quick intro for the restaurant came up.
[00:18:05.240 --> 00:18:11.200]   Yeah. So it's got cool stuff. Mm hmm. Yeah. I was chatting with Leo for quite a while
[00:18:11.200 --> 00:18:14.880]   this morning. Actually, you can pull my screen here. He was, he was waiting at the airport.
[00:18:14.880 --> 00:18:22.440]   So I think him, I'm sure was kind of bored. And so we went for a long chat on here. And
[00:18:22.440 --> 00:18:26.440]   actually, one of my, one of the things that I really like about it is that audio message
[00:18:26.440 --> 00:18:31.800]   feature. Right now I'm doing an episode of this week in Google Leo wish you were here.
[00:18:31.800 --> 00:18:36.120]   But really you're having just a tad more fun than we are unless you're on an airplane.
[00:18:36.120 --> 00:18:40.800]   If it's that's the case, then I'm very sorry. So then I let go. That's going to send him
[00:18:40.800 --> 00:18:45.720]   a 10 second message and right now I'm doing an episode of this week in Google. All right.
[00:18:45.720 --> 00:18:48.920]   And you heard me do it the first time. But it was really cool because like you start
[00:18:48.920 --> 00:18:54.920]   doing this is almost like like this delayed cloud sync push to talk like and not that
[00:18:54.920 --> 00:19:00.520]   voice messages are anything new. But the way that Aloe kind of surfaces it, it makes it
[00:19:00.520 --> 00:19:05.160]   really easy to use on the fly when you want to communicate something, maybe typing it
[00:19:05.160 --> 00:19:09.320]   just seems like God, am I going to seriously sit here for 15 seconds and swipe out my idea?
[00:19:09.320 --> 00:19:13.000]   I'm just going to record my video and move on with my day or my audio and move on with
[00:19:13.000 --> 00:19:18.200]   my day. I really like that feature. But there's no undo button. No, there is not.
[00:19:18.200 --> 00:19:25.000]   Which I was as I was like, don't. So you got like two seconds of Stacy going, wait, ah,
[00:19:25.000 --> 00:19:31.960]   which I'm very happy to have. Yes. Yeah. No, that's a really good point. I mean, once you hold
[00:19:31.960 --> 00:19:37.960]   that down, that thing, when you let go of it, it's sending. It's going whatever you say there or
[00:19:37.960 --> 00:19:41.960]   if someone, you know, suddenly runs by yelling their social security number, there's nothing
[00:19:41.960 --> 00:19:48.040]   you can do to prevent that from happening. That is true. So I compare Aloe to Facebook
[00:19:48.040 --> 00:19:53.400]   messenger, to Google Hangouts, to WhatsApp. What's your thoughts?
[00:19:53.400 --> 00:19:58.600]   I've really used WhatsApp. So it's hard for me to compare it to that. But a lot of people are
[00:19:58.600 --> 00:20:04.280]   comparing this in many ways to WhatsApp. Personally, I don't know that I don't know the comparison.
[00:20:04.280 --> 00:20:09.720]   I know the voice mail or the voice message thing is very similar. And a lot of the UI has similar
[00:20:09.720 --> 00:20:15.320]   kind of notes between the two. Leo mentioned on that audio message that you played that there's
[00:20:15.320 --> 00:20:19.800]   no SMS integration. A lot of people are upset with that about the fact that you can't make this
[00:20:19.800 --> 00:20:27.240]   your SMS app. Google did note it. Note that at I/O. So that's not necessarily a surprise. But
[00:20:27.240 --> 00:20:33.160]   it's one of those kind of indicators that makes this whole like Google and messaging
[00:20:33.160 --> 00:20:39.720]   kind of conversation much more confusing, right? Google has so many different things going and
[00:20:39.720 --> 00:20:47.320]   messaging right now. They've got Aloe for the smart chats between people. They've got hangouts for
[00:20:47.320 --> 00:20:55.160]   messaging between people. I don't know. The messenger is for the SMS aspect. Hangouts is also for the
[00:20:55.160 --> 00:21:00.200]   SMS aspect. But now they've kind of removed some of the SMS functionality. So it's not as much.
[00:21:00.200 --> 00:21:04.520]   It's just so confusing. I don't know how you compare it because they're all different enough,
[00:21:04.520 --> 00:21:11.000]   but similar enough, if that makes any sense. With hangouts, you can still, or I think you can still,
[00:21:11.000 --> 00:21:18.360]   turn a conversation incognito or I think it's take it off the record in the middle of a conversation.
[00:21:18.360 --> 00:21:26.440]   Yes. And I like that. I do like that. I'm trying to, compared to WhatsApp, it feels like
[00:21:26.440 --> 00:21:31.320]   comparing, it feels like bringing WhatsApp in with some of the nice features from Google Now. So like
[00:21:31.320 --> 00:21:37.240]   when you click on one of these restaurants, like Kevin and I were looking for restaurants in London,
[00:21:37.240 --> 00:21:43.000]   and he actually just typed, I think he typed, "I want to stake dinner in London Saturday night."
[00:21:43.000 --> 00:21:53.240]   And it just brought up a bunch of restaurants in London. And being able to look at the menu
[00:21:53.240 --> 00:21:56.920]   from in there and all of that stuff was really nice. I don't know.
[00:21:56.920 --> 00:22:02.200]   And could you make a reservation from that point too? I know some of these bots allow you to go
[00:22:02.200 --> 00:22:07.080]   further with it. So I clicked on a restaurant near me, and it gives me the option, in this case,
[00:22:07.080 --> 00:22:13.080]   to call, directions, pictures, menu, or it tells me to go to other places.
[00:22:13.080 --> 00:22:18.200]   Right. So I guess I have those results too. I could tap into it and see what happens here.
[00:22:18.200 --> 00:22:23.800]   Namaste. Okay. And it gives me the information that you would get in like an informational card on
[00:22:23.800 --> 00:22:29.000]   Google search for your audience. Yeah. I thought you were also told, I said, I need to go to Berlin.
[00:22:29.000 --> 00:22:31.960]   I thought I would say, "Oh, do you want flights? Do you want this?" And that just gave me the,
[00:22:31.960 --> 00:22:37.160]   you know, the Brandenburg Gates there. It didn't offer to teleport you there. Google.
[00:22:37.160 --> 00:22:43.480]   It's got a button for flights. And I'm not sure what I expect from a chat app.
[00:22:43.480 --> 00:22:49.160]   Yeah. Well, yeah. That's kind of nice. It's nice to have this in here. I don't know,
[00:22:49.160 --> 00:22:54.840]   you know, again, I think it takes a little bit of programming on the user side to think about
[00:22:54.840 --> 00:22:59.640]   using a chat app for some of this stuff. Like, I just, it's not the first thing that occurs to me,
[00:22:59.640 --> 00:23:03.800]   but maybe that's just because I haven't used a chat app for this sort of stuff very much yet.
[00:23:03.800 --> 00:23:10.440]   Maybe it'll make sense as I use it more, why I would choose Alo to, you know, do these searches.
[00:23:10.440 --> 00:23:16.440]   Oh, this is cool. What's up? Sorry. As someone who travels a lot, I asked it,
[00:23:16.440 --> 00:23:24.440]   I need a hotel in Seattle. And one of the options was under $100 USD. So I gave me some hotels
[00:23:24.440 --> 00:23:31.240]   and some options and I clicked the $100, and it just came up with a bunch of things for me.
[00:23:31.240 --> 00:23:41.960]   Like the Motel 6. Excellent. Book it. Done. I can't actually book it. Let's see, Motel 6.
[00:23:45.160 --> 00:23:47.960]   Yeah. I thought you're better than that, Stacy. Well, I'll let you because it wants you to stay
[00:23:47.960 --> 00:23:52.600]   at a nicer place. I'm not, I wasn't actually going to stay at the top six. You're right.
[00:23:52.600 --> 00:23:55.480]   It's sending me to register. But it wants you to stay in the four seasons.
[00:23:55.480 --> 00:24:01.160]   The first option was the Fairmont in Seattle. So, oh, okay. All right. That's better, Stacy.
[00:24:01.160 --> 00:24:05.640]   Was that I went to Jeff. I don't know. You guys know Jeff Palmer? You must know Jeff Palmer,
[00:24:05.640 --> 00:24:10.360]   Stacy. No, I know. Jeff's a wonderful guy. I said yesterday, I spoke, he has a new conference
[00:24:10.360 --> 00:24:15.640]   called, I don't know what the hell it pronounce, it's Mo-NAGE, M-O-N-A-G-E about messaging.
[00:24:15.640 --> 00:24:21.720]   And he put together a wonderful group of people. I was the first speaker yesterday there.
[00:24:21.720 --> 00:24:28.360]   As I said there, Jeff is everybody's cousin. We all love Jeff. But it was a conference about
[00:24:28.360 --> 00:24:32.440]   messaging which included bots. There were some brilliant bot people there. And it is really
[00:24:32.440 --> 00:24:39.320]   just the beginning of this world. In terms of being able to use natural language processing
[00:24:39.320 --> 00:24:44.200]   and AI to guess what you need and be able to bring the stuff back. I do think that the,
[00:24:44.200 --> 00:24:52.440]   is Google behind Siri and behind Amazon? Yes. But I still think it has such capability that if it
[00:24:52.440 --> 00:24:58.440]   can hold onto this, when I not pull a wave on it and kill it, though I was wrong about wave,
[00:24:58.440 --> 00:25:01.960]   I was wrong about all that stuff, it went on the wayside. But you'd think that they have the
[00:25:02.760 --> 00:25:10.600]   wherewithal to make this new and different. Google has a packaging problem. They know what,
[00:25:10.600 --> 00:25:17.240]   it's cool. But, and they did actually, they just this week bought an AI-compared natural
[00:25:17.240 --> 00:25:24.520]   language processing company. So the API.ai startup. So maybe we'll get there.
[00:25:24.520 --> 00:25:29.800]   That's right. Tools for speech recognition and natural language comprehension.
[00:25:30.680 --> 00:25:35.800]   Basically what that's all about. Better voice recognition, better understanding of commands.
[00:25:35.800 --> 00:25:39.880]   You can see this completely tie in with what we're talking about with the system potentially.
[00:25:39.880 --> 00:25:45.240]   And I mean, I should also add like a system is kind of, is the new, you know, it's like Google
[00:25:45.240 --> 00:25:50.520]   now 2.0 essentially or probably even further than 2.0 at this point. There, you know, suddenly
[00:25:50.520 --> 00:25:54.840]   mentions of Google now and the Google app are disappearing. I think there's a single mention
[00:25:54.840 --> 00:25:59.800]   where there used to be a number of different mentions in there. Now on tap is now named
[00:25:59.800 --> 00:26:05.960]   screen search within that app. Now cars are renamed to feed. So they're preparing this transition
[00:26:05.960 --> 00:26:12.600]   from Google now, which we are very used to using for being our, you know, somewhat assistant to
[00:26:12.600 --> 00:26:19.400]   assistant being our total voice assistant comparable to something like Siri or whatever.
[00:26:19.400 --> 00:26:23.080]   As far as what you were talking about Jeff. So that transition is happening, it seems like.
[00:26:23.640 --> 00:26:32.120]   What's the, what's the, what's the voice prompt? It's still, it's still okay. Okay, Google.
[00:26:32.120 --> 00:26:35.720]   I would guess. Sorry. Okay. Now we know we just saw the whole world.
[00:26:35.720 --> 00:26:41.160]   As Casey didn't do it, I did it because we both did it back to back. So apologies to everyone.
[00:26:41.160 --> 00:26:47.240]   But hey, it still works. But when when I apologized, I got the sorry song from Justin Bieber.
[00:26:49.880 --> 00:26:57.080]   Google really does know what we want. Yes. So I finally today got the seven dot
[00:26:57.080 --> 00:27:02.680]   download, the new get download for my Nexus six. Excellent. I'm putting it on right now.
[00:27:02.680 --> 00:27:07.400]   How's it treat? Let me know next week how it treats your battery because mine has been.
[00:27:07.400 --> 00:27:16.040]   Oh no. Has yours been bad? Okay. I because I test a lot of things, my phone is not as consistent.
[00:27:16.040 --> 00:27:21.640]   But I feel like the battery has been draining faster. So I feel like I'm getting about an hour
[00:27:21.640 --> 00:27:27.160]   less battery usage. You're not alone. There are definitely people that are complaining about that.
[00:27:27.160 --> 00:27:32.840]   I've, I have not noticed that on mine, which I'm really surprised about because usually that
[00:27:32.840 --> 00:27:38.200]   stuff hits me for the same reason it does for you. I install so many apps and uninstall so many
[00:27:38.200 --> 00:27:42.520]   apps and make so many changes to my settings because of the shows that we do around here.
[00:27:42.520 --> 00:27:47.400]   Like I'm always monkeyin with my phone. So I always expect it to be the, you know,
[00:27:47.400 --> 00:27:50.760]   the worst of the worst when it comes to stuff like that. But I've not really noticed much
[00:27:50.760 --> 00:27:56.040]   battery difference. So I don't know. But definitely you're not alone. There are a lot of people
[00:27:56.040 --> 00:28:02.440]   complaining about that. In someone in our chat, actually put a link to the story about boot loops
[00:28:02.440 --> 00:28:09.720]   on NuGet with 5x owners. And I actually have that issue you guys and what happened? I uninstalled
[00:28:09.720 --> 00:28:17.960]   it and reinstalled it and that didn't help. But then it went away. So I'm not. So what happened?
[00:28:17.960 --> 00:28:24.840]   Magicly fixed. But I will, I will say that I had that same thing and it was really frustrating
[00:28:24.840 --> 00:28:28.440]   because I would pick up my phone and ever it would just be brick or it'd be off. And I'm like,
[00:28:28.440 --> 00:28:37.640]   what, what just happened? So it says that this is a hardware related issue and you should contact
[00:28:37.640 --> 00:28:41.480]   your place of purchase for warranty or repair options. I bought it from Google.
[00:28:41.480 --> 00:28:48.040]   So I suppose I could call them, but it seems to have stopped. So I don't know what to say.
[00:28:48.040 --> 00:28:53.400]   Yeah. I mean, if it's doing it and they're offering a replacement, yeah, I guess if it happens again,
[00:28:53.400 --> 00:28:58.840]   take them up on that because you might as well have a perfect device, not a subpar device.
[00:28:58.840 --> 00:29:03.720]   Although there's no such thing. I was gonna say the 5x there is such thing as perfect 5x because
[00:29:04.760 --> 00:29:12.360]   it's just had issues all around, I think. So that's Aloe. Any final thoughts on Aloe before we move on?
[00:29:12.360 --> 00:29:17.240]   I think I think it's so new. We've had to spend time playing with it and everything, but I don't
[00:29:17.240 --> 00:29:23.800]   know. I like what I see. I just don't know if I'm really thrilled about moving, you know, like my
[00:29:23.800 --> 00:29:28.200]   wife over to it and teaching, you know what I mean? Like moving people into this new thing when
[00:29:28.200 --> 00:29:32.600]   I've already done that a million times. What's the compatibility with SMS? Oh, that's actually
[00:29:32.600 --> 00:29:38.600]   really good point. So, okay, so there is no SMS. You cannot make this your SMS app. So your SMS
[00:29:38.600 --> 00:29:44.840]   has to come into another app, let's say. If you send a message to someone from your contacts list or
[00:29:44.840 --> 00:29:52.440]   a number that is not registered as being a user of Aloe, Google determines this, your Aloe account
[00:29:52.440 --> 00:29:57.000]   is tied to your phone number and you can only, your conversations don't move from device to device.
[00:29:57.000 --> 00:30:01.960]   So if I have a conversation with you, you both on this device and I move to another device,
[00:30:01.960 --> 00:30:04.840]   even though I put in my account, that's not going to follow me over there. So it's all tied to your
[00:30:04.840 --> 00:30:11.000]   number and your device. It's a little confusing. But if I send a message to someone through SMS,
[00:30:11.000 --> 00:30:17.480]   using Aloe, that doesn't have an Aloe account, depending on where they're at and what OS they're
[00:30:17.480 --> 00:30:21.320]   using. If they're on Android and they're in the US, they're going to get this little toast message
[00:30:21.320 --> 00:30:26.760]   in Android and it's going to be the message relayed through Google servers via SMS,
[00:30:27.560 --> 00:30:33.160]   but sent to their phone not in their SMS app, but in this toast message to say,
[00:30:33.160 --> 00:30:38.680]   "Here's the message. Do you want to reply via SMS or do you want to install the app so you can
[00:30:38.680 --> 00:30:42.520]   do it?" It actually kind of looks a little spammy. It looks a little spammy here.
[00:30:42.520 --> 00:30:44.680]   You get that every time or is it a one time choice?
[00:30:44.680 --> 00:30:47.640]   That's a good question. I don't know if it's an every time or one time choice thing.
[00:30:47.640 --> 00:30:52.760]   I know that and then the number that's associated with it is like a shortened
[00:30:53.400 --> 00:30:59.000]   number in the US. I can't remember the reason. I think some FCC requirements
[00:30:59.000 --> 00:31:03.560]   around that aspect of it. But if you're outside of the US in certain places,
[00:31:03.560 --> 00:31:07.240]   you'll get the full phone number, the originating phone number that it was sent from.
[00:31:07.240 --> 00:31:12.120]   This is a little confusing and I don't know how I feel about it, but I understand why they're
[00:31:12.120 --> 00:31:17.720]   doing it because they want to drive adoption of the app. But the whole SMS aspect is a little strange.
[00:31:21.720 --> 00:31:29.560]   That is that. I will take that as a reason to take a break here and move on because we've got even
[00:31:29.560 --> 00:31:35.640]   more crazy news, hardware news for Android here coming up. We'll talk about that in a second. But
[00:31:35.640 --> 00:31:41.720]   before we do, let's take a minute to thank Casper, the sponsor of this episode. I sleep on a Casper
[00:31:41.720 --> 00:31:48.920]   every single night, be it in my actual bedroom or be it in my kid's bedroom. When our kids come
[00:31:48.920 --> 00:31:54.120]   into our bed and kick us out, I end up in their bed and they have a Casper too. So we love Casper's
[00:31:54.120 --> 00:31:58.520]   in our house, Casper's an online retailer, a premium mattress for a fraction of the cost.
[00:31:58.520 --> 00:32:04.040]   Casper's actually changing the way that you buy mattresses. They're revolutionizing this,
[00:32:04.040 --> 00:32:08.680]   the mattress industry, by cutting the cost of dealing with resailors and showrooms and they
[00:32:08.680 --> 00:32:14.920]   pass that savings on directly to you, the consumer. Casper's mattress is obsessively
[00:32:14.920 --> 00:32:19.640]   engineered and it's a fair price. You'll see when you go to the site and check it out for yourself,
[00:32:19.640 --> 00:32:25.640]   Casper combines two technologies. There's a springy latex foam and then also a supportive
[00:32:25.640 --> 00:32:31.640]   memory foam as well. That creates an award-winning sleep surface with just the right sink,
[00:32:31.640 --> 00:32:35.000]   just the right bounce. You're going to fall asleep almost immediately when you lay down on this
[00:32:35.000 --> 00:32:40.600]   thing. The Casper mattress is a 2016 Business Intelligence Group Innovation Award winner.
[00:32:41.320 --> 00:32:45.960]   Casper mattress provides long lasting comfort. This is going to last you a really long time
[00:32:45.960 --> 00:32:52.280]   and support. It's got a breathable design. You don't end up super hot at night. It keeps you cool,
[00:32:52.280 --> 00:32:56.520]   keeps you regulated, your temperature regulated throughout the night so that you're comfortable
[00:32:56.520 --> 00:33:03.640]   throughout. You can buy it easily online. That's a big component of what Casper's doing differently
[00:33:03.640 --> 00:33:08.840]   here. It's completely risk-free. You can try on a Casper mattress in your home basically. Casper
[00:33:08.840 --> 00:33:13.080]   understands the importance of truly trying out a mattress that in all reality, you're going to
[00:33:13.080 --> 00:33:18.520]   spend a third of your life on these things. You better get it right. Casper offers free delivery
[00:33:18.520 --> 00:33:23.320]   and painless returns within a hundred-day period. You don't have to lie down in a show room for
[00:33:23.320 --> 00:33:28.520]   like two minutes and go, "Yep, that's the one." We actually did that in our oldest daughter's room
[00:33:28.520 --> 00:33:33.880]   when we upgraded her to a bed. It's the bed that no one wants to sleep in because it's not as
[00:33:33.880 --> 00:33:40.440]   comfortable as the Casper. Casper offers just a whole lot more. The engineering underneath,
[00:33:40.440 --> 00:33:45.880]   the engineering of the mattress meets that the kind of magical Goldilocks standard of just right,
[00:33:45.880 --> 00:33:51.240]   so it's not too hard, not too soft. Casper mattresses uphold the highest environmental production
[00:33:51.240 --> 00:33:56.440]   standards. They're made in the USA free shipping and returns to the US and Canada.
[00:33:56.440 --> 00:34:01.400]   If you want to drop a pineapple on your Casper mattress like you're seeing in the ad here,
[00:34:01.400 --> 00:34:08.200]   get a Casper mattress today. $500 for a twin or $950 for a king size compared to industry averages.
[00:34:08.200 --> 00:34:13.960]   That's, I think you can agree, that's an outstanding price. You can save an additional $50 towards
[00:34:13.960 --> 00:34:19.240]   a mattress purchase as one of our audience members by going to Casper.com/twig
[00:34:19.240 --> 00:34:27.640]   and entering promo code twig. That's Casper.com/twig. Make sure and enter the promo code twig
[00:34:27.640 --> 00:34:32.120]   terms and conditions apply. Check it out. You're going to sleep really good once you get one of
[00:34:32.120 --> 00:34:39.560]   these bad boys in your home. We thank Casper for their continued support of this week in Google
[00:34:39.560 --> 00:34:46.120]   and the Twit Network. I think the good transition at this point from Aloe and Assistant, especially
[00:34:46.120 --> 00:34:50.760]   because there's going to be some assistant, I have to imagine, some ways at the event. Google
[00:34:51.560 --> 00:34:58.360]   announced officially, we heard off and on through the rumor mill that this was going to happen,
[00:34:58.360 --> 00:35:03.320]   that this date, October 4th, was the date that we were going to get a hardware announcement from
[00:35:03.320 --> 00:35:09.960]   Google. Sure enough, they unveiled their announcement. They have a teaser site. It's made by dot google
[00:35:09.960 --> 00:35:19.080]   dot com. You can go there and see, well, a little teaser. It's like a search box that slowly morphs
[00:35:19.080 --> 00:35:24.360]   into the shape of a phone. That's about all you get. Like a little carousel of pictures through
[00:35:24.360 --> 00:35:29.640]   there, which I mean, we still don't even know if those pictures were taken with the phone or phones
[00:35:29.640 --> 00:35:35.400]   that'll be announced at the event. Is it just phones as far as the rumor mill says? No, so it's
[00:35:35.400 --> 00:35:41.640]   not. So what we're looking at as far as what we've heard and things that we're expecting by the
[00:35:41.640 --> 00:35:50.360]   end of the year. So we've got the pixel phones. So Nexus branding out pixel branding in for their
[00:35:50.360 --> 00:35:58.440]   phones. Those would be the two HTC devices, the pixel and the pixel XL. So a smaller five inch
[00:35:58.440 --> 00:36:02.440]   version and then a larger one. I can't remember the size of the larger one if it's 5.7 inches or
[00:36:02.440 --> 00:36:07.800]   what? Yeah, these are some leaked photos because it's about that time where everybody's, you know,
[00:36:08.920 --> 00:36:14.840]   dripping these out to the press so we can all get excited about them. Made by HTC, which kind of
[00:36:14.840 --> 00:36:20.680]   goes counter to the slogan made by Google, personally, that's how I feel anyways. Yeah.
[00:36:20.680 --> 00:36:25.880]   Brought that up last night in all about Android and I think I was outnumbered in that belief. I
[00:36:25.880 --> 00:36:29.800]   don't know. I feel like it's just a little disingenuous to say this is made by Google when it's when
[00:36:29.800 --> 00:36:34.280]   it's not and none of the other Nexus devices were made by Google. They weren't making that claim
[00:36:34.280 --> 00:36:41.480]   that. Well, the the the the pixel computer and tablet were made by Google, yes. Exactly. And they
[00:36:41.480 --> 00:36:46.920]   they have the Google design stamp on them, you know, they have a very different kind of design
[00:36:46.920 --> 00:36:52.120]   approach. And to me, that looks made by Google. And I just feel like calling these made by Google
[00:36:52.120 --> 00:36:56.920]   when they're not, it just feels a little weird to me. So what else is coming out though? So we got
[00:36:56.920 --> 00:37:04.040]   those potentially, we've got a tablet by Huawei possibly it would be the seven seven P, you know,
[00:37:04.040 --> 00:37:08.200]   because I'm eager for a seven inch to come back. I loved my seven inch loved.
[00:37:08.200 --> 00:37:13.560]   Every Google or a lot of Googlers, I know still carry their old Nexus sevens.
[00:37:13.560 --> 00:37:19.080]   They were they're attached to them. Yeah. Yeah, they're a good solid device. So we might see that.
[00:37:19.080 --> 00:37:24.440]   That's expected by years end based on what we've read. I think it would be really strange for that
[00:37:24.440 --> 00:37:29.160]   to release or, you know, be announced outside of this event. This event seems like it would be the
[00:37:29.160 --> 00:37:33.560]   catch off for all that stuff. Any rumors of a Chromebook pixel? I haven't heard anything about
[00:37:33.560 --> 00:37:37.640]   that. No, that's that's that's depressed. It's based on the don't aren't selling them anymore.
[00:37:37.640 --> 00:37:43.480]   Right. They depress me. Maybe that's a really good secret. Maybe, you know, like we do a lot of
[00:37:43.480 --> 00:37:48.760]   these things ahead of time. That would kind of make sense if Google's got, especially if they're
[00:37:48.760 --> 00:37:55.720]   moving to the pixel branding, you know, for a larger family of devices, you know, and the device
[00:37:55.720 --> 00:38:00.280]   that started at all, the pixel gets an update, you know, the Chromebook pixel gets an update.
[00:38:00.280 --> 00:38:07.160]   I don't know, but that's total speculation. 4k Chromecast, which I guess the 4k Chromecast was
[00:38:07.160 --> 00:38:11.400]   potentially going to be released earlier this year. It missed some sort of a release or
[00:38:11.400 --> 00:38:15.640]   announcement. So that didn't happen. So people are thinking we're probably going to see that here.
[00:38:15.640 --> 00:38:22.120]   And then a big part of Android right now, at least part of NuGet is Daydream, which is the virtual
[00:38:22.120 --> 00:38:29.800]   reality layer, let's say baked into Android OS, as well as the Daydream spec for hardware.
[00:38:29.800 --> 00:38:35.880]   So there are rumors that are saying a Daydream view, be called the Daydream view headset might
[00:38:35.880 --> 00:38:40.600]   be showing off. I think it's very likely we're going to hear something about a VR and maybe some
[00:38:40.600 --> 00:38:46.760]   sort of hardware shown off for VR because these phones I have to imagine are built with Daydream
[00:38:46.760 --> 00:38:52.520]   in mind, especially the fact that Daydream is a component of NuGet. So I mean, you have to like,
[00:38:52.520 --> 00:38:58.600]   here's what we're talking about in IO. Here it is. I don't know any of that stuff excite you.
[00:38:58.600 --> 00:39:07.160]   Stacy, what do you think? No, because I'm not a huge tablet or I use a MacBook instead of
[00:39:07.160 --> 00:39:15.240]   I'm sorry. Don't be sorry. Or a Chromebook. And so none of that's super exciting. I am waiting
[00:39:15.240 --> 00:39:21.240]   for the Google Home stuff before K Chromecast. I'm like, yeah. Yeah, Google Home. That's the
[00:39:21.240 --> 00:39:25.400]   other part that I actually missed. And that's actually a really exciting one too, because it's got the
[00:39:26.200 --> 00:39:30.600]   got the assistant. Can we take that coming out on our form? Yeah, we do. We think they're going to
[00:39:30.600 --> 00:39:36.200]   give us a lot more detail about that. Yeah. And so Kevin Tofel and I talk about this a little bit
[00:39:36.200 --> 00:39:42.600]   and I'd love to get Elle's opinion. I love it. I love it. I'm in the dark Texan. Sorry. It's
[00:39:42.600 --> 00:39:47.800]   more efficient. So you've got Google Home and you're going to be talking to it. And I'm going to
[00:39:47.800 --> 00:39:55.080]   say it again, you guys. Should Google name their assistant? So Google's its named assistant assistant,
[00:39:55.080 --> 00:40:03.000]   but should I have a person's name? Yeah. Because I feel like you put yes, like Stacy, that would be,
[00:40:03.000 --> 00:40:07.880]   I would hate them if they did that. So we can do that. Jarvis. My way to hate them too,
[00:40:07.880 --> 00:40:14.520]   because their name is Stacy. Yes, like Jarvis. So yes, you do that. But I'm just thinking, you
[00:40:14.520 --> 00:40:19.800]   know, wouldn't that be a little bit more fun in the home, make it a little bit more like Alexa
[00:40:19.800 --> 00:40:26.920]   has a seat at our table, basically. When we talk at the dinner table, it's time to settle an
[00:40:26.920 --> 00:40:31.320]   argument or ask something. We actually try her first. Sometimes she doesn't get it and then we
[00:40:31.320 --> 00:40:38.680]   move to Siri. And only then will we actually talk to Google because I don't know. It's just not.
[00:40:38.680 --> 00:40:44.680]   She doesn't blog at the dinner table. It doesn't. See, Google's still in it to me, whereas all
[00:40:44.680 --> 00:40:49.080]   the others are she's. Well, I mean, is the difference? Well, I guess Siri would be this way. I was
[00:40:49.080 --> 00:40:54.440]   thinking is the difference, the fact that it's an appliance versus a device. Like, I always feel
[00:40:54.440 --> 00:40:59.480]   weird pulling out my phone, let's say at the dinner table, at home anyways. And when I'm out,
[00:40:59.480 --> 00:41:04.680]   like, friends, maybe not as weird, just yelling to the air. I don't know. Like, if it's an appliance,
[00:41:04.680 --> 00:41:10.200]   then it's there. It's not like you're going out of your way to tell everyone, all right,
[00:41:10.200 --> 00:41:14.840]   wait a second. Let me pull it up this wall between us and ask this thing a question.
[00:41:14.840 --> 00:41:18.840]   You all have equal opportunity to just kind of throw it out there and use it because it's
[00:41:19.000 --> 00:41:26.120]   always there working. You know, I'm fascinated as we negotiate our new norms in society around
[00:41:26.120 --> 00:41:30.120]   all this. I really am. Yeah. It fascinates me that to you, the idea of playing with the phone,
[00:41:30.120 --> 00:41:38.600]   let me just ask Google is somehow more in play than, Hey, Google, when was FDR born?
[00:41:38.600 --> 00:41:46.440]   I think we've developed a way to like manage this, which is, okay, I'll bet you have.
[00:41:47.320 --> 00:41:51.080]   We're arguing over something. Oh, I think it's this or I think it's that. And we're like, all right,
[00:41:51.080 --> 00:42:01.640]   all right, let's let Alexa decide. Hey, Alexa, so we've, I mean, it's very much a negotiated thing.
[00:42:01.640 --> 00:42:06.040]   I mean, like socially, we bring her in as a poet. And it's, there's a moment for people to be like,
[00:42:06.040 --> 00:42:11.960]   no, no, let's not be in the vice at this. No, you can't invite Alexa again. Man, dinner is just
[00:42:11.960 --> 00:42:14.120]   never the same. Once Alexa's every dinner.
[00:42:14.920 --> 00:42:18.360]   She's such a know it all. You can't, you can't, okay, that's interesting. You can't just blurt
[00:42:18.360 --> 00:42:21.960]   out in the middle of nothing. When you have a curiosity or you're asking somebody, you just turn
[00:42:21.960 --> 00:42:26.360]   and say, Oh, Jan, I don't know. What was that? Hey, Alexa, what was that? You can't do that.
[00:42:26.360 --> 00:42:31.240]   Yeah, I mean, you could in that situation, but we've got, we've got my daughter, my husband,
[00:42:31.240 --> 00:42:37.880]   and I, and we're usually like in a conversation. So, and I would like to bring up because people
[00:42:37.880 --> 00:42:44.680]   are talking about being able to give your own name to these things. And that's actually a really
[00:42:44.680 --> 00:42:51.800]   difficult problem for the hardware and the computer scientist working on voice recognition. So,
[00:42:51.800 --> 00:42:58.520]   it's worth noting that deciding what to call one of these devices, because it's, or deciding on the
[00:42:58.520 --> 00:43:05.480]   wake world, wake word for one of these devices is actually difficult because they have to
[00:43:05.480 --> 00:43:09.720]   understand it. They have to make sure the false positives are kept to a minimum and that
[00:43:10.680 --> 00:43:16.360]   it responds whenever you say something. So, it's got to be well-trained into the computer in a
[00:43:16.360 --> 00:43:22.360]   bunch of different ways, accents, and you throw it in in the middle of a lot of different inputs,
[00:43:22.360 --> 00:43:29.240]   because you don't always get this pure play. Alexa, sometimes it's like across the room or,
[00:43:29.240 --> 00:43:36.680]   hey, this or whatnot. Yeah, I mean, the average person would not put any thought into, Oh,
[00:43:36.680 --> 00:43:42.040]   I'm going to give it this name. And the fact that that name actually sounds very close to this other
[00:43:42.040 --> 00:43:48.360]   phrase or two or three syllables that you say all the time in conversation. So, that wake word is
[00:43:48.360 --> 00:43:55.080]   just constantly the the AI is just thinking that it's being woken up when it's in fact not.
[00:43:55.080 --> 00:43:59.480]   No, no normal person would think about that. They just go, I really like the name bud.
[00:44:00.040 --> 00:44:06.280]   So I'm going to do that. And that sounds a lot like a lot of other words. So, right. Yeah, like,
[00:44:06.280 --> 00:44:10.360]   but like but I wasn't going to say it. But there you go. Every time you say but,
[00:44:10.360 --> 00:44:17.880]   no, I don't mean but like that. I mean, but on the other hand, both, both, both kinds of goes how
[00:44:17.880 --> 00:44:22.280]   immediately both both kinds of butts. That's all I'm saying. There are lots of different ways
[00:44:22.280 --> 00:44:27.160]   that work. That's a probably a big thing in this house. It's you know what else it's a constant
[00:44:27.160 --> 00:44:30.840]   struggle. The six year old is going to come in and sabotage it and name it fart.
[00:44:30.840 --> 00:44:36.040]   I would laugh at that when I yeah, you would every time because we're
[00:44:36.040 --> 00:44:38.280]   hard. That's an hour's turn thing. That's why farts are funny.
[00:44:38.280 --> 00:44:42.600]   Yeah, I'm just trying to hope you can pass this.
[00:44:42.600 --> 00:44:49.560]   No, no, I'm like I would giggle. I there used to be a Cardinals player named Albert Puhles and I
[00:44:49.560 --> 00:44:54.200]   would giggle literally every time he came up to bat because I never thought of it like that.
[00:44:54.200 --> 00:45:00.280]   Because I'm six inside. I've heard his name a million times. I've never thought of it like that.
[00:45:00.280 --> 00:45:05.000]   I ruined it, but he didn't know. I'm sorry. That's okay. That's okay.
[00:45:05.000 --> 00:45:10.040]   The past tense up to drive in German is fart and every German student in the earth just giggles
[00:45:10.040 --> 00:45:17.000]   every single time it's said America. Oh man, I'm sorry that when I come on this show, it devolves to
[00:45:17.000 --> 00:45:21.480]   conversation. So I'm pretty much through that. Okay, good. All right, good. Not alone.
[00:45:22.680 --> 00:45:27.320]   I don't know. I'm looking forward to it. There was a there on the same day as the announcement
[00:45:27.320 --> 00:45:33.480]   of the hardware. Google started this big advertising blitz and it's kind of ongoing, right? There was
[00:45:33.480 --> 00:45:40.440]   an ad run on the Big Bang Theory. There was a leak of the phone. I don't know if it's a leak or if
[00:45:40.440 --> 00:45:47.880]   it's intentional or what, but a nest ad that was ran in the Netherlands had a front and back shot
[00:45:47.880 --> 00:45:54.280]   of a device that matches up with the leaks of the pixel phone. So I don't know if that was a
[00:45:54.280 --> 00:45:57.880]   premature ad or if that was meant to come out after the actual announcement.
[00:45:57.880 --> 00:46:02.040]   Does anybody look different about this phone? Really? It looks pretty close.
[00:46:02.040 --> 00:46:07.720]   I didn't scrutinize it, but is there a headshot? Is there anything that knew about this?
[00:46:07.720 --> 00:46:12.280]   The hardware? Oh, you mean just in general, what sets the hardware apart from?
[00:46:13.160 --> 00:46:19.080]   No, I mean, I don't know. Looks like it has only one camera in the back, right? Not two.
[00:46:19.080 --> 00:46:21.960]   Yeah, one camera. No, the pair will like spew stuff.
[00:46:21.960 --> 00:46:29.960]   Yeah. I don't know. It doesn't really look very, very different to me, but it doesn't have a
[00:46:29.960 --> 00:46:35.960]   periscope like the 6P did in the leaks. So I don't know what to expect.
[00:46:35.960 --> 00:46:43.080]   But I know. But they did say, didn't someone say that it was going to cost $649 premium prices?
[00:46:43.080 --> 00:46:44.120]   These devices, yes.
[00:46:44.120 --> 00:46:45.960]   Small one, right?
[00:46:45.960 --> 00:46:47.960]   The small one. There it is.
[00:46:47.960 --> 00:46:53.880]   Yeah. So this is obviously leaked information. So that could be that could change.
[00:46:53.880 --> 00:47:03.320]   But I mean, that puts it squarely in the Samsung Galaxy S7 range of cost for these things.
[00:47:03.320 --> 00:47:04.520]   You know, I'm pretty much.
[00:47:04.520 --> 00:47:09.240]   Unlike Leo, I don't have an expensive account. I pretty much buy every new one that comes out.
[00:47:10.680 --> 00:47:15.640]   My 6P is still a good phone. This is maybe the one time I don't know. I made a skip.
[00:47:15.640 --> 00:47:22.280]   Because I also, if they do come out with a new Chromebook Pixel, I need to save my bucks for that.
[00:47:22.280 --> 00:47:32.280]   Yeah. And if they don't, I'm going to cry. Okay. I'm just going to break down and cry right
[00:47:32.280 --> 00:47:37.080]   here in front of you all. It's going to be very sad. You could get the seven inch tablet.
[00:47:38.280 --> 00:47:45.800]   No, then no. No, actually, I am using my Pixel C. I mean, sorry, my, yeah, Pixel C.
[00:47:45.800 --> 00:47:49.800]   I get all these. I'm getting all confused. Yeah. I use that a lot. Is that a lot?
[00:47:49.800 --> 00:47:55.240]   I will be excited that the when they, they combine all the brands together.
[00:47:55.240 --> 00:48:02.360]   Because I'm like pixels, Chromebooks, next, I, Nexus is. Well, speaking of combining things,
[00:48:02.360 --> 00:48:08.600]   and I like accounts. So the new travel app is wrong, right? Google travel thing.
[00:48:08.600 --> 00:48:14.760]   Uh huh. Yeah. Oh, yeah. Yeah. Yeah. Of course, Jeff installs it. And guess what happens?
[00:48:14.760 --> 00:48:21.560]   Oh, the account administrator won't work. We'll do this. We'll do that. I don't want.
[00:48:21.560 --> 00:48:24.680]   That's a lesson that that will apparently never be learned.
[00:48:24.680 --> 00:48:29.080]   Apparently, because every single product that happens, that they release.
[00:48:29.080 --> 00:48:37.240]   Humans. Well, that's a bummer. It's a good app. I'll, uh, I'll talk about it a little later.
[00:48:37.240 --> 00:48:41.640]   Okay. Oh, sorry about that. Okay. God. We're ruining your picks here.
[00:48:41.640 --> 00:48:47.880]   No, this is, no, this is, this is effective. This is a point. This is a tease forward.
[00:48:47.880 --> 00:48:55.320]   Or shadowing. Or shadowing into the future. Um, let's see here. What else we've got?
[00:48:55.320 --> 00:48:59.720]   Well, we've got the ongoing saga of Samsung. I just want to talk about that a little bit.
[00:48:59.720 --> 00:49:04.840]   No, I feel bad for Samsung. I do too. They finally got their act together. They made it,
[00:49:04.840 --> 00:49:09.000]   you know, a decent phone. They got everything going and then they're blowing up the world.
[00:49:09.000 --> 00:49:14.920]   I really do feel bad for them. Yeah, I do too, Jeff. Because I mean,
[00:49:14.920 --> 00:49:21.000]   by all accounts, everything was going well, leading up to the note seven, right? The,
[00:49:21.000 --> 00:49:27.000]   the Galaxy S seven, S seven edge was selling like crazy. Sales were just starting to slow down a
[00:49:27.000 --> 00:49:32.040]   little bit. So it made sense as Samsung usually does this time of year to release the note seven
[00:49:32.040 --> 00:49:37.800]   to kind of bring that bump, that bump back up lead into the holiday season. Be strong throughout,
[00:49:37.800 --> 00:49:44.040]   compete with Apple, all that sort of stuff. And of course, uh, what news is coming out right now.
[00:49:44.040 --> 00:49:50.520]   I think Bloomberg has had a story that said that, uh, the reason for the battery mishap,
[00:49:50.520 --> 00:49:57.160]   if you want to call it that is that Samsung was so focused on beating Apple to market,
[00:49:57.160 --> 00:50:03.080]   based on an iPhone that they thought that they had heard, uh, that was a weak, uh, iteration of
[00:50:03.080 --> 00:50:09.480]   the iPhone. And so, you know, they placed even more pressure on suppliers and manufacturers to kind
[00:50:09.480 --> 00:50:15.880]   of speed things up and in doing so missed some critical errors. Uh, so is the, is the, is the,
[00:50:15.880 --> 00:50:21.080]   is the note seven brand dead? Does it come back? Do you get replaced with a new note seven? What's,
[00:50:21.080 --> 00:50:26.360]   what's the deal? Well, so they have the official recall today was the, uh, the day that Samsung,
[00:50:26.360 --> 00:50:31.400]   uh, said they would make sure that 500,000 replacement note sevens would be available for
[00:50:31.400 --> 00:50:35.800]   exchange. So you go to retail stores where you bought your device, you can now go there and,
[00:50:35.800 --> 00:50:40.600]   and get that note, um, exchange with another one. They, you know, they also have other plans that,
[00:50:40.600 --> 00:50:45.720]   that you can do. You can get a refund entirely, uh, and not get a note seven or you could, you know,
[00:50:45.720 --> 00:50:51.240]   get the difference refunded to you, I think, uh, for getting like an S seven or an S seven edge.
[00:50:51.240 --> 00:50:56.520]   So they should have stock of note sevens now. Apparently. Oh, oh, oh, they're, they're safe. Okay.
[00:50:56.520 --> 00:51:03.080]   Yes. And those would be seen as, and is it sure that we know which ones are dangerous?
[00:51:03.080 --> 00:51:09.880]   Cause that's an important thing to know. Uh, so Samsung is basically putting a green battery
[00:51:09.880 --> 00:51:16.600]   indicator on devices that are safe. Uh, and this is, this is kind of interesting because it goes
[00:51:16.600 --> 00:51:22.600]   against, um, Google spec for Android, but Hiroshi Lockheimer actually said on Twitter, like they
[00:51:22.600 --> 00:51:28.120]   made a big, they made an exception and worked with Samsung to come up with an alternative on this
[00:51:28.120 --> 00:51:34.920]   because the, because the scenario is just so, you know, important. But I, so I've flown four times
[00:51:34.920 --> 00:51:41.400]   since this happened and then boy, boy, they announced on every flight. Wow. They do use it.
[00:51:41.400 --> 00:51:48.680]   So what happens now is, oh, no, no, everybody's okay. Oh yeah, sure. Don't you turn that on. Um,
[00:51:48.680 --> 00:51:55.880]   you know, that's going to be really interesting. Yeah. How do you undo the damage that, that's
[00:51:55.880 --> 00:52:00.440]   caused for people who own it and a lot of people, there was, there was something in the, I want
[00:52:00.440 --> 00:52:07.960]   to say it was in USA today about not a lot of people are opting for Android or for
[00:52:07.960 --> 00:52:15.400]   Note sevens, they're opting for other phones like the iPhone. Oh, there it is. So just 25%
[00:52:15.400 --> 00:52:21.400]   Note sevens. Uh, Samsung says only 25% has been exchanged so far. Uh, regardless of the
[00:52:21.400 --> 00:52:26.040]   availability of replacement device. Yeah, she's going to change hers, but she was holding on to
[00:52:26.040 --> 00:52:33.480]   hers until she's like, it's not going to explode. It's Stacy. So take, she's, she's ready to
[00:52:33.480 --> 00:52:39.000]   shoulder that risk. She feels like a hard business mom. Yes. They're all weak for listening to
[00:52:39.000 --> 00:52:45.480]   recalls. Does she charge it next to her bedside at night? I have not. Yeah, she, yeah, she leaves
[00:52:45.480 --> 00:52:54.280]   it next to like some oily rags. That is not smart Stacy's mom. Don't do that.
[00:52:55.320 --> 00:53:03.400]   Yeah, she's. Yeah, there's also actually a warning from what I understand. Samsung will put up a
[00:53:03.400 --> 00:53:07.080]   warning on your device. I don't know if it's at boot or whatever, but if you have one of the
[00:53:07.080 --> 00:53:12.440]   affected devices when you boot it up, it's like a full screen is like, turn this off, idiot. It
[00:53:12.440 --> 00:53:19.240]   says, don't do this. Take it back. Get their, get their refund or get a new one or whatever. Oh,
[00:53:19.240 --> 00:53:23.400]   man. I thought that's, that's good. Actually. So this is a place where connected devices.
[00:53:24.200 --> 00:53:29.320]   Yeah, have a huge advantage. Because like, I don't know, as a parent, I remember like all the,
[00:53:29.320 --> 00:53:34.920]   like we bought a crib and later it was recalled. And so now that crib, like what happens to it,
[00:53:34.920 --> 00:53:39.560]   we did not like donated to goodwill or anything like that and have someone else have the issue.
[00:53:39.560 --> 00:53:46.600]   But you know, there's lots of my biophone on eBay or in this case. That's that's, that's, that's,
[00:53:46.600 --> 00:53:52.280]   Ms. IOT. That's really an interesting point. If, if devices are going to be connected moving forward,
[00:53:53.080 --> 00:53:59.160]   should like consumer products, safety commission put in a requirement for a kind of red light
[00:53:59.160 --> 00:54:07.720]   recall notice on the device. If the manufacturer could send a recall notice for any unsafe device,
[00:54:07.720 --> 00:54:14.280]   that'd be amazing. It there's the ability to do that. There's also the ability to track it.
[00:54:14.280 --> 00:54:19.960]   So like the database that tracks this stuff could be a lot more accurate. So they could actually
[00:54:19.960 --> 00:54:24.760]   see where these devices are when they. That's going to freak me off knocking on your door.
[00:54:24.760 --> 00:54:30.760]   Hello, it's the crib police. We understand you have a recalled crib in this house.
[00:54:30.760 --> 00:54:37.000]   What else do they know about me? Well, I mean, but I mean, you have to know that if you've got
[00:54:37.000 --> 00:54:42.440]   a connected device, you know that is like, like not that I would cheat on a review, but I'm highly
[00:54:42.440 --> 00:54:49.880]   aware when I'm testing a device that is connected that everything I'm seeing, the company is also
[00:54:49.880 --> 00:54:56.360]   seeing. So if I if I write about it, I have thought of that. I mean, it's again, I'm,
[00:54:56.360 --> 00:55:03.240]   you know, testing everything. So it doesn't bother me, but it is. It's like a seven seven
[00:55:03.240 --> 00:55:08.680]   I think when I was a TV critic, I I did have a very strict rule. I would not fast forward
[00:55:08.680 --> 00:55:14.440]   between. I mean, this was hell when they had 14 hour mini series like AD, but it also meant
[00:55:14.440 --> 00:55:18.040]   that I didn't rewind the tapes to that I said it back. So you can make sure I watch this piece of
[00:55:18.040 --> 00:55:25.960]   crap. I like that you had actual tapes. I know that's Stacy recorder inch tapes,
[00:55:25.960 --> 00:55:35.960]   one hour maximum each. So AD arrived with 14 fiction bit Bible sized containers to get the
[00:55:35.960 --> 00:55:44.120]   mini house. Wow. Wow. Yeah, that's rough old school, hard work. And you made sure to watch all the
[00:55:44.120 --> 00:55:48.600]   commercials. No, no, the real commercials in it was you got your rough cuts and things.
[00:55:48.600 --> 00:55:52.680]   So then what were you not fast forwarding through? I guess I missed that part.
[00:55:52.680 --> 00:55:59.000]   They would send me a tape before it was on the air. Oh, I see. Okay. So it was a preview. Yeah.
[00:55:59.000 --> 00:56:06.520]   The old the old days, son. Back in those days. Good morning. Oh, yeah. Well, I had a laser
[00:56:06.520 --> 00:56:10.280]   disc player and halfway through a movie, I had to wait because they had to flip over to the other
[00:56:10.280 --> 00:56:15.000]   side. So there is bad in my day. Uncle Jason. Yes.
[00:56:15.000 --> 00:56:22.600]   Yeah, I feel bad for Samsung. I think they're doing, you know, and I think that the kind of,
[00:56:22.600 --> 00:56:28.040]   the tricky part is that they really wanted to do things quickly and swiftly because they had
[00:56:28.040 --> 00:56:33.800]   researched how, you know, effective product recalls are done. And usually it involves the company
[00:56:33.800 --> 00:56:38.520]   responding very quickly. The unfortunate thing is they missed the fact that they needed to
[00:56:38.520 --> 00:56:43.880]   make sure that they coordinated this with the proper, proper organizations and they did not do that.
[00:56:43.880 --> 00:56:47.320]   And in doing so, it ended up making everything a lot more confusing.
[00:56:47.320 --> 00:56:52.200]   Oh, I see that's that's so yeah, what are because they seem to be acting on their own
[00:56:52.200 --> 00:56:56.280]   say, no problem. But then the government issued an official recall. That's why.
[00:56:56.280 --> 00:57:01.080]   Yep. That's exactly why. I see the US Consumer Product Safety Commission. Basically,
[00:57:01.080 --> 00:57:04.840]   yeah, there was there was a longer delay because they essentially had to analyze and
[00:57:04.840 --> 00:57:09.800]   undo to a certain degree what Samsung had already the wheels that they'd already put in emotion
[00:57:09.800 --> 00:57:16.520]   because they have to then come in and literally be the ones to clear whatever the solution is,
[00:57:16.520 --> 00:57:21.000]   you know, those devices that are being sent out. Are those good replacement devices? Is replacing
[00:57:21.000 --> 00:57:26.520]   a device a good alternative? Is that sufficient enough for consumers or, you know, do we need to
[00:57:26.520 --> 00:57:30.920]   do something different? Samsung had already made a lot of those determinations prior to letting them
[00:57:30.920 --> 00:57:37.160]   know that anything had happened. And so that's why it took longer. So they really wanted to do
[00:57:37.160 --> 00:57:41.960]   good on their customers, I think. Yeah. Yeah. We will. I guess, washing the product through
[00:57:41.960 --> 00:57:48.840]   it away. It's unsafe. Yeah, that's not a good thing either, right? But you know, I guess the
[00:57:48.840 --> 00:57:55.400]   quite the big question is in doing so, did they know? And I'm guessing no, but I guess I don't know
[00:57:55.400 --> 00:57:59.160]   how it works behind the scenes, but did they know that there was a potential that there was a
[00:57:59.160 --> 00:58:02.760]   possibility? I can't believe they did. I can't. No, they would not. I mean, they're having to
[00:58:02.760 --> 00:58:08.440]   sell off assets to pay for this recall. That is, I mean, if they knew that would be like,
[00:58:08.440 --> 00:58:14.360]   yeah, they were what did Samsung just bought? Sorry, just sold. No, they did. You're right. I
[00:58:14.360 --> 00:58:22.680]   read that yesterday briefly. They sold it off of different assets. Yeah. Yeah. I'll give them
[00:58:22.680 --> 00:58:28.520]   the benefit of the doubt on that one for sure. You know, I guess I've just seen Fight Club one
[00:58:28.520 --> 00:58:35.800]   too many times where you realize there's like, there's the level of like calculated risk.
[00:58:35.800 --> 00:58:39.880]   And it's like, well, does this outweigh that? If so, then it's worth taking the risk.
[00:58:39.880 --> 00:58:43.720]   I guess you never know, but they probably knew. I didn't know enough to prevent it.
[00:58:43.720 --> 00:58:52.920]   Oh, so Samsung sold its shares in Seagate, Rambus and Sharp. Oh, and also ASML, which is a
[00:58:52.920 --> 00:59:01.480]   semiconductor manufacturing company. So, I mean, I don't know if all of those things went towards
[00:59:01.480 --> 00:59:07.080]   paying for the recall, but they did blame it on that, which is a pretty significant step.
[00:59:07.080 --> 00:59:13.640]   Yeah, for sure. Indeed. Let's take a quick break and thank another sponsor of this episode of
[00:59:13.640 --> 00:59:20.760]   This Week in Google. And that is Wealthfront. You invest for the long term for your family's
[00:59:20.760 --> 00:59:25.960]   financial health, for your own financial health, but doing that, I mean, it's not the easiest thing
[00:59:25.960 --> 00:59:29.160]   in the world. In fact, it can be very difficult, especially if you're trying to do it the right way.
[00:59:29.160 --> 00:59:35.240]   There's so many moving parts. It's complex. It's time consuming. That's where Wealthfront comes in.
[00:59:35.240 --> 00:59:41.080]   Traditional advisors charge huge fees between one to 3% of what they manage. With Wealthfront,
[00:59:41.080 --> 00:59:47.640]   you pay one quarter of 1% a year. That's 25 basis points, zero commissions, no hidden fees,
[00:59:47.640 --> 00:59:54.200]   which comes out to around $5, well, less than $5 a month to invest a $30,000 account. There are
[00:59:54.200 --> 00:59:59.240]   no additional charges for any of Wealthfront's services. With Wealthfront's new portfolio review,
[00:59:59.240 --> 01:00:03.320]   you can actually see if your portfolio is at risk, how diversified your investments are,
[01:00:03.320 --> 01:00:09.080]   what you're losing to fees. You can even minimize your taxes. And you can get started investing
[01:00:09.080 --> 01:00:15.800]   today. This is a little as $500 to kick it off. It only takes a few minutes to sign up. And
[01:00:15.800 --> 01:00:19.720]   once you do, it goes right to work. It starts monitoring your portfolios around the clock,
[01:00:19.720 --> 01:00:26.440]   takes action as soon as an opportunity arises. Wealthfront is transparent. It's accessible.
[01:00:26.440 --> 01:00:31.560]   You can view and track all your accounts in one single place. Wealthfront can also track
[01:00:31.560 --> 01:00:35.800]   both your Wealthfront and your non- Wealthfront bank and brokerage accounts. And they're going
[01:00:35.800 --> 01:00:40.840]   to provide all of that in a summary of all your assets too. You can also see every trade that
[01:00:40.840 --> 01:00:46.360]   Wealthfront makes on your behalf, on your Dashboard, on your desktop, or with their mobile app.
[01:00:46.360 --> 01:00:51.560]   Wealthfront's process is based on Nobel Prize winning academic research. It's the best
[01:00:51.560 --> 01:00:56.200]   investment practices are employed here. We've heard from many Twit fans who've used Wealthfront.
[01:00:56.200 --> 01:01:01.640]   And they write in because they love how they can diversify their portfolios. They're buying
[01:01:01.640 --> 01:01:05.480]   stocks from in-demand companies, companies that we're talking about all the time on this show,
[01:01:06.200 --> 01:01:10.920]   and all the shows that we do. Apple, Amazon, Facebook, Google, all commission-free. Wealthfront
[01:01:10.920 --> 01:01:16.280]   recently introduced their 529 college savings plan that allows you to invest after tax dollars,
[01:01:16.280 --> 01:01:23.320]   much like a Roth IRA, and save for your child or your grandchild's higher education expenses.
[01:01:23.320 --> 01:01:28.840]   Wealthfront manages almost $3 billion in plant assets. It's growing rapidly every day. So you've
[01:01:28.840 --> 01:01:33.640]   no reason to wait. Check it out for yourself. Invest in your future today with Wealthfront.
[01:01:33.640 --> 01:01:37.240]   All you have to do is visit www.wealthfront.com/twig.
[01:01:37.240 --> 01:01:42.280]   And you go there, you sign up, you get a free personalized investment portfolio. You're going to see
[01:01:42.280 --> 01:01:47.640]   the customized allocation that they recommend for your profile. And just for Twit listeners,
[01:01:47.640 --> 01:01:55.080]   if you sign up to invest, Wealthfront will manage your first $15,000 entirely free of charge for life.
[01:01:55.080 --> 01:01:59.080]   Join the many Twit fans who've seen huge success with Wealthfront and claim your offer today
[01:01:59.080 --> 01:02:04.040]   at wealthfront.com/twig. That's T-W-I-G.
[01:02:04.040 --> 01:02:10.680]   So this is, let's see here, do we want to talk about trolls or election?
[01:02:10.680 --> 01:02:15.080]   Oh, I want to just talk about the profile. Same difference. Yeah, basically.
[01:02:15.080 --> 01:02:22.440]   What were you saying? I was going to say, I wanted to talk about the profile of Ruth Porret
[01:02:22.440 --> 01:02:27.480]   from Fortune, just because there's a lot of really great information in there about the fate
[01:02:27.480 --> 01:02:29.400]   of Alphabet and that shift.
[01:02:29.400 --> 01:02:32.120]   Okay, go for it.
[01:02:32.120 --> 01:02:34.920]   We need to try to read that one. I'm sorry.
[01:02:34.920 --> 01:02:36.520]   Oh, it's riveting.
[01:02:36.520 --> 01:02:37.560]   Apparently I need to.
[01:02:37.560 --> 01:02:43.160]   Well, it starts off with this, she slips on some ice, she's on her way to spin class,
[01:02:43.160 --> 01:02:47.080]   slips on some black ice and breaks her shoulder. And apparently for two days,
[01:02:47.080 --> 01:02:51.800]   she walks around like postponing surgery so she can make an earnings call it Morgan Stanley.
[01:02:52.760 --> 01:03:01.800]   And that's hardcore. But it's basically, I encourage people to read it because it's a really nice
[01:03:01.800 --> 01:03:09.480]   look at some of the things that are happening inside the other bets, divisions and alphabets that
[01:03:09.480 --> 01:03:17.080]   we've seen some of the Google fiber cutting costs, nests, like Tony Fidelity being all of these
[01:03:17.080 --> 01:03:22.520]   things, just kind of explain some of the back end stuff that's happening. So it's talking about
[01:03:22.920 --> 01:03:26.680]   the other bets businesses being billed for some of the company resources.
[01:03:26.680 --> 01:03:36.120]   So like legal counsel, human resources and PR are now these other bets companies can use
[01:03:36.120 --> 01:03:40.680]   the alphabet services, but alphabets charging them, which is a very corporate kind of old school
[01:03:40.680 --> 01:03:46.040]   corporate thing to do and not very Google like. So I just, I thought this whole thing was kind of
[01:03:46.040 --> 01:03:51.160]   a really interesting look at Google trying to grow up and I wondered if you guys had thoughts on if
[01:03:51.160 --> 01:03:52.360]   this is the right way to do it.
[01:03:52.360 --> 01:03:58.600]   All right, you know, full disclosure is I'm a nano Google shareholder.
[01:03:58.600 --> 01:04:03.640]   If you are a shareholder, would you feel better about the company knowing that she's in this
[01:04:03.640 --> 01:04:04.600]   powerful position?
[01:04:04.600 --> 01:04:14.760]   It depends on what I think Google is. Am I investing in Google for like their incredible
[01:04:14.760 --> 01:04:19.000]   short term profits based on advertising or am I investing in Google for the long term?
[01:04:19.000 --> 01:04:23.240]   Really, really good question. So all right. So which way does she come down in that world?
[01:04:23.240 --> 01:04:34.840]   You could argue that it's both. Because you can't like, I guess then the question is,
[01:04:34.840 --> 01:04:39.400]   is this sort of accountability going to hurt their,
[01:04:39.400 --> 01:04:46.360]   their progress for the long term or is it just kind of shutting down things that are silly?
[01:04:47.240 --> 01:04:53.560]   I think it's probably a smart thing to do to be honest. I think some of the,
[01:04:53.560 --> 01:04:58.680]   some of the things in Silicon Valley where people are like, I'm going to throw a lot of money at
[01:04:58.680 --> 01:05:05.240]   a crazy idea and see if it flies. It sounds good. Some things have come of it, but I don't think a
[01:05:05.240 --> 01:05:12.280]   little discipline is bad. I guess. Yeah, I agree. Yeah, it seems like the promise of these long
[01:05:12.280 --> 01:05:18.040]   shot bets for the, for the longest time anyways, it seemed like we were willing to kind of go
[01:05:18.040 --> 01:05:22.200]   along for the ride with Google and be like, Oh, yeah, if anyone could do it, you know,
[01:05:22.200 --> 01:05:25.640]   just taking Google as an example, Google could do it because they've got more money than,
[01:05:25.640 --> 01:05:30.360]   than they need. And you know, they've got all the resources, but it seems to be turning out,
[01:05:30.360 --> 01:05:36.200]   turning into kind of a realization that even with all that money, it's still incredibly hard to
[01:05:36.200 --> 01:05:40.840]   pull a lot of this stuff off and Google, you know, Google dreams big. That doesn't necessarily
[01:05:40.840 --> 01:05:46.040]   mean that Google can't dream big, but by focusing a little bit, maybe that's a good way to make
[01:05:46.040 --> 01:05:52.280]   sure that some of them happen and our executed as opposed to all of them not or whatever the case
[01:05:52.280 --> 01:05:59.080]   may be. So that's it. I just, I liked the profile. I liked the writing. Yes, I used to work in fortune,
[01:05:59.080 --> 01:06:04.680]   but I just, I was like, that's pretty cool. And you, so we can talk about trolls now.
[01:06:06.600 --> 01:06:10.440]   That sounds, that sounds fun. Jeff, you pick this time, which one you want.
[01:06:10.440 --> 01:06:13.160]   Oh, no, you guys know better. Go ahead.
[01:06:13.160 --> 01:06:20.600]   Well, let's talk about election first here. It really seems like, well, if you didn't know,
[01:06:20.600 --> 01:06:26.840]   there's a big election coming up in the US and technology is very infused this time around. I
[01:06:26.840 --> 01:06:33.560]   feel like in years past, you know, the internet, you played into different facets of the election
[01:06:33.560 --> 01:06:40.440]   in different ways. This seems to be the first US election that I can remember, where social media
[01:06:40.440 --> 01:06:47.080]   is not just this kind of tangential thing on the on the outsides of it, but actually totally tied
[01:06:47.080 --> 01:06:53.160]   into the process to a certain degree case in point, Google, Facebook, they're all basically
[01:06:53.160 --> 01:06:58.920]   getting involved in things like the upcoming debates, they're going to be offering data to
[01:06:58.920 --> 01:07:05.960]   moderators leading up to kind of help plan for these events as could be expected. Facebook is also
[01:07:05.960 --> 01:07:12.520]   going to be helping to source questions during the town hall debates. There's going to be Facebook
[01:07:12.520 --> 01:07:17.160]   live broadcast from the events, Snapchat live stories are happening from the events. They're all
[01:07:17.160 --> 01:07:24.040]   kind of getting involved in these debates, kind of making the town hall just a little bit broader.
[01:07:24.040 --> 01:07:27.480]   I don't know if that actually means that, great, stop wagging.
[01:07:27.480 --> 01:07:30.600]   I don't want to make any political statements. I won't make any political statements. I just
[01:07:30.600 --> 01:07:34.840]   want to be here. Yeah, I'm going to try my best to not make any political statements.
[01:07:34.840 --> 01:07:42.280]   But I don't know. Is this good? I mean, I suppose it makes sense because our world is, you know,
[01:07:42.280 --> 01:07:47.880]   social and technology is such a big part of what we do nowadays. So it makes sense to include those
[01:07:47.880 --> 01:07:53.320]   voices in the process. But we're going to present the United States things. So yes,
[01:07:53.320 --> 01:07:58.920]   she's calling her a headdress. Audio listeners have no idea what you're talking about. That
[01:07:58.920 --> 01:08:01.960]   might be a good thing. Jeff was just making a political statement, sartorial.
[01:08:01.960 --> 01:08:08.840]   Yeah, just ignore this. Yeah. Look the other way. I'll get in such trouble.
[01:08:08.840 --> 01:08:13.880]   We think a good idea. Oh, sorry. You asked a question. Oh, it's all good.
[01:08:13.880 --> 01:08:19.640]   Just back on Stacy. I'm sorry. Were you engaging us in debate? All right. What was
[01:08:20.840 --> 01:08:27.320]   your question? Basically social media. Should we be using it? Well, no, I think is, can social
[01:08:27.320 --> 01:08:34.920]   media be counted upon to take something like an election debate process and keep it, I don't know,
[01:08:34.920 --> 01:08:39.880]   keep it focused? No, no, as much as I love it, as much as it matters.
[01:08:39.880 --> 01:08:46.440]   You know, we have that's why politics and trolls are the same topic. You know, we've reached this
[01:08:46.440 --> 01:08:53.080]   point where I crave civility. I crave some way to get a decent conversation going.
[01:08:53.080 --> 01:09:00.520]   And it's so hard now. And I'm not sure what to do about it. And this election,
[01:09:00.520 --> 01:09:07.320]   how do I say this with like any trouble? Because I am clearly partisan. I mean, the full disclosure,
[01:09:07.320 --> 01:09:10.680]   if you did for those of you on audio, is just so you know, before I go further, I'm not making
[01:09:10.680 --> 01:09:15.800]   it as I'm voting for Hillary Clinton. If you still follow me on Twitter, you know that for sure.
[01:09:15.800 --> 01:09:21.880]   But okay, so that's my perspective, which is important to say. Journalism, you know,
[01:09:21.880 --> 01:09:27.160]   professional journalism has failed miserably. We have an ill informed electorate and it's our
[01:09:27.160 --> 01:09:32.280]   fault. It's our job to inform. We didn't inform. So how do we expect social media to come along
[01:09:32.280 --> 01:09:39.080]   and make up for what professional journalists have done horribly? And you know, the other thing
[01:09:39.080 --> 01:09:44.120]   about this world, is that journalism also has done a terrible job of reflecting certain parts of
[01:09:44.120 --> 01:09:53.720]   America. And you know, including less obviously African Americans and Latinos and women and
[01:09:53.720 --> 01:09:58.920]   other groups are long ill reflected. But so are in this election, we're learning
[01:09:58.920 --> 01:10:06.200]   under employed angry white men because because that's the breeding ground for Trump. And so
[01:10:06.200 --> 01:10:12.600]   media have done a terrible job. And how we expect social media to come along and without any systems
[01:10:12.600 --> 01:10:19.320]   without any structure to fix that, they're not going to happen. Now, what we what we immediately
[01:10:19.320 --> 01:10:23.080]   need to do is to better inform those conversations. What we immediately need to do is to better
[01:10:23.080 --> 01:10:27.640]   reflect those communities and their concerns and give them where to respect. I'm writing a post
[01:10:27.640 --> 01:10:30.520]   right now, I'm actually playing with the idea of saying that if liberals want to fix things in
[01:10:30.520 --> 01:10:34.280]   this country, they should fund the creation of quality conservative media.
[01:10:35.720 --> 01:10:40.200]   So that you do have people were feeling reflected and feeling as if their concerns
[01:10:40.200 --> 01:10:45.320]   are paid attention to. Sorry, ask me a simple question. You're going to get me to go off on
[01:10:45.320 --> 01:10:53.880]   a similar liquid. But I just think that that, you know, we've got to learn some lessons after
[01:10:53.880 --> 01:11:00.200]   this election. And it's a it's a huge problem. And we see the debate after I'm sure you talked
[01:11:00.200 --> 01:11:05.240]   about the the napalm photo on Facebook when I was gone last week. But there are those in my
[01:11:05.240 --> 01:11:09.320]   field who say Facebook is media, it should act like media should have operated our standards.
[01:11:09.320 --> 01:11:13.080]   And I say, no, Facebook's not media. Facebook's a connection machine. It's something entirely
[01:11:13.080 --> 01:11:17.800]   different. It doesn't have a responsibility of the same way we think we do. Nonetheless,
[01:11:17.800 --> 01:11:23.560]   Facebook has an opportunity to better inform people and to figure that out and do exposes
[01:11:23.560 --> 01:11:27.640]   to things and so on and so forth. So it's a really complex question about a time in this
[01:11:27.640 --> 01:11:33.160]   country when when huge institutions like media are changing, when, you know, a renegade can come
[01:11:33.160 --> 01:11:38.040]   along part of me and take over a political party and utterly, utterly change it. These are these
[01:11:38.040 --> 01:11:43.880]   are changes. So sorry for the soliloquy, but I'll end it there.
[01:11:43.880 --> 01:11:47.080]   This soliloquy is what I was hoping for, Jeff. Thank you.
[01:11:47.080 --> 01:11:56.120]   That was lovely. I will say what can I say after that? I will say that I'm glad that
[01:11:57.720 --> 01:12:04.040]   Google and Facebook are using their platforms to give people access to this debate that may not
[01:12:04.040 --> 01:12:11.320]   otherwise have it and to bring people into the process. Like I do feel like
[01:12:11.320 --> 01:12:17.880]   maybe they're not better informed, but people are more involved when it
[01:12:17.880 --> 01:12:24.360]   politics reach out to them through these platforms. I will say that I totally agree that
[01:12:27.000 --> 01:12:31.080]   it's not just this election, previous elections have been the same way. It is hard to get
[01:12:31.080 --> 01:12:37.080]   any sort of politician to talk substantively about anything during an election season.
[01:12:37.080 --> 01:12:42.760]   I know it feels like so many ways. It is worse, but it's also not
[01:12:42.760 --> 01:12:49.800]   it's not unfounded that this happens. No, no, no, it's a progression, but it's a progression.
[01:12:49.800 --> 01:12:51.880]   Well, sorry, I'm interrupt this message for a quick question.
[01:12:53.000 --> 01:13:00.600]   I thought when you got to seven, you wouldn't get this damned upgrading every application message.
[01:13:00.600 --> 01:13:03.640]   Oh, no, no. It does that.
[01:13:03.640 --> 01:13:06.760]   I thought that was the problem is we were going to get rid of that.
[01:13:06.760 --> 01:13:10.840]   Was the news did not do that? Mine did not do that, but we
[01:13:10.840 --> 01:13:15.880]   minded and were you on the I'm thinking maybe the different maybe the differences the developer
[01:13:15.880 --> 01:13:21.880]   preview were you on the developer preview prior? I was not. I was not. We were. At least I know I
[01:13:21.880 --> 01:13:26.840]   was and I'm pretty certain Leo was. Maybe that's the difference. Yes, that was one of the things
[01:13:26.840 --> 01:13:32.040]   that they said you would not get in NuGet, but that might be I don't know, it might be tied to
[01:13:32.040 --> 01:13:34.840]   getting a new device. Maybe get it the first time. Maybe the second double.
[01:13:34.840 --> 01:13:38.280]   Okay, I'm sorry. I'm sorry. I'm sorry. I hate that screen.
[01:13:38.280 --> 01:13:41.240]   Yes, that screen is. Oh, I just lies it.
[01:13:41.240 --> 01:13:50.280]   Right. So what do we what do we do about this? How do we how do we return to civility in this
[01:13:50.280 --> 01:13:52.600]   country? I don't think we can.
[01:13:52.600 --> 01:13:59.880]   I think with the cat is out of the bag. We are moving to a. Oh, who's the character?
[01:13:59.880 --> 01:14:06.760]   A zap-eyed people with Brock's from Hitchhiker's Guide. So our elections are going to be purely
[01:14:06.760 --> 01:14:15.080]   theatrics. I mean, you got into this in Trump saying, you know, the offers to what it wasn't
[01:14:15.080 --> 01:14:19.480]   Mike Pence. It was another VP candidate and he was like, you know, you could you get to
[01:14:19.480 --> 01:14:25.160]   actually deal with Congress. Yes, you can deal with all international and foreign things. What
[01:14:25.160 --> 01:14:31.000]   is that kind of or domestic and foreign affairs? Exactly. You be president. I'll be wrong.
[01:14:31.000 --> 01:14:40.120]   The hotels. Okay. So, I mean, maybe it's really cynical. Maybe it's just reality. I feel like
[01:14:40.120 --> 01:14:48.360]   we've been moving this way forever. Politics are now sound bites and who makes who looks best on
[01:14:48.360 --> 01:14:52.280]   television. And if you're lucky, you're going to get someone who actually cares about this and is
[01:14:52.280 --> 01:14:56.920]   good at it. If you're not, you're going to hope that there are people behind the scenes that are
[01:14:56.920 --> 01:15:01.160]   supporting them that are actually lucky and or know what they're doing and good at it.
[01:15:01.160 --> 01:15:07.400]   I don't know. So there's the social kind of media getting involved in the election,
[01:15:07.400 --> 01:15:11.880]   the debates itself. But then there's also kind of the technology companies like you were saying,
[01:15:11.880 --> 01:15:17.480]   Stacy, who are empowering people to get involved, which is the other important component here.
[01:15:17.480 --> 01:15:25.400]   YouTube announced today the vote, IRL, the real life campaign to basically kind of get young people
[01:15:25.400 --> 01:15:33.480]   to the polls. And they're listing some top YouTube talent to basically record one minute and 34
[01:15:33.480 --> 01:15:41.880]   second videos to raise awareness, leading up to the national kind of voting registration day,
[01:15:41.880 --> 01:15:46.920]   which is the September 27th. So that's the next week. And basically, it's a minute 34,
[01:15:46.920 --> 01:15:52.600]   because Google says it takes one minute 34 seconds to register to vote. So really kind of driving
[01:15:52.600 --> 01:15:57.960]   the point home for younger potential. I went to Bethlehem, PA, which swing state last week.
[01:15:57.960 --> 01:16:02.200]   And I've gone to Pennsylvania twice to volunteer in both cases as registry and voters, which is
[01:16:02.200 --> 01:16:07.720]   God's work in any case. So it's fine. And so I sat outside the Bethlehem PA library. Now,
[01:16:07.720 --> 01:16:12.440]   Bethlehem PA, by the way, is a city made by Bethlehem Steel. It couldn't be more labor in
[01:16:12.440 --> 01:16:18.120]   his heritage. And there's more than two colleges there. So there's a bunch of commie Pico academics
[01:16:18.120 --> 01:16:23.560]   there. I was amazed at the number of people who were Republican, which is fine. It's a pretty
[01:16:23.560 --> 01:16:27.800]   country. It's fine. And we're voting for Trump. I saw enthusiastic Hillary voters who told me
[01:16:27.800 --> 01:16:32.840]   they were scared to put bumper stickers in their cars. And I know one Trump voter who also got
[01:16:32.840 --> 01:16:36.680]   something thrown at his car because of his Trump bumper sticker. It's not just virtual. This is
[01:16:36.680 --> 01:16:42.200]   happening now. There's a there's a fear of the discussion and the discourse around. I had
[01:16:42.200 --> 01:16:47.160]   Schruggie voters, but what disturbs me most is people said, no, I'm gonna come up. The kind of
[01:16:47.160 --> 01:16:55.080]   the curl lips near, especially young people. I used every persuasive skill I had to get some
[01:16:55.080 --> 01:16:57.800]   young people to register. And I don't think they're going to show up with the polls.
[01:16:57.800 --> 01:17:05.000]   So I don't think just saying, Hey, I'm famous. So you should vote like me. It's a bigger problem
[01:17:05.000 --> 01:17:10.600]   than that. I think if you want people to register to vote, that's fine. But I think
[01:17:10.600 --> 01:17:17.720]   those efforts would be much better directed at something like the there's there's a
[01:17:17.720 --> 01:17:23.240]   poll or an effort to get companies to sign on to give people two hours off so they can go
[01:17:23.240 --> 01:17:30.120]   during week. If we could get not just tech companies, but everyone to push for something
[01:17:30.120 --> 01:17:35.480]   like that, that's probably better than a thousand, you know, rock the vote, ask YouTube videos.
[01:17:35.480 --> 01:17:38.600]   You know, well, Stacy, it's a great point. Do you know any of the tech companies come up with
[01:17:38.600 --> 01:17:45.240]   that policy? A lot of them have. I was just going to check if Google has signed the I'm trying to
[01:17:45.240 --> 01:17:49.480]   remember what it's called. That's that's. Oh, there is something. Yeah, there is something. I saw
[01:17:49.480 --> 01:17:58.280]   that a few weeks back. What was that? Google food don't let me down. Yeah, I can't remember
[01:17:58.280 --> 01:18:05.000]   exactly who, but there are tech companies doing that right now. I would also love like in Texas,
[01:18:05.000 --> 01:18:10.680]   they've changed the early voting laws and restricted it somewhat. And then they've also changed the
[01:18:10.680 --> 01:18:16.360]   number of places where you can go vote in an effort to reduce minority voting. I'll be honest,
[01:18:16.360 --> 01:18:23.160]   that's what it's about. And I would love to get proactive notifications like one or two on my phone
[01:18:23.160 --> 01:18:29.720]   saying, Hey, today you can go vote at these places. You know, just as like just a little
[01:18:29.720 --> 01:18:34.520]   notification in the morning. And I remember, you know, Uber did this when in Austin, when we had the
[01:18:34.520 --> 01:18:40.040]   kick out Uber effort. And as a private company, they were advocating for their
[01:18:41.240 --> 01:18:47.960]   the law they wrote basically. And they did they were very like aggressive. They were like,
[01:18:47.960 --> 01:18:53.640]   remember, vote today, vote today. And I think if you had something like that, because a lot of
[01:18:53.640 --> 01:18:59.240]   people, they're like, Oh, yeah, I gotta vote. Oh, yeah, I gotta vote. But it's one thing to be
[01:18:59.240 --> 01:19:04.520]   like, Oh, hey, I need to vote in. Oh, I'm right over here. And there's a vote. There's a polling
[01:19:04.520 --> 01:19:13.000]   place near me. So I don't know. I feel like there's this is window dressing. This like YouTube
[01:19:13.000 --> 01:19:17.240]   star is telling people to vote. I mean, that's all it is.
[01:19:17.240 --> 01:19:24.920]   Marginally effective was rock the vote very effective in its effort. I mean, I remember it as a kid.
[01:19:24.920 --> 01:19:29.240]   And I mean, when I was younger, I'm trying to remember if it was the reason that I ever registered
[01:19:29.240 --> 01:19:33.320]   to vote. But I don't know. That was that was the first election I voted in. But I'm one of those
[01:19:33.320 --> 01:19:38.440]   weird goody two shoes types of people. So I like, I was excited to vote. And I was going to vote.
[01:19:38.440 --> 01:19:43.160]   And I did vote right when I turned 18. So I can't tell you if it was effective or not.
[01:19:43.160 --> 01:19:47.880]   Yeah, hard to know if it had anything to do with that. For me too, because I feel like I was pretty
[01:19:47.880 --> 01:19:51.880]   charged up to vote regardless. But I don't know part of that influence came from the fact that all
[01:19:51.880 --> 01:19:57.080]   my favorite watch bands were saying I should vote. Yeah, well, that's it. See, which was the first
[01:19:57.080 --> 01:20:02.120]   presidential election for each of you. Clinton. Yeah, it would be Clinton.
[01:20:03.000 --> 01:20:08.600]   Mm hmm. Oh, here it is. It's called Take Tuesday asking employers around the country to make
[01:20:08.600 --> 01:20:14.440]   November 8th of vacation day on their corporate calendar. There you go. So, oh,
[01:20:14.440 --> 01:20:21.400]   many major tech companies. Casper, Casper, Thrillist, Data Zoo, let's see. Hunter Walker has a Google
[01:20:21.400 --> 01:20:28.680]   Doc. So I'm looking at the Google Doc. So here I am loading the Google Doc.
[01:20:30.680 --> 01:20:38.680]   See, you can find what I can't get past the lock screen of my phone. Oh, no, maybe you're one of
[01:20:38.680 --> 01:20:46.680]   those people. Oh, no, it's a six P. Oh, then you're not one of those people. I don't see Google on here.
[01:20:46.680 --> 01:20:55.000]   Lipple, good, Giffy, get dusk, Guild education. No, Google is not on here. Oh, wait, maybe alphabet
[01:20:55.000 --> 01:21:04.040]   is. Hold on. Al for right. Yeah, that makes more sense. I don't see alphabet on here. Oh, now California
[01:21:04.040 --> 01:21:11.000]   requires employers to give time off. So that's in order to that varies. But in that's fine, but it's
[01:21:11.000 --> 01:21:15.320]   one thing to be like, Hey, you can do it. And it's another to establish a culture where it's cool to go
[01:21:15.320 --> 01:21:23.320]   vote or acceptable. Yeah. Yeah. Like, am I a giga, um, you know, someone would be like, Oh, you know,
[01:21:23.320 --> 01:21:27.800]   I'm going to go vote. And, you know, somebody be like, I don't know if I went to, we're like, go vote.
[01:21:27.800 --> 01:21:38.920]   So that's more effective than YouTube stars, probably. All right, before we get to our final
[01:21:38.920 --> 01:21:45.160]   ad and do picks and tips and stuff like that. I don't know. Is there anything in here that we
[01:21:45.160 --> 01:21:50.120]   didn't talk about that you were really charged up to talk about? Anything that I mean, there's a
[01:21:50.120 --> 01:21:53.720]   lot of stuff in here that we did not talk about. But I think we stuck pretty close to the Google
[01:21:53.720 --> 01:21:58.920]   front today. Oh, you did a job boss. Yeah, you actually did better than we did. Because I think
[01:21:58.920 --> 01:22:06.120]   we talked about Google like most of the time. Yeah, that's amazing. Which is unusual. All right,
[01:22:06.120 --> 01:22:10.760]   well, let's, uh, let's stop while we're ahead. I'm going to thank a blue apron who's the sponsor
[01:22:10.760 --> 01:22:15.800]   of this episode, and then we can come back and we can do tips and tricks and pointers and whatever
[01:22:15.800 --> 01:22:20.600]   we have numbers, all that kind of stuff. So let's take a break. Thank blue apron the sponsor of this
[01:22:20.600 --> 01:22:25.240]   episode. This is the part of the show where I get super duper hungry because I ate kind of a
[01:22:25.240 --> 01:22:29.640]   lunch, but I didn't need a blue apron lunch. And I kind of wish I did. Blue apron's mission is to
[01:22:29.640 --> 01:22:35.720]   make incredible home cooking accessible to everyone while also supporting a more sustainable food
[01:22:35.720 --> 01:22:40.520]   system. And in doing so, setting the highest standards for ingredients and building a community
[01:22:40.520 --> 01:22:44.600]   of home chefs, blue apron is going to make you a better chef. That's kind of the beauty of blue
[01:22:44.600 --> 01:22:51.080]   apron. And I've loved learning how to cook better by using blue apron. It delivers seasonal
[01:22:51.080 --> 01:22:55.880]   recipes along with fresh high quality ingredients to make delicious home cooked meals. Every meal
[01:22:55.880 --> 01:23:01.160]   comes with a step by step easy to follow recipe card that you get to keep after the fact so you
[01:23:01.160 --> 01:23:06.040]   can remake these recipes if you want. Pre portioned ingredients that can be prepared in 40 minutes or
[01:23:06.040 --> 01:23:11.240]   less. You'll save time and money. You know, when you're going to the grocery store, you're paying a
[01:23:11.240 --> 01:23:16.920]   lot. It's 60% more expensive than what you pay with blue apron, basically. If you spend a lot of
[01:23:16.920 --> 01:23:21.800]   time and money eating out or going to high and grocery chains, now you're going to spend under
[01:23:21.800 --> 01:23:26.920]   $10 per person for healthy home cooked meals. You can customize your recipes every week based on
[01:23:26.920 --> 01:23:31.160]   your dietary preferences and choose a delivery option that fits your needs and your schedule.
[01:23:31.160 --> 01:23:36.360]   There's no weekly commitment. So you only get deliveries when you want them. Blue apron delivers
[01:23:36.360 --> 01:23:42.120]   to 99% of the continental US. Blue apron sets the highest quality standards for their community of
[01:23:42.120 --> 01:23:48.120]   over 150 local farms, fisheries and ranchers across the US. Seafood is sourced sustainably.
[01:23:48.120 --> 01:23:53.800]   Beef is raised humanely. Chickens are free range. Pork is raised naturally. And regenerative
[01:23:53.800 --> 01:23:58.440]   farming practices are used for produce. And you know, they're only sending you the exact amount
[01:23:58.440 --> 01:24:02.840]   that's required for that particular recipe. So in doing so, blue apron reduces food waste.
[01:24:02.840 --> 01:24:07.400]   And it also keeps the recipes really kind of specific. You don't end up with extra and have
[01:24:07.400 --> 01:24:11.240]   to figure out what you do with that extra, you know, a little teaspoon of sugar or whatever the
[01:24:11.240 --> 01:24:16.680]   case may be. Whether it's Japanese ramen noodles, wild caught Alaskan salmon or heirloom tomatoes,
[01:24:16.680 --> 01:24:21.400]   blue apron brings you the best. Blue apron not only supports a more sustainable food system,
[01:24:21.400 --> 01:24:25.880]   it also supports happy and healthy families. Because when you cook together, you build strong
[01:24:25.880 --> 01:24:30.440]   family bonds. Research actually shows that blue apron families cook nearly three times
[01:24:31.480 --> 01:24:36.120]   more often. New recipes are being created every week by a blue apron's culinary team.
[01:24:36.120 --> 01:24:40.360]   They're not repeated within a year. So you can get paprika, spiced shrimp and cheddar grits
[01:24:40.360 --> 01:24:44.040]   with tomato and sweet corn. You're starting to salivate.
[01:24:44.040 --> 01:24:51.000]   Eggplant and chickpea. Is it tagine? Tagine with some of the tagine maybe with
[01:24:51.000 --> 01:25:00.040]   islander tagine. Okay, now we know that fella. Tagine. We get that eggplant and chickpea tagine
[01:25:00.040 --> 01:25:04.600]   with islander pepper, tomato and couscous. Their summer ood on noodle salad with cherry tomatoes,
[01:25:04.600 --> 01:25:10.680]   corn and summer, sweet pepper and spicy hoisin chicken stir fry with baby bok choy and sesame
[01:25:10.680 --> 01:25:16.200]   ginger cucumber salad. This sounds really good. Check out this week's menu and get your first three
[01:25:16.200 --> 01:25:21.720]   meals free with free shipping by going to blue apron.com/twit. You're going to love how good it feels
[01:25:21.720 --> 01:25:26.360]   and tastes to create incredible home cooked meals with blue apron. So do not wait. Visit blue
[01:25:26.360 --> 01:25:31.400]   apron.com/twit. We thank Blue Apron for their support of this week in Google. Blue Apron is a
[01:25:31.400 --> 01:25:37.160]   better way to cook. My favorite of the of the meals that would be in some of the reads for
[01:25:37.160 --> 01:25:41.640]   Blue Apron was a chicken tingitakos because it's a lot of fun to say. And I still have
[01:25:41.640 --> 01:25:47.000]   yet to make a tingitakos, but I want to because it's named so it's barbecue tacos.
[01:25:47.000 --> 01:25:53.480]   Oh, that's that's all I mean, it's kinga is barbecue sauce with Mexican food basically.
[01:25:53.480 --> 01:25:58.440]   Still sounds delicious. Oh, yeah, I mean, I'm a Texid. We're like, wait, barbecue plus Mexican?
[01:25:58.440 --> 01:26:04.200]   I've just I've just never I had never heard of tingitakos before before Blue Apron and
[01:26:04.200 --> 01:26:08.120]   even not knowing that it was barbecue, it still sounded delicious just based on the way the words
[01:26:08.120 --> 01:26:12.040]   sounded. So I got to make it. And the good the good thing is you can go to their site. You can
[01:26:12.040 --> 01:26:16.360]   actually find all the recipes and try them for yourself. So there you go. They get their chicken
[01:26:16.360 --> 01:26:24.520]   tingitakos recipe. Okay, so let's do tips and numbers and all that stuff. Jeff, why don't we
[01:26:24.520 --> 01:26:31.960]   start with you? What's your number? So this afternoon, Priscilla Chan and Mark Zuckerberg went on
[01:26:31.960 --> 01:26:37.400]   Facebook Live, of course, to announce a major initiative. They promised to give away most of
[01:26:37.400 --> 01:26:48.120]   their money in their lifetimes. They're giving away $3 billion to cure disease. Wow, a better
[01:26:48.120 --> 01:26:53.160]   thing to do. I can't imagine. However, I imagine commentators will say that there's a bit of
[01:26:53.160 --> 01:26:58.440]   hubris to this because $3 billion is a hell of a lot of money more than we have. And you have us
[01:26:58.440 --> 01:27:04.600]   can be spent over 10 years, but the budget for, you know, the government's efforts in this line
[01:27:04.600 --> 01:27:12.600]   are $31 billion per year. So I'm not sure, you know, what $3 billion is a generous gift. It's an
[01:27:12.600 --> 01:27:18.200]   important gift. What I don't know yet is how they have the belief that that $3 billion is going to
[01:27:18.200 --> 01:27:23.240]   be able to do this. And as I said, it doesn't mean that people aren't going to get sick, but they want
[01:27:23.240 --> 01:27:28.840]   to make diseases curable and manageable. They also are taking everything and making it open source,
[01:27:28.840 --> 01:27:33.000]   which is all this is great. All of this is great. But what I don't know yet is how is $3
[01:27:33.000 --> 01:27:37.480]   billion is going to do it. And that really puts things into perspective.
[01:27:37.480 --> 01:27:45.640]   That is insane. I never would have known that. That's crazy. Yeah, that's it.
[01:27:45.640 --> 01:27:51.480]   There's other things to draw. There's other things to do. Yeah, but it's a very hard
[01:27:51.480 --> 01:27:57.880]   problem. Engineers love hard problems. Yeah. But I know that the tech naysayers out there are
[01:27:57.880 --> 01:28:05.400]   going to say, Oh, they can do what God couldn't do. You know, so I'm hopeful. But I'm not looking
[01:28:05.400 --> 01:28:12.920]   forward to the conversation over the next 72 hours. Wow. Yeah. And hey, give something is better
[01:28:12.920 --> 01:28:19.800]   than nothing. So at least it's all I'm supportive. I think it's great. But there's a lot more to come
[01:28:19.800 --> 01:28:26.760]   up here. Yeah. All right. We will be following that. Stacy, what you got?
[01:28:26.760 --> 01:28:32.840]   I have a recipe for you guys. Now the challenge with all of my recipes are
[01:28:32.840 --> 01:28:37.160]   their device specific. So if you have these devices, you'll be excited. If you don't
[01:28:37.160 --> 01:28:46.280]   go buy them. I talked about this before. This one, this involves three things. So get ready.
[01:28:46.280 --> 01:28:52.920]   The first is a my cue garage door opener from Chamberlain. It's I bought mine for about 100 bucks.
[01:28:52.920 --> 01:28:59.240]   It's I think 130 right now at Best Buy. So this is an attachment that you put on your garage door
[01:28:59.240 --> 01:29:04.120]   and you can use it to remotely open and close your garage door. And you can also see and get
[01:29:04.120 --> 01:29:08.360]   notifications if your garage door has been open for a while. I love that about about it because
[01:29:08.360 --> 01:29:13.880]   we're moving in and out and our garage door is almost always open. So I'm like, Oh, close it.
[01:29:13.880 --> 01:29:21.160]   Okay. So that's part one. Part two is a Wink Hub. So the Wink Hub, it's about $50. We think a new
[01:29:21.160 --> 01:29:26.760]   one's coming out soon, but we don't know. So you may want to wait a little. And then the third item
[01:29:26.760 --> 01:29:32.920]   you need are Lutron lights. And the reason you would have all of these things or if you have all
[01:29:32.920 --> 01:29:40.120]   of these things, what I've done is I've set up a recipe using the Wink app to open whenever my
[01:29:40.120 --> 01:29:46.520]   garage door opens after a certain time at night, my porch lights come on. And this is super handy
[01:29:46.520 --> 01:29:53.160]   because even if I'm opening it to leave, it's nice that I've left the house and my porch lights
[01:29:53.160 --> 01:29:59.880]   are on. So yay. Or if I'm coming home late and they're dark, then when I walk outside, because I
[01:29:59.880 --> 01:30:05.800]   have to walk outside my garage and go up the stairs to get to my front door, then I've got light.
[01:30:05.800 --> 01:30:12.520]   So it's a nice app or a nice recipe. If you're going to do it, the Wink app is sometimes a
[01:30:12.520 --> 01:30:18.280]   little bit wonky. So if it doesn't work for you, you may have to divide your A it like
[01:30:18.280 --> 01:30:25.400]   before midnight, your night into before midnight and after midnight. So that's your pro tip for you
[01:30:25.400 --> 01:30:30.760]   if you're actually going to do this. That is cool. How connected is your home? I mean, I know,
[01:30:30.760 --> 01:30:37.480]   I know that IOT is kind of your thing. Do you practice this to like an insane degree at home?
[01:30:37.480 --> 01:30:42.600]   Is your home super connected? My home is super connected, but it's not convenient.
[01:30:42.600 --> 01:30:47.480]   My husband will be the first to tell you like this one is something that works.
[01:30:47.480 --> 01:30:56.600]   But as you can see, like it requires a lot of things to do this sort of stuff. And
[01:30:57.560 --> 01:31:01.320]   like to get this one working, I actually had to call Wink because they had a glitch in their
[01:31:01.320 --> 01:31:07.560]   system. So if I tried to make my night last the whole night, instead of dividing it up into two
[01:31:07.560 --> 01:31:15.320]   chunks, it at midnight, it was like, oh, I'm done. I'm no longer going to work. So the whole
[01:31:15.320 --> 01:31:19.400]   recipe just didn't work. And I didn't know why. So I had to call them and figure it out. So this
[01:31:19.400 --> 01:31:25.400]   is why I'm telling you, because if you have these things, this is how you can make something like
[01:31:25.400 --> 01:31:31.000]   that happen. That's cool. Oh, the other for because y'all are sorry, because y'all are Google people.
[01:31:31.000 --> 01:31:38.040]   The nice thing about Wink is they actually show up some of the devices that are on my Wink,
[01:31:38.040 --> 01:31:43.400]   show up in my Google, it's I would call it my Google now screen, but now it's something else.
[01:31:43.400 --> 01:31:48.840]   It shows up as a card on my, what do we call this now? Not the Google now screen?
[01:31:48.840 --> 01:31:52.680]   Well, that's a good question. That's a good question.
[01:31:52.680 --> 01:31:56.680]   All right. I mean, the assistant screen, I don't know what it's going to be. And it's still Google
[01:31:56.680 --> 01:32:02.440]   now. It's still Google now, but it's changing. The status of some of my devices, it'll say things
[01:32:02.440 --> 01:32:07.400]   like, Hey, we noticed you're not home and your garage door is unlocked. And then I'm like,
[01:32:07.400 --> 01:32:11.000]   Oh, crap. And I'll hit it and it'll lock it straight for the screen. It's totally
[01:32:11.000 --> 01:32:17.160]   unprobed to I didn't do anything with it. So that's nice. That's nice. I imagine, I imagine there's
[01:32:17.160 --> 01:32:23.640]   going to be a sequel to Soilent Green made from your house. Everything is controlled.
[01:32:23.640 --> 01:32:28.760]   Everything is controlled. And there'll be these kind of iron doors that come popping down
[01:32:28.760 --> 01:32:34.360]   and alerts that go up and cameras that go around. I just imagine you and your
[01:32:34.360 --> 01:32:42.520]   dotege having everything you need for a perfectly paranoid, but yeah, it's oddly convenient existence.
[01:32:43.480 --> 01:32:49.240]   Paranoid and yeah, probably. I like this a lot. 20 years.
[01:32:49.240 --> 01:32:55.880]   But what I like about it is it's the old, powerful Stacy. Yeah, sitting on her couch can do anything.
[01:32:55.880 --> 01:33:01.560]   That's I really want that to be the case. So I like, I never have to move.
[01:33:01.560 --> 01:33:09.560]   Exactly. This is the greatest vision that you can be in your fortress. Yeah, it's kind of the
[01:33:09.560 --> 01:33:14.280]   promise of this of the technology that we have right now is to make all of the things in our
[01:33:14.280 --> 01:33:20.280]   life easier. But you know, I mean, and I'm sure you would agree, the promise of things like IOT
[01:33:20.280 --> 01:33:24.600]   doesn't always bear out in practice. I can't even just really stage this. It's learning,
[01:33:24.600 --> 01:33:26.920]   it's learning stages right now. You know what will happen Stacy?
[01:33:26.920 --> 01:33:30.200]   St. Paul, what happened is you'll have your fortress set up. I'll try to be doing the same
[01:33:30.200 --> 01:33:34.360]   thing, but I'm on a Google Apps account. So another little work for me. It's true.
[01:33:34.360 --> 01:33:36.040]   Jeff, I bought a Google Apps account.
[01:33:36.840 --> 01:33:39.960]   I bought Google Apps. I got trips going.
[01:33:39.960 --> 01:33:45.240]   All right, trips. Good segue. Let me show you what you're missing, Jeff. I'm sorry that you
[01:33:45.240 --> 01:33:52.920]   can't get this because it's actually really cool. So, some day, Jeff, don't worry. It actually makes
[01:33:52.920 --> 01:33:56.440]   sense for Google Apps because it's, you know, it's tight to your business account. You do a lot of
[01:33:56.440 --> 01:34:02.360]   travel and business. I'm sure there's a lot of overlap there. So what does it do? Google trips
[01:34:02.360 --> 01:34:07.240]   basically trawls through your search history through, okay, that needs to stop. Your search
[01:34:07.240 --> 01:34:15.720]   history, your hi, Megan. Megan is allowing me right now. She must know that this is appearing on
[01:34:15.720 --> 01:34:20.840]   the show right now. She's doing some research for techniques today. I have.
[01:34:20.840 --> 01:34:23.160]   Oh, go to Austin. We can see how good it is.
[01:34:23.160 --> 01:34:28.040]   So this is, okay, so this is from back in 2010. You can see the date there, 2010. Back then,
[01:34:28.040 --> 01:34:34.680]   I went to Austin with Twitch for South by Southwest. So here is, so basically it's gone through my
[01:34:34.680 --> 01:34:40.120]   email, my Gmail account, and found all the travel-y things that I have and put them in here.
[01:34:40.120 --> 01:34:46.280]   Now, I don't really have a whole lot in here from Austin other than probably reservation. So,
[01:34:46.280 --> 01:34:48.520]   yeah, stayed at the four seasons, hotel in Austin.
[01:34:48.520 --> 01:34:53.720]   Dang. Oh, geez, Jason. You know nothing but the best.
[01:34:53.720 --> 01:34:57.960]   Oh, hey. I'm staying at the Motel 6, but you.
[01:34:57.960 --> 01:35:04.520]   That was actually really nice hotel. I have to say, that was a really nice hotel.
[01:35:04.520 --> 01:35:07.240]   Very fond of that hotel. Yes, it is.
[01:35:07.240 --> 01:35:11.080]   Megan, stop setting me stickers.
[01:35:11.080 --> 01:35:16.120]   Anyway, so you get all the information about your reservation. If I had flight information,
[01:35:16.120 --> 01:35:20.520]   which, you know, I think in this case it was tied to my Twitch account, then it would go there.
[01:35:21.320 --> 01:35:24.360]   You get information about what you can do while you're there. So while I'm in Austin,
[01:35:24.360 --> 01:35:28.920]   I've got top spots here, of course, for you indoors, you know, if you want to check out museums or
[01:35:28.920 --> 01:35:34.200]   whatever, outdoors, botanical gardens, zoos, that sort of stuff, things that are kid-friendly.
[01:35:34.200 --> 01:35:38.040]   All these things you can kind of look at in advance and go, "Oh, yeah, I definitely want to
[01:35:38.040 --> 01:35:43.800]   check out the Hamilton pool. I'll go ahead and favor it." Right? As I favor things, they appear in
[01:35:43.800 --> 01:35:49.000]   saved places that I can remember them later. Now, where this gets really kind of interesting and
[01:35:49.000 --> 01:35:53.400]   powerful, and I'm not seeing it for Austin, I don't know why. So let's go into something else here and
[01:35:53.400 --> 01:36:00.200]   see if I get that day plans. So if I've saved something for in day plans, let's see if I have
[01:36:00.200 --> 01:36:07.880]   saved places for Las Vegas. If I go into day plans, I'm given both pre-arranged, predetermined kind of
[01:36:07.880 --> 01:36:13.560]   like things that you can do order, an order of sites and experiences that you can do while you're
[01:36:13.560 --> 01:36:19.240]   there for an extended period of time, let's say, but I can go ahead and create. And it will take
[01:36:19.240 --> 01:36:23.800]   into account the things that I've saved and the things that it thinks in that area I should check
[01:36:23.800 --> 01:36:28.200]   out. And it'll create a full day itinerary in this case. I could tweak that to say I'm only going to
[01:36:28.200 --> 01:36:32.920]   be there in the afternoon, and it would kind of narrow it down and be like, "Okay, well, in that
[01:36:32.920 --> 01:36:38.600]   case, this, these five locations are where you should go and in this order so that it makes sense
[01:36:38.600 --> 01:36:45.720]   geographically moving from one point to the other." And so then you can save it, and that's part of
[01:36:45.720 --> 01:36:53.000]   your itinerary going forward. And what makes it more powerful is when you're going to this far off
[01:36:53.000 --> 01:36:57.720]   land, in this case, Vegas, where I'm sure connectivity is plentiful, but if you're going somewhere else
[01:36:57.720 --> 01:37:02.840]   where maybe you're in the mountains or whatever, and overseas where you don't have data, you can set
[01:37:02.840 --> 01:37:08.280]   it for offline. And all that information that you've searched in here stored everything is stored
[01:37:08.280 --> 01:37:12.440]   within this little packet so that when you get there, you don't need connectivity. You can just
[01:37:12.440 --> 01:37:19.320]   pull from here. I'd sure like to have that. Would it be nice? It would be nice. It would be nice.
[01:37:19.320 --> 01:37:25.480]   Yeah, it's really nice. It's a cool tool. And I have the imagines going to continue getting better.
[01:37:25.480 --> 01:37:31.480]   Again, it relies on information that you're willing to allow Google to hold on for you.
[01:37:31.480 --> 01:37:35.480]   On to for you. I have no problem with that. Google has a problem with me, apparently.
[01:37:35.480 --> 01:37:40.440]   Yeah, I have no problem with Google. I went into my apps administrator account,
[01:37:40.440 --> 01:37:44.840]   and I'm already set up so it is supposed to just automatically say, okay, anything new.
[01:37:44.840 --> 01:37:53.160]   But there nothing. Something. Some day. No, that is frustrating because I've got a Google apps,
[01:37:53.160 --> 01:38:00.360]   and I just got if I do my apps account, it didn't work. So I'll go in and administer my account. So
[01:38:00.360 --> 01:38:05.880]   it does. But I travel both personally and for business. So I'm kind of like, I want both of them to be
[01:38:05.880 --> 01:38:13.800]   the same. Yes, just. Well, come back to Google. I give you a vision to mush. You know, how many
[01:38:13.800 --> 01:38:17.960]   years Google should be able to write. You should be able to give Google permission to say, I am the
[01:38:17.960 --> 01:38:22.600]   same person and combine these things. It's good for Google. It's good business for Google because
[01:38:22.600 --> 01:38:27.960]   they would know more about you as a person to confirm you. I don't get it. Yes. I get this.
[01:38:27.960 --> 01:38:33.480]   You're a company selling people Google apps. Yeah. If you're if you're a company that's
[01:38:33.480 --> 01:38:37.320]   administering this account, maybe you don't want Google to have some of this information.
[01:38:37.320 --> 01:38:41.640]   Okay. But when you do get the permission, it doesn't make any difference. We are sorry,
[01:38:41.640 --> 01:38:45.400]   but you do not have access to Google trips yet. Please contact your Google apps administrator
[01:38:45.400 --> 01:38:49.640]   for more information. Hey, I'm some administrator. Yes, Mr. Jarvis, what would you like? I'd like
[01:38:49.640 --> 01:38:53.800]   to have trips. Okay. Let me see if I can get it for you. Oh, sorry, you're our out of luck.
[01:38:55.640 --> 01:39:02.440]   Oh, well, no, it's so it's actually pulling up some of my trips. Are they both from your business?
[01:39:02.440 --> 01:39:07.880]   Yeah. If you ever forwarded it to your personal account, it would pick that up and it would put it
[01:39:07.880 --> 01:39:13.480]   in. I know some of my personal stuff to my business account, I think. Well, sometimes like I get
[01:39:13.480 --> 01:39:18.200]   travel travel information, you know, set up for Twit. And in order to make sure that I have it,
[01:39:18.200 --> 01:39:22.040]   you know, in my personal account, I'll just forward the email over just so that I have it there and
[01:39:22.040 --> 01:39:28.600]   start just so it's in both places. And it picked up those in the in trips. So I don't know if that's
[01:39:28.600 --> 01:39:35.000]   what's happening. I travel a lot. Yeah. Well, then this is probably right up your alley. This is
[01:39:35.000 --> 01:39:40.200]   this is good for anyone that's traveling a lot, especially if you're going up some place like
[01:39:40.200 --> 01:39:43.800]   that doesn't have any connectivity. That's awesome to have that stuff accessible.
[01:39:43.800 --> 01:39:51.480]   That I believe as they say is that this is a lot of fun. We stuck pretty darn close to Google
[01:39:51.480 --> 01:39:57.720]   today and had a great time doing it. Let's start with you Stacey. I know you have the IOT podcast
[01:39:57.720 --> 01:40:05.160]   at IOT podcast.com. Got the Internet of Things newsletter at Stacey on IOT.com. What am I missing
[01:40:05.160 --> 01:40:11.160]   here? What else you got? I have every two weeks. I've got a smart home column in PCMag, if you
[01:40:11.160 --> 01:40:17.000]   want to read that. I had one come out today where I give I answer readers questions about various
[01:40:17.000 --> 01:40:21.640]   smart home stuff. And I actually did a different recipe in there for connecting your doorbell to
[01:40:21.640 --> 01:40:27.960]   your lights. Nice. So somebody rings your doorbell and your lights turn on. Yes, it's for somebody
[01:40:27.960 --> 01:40:32.840]   has somebody asked me a question because they have a deaf sibling and they were like, I'd like to
[01:40:32.840 --> 01:40:36.920]   help them out. Yeah, that's a really smart solution. I want to read really doorbell and
[01:40:36.920 --> 01:40:42.440]   starts pouring the cabernet. Yeah, come on in. Somebody rings the doorbell and the champagne
[01:40:42.440 --> 01:40:48.760]   pops in the other room. A visitor. Yeah. It's a party. Music starts playing. Yeah.
[01:40:48.760 --> 01:40:54.760]   Jeff, we could make that happen. I know you could have a disco ball living right on.
[01:40:54.760 --> 01:40:59.320]   The steel shutters come down and nobody else can come in.
[01:40:59.320 --> 01:41:06.680]   This is a closed off party. Thank you Stacey. This is a lot of fun. I really appreciate it.
[01:41:08.040 --> 01:41:13.320]   Jeff, what about you? You've got buzzfeed.com. Buzzfeed. I don't I wish I was on buzzfeed.
[01:41:13.320 --> 01:41:18.200]   Wait a minute. Yeah. No, that doesn't make any sense. Sorry. It's in the back. I just did a total
[01:41:18.200 --> 01:41:23.800]   Ron Burgundy right there. It's a buzzfeed. Buzz machine. Not pretty much it for now.
[01:41:23.800 --> 01:41:30.840]   That's it for now. All right. All right. @Jeff Jarvis on Twitter to follow. And medium slash
[01:41:30.840 --> 01:41:34.440]   at Jeff Jarvis too. I do a lot of stuff there. Excellent. Thank you, Jeff.
[01:41:35.240 --> 01:41:39.960]   You good job, boss. Thanks, man. This is fun. I've got another two weeks in the hot seat. So
[01:41:39.960 --> 01:41:46.360]   I'm looking forward to it. Did I see one of you is out next week? Is that right? I think I
[01:41:46.360 --> 01:41:52.600]   know California. This is the trouble week where we're probably both out. I apologize. I've been
[01:41:52.600 --> 01:41:57.960]   I've been a bad boy this month, but it's just a bad confluence. That is okay. We will figure it
[01:41:57.960 --> 01:42:03.320]   out. I know that we've already got actually we have Ron Richards on the docket for next week.
[01:42:03.320 --> 01:42:07.640]   So we'll figure it out. We got you covered. You are you both flapped. We got you are on flapped. You
[01:42:07.640 --> 01:42:12.520]   are on flapped. You lose your identity on the air and and you just don't flap and you are amazing.
[01:42:12.520 --> 01:42:21.320]   I had no choice. I lost access to all my Google account. I really had no choice but to plow on.
[01:42:21.320 --> 01:42:26.760]   But hey, I got access back. So you know what more could you ask for and we learned cuts. We learned
[01:42:26.760 --> 01:42:30.600]   yeah, thank you to Matt cuts and a whole lot of other people. We learned a lot of value and
[01:42:30.600 --> 01:42:36.360]   valuable important lessons that day. Let's see here twig this week in Google records every Wednesday
[01:42:36.360 --> 01:42:43.960]   130 p.m. Pacific for 30 p.m. Eastern 2030 UTC. You can always join live to watch the show at
[01:42:43.960 --> 01:42:50.680]   twit.tv slash live course on demand at twit.tv slash twig and pretty much everywhere you're
[01:42:50.680 --> 01:42:55.960]   going to find your podcast both audio and video all over the map. But that is it for this week
[01:42:55.960 --> 01:43:09.400]   on this week in Google. We will see you all next week. Take care you guys.

