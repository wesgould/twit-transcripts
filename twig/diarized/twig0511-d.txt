;FFMETADATA1
title=Where Do You Put the Naked People?
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=511
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" But it's also true on the other end of the color spectrum for me."): backtrack failed, resorting to original...
Speaker: SPEAKER_02
Transcript:  It's time for twig this week in Google. Jeff and Stacey are both here. There's lots to talk about,  including Apple's thousand dollar monitor stand, some brand new tools from Google,  and my new tiny cell phone. It's all next this week in Google.

Speaker: SPEAKER_03
Transcript:  Netcasts you love from people you trust.

Speaker: SPEAKER_00
Transcript:  This is twig.

Speaker: SPEAKER_02
Transcript:  This is twig. This week in Google episode 511, recorded Wednesday, June 5th, 2019.  Where do you put the naked people? This week in Google is brought to you by WordPress. Turn your  dreams into reality and launch your website at WordPress.com. Get 15% off any new plan  at WordPress.com slash twig and by LastPass, the number one most preferred password manager.  Just remember your master password and LastPass remembers the rest. Visit lastpass.com slash  twig to learn more. It's time for twig this week in Google. The show we cover the Google verse,  Facebook, Google, House Judiciary Committee hearings with us Stacey Higginbotham from her new home  in the great Pacific Northwest. Finally, you're in our time zone. Hi Stacey. Welcome back. So I  don't have to worry about you getting the urge to get go get queso or anything because

Speaker: SPEAKER_03
Transcript:  you really never know Leo. I mean, I could be hungry in this time zone too.  It's what has the move going? It's a little awkward. Our stuff has not arrived and it will  not arrive for another week and a half. So that was a little bit of misplub. Oh well. How did you

Speaker: SPEAKER_01
Transcript:  get there? Did you drive your car across or? No, we flew. She was going to drive but that I guess

Speaker: SPEAKER_03
Transcript:  change of plans and my dog. This is my dog is crazy. That's right. That's right. That's Jeff

Speaker: SPEAKER_02
Transcript:  Jarvis, professor, Leonard town professor as it might be for journalistic innovation at the  great no mark graduate school of journalism at the city university of New York. Hello, Mr. Jarvis.

Speaker: SPEAKER_01
Transcript:  Welcome. You know, my sport is trying to get you to buy things. You want me to buy something?  I've got it. I've got it for you. Unfortunately, you can't buy quite yet, but Boston dynamics has  its first commercial robot spot. Oh, this is the dog. And how much is it? I'm not finding a price.

Speaker: SPEAKER_02
Transcript:  Yeah. That means if you have to ask kids, is it more or less than a new Mac pro monitor stand?  We see the problem with Boston dynamics is there a bunch of engineers. They don't get making things

Speaker: SPEAKER_03
Transcript:  cute and fuzzy. Oh my God. The fact that that's running around the conference floor at remars,  like if that came up to me, I probably would scream because they go,

Speaker: SPEAKER_01
Transcript:  they know dog terrifying plays. It gives it, there's a video. You want to see it here? Yeah.

Speaker: SPEAKER_03
Transcript:  This is spot mini. It's the one that opens doors. Yeah.

Speaker: SPEAKER_02
Transcript:  Oh my God. I can't even watch it. I'll make you a deal. Jeff, if I can get it for less than 1500  bucks, I'll buy it. Oh, look at the dog is terrified. Yes. Oh, wait a minute. I'll take the toy.

Speaker: SPEAKER_03
Transcript:  That's, oh my God. Is that creepy? So creepy. It's technology. Nope. I showed it to my daughter and  she unreservedly was like, Oh mom, that's awful. It's awesome. There's something missing in you,

Speaker: SPEAKER_02
Transcript:  Jeff. I don't know what it is. The last thing you see before you die. As it eats you. Oh,  this is so awesome. So cool. And it's the one that opens doors. So it'll come for you.  It's a lot quieter than the old ones. The steam powered ones are really noisy,  but I think these are electric, which means probably they don't go as long.

Speaker: SPEAKER_01
Transcript:  So I, I, uh, I'm on the board of a foundation that's in a building in Morristown, New Jersey,  the same place as the place where they hand over puppies for CNI to get trained. Yeah.  And, you know, I was thinking about what, what, what if you had that as a CNI dog?

Speaker: SPEAKER_02
Transcript:  Um, you know, one of the things companion animals do though, is they sense mood,  they understand there's, there's, there's heart attack dogs. I mean, I don't know.

Speaker: SPEAKER_01
Transcript:  True. I don't know if these dogs imagine the data capability of that to know,  Hey, take me to Starbucks. I guess you could, you know, you could really have a much smaller

Speaker: SPEAKER_02
Transcript:  guide dog that you just would, you know, use as a, to accompany you. Here's a, uh, another video  of the Boston dynamics robot dog. Here's the robot dog army. Oh,  but see if they'd had this at Chernobyl, thousands of people would have survived.

Speaker: SPEAKER_01
Transcript:  Why do the rest of them have no heads? They have heads. Oh, they're pulling a truck. Oh, wow.

Speaker: SPEAKER_02
Transcript:  They're pulling a semi the Boston dynamics truck doesn't have to have an engine. Apparently it's  like Santa and his robotic reindeer. They call it spot power. It takes 10 spot power to haul a truck.

Speaker: SPEAKER_03
Transcript:  Do you realize that that's, do you realize how capable those are? Oh no, here's another one.

Speaker: SPEAKER_02
Transcript:  This is even scarier. Wait a minute, wait a minute, wait a minute. Put the sound on again for this one.  This one's even scarier.  Here. You got it. You got to show it to them. So this is the dogs waking up to an all day.  If you could see this folks, if those of you listening at home, it's just imagine 10  robotic yellow robotic dogs. So I wonder how much they're going to be $10,000, right? They're not.

Speaker: SPEAKER_01
Transcript:  So this story, Gizmodo says that the industrial robot Baxter cost 22,000.  Sony IBO costs 2000 because it's gonna be closer to Baxter than it is to Sony.

Speaker: SPEAKER_02
Transcript:  Really? Yeah. Baxter was pretty fancy though. Yeah. IBO was actually fancy in other ways.  Couldn't pull a truck, but it was cute and it played games.

Speaker: SPEAKER_01
Transcript:  You see that what makes, see, that's the thing here, right? It's the same basic  technology. It's the same basic thing. One is adorable. One is creepy. Come on.

Speaker: SPEAKER_03
Transcript:  Okay. Once IBO is this big. IBO also does things like this cocks his head at you and looks all cute.  Yes. They make it cute. Big dog. When it cocks its head,  you're thinking it's going to shoot lasers out of its eyes because it is scary.  But IBO could shoot lasers out of its eyes. Yeah. Honestly, if you're going to make a killer dog,

Speaker: SPEAKER_02
Transcript:  what are you going to make it look like? It's going to make it cute.

Speaker: SPEAKER_03
Transcript:  Yeah. I mean, IBO also cannot open doors nor can it climb stairs. So if you're going to run away  from big dog, it's going to catch you. Also, big dog is fast. Very fast. Like 60 miles an hour.  What? Really? It can run. Google how fast can big dog run? It's really, it's fast.

Speaker: SPEAKER_02
Transcript:  This is the, by the way, IBO is back. Sony is making it again. This is the new  IBO. I just had a curiosity. This we should buy. How much? Yeah. It's in it to me because I want it.  $3,000. Whoa. 28.99. Whoa. Yeah. Plus you have to buy its toys.  Yeah. Apparently you also have to buy paws.  Oh, paw pads. If you want paw pads, it'll be an extra 10 bucks.

Speaker: SPEAKER_03
Transcript:  I think your dog's skipping around and you're like, buy the paws. Buy the paws.

Speaker: SPEAKER_02
Transcript:  Don't buy the paws without the dog though. That'd be my suggestion. You want to see IBO at work?  Here we go. Here's a little IBO and IBO takes Manhattan.

Speaker: SPEAKER_00
Transcript:  I'm from Brooklyn, New York. The Bronx. You know what I'm saying? I live on the Upper East Side.

Speaker: SPEAKER_02
Transcript:  Maybe surprise, but I'm never shocked. Let's try and do this the most glamorous way as possible.  These are definitely New Yorkers. I love New York.  See, this is what Stacey was talking about though. It's really...

Speaker: SPEAKER_00
Transcript:  I feel kind of skeptical.

Speaker: SPEAKER_02
Transcript:  I like the whirring sounds. It does bark well.  Time to meet IBO in this.

Speaker: SPEAKER_00
Transcript:  Oh my God. Oh my God.

Speaker: SPEAKER_02
Transcript:  Okay. This I've never seen before.

Speaker: UNKNOWN
Transcript:  Oh my God.

Speaker: SPEAKER_02
Transcript:  Okay. That's a great ad.  Can you take it home with me?  He's really cute. I have to say he's really cute, but $3,000 is a little bit out of my price range.  For that, I could get half a Mac Pro.

Speaker: SPEAKER_03
Transcript:  Oh, true. Yeah. If Boston Dynamics had that marketing... But I'm serious. If you opened  your eyes and again, that was in front of you, you would scream. Not in a good way. In the like...

Speaker: SPEAKER_02
Transcript:  So we were in the middle of Twit when...  Do we actually...  What?

Speaker: SPEAKER_03
Transcript:  Are we in Twit now?

Speaker: SPEAKER_02
Transcript:  We're in Twig.  Did we start?  Yes. I introduced you and everything. Remember I asked you how your trip was, how Seattle was?  Stacey's jet lagged.  Yeah, a little bit. So on Sunday in the middle of Twit, actually before Twit,  but during most of Twit, Google went down.  Oh, yes.

Speaker: SPEAKER_01
Transcript:  Oh, it was during the show. Oh, cool.

Speaker: SPEAKER_02
Transcript:  It didn't disrupt our internal operations, even though we use Google Drive and stuff,  because we're out here in California and it apparently didn't affect us as much.

Speaker: SPEAKER_01
Transcript:  For once, my apps account was fine.

Speaker: SPEAKER_02
Transcript:  And you were fine?

Speaker: SPEAKER_03
Transcript:  I was fine.  I was fine, but I am sad because I didn't have any of my Google stuff in. Oh, I couldn't actually  check the weather. I tried to check the weather on my phone and it was not working.

Speaker: SPEAKER_02
Transcript:  Yeah. So Google, it seemed it was mostly in the northeast, but then Seattle did seem to  have some hot spots. Google's explanation. Yesterday, a disruption, yesterday, Sunday,  a disruption in Google's network in parts of the United States caused slow performance,  elevated error rates on several Google services, including Google Cloud, YouTube, Gmail, Google  Drive, and others. It impacted people trying to watch us on YouTube, but it couldn't.  Because the disruption reduced region. This is the thing that seemed kind of not completely  accurate because the disruption reduced regional network capacity. Yeah, by a lot, like to zero,  in some cases, the worldwide user impact varied widely. For most users, there was little or no  change to their services. So the root cause, they say, was a configuration change intended for a  small number of servers in a single region. But there was an error that applied that  configuration to a large number of servers across several neighboring regions and caused those  regions to stop using more than half of their available network capacity. After talking to  some network experts, I found out that Google, all services are not created equal on Google.  Some services are a higher priority. There's quality of service, just as there might be in  your home if you want to watch TV versus if you want to read email or a web page. And that is true  of all the Google services. And the problem is this configuration, which was intended to make  servers use less bandwidth, was then extended to too many servers. And servers that were actually  mission critical were offering important services, would normally be highly prioritized, were down  prioritized. The network traffic they continued from and to those regions then tried to fit into  the remaining capacity, but it did not. So it's kind of like Chernobyl. It melted down. No, because  you would think that if some servers then went down to half capacity, it'd leave more room for  other services. But because those services were trying to jam their way into the constrained

Speaker: SPEAKER_03
Transcript:  services, everything stopped working. Yes. And what this actually, I didn't really, this makes  me wonder how close to capacity Google runs at all times. Yeah. That's actually what I was thinking.  I was like, oh, I always felt like they had more overhead, but maybe they don't. They kind of just

Speaker: SPEAKER_01
Transcript:  try to like turn off things until it's needed. Yeah. Think about it. You don't overhead is cost.

Speaker: SPEAKER_02
Transcript:  You don't want too much headroom because if you have, and this was the problem. I mean,  I think about other network situations like on live, remember the streaming gaming service,  the predates Google Stadia on live. Their problem was that at peak times, it required far more  servers than they had. And most of the time they could handle it, but they couldn't afford to have  all the servers available that they needed for peak hours. So Google, I'm sure in Facebook and  other massive operations constantly adjusts. I'm sure the bandwidth they consume and the servers  they have up and running in any event, they said the networking systems correctly triaged the  traffic overload, dropped larger, less latency sensitive traffic in order to preserve smaller  latency sensitive traffic flows. They, I think poorly analogize that to urgent packages being  couriered by bicycle through the worst traffic jams. I mean, it gives an accurate picture like,

Speaker: SPEAKER_03
Transcript:  cause it is true. Like you're like, Hey, why does this work when this doesn't? Yeah. Yeah. It wasn't

Speaker: SPEAKER_02
Transcript:  like it Google was down entirely, but it was just, uh, some was, some wasn't. Google's engineering  teams detected the issue within seconds, but diagnosis and correction took far longer than  our target of a few minutes. They, in other words, they knew what was going on, but this is why it's  like Chernobyl. The same network congestion that was creating service degradation also  made it impossible for them to correct the outage. It's like the same traffic jams.  They couldn't get in. They couldn't get in. The Google teams, this is the drama. And I want to  see this as a mini series in HBO. The Google teams were keenly aware that every minute which passed  represented another minute of user impact and brought on additional help to parallelize  restoration efforts in effect parallelized. You like that? It was parallelized  and which we were all paralyzed as a result. It's they hit AZ five and nothing happened.  I'm sorry. I just finished Chernobyl. I'm making a little bit like Chernobyl.

Speaker: SPEAKER_03
Transcript:  Well, a network congestion, depending, I mean, the way, the way you do routing anyway,  once you have congestion, your packets are going to keep sending until they're delivered,  which means congestion begets more congestion, which begets more congestion.

Speaker: SPEAKER_02
Transcript:  Exactly. And then really it just shows you how reliant we are on Google and how  responsive Twitter is because they say overall YouTube measured a 2.5% drop of views for one  hour, like nothing. Google Cloud, though storage represent a 30% reduction in traffic. 1% of active  Gmail users had problems, but it sounded like all of Gmail was down. If you followed it on Twitter  or a chat room, it sounded like, I can't, my Gmail's not working. Of course, if you're even on a  Sunday, if you're a business that runs on Gmail, that's not good. So they're doing a post-mortem  and I'm sure that they'll have a show trial and some engineers will be shot.

Speaker: SPEAKER_03
Transcript:  That is not how you do this because otherwise people will become like Chernobyl and hide their

Speaker: SPEAKER_02
Transcript:  mistakes. In fact, they didn't, that's what they said the Legos off. We'd kill you, but  it wouldn't solve anything. Everybody noticed.

Speaker: SPEAKER_03
Transcript:  I would say that, you know, anytime I know that Google lost a lot of market value and everyone  suddenly was like, Oh my God, we're highly dependent on Google and Amazon and Microsoft  for a few, you know, a few companies for our big services. But I would also say  having these kinds of post-mortems, even if this isn't as detailed as maybe we want,  That's pretty good. It's got, it's pretty good. And I guarantee that if you are, well, not Netflix,  but if you're a Snapchat or somebody who's actually a big Google customer, you're getting

Speaker: SPEAKER_02
Transcript:  way more detailed than this. Yeah. And I imagine somebody who can understand it could find out  more. I mean, you know, what was the configuration error? Was it a BGP issue or  issue or, you know, what exactly was going on? But I think they gave enough details for people  to read between the lines. I read a bunch of comments on hacker news, talk to people  and engineers who understand these things seem to kind of understand what was going on.  So yeah, there you go. Well done. Mission accomplished. The best part though,  was the Google engineers working in the nude all night to, to get it working.

Speaker: SPEAKER_03
Transcript:  Wait, there was, that was not in there. That wasn't there. That didn't happen.

Speaker: SPEAKER_02
Transcript:  Like, wait a second. I'm sorry. Chernobyl Chernobyl.

Speaker: SPEAKER_01
Transcript:  Did you turn over? I don't want to picture panic worse. Yeah. Well, yeah. Well,

Speaker: SPEAKER_02
Transcript:  yeah, I don't know. It certainly made me think maybe we don't want more nuclear power.

Speaker: SPEAKER_01
Transcript:  Facebook is not nuclear power. Just remember that. Okay. Well, speaking of moral panic,

Speaker: SPEAKER_02
Transcript:  here comes the tech lash because Congress now says we're going to investigate Apple, Facebook,  Google and Amazon. The FTC and the F and the department of justice apparently divided  their attacks. The FTC will be going after Facebook, department of justice, going after  Google investigations. But, but I think the tech lashes is, is, is upon us.

Speaker: SPEAKER_01
Transcript:  Well, the problem now is it becomes impossible to separate out concerns versus politics.  And, and, and, you know, there's, there's the right and the left of both going after the platforms.  And given that I don't want to get too political here, given that the chief executive of the  nation just this week tried to go after AT&T just because he doesn't like CNN, you know,  what's the motive? You don't know. The people screaming for blood,

Speaker: SPEAKER_02
Transcript:  Kara Swisher in the New York Times yesterday, the people screaming for blood have no idea  how tech actually works. Suddenly regulators guns are blazing, but it looks thoughtless  and is likely to prove pointless. She says she's always thought there should be some guard rails

Speaker: SPEAKER_01
Transcript:  on technology. And I respect Kara immensely, but I think that she lately has been part of the cause

Speaker: SPEAKER_03
Transcript:  of the tech lash. New York Times has that's for sure. I think she has been pointing out legitimate  issues and has been for a long time that have led to this. The problem that she's writing about is  that what's going to happen here is now that everybody's on board, she's concerned that  they're going to, again, let politics control this and they're not going to be sensible. They're  going to have these knee jerk reactions, which is how we pass laws in this country for the last

Speaker: SPEAKER_02
Transcript:  20 to 30 years. I would agree with her, but I think she, as all of us in the tech press,  we're all a little bit guilty of cheerleading as we march down the path to tech giants.  Maybe we could have averted this by urging them to be more judicious from day one. Maybe not.

Speaker: SPEAKER_03
Transcript:  But I have, I don't think we have. I think most of the responsible tech journalists,  I am very excited about a lot of things like IoT can do, but I have never been unaware of the  privacy and surveillance areas and the ways it can be used for ill. And I talk about those,  and I think most responsible tech journalists have, and most of us have been calling for  regulation. I mean, I've been calling for regulations forever and people hate me for it.

Speaker: SPEAKER_02
Transcript:  I apologize. I said the DOJ and FTC split the baby, but FTC did not take Facebook,  they took Amazon. Sorry, it's Congress is going to take Facebook. So Google goes to the Department  of Justice, FTC takes on Amazon. Although when you hear that there is an FTC task force to  monitor competition in the US technology market, you feel like, okay, task force,  that's one way of saying we're not going to do anything, but we're going to look like we're  doing something. I hate task force. We're establishing a committee. And I think-

Speaker: SPEAKER_01
Transcript:  So I put up my, I thought last week I talked about the efforts to come up with some sane regulation  and part of this working group on- Oh, wait a minute.

Speaker: SPEAKER_02
Transcript:  On net regulation. My Lenovo alarm says it's time to get up.  Hey Google snooze.

Speaker: SPEAKER_00
Transcript:  All right. I'll give you 10 more minutes. 10 more minutes.

Speaker: SPEAKER_01
Transcript:  All right, Jeff, keep talking. And then it's harder to say that than it is to just hit something.

Speaker: SPEAKER_02
Transcript:  Can I just say stop now? Isn't that one of the things you can do? Or is that,  yeah, they could, they said I could say stop. I don't think it's, is it, is it rolled out yet?

Speaker: SPEAKER_03
Transcript:  I tried to do it. I'll try it. Stop. You really, you really should test it. It should be like,  this is-

Speaker: SPEAKER_04
Transcript:  Shut up.  Shut up.

Speaker: SPEAKER_02
Transcript:  This is-  Okay, F in Google.  We, we, we, this is the new $90 Lenovo, small little Lenovo desk or a table side clock for your  bedroom. That's mostly a clock, although it does play music. Actually, it's a surprisingly good  speaker. There's my calendar. What's the size? It's very small.

Speaker: SPEAKER_03
Transcript:  Does it display anything else like photos or-

Speaker: SPEAKER_02
Transcript:  No. And see, I like it's, it's about the same price as the Home Hub, maybe 10 bucks less if  you shop around. And I think the Home Hub with a bigger screen and doing things like that is  probably a better choice for most people. But if you just want a little thing, it's a clock. It's  about the size of a little alarm clock.  There's no camera in that, right?  There's no camera, but there isn't in the Home Hub either.  Yeah. It's, you know, it shows you the way you can show the weather and what time it is. And  it's telling me I got eight, 40, eight minutes, 40 seconds left till the alarm goes back off.  And I don't know.

Speaker: SPEAKER_03
Transcript:  Okay. Let's keep talking about politics because it's a wonderful little break.  It should be heated.

Speaker: SPEAKER_02
Transcript:  And it should be, it should be 30 bucks. I don't, the speaker's decent though. I'll play some music  at some point and the speaker's decent, but I feel like it should be less expensive.

Speaker: SPEAKER_01
Transcript:  Go ahead, Jeff. Sorry.  Oh, I'm just saying that on this topic last week, we talked about, um,  I gave a report from the Facebook, uh, Oversight Board working group. And, uh, I talked about the  book, um, 26 words that created the internet. So anyways, I have a long, you know, five year  read post on medium, uh, recounting all of that with links and everything on medium. So just,  we won't bore you again, audience.  Yeah. I mean, I,

Speaker: SPEAKER_02
Transcript:  I was likening this during windows weekly to, uh, a watchmaker with a very, uh, elaborate watch,  trying to fix it with a hammer that the, this is a, these are complex mechanisms, complex,  and they're very integrated into society and our economy now. And I don't think Congress,  I don't know if Congress can come up with the right.  No, Congress is not, but, but, but even the French, even the French came up with what I think is a,

Speaker: SPEAKER_01
Transcript:  uh, no offense French, but it is a sensible regime, which again, we talked about last week  of holding, getting platforms to make covenants with their public, what they're going to do,  and then hold them accountable for doing that. And I'm, I'm cool with that.  Don't we kind of already do that with privacy statements? Isn't there enforcement?

Speaker: SPEAKER_02
Transcript:  No, no, cause no one reads them, not even Congress, but so I would say let's, let's,

Speaker: SPEAKER_03
Transcript:  okay. I know that we're actually possibly thinking about maybe doing something that's  now here, but all the way back in 2014 and maybe even 2013, the FTC actually put out some really  good research on data privacy and how to look at that and think about that. So if it looks in,  in it, did a task force and all this. So if it takes that kind of information from a few years  back and tries to implement that, that's not a bad idea. And that's actually not knee-jerk.  Maybe it's like, oh, now the time is right to actually do something. If it pulls some of the  stuff that it, it has available to it, that could be good. If we start from scratch though, I'm kind  of like, we'll never get this done and it'll be stupid. I'm terrified though. I'm really terrified

Speaker: SPEAKER_02
Transcript:  that these will be like Ned Ludd throwing, you know, hammers into the looms. It'll be,

Speaker: SPEAKER_03
Transcript:  no, that's just, no, that's, that is what they want you to think. There are reasonable outcome  based decisions and rules that we can put into place. And I would encourage you actually to go  back to the 2014 FTC report around data privacy, because they actually foresaw a lot of these  issues and they talked about ways to make it less onerous on the companies, but still like

Speaker: SPEAKER_01
Transcript:  more transparent and protective of users. Right. I just got another new book.

Speaker: SPEAKER_02
Transcript:  Time to read this stuff. Speech Police, the train rides speech police, the global struggle

Speaker: SPEAKER_01
Transcript:  with government, the internet, but David K. David K is spectacular. He is the special UN special  rapporteur for protection of the right to freedom of opinion and expression. He's a law professor  at UC Irvine. I've, I've met him and been on task forces lately with him and I'm going to  read this tomorrow on the plane to Athens. Oh man. It's good thing you travel a lot.

Speaker: SPEAKER_02
Transcript:  That's also how I get stuff. Yeah. So GCHQ, the British spy agency has proposed a kind of crazy,  and by the way, not, not, it's not a law. They're just saying, maybe we could do this.  A crazy idea. We do things without laws. Yeah, that's true. They don't really need laws  to create a, a ghost participant in every encrypted message conversation that can kind  of snoop on it. In other words, we don't have to break the encryption. We just have to allow,  have you allow us to join every encrypted conversation. That's ridiculous. Google,  WhatsApp, Apple, and 47 other companies, uh, sent a strongly worded open letter to,

Speaker: SPEAKER_03
Transcript:  to having the key to the locked room where you're meeting. Let's just put someone in there. Yeah.

Speaker: SPEAKER_01
Transcript:  So explain something to these smart people. Um, so I saw a story last week. I didn't put on the  rundown. I can't remember where I saw it, but, but, you know, fear is that AI will mean that  encryption is dies because it is possible to, I guess, brute force go into encryption. So what,  what is the answer here? No, no, no, that's not true. Quantum computing. Yeah. Also something

Speaker: SPEAKER_03
Transcript:  that doesn't exist. Okay. Right. Well, and there's, okay. So encryption, like,  it's basically a mathematical cipher and you have different versions of encryption.  I think currently the strongest is still AES 256. Is that correct? Yeah. Um, it's the,

Speaker: SPEAKER_02
Transcript:  it's the gold standard. There is stronger. There's elliptical curve crypto. There's stronger stuff.  Basically it's a hard math problem, but as computers get faster and they'll have to get  exponentially faster, the fear is they'll get fast enough to crack these in a reasonable time frame  right now with the ECC elliptical encryption, elliptical curve encryption. It's, it's millions  of years or trillions of years or the lifetime of the universe, depending on how fast your computer  is to crack these. But if quantum computing ever gets working, which it's not even close to doing,  I might point out, um, in theory, it could be fast enough, but then you just come up with better  harder math problems. So I actually talked to some companies who are building chips that are

Speaker: SPEAKER_03
Transcript:  quantum key resistant or quantum resistant. And they're really, yeah. And they're interesting  because they're doing random and these are, these are DARPA funded chips, but what they're doing is  they're doing the way you make a semiconductor is you, you basically layer on different materials  and then etch away at them in certain patterns. That's very basic. What they're doing is they're  doing randomized patterns being etched and you'll match that to a key. And so the idea is that you  can't break that even using quantum computing because it's, it's just so random. So chaotic.  Yeah, exactly. So that's, that's, again, this is far, this is research level stuff. This is not in  the real world, but it's, it's pretty cool. Um, so the point is you don't have to worry about quantum  encryption yet because we don't have quantum computers, but there are really smart people  already worried about it. So when that time comes, it's hypothetical. I wouldn't worry about it.

Speaker: SPEAKER_01
Transcript:  Yeah. So last week we talked to about, about quantum random number generator. Yes. Is that  useful in better encryption? No, that's a different thing. I said smart people explain these things to

Speaker: SPEAKER_03
Transcript:  me. I'm not laughing at you, Jeff. I'm laughing at like, Oh, I'll just put quantum in front of it.  Well, it's, yeah, it's a little bit like that chain with cold fusion power. Exactly.

Speaker: SPEAKER_02
Transcript:  Exactly. I, I think that's, there are many people who think the notion of quantum computing is  either maybe impossible or maybe cold fusion impossible, or maybe just so far off. We don't,  it's not, we're just so, I mean, so impractical. Yeah. Well, that's why it's far off. It's like,  you know, cold fusion is not impossible. It's just impractical. Does Microsoft have IBM? They all

Speaker: SPEAKER_03
Transcript:  have quantum computers technically running. So do they? Yeah. Google, Google, Lockheed Martin,  Google quantum computer. I know IBM has that thing. Yeah. And IBM, you know, they've,  their Almeida labs have some crazy stuff. I have been there and seen the crazies. They're fun.

Speaker: SPEAKER_02
Transcript:  I can't figure out if this is a joke or not, but apparently Schrodinger's cat,  Schrodinger's cat, a team of Yale researchers, I think this, I thought at first this is the onion.  A team of Yale researchers blew the lid off one of quantum computing's biggest problems,  the unpredictability of qubits, what's being dumped, dubbed a beautiful experiment. The team  discovered how to catch an artificial atom mid quantum quantum quantum quantum quantum quantum  jump and interfere with its outcome. In other words, to save the life of Schrodinger's cat.  And don't worry, it's, it's all theoretical.  Honestly, I know IBM is using the word quantum computing. I do not think it means what they

Speaker: SPEAKER_03
Transcript:  think it means. No, no, they have, they have held, they have actually managed to both  generate and I think it was eight qubits and a qubit is the quantum version of a bit. It's the,

Speaker: SPEAKER_02
Transcript:  it's multi-dimensional. Yeah. That was like, it's not as you're

Speaker: SPEAKER_03
Transcript:  going to need to make the arc. That's right. But, oh, there you go. Yeah. They did it.  I shouldn't be quite in the, because the challenge is it has to be really cold and they're very,  they collapse very quickly. So the challenge you're looking for in quantum development for  computing is how long your qubits can actually stay around and how cold you need to keep it.  And then how much power you need to make the whole thing run. And right now that's where  more of the research is. Yeah. Did that make sense?  Yes. Okay. We can stop talking about quantum. In fact, that is why that, that whatever study out

Speaker: SPEAKER_02
Transcript:  of Yale, the experiment out of Yale is so important. It's still,  you're not going to be using a quantum computer anytime soon. I don't think.

Speaker: SPEAKER_01
Transcript:  When, when the robots are quantum power, you watch out people.

Speaker: SPEAKER_03
Transcript:  Well, again, what does that mean? I'm going to tell you, they have, let's see,  they have built a circuit according to, I'm, y'all talk about something else.  Do you really want to know or not? Yeah. Okay. She's reading.  So IEEE spectrum in March, there's an article, Google builds circuit to solve one of quantum  computing's biggest problems. To solve that. That's the qubit problem.  Yes. It's a 72 qubit quantum processor. Check out the picture. This, this shows you how far off we

Speaker: SPEAKER_02
Transcript:  are. Actually. Well, that's what I'm saying. And by the way, this is 72 qubits.  And I don't even know if it's stable. I mean, I think there's all sorts of issues.

Speaker: SPEAKER_03
Transcript:  Wow. They have 168 coax cables going into the refrigerator and connecting to the 10.  Yeah. Oh, by the way, it's a.

Speaker: SPEAKER_02
Transcript:  Millikelvin quantum processor. Wow. Yeah. It's a cryogenic enclosure  that is basically an absolute zero. Okay. I'm sure I'll have one of those in my phone soon.

Speaker: SPEAKER_03
Transcript:  It's running at more than 200 degrees below what silicon foundry simulation mobs can deal with.  That's awesome.

Speaker: SPEAKER_02
Transcript:  Yeah. I don't, I don't think this stuff is that stable. I just, I don't know, maybe I'm wrong.  I'm sure I will get emails from somebody who says, well, actually I'm staring at a quantum  computer right now. You can bring on the D wave guy, have them come back and tell you what it's

Speaker: SPEAKER_03
Transcript:  about. Yeah. Those guys are fun. I think there's a lot of.  They've been with us for 20 years. Fogosity in, in some of this stuff.

Speaker: SPEAKER_02
Transcript:  In, in some of this stuff, but okay, whatever, whatever.  Let's take a break and then we're going to talk about YouTube because holy cow, what's going on  at YouTube. This was a busy time last couple of days for YouTube.  It's possible that they were the ones who shut themselves down on Sunday and then we're wishing  they couldn't come back. Just don't just die. Can we get a break?  Please. We got to, we need a break. Our show today brought to you by WordPress. I'll tell you what,  it is absolutely the case. The web is still here. It's still present. In fact, you ought to have a  website, even if you're a YouTube star or a Facebook maven or a Twitter to wampus, you need  a WordPress site because having that website puts you on the web. It's the first thing people find  when they search for your name. It's the place where you could put all the best stuff. And you  know what? If you don't have a website, it leaves a vacuum. Others will fill the best place to create  that website, wordpress.com as an individual, as a business, there is no better place. First of all,  33% of the internet runs on WordPress. 33% of the internet runs on WordPress. That's because  it's easy to use. It's powerful. It's just dominant. WordPress.com hosts it for you.  It's the same people. It's automatics, the WordPress people, but they do the hosting. They do the  security. They do the patching, the updating. And most importantly, your WordPress support team is  there 24 seven. And it's not just somebody reading a notebook. These are people who live, breathe and  eat WordPress. They know it backwards and forwards. And that means you're getting help from a true  expert. WordPress has the best site building tools, thousands of themes, a very vibrant ecosystem,  no two week trials, no hidden fees. WordPress.com was started so that anybody could publish their  ideas. And it's free to start, but it always has room to grow. You know, you want more,  you can have e-commerce. I've been a wordpress.com customer for 12 years. It's the best. And they are  there to help 24 hours a day, flexible, powerful. Some of the biggest companies in the world like  Fortune use WordPress for their website, Quartz. And millions of people use WordPress every day,  including me, leolaport.com is my WordPress site. WordPress.com slash twig. If you go there right  now, you'll get 15% off any new plan purchase. And it's a great way to show your support of the show.  WordPress.com slash twig. We thank WordPress so much for their support of this week in Google and  for keeping alive the whole notion of a free and open web WordPress.com slash twig.  So YouTube, YouTube, YouTube, where to begin? I should, I should begin with the newest stuff,  which is that YouTube has announced this morning that they are going to go even farther  to ban extremist hate. So this was the blog post this morning on the YouTube official blog,  our ongoing work to tackle hate. They say and point out, you know, we've always done this,  we've always had a great policy, blah, blah, blah. They also, wow. They also say some of this content  has value to researchers and NGOs looking to understand hate in order to combat it. So we're  exploring options to make this content available to them in the future. But meanwhile,  we're taking another step in our hate speech policy by specifically prohibiting videos.  And here are the criteria. I'm always looking for what are the criteria? Videos that allege that  one group is superior in order to justify discrimination, segregation or exclusion based  on qualities like age, gender, race, caste, religion, sexual orientation, veteran status.  So this would include, for example, videos that promote or glorify Nazi ideology, which is  inherently discriminatory. Really, that's good to know. Finally, we'll remove content denying  well documented violent events like the Holocaust or Sandy Hook. We begin enforcing this policy  today. No one knows, but it's estimated that thousands of channels will get banned,  but it will take time for our systems to fully ramp up over the next several months.  YouTube has been under continuous pressure. Most recently, the Crowder, Louder Crowder channel.  This story came out yesterday that Crowder, who was a conservative, it's really more like a,  I watched a little bit of it, it's more like a morning show. He's kind of copying,  I would say copying to some degree, Howard Stern. He's been critical of a Vox video columnist,  Carlos Maza, attacking his sexuality, his ethnicity, making fun of him in a kind of shock jock way.  So at first, Google's YouTube said, nah, you know what, this kind of does not violate our policies.  We're not going to shut down his channel. This is a very, very, very, very, very, very, very,  this morning they announced we are going to demonetize. We're going to, so he has a channel,  still louder with Crowder, but update on our continued review, we've suspended this channel's  monetization. We came to this decision YouTube tweeted because of a pattern of egregious actions  that's harmed the broader community and is against our YouTube partner program policies. So they're  not blocking it, but they are going to keep him from making money. Oh, sorry. There you go.  I was wondering why it was so quiet over there. Oh, hey, hey, hey, you'd been muted.

Speaker: SPEAKER_01
Transcript:  I saw something else and I don't know how true this was, but said that he wasn't fully demonetized  that if he takes down his t-shirts or something else, I don't know. He had, he had t-shirts that

Speaker: SPEAKER_02
Transcript:  weren't exactly anti-gay, but they weren't exactly friendly either. Maza has been, you know,  livid, rightly so. I don't blame him. What do you think, Jeff? I mean, you, you, you know,  Howard Stern's not recently, this is the new Howard Stern, but in the past he's done stuff like this,

Speaker: SPEAKER_01
Transcript:  right? No, I don't think he's, no, I don't think he's ever been hateful. But the problem is how  you define hate. When I sat in the Facebook workshop on its oversight board, I got uncomfortable that  the word, you know, hate speech was thrown around all the time is, it's kind of being anything.

Speaker: SPEAKER_02
Transcript:  So Crowder called Maza, I won't play the video, I watched it. It's all done in this humorous  fashion. He's got his zoo laughing at him, called Maza a lispy queer and a gay Mexican.  That sounds nasty and hateful. I don't know if it's hate speech.

Speaker: SPEAKER_01
Transcript:  Hate speech, right. That's what the problem, we, we, we, we're devaluing the label of hate speech.  And that's what I worry about. So that anything becomes hate speech and then nothing is hate  speech. And that's, that's going to be a problem. We've got to, we've got to have discussion about  that. I mean, listen, I think that Google is a company, YouTube is a community, YouTube has  the full right responsibility to have a decent experience. And I think they should take this  crap down. However, there are implications, right? One is that this does force these folks more  underground and it's going to be harder to ferret out. And that's always the problem here. And  number two, listen, this is the obvious stuff. If you look at something like it, I'm going to get  in trouble here. PragerU. It's very slickly done arguing that, oh, hey kids, there's a war against  men. Did you know that? Hey kids, the civil war, was it really about slavery? And very, very slickly  done. I learned this from our friend, Joan Donovan and Dana Boyd. And the problem is it's  not hate speech. You can take it down, but it's, it's very effective. And the problem for the  YouTubers of the world is there's nothing kind of on the opposite side of it. I mean, the extreme  of this is you can find lots of videos denying the Holocaust, but not so many verifying the Holocaust  because who thinks you need to? Well, in this world-  You don't see a lot of videos saying the world is round.

Speaker: SPEAKER_02
Transcript:  Right. Right. Who thinks you need to? Actually, if you do, it's solely because of so many flat  earth videos. In other words, it's bringing out the demonstrators, no, no, wait a minute, slow down.  It is round and I can prove it. Now I have to say there is a certain hypocrisy in YouTube waving  rainbow flags celebrating pride month. On the one hand, in fact, they financed a documentary called  State of Pride and on the other hand, allowing homophobic slurs on some of their-

Speaker: SPEAKER_03
Transcript:  But, okay, was this bad enough for Banning? Well, again, is it a neutral platform? Is it a  community? That's a really tough question.  And it's fine to say this isn't in my community. And to the idea that this would go further  underground, in a lot of ways, I'm okay with that because like my kid is on YouTube, for example,  my kid isn't searching out the weird, the dark area. She's not on the Reddit, you know,  slash she's on the Reddit slash corgi page, but she's not on the Reddit slash, you know,  I hate the Jews page or whatever. I don't frequent the darker corners of the internet. So,  you know, in some ways, I mean, I see your point, Jeff, but I'm also like,  if we're going to say YouTube is this fun gathering area for videos, then it makes sense  that we should treat it like a community and say, yeah, you know what, do not call someone a,  what was that, a sleazy, Mexican queer or something, you know, that's, we don't want  that on our site. We don't want active docs. Yes. But then, you know, when I learned this,

Speaker: SPEAKER_01
Transcript:  talking to all these people who do this work, I've talked to people on all the platforms that  are doing this work and they need rules. So the example I used up on online is the Nancy Pelosi  slow down speech video. Kara Swisher was saying, take it down. Everybody's saying, take it down.  Well, I put right underneath that the video did the exact same thing to Donald Trump.

Speaker: SPEAKER_02
Transcript:  Yeah, we don't. We did it last week. We showed it.

Speaker: SPEAKER_01
Transcript:  Right. I did. I last. Okay. Yeah. Should that be taken down? Where's the, they need  rules that can be enforced with some predictability, some fairness, I would say.

Speaker: SPEAKER_03
Transcript:  So what about conversation? And, you know, when you were talking about slavery, for example,  I grew up in Texas and in Texas, when I was growing up, and for all I know, it's still the case,  I was taught that the Civil War was a state's rights issue.

Speaker: SPEAKER_02
Transcript:  There's a big statue right in front of the state house in Austin.  There is.  A state's rights statue.

Speaker: SPEAKER_03
Transcript:  It was in the textbooks. I mean, this was something that was taught to me. And it took me  until, you know, high school when I finally read the People's History of the United States that I

Speaker: SPEAKER_02
Transcript:  was like, holy shit, I've been lied to my whole life.  One particular right that the states wanted. And it was an abortion, by the way.

Speaker: SPEAKER_03
Transcript:  And so I would say that there are some things that, you know,  we're still having discussions about this. And I think it's, I mean, in my mind, I would like,  yeah, Google or sorry, YouTube, you should not have that. But I'm also like,  that is not actively inciting hate against an individual, especially an individual who has  no power, perhaps.

Speaker: SPEAKER_01
Transcript:  Right. Well, the worst thing, you're right, is that when other people get inspired by it  and they have no power to deal with that, that's the real problem here.

Speaker: SPEAKER_03
Transcript:  So I, well, I don't know if it's, if there's a lot of real problems here, but  we have to think about what is, what the end result of some of the videos would be and how  much agency the person being attacked has to solve it, rectify it, or protect themselves, perhaps.  And that might be another way to think about how we formulate these rules. So  are you attacking an individual? Are you attacking a whole nation? If you're attacking a whole nation,  yeah, that sucks. And you're a real jerk. But is that some, is that enough? You know, I don't know.  So that's one way to maybe think about this. It's not going to get rid of everything.

Speaker: SPEAKER_01
Transcript:  But the other question, and I'm playing devil's advocate here. So again, I think that the community  needs to have a community standards and needs to be responsible for them. So I'm, you know, I'm,  but I'm a free speech advocate. And I think generally this, this notion that we can tamp  down and get rid of and play whack-a-mole with what we consider bad speech is a real problem.  So the post that I wrote, I explored this idea that I talked about a little bit last week,  that regulating content is inevitably going to be a mistake. Regulating content requires  that you have context about the intent and the impact. And so what you're really regulating is  behavior. And that's harder, but that's what's really happening here. And so what we have is  governments and media people saying to the platforms, you must regulate this behavior.  We don't want to do it. It's your job to do it. We're not going to set the rules. We're not going  to define anything here. It's harmful. You're going to get rid of this. Well, they're regulating  behavior and that's okay. We should, should you regulate bigotry?

Speaker: SPEAKER_03
Transcript:  Yes. Okay. Well, hold on. Stop using the word regulate just for fun and accuracy,  because this is, this is not a government. So let's talk about, but there's also,

Speaker: SPEAKER_01
Transcript:  but it stretches to that, like the UK harm. Don't stretch right now. Cause that's a slippery

Speaker: SPEAKER_03
Transcript:  slope. We're not going to go there. So just for, you know, fair argument, let's call it what it is,  which is, you know, uh, guidelines or moderations. Yeah.  And except, okay. I think it's important to look at it. And, and I'm going to stick with this  because I do think this is a good distinction to talk about. And we don't usually talk about it  is how far that content goes. And I know moderation is tough, but I do think  if I am a person who's being attacked and I bring something up that it is in,  and YouTube does have community guidelines already in place. I think they need maybe a  better process for people making complaints and determining if they're legitimate and taking it  down quickly. Um, and I think there's the, that same, and maybe like you said before,  maybe it's a court kind of structure. Cause I think, you know, you could argue that Pelosi  versus us slowing down or someone slowing down Trump, you know, those might be enough in the  public interest, public interest or newsworthiness. I don't really know that you would keep those up,  but attacking an individual is probably not an individual that is not a public figure, for example.

Speaker: SPEAKER_02
Transcript:  Right. Do you think we're, do you think, uh, so there are, I mean, there are systems, there's  there, it's new and we're still trying stuff out, but we've got systems, for instance, with the  Pelosi video, uh, Facebook would pull up, uh, additional links and sources perhaps, or say that  the, there's some question about the authenticity of this video. By the way, the video seems to have  disappeared completely from Facebook for whatever reason. Um, but I think that there seemed to be,  we're seem to be making progress perhaps in not necessarily pulling stuff down, but, but adding  additional information. Is that sufficient?  Yes. So that's what Facebook did with the Facebook. I talked to people there about this.

Speaker: SPEAKER_01
Transcript:  Um, they will confess that primary problem of the Pelosi video was they didn't act quick enough.  It took too long for them to see what it was. Um, once it, but they, you know, Facebook always says  we have three actions. We can downgrade, we can add, we can, we can kill and we can add information.  They try not to kill, uh, for I think decent reasons downgrading is them taking personal  responsibility, not our corporate responsibility, not to promote something, but that's really,  by the way, the big question with Google as well, which is their recommendation, engine, engine

Speaker: SPEAKER_02
Transcript:  promoting this, inadvertently promoting that's where, that's where they step in.

Speaker: SPEAKER_01
Transcript:  And that's where their role really is sufficient to say, don't promote stuff in most cases.

Speaker: SPEAKER_02
Transcript:  I think generally, and then add that third thing and add information.  You say people didn't know this. So the problem there though, is there isn't sufficient research

Speaker: SPEAKER_01
Transcript:  and sufficient data to know the impact of those informational boxes. We do know in the case of  Facebook, that when they added things to say, it said this had been challenged by fact checkers  that created more traffic for it and more people believing it.  Isn't that weird, but you can't fix stupid. I mean, honestly, there's so much these platforms.

Speaker: SPEAKER_02
Transcript:  I mean, honestly, there's so much these platforms can do.

Speaker: SPEAKER_01
Transcript:  You've got to be aware of the interventions impact as well.

Speaker: SPEAKER_02
Transcript:  Um, and so, so, you know, but I think that's doing the right thing and not blocking it,  not banning it, adding context, not promoting it either. In other words,  staying fairly neutral and adding context on it. That seems to me the right thing. Anything more  seems to me weighing in a little to putting a thumb on the scale a little too much.

Speaker: SPEAKER_03
Transcript:  Well, it kind of depends on, I mean, I think some of the stuff you would want to put your thumb on  the scale more, like some of the stuff merits greater intervention, not everything, but some  things. And I would say like a tax against an individual person rise to that occasion.

Speaker: SPEAKER_02
Transcript:  Yes. Okay. I agree with you. There's, but those things are illegal too. I mean, there's certain

Speaker: SPEAKER_03
Transcript:  things- Or actually I would also say if you could definitively prove that this is a bot activity,  I would say that might rise to the occasion. That would be a good one too.

Speaker: SPEAKER_02
Transcript:  If it's not real people, if it's being done in a concerted campaign for other reasons, maybe.  Well, there's- But you know, I watched last night, I watched Cabaret, the original Bob Fosse,

Speaker: SPEAKER_03
Transcript:  1972 Cabaret, which I- Okay. Like, let's make this connection.  Are you ready? Money, money, money, money, money, money, money, money, money.

Speaker: SPEAKER_02
Transcript:  There's a lot of Nazis in it. And there's Nazis not, I mean, the movie is about Berlin  as in during the rise of the Nazis. I know people think it's about, you know, life is a cabaret.  And I guess on Broadway originally it was, but by the time Fosse got ahold of it,  it became a movie about the rise of Nazism. But it did it kind of-

Speaker: SPEAKER_01
Transcript:  No, it was on Broadway too. The book, the original book was-

Speaker: SPEAKER_02
Transcript:  Was about that. Broadway was a little happier. Fosse added some stuff and decided to make it  a little bit grimmer. But nevertheless, in some ways showing it without commentary or  maybe the way he juxtaposed images perhaps is more powerful than saying, no, no, no, no,  don't show any of that. So showing stuff in context versus burying it, I'm not sure  burying it is always the right, I mean, that's the solution Germany has chosen. They don't want to  see anything like that. So I don't know. But I think the risk of burying it is you forget it.

Speaker: SPEAKER_03
Transcript:  Well, yes. And I think some things, some things probably should be buried, but they're always  going to come to light eventually, I guess. So yeah, I don't know. I mean-

Speaker: SPEAKER_02
Transcript:  As human beings, we love making the other evil and wrong and bad. It's a very natural thing to do.  So instead of pretending we don't do that, maybe we should show it and show it in context and show-  That's the key. I think that we can protect-

Speaker: SPEAKER_03
Transcript:  Even when you show things in context, people will take from that what they will.

Speaker: SPEAKER_02
Transcript:  And as I said, there's no fix and stupid because people are people.

Speaker: SPEAKER_01
Transcript:  You can't put a condom around the world's brains.

Speaker: SPEAKER_02
Transcript:  Yeah, I think that's the real risk. I think a lot of people-  That would be ineffective in the first place.  It's a great image though. I think that that's the problem is that there are people,  and maybe Elizabeth Warren is one of them, who want to protect everything and you can't.  You can't.  You can't. And maybe the electorate is stupid. I think there's a lot of evidence.  Yeah, the cure here is education.  Yeah, let's promote education. Let's give people the tools they need to judge these things.  But if somebody's going to look at Louder with Crowder and say,  Yeah, those gay people lisp. I hate that. What are you going to do? There are people like-  I mean, what are you going to do?  Actually, it was interesting because in Cabaret, Michael York's character does stand up and says,  You're a dunderhead or whatever. And he gets beat up as a result, but he chooses to fight them.  Everybody else is kind of turning their head. It's interesting to watch these days because-  That is.

Speaker: SPEAKER_03
Transcript:  Well, there is an argument that there are certain things you have to fight. You can  ignore as much as you-  Yeah, punching a Nazi in the nose is okay.  I'm actually okay with that too.  That's okay.  I would do that.

Speaker: SPEAKER_02
Transcript:  It's okay. We are in the 50th anniversary of D-Day tomorrow and we are the 50th anniversary-  No, I'm sorry. The 75th anniversary of D-Day, the 50th anniversary of Stonewall Riots,  which is why it's Pride Month.  It's not that long ago.  All right. We talk about this a lot and it's something that we chew on a lot  because I don't think there is an obvious and easy answer.

Speaker: SPEAKER_01
Transcript:  The kid thing. I think that's more-

Speaker: SPEAKER_02
Transcript:  Well, YouTube acted quickly on that and that's a recommendation engine problem, isn't it?

Speaker: SPEAKER_01
Transcript:  It was a couple things. As I understand it, yes, it's a recommendation engine problem. It's also  a live problem and so children cannot be on a live video unless they are visibly accompanied by  an adult.

Speaker: SPEAKER_02
Transcript:  Do you think that will fix it? I don't even know what that-

Speaker: SPEAKER_03
Transcript:  There are some bad adults out there, but it's probably a start.

Speaker: SPEAKER_01
Transcript:  It's a start. It's a good start.

Speaker: SPEAKER_02
Transcript:  But the idea is that young kids are live streaming themselves and that petarasts  inappropriately can watch these videos and start commenting on them and get other petarasts to  watch. Or comments or write all kinds of-  And then the theory being the kids don't know and so if there were an adult around who would say,  maybe you should put some clothes on, Johnny.

Speaker: SPEAKER_01
Transcript:  But Leo, how old was the- We mentioned her last week or week before last, the young woman who does  the- Comedy?

Speaker: SPEAKER_02
Transcript:  Yeah, she was like a high school kid. She's 14.  How old was she? 14.

Speaker: SPEAKER_03
Transcript:  14. She started when she was like 9. And there's like little Tay, is that her name? She's like 9  years old and saying terrible, terrible things.

Speaker: SPEAKER_02
Transcript:  The thing about those kids is they're copying what they see on YouTube. They're copying what  YouTube influencers are successful- Or their parents or God knows what.  Well, but no, I think honestly, at least in the case of the 14-year-old that we were  talking about a few weeks ago, she was right in there with the Google, with the YouTube  zeitgeist. She fit right in. And I think she was a creature of that age, of that time.

Speaker: SPEAKER_03
Transcript:  And part of that is like, I know that everyone was making a big deal of the New York Times  article about the guy who got jail time for feeding the homeless guy Oreos with toothpaste  in it. But part of the problem is that all of these are optimizing for views and people  are prurient, prurient, prurient. And if you could optimize instead of for views. And the  other thing is very accurately, it makes Google and YouTube more money when you have more people  viewing for longer. But maybe instead of optimizing for engagement and views and thus ad revenue,  we optimize for something else. Maybe it's clicks on a, you know-

Speaker: SPEAKER_02
Transcript:  That's what Google says we're going to start doing is we're not going to just base it on  engagement because clearly that algorithm has failed. What if they didn't do recommendations  at all? I don't know. I mean, I don't know. But recommendations are notoriously terrible.  But they don't have to be fixed. Well, maybe they do. Maybe that's a hard thing to fix.

Speaker: SPEAKER_03
Transcript:  Well, like if I look for quantum computing videos, for example-

Speaker: SPEAKER_02
Transcript:  But no, that's different. You're doing a search. It's not that initial search. I want them to stop.  It's the then after you watch the quantum computing video, the next one.

Speaker: SPEAKER_03
Transcript:  Okay. So like, so I'm watching a quantum computing video. Right now, everything's optimized for  engagement, which means that like the next highest- Well, what's wrong with you searching

Speaker: SPEAKER_02
Transcript:  for another quantum video rather than Google proposing? Because I'm lazy and maybe I won't-

Speaker: SPEAKER_01
Transcript:  Well, stop being so lazy. Generally, relevance is a good thing.

Speaker: SPEAKER_02
Transcript:  No, it's because they can't do it well. And because-

Speaker: SPEAKER_03
Transcript:  No, they're picking their recommendations. Like, so they've talked about how Google sends  YouTube longer and longer videos because they want to optimize for more engagement and add time.  So maybe you stop picking the longer videos. Maybe you optimize for- Maybe in the middle of  a video, you have people who are watching it. Hey, are you still watching it? And are you learning  something? And if I click yes, then that helps you, that helps get you a better recommendation.  That's a weight that they use when they're doing that algorithm. Maybe I'm optimistic.

Speaker: SPEAKER_02
Transcript:  I just don't think we need it. When you go look at a web, when you search for quantum computing and  you go to read a webpage, Google doesn't then put up a sidebar saying, here's five other web  pages you'd be interested in. No, you search for another page. You continue on. You do a normal

Speaker: SPEAKER_01
Transcript:  thing. When I go to Amazon and I look for a book, I'm grateful that Amazon says here's other books

Speaker: SPEAKER_03
Transcript:  that are related. Because those recommendations are ghastly on Amazon. Did you see how they talked  about that? They actually did a thing today at Remars. They talked about how their original  recommendation efforts were terrible and how they worked to improve them. So it was a whole thing on  how they tweaked their algorithms. And I wish I could tell you how, but I have not finished reading

Speaker: SPEAKER_02
Transcript:  it. So I guess you could make recommendations better. I think maybe just dump them because you  can, you're not, you could find the next video. You don't need them to tell you the recommendations

Speaker: SPEAKER_03
Transcript:  are no, maybe, you know, I may not find the slack scientist who is, you know, the top of his field  doing this because maybe, I mean, and currently my search recommendations are based on, you know,  links in. So what if we create the equivalent of links in or reputable links in to a YouTube video?  So maybe if you're a professor at a certain university, maybe that gets you extra points.  So your videos on your topic of expertise are, you know, like I would love to get those  recommendations from random paleontologist. I don't even know if that would be nice if that

Speaker: SPEAKER_01
Transcript:  worked, but it doesn't. But I watch a nice, a nice elephant video and I get more elephant videos.

Speaker: SPEAKER_02
Transcript:  I get elephants and bikinis. I don't want it. I want to see an elephant in a bikini. Don't stop  me from my nice elephant video. So here's the recommendations Amazon's giving to me. First thing,  bought it. Second thing, bought it. Third thing, bought it. Fourth thing, looked at it, didn't buy  it. Fifth thing, looked at it, didn't buy it. Why are you getting an old Nokia phone?  They're recommendations for stuff I either bought or looked at. This is, this is brain dead.  This is not good. This is not adding anything to my life. That screen shine is good. It really,  it works well by the way. Oh, see now that's useful if you tell me that. Yeah, that's good.  Yeah. You like that, huh? Oh, the whoosh. Yeah. You know why it's recommending that? I bought a case

Speaker: SPEAKER_03
Transcript:  of it. Oh, my recommendations are awesome. I've got exhalation by Ted Chiang. Totally. And then  I've got a whole bunch of books that I've bought for my daughter. That makes sense. Yeah, but you

Speaker: SPEAKER_02
Transcript:  already bought them. Why is he recommending something you already bought? That's not a good  recommendation. I haven't, I haven't bought them yet. But I bought a lot of these and I don't want  to buy it again. Maybe if they said buy it again, Leo, that would make sense. And then underneath it,  things you had looked at but didn't buy or categories. The only one good thing in here is  that when I bought the whoosh, now it's saying, well, maybe you'd be more interested in screen mom.  No, don't think so. It's trying to offer me an alternative. Now that is that, oh, notice by the

Speaker: SPEAKER_03
Transcript:  way, Amazon's choice. Oh, this says recommended items other customers often buy again. Not for me.

Speaker: SPEAKER_02
Transcript:  This is just recommended period for you. Things you should get. One of these is really good. I  might just buy it. Well, obviously people do buy this crap because otherwise why would

Speaker: SPEAKER_01
Transcript:  Amazon do it? Why is it recommending an old Nokia phone to you, Leo? I bought it. This is

Speaker: SPEAKER_02
Transcript:  the greatest thing ever. Yeah. Oh, I got it. Oh, no, it's a fake Nokia 3310. It's the size of  a matchbook. Do I have it here? Can you get me my backpack? It's in my backpack, Jeff.  It is really adorable. It's adorbs. I don't think they say that anymore.  It's on fleek. Did they say that? No, no, that is very much done.  Honestly, I think we could live without Google or Amazon recommendations. Netflix recommendations  equally crappy. I don't mind them. It'll make them better. But honestly, isn't that the primary  problem with YouTube is those recommendations? If you didn't have those, wouldn't this stuff go away?

Speaker: SPEAKER_01
Transcript:  No, that is not the primary problem. It's 0.00001% of the recommendations are causing trouble and the  rest are giving me more elephant videos and I'm grateful for that. You cruel bastard. It's because

Speaker: SPEAKER_02
Transcript:  of you and lazy people like you that we have this whole flatters, no vaccination Nazis.

Speaker: SPEAKER_01
Transcript:  They're evil people who will game systems. And the problem is they're not going to go back to  regulation. The effort is not to regulate technology. The effort is not to regulate  algorithms. It's to regulate people's behavior. They're not gaming it. It's the stupid little

Speaker: SPEAKER_02
Transcript:  algorithm. Look at that. Isn't that the cutest thing you ever saw? Oh my Lord. How do you dial it?  What do you do with it? It works. You can even text. It reminds me of Zoolander. It's as small  as a SIM card. It was $20. It was cheap. I couldn't resist. So you just pop your SIM card in and you  put a SIM card in. Even has room for an SD card. Can you see this saying welcome? Can you take a

Speaker: SPEAKER_03
Transcript:  picture? What do you do with it? Just talk in text. Yeah, talk in text. It's a phone. You ever hear

Speaker: SPEAKER_02
Transcript:  of a phone? Oh my goodness. Hello. I love it. How's the sound? Just like you just heard. It's tinny,  but it's a phone. You can eat it. It's like a four-year-old there. Don't put that in your  mouth, honey. That is a phone. Phones are not for eating. But it's red raspberry flavor.  Okay. Should we do the changelog? Get the changelog ready. Fire up the drums. Play the trumpets.  It's time for all the new things at Google. This is so cool. Actually, the first time I saw this,  there must be something new that's going on in the web that allows you to do AR on the web,  because the first time I saw this was on Tuesday or Monday when Apple had its event. If you scroll  to the bottom of the new Mac Pro page, it said open this in Safari and you can have an augmented  reality. I was able to put my Mac Pro on my table beautifully. Well, now you can do this  in Google search. AR objects in Google search. If you search for Tiger, they actually announced this  at Google I.O., but now it's live. I can't really do it because in order to do it,  I'd have to. But I'll show you a video on Twitter. You're searching for Tigers and then you see that  meet a Lifesize Tiger in real life. Then if you press View in your space, you can put it there  and you can resize it and rotate it. It's just like it's there with you. I have to say, the AR  stuff here has gotten better and better and better. The Mac Pro was really sitting right on  the table, nice and solid. Apple showed some occlusion stuff that really works very well.  Yeah, it was Apple. I think this is exciting. Obviously, nobody really wants to hold up a phone.  Your arm gets tired and do this forever, but it seems pretty clear both Apple and Google  and I guess Microsoft too are getting very close to putting this stuff in glasses or something.  Right? Sorry, I didn't mean to put you to sleep, Stacey. No, it's just me. I know what you like.  How about whale songs? Do you like whales? Do you like whale songs? You're going to like whale song  radio. Oh my Lord. So, NOAA, the National Geographic and Atmospheric Administration or whatever.  Is that right, John? Did I get it? Okay.

Speaker: SPEAKER_04
Transcript:  The ocean is producing some form of sound.

Speaker: SPEAKER_02
Transcript:  Has recorded tens of thousands of hours of whale song. Christopher Clark here. Go ahead.  You can do the songs of life around this planet.  He loves these little whale songs. Listen to this expanse of the...  So what's Google doing with this? Well, Google has been working with NOAA to train an artificial  intelligence model on their thousands of hours of underwater recordings so you can, I don't know,

Speaker: SPEAKER_01
Transcript:  talk whale talk? I don't know. So Pete Buttigieg could talk whale talk.

Speaker: SPEAKER_03
Transcript:  Somebody's going to talk whale talk. So you know what's the... Okay, Slate does these stories as  part of their Future Gents effort and they get these writers to write random stories and Annelise  Neuetz wrote one about, it was about crows and people and a robot. And the robot basically  learned how to speak crow in the story. There you go.  And it was actually a really cool story because it was this friendship between this robot who  had AI and crow and they worked together to help prevent diseases. I'm going to teach

Speaker: SPEAKER_02
Transcript:  my bio Boston Dynamics spot dog to talk whale so it can attract them and eat them.

Speaker: SPEAKER_03
Transcript:  This is Google's... No, I'm kidding. Wait, so there is actually a...  In the Pacific Northwest where I now live, there was a ferry that just hit a whale. It was the  first time that ever happened. It was tragic for everybody. Mostly the whale, but nobody wanted  to hit it. But what if you could put on the ferry a whale song that broadcasts like, stay away, I'm

Speaker: SPEAKER_02
Transcript:  dangerous. Get out of the way, here I come, I'm a big boat, watch out for me. That would be really nice.  So this is, you can do this yourself. Now this is the Google part, the Googly part,  patternradio.withgoogle.com. You can explore thousands of hours of humpback whale songs  and make your own discoveries. I don't know what discoveries you would make,  but you want to do a tour? Let's, we can do a tour of whale songs.  Matt Harvey is a software engineer who's working with Ann Allen on machine learning model. So he's  going to show you, he says there's a song in this section, it's very faint because the whale's far  away. Zoom out to see it's surrounded by louder sections. My deep net machine learning  model worked better than my ears for faint calls. Okay, let's see what Ann Allen has to say.  So if you're interested in whale song, basically it's whale song radio, patternradio.withgoogle.com.  You have trouble falling asleep, man. It's very, very soothing. It's kind of,  you know what, really it's like alien speech.  So anyway, you can, you can wander to your heart's content through these  fabulous whale songs. I don't know. That's, that's one thing. Anyway, go away whale songs. Thank you.  Google photos.  Go away.

Speaker: SPEAKER_00
Transcript:  I'm sailing here. Get out of the way.  Here comes a big boat. I speak whale.  That's like my daughter and I still do that. It's one of our favorite things.

Speaker: SPEAKER_03
Transcript:  See, see, see. You might want to show her this. Google photos.

Speaker: SPEAKER_02
Transcript:  Dark mode rolling out to Android pie and Oreo. Everybody was so excited when Apple announced dark mode for iOS 13 on Tuesday.  I hate dark mode. Yeah, hate it. Yeah, actually there's, there's now a kind of an anti dark mode contingent rising up.  Yeah. Yeah. I like dark mode. Yeah, you know, you would. Yeah, you have your choice. Yeah, I hate it.  No, because sometimes that just, it just thinks it's doing a favor and just because it gets dark out of dark mode, it's just like,

Speaker: SPEAKER_01
Transcript:  it freaks me out and I hate it. Hate it.

Speaker: SPEAKER_02
Transcript:  If you want to see if your Android pie equipped phone can receive the new dark mode in photos, head to settings, display, advanced device theme, turn on limited dark mode.  And if you, and you'll, you'll have a dark darkness.

Speaker: SPEAKER_03
Transcript:  You need a setting never dark.

Speaker: SPEAKER_02
Transcript:  Yes, exactly. Dark. It's good for you. It's good for your phone.

Speaker: SPEAKER_01
Transcript:  And every week now there's there's there we got another story just says, oh, so and so has dark mode down.

Speaker: SPEAKER_02
Transcript:  Yeah, I know. The only thing that the crowd at the Apple event was more excited about than dark mode was the fact that they're the new watch calculator will do tipping.  Tipping. They cheered. They cheered like, oh my God, math is hard. The heavens have opened. I now can do 15%.  It's 20%, which is easier math. Come on. It's easy. That's why I always, you know what I always do? I always double the bill and give them that.  Yeah, 20%. Oh, that's what you're supposed to give now. You're supposed to take off some of those zeros, aren't you?  No wonder they like you.

Speaker: SPEAKER_01
Transcript:  You know, it gets great service everywhere.

Speaker: SPEAKER_02
Transcript:  Actually over tip because I as a young man have worked in the service industry and I know.  Well, they still haven't they still haven't updated the server wages. So it's still like $2 and 13 cents plus your tips.

Speaker: SPEAKER_03
Transcript:  So if your tips aren't going up, you are hosed.  Leo, do you also have a bit of a celebrity tax?

Speaker: SPEAKER_01
Transcript:  No, nobody knows who I am. But you're right. You know, I saw Bill Murray went to the Groundhogs.

Speaker: SPEAKER_02
Transcript:  I went to the Groundhog Day Broadway show and I noted that as he went and bought a ginger ale before he sat down, he had to tip the guy 50 bucks.  And that's the celebrity tax.  Because if you're Bill Murray and you give him a buck or no tip at all, there's going to be a there's going to be a story on page six about you.  Right?

Speaker: SPEAKER_03
Transcript:  I think if you just give a dollar, you're fine.  No, 50 bucks.

Speaker: SPEAKER_01
Transcript:  Not if you're Bill Murray. Howard Stern, same thing.  He has to. Yeah.

Speaker: SPEAKER_02
Transcript:  Actually, I was watching comedians in cars getting coffee, you know, the Seinfeld show, and he was I think he was out with I can't remember somebody some other famous comic and the comic wants to leave a normal tip and the guy and Seinfeld said you can't leave that tip.  Yeah, you're famous. You have to give him 100 bucks. You can't leave that tip.  Google Maps is rolling out a live speedometer feature in the US and some EU nations.  So as you're driving along, your Google Maps will now tell you what the speed. Catching up to Waze, which has had it for ages.  Yeah, as as our Tesla.

Speaker: SPEAKER_03
Transcript:  I turned that off. I was like, it does not.  You don't want to know.  Oh, you know what?  If you have a Tesla, you know what happened somehow?  When I do a map now in Google, I get an option when I have it.  Oh, when I do an address in Google, I have an option now to send it to my Tesla.  Oh, that's very fancy, but very small.  I like that.

Speaker: SPEAKER_02
Transcript:  I have to say, Tesla is one of the few car companies who still does all of their own, you know, entertainment system stuff on the center console.  I love Android. We got we just got a Chevy Bolt, the B-O-L-T.  Well, you did. Yeah.  And I love Android Auto and CarPlay, but Android Auto, especially really great.  It's really great. You get to use Waze, your Google Maps on the Apple.  You can also use Apple Maps and it's just it's a it's much better.

Speaker: SPEAKER_01
Transcript:  So let me tell you something. So I switched to my Google 3A XL.  Oh, good. How do you like it?  I like it. I like it.  I mean, I'm about to buy that.  I like it. I like it.

Speaker: SPEAKER_02
Transcript:  You had a Pixel. You had a Pixel XL, right?  Pixel 2.  Oh, OK.  Oh, how do you wait?

Speaker: SPEAKER_01
Transcript:  It was a skip. It's very nice.  But you know, but it's not that noticeably different.  I love it. It's great.  OK, because I'm going to do that, too.  Thanks, Jeff. It's good.  It's good. Yeah.  And but but so I use Android Auto and I was frustrated as hell because the only  things that would show up under the audio under Android Auto on the car screen  were the Google Apps.

Speaker: SPEAKER_02
Transcript:  Oh, no, I can use Audible now, which is nice.

Speaker: SPEAKER_01
Transcript:  Well, my Audible wouldn't show up and I was going crazy.  So finally, I looked up some stuff.  I had to go in and enable developer mode for Android Auto to say,  except strange apps, you know, whatever they call it.

Speaker: SPEAKER_02
Transcript:  Because you get Pandora, you can get Spotify.  Now they're all there.  Now they're all there.

Speaker: SPEAKER_01
Transcript:  But it was it was all there before.  So they must have done some kind of security change.  So I had to go in and it was a pain.  And so to get a developer mode, you have to go to the about page and click on  something 10 times.  Yeah, yeah.  And that's crap.

Speaker: SPEAKER_03
Transcript:  Are you sure? Are you sure? Are you sure?  Yeah, no, no, no, it's just you have to.

Speaker: SPEAKER_02
Transcript:  It's everybody.  You have to know the secret handshake.  It's a secret.

Speaker: SPEAKER_01
Transcript:  So if anybody out there is having that problem, because my prior phone was fine.  And then this one, I could not do a thing.

Speaker: SPEAKER_02
Transcript:  Don't have to do anything on my Samsung Galaxy S10+.  It's just it sees it all.  And you know, it's really awesome on the iPhone.  There's a third party Twitter app called My Twitter, which I really like.  It showed up.  There's a big Twitter logo right there on the screen.  I can listen to Twitter live.  I can listen to Twig.  And here's a question for you.

Speaker: SPEAKER_01
Transcript:  So I love ways being on the big screen on the car.  I cannot get turn by turn directions.  All it gives me is the map.  Oh, I don't know.

Speaker: SPEAKER_02
Transcript:  I haven't tried it.  Oh, you know, Google has.

Speaker: SPEAKER_03
Transcript:  So Google has something with Android Auto.  It started offering me this recently and it drove me nuts and I can't think of what it's  called, but I had to download it.  That's what was offered you.  Dark dark.  It was it.  It was navigation for Android Auto.  Oh, it was.  So I had to download something else to.  I just I just press the little microphone.

Speaker: SPEAKER_02
Transcript:  I say navigate to work and it does the turn by turn.

Speaker: SPEAKER_03
Transcript:  So that's on that's on your Tesla.  So that's no, no, that's not on the Tesla.  That's on the Bolt.

Speaker: SPEAKER_02
Transcript:  Well, I mean, it does.

Speaker: SPEAKER_01
Transcript:  I don't know.  I don't know.  I surprised myself.  Well, I can see the map.  I can't see the alphanumeric list of.  Oh, you want the list.

Speaker: SPEAKER_02
Transcript:  You don't.  It'll give you the tell you the turns.  It gives you turn by turn.

Speaker: SPEAKER_01
Transcript:  Only because because then I can't judge what it's doing ahead.  There's no way to see ahead.  So what I do is I zoom it.  You can pinch it.

Speaker: SPEAKER_02
Transcript:  Pinch it down so you see more of the map.  Well, I can't know on the Mazda.

Speaker: SPEAKER_01
Transcript:  If you're moving, you can't pitch.  You can't touch the screen.  It has a screen.

Speaker: SPEAKER_02
Transcript:  Well, you need a better.  You need a better car.  Well, I do actually.  Yeah, I didn't buy a new car.

Speaker: SPEAKER_01
Transcript:  Son got a my son got a Volkswagen and I didn't get it because it was going to require premium  gas.  Yeah.  And then now the turbo doesn't require premium gas.  And I'm all jealous.  Actually, I want I'm only by electric.

Speaker: SPEAKER_02
Transcript:  I love electric.  So this is the ball.  Tell us about the ball.  It's great.

Speaker: SPEAKER_01
Transcript:  It's great.

Speaker: SPEAKER_02
Transcript:  Little car.  Yeah.  One thing it will not get, though, and I'm sad because my Tesla will is Cuphead.  Did you see this, Stacey?  This is not a change log item, but I got to say it.  Tesla is going to add you know how they have Atari games.  They're going to add one level of the hardest video game ever, which is Cuphead.  Which is Cuphead.  This really should never be on a car because what is happening?  Well, you can't you can't do it while you're driving.  But apparently, Elon says they're working with the Cuphead developer and he says it's  a cool game.  It's insanely difficult.  I think it's just because Elon likes the game.  Probably it's statistically difficult.  It's a twisted plus dark.  It looks like some cute Disney thing.  And you're like, this plot is very dark, which is true.  So I love Cuphead and it's coming to the Tesla.  But that is that is really inappropriate in the Google change log.  So let me continue on.  Google Play is adding 43 US banks and credit unions.  So if you've asked Google Play to add a credit card and it said, no, your bank doesn't support  it, try again.  Try again.

Speaker: SPEAKER_01
Transcript:  What do I need to add?  I need to add.

Speaker: SPEAKER_03
Transcript:  Oh, yes, give us the credit card numbers and chase in there.

Speaker: SPEAKER_02
Transcript:  I don't see chase.  Oh, yes.  But but this is just the first tranche of 14.  More will come.  You know, I use the financial term instead of I put everything on my United card to get

Speaker: SPEAKER_01
Transcript:  miles.

Speaker: SPEAKER_02
Transcript:  Everything, everything.  Finally, and this is actually tomorrow's change log, Stadia is tomorrow.  Google at 9 a.m. Pacific noon Eastern.  We're going to stream it live.  Google is going to announce Stadia pricing and launch games.  So Stadia is that streaming gaming service.  Google teased at the Gamers Developers Conference.  They're jumping the gun because E3 is next week and they're going to.

Speaker: SPEAKER_00
Transcript:  Some news can't wait for E3.  Announce it tomorrow.  Yes.  Launch info, game announcements, price reveal.  Watch Stadia connect June 6th on YouTube.

Speaker: SPEAKER_02
Transcript:  Wow.  A promo for an announcement.  Anyway, we will stream that live until YouTube pulls this down.  And that, as far as I can tell, unless I've left something important out, is the Google  change log.  Symantec published an interesting blog post this morning about Twitter bots.  They did an analysis of the bots created by the Russian Internet Research Agency.  I thought very interesting.  For instance, among their key findings, the operation was carefully planned.  Accounts were often registered months before they're used, well in advance of the election.  The average time between account creation and first tweet, 177 days.  The most terrifying stat was that the most retweeted account got over 6 million retweets.  Very few of those from the other bots.  Almost all of them from genuine Twitter users.  Six million.  That shows you how successful the campaign was.  Most accounts were primarily automated, but they would frequently show signs of manual  intervention, such as posting original content or slightly changing the wording of reposted  content, presumably in an attempt to trick Twitter to make it look more authentic.  Fake news accounts were set up to monitor blog activity and automatically push new blog  posts to Twitter.  Auxiliary accounts configured to retweet content pushed out by the main accounts.  What's interesting is that they didn't take a side in the election.  The campaign directed propaganda at both sides of the liberal-conservative political divide  in the US, but almost always focused on the more disaffected elements of both camps.  Bernie and Trump, I guess, right?  So, and there's a nice little infographic.  Twitter bots.  Anatomy of a propaganda campaign.  10 million tweets.  6.4 million followers following 3.2 million.  A total of 3,836 main accounts.  Is this any of your numbers, Jeff?  I hope it's not.  Nope.  Nope.  Nope.

Speaker: SPEAKER_01
Transcript:  Sorry.  That's why I come up with backups, though.  Yeah, good thinking.  I have more backups than a Google network.  Here is an example account with half a million retweets.

Speaker: SPEAKER_02
Transcript:  Tranisha Cole.  Tranisha's profile says, love for all my people.  Love for all my people of melanin.  Your black is beautiful.  And then some things, some hashtags I can't say out loud.  Here's one from Kenny Jackson.  Follow the example set by Mrs. Obama.  Peace, love, and acceptance and vigilance.  Impeach 45 resists gun reform now.  Then there's also 10 GOP unofficial Twitter of Tennessee Republicans.  6 million retweets on this one.  This is the one covering breaking news, national politics, foreign policy, and more.  And more MAGA 2A.  What is 2A?  What's hashtag 2A?  Is that something I don't know?  Second Amendment.  Got it.  Thank you.  Oh.  So really an interesting, and I think very clever in many ways, campaign promoting fake  news, promoting division.  That's a semantics study.  The US, it'll be easier for Symantec to do their job because the US is now asking anybody  looking for a visa to enter the United States for every social media account they've ever had.  This is disgusting.  This is just awful.  The administration promised this a couple of years ago.  It's now, it's on the form.  14 million visitors to the US each year will be affected by the changes.  It's not just immigrants.  It's 710,000 prospective immigrants, but anybody visiting the US from a country that requires  a visa, which is I think most of them, will have to fill out this form.  They want to know your social media username, your social media accounts, and if, and they  give you a list of all the social medias that you, you know, they know about.  And if you have any others, they ask for those too.  They say, you know, if there's anything we left out, please let us know.

Speaker: SPEAKER_03
Transcript:  And what's terrible is a lot of countries will reciprocate.  And then when, and I'm like, I'll never get it.  That is not, that is inconvenient to me personally.  What is also, we're supposed to be this land for free speech and blah, blah, blah.  And this is a very sensorious way to like, but do you think really that CPB is going

Speaker: SPEAKER_02
Transcript:  to look at all of the social media accounts for 14 million people?

Speaker: SPEAKER_03
Transcript:  You will censor by vulnerability.  So the more, if you are a white guy in the UK, you're not going to feel bad about anything.  If you're a brown person from a part of the world that we've declared like evil, you're  going to be like, ah, I once hated said I didn't like apple pie.

Speaker: SPEAKER_01
Transcript:  That's, ah, or it's not hard to, to, you know, get the fire hose and just store away people  who were critical of a president.

Speaker: SPEAKER_03
Transcript:  You can also do it retroactively once someone like you stop them.  You're like, cause we have the tools at our disposal.  Like if someone stopped for questioning, for example, someone could be like, ah, I  know someone could on a little tablet, just pull up all of their social media and be like,  and then you could like treat them worse.  It's not a good, it's not a good look.

Speaker: SPEAKER_02
Transcript:  I want to prepare a little list for yourself of all your social media accounts, all your  handles, your passwords, anything that there goes my global services.  Well, I have to wonder, I mean, I haven't seen stats lately, but I wonder how tourism  is impacted by this in the United States.  It was down a lot.

Speaker: SPEAKER_03
Transcript:  Kids coming to study college abroad here are down.

Speaker: SPEAKER_01
Transcript:  Are they?  Yeah.  Oh yeah.  Well, you know, at the Newmark graduate school of journalism, our international students  now cannot write for any publications in the U S unless we own them at the school.  Oh wow.  Why is that?  They can't get clips.  Well, cause there's not allowed to work in any definition that would include writing  a piece for, you know, ProPublica.

Speaker: SPEAKER_02
Transcript:  If unemployment really is down a few percent, why not let them work?  I know.  I've been, I've been seeing on Reddit a lot of posts on the cruise subreddit about people  whose trips to Cuba have been summarily canceled because of course the United States is now  prohibiting virtually all visitors to Cuba, including people who were previously allowed  to as part of tour groups, cruises that were scheduled or being canceled and rerouted  to Mexico and other places.

Speaker: SPEAKER_03
Transcript:  I'd be so pissed if I wanted to go to Cuba and I ended up in Mexico.

Speaker: SPEAKER_02
Transcript:  I had a trip to Cuba planned for last year and I was so worried after Trump's election.  I now I feel like it was a mistake.  I canceled it because I figured, well, by the end of, you know, nine months from now  when I'm supposed to go on that trip, I'm sure this regulation will have passed because  they promised it.  They didn't.  I could have gone.  I wish I had now because who knows when we'll be able to go again.  But you know, they are lawless commies.  Let's not forget.  Godless.  Godless.  They have laws.  They don't have God.  I'm sorry.

Speaker: SPEAKER_03
Transcript:  I always forget which that is.  Wait, I'm sorry.  Was that, was that Russia?

Speaker: SPEAKER_02
Transcript:  No.  Russia is godless.  I mean the Soviet Union.  Actually, Russia.

Speaker: SPEAKER_01
Transcript:  Well, actually we like them now.

Speaker: SPEAKER_02
Transcript:  Yeah, they're okay.  It's so this is why it's so confusing.  You can go to Russia, but you can't go to Cuba.  I'm just getting that straight.  Apple has announced on Tuesday a single sign on to compete with Google, Twitter and Facebook.  Sign on with Apple.  The button will be, if you do see it, above the others.  That's part of Apple's requirements.  They're also apparently going to require anybody in the app store that has a Google, Twitter  or Facebook sign on to add the Apple sign on above all the rest.  Now if you're a privacy advocate, you may like it because one of the features of Apple's  single sign on is they'll allow you to obfuscate your email address.  And this is one reason I think a lot of people would, who are using Facebook, Google or Twitter  logins right now might not want to use the Apple login.  They want your email address.  Instead they'll get a special address that Apple will then forward to you.  Of course, Apple will have the opportunity to see all the email from all of these companies,  but we trust Apple.  So it's okay.  Because they're privacy focused.  They're doubling down on privacy.  Actually, I don't use those sign on buttons because after I quit Facebook, I realized  I just severed my connection to hundreds of apps and websites.

Speaker: SPEAKER_03
Transcript:  I don't use them because I have a password manager and that's just, I'm like, that's  what I do.  That's the better way to do it.  Those companies, I mean, they probably do know thanks to like tracking pixels, but they  don't need to know where I am all the time on the web.  They're not offering me a service for that.

Speaker: SPEAKER_02
Transcript:  Actually, that's why I use the Brave browser because it lets you turn off those tracking  pixels in the settings.  So I turn off LinkedIn, Google, Facebook and Twitter.  And so those bugs no longer work.  They just block that JavaScript, which I think is great.  Or maybe they block the IP address.  Brave is a pretty cool browser.  It's one of my favorites.  Let's take a break speaking of password managers and come back with your picks and number and  then we'll...  Can I ask a question first?

Speaker: SPEAKER_01
Transcript:  Yes.  Can you make a display stand worth a thousand dollars?  Can you explain that to me smart people?  Yeah, well if Apple can...

Speaker: SPEAKER_03
Transcript:  Johnny Ives and his pronunciation of aluminum.

Speaker: SPEAKER_02
Transcript:  If you're buying one of these pro display XDRs for $6,000, buying a thousand dollar  stand makes sense because you have too much money.  How is it though?  Well, okay.  Probably you could get a stand with similar functionality from another party.  And by the way, since this, you can also buy a Visa mount instead of the stand.  It doesn't come with anything.  I know it's...  It's just a giant display.  It's a display.  Stand is optional.  So you could buy somebody else's stand.  I'm sure there'll be a brisk market in $100 stands.  But the Apple stand rotates and has an arm that gives you angles and has some features.  And honestly, anybody who's buying this is working in graphics, photography, video.  In the arts where design is important.  Design is important but also your clients are paying for this.  This is part of your business.  And it's the same reason the Mac Pro starts at $6,000.  And probably that's a very minimal configuration.  Any reasonable configuration will be more like $10,000.  So what are you worried about $1,000 for a stand?

Speaker: SPEAKER_03
Transcript:  That's still 10% of the price of it.  I mean, that's not insignificant.

Speaker: SPEAKER_02
Transcript:  Just charge it back to the client and you add 15% and you're making money.  It's a profit then.

Speaker: SPEAKER_03
Transcript:  It does have that cool magnet, I will say.  And having played with magnets and like my video cameras, that's satisfying.

Speaker: SPEAKER_02
Transcript:  There's a lot of design in that stand.  That's cool.  You're right.  It probably costs Apple $100 to make.  They got a lot of attention for it.  They probably, in hindsight, shouldn't have mentioned the price of the stand.  I thought it was surprisingly forthright of them to mention that.  I don't honestly think that somebody buying a $6,000 monitor because of the features of  the monitor is thinking about the stand.  These monitors are-  That's true.  I mean, I would never buy that monitor.  No, it's not for you and me.  It's for professionals.  And professionals really honestly aren't.  If you're recording the next- who's a big star?  Miley Cyrus album.  If you're recording, I don't know, the next whoever big star album, the Jonas Brothers  album, I'm so out of it.  You're in a big recording studio.  You're buying this expensive gear.  The stand is the least of your worries.  And you just charge it back to Miley anyway.  $5,000 for the Pro Display XDR.  $6,000 for the Mac Pro.  And that's base.  That's the base model.  The Mac Pro has 256 gig hard drive in it.  It's got the tiniest little bitty hard drive in it.

Speaker: SPEAKER_03
Transcript:  That is almost insulting, I'll be honest.

Speaker: SPEAKER_02
Transcript:  Well, you're not going to buy that.  Nobody's going to buy that.  You know, eight cores.  What do you mean eight cores?  I need 16.  I need 24.  I need 32 cores.

Speaker: SPEAKER_03
Transcript:  That's like my early Tesla that I got.  And they were like, and for cup holders, we're going to charge you.

Speaker: SPEAKER_02
Transcript:  Oh, Tesla totally does that.  Oh, my God.  Do they do that?  Yeah.  But if you're a recording studio and the Everly Brothers are coming in to record that  big hit song.  I'm sorry, Jonas Brothers, not Everly Brothers.  Our show today brought to you by LastPass.  You have a password vault.  You have a password manager.  You should have a password.  If you don't have a password manager, you need LastPass.  The number one most preferred password manager.  It's the one I use, the one Steve Gibson recommends and uses.  It is strong encryption.  It is your passwords are only decrypted on your devices.  LastPass doesn't have access to them.  Nobody does.  It has a password generator in it.  It has a security check.  By the way, that's the first thing I did when I got home this week after Twitter is I ran  it because I'd heard about another yet another breach.  More passwords released into the wild.  And I thought I better run through my security checker on LastPass.  It'll check all your passwords, all your email addresses.  If any have been breached, it will offer to change them automatically.  I read it about 100 passwords in, I don't know, five minutes.  It was done.  It just happened with strong passwords.  And of course, LastPass doesn't have to show you the password because it remembers it.  It fills it in.  Now, the best thing about LastPass is LastPass for business.  43,000 businesses use LastPass, including Twitter.  We use LastPass Enterprise because your employees are the weakest link here.  We know employees share passwords, not just with other employees, but with a real outside  world.  And you're giving them the keys to the kingdom.  Our business department has all our bank accounts, all our books, ops, you know, the engineers  have access to our websites and our databases.  It's really nice to know that it's all stored in LastPass.  You can share it with them without them even seeing it.  If you change the password, it's automatically changed for them.  You can set over 100 customizable policies to give you more flexibility and control for  instance, we have certain standards for the master password to help protect it.  We require second factor authentication.  LastPass supports all of them, including YubiKey, but also Duo, Security, all the authenticators.  As an admin, you'll have access to customized reporting so you can track changes over time.  You can reset passwords.  You can see how people are using passwords.  You can see if they're using bad passwords.  You have full control.  Seamless background sync, offline access.  By the way, LastPass works everywhere you do.  It's the first app I install when I get a new phone or a new computer.  Windows, Mac, Linux, Android, iOS, every browser.  I love LastPass.  You will too.  Join 13.5 million people who've signed up for LastPass.  They're loving it and trusting it.  I trust it.  LastPass premium for individuals, LastPass for teams, for small groups of 50 or less.  LastPass families, that's what you use at home because it has easy sharing plus that  emergency access feature, which is great.  It says I can designate a survivor who has access to my stuff if something should happen  to me.  LastPass Enterprise, which is what we use here at Twit.  In fact, we like it so much we give LastPass to every employee as a benefit of employee.  Have you signed up for LastPass, Jeff?  Yes, our newest engineer.  LastPass.com slash Twit.  LastPass.com slash Twit.  We thank LastPass for their support.  LastPass is easy, secure, reliable.  Don't leave home without it, as they say.  I wouldn't dream of it.  Thank you, LastPass, for your support of all our shows.  Stacey, you said you have something exciting.  Is it an unboxing?

Speaker: SPEAKER_04
Transcript:  It is.  Tell us.

Speaker: SPEAKER_02
Transcript:  Tell us.

Speaker: SPEAKER_03
Transcript:  This is the Luchon Aurora.  Only you would be excited by this.  What is it?  Oh my gosh.  Okay.  This is a device.  The idea is this works with Philips Hue light bulbs.  You know how you turn your light switch off and your Philips Hue light bulbs stop working?  Yes.  This prevents you from turning off your light switch and making your Philips Hue bulbs stop  working.  They're always powered.

Speaker: SPEAKER_02
Transcript:  Oh my God.  They're always on.  I need this so badly.

Speaker: SPEAKER_03
Transcript:  Everyone can use it.

Speaker: SPEAKER_01
Transcript:  Is this like scotch tape on the switch?  No.

Speaker: UNKNOWN
Transcript:  Kind of.

Speaker: SPEAKER_03
Transcript:  It's more aesthetically pleasing and it has a dimmer function.

Speaker: SPEAKER_02
Transcript:  They have all the different kinds of switches.  You have a dimmer or a regular switch, right?

Speaker: SPEAKER_03
Transcript:  This one only works on toggle switches, but it will turn into a dimmer.

Speaker: SPEAKER_02
Transcript:  This is the problem.  People come into my office where I have a motion sensor and Hue lights.  I want it so that when I go in my office, my lights come on.  People inevitably, I know today, somebody will have gone to my office and switched it  off because they say, well, the lights are on.  They flip it off and then nothing happens.  This will prevent that.

Speaker: SPEAKER_03
Transcript:  Yes.  It is kind of expensive in my opinion.  It is $40.  Come back to me.  All right.  So here's the two pieces you need.  This is all you get.  And you have to have the Philips Hue bulb in hubs.  This has a Zigbee radio on it.  It's 3.0.  They're going to work with other light bulbs eventually, but they've got to test compatibility.

Speaker: SPEAKER_02
Transcript:  So it still uses your existing hardware on the wall.  It just replaces.

Speaker: SPEAKER_03
Transcript:  Yeah.  This is something anyone can do.  You don't have to worry about electricity.  Does it glue on top of it?  No.  Hold on.  Hold on.  Hold on.  Hold your horses, Laporte.  You turn your light switch on, your toggle switch on.  Yeah.  Okay.

Speaker: SPEAKER_02
Transcript:  So this is, this is your finger is your switch.  Okay.  You put this thing over it like this.  Yeah.  And it keeps it on.

Speaker: SPEAKER_03
Transcript:  And it keeps it on.

Speaker: SPEAKER_02
Transcript:  And then you, what's the knob do?  Okay.  Snap it to it.

Speaker: SPEAKER_03
Transcript:  Yeah.  And now I have a dimmer function.  So all that's happening is this is this great thing is holding your light switch on.  Yeah.  So this is basically telling the Zigbee stuff to be like, boop boop, work.  Don't work.  So it's see, hold on until you see this.

Speaker: SPEAKER_02
Transcript:  Unfortunately, I don't have those old fashioned toggle switches.  I have the fat ones.  You know, they're

Speaker: SPEAKER_03
Transcript:  This is me, the rocker switches.  Rocker.  They're not making it for the rocker switches.  So your options are as follows.  I just get a different switch.  Get a different switch.  But when you change out the switches, you actually do have to change out the electricity.

Speaker: SPEAKER_01
Transcript:  You can just turn on the light with a switch.

Speaker: SPEAKER_02
Transcript:  No, it's not turning it on is the problem.  It's the turning it off.  People turn them off.

Speaker: SPEAKER_03
Transcript:  No, no.  Smart lights are actually super useful, Jeff, for a variety of reasons.  Number one, you can be in bed and you say, Madam A, turn off the lights.  Number two, you can set up really cool like modes like movie time.  Right?  Number three, when you leave your house, most security systems now will work with your lights  to make them look like they're on and off and kind of a randomized or the same pattern  that you use.  So then it becomes a security feature.

Speaker: SPEAKER_01
Transcript:  You know, I go into the restroom these days, right?  And you can't turn on the lights.  I know.  Where is the lights?  No, it's not that.  I can't turn on the soap or the water.

Speaker: SPEAKER_02
Transcript:  Oh, none of that works.  Because you know why, Jeff, you're so pale, you're invisible.

Speaker: SPEAKER_01
Transcript:  Well, it actually usually happens the other way where people of color can't turn the  light on.  Is that true?  Because the system doesn't know that.  Are you kidding?  Those automatic faucets are racist?

Speaker: SPEAKER_02
Transcript:  Oh no.  Yes.

Speaker: SPEAKER_03
Transcript:  Oh my God.  Because they only tested them against white people.

Speaker: UNKNOWN
Transcript:  Anyway.

Speaker: SPEAKER_04
Transcript:  Oh my God.  That's terrible.

Speaker: SPEAKER_02
Transcript:  That's just like this is this is the persistent, unconscious, subterranean racism that pervades  our lives.  Yes.  Well, so what do people of color do?  They go in an airport restroom.  They can't wash their hands.

Speaker: SPEAKER_01
Transcript:  Yeah, because you can't get the water to turn on.  The water won't go on.  They just go like this around underneath them.  So I'm just saying we're getting this rule where you can't you don't touch anything,  right?  You don't touch doorknobs, paper towels, soap, water.  It all is.  Yeah.

Speaker: SPEAKER_02
Transcript:  Maybe we should still.  I have put in my house it and my wife hates it.  But I don't.  So if my hands are dirty, I don't want to go pump the soap dispenser or pick up a bar  of soap.  So I put automatic soap dispensers in my in the house.  So you put your hand on it, squirts soap in there and it's good.  But I didn't realize maybe it's racist.  Fortunately I don't know any black people, so it's OK.  When are you going to deliver?  I'm joking.  I'm joking.  Some of my best friends are people of color.  No, no, actually we do.  And I haven't but I haven't asked them what do you do when you use the soap dispenser?  I mean, I didn't even know this was an issue.

Speaker: SPEAKER_01
Transcript:  I would hope that they're getting fixed.  But yes, it's been an issue.  Yeah.

Speaker: SPEAKER_02
Transcript:  Well, I think mine is smarter.  I really like it because often my hands are filthy.  You know, like we're grilling and I put the charcoal in the grill.  I don't want to have to get charcoal dust over everything.  You have that at home?  Yes.

Speaker: SPEAKER_03
Transcript:  I love it.  That's what he's saying.  I love my touch faucet.  I'm really sad that I don't have it.  I know.

Speaker: SPEAKER_02
Transcript:  I wish I had one of those.  Because I do have to do the knob on the faucet, but I can do that with the edge of my hand.

Speaker: SPEAKER_03
Transcript:  No, no touch is way better.  All right.  So that's my thing.

Speaker: SPEAKER_01
Transcript:  That's a good thing.  Very cool.

Speaker: SPEAKER_02
Transcript:  It's a very cool thing.  But you're right.  You could spend a lot of money on.

Speaker: SPEAKER_03
Transcript:  It's $50 to switch out all of this stuff.

Speaker: SPEAKER_02
Transcript:  Yeah.  And all the money you spend on the.

Speaker: SPEAKER_03
Transcript:  Hue bulbs.  But if you've already spent the money on the hue bulbs or if in my case, because I'm in  a rental house, it actually would be useful, except I don't have the right switches.

Speaker: SPEAKER_02
Transcript:  $25 for the Secura premium touchless battery operated electric automatic soap dispenser  with adjustable soap dispensing volume control dial.

Speaker: SPEAKER_01
Transcript:  Is that what you have?

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_01
Transcript:  It's ugly.  It's actually.

Speaker: SPEAKER_03
Transcript:  It's not ugly.  It's a good thing.

Speaker: SPEAKER_02
Transcript:  That actually is kind of cool.  It works great.  And then you can get this nice.

Speaker: SPEAKER_03
Transcript:  I wish it were plug inable.  I don't like how long does the battery last?

Speaker: SPEAKER_02
Transcript:  They last forever.  I've had it for a long time and I haven't had to change the batteries.

Speaker: SPEAKER_03
Transcript:  Maybe you don't wash your hands a lot.

Speaker: SPEAKER_02
Transcript:  I wash.  No, I wash my.  I wash my hands more because it's so easy.  I wash my hands many, many times a day.

Speaker: SPEAKER_03
Transcript:  Yeah, because I'm like because, you know, when I'm like cooking or dealing with raw  meat, I hate, you know, I do it with exactly.

Speaker: SPEAKER_02
Transcript:  I just put chicken in on the, you know, and I now have and what am I going to do?  I don't want to touch anything.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_02
Transcript:  You see what I'm saying?  You see what I'm saying?  Jeff, your number.  My father's favorite gift for Andrew.  Andrew would love it.

Speaker: SPEAKER_03
Transcript:  He would.  He's very germ conscious.

Speaker: SPEAKER_02
Transcript:  Yeah.  My wife, she says, I don't like it.

Speaker: UNKNOWN
Transcript:  I don't know why.

Speaker: SPEAKER_01
Transcript:  What is it takes up counter space?

Speaker: SPEAKER_02
Transcript:  That's a problem.  Yeah, I put you know what?  The other thing is I put it right over the sink.  So if it drips or it's accidentally shoots itself, right, it goes right in the sink.  I'm liking this.  All right.  See, what's your.  All right.

Speaker: SPEAKER_01
Transcript:  We're going to start here.  So Spencer Tunic came to New York to have a protest on behalf of the nipple in front  of Facebook.  And dozens of people strip in front of Facebook's New York headquarters.  That's point one.  Oh, my God.

Speaker: SPEAKER_02
Transcript:  You're safe for work.  Yeah, because we all have butts.  Oh, this is that guy.  Spencer does this.  He does this all the time.  Did you go down there?

Speaker: SPEAKER_01
Transcript:  No, I would be tempted to do it sometime if I've done the German sauna thing.  You know, why not this?  This is great.  But I think my family would have a fit.  If you go to the second link, there's one that actually shows what they were doing.  Is it safe for.

Speaker: SPEAKER_03
Transcript:  That is not safe for work.  It depends on how you feel about public nudity, I guess.

Speaker: SPEAKER_02
Transcript:  It's from it's from Fox.  So they've actually blotted out any body parts.

Speaker: SPEAKER_01
Transcript:  Yes. So they're holding up.  They're putting nipples in front of their private parts.  Big, big pictures. Oh, that's funny.

Speaker: SPEAKER_02
Transcript:  Which is funny. Oh, that's actually pretty funny.  It's pretty funny.  So that's that's one that is a double standard.  And Sarah Silverman was talking about that.  She got she put a picture up of her and her breasts were in it.  And it was immediately taken down.  So she put up all these pictures of nipples.  You can't tell if they're male or female to complain to Instagram.  And I think she had an excellent point.  Why is why is a male nipple?  How is that exactly different?

Speaker: SPEAKER_01
Transcript:  It is sexist. Yeah.  So then Facebook can solve this because they might get a gigantic new  New York headquarters.

Speaker: SPEAKER_02
Transcript:  Where's it going to be?  Where's it going to be?

Speaker: SPEAKER_01
Transcript:  In the in the spot of the old Hotel Pennsylvania,  which is kind of falling down around itself.  But a huge building, 50,000.  It's cool.  I with plants all over.  It looks like a Jenga building in them.  Oh, we have one of those in Austin.

Speaker: SPEAKER_03
Transcript:  We call it the Jenga building.

Speaker: SPEAKER_01
Transcript:  The what building?  Jenga. It looks like Jenga.  Yeah, Jenga. Yeah, that's right.  There is one in Austin. Yeah.

Speaker: SPEAKER_02
Transcript:  Will is this all going to be Facebook, this building?

Speaker: SPEAKER_01
Transcript:  No, it's but a huge part of it. Wow.  Supposedly it's.  So there's that.  And so you see there's a picture of people going down.  There's a picture of like the park. Wow.

Speaker: SPEAKER_02
Transcript:  Where do you put the naked people?

Speaker: SPEAKER_01
Transcript:  That's exactly it. Right.  So now it's safer.  Now, now you it's harder.  It's right. Look at the park.  It's not that's the park. Yeah.  So this is how it's same as their is there.

Speaker: SPEAKER_02
Transcript:  Is there actually this is really convenient.  It's right up the street from the club.  Oh, yeah. I run over.  Isn't it beautiful?

Speaker: SPEAKER_01
Transcript:  That's the old building that that design style.  Then I want to show one of the things.

Speaker: SPEAKER_03
Transcript:  Is it going to be one of those super, super high ones  that people are upset about because it says they're going to have a bunch of floors

Speaker: SPEAKER_02
Transcript:  with no thinning in them? Yeah, it's really these super skinny,  tall skyscrapers that are popping up.  Oh, yeah. Super tall. Yeah. Yeah. I don't like them.  What do you think, Jeff? You're the one who lives there.

Speaker: SPEAKER_01
Transcript:  Well, I don't like so I have to I have to occasionally go.  It doesn't like any work at one World Trade Center. Yeah.

Speaker: SPEAKER_02
Transcript:  And you don't like going up there. I know.  Oh, no. I bet that's scary for you. Yeah.

Speaker: SPEAKER_03
Transcript:  Does it sway in the wind?

Speaker: SPEAKER_01
Transcript:  Yeah, so does my imagination.  Since we were talking about about racism, let's talk about Baratunde.  I recommend heartily. Yeah.  Baratunde Thurston's Ted Talk. Yes.

Speaker: SPEAKER_02
Transcript:  If you haven't watched it, do Ted 2019.  Have you seen it yet?  He sent me the text and I have not, but I love I love Baratunde  and I will watch it. Absolutely.  He's he's the greatest guy. And I bet it's a great talk.

Speaker: SPEAKER_01
Transcript:  And it's about yeah, it's about it's about living while black.

Speaker: SPEAKER_02
Transcript:  Yeah, he wrote the book How to Be Black.

Speaker: SPEAKER_01
Transcript:  Right. And so he has a great line in it.  I'll ruin what spoiler one line he says.  And if you haven't bought the book yet, you're a racist.

Speaker: SPEAKER_02
Transcript:  I immediately bought the book.  You know, I have a number.  Oh, you do. I do.  Ten thousand.  That's how many steps you're supposed to take every day, right?  Do you know where that number comes from?  Japan. You know, don't you, Stacey?  Did you read this article? Did you know that before?

Speaker: SPEAKER_03
Transcript:  I did. But we knew it before.  This is like the third time in a row that this has popped up.  But that's OK. Keep going everywhere.

Speaker: SPEAKER_02
Transcript:  When you get one of these smartwatches or, you know, Google  Fit on your phone, it says, hey, ten thousand steps.  That's the secret to health that and eight glasses of water a day  and eight hours of sleep.  And don't forget breakfast is the most important meal of the day.  Wrong. Wrong. Wrong.  The reason for ten thousand steps.  Actually, it's a fascinating story.  A professor of epidemiology at Harvard's  T.H. Chan School of Public Health, I.Min Lee,  wondered where did ten thousand come from?  It turns out the basis for this ten thousand step guideline  was a marketing strategy in 1965.  A Japanese company was selling pedometers and they gave it a name  that in Japanese means the ten thousand step meter.  She believes that name was chosen because the character for ten thousand  in Japanese looks kind of like a man walking.  She says, as far as she knows, the actual health merits of that number  have never been validated.  In fact, she quotes a study of sixteen thousand elderly women  that found that really forty four hundred steps a day  makes a huge difference in your mortality rate.  It continues to drop to up to about seventy five hundred steps,  at which rate nothing more matters.  Now, that's elderly women.  And of course, one of the things that found even as little as ten  two thousand steps a mile of walking is associated with health, healthy outcomes.  So it's unknown how many steps is the perfect number, but it sure is not ten thousand.

Speaker: SPEAKER_03
Transcript:  They did a study on UK or maybe it was Scottish  postal workers on the number of steps they took and how that  correlated with their health outcomes.  So if you look up that study, it might offer you better data.

Speaker: SPEAKER_02
Transcript:  Yeah, I think we know that it's a good idea to get exercise every day.  You should walk just walking is great exercise.  Yeah, but you don't need to do ten.

Speaker: SPEAKER_01
Transcript:  Well, because that's the story of 2017 asking whether fifteen thousand steps.

Speaker: SPEAKER_02
Transcript:  Well, ten is good. Why wouldn't fifteen be better?  This is the problem with all media coverage of science. Yeah.

Speaker: SPEAKER_01
Transcript:  Yeah, right. It's like here's the latest word.  And that that that erases all other previous science.  It's just the exact opposite of how science operates.

Speaker: SPEAKER_02
Transcript:  So I apologize for repeating something you already knew, Stacey,  but I thought that was Stacey knows everything kind of happens a lot.

Speaker: SPEAKER_03
Transcript:  Oh, I'm just teasing.  I was I was referring less to you.

Speaker: SPEAKER_02
Transcript:  It's tough when you're a smart person, isn't it?  And all the people around you are stupid.  I just read a lot.

Speaker: SPEAKER_03
Transcript:  And I'm obsessed with my or my my Fitbit.  I got the charge three. I like it.

Speaker: SPEAKER_02
Transcript:  Yeah, you showed us. That's really nice. Yeah.

Speaker: SPEAKER_03
Transcript:  It doesn't change fundamentally from the I got a little surprise the other day.

Speaker: SPEAKER_02
Transcript:  So back in the early 2000s, I think I got one of those why things scales  and I set it up.  I don't know how maybe with this and that, I have to do some investigation  that it would tweet my weight.  And I remember that. Yeah.  Remember that? And it did it for a long time.  And then it hadn't done it for since 2015.  It hasn't done in five years.  I got another why things scale and I got a why things blood pressure monitor.  It started tweeting immediately.  So it was like somebody somebody told me, oh, I saw you.  Congratulations on your blood pressure. I said, what?  I said, how did you know?  She said you tweeted it.  So no, I didn't.

Speaker: SPEAKER_03
Transcript:  Yeah, so that's one of the steps when I talk about decommissioning device.

Speaker: SPEAKER_02
Transcript:  This thing's tweeting again.  It's like from the dead.

Speaker: SPEAKER_03
Transcript:  Yeah, that's that's one of those decommissioning device steps.  And that's why you do it.

Speaker: SPEAKER_02
Transcript:  Well, it's funny because I did decommission the device, but what I didn't I  and I to this day don't know.  I don't know where I set up a script, but it must be somewhere.  I have to find this probably if this and that.  Yeah, that's so Leo's underscore scale on Twitter.  I may not have a Twitter account, but my scale does.  And it's it's active again.  That was the what a weird thing.  It's like, oh, yeah, it's like it's like a ghost.

Speaker: SPEAKER_01
Transcript:  How's the diet, Leo?

Speaker: SPEAKER_02
Transcript:  It's great. I've been doing.  You're looking. I've lost.  I don't know.  It's about a pound a week for the last four months, something like that.  Fifteen, 14 pounds and continuing to do so.  Yeah, I'm doing.  It's a startup at a Silicon Valley.  The guy who became the chief  physician spokesperson for ketogenic diets, Stephen Finney,  did a startup called Virta Health.  And you have to be pre-diabetic or type two diabetes or to do it.  And so I qualified.  So I signed up for about three months ago, four months ago.  And it's been great. It's worked very well.  And I'm very happy.  But now you can find out by following my scale.  Ladies and gentlemen, the smartest person in the room is about to leave.  That's Stacey Higginbotham.  She is. She's in her new home in beautiful Seattle.  Stacey already knows it.  And she knows it.  We appreciate it. Stacey, her podcast, Stacey.  The IOT podcast with Kevin Toffel is available at Stacey on IOT.com.  Subscribe to her free newsletter, too. It's great.  It's a great read.  We love it. Thank you.  And are there new opportunities for you in Seattle  or you just felt like relocating?

Speaker: SPEAKER_03
Transcript:  I was like, there's opportunities to go hiking and kayaking  and all kinds of fun things.

Speaker: SPEAKER_02
Transcript:  Yeah, Lisa and I want to move to a low or no income tax state.  So Washington is on the list.

Speaker: SPEAKER_03
Transcript:  Yeah, I know. But if you don't have your business, you're OK.

Speaker: SPEAKER_02
Transcript:  Well, it's when we retire. OK.  Yeah. So we are actually planning a trip to Seattle to scope out the scenery.  OK, well, let me know when you're here.  I'll let you know.  So you can avoid me. So you can be out of town.  Yes, that is it.  So you can buy me some of that great Seattle queso.  They're so famous for.  We'll come up with something better.  Jeff Jarvis, he is the director of the Townite Center for Entrepreneurial  Journalism at the Craig Newmark's Graduate School of Journalism  at the City University of New York, blogger at BuzzMachine.com  and a great author, prolific author of many books, including  as prolific as I wish, Public Parts.  When's the new one coming out?  When's it? When's the first page?

Speaker: SPEAKER_01
Transcript:  Yeah, but I've just got no time.  So many projects.  That's my excuse.

Speaker: SPEAKER_02
Transcript:  It's you know, whatever happened to publish or perish, Jeff?

Speaker: SPEAKER_01
Transcript:  I know I'm perishing slowly.

Speaker: SPEAKER_02
Transcript:  No, we all are.  You're doing pretty good for a former TV guide critic.  I just want to say  really amazing, really.  Thank you, guys. It's always a pleasure.  I love it when it's always the core group.  You guys are fantastic.  We do this show on Wednesdays round about 130 Pacific, 430 Eastern, 2030 UTC.  You can watch or listen live at Twitter TV slash live.  If you want to download copies of the show for later consumption, audio  and video lives on our website, Twitter TV, actually for all of our shows.  But this one is Twitter TV slash twig.  You can also subscribe in your favorite podcast application.  That way you'll get it automatically the minute it's available.  I'm so glad you were here.  There it is, Twitter TV slash twig.  I'm so glad you were here and I hope you will return next week.  We'll see you then on this week in Google.

