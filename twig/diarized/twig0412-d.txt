;FFMETADATA1
title=The Yodeling Pickle
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=412
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf58.76.100
Failed to align segment (" I mean, show the over the shoulder shot."): backtrack failed, resorting to original...
Failed to align segment (" I think this is clearly the inspiration for the wand."): backtrack failed, resorting to original...
Failed to align segment (" Oh, we did play it on the show, that's right."): backtrack failed, resorting to original...
Failed to align segment (" $129?"): no characters in this segment found in model dictionary, resorting to original...
Speaker: SPEAKER_02
Transcript:  It's time for Twig, this week in Google.  Stacey Higginbotham's here, Jeff Jarvis is here.  We're gonna get into some raging debates coming up  on privacy, on sexism, on yodeling pickles.  It's all next on Twig.  Netcasts you love.

Speaker: SPEAKER_00
Transcript:  From people you trust.

Speaker: SPEAKER_02
Transcript:  This is Twig.  Bandwidth for this week in Google  is provided by Cashfly.  C-A-C-H-E-F-L-Y.com.

Speaker: UNKNOWN
Transcript:  This is Twig.

Speaker: SPEAKER_02
Transcript:  This week in Google, episode 412,  recorded Wednesday, July 5th, 2017.  The yodeling pickle.  It's time for Twig, this week in Google,  the show where we talk about the latest news  from the Google-verse, from the Facebook-verse,  the Twitter-verse, from new media, old media.  Really, it's a wide-ranging conversation  on a variety of topics with some of the smartest people  I know, starting with Stacey Higginbotham.  You remember her from GigaOM.  She now is doing her own thing at stacey on iot.com.  And subscribe to the newsletter there.  And she has a podcast with Kevin Toffle, iotpodcast.com.  Giga Stacey, ladies and gentlemen.  Hello, Stacey!

Speaker: SPEAKER_03
Transcript:  Hello, I cleaned up my study, you see?  No boxes.

Speaker: SPEAKER_02
Transcript:  Are you gonna ever hang anything on the wall there?  See, we're not gonna stop shaming you.  It looks like you just moved in.

Speaker: SPEAKER_03
Transcript:  Look, see, there's stuff.

Speaker: SPEAKER_02
Transcript:  Oh, I can't, this is the wrong camera.  Yeah, see, there's more stuff in the other place.  But your back, oh, there's your whiteboard,  which is very clean.  I like whiteboard, yeah.  A clean whiteboard is a clean mind.

Speaker: SPEAKER_01
Transcript:  Did we shame you into taking the boxes away?

Speaker: SPEAKER_03
Transcript:  Oh, no, no, I just, I cleaned up.  I had, we had a party yesterday.

Speaker: SPEAKER_02
Transcript:  Oh, fun, the Fourth of July event.  Did you do a barbecue?  I don't know who you are in Austin, Texas.

Speaker: SPEAKER_03
Transcript:  No, no barbecue, although I did make,  I made excellent ribs.  I can share the recipe with you guys.

Speaker: SPEAKER_02
Transcript:  I would love it.  Oh, I bet.  Stacey's an amazing resource in so many ways.  Stacey on iot and the Internet of Things podcast.  Also here, Jeff Jarvis, professor of journalism at CUNY,  the City University of New York.  He's also a book author, written many books,  including What Would Google Do?,  Geeks Sparing Gifts About Reinventing the News Industry,  blogs at buzzmachine.com,  and he's at Jeff Jarvis on Twitter.  Hello.  Hello.  I have to share a little personal story with you.  My son, who as you know,  went to the new journalism program at Colorado, CU Boulder,  graduated in the June, May, I guess I was out there,  and he was desperately looking for an internship,  and I did everything I could to connect him,  emailed Lance Yulanov at Mashable,  all sorts of people,  was not able to get him an internship.  However, he did get an internship  at the Center for Investigative Journalism,  which is a pretty good internship.  CIR is great.  Yes, CIR.  They are spectacular.  They're 40 years old,  the longest running independent investigative reporting  outfit in the world.

Speaker: SPEAKER_01
Transcript:  And one of the most advanced in visionary attitude.

Speaker: SPEAKER_02
Transcript:  It's just they're just great.  Because they've created a new site called revealnews.org.  That's new media.  And he's gonna be working there.  But then it turned out,  so he's become buddies with Phil Bronstein.  I know you know Phil.  Yeah, yeah, yeah.  Was he your boss when you were at the exam?  No, no, he's too young, Phil.  He's too young.  So Bronstein, who's a famous journalist,  and apparently, I didn't know this,  had filed dispatches from El Salvador  during the revolution there.  And so Henry's job this summer  is to go through everything he's ever written,  Phil Bronstein ever wrote at The Examiner.  He became editor in chief later.  And prepare, do the research for a documentary  about Phil Bronstein.  Wow.

Speaker: SPEAKER_01
Transcript:  Yeah.  Does this include Sharon Stone stuff?

Speaker: SPEAKER_02
Transcript:  I don't, but probably.  I mean, that's the sad thing.  In fact, Henry was saying,  gosh darn it, everything I find mentions Sharon Stone.  Can we just get this?  He married Sharon Stone briefly  and also famously got bit by a lizard.

Speaker: SPEAKER_01
Transcript:  Bitten by a, well not a lizard,  by a Komodo dragon, was it?  Komodo dragon, yeah.  Seriously, bitten, severely injured.  On his foot.

Speaker: SPEAKER_02
Transcript:  Came through.  Yeah, he came through.  It's one of those horrible things  that end up being kind of comedic.  Yeah.

Speaker: SPEAKER_01
Transcript:  Wow, congratulations to Henry.  I know, isn't that?  That's phenomenal.

Speaker: SPEAKER_02
Transcript:  You know, I had nothing to do with it.  He just, I don't know, you know.  All the better.  Yeah.  Actually, it goes back to his birth  because I think it was when he was a baby  or maybe when my other child, Abby, was a baby.  I think it was when Abby was a baby.  My wife, after the baby was born,  would go back to the Cal Pacific Medical Center  for baby mommy and me classes  where you learn how to nurse and all that stuff.  And she met a very lovely lady  who'd also had a baby at the same time.  And she came back and said,  oh, I just made great friends  with this wonderful woman and her child.  Her name is, I don't know,  her name is Maggie Hurst.  Should I know that name?  And I said, yeah.  That's where the Will connection comes.  Oh.  Yeah, so it really goes back to that.  Oh, wow.  Oh, I was just about to ask you.  Maggie's married to Will Hurst,  who ended up, the Hurst became great friends.  And so I guess Henry got called Will  and Will got him the job.  Because Will is a big benefactor to the CIR.  He really is.  Yeah, which is great.

Speaker: SPEAKER_01
Transcript:  That's just great.  Congratulations.  But then tell him what he's done with the internship.  You know what he's doing?  What?

Speaker: SPEAKER_04
Transcript:  Oh, he's getting a graduate degree at CUNY.  I agree.

Speaker: SPEAKER_02
Transcript:  Yes, he is.

Speaker: SPEAKER_03
Transcript:  Yes, he is.  Wait, shouldn't he get a journalism job first?  Shh.  He does have one.

Speaker: SPEAKER_02
Transcript:  Sorry, no.  Actually, what I told him is this is an internship,  but this is gonna turn into a job.  And probably for life, right?  Stay at the CIR, why not?

Speaker: SPEAKER_01
Transcript:  That's their great place.  They do some amazing things.  They do news as comics.  They do plays and dramas to communicate news.  You might have heard about NPR.

Speaker: SPEAKER_02
Transcript:  They do a lot of reports on NPR.  But yeah, if you go to revealnews.org,  this is their new media site, and it's really good.  It's really good.  And I think-  So do they?  Go ahead.  Do they pay?  Well, he's not getting paid right now,  but they do have money because they are,  I mean, it's nonprofit, but they are, I think-  So it's not a paid internship?  Well, in doubt.  There's a button that says donate on the page.

Speaker: SPEAKER_03
Transcript:  I'm just curious,  because the more prestigious the journalism internship  is, the less it paid.  So I did my journalism internship  at Texas Highway Patrol Magazine.  See?  You see?

Speaker: SPEAKER_02
Transcript:  You see?

Speaker: SPEAKER_03
Transcript:  Where I laid out all the stories edited  and commissioned freely as a software.  That's how you learn.  But I did it because they paid.

Speaker: SPEAKER_02
Transcript:  Oh, well, even better.

Speaker: SPEAKER_01
Transcript:  So at the CUNY Graduate School of Journalism,  we require an internship after two semesters  and going into the third and final.  And if the employer does not pay, we pay.  We raise money to do that so that every student  can afford to do the required internship.

Speaker: SPEAKER_02
Transcript:  Yeah, and I told, it was one of my deals with Henry,  because I think internships are so important.  Most of them are, if not unpaid, mildly paid.  I think we pay $5 a day or something.  Those jobs are really how you get a real job.  Those are the skills you learn,  but also the people you meet.  And very often, working free for someone  is a great way to get a paid job with somebody.  So I told Henry, if you do go out of school  and get an internship,  I will continue to support you for a little while anyway.  Is he living?  They're in Emeryville.  He's living here in Petaluma.  Community.  Yeah, so it's not too bad.  Yeah, he goes to the San Francisco Library every day,  because after the Examiner was sold,  they didn't digitize any of it.  It's all in microfiche.  So he's learning a really useful skill as a journalist,  how to use a microfiche reader.  Microfiche.

Speaker: SPEAKER_01
Transcript:  Well, when he runs across,  if he runs it across any old take five columns by Jeff Terps.

Speaker: SPEAKER_02
Transcript:  I know, I know.  I thought that was hysterical.  And I told him, you gotta read up on the history  of the San Francisco Examiner and the Chronicle.  I had to tell him, in the old days,  every town would have two papers,  a morning paper and an afternoon paper.  At least two.  But then over time, there wasn't enough money for both.  So it ended up usually being one paper.  And then in some towns, no paper.  And what's paper would be the next question.  We live in an interesting age.  So how long did you work for the Texas Highway Patrol?

Speaker: SPEAKER_03
Transcript:  I think it was two semesters.  See, that's a great internship.  So I also was an RA at the time,  and I was a substitute babysitting,  or a substitute daycare teacher.  So I could have actual enough money.

Speaker: SPEAKER_02
Transcript:  Good for you, spending money.  You worked your way through school.  Good for you.  I worked in the dining halls  because that was the highest hourly wage,  which I think at the time was like 350 an hour.  That's how long ago that was.  But that's what I did all four years of school.  Wow, all four years.  Well, I didn't go for four years,  but I did it for four years.  I ended up dropping out of school  and keeping the dining hall job.  That was not a good career move, but.

Speaker: SPEAKER_03
Transcript:  Life goals.  But your parents were real proud, Leo.

Speaker: SPEAKER_02
Transcript:  But I dropped out of school in my junior year  so I could work at the campus radio station.  So, and that paid.  So I was able to do that in the dining hall.  But I was there until my class graduated,  because I don't know why.  I was loyal.  I was loyal to them all.  So we spent a lot of time on Sunday on Twitter,  on This Week in Tech.  I kind of rejiggered the panel  because I want to make sure we had at least one woman.  We called and got Katie Benner  who wrote the New York Times article  about harassment in Silicon Valley.  Really blew the lid off of it.  It all started, and credit to Reid Alberghati  over at The Information,  who broke the story of Justin Kaldbeck.  And Kaldbeck, of course, a venture capitalist  who was accused by at least six women  of using his position of power  to harass, sexually harass women who were,  women entrepreneurs who were trying to get funding.  I mean, that is as bad as bad as you can get.  And then Katie Benner in her article  for the New York Times furthered the story  by talking about Chris Sacca,  another very well-known venture capitalist.  Dave McClure of another very famous,  and Mark Cantor, a very famous entrepreneur,  all three of whom apparently did something similar.  In fact, Dave McClure in Medium,  shortly after the New York Times article,  wrote a mea culpa, a confessional piece  in which he said, I'm a jerk.  You know, you got me.  And it stepped down from his position.  Chris Sacca has, I'm a creep,  I'm sorry was the name of that story.  Chris Sacca has continued to kind of deny the allegations  as has Mark Cantor.  But nevertheless, these are well-known people  in Silicon Valley, not so much Justin,  but these two very well-known.

Speaker: SPEAKER_01
Transcript:  Mark Cantor's was much worse.  You know, he said that, well,  I feel like a jerk to get rid of her.  Yeah, he really denied it.

Speaker: SPEAKER_03
Transcript:  That was really.  That was awful.

Speaker: SPEAKER_02
Transcript:  Yeah.  So, I mean, it's clear that at least some  of these allegations are found.  And in fact, I mean, both Kaldbeck and McClure  have left their positions.  And in fact, the Kaldbeck's fund has been dissolved.  Oh, really?  Yeah.  Yeah.  McClure apparently had decided to quit earlier,  but as it turns out, now there's still, by the way,  there's still a lot of conversation about all this  in Silicon Valley and elsewhere.  He apparently, they knew about this  and they didn't maybe act on it as quickly as they should.  Christine Tsai, who is his partner  and now runs the fund, 500 Startups, says, I didn't know,  but he'd said he was gonna step down earlier this year  anyway, and anyway, there's a lot more to this story.  And I don't, we don't need to go into the deets  of these specific story as I'm much more interested.  And I know Stacey, you wanted to talk about this.  In the culture, I have to say though,  the conversation is really important.  And I have to say that as we've started talking about this,  I've heard from everybody I know, oh yeah, I've been harassed.  And not just in the tech business,  but every woman has been harassed,  at least once, if not many times.  How much worse is the tech business?

Speaker: SPEAKER_01
Transcript:  That's a good question.  Yeah, that's, that's-  I don't think it is.

Speaker: SPEAKER_03
Transcript:  Okay, well, whoa, whoa.  Okay.  I would say I've worked in finance.  So I worked when I was very young,  my first job was bond traders and working at the bond buyer.  That's a bunch of bros.  It's a bunch of bros.  It's a very-

Speaker: SPEAKER_02
Transcript:  Big swinging you know what's.

Speaker: SPEAKER_03
Transcript:  Yeah, I'm like, yeah, there's harassment there.  Then I worked actually here in Austin,  where I dealt with a lot of the real estate guys.  And they were at the time,  I guess you could get porn on your smartphones.  And I vividly remember sitting at a table,  like at a gala with some real estate guys,  and they were like showing me the porn on their smartphone.  And I'm a 23 year old kid.  Yeah, isn't that sweet?

Speaker: SPEAKER_02
Transcript:  I'm like, ew.  My wife worked in the construction industry, similar.  Oh yeah.  Similar, very few women and very macho culture.

Speaker: SPEAKER_03
Transcript:  And then yeah, tech guys are also bad.  So honestly, I think, let us say,  oh, hey, I think the issue here is that the tech industry  is not as enlightened as they maybe thought they were.

Speaker: SPEAKER_02
Transcript:  And not as diverse as it needs to be.

Speaker: SPEAKER_03
Transcript:  Well, we've known that forever.  I mean, I was kind of getting to that  from an economic diversity when I was asking  about internships and journalism being paid, for example.  That's a different kind of diversity.  We're not talking about that here,  but I mean, these are conversations everyone  should be having across the board,  both economic, racial, gender, all of that needs to be,  if we want to fix where we are, right?  So those are the big macro kind of questions.

Speaker: SPEAKER_02
Transcript:  Boys will be boys.  Wrong.  If there aren't enough women around to say,  knock the heck out, stop it.

Speaker: SPEAKER_03
Transcript:  So that's not, I mean, and most women aren't going to do it  because boys still have the power  and you don't want to be seen as.  Right, that's right.

Speaker: SPEAKER_02
Transcript:  So until women are equals in power, I would submit,  that's going to be a problem.

Speaker: SPEAKER_03
Transcript:  You should not say the word boys will be boys.  You as a person, Leo, should say,  hey, there's not enough women in power.  I'm going to say, hey, stop it, don't do that.  And I have worked for some real jerks  and I've worked for people who are amazing.  And I'll call it own for being really amazing because.

Speaker: SPEAKER_02
Transcript:  Right, he set a great culture.

Speaker: SPEAKER_03
Transcript:  He did, and I remember someone writing  on the bottom of a blog post.  It was a picture from one of our structure events  and it was a picture of me sitting,  talking to some person at a cloud computing event.  And the person wrote great legs.  And I saw this and I was like,  oh my God, that's so embarrassing.  And Ohm just without even thinking about it,  just deleted it and was like, sent a note to the person,  was like, screw you,  we don't want your kind here on our site.

Speaker: SPEAKER_02
Transcript:  Good for Ohm, I love that.  I don't say boys will be boys to in any way condone it  or even say it's okay, but just that this is what happens  when you get a bunch of men together.  You go in a locker room.

Speaker: SPEAKER_03
Transcript:  It doesn't have to happen.  I get lots of men. It doesn't, but it does.

Speaker: SPEAKER_02
Transcript:  I agree it shouldn't happen, but it does.  And somebody in the chat room saying,  I worked in construction.  There's not a single construction office in the country  that doesn't have a adult calendar on the wall.  Now, if there were women executives  that would stop immediately.

Speaker: SPEAKER_03
Transcript:  It might not.  Some women internalize a lot of this.  I guess.  I'm looking at Google's diversity report,

Speaker: SPEAKER_02
Transcript:  which just came out.  This is overall 69% men, 31% women in general.  If I go to tech, which is what we really care about,  it goes down to 20% women.  The thing I see also very shameful,  1% black, 3% Hispanic,  53% white.  The next largest ethnicity is Asian, 39%.  So this is Google who's trying,  apparently trying very hard to create diversity.  But if you are in an environment like this,  I think that's very hard on the one in five women.

Speaker: SPEAKER_01
Transcript:  Lyle, yes, I think that's true.  What should frighten us more is that when one,  for whatever reason, one person has the courage to come out  and expose this, the number who then follow.  Yeah, look what's happened.  Whether it's BC or whether it's Bill Cosby  or any of these cases.  So it's not a numbers game.  I think Stacey's quite right.  It's a power game no matter what.  And even if the numbers are 50-50,  there's intimidation that goes beyond even that.

Speaker: SPEAKER_02
Transcript:  Oh, absolutely.  And you know, aggressions of all kinds.  And we should, I agree with you, Stacey,  we should all be more like OAM.  And even if there aren't women in the workplace,  there should be men in the workplace who say, knock it off.  Exactly.

Speaker: SPEAKER_03
Transcript:  And I would say, so here's my advice  to guys in the workplace.  It's just basic rules that I can't believe someone,  they don't know.  But if you're dealing- Their mothers didn't teach them.  Their mothers didn't, or their fathers.  I mean, my brother- Yes, yes, sorry.  Sorry, I'm like, we are not putting in this,  all on the women.  Sorry, Jeff. No, no, no.  This is a hot button. No, no, no.

Speaker: SPEAKER_02
Transcript:  But the real problem is that men-  Wait, Leo, Leo. Go ahead.

Speaker: SPEAKER_03
Transcript:  Please give you my rule.  Okay, rule is, I should never know  if you wanna sleep with me in a work environment.  And you're dealing with a woman.

Speaker: SPEAKER_02
Transcript:  That's a good rule, I like that.

Speaker: SPEAKER_03
Transcript:  Any woman you're working with should never know  if you wanna sleep with her or not,  because it's completely irrelevant  to your professional relationship, period.  And if you follow that rule, you're great.

Speaker: SPEAKER_02
Transcript:  That doesn't mean just not saying I wanna sleep with you.

Speaker: SPEAKER_03
Transcript:  No, it means all of the flirty,  weird things that people do.

Speaker: SPEAKER_02
Transcript:  But let me, but what I, I think that's a very good rule.  And the thing I would say is that most men  wanna sleep with most women.  So the difficulty, and the reason men kind of gloss this  over is, well, we're all thinking this anyway.  So it really is, it's gotta be at a behavioral level.  You can't, I don't think you can teach men  not to think that.

Speaker: SPEAKER_03
Transcript:  Right, I don't care what they think.  I just should never know.  I love that rule.  I love that rule.  I work with so many men, and I work really closely  with lots of men.  I honestly, I don't give it much thought,  but when I was thinking about this rule,  I was like, God, did any of them wanna sleep with me?  And I have no idea.

Speaker: SPEAKER_02
Transcript:  Good. Zero.  That's good, I like that a lot.  So.  And you can tell I don't wanna sleep with you, right?

Speaker: SPEAKER_03
Transcript:  That, I don't even think about it.

Speaker: SPEAKER_02
Transcript:  No, it shouldn't come up.  It shouldn't even be, no, that's such a great rule.  I've never heard it articulated like that.  And I think that that's, if it comes down to it, that's it.  But you really gotta say, that doesn't just mean  you say something, it means showing you porn at a dinner.  It means having a sexy calendar even in your office.  It means treating you with respect.  Yeah, treating women with respect, yeah.

Speaker: SPEAKER_01
Transcript:  And also, Stacey, Stacey, let me say this if I may,  because I'm an offender on this one,  it means not interrupting.

Speaker: SPEAKER_03
Transcript:  I interrupt.  I just interrupted you.  I mean, we're on a talk show.  I totally don't, I don't think anything of us  when we interrupt.

Speaker: SPEAKER_02
Transcript:  Well, and there's a technical reason for interrupting  because we're on Skype and there's some delay between.

Speaker: SPEAKER_01
Transcript:  Oh yeah, I mean, I'll take the handicap points.  But I agree with you.  I agree with you.  I watched a panel last week, or VidCon,  and there were two men and one woman.  And she tried like three times to break in  and was interrupted and then finally sat back  with that grin that said, yeah, okay, well, I'm normal.  And we're just not aware of it enough.  I'm not aware of it enough.

Speaker: SPEAKER_02
Transcript:  It's mansplaining, it's interrupting.  There's a lot of that too.  So it does go to even beyond that, not knowing that you.

Speaker: SPEAKER_01
Transcript:  So Stacey, let me ask you this.  As African-American men were being shot by police  in America and we saw lean African-Americans  say that they had, including the president  of the United States saying that they had the talk  with their children.  As a woman, did anyone ever have a talk with you,  mother, coworker, mentor, about what would happen  to you in the workplace and how to deal with it?

Speaker: SPEAKER_03
Transcript:  Let's see, I'm gonna say no.  I mean, my mom was a geophysicist.  And so she was in the oil industry,  which was hugely male dominated.  And yeah, I don't, I mean, she met my dad  on an oil boat though.  So I'm kind of like, no, no one ever had the talk.  I will say I talk with my daughter about,  I train her to notice things like we were,  we were in Harry Potter world.  And this is kind of silly, but some little boy  who was probably her age got on the,  we were in the train and he and his family got in  and we were on our side.  And a little boy just stopped, talked and talked  and talked and talked and just, ah.  And I finally, you know, I did not tell the boy to shut up  but I was like, man, I would tell my daughter to shut up  at this point, because it was really annoying.  But the boy's family didn't tell him to shut up.  And Anna, my daughter, you know, she turns to me  and she's like, man, he talked a lot.  I was like, he did.  And I bet, you know, if you had been talking  I would have told you to stop talking,  but no one shut him up.  In fact, they kind of were all grinning and like humoring him.  And that's again, that could be a totally  just different parenting style.

Speaker: SPEAKER_02
Transcript:  It can go both ways too.  Cause my daughter was, would dominate dinner conversations.  And my wife and I often talked about,  how do we get Henry into the conversation?  The kid just never gets a word in Edgewise.  So it can go, that's a personality style too.  It's not merely a gender style.  That's true.  Let me show you Apple's diversity report, just to be fair.  Looks like Apple's doing a little bit of a better job  with Google.  Now they talk more about what we've done lately  than the overall, but you see new hires 37% in 2016.  But here-  Like down tech versus store and such.  They don't do, no, and I wish they did.  Yes, store changes things, doesn't it?  And I wish they did say, you know,  among our tech employees, our engineers, they don't.  At least not as far as I could see, but here is,  the number you want to look at to compare it to Google's  is the bottom number here.  So 19% Asian, this is totals,  9% black, 12% Hispanic.  This is not, this is ethnicity is not about gender.  And then I think the big story too is pay equity, right?  We know that that doesn't happen still.  Then Google's been dinged for not paying its females.

Speaker: SPEAKER_03
Transcript:  Yeah, I was gonna see, did they ever give that information  to the-

Speaker: SPEAKER_02
Transcript:  Yeah, I don't know what the new-  Department of Labor?  I don't know what the latest is on that.  Does the current Department of Labor give it?  Do they care?  That's a really interesting question.  That was a story we talked about a couple of months ago,  but nothing.  Google refuses to hand over salary data  after Labor Department accuses it of underpaying women.  That's back in, that's in June.  So I guess they're continuing to do that.  That's, this is current.  So Google says, of course we pay women fine,  but we're not, and the numbers would be misleading.  I don't know.

Speaker: SPEAKER_03
Transcript:  Well, and that's two different issues.  So harassment, one issue, right?  Is it two different issues?  They're related, but I would say a bigger problem  in Silicon Valley, so if you're dividing it into harassment  and pay equality or discrimination based on gender,  so separate from sexual harassment,  there's more on the discrimination by gender  that I think, it's a different topic,  and it's also part of Silicon Valley's mythos  of the incredibly hardworking entrepreneur  with no family, et cetera, et cetera.  So I think that dings women too.

Speaker: SPEAKER_02
Transcript:  It dings everybody.  I mean, that's a terrible culture, right?

Speaker: SPEAKER_03
Transcript:  It is, but women bear the brunt of that culture  and they bear it not just in the tech,  they bear it in other industries like law and finance.

Speaker: SPEAKER_02
Transcript:  I go home to this issue all the time  because my wife runs our company.  She's a CEO, as I said, she used to work in construction  and she's tough.  She's really tough and she had to be tough, I think,  to work as one of the sole females  in the construction industry.  And she's tough today.  And she's been harassed endlessly.  So she's tough enough to stand up to it in most cases,  I think in every case.  But not everybody is, and not everybody's in a position  where they could be.

Speaker: SPEAKER_03
Transcript:  You shouldn't have to be tough.  I agree.  You don't know what your wife has internalized  or where she could have focused her energies  and what she could have done  if she didn't have to deal with all that BS.

Speaker: SPEAKER_02
Transcript:  Well, it's true.  That's a good point, yeah.

Speaker: SPEAKER_03
Transcript:  Maybe she would have married someone else  and had an even better life.

Speaker: SPEAKER_02
Transcript:  No, I'm kidding. Oh, thanks a lot.

Speaker: SPEAKER_01
Transcript:  Jeez, jeez, what'd he do to you today?

Speaker: SPEAKER_02
Transcript:  I'll just have you know,  I keep my harassment to the bedroom.  That's where your harassment belongs.  Hey, honey, you're looking good today.  Anyway, I'm glad, Stacey said it before the show started,  I wanna talk about this.  We did make a point of talking about it on Sunday.  It is a huge story.  And I think the Silicon Valley story is a big deal  because we think of ourselves,  tech people think of ourselves as enlightened,  Exactly. merit-based.  We think it's a meritocracy, but the numbers belie that.  And now the facts belie it.  Again, credit to Susan Fowler,  her blog that blew the lid off Uber.  I think some, I have to say, Jeff,  now I'm gonna get political,  some of this comes from the top, right?  And the climate in this country  and the tribalism in this country.  And there is definitely,  it almost feels like a retrenchment,  a move backwards in terms of  what we used to call women's lib,  in terms of empowering women.  And I feel that's really unfortunate,  but there's definitely,  same things happen with racism in this country.  There are a group of people in this country.  There are a group of people in this country  who have suddenly become empowered.  Because of the election of President Trump  and kind of the general tenor of his tweets.  By the way, you've come around to my point of view,  haven't you?  That we let Trump tweet.

Speaker: SPEAKER_01
Transcript:  Oh, oh, I've come around?  Oh, absolutely, I agree.  I get so angry when journalists say,  he shouldn't tweet, it would be wrong for him to tweet.  Why shouldn't he stop tweeting?  No, let him implicate himself in every crime possible.

Speaker: SPEAKER_02
Transcript:  It is bad for the country that he's tweeting, I suppose.  It's bad for our reputation, bad for our relationships.  It's a true view of where we're going.  But at the same time,  if it's an insight into the mind of the leader  of the free world, I think that's a valuable tool.

Speaker: SPEAKER_01
Transcript:  Leo, back to your prior point.  I think you need to have data to say whether the Delta,  where's the Delta going?  Because certainly before the current administration,  we had plenty of problems with racism in this country.  I agree, but it's purely anecdotal, I agree.  And, but what you also see is that  when a group is threatened,  they respond as threatened animals, right?  And so that's what we're seeing when it comes,  that's what the basis of the nationalism we're seeing is.  That the white majority of America,  the male majority of America,  the male powerful America,  is not the majority or not the powerful as much.  And so then they react.  So then you see things like the so-called,  horribly named men's rights movement.  You see Gamergate, you see all that kind of stuff emerging.  And it's a reaction against a trend  that is going against them.  And so it's kind of a last gasp fight.  And that's what I believe is going on right now.  And-  That's what I hope is going on.  But it's, boy, it's a painful, painful stage, isn't it?  You know, I also think that the nation  is challenged as an institution  and thus nationalism is rising.  I would also-  White majorities are challenged.  I would also to be-

Speaker: SPEAKER_02
Transcript:  A national-  To point out that Lisa says this, she says,  if I had been the woman I am  in many other countries in the world,  I would be dead by now.  And we should point out that as we talk about  how bad it is for women here,  but it is far worse in many countries of the world.

Speaker: SPEAKER_01
Transcript:  Well, so I was talking to the colleague today about,  oh, sorry, Stacey, go ahead.

Speaker: SPEAKER_03
Transcript:  I was just gonna say that kind of relativism does,  that is nothing.  It is, sorry.

Speaker: SPEAKER_02
Transcript:  I agree, it's still bad,  but I just wanna say that we've made some progress.

Speaker: SPEAKER_01
Transcript:  Well, let me put it, let me try it this way.  So I was talking with my colleague  who's gonna run the News Integrity Initiative today  about diversity is one of the pillars that we wanna face  because we think that news organizations  that don't have diversity,  don't understand the communities  that they are to serve and reflect,  and having greater diversity will help them with that.  It's pretty straightforward.  We at CUNY take that as a major part of our mission.  So then we were talking about, I said,  well, how do we internationalize that topic  as we're supposed to be international?  And as I was thinking about it, let's be very, very clear.  The United States, we are bad at this.  We still have a great long way to go with this.  However, there is far more discussion of diversity  in the United States because we've been bad at it,  because we have a racial problem,  because we had slavery, because of all these reasons,  that if you go to Europe,  you hear far less discussion of diversity  and the impacts of diversity on companies  and on how they operate.  So the weird thing is even though we're way behind  and where we should be, we have a discussion here  that I think could be also brought to other countries,  could be brought to Europe and elsewhere in the world,  that would be beneficial to never stand above  and say that we're high and mighty and doing so well.  We're not, but the discussion itself needs to be exported.  Does that make any sense?  It does.

Speaker: SPEAKER_03
Transcript:  But it was like, where's my gadgets?  No, no, no, not at all.

Speaker: SPEAKER_02
Transcript:  I'm very willing to talk about this.  I think it's very important.

Speaker: SPEAKER_03
Transcript:  Yes, and I think there's a couple things here  and it's hard to talk about right now  because it feels like we're in kind of the nadir  of our diversity experiments in some ways,  but immigration and opening our borders  has unequivocally helped make America truly great, right?  And many other countries, if you look at Japan  and parts of Europe where immigration is frowned upon  and they don't welcome people in,  they have problems associated with that.  So in a lot of ways, it is a conversation  that everyone should be having.  And so I agree.  Long way of saying I agree.

Speaker: SPEAKER_02
Transcript:  It's happening, this is why it's kind of shocking to us  in Silicon Valley  because we really thought we were better than this.  Look at Tesla, which you would assume  is a very forward-looking company.  They've had some serious accusations  and now they have a diversity panel  on International Women's Day.  They invited their female staff to a diversity panel,  actually it was originally going to be  an essential oils lunch and learn,  but then people complained that, wait a minute,  that's what you want us to talk about  as ladies on International Women's Day?  No, well let's have a diversity panel.  And it turned up even more issues.  New allegations according to Engadget  are gonna make it hard for Tesla to downplay the accusations.

Speaker: SPEAKER_03
Transcript:  It's the Guardian that they're reporting on this.  Yes, actually, let's go to the Guardian.  Sorry, I'm like, hold on,  I read this this morning and I was like boom.

Speaker: SPEAKER_02
Transcript:  I read it and Engadget, but it's linking back to this.  She took on Tesla for discrimination,  now others are speaking up.  It's too big to deny.  A female engineer who came forward with claims of harassment  says she was fired in retaliation,  but now other women are stepping forward.  So instead of discovering essential oils,  they're maybe focusing a little bit more on,

Speaker: SPEAKER_03
Transcript:  When they did this open forum,  instead of the essential oils,  they heard about how women would avoid  parts of the factory floor  because they were getting catcalled.  They called them predator zones.  Yes, which kind of tells you a lot  about what it's like to be a woman  in some of these places and how,  how the word inappropriate covers a multitude of sins,  all of which are bad,  and some of them are more inappropriate than others.  I have to say, I think a lot of this is

Speaker: SPEAKER_02
Transcript:  because we as men are not taught that it's bad.  They should be.  There's this kind of sense that,  oh, boys will be boys,  that's why you didn't like me to use that phrase,  but that's the phrase that's used,  and that's how guys are,  and they're always gonna hit on women,  and they're always gonna hit on women,  and give them catcalls.  The gals, they secretly like that.

Speaker: SPEAKER_03
Transcript:  What about younger women though, or younger men?  I don't know.

Speaker: SPEAKER_02
Transcript:  I'm an old man, so I can't speak for younger men.

Speaker: SPEAKER_03
Transcript:  I'm curious about what's happening generationally  and how attitudes have shifted  because my generation,  we got a lot of the quote unquote nice guys,  which aren't nice.  They're just like, I'll pretend not to be a jerk  on the surface so I get someone to sleep with me.  But again, the-

Speaker: SPEAKER_02
Transcript:  By the way, I've been using that for years.  They're very effective.  Yeah.  Go ahead.

Speaker: SPEAKER_01
Transcript:  Leo plays this cuddly thing.

Speaker: SPEAKER_02
Transcript:  Yeah, the nice guy thing, yeah.  It's a good one.  Except that, well, nevermind.  It's gonna get even worse to say that,  the girls always like the bad boys.  That's the problem.

Speaker: SPEAKER_01
Transcript:  Well, that, yeah, that's-  I bought a leather jacket.  Those nice guys lose out.

Speaker: SPEAKER_02
Transcript:  I'm sorry, Stacey, go ahead.  Jeff, you and I, we're gonna go in the corner now.  Where is my punch, Leo button?

Speaker: SPEAKER_03
Transcript:  Where is that button?  Yeah, so the point is, yes, boys should be taught better.  I would encourage everyone, including you, Leo,  to excise the phrase boys will be boys  from your vocabulary and start making people,  acting as a role model and then also speaking up.  I mean, guys can see when guys are behaving badly.  And you should just be like, yo, dude, that's not cool.

Speaker: SPEAKER_01
Transcript:  Well, so here's a question, too, about our social age.  I'm fascinated by the Redditor who confessed  to creating the-  Wasn't that interesting.  Trump beats up CN video and did an apology of sorts  and CNN decided that he was, that person was he,  was-  He was a troll.  Confessing enough that they wouldn't reveal him  and wouldn't out him when there's some debate about that.  But what strikes me so much is that how far overboard  does an individual or a group or a society have to go  to realize that bad behavior is bad?  Do we have no hope of getting rid of trollish  and misogynistic behavior unless it goes so far overboard?  Unless the President of the United States grabs a woman by-  Do you know why you will not say-

Speaker: SPEAKER_02
Transcript:  CNN auto-play, sorry.

Speaker: SPEAKER_01
Transcript:  I, God bless CNN.  Will CNN never learn that it has to go overboard  with auto-play before discovery and everyone hates it?  So this is, I don't know, what is it gonna take  to recapture civility and sense  or to capture it in the first place  if we have to go this far overboard?  Somebody could post a whole mess of violence against media  and anti-Semitic things to say,  oh, right, I was just trolling, no, I was going too far.

Speaker: SPEAKER_02
Transcript:  That's what was interesting.  I wonder if that will often be the reaction or the result  if you out a troll, they'll go,  oh, you know, I don't really believe this anti-Semitic stuff.  I just was trolling.  I was just doing it for-  I was doing it for the loans.

Speaker: SPEAKER_01
Transcript:  Or the venture capitalist who says,  oh, okay, I confess, I'm a jerk because I have to.  Right.  Because that's what my PR person told me to do.  Now, I'm not saying that there isn't a possibility  to learn the lesson and to recant and that's fine  and that's exactly what someone should do.  So I welcome that.  But how do we teach the lesson  before getting over the cliff?

Speaker: SPEAKER_04
Transcript:  And I don't know-  And by the way, the cliff-  The social media world.

Speaker: SPEAKER_02
Transcript:  The cliff were right on the brink.  There were a number of CNN journalists tweeted,  I'm afraid for my life, that feels like a call to violence  by the president of the United States.  And that actually, it puts me in fear of my safety.

Speaker: SPEAKER_01
Transcript:  So this goes to Stacey's point,  that what you have, we all have to shun the bad behavior.  You can't sit back silently and let it happen  and then say, oh yeah, I agree with that.  That was awful.  I hated it when it happened.  We have to develop the norms and mores  to show that we do not accept bad behavior,  whether it's misogynistic or racist or whatever it is.  Sorry, Stacey.

Speaker: SPEAKER_03
Transcript:  Oh no, we used to do that.  Although in America, and this is a real,  this is a tension in our society.  We used to do that and you done to a certain way,  you become a very censored and repressive society, right?  And you could say, hey, being respectful of people  is not awful and censoring and whatever,  but it does require us to have some sort of common norms.  And right now we don't have common norms.  We're fragmenting into all these crazy different norms.  And it's one thing to say bygones be bygones,  but we're also kind of shouting all our weird norms  in these social media bubbles  where other people can stumble across them.  And I think this is really like structurally  and from a societal perspective, really fascinating.  And I'm not sure what we do with that  because I mean, you could argue my making ribs  is really offensive to someone who's a vegan  and who, I mean, and I'm not making fun of that.  I mean, there are people  who would feel very strongly about that.  And if I were in certain cultures,  making ribs would be a real problem.  And we just, we're all living together in these bubbles  where we see everybody else's bubbles and it's,  ah.

Speaker: SPEAKER_02
Transcript:  Here's an interesting question.  Actually the chat room kind of made me think of this  because there's people saying,  CNN is threatening to dox this guy.  And what about free speech?  Does free speech protect anonymous speech?

Speaker: SPEAKER_01
Transcript:  Free speech, this is the great misnomer.  CNN, Reddit, Google, Facebook, Twitter,  the New York Times all have the right to edit  as a matter of their free speech.  Allowing and enabling anyone's speech  about anything in any manner is not the free speech  that we're talking about.  Government stopping you from speaking freely  is the question of censorship.  But CNN, Reddit, all those places have the right to edit.  That's part of their right of free speech.

Speaker: SPEAKER_02
Transcript:  XKCD's famous cartoon 1357.  The right to free speech means that government  can't arrest you for what you say.  It doesn't mean anyone else has to listen to your BS  or host you while you share it.  The First Amendment doesn't shield you from criticism  or consequences if you're yelled at, boycotted,  have your show canceled,  get banned from the internet community.  Your free speech rights are not being violated.  It's just the people listening think you're in a hole  and they're showing you the door.  So to your point.  But okay, okay.  So then what do you think of CNN doxing that guy?  What do you think of that?  They didn't, by the way.  They chose not to dox.  They kind of, I mean, they said we know who it is.  But they didn't reveal.

Speaker: SPEAKER_01
Transcript:  They didn't reveal it.  Now is that the right, journalistically,  is that the right thing to do?  This is somebody who the President of the United States  passed this on, this fed into his Twitter feed  and hate of the media, it was a newsworthy event,  it was newsworthy of who did it.  Do people have a right to know who did the,  not right, go back, as journalistically,  do you feel responsibility to not have doxed him?  No, to dox him.  I think it is to dox him.  So what makes CNN think in this case,  we're not gonna reveal?

Speaker: SPEAKER_02
Transcript:  Well, maybe as somebody in the chair points out,  the threat is if you don't do it anymore,  we will reveal you.

Speaker: SPEAKER_01
Transcript:  But is that CNN's role?  Isn't that up to the public to decide?  Right.

Speaker: SPEAKER_03
Transcript:  Now.  I would say it's a natural consequence  of throwing something like that out there  with CNN as the target.  Like that's the targeted individuals speaking up  and saying, hey, don't do that again.

Speaker: SPEAKER_02
Transcript:  Yeah.  I mean, if you choose.  Yeah, I don't have a problem with it.  Well, is it chilling?  No, because free speech is about government suppression  of speech, not about facing the consequences, right?  Of your speech.

Speaker: SPEAKER_01
Transcript:  Yeah, I keep on coming back to this question of civility,  that the fake news, lack of facts, argument.  People aren't civil, Jeff.

Speaker: SPEAKER_02
Transcript:  Yeah.  Well, that's kind of what I meant when I said boys  were boys and men are very much not civil.  If it weren't for the civilizing force of the females,  I think this would be a very different world.

Speaker: SPEAKER_03
Transcript:  Okay, that is crazy sexist.  I think it's true.  I think it's true.  As a guy, I think it's true.  I can tell you that I am not necessarily as civil  as my husband is very civil.

Speaker: SPEAKER_01
Transcript:  Okay, but Stacey put it another way  on the terms of going overboard.  How often have you run across a female troll?

Speaker: SPEAKER_03
Transcript:  I have, I know many women who are trollish  in their behavior, who may not be trolling aggressively  on Twitter, but that's a very different.

Speaker: SPEAKER_02
Transcript:  That's a good point, you're right.  Okay, all right.  I agree with you, you're right.

Speaker: SPEAKER_03
Transcript:  I mean, I have said very negative things about a woman.  Like just, I have been known to use words  that are really awful and I am not at all civilized.  I know, see, but that's the point.  The point is people are not.  My world is crumbling around me.

Speaker: SPEAKER_02
Transcript:  Women have a veneer of civilization.

Speaker: SPEAKER_01
Transcript:  There is, but Leo, we're not going there.  We're not going there, no.

Speaker: SPEAKER_02
Transcript:  No, you know what, here's where I'll go.  In general, humans are pretty bad.  We are very, we are flawed.  But we controlled it better.  And one of the goals humanity should have is to be better.  All of us.  And that's called civilization, right?  And I think is a civil society.  And I think one of the things that you and I, Jeff,  are upset about is the breakdown of civil society  on places like Twitter.  Hey, it's not just us.  Ed Sheeran's unhappy too.  Did you see he's quitting Twitter  because of the mean tweets?  I don't think quitting Twitter stops the mean tweets,  but at least you don't have to see them.  Well, you don't have to look at them.

Speaker: SPEAKER_01
Transcript:  Well, that's the Twitter rule.  Twitter, oh, you can just mute these people  or they're still going to be insulting you  and saying horrible things about you and threatening you.  But you don't have to see it.  That's the Twitter rule.

Speaker: SPEAKER_02
Transcript:  Yeah, that's the only rule.  Twitter says, we'll publish anything, just, you know.  Yeah, so I think that in a way,  that's what this whole conversation could boil down to,  is are we moving forward as humans in becoming better,  or are we moving backwards  and reverting to a less civilized state?

Speaker: SPEAKER_01
Transcript:  I think it fits in sports  because I think you test the limits  and then you pull back and renegotiate.  Hope you're right.  I hope.  I'm optimistic, but I'm too far.

Speaker: SPEAKER_02
Transcript:  You know, and the whole conversation may be moot  when we get into a nuclear war with Korea.

Speaker: SPEAKER_03
Transcript:  Yes, yes.  That will be very exciting.

Speaker: SPEAKER_02
Transcript:  There are other fish being fried at this very moment.  Hey, but meanwhile, I have a gadget that will  scan barcodes of stuff in my refrigerator.  Anybody?  I've got one too.  It's just a red.

Speaker: SPEAKER_03
Transcript:  I thought we were gonna go for a Google story.

Speaker: SPEAKER_02
Transcript:  I often feel guilty.  This, I think we've talked about this before,  because sometimes, you know, technology journalism  and what we do at Twitter is about the toy store.  And there's lots of toys,  but then sometimes I feel like we're using those toys  to distract ourselves from things  that actually have real meaning and purpose and consequences  unlike the Amazon Scala Wand,  which has absolutely no meaning, no purpose,  and zero consequence.

Speaker: SPEAKER_01
Transcript:  Is this the Dash Wand with Alexa?

Speaker: SPEAKER_04
Transcript:  Yeah.

Speaker: SPEAKER_01
Transcript:  Okay, don't say her name.

Speaker: SPEAKER_02
Transcript:  Yeah.  It's the Amazon Wand.  So I'm still waiting.  Neither Stacey nor I are as fashionista enough  to get our invitation to buy the look.

Speaker: SPEAKER_03
Transcript:  Ah, Amazon, come on.

Speaker: SPEAKER_02
Transcript:  Come on, look at her.  She's a fashion plate.

Speaker: SPEAKER_03
Transcript:  Wonderful things you could style for me.  Wonderful clothes.

Speaker: SPEAKER_02
Transcript:  I would submit that I ain't no slouch  in that department either there.

Speaker: SPEAKER_03
Transcript:  You own a fedora, my goodness.  I own many fedoras.  Oh, multiple fedoras.

Speaker: SPEAKER_02
Transcript:  I buy hats, I buy jackets and clothing.  I'm a very stylish fella.  And I think, frankly, anybody who wants the look  should be allowed to buy it.  Isn't it?

Speaker: SPEAKER_03
Transcript:  I think it actually, so I was thinking about it  because a friend of mine wanted it  because she does quilting,  and she wanted to show people,  because her hands are busy when she's quilting,  she liked the idea of telling it to snap a picture  for her blogs or whatever.  And I was thinking about that when I'm working,  installing a gadget,  and I've got my hands,  I could have it take pictures while I'm installing.  So you get a step-by-step of,  and if you're really lucky,  maybe you get Stacey getting fried  with the electrical circuit.

Speaker: SPEAKER_02
Transcript:  So I thought I was okay with having cameras everywhere.  I really did.  In fact, remember Stacey, I ordered,  and you called me a doofus for doing it.  The Nest IQ cams.  So I put, I had got two of them,  and I put them up in the house about a week ago.  And the idea of the IQ cam is,  couple of interesting things.  One, it has, I think a 4K camera,  but it doesn't stream the full 4K,  but it can zoom in.  So if it sees faces or movement, it can zoom in on it.  It does face recognition.  And in theory, although I found it didn't really,  well, I don't know how long it was gonna take,  but it would start to recognize people in your house  and not notify you about them,  only notify you when a stranger was in the house.  But of course, when you first put it in,  everybody's a stranger, it was telling me about balloons.  It was telling me.  Did you draw little faces on it?  I didn't have to.  It's so funny, he said,  there's somebody in your house,  and it zoomed in on these Mylar balloons.  Well, not really.  Anyway, I thought I was okay with cameras,  because I got cameras everywhere.  I got all the Amazon stuff.  And then after a little while,  I got a little creeped out by it,  and I ended up taking them out.  And they're here at work,  where there's something cameras anywhere.  Yeah, anywhere.  It doesn't really matter.

Speaker: SPEAKER_03
Transcript:  You don't pick your nose in your office, right?

Speaker: SPEAKER_02
Transcript:  Well, I started to realize,  I mean, that we have one in the living room  and one in my office, the IQ, Nest IQ.  And I thought, you know,  I know no one's seeing it but me, unless they get hacked,  and you've said this too, Nest has good security.  I turned on two factor,  so nobody could hack my,  or make it hard to hack my account.  But I still, the idea,  and this is little green glowing light,  it has night vision, very good night vision.  And I just kind of got creeped out by it.

Speaker: SPEAKER_03
Transcript:  No one wants to see your midnight refrigerator runs  when you're in the PJs.  Exactly.  So I'm gonna throw it out there again.  I would try the Netatmo  because none of that goes to the cloud  and it actually has better,  based on what you just told me,  better facial recognition  because you train it in your first initial setup.

Speaker: SPEAKER_02
Transcript:  That's something that the Nest should do.  They should have training.  So Netatmo.  And if it doesn't go to the cloud, where does it go?

Speaker: SPEAKER_03
Transcript:  You can set it up on your own FTP server,  or you can actually, if you want,  you can actually send it to Dropbox,  or you can save it to an SD card.

Speaker: SPEAKER_02
Transcript:  It's French, that's why.

Speaker: SPEAKER_03
Transcript:  Yes, it's European.

Speaker: SPEAKER_02
Transcript:  They're more privacy focused.

Speaker: SPEAKER_01
Transcript:  Well, to a fault, we'll get to that story in a minute.

Speaker: SPEAKER_02
Transcript:  Yeah, we will.  Yes.  Yeah, we will.  All right, Netatmo,  and they have an outdoor and an indoor one.  I've got the Nests Outdoors, those I don't mind.  I don't mind if critters get caught in the camera.  The truth is also, there was really no justification  for me having cameras in the house.  We're not worried about getting robbed or anything.  So it was-

Speaker: SPEAKER_03
Transcript:  A lot of people put them in there for pets,  because everybody, whenever I ask about this,  they're like, I love seeing my pets.  Yeah.

Speaker: SPEAKER_02
Transcript:  And some people put it-  I don't love my pets that much.

Speaker: SPEAKER_03
Transcript:  Well, there's also the front door,  and okay, this is a very specific use case,  but we have a fish tank, and we bought snails,  and then we went out of town for a week,  and we were very concerned about the fate of the snails.

Speaker: SPEAKER_02
Transcript:  But the problem is, okay,  so do you get motion activations from snails or no?  Yeah, that's right.

Speaker: SPEAKER_03
Transcript:  Well, so I just thought we could just have a camera  that we could check in on the live view.  I wasn't worried about motion activation,  but you're right.

Speaker: SPEAKER_02
Transcript:  Your snail hasn't moved.  Well, maybe it has.

Speaker: SPEAKER_01
Transcript:  Only with time lapse.

Speaker: SPEAKER_02
Transcript:  I wish I could get my money back in the next IQ,  but I can't.  It's really a great camera.  I'll show you the camera.  I don't know, did we take them down?  I don't see it.

Speaker: SPEAKER_03
Transcript:  You can give them away.

Speaker: SPEAKER_02
Transcript:  I could give them to Stacey.

Speaker: SPEAKER_03
Transcript:  Or you can sell them on eBay.

Speaker: SPEAKER_02
Transcript:  Oh, actually, I would take one.  Somebody unplugged it.  Why was it unplugged?  I guess even my staff doesn't like the idea.  They unplugged them.  Well, they have a right to.  They have a right to.  But look at that.  Do you want, look at that eye glaring at you.  Do you want that in your...  Doesn't that look like it's watching you?

Speaker: SPEAKER_03
Transcript:  Did I show you the NetApp?

Speaker: SPEAKER_02
Transcript:  I can go grab mine.  Well, I'm looking at the website.  It looks like, it looks more like a bar than a...

Speaker: SPEAKER_03
Transcript:  Yeah, it's just a friendly cylinder.  It's a friendly cylinder.  Well, it is.  I mean, like, it doesn't look like,  yours looks like an eye.  Mine looks like this.  It used to be on my desk, but I cleaned up.  This is why I don't clean up you guys.

Speaker: SPEAKER_02
Transcript:  So do you have it for, besides snails, other pets?  Or is it...

Speaker: SPEAKER_03
Transcript:  I had it because it has the,  I really like the facial recognition feature  and the way they implemented it.  It seems like a good idea, yeah.  I keep waiting for companies to use that part of the API.  So like, IFTTT has NetApp mode,  but it doesn't use the facial recognition part of the API.  And maybe that's a privacy setting because they're French.  And I would love, I would love for it to be like,  hey, I haven't seen Stacey, her daughter,  or her husband for 15 minutes.  I'm gonna arm the security system.  Yeah.  So it does that already, but that information,  I would love for that information to be used  for some of my other devices too.

Speaker: SPEAKER_02
Transcript:  So the Nest does that,  but it does it based on your smartphone.  So it says as soon as you move out of range  with your smartphone.

Speaker: SPEAKER_03
Transcript:  My daughter doesn't have a smartphone.

Speaker: SPEAKER_02
Transcript:  Right.  No, I like that.  Why do that?  Why not do the recognition?  Here's the image from my studio.  My studio is on right now.  And it's a pretty detailed image.

Speaker: SPEAKER_03
Transcript:  That's a lot of hats.  Why do, what, why?

Speaker: SPEAKER_01
Transcript:  That's our Leo.

Speaker: SPEAKER_03
Transcript:  What is happening there?  Oh my gosh.  Is that the ostrich sleeping pillow?

Speaker: SPEAKER_02
Transcript:  Yes, it is.  How did you recognize that?  That's exactly what it is.  Because I'm obsessed with that thing.  Oh look, somebody's stealing my hat.  Quick.  Get him.  Go get him, Nest.  The other thing I like about this is both the Nest  and the Ring Video Doorbell,  I can pipe to the Echo Show, which is this is,  the Echo Show is the one,  and you can see it on my desk right now,  with the, with the screen on it.  So you can say, Echo Show my front door,  or Echo Show the studio cam,  and you can see it on the Echo,  which is kind of neat.

Speaker: SPEAKER_03
Transcript:  How was your latency?  Because I did that with my August,  and I was like, show me my front door,  and I counted to six seconds before it.

Speaker: SPEAKER_02
Transcript:  Yeah, and that's a problem.  Okay.  With the Ring, the first time it says it's asleep,  but presumably somebody's ringing the doorbell,  or if there's motion, it will be awake.  And there is, yeah, six seconds, that sounds about right,  which is a little bit of an issue,  because the person might have rung the doorbell and left  by the time you see them.

Speaker: SPEAKER_03
Transcript:  I wanted to, so when we did the Fourth of July party,  yesterday, I was, I had this great idea for a use case,  and I don't know if it would be feasible,  but getting like the Arlo outdoor cameras,  or I guess the Logitech, I know has an Echo Show integration,  I'm not sure about the Arlo cameras,  but being able to show the parents,  their kids playing on the roof  while we're all downstairs drinking,  and the kids are all running around,  that would have been actually kind of a cool use case.  So.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_02
Transcript:  I don't know.  So to me, I like the Echo Show a lot.  The IQ camera's a little less.  I do like my doorbell camera.  That makes, that's a use case that makes sense to me.  That makes sense.  An outdoor camera makes sense.  An indoor camera makes a little less sense to me.

Speaker: SPEAKER_03
Transcript:  Yeah, other than the snails.  My husband, when we go out of town for a long time,  he does like having an indoor camera.

Speaker: SPEAKER_02
Transcript:  People are pointing out that you can do this on the phone.  Of course you can, all these apps,  and I'm just showing you my Nest camera on the web,  but having it right there by voice control,  and to me, the Echo Show belongs on your desk.  It's a desk.  It's like, it's a great, or a kitchen, a desk.  It's like a counter thing.

Speaker: SPEAKER_03
Transcript:  It is, so we have ours on,  this is my breakfast bar, that's what it's called.  I always say my bar, but it's not a bar.  Breakfast bar, yeah.  And we actually, we were actually watching quirky videos  on YouTube the other day in the morning.  Isn't that cool?  Yeah, we were like, she was.  On your Echo Show.  Yeah, it's that great quality.  And I like it that I can set up my flash,

Speaker: SPEAKER_02
Transcript:  I thought it was gonna be very low quality,  because it's so small, 1024 by 980 is fine.  And I have, you can see the Tonight Show monologue  from the night before, CNN has videos,  I think CNBC's doing video.  I think we're gonna inquire,  because we have a flash briefing for Twitter,  which is Monday through Friday, our tech news today,  and then on Saturday, it's new screensavers,  and Sunday, it's Twitter, and it'd be great  if we could put video in there.  And I think that's a nice use for it.  I love seeing lyrics in songs, isn't that nice?

Speaker: SPEAKER_01
Transcript:  I still think that karaoke is a missed opportunity.

Speaker: SPEAKER_02
Transcript:  Well, you could do it,  and you could sing along with a real song.

Speaker: SPEAKER_01
Transcript:  But then you have the,  then you'll sound bad next to the real person.

Speaker: SPEAKER_02
Transcript:  Well, I believe, in fact, I know,  because I keep getting them by accident,  there are karaoke tracks on most of the music services.  If you ask, it used to be when you asked for the Beatles,  you'd get Beatles karaoke,  because they didn't own the lyrics.

Speaker: SPEAKER_01
Transcript:  But we did it last week, and there were no lyrics.

Speaker: SPEAKER_03
Transcript:  So yeah, if you get the real song,  there may not be lyrics.  But if you get the karaoke version,  in Amazon, you have to ask for the karaoke version.  But Google constantly serves me  the karaoke version things.  I'm like, God, stop.

Speaker: SPEAKER_02
Transcript:  Yeah, take it out.

Speaker: SPEAKER_03
Transcript:  And I don't understand why Google is so much worse,  because they're both pulling from Spotify.  So I'm like, what is happening on the back end there?  That's interesting.

Speaker: SPEAKER_02
Transcript:  So using Spotify as your service on both of those.

Speaker: SPEAKER_03
Transcript:  Yeah, and if I,  and I actually, I shot a little video of this,  of asking for certain songs,  and Google will always feed me  the karaoke version of these songs,  whereas the Echo will feed me the right version.  I have no idea why this is different.

Speaker: SPEAKER_02
Transcript:  So I use for my music on the Echo,  I use Amazon Unlimited Music, as well as Google Music.  But I almost always get lyrics, but not always.  But some, for some reason,  I, like, so there's some country artists  that don't get lyrics.  And I just think they're not on Rap Genius,  or whatever it is that they use for lyrics, right?

Speaker: SPEAKER_01
Transcript:  How many music services do you pay for?

Speaker: SPEAKER_02
Transcript:  Google and Amazon.  I used to pay for Spotify.  I dumped it, and actually, Paul Therotte,  on Windows Weekly moments ago,  showed me this great site  that lets you import your playlists  from one service to another,  which is huge for me,  because I have all these great playlists  that I miss on Spotify.  It's called Stamp, it's a freerermusic.com.  So I can finally get my Spotify playlist  moved over to my Google Play music.  I might pay for Apple Music, too,  because they now have a $99 a year tier,  which is almost, what's it, like eight bucks a month,  a little less.  That's a pretty good deal.  You only need one, obviously,  but I only need one Echo show, but I have three.  It's because this is my job.  That's my story, and I'm sticking with it.  Yeah, I know, I know.  Sorry, I dropped my battery.  I'm trying to figure out,  this is a bit of a puzzle.

Speaker: SPEAKER_03
Transcript:  You pull it apart.

Speaker: SPEAKER_02
Transcript:  I don't wanna break it.

Speaker: SPEAKER_03
Transcript:  I have the same thing, but you do pull it apart.

Speaker: SPEAKER_02
Transcript:  Just like this?  Yeah, right before the show. Like a cracker?  Like a party cracker?  Yeah.  It's quite hard to pull apart.  It's also, it's a strength test, Leo.  I know, do you want me to go get mine?  Oh, I did it. There you go.  I felt like I might break it.  I wasn't, you know, and of course,  the last thing I'm gonna do is look at a manual.  All right, so put the batteries in.  So this is the Amazon.  Old fashioned batteries.  Triple A's.

Speaker: SPEAKER_04
Transcript:  Triple A batteries.

Speaker: SPEAKER_02
Transcript:  But you know, I use rechargeables,  so when I replace them, I'll have rechargeables.  Problem with rechargeables is they tend to,  over time, leak, which means you just lose the power  if you don't use it.  All right, so now what do I do?  I have to set it up.  There's no screen.

Speaker: SPEAKER_03
Transcript:  There's no screen, you need to get your phone.

Speaker: SPEAKER_02
Transcript:  Oh, I set it up by my Echo app.

Speaker: SPEAKER_03
Transcript:  You go to www.amazon.com slash dash wander.  Oh, you have to do it by the web.

Speaker: SPEAKER_02
Transcript:  I can't do it with the Echo apps.

Speaker: SPEAKER_03
Transcript:  I bet you could do it by the, see, I read the manual  because there was your mistake.  Stacy's that kind of good person.

Speaker: SPEAKER_02
Transcript:  That was your mistake.

Speaker: SPEAKER_03
Transcript:  So actually, most of the times I don't read the manual,  but once I couldn't figure out how to put the batteries in.

Speaker: SPEAKER_02
Transcript:  Exactly, I was about to get the manual out.

Speaker: SPEAKER_03
Transcript:  I clearly need a manual here.

Speaker: SPEAKER_02
Transcript:  Because it wasn't obvious.  All right, so can I add a device?  Set up a new device.  Yeah, you're right, you have to go to the web  because they have Echo Tap and Echo Dot.  They don't have any of the, choose a device  so you can't choose the wand.

Speaker: SPEAKER_03
Transcript:  So do you want me to tell you that this is gonna suck  and you're gonna hate it?  Or do you want me to make you hate it?  I think I already know

Speaker: SPEAKER_02
Transcript:  because I played with Megan Moroney's.  It's terrible.

Speaker: SPEAKER_03
Transcript:  Well, it just hooks you into Amazon.

Speaker: SPEAKER_02
Transcript:  Well, that's all right.  That's too late, I've already.

Speaker: SPEAKER_03
Transcript:  Well, I'm hooked into Amazon, but I didn't realize,  I wanted to be able to export stuff to a generic list  for things I didn't want for Amazon,  but I don't see how that's possible.  And that saddens me.

Speaker: SPEAKER_02
Transcript:  US-1 setup, okay.  Good, I am good.

Speaker: SPEAKER_03
Transcript:  If you do the UK,  maybe you'll get cool spellings for all your words.  And your arugula would be called rocket.

Speaker: SPEAKER_02
Transcript:  Hello, would you like some coriander?  Wow, okay.  Insert batteries, it shows you, that's good.  How, continue.  So what don't you like about this?

Speaker: SPEAKER_03
Transcript:  I thought I'd be able to get,  I thought I could use it  as a generic grocery list generator to an app,  but really everything. Oh, it's only to Amazon, yeah.  It's only to Amazon.  And so now I've gotta still think before I scan something,  is this something I usually buy on Amazon or not?  So it doesn't make my life as effortless  as I wanted it to be.

Speaker: SPEAKER_02
Transcript:  Do you have it magnetically attached to your refrigerator?  That's what you're supposed to do.

Speaker: SPEAKER_03
Transcript:  Yes, I do.  Well, most of them.  It also comes with a convenient hook

Speaker: SPEAKER_02
Transcript:  you can attach to the wall.

Speaker: SPEAKER_03
Transcript:  It's a hideously ugly hook.  I would never want that on my wall.

Speaker: SPEAKER_02
Transcript:  I was like, oh, Amazon.  It's just a hook.  What do you mean hideously ugly?  A hook is a hook.

Speaker: SPEAKER_03
Transcript:  You can have a little style to your hook.

Speaker: SPEAKER_01
Transcript:  She has high hook standards.

Speaker: SPEAKER_02
Transcript:  Apparently. I do.  All right, so, and then you're supposed to hold it  till the ring turns orange,  which it was stubbornly refusing to do.  Maybe I put the batteries in wrong.

Speaker: SPEAKER_03
Transcript:  They both go the same direction, which is unusual.

Speaker: SPEAKER_02
Transcript:  It made noise.  You know, if you're lucky enough to have Stacey on IoT,  helping you install your IoT device.

Speaker: SPEAKER_03
Transcript:  I'm clearly not helping you enough.

Speaker: SPEAKER_02
Transcript:  Well, see, for what, you know what,  I'm kind of with you,  because I want to try Instacart before they go out of business.

Speaker: SPEAKER_03
Transcript:  Oh, we ordered Instacart yesterday and it was great.

Speaker: SPEAKER_02
Transcript:  I think it's great.  I've been told by a number of people,  including my son, who's an Instacart user,  that it really, I said, do you get good produce?  He said, yeah, everything works really well.

Speaker: SPEAKER_03
Transcript:  Yeah, we got some produce.  We got six bags of ice too, which was nice.  Cause our party, you know how-  Oh, that's nice. It wasn't melted.  So we got six bags of ice.  We got some more brownie bites because they're delicious.

Speaker: SPEAKER_02
Transcript:  Oh, so they went to Costco as well as they'll go to  somewhere, it's not just whole food.  They went to HEB.  Okay.

Speaker: SPEAKER_03
Transcript:  It's not just whole foods.  Well, Instacart is HEB.  He also told us they go to like pet stores for pet food.  They'll go to CVS for like, if your kid's sick and,  you know, your spouse is out of town or something,  you can be like, help me.  I need eight gallons of Pedialyte stat.  Pedialyte.

Speaker: SPEAKER_02
Transcript:  Exactly.  We always have Pedialyte in our pantry, just in case.

Speaker: SPEAKER_03
Transcript:  Wow. That's expensive and nasty, nasty stuff.

Speaker: SPEAKER_02
Transcript:  Yeah. We got it.  Okay. Now select your wifi network.  Okay. Okay.  And the idea is you're going to scan,  when you run out of stuff,  you put it in the other refrigerator, right?

Speaker: SPEAKER_03
Transcript:  Yeah. You can.  I put mine on the refrigerator.

Speaker: SPEAKER_02
Transcript:  Right.  Cause the idea is that you scan stuff.  Like when you're done, you're out of milk,  before you throw out the cart and you scan it.  Is that kind of the whole premise?  And it has a little tiny speaker and it can talk like,  it could do all the other, oh good, green light.  That means-

Speaker: SPEAKER_03
Transcript:  You can ask it what the weather is.

Speaker: SPEAKER_02
Transcript:  You can.  But why would you, you know, I have,  already have it echoing.

Speaker: SPEAKER_01
Transcript:  Well, but wait, can you use only that?  Can I just use that and nothing else?  The Alexa family?  Yeah. It's just got-  Yes. Except it doesn't play music.

Speaker: SPEAKER_03
Transcript:  And thank you, Jack, that is why.

Speaker: SPEAKER_02
Transcript:  Okay. Beep this.  Everybody hold your ears.  What's the weather?  Oh, I have to push the button.  What's the weather?  So that's one different thing.  It's not-

Speaker: SPEAKER_00
Transcript:  It's Santa Rosa.  It's 79 degrees with mostly sunny skies.  It's like a real-  Today, you can look for intermittent clouds  with a high of 79 degrees and a low of 50 degrees.

Speaker: SPEAKER_02
Transcript:  It's like a really bad AM radio.  It's really-

Speaker: SPEAKER_03
Transcript:  Well, I mean, you press it because of battery life.

Speaker: SPEAKER_02
Transcript:  Yeah, yeah, yeah.  I mean, that's-  And do you press to scan?  It doesn't automatically see stuff, right?  You press to scan.

Speaker: UNKNOWN
Transcript:  Okay.

Speaker: SPEAKER_03
Transcript:  Although for all I know, there's a giant camera in there  and Jeff Bezos checks in every now and then.  Hi, Jeff.

Speaker: SPEAKER_01
Transcript:  Does it tell you other things?  Can you scan something and ask what ingredients are in it  or how many calories or any of that kind of stuff?

Speaker: SPEAKER_03
Transcript:  That's what it's told.  Oh, that would be really interesting.  What is that?

Speaker: SPEAKER_02
Transcript:  Somebody told me.  It's Dinty Moore, hearty beef stew, don't you?  No.  So I just point it at the barcode, that's it?

Speaker: SPEAKER_03
Transcript:  I don't think you can get that at Whole Foods.

Speaker: SPEAKER_02
Transcript:  Oh, okay. Problem one.  It doesn't tell you what it scanned.

Speaker: SPEAKER_03
Transcript:  Oh.  Yeah, you got to, it's on your Amazon list.

Speaker: SPEAKER_02
Transcript:  Oh.  I was going to say, I think that's Dinty Moore beef stew.

Speaker: SPEAKER_01
Transcript:  Yeah, it should.  I'm canceling mine right now.

Speaker: SPEAKER_02
Transcript:  That's dopey.  You don't know.  That's one of the things Megan complained about.  So you need to go to your Amazon shopping list.  Which I don't even know where that is.  Plus there's stupid stuff.  Oh yeah, look.  Dinty Moore beef stew, scanned with Dash.  It did see it.

Speaker: SPEAKER_03
Transcript:  Look at that.  I think you can tell it to buy stuff  and it will actually buy it.

Speaker: SPEAKER_02
Transcript:  Oh, wait a minute.  Can I just point out what it's going to order  if I go ahead and order?  12 pack.  Is a pack of 12.  That's a lot of beef stew.  Oh, that's a lot of beef stew.  And usually ships within one to two months.  So in September, I'm going to get,  for reasons I really don't understand,  a carton of 12 Dinty Moore beef stews.

Speaker: SPEAKER_03
Transcript:  Yeah, I would maybe.

Speaker: SPEAKER_02
Transcript:  Not good.

Speaker: SPEAKER_03
Transcript:  Maybe don't hit buy.

Speaker: SPEAKER_02
Transcript:  But that's the other bad thing is it is,  well, I guess that's good in this case.  It's not going to do anything really.  It just makes a list.

Speaker: SPEAKER_03
Transcript:  Yeah, well, no, if you say buy.  When?  Not if you say buy and scan,  but if you say buy.

Speaker: SPEAKER_02
Transcript:  Oh, you can still do that with the,  which you would do with a regular one, right?  Yes.  Yeah.  Buy underwear.

Speaker: SPEAKER_00
Transcript:  Oh God.  Anything for underwear.  So I've added underwear to the shopping list.

Speaker: SPEAKER_02
Transcript:  So it's just like a regular echo in that respect.

Speaker: SPEAKER_01
Transcript:  Yes.  So what does it show a picture of, sir?

Speaker: SPEAKER_02
Transcript:  Buy Pilot Pens.

Speaker: SPEAKER_00
Transcript:  Amazon's choice for Pilot Pens is Pilot Precise V7  black ball pens to Zimbabwe.  It's $12.16 plus tax.  Would you like to buy it?

Speaker: SPEAKER_02
Transcript:  Yes.  Oh, I have to press the button.  I have to press the button.

Speaker: SPEAKER_04
Transcript:  Yes.

Speaker: UNKNOWN
Transcript:  Yes.

Speaker: SPEAKER_02
Transcript:  Does that ding mean I bought it?

Speaker: SPEAKER_01
Transcript:  Look at your Amazon app now.  Plus what did it show for underwear?  That's what I want to see.  Did it put in sample underwear?  Well, the last time,  the last time I did this,

Speaker: SPEAKER_02
Transcript:  it said it bought me some emergency underwear.  I'm not kidding.

Speaker: SPEAKER_03
Transcript:  Emergency underwear comes in handy.

Speaker: SPEAKER_02
Transcript:  Well, I now have a,  it's just grab and go  emergency underpants dispenser.  And I, it's actually a great gag just to have around.  So I just leave it lying around,  but yeah, it bought me that by accident.  So there's other kinds you can get instant underwear.

Speaker: SPEAKER_01
Transcript:  Wait, wait, wait, wait, scroll down.  Instant underpants?

Speaker: SPEAKER_02
Transcript:  What's that?

Speaker: UNKNOWN
Transcript:  Just add water.

Speaker: SPEAKER_03
Transcript:  Is it like a washcloth?  One of those like instant washcloth?  Oh yeah.

Speaker: SPEAKER_02
Transcript:  These underpants are conveniently compressed  into a compact pellet.  If you add water you can't wear them  because they're wet.  He says, remember it's better to have damp underpants  than no underpants at all.  Oh, here's the bad,  here's the bad news right at the bottom.  Fine print fits most children and small adults.  I am not a small adult.  So I guess this is just not.  You're a SOL on that one.  By the way, frequently bought together,  Archie McPhee instant underpants just add water.  A Couturant's yodeling pickle  and a bag of unicorn fart cotton candy.

Speaker: SPEAKER_03
Transcript:  I sent my friend a yodeling pickle.  It was awesome.  What is a yodeling pickle?  Oh, you've never seen this?

Speaker: SPEAKER_02
Transcript:  You have to have one there.  You press the button and it yodels?  This is exactly, look at it.  It even looks like the Amazon wand.  I think this is clearly,  this is clearly the inspiration.  Look at this, Carson, show my screen.  I mean, show the over the shoulder shot.  I think this is clearly the inspiration for the wand.  Amazon, Jeff must've said,  you know that yodeling pickle really sells well.  Let's make a yodeling pickle echo.

Speaker: SPEAKER_03
Transcript:  But the echo doesn't, ask her to yodel.  Let's see if she'll yodel for you.

Speaker: SPEAKER_02
Transcript:  Yodel.

Speaker: SPEAKER_03
Transcript:  You may have to say,  You just bought a bunch of yodels.  You bought some yodeling pickles.

Speaker: SPEAKER_02
Transcript:  Beatbox.

Speaker: SPEAKER_03
Transcript:  You may have to say her name.  I have to press the button and say her name?

Speaker: SPEAKER_02
Transcript:  Well, I don't know.  That's annoying.

Speaker: SPEAKER_03
Transcript:  Cause you might be adding that to the shot.  It might think of that as a shopping request.  Do you press and hold?  I pressed and hold it, held.

Speaker: SPEAKER_02
Transcript:  Yodel.

Speaker: UNKNOWN
Transcript:  Yodel.

Speaker: SPEAKER_02
Transcript:  This is, throw this.  There's one button.  You just bought a yodeling pickle.  Can't grab the pickle.  You bought the yodeling pickle button.  Oh Lord.  Oh Lord.  Hours of mindless entertainment.

Speaker: SPEAKER_03
Transcript:  It makes a great gag gift.  I'm just very emphatic about my yodeling pickle.

Speaker: SPEAKER_02
Transcript:  I think it'd be good for like one of those  white elephant parties.  Yes.

Speaker: SPEAKER_03
Transcript:  Yes, I may have purchased it for that too.

Speaker: SPEAKER_02
Transcript:  Yes, those are very useful for that.  Okay, here's, I should read the manual.  Things to try.  To add an item to your cart, say dark roast coffee  or scan the item's barcode.  To buy now, say buy and the thing.  To track your order.  Oh, here, let's try this.  Where's my stuff?

Speaker: SPEAKER_00
Transcript:  A shipment for Leo's order placed yesterday  should arrive tomorrow.

Speaker: UNKNOWN
Transcript:  What's in it?  A yodeling pickle.

Speaker: SPEAKER_02
Transcript:  How many tablespoons?  So you can do all the normal things.  They're in a stick of butter.  How many calories are in an apple?  You could do the dim hue lights thing, calendar sports.  If this were Google, you would point to the de nemois stew

Speaker: SPEAKER_01
Transcript:  and you would say how many calories are in that.  I know.  They could really do much better.

Speaker: SPEAKER_02
Transcript:  This is promising start, but they really need  to do more with this, I think.  Yes, I think so.  It's a yes.  That was your reaction too.

Speaker: SPEAKER_03
Transcript:  Yes, although for controlling smart home stuff,  I could put this in my guest room, for example.  Oh, there you go.  Without spending a lot of money.  Because it's cheap.  It won't play music for people, but they could be like.

Speaker: SPEAKER_02
Transcript:  It's only $20, we should point out.  This is the least expensive Echo you can buy.  Actually, if this did more like control the TV,  this could be a great remote control.  There's all sorts of things this could do  if they would add some features to it.  And you're willing.  But then it wouldn't cost $20.

Speaker: SPEAKER_03
Transcript:  I mean, 20 bucks, that's great.  I know, but if they added features,  it probably wouldn't cost $20.

Speaker: SPEAKER_02
Transcript:  Not necessarily.  I mean, they just add Echo features to it.  Somebody said this, and I think this is kind of true,  that maybe both this and the show were rushed a little bit.  For instance, if you use the Echo app on Android,  it's terrible for setting up the show.  It looks like it has all the back end,  but nobody did front end design on it.  But on the iPhone, it looks fine, it looks good.  Things like that.  It feels like they just kind of had to rush it out the door.  What else should we talk about?

Speaker: SPEAKER_01
Transcript:  Oh, well, I think we need to talk about the Brits.

Speaker: SPEAKER_02
Transcript:  The Brits, are you talking about NHS?  Yep.  In DeepMind?  Yep.  So it is illegal.  It's illegal.  Google has a partnership  with the National Health Service in the UK,  and it is illegal according to today.  So here it is.  1.6 million patient records are shared with Google  in an attempt to use AI to predict  which patients would be risk from kidney damage.  It was the ICO,  which is the Information Commissioner's Office,  the UK privacy body has ruled,  that it was illegal.  Today my office, this is the quote,  today my office has announced  that the Royal Free NHS Foundation Trust  did not comply with the Data Protection Act  when it turned over the sensitive medical data  of around 1.6 million patients.  Was it anonymized information or no?

Speaker: SPEAKER_01
Transcript:  Yeah, of course it was.  But here you go to the next two paragraphs down.  The law says that patients are implied  to have consented to data being shared  for the purposes of their direct care,  but as the aim here was to develop an app  that would help future patients,  no consent could be assumed.  Isn't that just ludicrous?  Now in some small fairness,  they said that there are ways they could have done it  to protect privacy and so on,  but it just shows the priority.  The techno panic beats helping people.

Speaker: SPEAKER_03
Transcript:  Well, hold on, hold on, hold on.  What if it shows that, hey, we're doing totally new stuff,  let's have a conversation about that,  which seems to be- Yeah, I kind of agree with you.  We kind of talked about this last week.  Was it last week with regulation in this era?  We're doing a lot of crazy stuff to say,  hey, let's figure, let's just talk through this  for a little bit as like an IRB.  Well, I'm sure they did.

Speaker: SPEAKER_01
Transcript:  No, but I think they did,  and they did an effort to do this in a way  that passed the law, and then the NHS comes back.  And with the NHS, not Google,  it was found to be at fault here,  but it shows the priority that we have.  You put privacy over lives.  That's where we are right now,  and this is dangerous.  This is highly dangerous,  because it's insane that we've got to control knowledge.

Speaker: SPEAKER_03
Transcript:  So privacy can also affect lives.  I don't think they're saying that privacy  is better than saving people's lives.  They're saying privacy has a cost  that can ruin people's lives,  and I don't think that's wrong.

Speaker: SPEAKER_01
Transcript:  But there's no privacy.  No, this is about consent.  This is not about privacy.

Speaker: SPEAKER_02
Transcript:  This is about consent.  But wait a minute.  You might be making it more global than it really is.  It might legitimately,  first of all, we know that anonymization  is not very effective, right?  And so I think it's not unreasonable for the ICO to say,  as you did it, it's not legal,  because those records anonymized  may not be truly anonymous.  And as a result, you need, well,  but you need more extensive,  you need permission to do this,  what it was was you need permission  to do this particular data sharing.  I agree, they probably shouldn't have brought up  this future versus existing patient thing.  But that's what it is.  That's what they did.  But their job is to protect privacy.

Speaker: SPEAKER_01
Transcript:  But well, but doctors' job is to protect lives  and to save lives.  And this time it's kidney damage.  It could be other things that are highly fatal.  And so this was a use  that could not have been anticipated.  The deep mind existed,  and AI could help predict kidney disease.  But what if Stacey's point is-  You couldn't have predicted that.  So you're saying to all the past patients  and all the past doctors and all the past bureaucrats,  should have thought of that, sorry it didn't,  so we can't use that.  We'll just let some people get kidney disease as a result.  Let's have the discussion, is what Stacey's saying.

Speaker: SPEAKER_02
Transcript:  We can go back to the table and have that discussion  and ask for permission.

Speaker: SPEAKER_01
Transcript:  No, those are patients from the past.  You can't go back and ask them for permission, over.  So you've lost that data now.  And you said to people, better go ahead, get kidney disease.  So because-  Because a legal fine point wasn't done here  for a use that couldn't have been anticipated.  This is the problem I have with the regulatory reflex,  especially in Europe,  where they think they know what the internet is.  They think they know what technology can do,  and they wanna constantly limit it to the past,  rather than anticipate the future and what can happen.  And is there some risk?  Yeah, but the risk to me is clearly greater  than people will get,  will now could get diseases  that could have been prevented and treated.  That is horrendous as the prioritization  we're putting on society because of this techno panic.

Speaker: SPEAKER_03
Transcript:  To be fair, we don't know  that this would actually save lives.  Yeah, but this disease-

Speaker: SPEAKER_01
Transcript:  We're assuming that it will.  Stacey, so make it breast cancer.

Speaker: SPEAKER_03
Transcript:  I understand, but we're not sure, A, if we take this data,  and I'm just kind of following down your argument's path,  not necessarily where I'm thinking this goes, but-  We're gonna save lives, prevent disease.

Speaker: SPEAKER_01
Transcript:  Make disease-  Right, and so it makes diagnosing diseases easier.

Speaker: SPEAKER_03
Transcript:  That's a good thing.  And recognizing-  That's an unalloyed good thing.  Yes, it is.  But when you do that using AI-  But they have put the priority.  Hold on, Jeff, hold on, hold on.  When you do that with AI, you're gonna have to test that,  and you're gonna have to do peer-reviewed studies  to make sure the AI is actually doing it correctly  and finding what you want it to find  as opposed to what it thinks you want to find.  And we can bring up many examples of all of that.  So you're rushing to saving lives,  but there's still time to get consent on data  and still do this,  because it's gonna be a long process  before actual lives are saved.

Speaker: SPEAKER_01
Transcript:  In one life.  Problem I have with this aggregation of data thing  is that the fight goes on about whether women should be,  when and how women should be tested for breast cancer,  when and how men should be tested for prostate cancer.  And the problem is that that's a discussion held in aggregate.  And well, the percentages don't go up much,  but in that delta, if there's even one life it's affected,  we have set the priority.  And the priority here is that we're gonna prioritize  techno panic over data is a bad thing  over helping people's health.  And the greater picture here is we've said  knowledge is dangerous.  The greater knowledge is here  is how to better diagnose people's ailments.  The sacrifice of some small risk here,  which is not even defined,  is to my mind, well frigging worth it.  And we've said, and techno panic has won the day.  And that, and it's won the day not only over health,  but over knowledge, over the value of knowledge.  And I find that horrendously offensive in a modern world.

Speaker: SPEAKER_03
Transcript:  Sorry.  I think that consent to get someone's information  is far more important than the pursuit of knowledge.  Because if we give that up,  we have so much information that could be mined  at any point in time then.  And I understand the arguments.  Okay, but also for things that might not be beneficial.

Speaker: SPEAKER_01
Transcript:  So you're gonna cut off all the good possibilities  because of bad things that could happen.  No, we're not gonna cut it off, Jeff.

Speaker: SPEAKER_03
Transcript:  We're gonna have conversations about it.

Speaker: SPEAKER_01
Transcript:  But in that time, in that time  when you have the conversation,  somebody's life is affected.  Somebody's mother, somebody's father,  somebody's uncle is affected by that kidney disease.  And the conversation can go on forever.  The priority is what's even in theory.  Somebody is always gonna get hurt

Speaker: SPEAKER_03
Transcript:  while someone will always get hurt.

Speaker: SPEAKER_01
Transcript:  Or, okay, which is the greater harm?  Which is the greater harm?  That someone gets a disease they may not have to have  versus somebody's data sits in a repository  they didn't give consent to.

Speaker: SPEAKER_03
Transcript:  I find that clear.  Well, what if that data gets,  what if the 20 million people whose data is in there  gets reversed, they get doxed and it gets hacked?  And what if?  And then, yes.  What if?  One person's life saved, 20,000 people are,  their lives are irrevocably changed  by their data getting out there.

Speaker: SPEAKER_01
Transcript:  So it's because they found out about where their kidneys.

Speaker: SPEAKER_02
Transcript:  Well, we don't know.  I mean, you have the right to have that be private,  whatever you might say.  I'm not sure you should.

Speaker: SPEAKER_01
Transcript:  I'm not sure you should.  I think the thing we've gotta solve in society.  Whoa!  Let me finish, let me finish.  The thing we've gotta solve in society  is about the bad use of data.  The problem here, and I wrote a book about this,  which I haven't sent you yet, which I need to.  The problem here is that we still have a stigma  around illness and disease.  That's a larger problem in society.  The fact that someone has, we have a problem  that bad insurance companies in bad countries  wanna pull insurance from you because you have a disease.  That's the problem.  The fact that you have the disease  and the fact that there's information about it  is not the problem.  The use of that data, the use of that information  is where the problem lies.

Speaker: SPEAKER_02
Transcript:  And you do have a point that much of that information  could be useful in preventing future disease.  I was part of a world of trauma.  Wouldn't you wanna know if the BRCA,  if the, I've been told you don't pronounce that Berka,  you pronounce it Barca.  That was Braca.  Yeah, well it's BRCA, you pronounce it anywhere you want.  I pronounce it Berca, but apparently  that's probably not the best pronunciation.  But if that gene, if you had more information  about how much that indicates a likelihood of breast cancer  via statistical analysis of past information,  I think that would be valuable.

Speaker: SPEAKER_03
Transcript:  So actually your doctor tells you when you go in to get,  when you go in for your annual,  your doctor asks you a series of questions  to see if you should be tested based on the utility  of whether or not you'd even have it  and then what you'd be able to do about it.  So there is a lot to unpack here.

Speaker: SPEAKER_02
Transcript:  That would give the doctor more information though, right?  He or she would now have a big statistical database  that would say, well, you know, actually after analysis,  we found that the presence of that gene only impacts you 20%  and based on these other things,  maybe you shouldn't do anything about it.  But right now they don't have that kind of,  what's missing. They do have that data on Braca.  They have some of it, but well, all right,  but it could be other kidney disease  might be a similar problem.

Speaker: SPEAKER_03
Transcript:  So, but there, okay.  I think I understand your point, Jeff.  And I am a big proponent of greater knowledge  and sharing data and using it in these things.  But I do think for reasons of privacy  and how people's lives have changed  and also too, forgetting this sort of consent in the future,  we should do it right.  And we should inspire patients.  I know that people are gonna die, Jeff.  People are always dying.  That's a great price.  That's a huge price.

Speaker: SPEAKER_01
Transcript:  So 100 years from now, you look back  and as anthropologists, you judge  the priorities of a society.  And you say that there was a choice held in this year, 2017  between taking data that didn't have the right tick box  next to the consent, because we didn't even think to ask,  because we had no idea technology would advance  and we could do these amazing things.  There was a choice between taking that data  to have an impact on people's lives  and not doing it because of protectionism around that data.  I think that shows a skewed societal prioritization.  I think that's an unethical prioritization.

Speaker: SPEAKER_03
Transcript:  Maybe that's because you don't worry as much  what happens when your data is leaked.  Maybe you're not in a pub, like a population  that has to think or be worried about that,  that pays more for, I don't know, insurance.

Speaker: SPEAKER_01
Transcript:  I pay a lot for insurance  because I have these pre-existing conditions.

Speaker: SPEAKER_03
Transcript:  So that is a good example, Jeff.  That's for example.  And this feels like an argument I have  with a lot of people who are very pro-tech,  who are like, why doesn't everyone want to give  this information or share this information?  And if you're coming at it from a different perspective,  maybe it becomes more clear.  And I'm just saying you're part of a very,

Speaker: SPEAKER_01
Transcript:  I hate to use this word.  Stacey, this isn't a tech perspective.  This is the perspective of somebody who has two cancers.  If there's more knowledge that could have  prevented my prostate from being taken  because they know more about it, I'm all for that.  And I understand the point about vulnerability and privacy.  I get that fully.  But I do think that we've got to get our act together  as a society, and rather than going  constantly to protectionism, we've got to grab  these new opportunities that are provided.  And it's not about technology, it's about information.

Speaker: SPEAKER_02
Transcript:  Going forward, I'm sure the NHS will add a clause that says

Speaker: SPEAKER_01
Transcript:  would you much- And we lose huge amounts of data.  I understand, but they didn't ask in that case.  Well, because we couldn't know it.  So actively get people. And this is not  an idle conversation.

Speaker: SPEAKER_03
Transcript:  No, I know, commit, get people.  So Google, instead of grabbing NHS,  which granted would have been easier,  now they should go out and advocate and advertise  and have people donate their data.

Speaker: SPEAKER_01
Transcript:  That's another way of doing this.  I mean years and years and years forward to do that.  There is tons of historical data  that today could save lives.  Today- I understand.

Speaker: SPEAKER_03
Transcript:  So you could have, you could probably,  can you pull data from dead people?  And I have no idea.  Well, let me tell you about that.

Speaker: SPEAKER_01
Transcript:  Let me tell you about that.  I'll tell you exactly about that.  Because I was just at the funeral home on Monday  with my mother's death certificates.  And a new wrinkle here I found out  since the last time we've had to go through this  with my family, is that we needed to get  two sets of death certificates.  We needed to get one that has no cause of death.  Because HIPAA requires that banks and such  receive a death certificate without cause of death.  They're not allowed to have it.

Speaker: UNKNOWN
Transcript:  Wow.

Speaker: SPEAKER_01
Transcript:  So even in death, yes, your privacy is protected  in a way that's ridiculous.  By the way, condolences.

Speaker: SPEAKER_02
Transcript:  I apologize for not saying this upfront.  No, no, no, no, I wasn't trying to go for that.

Speaker: SPEAKER_01
Transcript:  Thank you.  But HIPAA, thank you very much, appreciate that.  But I'm not trying to go milk for that.  HIPAA has gone to ridiculous extremes in a way.  So I was part of a world economic forum group about privacy.  And there was a great discussion there.  And you had major people in the health field,  doctors and hospitals and universities,  talking about what they lose  by this overprotection of privacy.  That discussion's being held.  It's being held in real terms.  And as far as I'm concerned,  the right side just lost one.  That's all I'm saying.

Speaker: SPEAKER_02
Transcript:  I'm right in the middle of this.  I recognize both arguments.  And I think because it's health data,  it's particularly charged.  Is it extra charged because it's Google  and had it been Watson, for instance?  You think the same ruling?  Probably, right?  Yeah, probably.  So it's not that it's Google,  although that adds to the fear that somehow DeepMind might.

Speaker: SPEAKER_01
Transcript:  Well, it's pointed out that Google did nothing wrong.  The NHS was the one who was named.  Though Google will still suffer.  Yeah, well, also some concerns that maybe.  And the Guardian went after this whole thing.  The Guardians, which has become my beloved Guardian,  has become so anti-tech.  So every time it's now reflexive  that every time they can go against technology, they will.  And so in this one too,  it's more you give too much data to Google.  Well, you weren't giving it to Google.  You were giving it to the NHS for good reasons,  but to treat you.  But anyway.  Sorry, I just.

Speaker: SPEAKER_03
Transcript:  Good talk, Jeff.  High five.

Speaker: SPEAKER_02
Transcript:  Yeah, and going forward, of course,  they should ask you if it'd be okay to share your data,  anonymized data with.  But that's going forward.  I understand it's not gonna save lives today.

Speaker: SPEAKER_03
Transcript:  Jeff, did you read,  Henrietta Lacks, what's the book called?  Is it something something life of.

Speaker: SPEAKER_02
Transcript:  Yeah, yeah.  Right, right.

Speaker: SPEAKER_03
Transcript:  It is sort of related here, but just.  With the physical thing as opposed to the.  I understand.  Racial things.  It's just perspective and historical use of data  slash physical, anyway.

Speaker: SPEAKER_02
Transcript:  It's the immortal life of Henrietta Lacks.  Her gene, which is scientists know as H-E-L-A or Gila,  she died of cancer in 1951,  and her gene cells were taken without her knowledge  at that time.

Speaker: SPEAKER_01
Transcript:  Which is a form of data, you're right,

Speaker: SPEAKER_02
Transcript:  her gene is a form of data.  And they've been bought and sold by the billions.  I think it's more, this one's more about  she was ripped off than her privacy.  That her privacy was impinged upon.

Speaker: SPEAKER_03
Transcript:  But this is kind of,  this is a consent issue because they actually didn't,  they used her, was it her ovaries?  I can't remember, her cervix cells.  They used those and cultivated them  without her permission or consent.

Speaker: SPEAKER_02
Transcript:  It's been used to develop the polio vaccine  for cloning gene mapping in vitro fertilization.  Her cells, the Gila cells are widely used and very valuable.  Now the question is, I mean,  they didn't have any value to her.  I don't know.  That is a fascinating.  They clearly had great value to a great many people.  Her family remains poor.  And that's an issue because, I don't know,  was money made with her cells?  I don't know.  Yes.  They were sold, huh?

Speaker: SPEAKER_03
Transcript:  I believe yes.  It's been like two, three years since I've read the book.  But totally an awesome book.  Everyone should read it.

Speaker: SPEAKER_02
Transcript:  It certainly raises some very interesting ethical issues,  somewhat similar to what we're talking about right now.  Although as an individual,  see, these are all individuals  whose data was borrowed by the NHS.  There's also the issue of what rights you've given up  by being a part of the National Health Service  and so forth and so on.  And the ICO's job is to protect you despite that.  The NHS clearly felt like, no, we own this information.

Speaker: SPEAKER_01
Transcript:  So let's say that you get the plague.  What, there were just two cases of the plague reported?  I know.

Speaker: SPEAKER_02
Transcript:  Fortunately, it's highly treatable in this era.  Thank God.

Speaker: SPEAKER_01
Transcript:  Thank goodness.  But let's say you get the plague and you say,  no, no, no, no, no, I don't want anybody to know that.  Nobody should, that's private.  And you risk other people getting the plague.  Right.  That's public health information.  I agree with you.  That's a good point. That's public health information.

Speaker: SPEAKER_02
Transcript:  In fact, yeah, when polio strikes or malaria  or any communicable disease,  that information goes right to the CDC.  It's anonymized also, but it goes to the CDC.

Speaker: SPEAKER_03
Transcript:  If you have certain strains of tuberculosis, actually,  but there are laws written about this.  Your data is actually shared.  But we wrote laws about that.  So people had these conversations,  not companies and the NHS,  but lawmakers and presumably medical advocates  and other people.  I see your point and I am not one to be like,  yes, let people die.  But I'm also a big proponent of privacy  and I'm not willing to give it up without.

Speaker: SPEAKER_02
Transcript:  Charm says, if you show up at work with a cold,  is it your obligation to tell your coworkers?  Or let's say something without symptoms  that's even more deadly, Ebola.  Right?  If you have Ebola, you should tell people.  You should tell people, I think you're right.

Speaker: SPEAKER_03
Transcript:  You should actually go, you might actually have to.

Speaker: SPEAKER_02
Transcript:  Well, what about more to the point and timely,  if you have AIDS?

Speaker: SPEAKER_03
Transcript:  You have to tell your partners.  There's laws about that.  You can't be a, what are they called?

Speaker: SPEAKER_02
Transcript:  Carrier?  There's a word.  Patient zero.  There's a word.  There's a word for someone who,

Speaker: SPEAKER_03
Transcript:  yeah, but there are laws about not infecting  your partners with it.  If you infect someone with AIDS  and you knew you had AIDS.  What do you bet?

Speaker: SPEAKER_02
Transcript:  Because that was, at the time, the gay cancer,  that that law got passed really fast.  Yeah.  That's the, I mean, part of the problem is,  and Jeff, I understand this is what rankles you most,  that there's a real mismatch between  how society decides this stuff and implements it  and the speed with which technology advances.  And you're all, you're in favor of technology  just advancing and Stacey's saying,  but there needs to be a discussion about this.

Speaker: SPEAKER_01
Transcript:  I agree with Stacey.  This is government data.

Speaker: SPEAKER_04
Transcript:  But I'm saying at some point,

Speaker: SPEAKER_01
Transcript:  you're right Stacey, it's government data.  The privacy is important, I agree with all that.  But I'm saying at some point, you choose to,  I would say we as a society should choose to violate  the lack of consent of people in the past  who wouldn't have known better.  I think at some point, if you said to Henrietta Lacks,  okay, we're going to try not to rip you off here.  But you know, if we take these genes from you  after you're gone, you could save countless,  countless people.  I bet Henrietta Lacks was a wonderful woman  who would have said, of course, of course.

Speaker: SPEAKER_02
Transcript:  Yeah, mostly upset about Hila is about the fact  that she wasn't compensated.  Right.  Not about privacy.

Speaker: SPEAKER_03
Transcript:  Well, and she did not get consent for herself.  And they talk about how uncomfortable it makes,  I think it may either it made her or it made her children  that parts of their mother in their,  and again, scientifically this is not accurate,  but they felt like parts of their mother  were like floating around in labs everywhere.

Speaker: SPEAKER_02
Transcript:  Right.  Which you- Of course it's not,  it's cells cultured from her cervical cells.

Speaker: SPEAKER_03
Transcript:  But no one explained that to them.  Yeah.  And that's why the second point,  so privacy is important, but two,  if you don't get consent and explain and educate people  about this stuff, all kinds of weird crap and beliefs  are going to like blow up around this.

Speaker: SPEAKER_01
Transcript:  So let's say that we find a lab  that has hundred year old hair samples,  and we find that using that data gets us something.  We have to go, we can't go back a hundred years.  But we find a new method.

Speaker: SPEAKER_03
Transcript:  Those people are all dead and that's anonymized.  Well.  I mean, hundred year olds.

Speaker: SPEAKER_01
Transcript:  No, it's not anonymized at all.  There's there's-  Was the issue that some of the data

Speaker: SPEAKER_02
Transcript:  that the National Health Service shared was live people?

Speaker: SPEAKER_01
Transcript:  No, it was the consent.  It was the lack of the proper consent for that data.

Speaker: SPEAKER_02
Transcript:  So they didn't stipulate whether they were dead or alive.  Some of them were, some of them weren't.

Speaker: SPEAKER_01
Transcript:  Yet again, because that wasn't anticipated  that you could ever predict kidney disease  based on this data.  So there was not a reason to ask.  That's the problem I have with this kind of limiting  the future by the knowledge of the past.  Then we cut off tons.  This is not just a little bit of NHS recent data  and the World Economic Forum project.  They were upset about having 50 years of data  they couldn't get because of things like this.  That had, these are the experts saying  we can have real impact from this.

Speaker: SPEAKER_03
Transcript:  I think that Google, if it wants this data  it can go and get a pretty relevant subset  of this type of data by talking to patients  and asking them to donate, talking to doctors  and having them talk to their patients.  It's just, it's a more fragmented approach.  It may be statistically not as awesome.

Speaker: SPEAKER_01
Transcript:  Which may lead to more false diagnosis.  But Google, which has an impact on people's lives.

Speaker: SPEAKER_02
Transcript:  But you're not gonna get 1.6 million patient records.

Speaker: SPEAKER_01
Transcript:  No, and the cost of that would be extreme.

Speaker: SPEAKER_03
Transcript:  I'm just saying that there are ways around it  just because in going forward, if that they can get consent.  I mean, you're basically saying I want it now  and I don't like the rules that were in place  when I got this stuff and now I want them changed  because we can do more with them.  That's not wrong.  But what the courts are saying is  we're not gonna retroactively change the rules  in this situation just because you,  someone wants it now. Reality changes.  And yes. Reality changes.  I know, I know.

Speaker: SPEAKER_02
Transcript:  But.  Should, just out of curiosity,  should we not have harvested and used those helos cells?  Are you asking me or both of us?  I mean, there was huge benefit from them.

Speaker: SPEAKER_03
Transcript:  No, we should, we did.  And if I were the doctor,  I mean, ideally we would have gotten consent.

Speaker: SPEAKER_02
Transcript:  Right. We didn't.  But she was dead.

Speaker: SPEAKER_03
Transcript:  No, when they harvested them,  they knew about them beforehand.  They knew her.  Well, they biopsied her cancerous cervix

Speaker: SPEAKER_02
Transcript:  and those cells that they had harvested.  But she was still alive.  Like some of the, she was alive.  Well, she was still alive, obviously.  But I don't know if they knew the value of those cells.  They just, because they were cancerous,  continued to reproduce.  And maybe later after she was dead,  they said these are valuable.  They got her consent probably to harvest them  in the first place.

Speaker: SPEAKER_03
Transcript:  No, they didn't.

Speaker: SPEAKER_02
Transcript:  That was part of the,  Well, it's part of the treatment.  I mean, she got a biopsy, right?  I mean,  Okay.

Speaker: SPEAKER_03
Transcript:  I don't know.  Like this is, I'm like,  should they have not done this?  I don't remember the facts.  There's a question of the greater good.

Speaker: SPEAKER_01
Transcript:  Right, did they do it wrong?  Yes, but is there a greater good?  I think they're clearly.

Speaker: SPEAKER_02
Transcript:  She wasn't harmed.  This was part of her cancer treatment.  So she wasn't harmed.  In fact, you could argue that this was  with an intent to help her.  It was later discovered the value of these cells.  It would have been nice, of course,  to compensate her and her estate  for the billions of dollars it's generated  or whatever it is.  Maybe it's a million dollars.  I don't know.  But there is  clear benefit to society from having done this.  No harm to her.  I don't know if a court would say,  there's a problem.  In fact, a court just.

Speaker: SPEAKER_03
Transcript:  But a court would probably say  they should compensate her in this case  or compensate her heirs.  But there was no harm.

Speaker: SPEAKER_02
Transcript:  So the interesting thing is.  Look, you know, even then,

Speaker: SPEAKER_01
Transcript:  even then, we all donate data to things.  So Foursquare makes money on knowing  that I've gone into that McDonald's  and not that McDonald's.  But you voluntarily give them.  They have that knowledge.  I did voluntarily give it,  but I didn't know that they were gonna make money  in a whole new model.  That's true.  They found a new model.  And I'm fine, of course, fine with that.  Knowledge.  This is the problem we get down to in the end  of saying can you own knowledge?  Yeah.  And a free society and an advanced and modern society,  the answer is no, you can't own it  because you can't tell other people  what they're not allowed to know.  And at the end, it's about knowledge.

Speaker: SPEAKER_03
Transcript:  Okay, no, there is a very big difference  between knowledge and data.  Oh, that's interesting.  Data gets knowledge.

Speaker: SPEAKER_01
Transcript:  And data is necessary to knowledge.  Data is information.  You can't own information.

Speaker: SPEAKER_02
Transcript:  Data is a precursor to knowledge, let's say that.  You can't own information.

Speaker: SPEAKER_01
Transcript:  You can own the treatment of it,  but you can't own information.  That is the essence of copyright.  You can only own the treatment of information,  not the information itself.

Speaker: SPEAKER_03
Transcript:  That's facts, but facts about an individual in person.  That's different from data about their genetic history  and that sort of thing, unless we create a series of laws  that protect people from the negative outcomes  that come from having certain-

Speaker: SPEAKER_01
Transcript:  That's what I argued in my book, exactly.  We need to do that.  I agree with that.  We absolutely need to do that.  And we need to stop people from insuring stuff.  So absent that, there are no protections.

Speaker: SPEAKER_03
Transcript:  There are no protections if your data-

Speaker: SPEAKER_02
Transcript:  We're gonna move-  Okay, I think we're gonna move on  because I think both points have been well-made.  It's a fascinating question.  And I don't know if there's a clear answer to it.  And the reason I mentioned harm  is because that's often the measure courts use,  the standard courts use for awards in lawsuits.  And it comes up in a recent lawsuit.  Facebook was being sued in the US over user tracking  when even after you're logged out of Facebook,  they would continue to track your internet activity.  And there was a suit saying that Facebook  had violated federal and California privacy  and wiretapping laws by storing cookies on their browsers  that tracked when they visited outside websites  containing Facebook like buttons.  The judge, Edward Davila in San Jose,  district court judge threw it out.  He said, nope, you failed to show  that you A, had a reasonable expectation of privacy  and more importantly B, that you suffered  any realistic economic harm or loss.  In other words, the abstract notion that it was harmful  wasn't sufficient for the judge to let the case move forward.  You had to show actual harm.  And I think a lot of these privacy issues are not,  it's difficult to show actual harm.  It's more potential or putative harm.

Speaker: SPEAKER_01
Transcript:  Or it's the creepy line or it's the what could be.  That's what I argued in the book.  Actual harm is the proper standard.  And even when there is actual harm,  the solution to that is not necessarily withholding  the information of the data.  It is almost always how the data is used.

Speaker: SPEAKER_02
Transcript:  And yet I bet a lot of people are upset over this decision  and feel like the judge protected Facebook.  And a lot of the stories I said,  Facebook allowed to continue to track you  even after you're logged out.

Speaker: SPEAKER_03
Transcript:  Well, okay, so here's something that,  and normally I'm pro in the harm category  in the sense that you should be able to,  you should have to show harm, except this privacy.  There's been some really well argued things  and I wish I were as erudite as the judges  who wrote their dissents here.  But privacy is the ability to like be your own person  in a space and not be judged.  And the question is, even if there's no harm,  is the fact that that information is known  and there is some judgment being made, is that a problem?  And that is a real question.  And that's where some of the privacy things about,  oh gosh, my brain just stopped working.  I'm sorry, you guys.

Speaker: SPEAKER_01
Transcript:  I'm too young for that, Stacey.

Speaker: SPEAKER_03
Transcript:  I'm so tired.  I blame the migraine medicine.  You can't use that excuse every week, Stacey.  It's topomax, it makes you stupid.  It is what it does.

Speaker: SPEAKER_02
Transcript:  Oh, can I get some?

Speaker: SPEAKER_03
Transcript:  It makes you skinny and stupid.  I call it the supermodel drug.

Speaker: SPEAKER_02
Transcript:  Oh man, that's nice.  Well, you know that that's how LSD was invented.  They were playing with Rymold's, Ergot,  which is used as a migraine medicine.  Yeah, and Albert Hoffman was trying  to synthesize migraine medicine  and accidentally synthesized LSD  and took the first acid trip.  What was that?  I think John will know this.  Was this back in 1945, I want to say?  It was in the 40s, it was a long time ago.  Took a very famous bicycle ride.  He accidentally touched some of it  and got some of it in his mouth,  got on his bicycle to go home and started tripping.  And all of that to keep you from getting headaches.  There we go.  Well, thanks, man.  Anyway, I'm sorry that you're a little spacey, Stacey.

Speaker: SPEAKER_03
Transcript:  I will be for like a month, but then I'll come back.  We got a new name for it, Stupimax.  Stupimax, oh, there you go.

Speaker: SPEAKER_02
Transcript:  So it's a month long treatment  and then you don't have to do it anymore?

Speaker: SPEAKER_03
Transcript:  No, it's forever.  Well, it's as long as I can tolerate it and then I stop.  I go off and on because it makes me lose my hair too.  I guess it's not the supermodel drug.

Speaker: SPEAKER_02
Transcript:  It's a, no, but I know it  because it's an anti-seizure medicine too.  It is.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_02
Transcript:  Hmm.  Yeah.  And in fact, the people I know who've been on, I hate it.  Hate it.  Because it makes you kind of...

Speaker: SPEAKER_01
Transcript:  Have you tried everything, I assume?

Speaker: SPEAKER_03
Transcript:  Oh, Jeff, I have tried everything  with the exception of LSD.

Speaker: SPEAKER_02
Transcript:  I think you should try it.  I've heard some good reports.  And I want to say, I've never had a migraine.

Speaker: SPEAKER_01
Transcript:  And we want to do the show,  well, we want to do the show with Stacey when she takes it.

Speaker: SPEAKER_03
Transcript:  Like, I'm usually not as bad,  but I'm struggling over this, who wrote this?  It was an awesome essay on the harms of a lack of privacy  that are not, that are just like self-censoring  is the closest I can get to it.  I was trying to look it up,  but I can't remember who wrote it.  So.

Speaker: SPEAKER_02
Transcript:  Well, yeah.  I mean, so yeah, that makes sense.  So in fact, it would have the opposite effect  to the beneficial effect Jeff talks about,  which is if you can't be assured that you control your data,  you might be more reluctant to share valuable data,  as Jeff often does about his medical condition  and his life condition.  And that is a valuable thing to share that.  But if you can't be assured that it's going to be,  that you control where it goes.  But I think Jeff's point is well taken,  which is we don't need laws to protect privacy.  We need laws to protect the misuse of that information,  that there is value in the sharing of information.

Speaker: SPEAKER_01
Transcript:  We need laws on privacy,  but the primary way to do that is to protect against it.  So Dana Boyd's great example of this,  when she sat me down and taught me about this,  she said, listen, Jeff, you come in and apply for a job.  I can see by the color of your hair, how old you are.  I can guess all kinds of other things about you.  I have the knowledge that you're an old fart.  And I can use that to not give you the job.  And I'll get away with that.  And that's the way life goes.  But if I do that 10 times in a row,  and you all get together,  and you share that knowledge that I've done that,  then there are laws and you can get after me  because of the use of that knowledge.  You can't stop Dana from knowing that I'm an old fart.  That's apparent.  What you do with that knowledge  and the pattern with which you do that  is a different matter.  And that's where we legislate the use of the knowledge  rather than the knowledge itself.

Speaker: SPEAKER_02
Transcript:  Boyd actually wrote, often privacy isn't about hiding,  it's about creating space to open up.

Speaker: SPEAKER_03
Transcript:  Oh, look, there it is.  Oh, is that what you were looking for?  Maybe.

Speaker: SPEAKER_02
Transcript:  I didn't take any Topamax.  This is a article in an ethics blog,  Loss of Online Privacy, What's the Harm?  From the Markkula Center for Applied Ethics  at the University of Santa Clara.

Speaker: SPEAKER_03
Transcript:  I keep scrolling when you show this on your screen.  I know, yes, that's it.

Speaker: SPEAKER_04
Transcript:  That's it.

Speaker: SPEAKER_02
Transcript:  They quote, and I love this at the beginning,  Gabriel Garcia Marquez,  all human beings have three lives,  public, private, and secret.  This is actually a really good article  that does address a lot of the things  we've been talking about.  Privacy is about much broader,  this is Jay Stanley, a senior policy analyst for the ACLU,  privacy is about much broader values  than just hiding things.  Ultimately, the fullest retort to the,  I thought it might be, I'm channeling you.  That's because I've taken a lot of acid.  Ultimately, the fullest retort to the nothing to hide impulse  is a richer philosophical defense of privacy  that articulates its importance to human life,  the human need for a refuge from the eye of a community  and from the self-monitoring that others,  that living with others entails,  the need for space in which to play  and try out new ideas, identities, and behaviors  without lasting consequences  and the importance of maintaining the balance of power  between individuals and the state.  And I would actually underscore that last one  because I think that's,  for a lot of people who watch this show,  the really, the kind of the critical point of all this  is maintaining the balance of power  between individuals and the state.  Yeah.

Speaker: SPEAKER_01
Transcript:  Yeah, and I have long argued that the state  presents itself as the protector of privacy.  It is the worst threat to privacy.  It is.  And I think that we should use that data  in ways that no one else can.  Yeah.

Speaker: SPEAKER_03
Transcript:  And this is also why I think like,  I am very against spying on like my daughter  because I think people need that space  to test things out and grow.  Yes.

Speaker: SPEAKER_02
Transcript:  That's why you shouldn't read a kid's diary unless,  and there are some mitigating circumstances  if you're afraid that they're doing something  really dangerous and you need to protect them.  You know, there are some mitigating circumstances,  but kind of generally invading their privacy  is not a good thing.  Everybody needs a private place.

Speaker: SPEAKER_03
Transcript:  Well, so then the question is,  without getting consent,  and I can't tell in this Facebook case if the issue,  I know he said it was harm,  but if people thought they were exiting Facebook,  thus making their activity on the web, quote unquote, private,  then does that mean,  then there is kind of a harm from it.  Except Stacey.

Speaker: SPEAKER_01
Transcript:  Okay.  But here's the but,  your ISP knows everywhere you've gone,  so it's not private to that extent.  So somebody else knows too.

Speaker: SPEAKER_03
Transcript:  Yes, and this is an issue of education among people  because I know that when I log out of Facebook,  Facebook is tracking me.  I know that if I actually turn on certain apps in stores,  their beacons are sharing my physical proximity data  in interest in certain products with Facebook and Google  because of retargeting via beacons,  which is freaking crazy.  But you are in a public place.  That doesn't, I mean, the issue is,  am I aware as an individual that this is all being shared?  And I think that's not a conversation we have a lot of,  and people don't know what they're sharing.  We're having it like crazy.

Speaker: SPEAKER_02
Transcript:  We have it here all the time.  Yeah.  I know, but like,  it's one of the few places, I agree with you.  I agree with you.  I agree with you, yeah.

Speaker: SPEAKER_03
Transcript:  It's like, you know, somebody walking around with like,  I don't know, they're fly unzipped.  We're all walking around with our flies unzipped  and we're not aware of it.  Well, I've done that.  And you know, maybe later someone decides  that it's a problem.

Speaker: SPEAKER_01
Transcript:  People respect my privacy and don't tell me,  I'd rather they tell me.

Speaker: SPEAKER_02
Transcript:  Did you see the story about the Ticketmaster app  that uses supersonic sound?  It's, so there's a new,  Ticketmaster is offering a new way to authenticate  at the gate when you buy a concert ticket.  You put their app on the phone  and the app emits tones at 19,  I think it's 19.5 kilohertz.

Speaker: SPEAKER_03
Transcript:  God, are you gonna play loud tones again?  No, I won't.

Speaker: SPEAKER_02
Transcript:  But you probably are young enough that you could hear this.  I am not, but, and most people are not,  very small percentage of people,  mostly young years can hear it.  But there's an additional feature to this app  because if you've installed this app,  which you have to to get into the concert,  it will continue to beacon at your location  easily and expensively to receivers all over the venue  so that Ticketmaster can track,  how much time do they spend at the beer counter?  How much time do they spend in the mosh pit?  How much time do they spend at their seat?  That kind of thing.  Now, I'm sure somewhere in the 15 pages  of tiny, tiny print on the back of your ticket,  Ticketmaster tells you that.

Speaker: SPEAKER_03
Transcript:  But you can't get in without it?

Speaker: SPEAKER_02
Transcript:  I think you need to have that to get in.  I think that's the plan.

Speaker: SPEAKER_03
Transcript:  So then you would have to get in and then delete the app  if you wanted to preserve your privacy?  Yeah.

Speaker: SPEAKER_02
Transcript:  Ooh, that is problematic.  I bet you could print out a ticket still.  It's on the ticket, I'm sure,  but it's in such fine print.  So that's another thing.  There's disclosure and then there's actual disclosure.

Speaker: SPEAKER_03
Transcript:  Right, well, in Europe at least, hold on.  I feel like I just saw a story about this this morning.  I'm pulling it up.  Okay, here we go.

Speaker: SPEAKER_02
Transcript:  This was an article in VentureBeat,  I think today, by the way, about this Ticketmaster app.

Speaker: SPEAKER_03
Transcript:  So this is from, remember how I told you  about my friend David  who started this Connected Rights newsletter?  He was writing about this Facebook case, I think.  But he said, consumer watchdogs in Germany and Norway  have recently been getting active in suing tech firms  over lengthy and penetrable terms and conditions  that make people sign away their privacy  without being super clear  about what will happen to their data.  So it sounds like we need some of that action here.  I actually had a class action lawyer a while back  on my show who talked about terms and conditions  and privacy rights.  The challenge is to do a class action suit,  which is one of the few ways  to get people to pay attention to this,  you have to prove harm.  So without harm, which is the case that we're talking about,  possibly what we're talking about with the Facebook thing,  they don't really have a case.  Now, a state attorney general though,  could come and sue on behalf of a population.  So that may be the future, I don't know.  I mean, this is where our legal system isn't quite set up  for what we're trying to make do with, I guess.

Speaker: SPEAKER_02
Transcript:  That was-  The company that Ticketmaster uses is Lysnr.  And apparently does this for other companies.  Land Rover uses it to have their cars communicate.  Here's the exciting video that Ticketmaster created  to share how wonderful this new listener technology  is gonna be.  No, it's unfortunately, it's all music, there's texts.  The ticket, an innovation that hasn't changed in 30 years,  but it's about to.  Two years ago, Ticketmaster set out to reimagine  how a ticket could personalize the experience  according to the identity of the fan.  By the way, you can't pirate these tickets  and it makes it hard to sell it in anything  but an approved venue,  which I think has a little bit to do with this as well.  So replacing the paper ticket with sound.

Speaker: SPEAKER_03
Transcript:  I wonder how easily you can hack it.

Speaker: SPEAKER_02
Transcript:  Yeah, wouldn't that be cool?  That would be.

Speaker: SPEAKER_03
Transcript:  I mean, cause like, if it's just a frequency,  isn't it easy to replicate?  I guess it's frequencies in several tones.

Speaker: SPEAKER_02
Transcript:  Yeah, but you copy the code.  Ticketmaster says the rollout has already begun  in some venues, it will take around four years  to complete the process globally.  And so if you, just so you know,  if you're a Ticketmaster user,  that there may be more going on.  If you walk up to the door and it says,  oh, hi Leo, we've been waiting for you,  your seat is ready.  Then you know you've got this new technology built in.  Each smart tone carries its unique identifier,  meaning venues can install smart tone scanners  around a space to track gig goers as they move around.  This not only arms venues with a vast swath  of geolocation data, it lets them target individuals  with tailored messages and quote,  deeply personalized experiences.

Speaker: SPEAKER_00
Transcript:  AKA ads.

Speaker: SPEAKER_02
Transcript:  Deeply personalized experiences.

Speaker: SPEAKER_03
Transcript:  I see you've been in the bathroom for 30 minutes.  Maybe you should lay off the hot dogs.  Yes.

Speaker: SPEAKER_02
Transcript:  This means, this is what EVP, a product ticketmaster says,  this means using identity to drive customized experiences  based on who you are, where you are, eliminating fraud,  resulting in a safer environment  and delivering more personalization  based on the specific event you're attending.  I'm going to bet this doesn't mean the band's  going to play more of your requests.  Wow, so you're going to see more of the shopping malls,  shoppers.  It's an interesting idea.  You don't have to use Bluetooth or beaconing.  You can just do it.  We know this already that TV speaks sometimes  to your app, right?  Yes.  Why is this better than a barcode?  Doesn't require the user to interact  or even know about it.  You just walk through the door.

Speaker: SPEAKER_03
Transcript:  That's why.  If it's a connected door, it'll shut in your face.  Like eh.

Speaker: SPEAKER_02
Transcript:  Google didn't Google use,  I think Google has something called nearby that's similar.  In fact, remember,  well, Google's trying stuff like this all the time.  For a while, you could pay at a McDonald's near Google  by just smiling and it would recognize you and say,  oh yes, we'll take that out of your account right now.

Speaker: SPEAKER_03
Transcript:  Ah, you're right.  Whatever happened to this?

Speaker: SPEAKER_02
Transcript:  You remember that?

Speaker: SPEAKER_03
Transcript:  I'm looking at it and I'm like, huh, this is cool.

Speaker: SPEAKER_02
Transcript:  I don't remember this at all.  It was only in Silicon Valley.  Oh.  So here's a, there's a little skills gap.  Has got, I mean, Echo has mad skills.  I guess if I change it and say, I mean,  doesn't mean it didn't activate your, you know who.  15,000 skills now on the Amazon Echo.  Compare that to the number of skills  the Google Assistant has, 378.  Or Cortana has, 65.  And you can see there's a fairly large skills app.

Speaker: SPEAKER_03
Transcript:  So let's ask, let's do a little informal survey.  What, how many skills do you have activated  in your Echo app?

Speaker: SPEAKER_02
Transcript:  Is there a way to go look and see that?

Speaker: SPEAKER_03
Transcript:  Yeah, well, I think, let me see if it's only smart.

Speaker: SPEAKER_02
Transcript:  Cause that's the really the big problem, isn't it?  Is that people don't know the skills exist.  It's hard to figure out what the skills are.  It's kind of like the app store problem.  One of the things I like about the Echo show,  and it might be one of the reasons they created a screen  is the screen will tell you about skills  as part of the rotator.  It tells you things you can do.

Speaker: SPEAKER_03
Transcript:  And so you can go into your skills.  If you go to skills, there's a button called your skills.  And then you can see what you, how many you have.  All right, let's go into skills.

Speaker: SPEAKER_02
Transcript:  How many skills do you have, Stacey?  I'm counting 12.  Oh, you have to count them?  16, 20, 24.

Speaker: SPEAKER_03
Transcript:  Okay, I have.  I have 25.

Speaker: SPEAKER_02
Transcript:  I have four a fart, 60 B,  seven minute workout, which I have never used.

Speaker: SPEAKER_01
Transcript:  I've used it.  Not even for one, for seven minutes?  Not even once.

Speaker: SPEAKER_02
Transcript:  Abra, which I think is the one where it takes,  your Echo can give your smart home commands  using spells from Harry Potter, I think.  Remember that one?

Speaker: SPEAKER_03
Transcript:  Oh yeah, I do remember.  This is your life.

Speaker: SPEAKER_02
Transcript:  Yeah, AccuWeather, admirer.  I can tell my admirer to make me smile.  I don't know, age calculator, things to try,  ambient noise of several kinds, thunder, rain, and ocean.  Anymote, I don't even know what that is.  Oh, ask Anymote to play my Sonos.  It's some sort of smart remote for Sonos.  Earthquakes, God, I'm just in the A's.  I'm not counting these.

Speaker: SPEAKER_03
Transcript:  There's a lot of them.  Yeah, you apparently have a lot.  Well, I try them.

Speaker: SPEAKER_02
Transcript:  I try them, I try everything.  But most people probably have a handful.  No, you go through your skills  and delete skills you don't use.  I'm doing it right now.  Why?  I have, here's a skill.  Here's a resistor decoder skill.  So you get a resistor and you read it,  the colored rings,  and it'll tell you what kind of resistor it is.  That's useful.  Boy, that's a 43 ohm resistor there you got there.  Petaluma Patch, NPR Story of the Day.  A lot of these are flash briefing.  Math puzzles, Magic 8 Ball.

Speaker: SPEAKER_03
Transcript:  Do you have Would You Rather?  Oh, that might be my tip of the week.

Speaker: SPEAKER_02
Transcript:  I hate Would You Rather.

Speaker: SPEAKER_03
Transcript:  Oh my God, my daughter loves it.

Speaker: SPEAKER_02
Transcript:  I hate that game.  It's all hypotheticals for one thing.

Speaker: SPEAKER_03
Transcript:  Oh, it's perfect.  You're a radio show host.  What are you talking about?  That's all.  What did we do?  We argued forever about hypotheticals.

Speaker: SPEAKER_02
Transcript:  That's a good point.  This is my life.  Hypotheticals are my life.  Well, it's not hypothetical 15,069 skills at last count.  I thought the last thing I remember was 5,000.  So it's just growing like toxic.

Speaker: SPEAKER_03
Transcript:  Yeah, they had 10,000 I think in February.  Yeah.  And nobody's making money on those, right?  You can.  Only on the game developer once.  And it's unclear how that works.  You have to apply and talk to the Amazon people.

Speaker: SPEAKER_02
Transcript:  Well, speaking of which,  remember that Prime Day is coming, the third annual.  And there will be, I'm sorry,  Echo voice deals for Prime Day.  So get ready.  Prime Day is July 11th.  It's a week from-  What's a voice deal?  Huh?  What's a voice deal?  Well, you can ask Echo,  God, I'm sorry.  You can ask Echo, what are your deals?  And then they will give you some.  And then you could say, order that.  That's dangerous.  And voice shoppers will get access to special deals  two hours before the main event begins  at 6 p.m. Pacific on July 11th.  Did you buy anything in the last Prime Day?  I didn't.  You know, I really resist.  It's nothing there.  I try to resist stuff like that  because I feel like I'll buy things I don't need.  Like I never do that.  Like all of a sudden, 16 yodel pickles will arrive.

Speaker: SPEAKER_03
Transcript:  That's happening, Leo.  You don't realize it, but the dash wand is like,  oh, yodel pickles for everyone.

Speaker: SPEAKER_02
Transcript:  Okay, but whatever you do,  don't order the sugar-free gummy bears.  Okay, I'm just saying.  Right.  Noted.  And by the way, if you're not a Prime subscriber yet,  this is a good time to become a subscriber to Prime.  You get $20 off, $79 a year, if you enable.  And you can do that with your Echo as well.  You just say, sign me up for Prime.

Speaker: SPEAKER_03
Transcript:  Oh, then it's like Prime cost,  what it cost when I first signed up.  Yeah, exactly.  That's what it's price used to be.  It's many years ago.

Speaker: SPEAKER_02
Transcript:  Yep, yep.  And $10 credit for any orders purchased before July 10th  if you've never used voice shopping before.  So, wow.  They're just gonna take over the world, I think.  They are.  They're just gonna take, this is the deals with,  they call it deals with the A word.

Speaker: SPEAKER_03
Transcript:  We have renamed her Madam A on our show.

Speaker: SPEAKER_02
Transcript:  Madam A, good.  Can we steal that?  You're welcome to it.  Once in a while I plug Stacey on IOT.

Speaker: SPEAKER_03
Transcript:  You don't have to, I mean, you don't have to plug the show,  but yeah, it's a little easier  because you wanna have a person.

Speaker: SPEAKER_02
Transcript:  Yeah.  I call it Echo, I don't think that's too hard to do.  But it's a- No, it's not.  Yeah.

Speaker: SPEAKER_01
Transcript:  You have seen the Saturday Night Live Echo  for old people, haven't you?

Speaker: SPEAKER_02
Transcript:  Oh, love it. Yes, oh, that was so great.  We played it on the show, you must have.  Yeah, yeah. It's just brilliant.

Speaker: SPEAKER_01
Transcript:  Just brilliant. I love it.

Speaker: SPEAKER_03
Transcript:  You know what would have made it more perfect  is if you were in the commercial, Jeff.

Speaker: SPEAKER_01
Transcript:  That would have been just awesome.  I'm not old.  Now you're really.

Speaker: SPEAKER_02
Transcript:  I'm cruising.  You know that Jeff and I are pretty much the same age,  you know that, right?  So anything you say bad about Jeff  bounces off him and sticks to me.

Speaker: SPEAKER_03
Transcript:  Well, that'll do it until I get my Punch Leo button, I guess.

Speaker: SPEAKER_02
Transcript:  Get off my virtual porch.  So Bixby, the Bixby button, what a mess up this is.  I have a dedicated button on my Samsung Galaxy S8  that not only doesn't do anything much now,  it won't for the foreseeable future.

Speaker: SPEAKER_03
Transcript:  That they're making a Bixby voice product for who?

Speaker: SPEAKER_02
Transcript:  Well, for Korea, that's the problem.  Bixby works fine in Korean.  Bixby is the smart intelligence additional.  Like I need an extra, on any Android phone,  anything besides Google Assistant.  Bixby is Samsung's version.  Like they do on all their, you know, they always do this.  Oh, it's not enough just to have Google voice,  you have to have Samsung voice or Google Pay,  you have to have Samsung Pay.  The English version will be delayed again  because it lacks enough big data to teach it to work.  Nobody's using it, how are they gonna?  It was supposed to launch in April,  then push to spring, then to June.  They have a beta version out now.  In fact, Florence Ion showed us on the new screensavers  a couple of weeks ago.  It's mostly, at least in its current incarnation in English,  used to launch apps.  And you can actually do things like crop pictures  and stuff with your voice.  So it doesn't really overlap that much  with Google Assistant.  But it's just annoying that they put  a physical button on there.  It does nothing.  Maybe they can make it yodel.  That would make it a very expensive yodeling pickle.

Speaker: UNKNOWN
Transcript:  Exactly.

Speaker: SPEAKER_02
Transcript:  And yeah, they're doing a Bixby powered smart speaker,  but it would, as is by the way,  I think Baidu is doing one for China.  They just released it.  But these are for those markets.  So the Korean Bixby does work.  It's getting out of their languages.  Oh, okay, so the challenge is it doesn't speak English.  It's getting out of their languages,  and so I presume the Bixby will be Korean only.  I didn't know this happened,  but it just happened, I guess.  The laptop ban on passengers flying  Etihad, Emirates, and Turkish airlines has now been lifted.  Oh, yay.  Six other airlines still are subject to the ban.

Speaker: SPEAKER_03
Transcript:  Did they change their screening policies?

Speaker: SPEAKER_04
Transcript:  Yeah.

Speaker: UNKNOWN
Transcript:  Okay.

Speaker: SPEAKER_01
Transcript:  I forget what they said when I read the story.  I can't remember what they're doing.

Speaker: SPEAKER_02
Transcript:  So the ban, remember, was started in March  covering flights to US destinations  from 10 airports in the Middle East.  And on only Middle Eastern airlines  of all electronic devices, including laptops,  tablets, and e-readers,  you couldn't bring your Kindle on either.  The ban was obviously difficult to carry out.  Individual boxing of every single electronic device  traveling with a passenger at the gate, things like that.  So anyway, so this article, TechCrunch, doesn't say  what changed.  I forget.  But that's good.  Maybe they won't do the generalized laptop ban  that they were talking about.  The Afghanistan, here's a story that'll cheer you up.  The all-girl robotics team, this is first,  which is great, and for the first time ever,  Afghanistan had fielded a first team.  It was a first team.  It was all women.  They tried, six Afghan inventors trying to come to the US  for the first global challenge in DC mid-July.  They couldn't get permission from the United States  to interview for their visas.  The girls risked a 500-mile trek cross-country  to the American embassy in Kabul.  And that's a dangerous place.  There've been a number of recent suicide attacks  and a truck bomb.  Yeah, it's dangerous just to be a woman there.

Speaker: SPEAKER_03
Transcript:  It's dangerous to be a woman who's interested  in getting educated.  It's dangerous to travel 500 miles across the nation

Speaker: SPEAKER_01
Transcript:  as a woman.  Yes.  And they did it not once, but twice.  Geez.

Speaker: SPEAKER_02
Transcript:  But were denied the visa.  So I think, though, that the teams from Iraq, Iran,  and Sudan were able to secure travel visas.  Only Afghanistan, Team Afghanistan, and Team Gambia  have been denied visas so far.

Speaker: UNKNOWN
Transcript:  It's kind of too bad.

Speaker: SPEAKER_03
Transcript:  Yeah, you know, we're gonna,  we're already seeing tourism down.  What happens when we stop hosting events like this?  Because people can't get here.  Yeah.  Because they can't travel here.  Well, convention's.  Yeah.

Speaker: SPEAKER_01
Transcript:  So I held a summit at CUNY some,  right after the ban was announced,  and there was the head of technology  for one of the largest publisher in Scandinavia  couldn't come because he was born in Iran.  That's ridiculous.  It is indeed.  Yeah.  This is our world now.  We make strangers the enemy, no matter who they are.

Speaker: SPEAKER_02
Transcript:  So I'm disappointed to say that Instagram  is now cracking down on fake influencers.  So that's gonna really reduce my ability  to sell health teas and makeup.

Speaker: SPEAKER_03
Transcript:  There goes my makeup blog.

Speaker: SPEAKER_02
Transcript:  Yep.  Sorry.  Dang it.  Sorry, Stace.

Speaker: SPEAKER_03
Transcript:  I was worried.  My van life blog.

Speaker: SPEAKER_02
Transcript:  What is a fake influencer?  I would like to know.  What is a real influencer?

Speaker: SPEAKER_03
Transcript:  I mean, really.  A Kardashian.  I'm like.

Speaker: SPEAKER_02
Transcript:  That's a real influencer.  So.

Speaker: SPEAKER_03
Transcript:  I got a name tag that called me an influencer,  and I was like, I'm sorry.  No, I'm a journalist.

Speaker: SPEAKER_02
Transcript:  Turns out there were sites like Instagram, Insta Plus,  and Peer Boost, which third party sites  which help you boost the number of followers,  not for real, obviously,  and that violates Instagram's guidelines.  They were wannabe influencers use these types of services  to automate generic comments and likes.  You pay for the number of likes and comments you want,  and a bot takes care of the rest.  So brands, I guess, see all those likes and loves  and comments and say, oh, this is an influencer.  We ought to give her a free Bose speaker system  or whatever it is.

Speaker: SPEAKER_01
Transcript:  There's huge ad agencies that do nothing but this now.  Yeah.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_03
Transcript:  If I search for influencer in my inbox,  I bet I have a bunch of crazy emails.  So yeah.

Speaker: SPEAKER_02
Transcript:  You're an influencer, I bet.  How many Instagram followers do you have?

Speaker: SPEAKER_03
Transcript:  I don't have an Instagram.  I mean, I do have an Instagram,  but I don't post anything on it.  I'm ancient.  Like you guys joke that you're old.  I am like.  You don't know old.  We know old.  I'm old and I'm not social.

Speaker: SPEAKER_01
Transcript:  So it's terrible.  You may be cranky, but you're not old.

Speaker: SPEAKER_02
Transcript:  Good article last year in Bloomberg by Max Chafkin.  He says.  Ah, Instagram.  Oh, wait a minute.  Let me pause this auto start video.  Confessions of an Instagram influencer.  I used to post cat photos,  then a marketing agency made me a star.  Oh, Lord.

Speaker: SPEAKER_03
Transcript:  That was a great story.  I remember this.  I know, remember this?  Yes.

Speaker: SPEAKER_02
Transcript:  So you can get $10,000 for one Instagram post.  Of course, the FTC says now you have to really use hashtag  add right at the front and stuff like that.  I don't know.  Do you think that that diminishes the value  because now people don't think you really like something?  You're just doing it because you, I think so.

Speaker: SPEAKER_03
Transcript:  Yeah.  And that's kind of one of the problems.  I mean, I remember when I was like probably in my teens,  reading a science fiction story  where they predicted basically today,  which was like the setting was a time  when people would get credit for liking things.  Like, oh, I love this scarf by so and so.  And no one actually liked anything anymore.

Speaker: SPEAKER_02
Transcript:  So I follow a good friend.  I just Dean love her.  She's a definitely influencer.  And I was following her Instagram and I saw this post.  She's talking about all her amazing.  Look at this TV.  It's like a wallpaper on TV.  And it really is cool.  And then I read the post and said,  this TV is so insane links in bio for unboxing  and set up hashtag LG LL OLED TV, hashtag ad.  And you're right.  It kind of soured me on this.  It's like, this isn't a real post.  This is an ad in my Instagram feed.  She got 79,000 views.  And I bet you she got, aside getting the TV for free.  She probably got some good money out of that.  No, I love Justine and more power to her.  I don't have a problem doing that at all  because she's hashtag added and everything.  But it does seem to me that the brand is getting less,  a little bit less because it's an ad.

Speaker: SPEAKER_03
Transcript:  Yeah.  But it's made to, I mean, that's,  we talk about that in journalism all the time.  The whole goal of advertisers right now  is to provide something that looks  as much like content as possible.  It's trick you.  Yeah.

Speaker: SPEAKER_02
Transcript:  Well, we've had a lot of fun and I am starving now.  So I want to just go have this can of Dinty Moore Hardy.  This is everything you want in a can of stew and more.

Speaker: SPEAKER_03
Transcript:  Hashtag add.  I used to get, my mom fed me that.  I don't, I've never opened a can.

Speaker: SPEAKER_02
Transcript:  That explains it all.  It's nasty.

Speaker: SPEAKER_01
Transcript:  You still haven't gotten over the adjuta, have you?

Speaker: SPEAKER_03
Transcript:  She was a working mom.  So it's totally, totally legit.  No, fine, yeah.  Bless her for feeding me at all.  She fed you.

Speaker: SPEAKER_02
Transcript:  That's, you know, she's her obligation, right?  And look at, you're strong, you're healthy.  You have migraines, that's probably why.  I said it.

Speaker: SPEAKER_03
Transcript:  I blame the hamburger helper in Dinty Moore beef stew.  I love hamburger helper.

Speaker: SPEAKER_02
Transcript:  That's still a treat.  It is not good for you.  It's a guilty pleasure.  Hey, I eat a lot of stuff that's not good for me.  It's county fair time.  And, you know, I told-  Oh, dogs.  Oh, exactly.  You know.  I told Lisa the only reason I go to the fair  is for fair food.  And I think, I don't know if she posted it,  but there's a picture of me somewhere  with a corn dog this big.

Speaker: UNKNOWN
Transcript:  Wow.

Speaker: SPEAKER_03
Transcript:  How do you feel about funny funnel cake?

Speaker: SPEAKER_02
Transcript:  Love it.  Love it. Okay.  Yeah.  And then there's a guy sells fudge there  that's just amazing.  And, you know, talk about guilty pleasure.  I just, I feel terrible for it.

Speaker: SPEAKER_01
Transcript:  Al Franken put up a link to the Minnesota State Fair  and they've gone all fancy dancy with the state fair food.  It was amazing.  And truffles and God knows what.

Speaker: SPEAKER_02
Transcript:  It's funny, because Minnesota State Fair  is I think where I first learned of the deep fried Oreo  and Snickers and all of that.  It looks like Lisa never posted the picture of me  in the giant hot dog.  It was a favor to you.  Thank you Lisa. Probably.  Because it really would have been compromising.  Is that what you like at the county, at the state fairs,  Jeff, is corn dogs?  I used to when I was a kid.

Speaker: SPEAKER_01
Transcript:  They're so good.  Fulton County Fair and Fulton County, Illinois.

Speaker: UNKNOWN
Transcript:  So good.

Speaker: SPEAKER_03
Transcript:  I do the turkey legs.

Speaker: SPEAKER_02
Transcript:  Oh yeah, the big Henry VIII turkey legs.  Oh, geez.

Speaker: SPEAKER_03
Transcript:  And you have to make noise and wave it around  like a drunken, angry, big man.

Speaker: SPEAKER_02
Transcript:  It is basically a club made of meat.  Yeah, yeah.  Stacey, share something cool and neat  that you just got with us.

Speaker: SPEAKER_03
Transcript:  Oh, so instead of a pic,  I was actually gonna revisit some of my old pics  after they've lived in my life.  That's actually a good idea.  Tell you what I think, what's worth it and what's not.  Good.  So a couple of weeks ago,  I told you about the Leviton light switch  that was Madam A enabled and it's also Google Home enabled.  After living with it,  I have decided I do not like this light switch.  It is.  So the Leviton, it's 50 bucks,  Leviton Decora Wi-Fi light switch.  I don't like the toggle mechanism  and I don't like the dimmer slider.  It's just not a fan.

Speaker: SPEAKER_02
Transcript:  So thumbs down on the Decora smart switch with Z-Wave Plus.  You were so excited about it when you got it.  Yeah, but you liked before you liked that other one.  What's that other one?  You still like that one.

Speaker: SPEAKER_03
Transcript:  I love Lutron.  In fact, I added more Lutrons to my house.  There is one in,  I'll post a video on it actually.  I forgot that I have a video on it,  but there's one that you can use without a neutral wire,  but it's only on off and I love it.  So it's the  That's the Cassetta.  It's the Cassetta, but it's the P, hold on, X, no, 5X.  There's a lot of weird.

Speaker: SPEAKER_02
Transcript:  So it doesn't have a dimmer, it's just on or off.

Speaker: SPEAKER_03
Transcript:  It's just on or off, but you can use it  to make your lights.  What's the word I'm looking for?  Five W. Smart.  Yes.

Speaker: SPEAKER_02
Transcript:  No, I would like that.  Cause I don't, a lot of this lights now I use are LEDs  and I don't, even if they're dimmable,  I don't like the way they dim, they dim, you know,  so I just

Speaker: SPEAKER_03
Transcript:  Oh, okay.  So yeah.  And you can put, so the one without a neutral wire  is the PD5WS.  Ah.  There is a one that is a six W and it's five amps  versus six amps is what it's controlling.  So, but if you don't need the neutral wire,  you can use the six amp or if you have a neutral wire,  you can use the six amp and I put mine on ceiling fans.  So that was nice.  And then the other thing I was gonna tell you about is

Speaker: SPEAKER_02
Transcript:  That works with HomeKit, it works with Echo.  It works with everything.  They have, I mean, it just, it's the smartest  of the smart switches, right?

Speaker: SPEAKER_03
Transcript:  Yes, but you do have to have a bridge.

Speaker: SPEAKER_02
Transcript:  They have their own bridge.  You have to use their proprietary bridge.

Speaker: SPEAKER_03
Transcript:  So, okay.  And then I have an update on the SNOOZ, S-N-O-O-Z,  which was the crazy expensive fan white noise machine.  I did not pay a full $80.  I paid 60 for mine.  And I think it was awesome.  This is a Kickstarter.  This is a Kickstarter.  It was.  Yeah.  I love it.  My whole family fights over it.  And apparently I snore gentle ladylike snoring at night  that may not be so gentle.

Speaker: SPEAKER_02
Transcript:  Here's a guy who clearly snores not ladylike.  There you go.  The SNOOZ video.

Speaker: SPEAKER_03
Transcript:  My husband turns it on.  Like sometimes if I forget that it's on,  my husband will like come over  and to my side of the bed and turn it on.  He says it helps reduce my snoring slash he doesn't hear it.  So there you go.

Speaker: SPEAKER_02
Transcript:  It's a peaceful white noise from a real fan.  But see, then you have a fan going.  I don't know if I want a fan going.

Speaker: SPEAKER_01
Transcript:  It's nice.  Everybody's just keep your laptop going, yeah.

Speaker: SPEAKER_03
Transcript:  Oh, you could do that.

Speaker: SPEAKER_02
Transcript:  But does a fan, does it blow air  or is the fan the noise generator?

Speaker: SPEAKER_03
Transcript:  It does.  It's the noise generator.  Okay.  So it doesn't blow air.

Speaker: SPEAKER_02
Transcript:  Oh, so yeah, I don't want a fan on my face.  Okay.

Speaker: SPEAKER_03
Transcript:  And you can schedule it.  So the Bluetooth stuff is not like my favorite.  I don't really spend a lot of time on the app personally,  but my daughter likes when she steals it,  she likes it to go off like at midnight or something.  So we can schedule it to go off at midnight.  So what does it sound like?  Oh, I played it for you guys.  Do you want me to run and get it?  No, no, no, that's okay.

Speaker: SPEAKER_02
Transcript:  It's like, is that whoosh sound?

Speaker: SPEAKER_03
Transcript:  Sounds like a white noise generator.

Speaker: SPEAKER_02
Transcript:  Let's see if he, oh yeah.  You can hear it's like.

Speaker: UNKNOWN
Transcript:  Oh.

Speaker: SPEAKER_02
Transcript:  There's too bad they have the cheesy Casio music  on top of it.  Exactly.  It's also great for kids.  Studies have shown that baby.  Oh, shut up.  There it is.  There it is.  And I think we've all been in that position.  Customize the tone from light fans.

Speaker: SPEAKER_03
Transcript:  Mine does not look like that.  Which is like packing.  This is the original Kickstarter.

Speaker: SPEAKER_02
Transcript:  That actually looked like it was made out of clay.  Yeah.  Yeah.  It's probably the clay prototype.  And they had some guy in the background going.  All right.  So the Cassetta, yes.  No, yes.  Cassetta, yes.  The Cora, no.  Snooze, yes.  Snooze, yes.  Got it.  Jeffrey, a number.

Speaker: SPEAKER_01
Transcript:  So two Silicon Valley billionaires  that is to say, where'd it go?  Where'd it go?  Here we go.  That is to say, Reid Hoffman and Mark Pinkus  have started a project to reinvent the Democratic Party  called WTF, which of course stands for win the future.

Speaker: SPEAKER_02
Transcript:  Oh, good Lord.  I think Mark thought up the name.

Speaker: SPEAKER_01
Transcript:  It's a modern people's lobby that empowers us all  to choose our leaders and set our agendas, said Pinkus.

Speaker: SPEAKER_02
Transcript:  Just what we need another lobby.

Speaker: SPEAKER_01
Transcript:  Yeah.  So people will vote on the policies  and discuss them on Twitter.  Oh, I can see nothing that will go with that.  Oh, this, no.

Speaker: SPEAKER_02
Transcript:  See, I think Reid Hoffman's very smart.  We talked about his decency pledge last week.  Mark Pinkus, the founder of Zynga, not so sure about him,  but I don't do, okay, well.  You know, I think it's pretty clear  that we need to find new ideas somewhere.  I just feel like Silicon Valley  may not be the place to loathe.

Speaker: SPEAKER_04
Transcript:  Yeah.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_01
Transcript:  Especially right now.  By the way, Leo, did you order the Centio,  that thing that turns your Amazon phone  into kind of a laptop?

Speaker: SPEAKER_03
Transcript:  Oh, did you get yours, Jeff?

Speaker: SPEAKER_01
Transcript:  Oh, no, no, no, no, it's now, I tried to cancel it,  that's what I always do.  I have second thoughts and then I couldn't.  And then they, they probably were very transparent  about learning some things in the beta  and making some changes,  but now means the delay is delayed until like November.

Speaker: SPEAKER_02
Transcript:  So I have the thing that Samsung shipped with their S8,  the Dex, which does some of the same thing.  And Samsung-  No more stationary.  The Dex is a little disc and you plug it  into any available mouse, monitor, and keyboard.  So unlike this, that's pretty small,  but where you're going,  you have to have a mouse, monitor, and keyboard.

Speaker: SPEAKER_01
Transcript:  Which is the issue.  I don't normally just have a spare mouse, monitor,  and keyboard anywhere.  So this kind of makes sense, but I don't know.  So you can now, you can now get a cancel  if it's too late in the night.  What do you think, should I hold on to it?  Or do I order?

Speaker: SPEAKER_02
Transcript:  I've never been overwhelmed by this.  One of the reasons that Samsung makes sense  is because they modified their version of Android  to accommodate the screen.  I don't know how Android's gonna look on, you know,  just a generic phone when it's hooked up to this.  I mean-  Well, there's an app you run.  Oh, there's an app, okay.  There's an app, yeah.  I mean, I think, you know,  I have a number of these devices.  And I think the principle makes sense.  Execution, maybe not.  You'd like something, but you travel so much,  I can understand why you'd want something like that.

Speaker: SPEAKER_01
Transcript:  I can't decide.  I never can.

Speaker: SPEAKER_03
Transcript:  How much is $129 to you, Jeff?  I mean, really, that's what you should ask.

Speaker: SPEAKER_01
Transcript:  It's actually, of course I ordered the Deluxe,  which has the backlighting and the backlit keyboard,  and so it's 190, I think.

Speaker: SPEAKER_02
Transcript:  Ooh, oh no, killing.  This was a winner on Kickstarter at the time,  the biggest hardware startup of all time,  $2.9 million they raised on this.

Speaker: SPEAKER_01
Transcript:  Yeah, so when's the Deluxe, you see?  You know, it's a good, you know,  they're being very transparent in saying  we started with this thing and we've learned some stuff.  So,  the main challenges the team faces,  a significant number of phones using  non-standard communications protocols  due to Android's fragmentation.  And so they changed the firmware and stuff,  so now it's gonna ship  late October to late, in late November.  Run away.  I ordered it.  Yeah.

Speaker: SPEAKER_02
Transcript:  I have ordered, I just got emailed today  that my Eco Rico's coming later in the month.  Do you know about the Eco Rico electric scooter?  Oh!  No, scooter?  No.  This is another way for me to break my neck.  Actually, I got it for Michael,  because his bus stop is about,  is like a mile from his school,  or actually two miles.  So we got him the Eco Rico, the new model R,  can go up to 20 miles an hour.  Wow!  It has a 10 to 40 mile range, lithium ion,  it's got a headlighted tail light,  an underlight, turn signals, air tires, front shocks.  It's a little heavy, it's 27 pounds,  but it's light enough that he could,  and it folds up that he could carry it  as he gets off the bus, carry it onto the bus,  and then unfold it and whiz off to school.  Nine out of 10 Americans commute to work.  We've seen it because this is a going concern,  which is nice.  This company, Eco Rico, makes other model scooters.  We haven't seen the R yet, but they make other scooters.  I don't know, I think this seems like a cool idea.

Speaker: SPEAKER_03
Transcript:  So I'm waiting on my, it's called Mighty.  It is a Spotify player,  and I wanted it when it first launched,  and I waited because I was like,  oh, this does not look like it's gonna go anywhere.  But then I bought it like at the end of June,  or no, the beginning of June,  because they had gotten finally all the Spotify approvals,  and they said it was shipping at the end of the month.  So I bought it, and now it was supposed to ship by June 30th,  but so far I got nothing and no communication from them.  It's a new feature of the show, Kickstarter nightmares.  I was so, I thought I was being smart.

Speaker: SPEAKER_02
Transcript:  No, it's never smart to buy something on Kickstarter.  Never, ever.

Speaker: UNKNOWN
Transcript:  Run away.

Speaker: SPEAKER_03
Transcript:  Exactly.

Speaker: SPEAKER_02
Transcript:  So, which is exactly why I just bought some Sara,  the world's first aluminum smart suitcase.

Speaker: SPEAKER_03
Transcript:  Oh, you know, AT&T is putting stuff into me now.  Did you see that?  Oh, see I like Toomey.  I mean, those are crazy overpriced.  Yeah, they're expensive.  Oh, of course you do, they're fancy.  I never own a Toomey.

Speaker: SPEAKER_02
Transcript:  It's one of my life bucket list goals.  With your Eames chair?  Yeah, my Eames chair, my Toomey.  So let me see.  Yeah, of the things I've ordered on,  there's quite a few things I've ordered on Kickstarter  that I never got.  Really?  Yeah, going back to 2011 when I ordered a pair  of $100 dice that I still haven't gotten six years later.

Speaker: SPEAKER_03
Transcript:  What kind of dice are these?  They ain't your grandpappy's dice.

Speaker: SPEAKER_02
Transcript:  They're quantum dice.  Quantum dice, I'm still waiting for my Jibo,  that was on Indiegogo, that was the robot that talks to you.

Speaker: SPEAKER_03
Transcript:  Oh yeah, they had some management shakeups.  Did they?  Yeah.  Cynthia was taken.  Cynthia Bershears left?  She's still there, but she was taken back from,  she's taken down as CEO.  So I think there was some.

Speaker: SPEAKER_02
Transcript:  Here's the Unity stand for IMAX and Apple displays,  never got that either, they canceled.  So if you buy stuff on Kickstarter,  let the buyer beware, I guess.

Speaker: SPEAKER_03
Transcript:  Well, you got your monies back, right?

Speaker: SPEAKER_02
Transcript:  Not in a lot of cases, no.

Speaker: SPEAKER_03
Transcript:  Oh, if you follow up, you might.

Speaker: SPEAKER_02
Transcript:  No, they don't guarantee that.  I did get my floating bonsai tree, I told you that.  Never gonna use it.

Speaker: SPEAKER_03
Transcript:  You want mine?  Well, let me see, is it an actual bonsai tree?

Speaker: SPEAKER_02
Transcript:  No, you don't get the tree.

Speaker: UNKNOWN
Transcript:  Oh.

Speaker: SPEAKER_02
Transcript:  You just get a piece of lava rock with a magnet in it  and a base and then it floats on the magnet.

Speaker: SPEAKER_01
Transcript:  I've found something I must buy, I must buy it.  What's that?  A floating bonsai tree?  It's right now, a project we love on technology,  interactive LED eyelashes.  Don't you think that'll look good on me?

Speaker: SPEAKER_03
Transcript:  Oh, I actually want those, don't make fun of me.

Speaker: SPEAKER_02
Transcript:  There's a market for every product.  Only reason I didn't buy them is because.

Speaker: SPEAKER_01
Transcript:  There is one more at every minute.

Speaker: SPEAKER_02
Transcript:  They're wired, they work.  What?  You have to have a wire coming out of your head?

Speaker: SPEAKER_03
Transcript:  Well, so the lashes, if they're the ones I'm thinking of  and I don't know how many flashing LED lights,  eyelashes that are out there.

Speaker: SPEAKER_02
Transcript:  It's gotta be the ones.

Speaker: SPEAKER_03
Transcript:  Yeah, those are it.  So you stick the LEDs just like you're applying  false eyelashes on your eyes and then there's a little wire.

Speaker: SPEAKER_01
Transcript:  But of course I know how to do so well, yes.

Speaker: SPEAKER_03
Transcript:  Okay, it's not hard, you just glue.

Speaker: SPEAKER_01
Transcript:  F, oh I like the name, F dot lashes.  The video's amazing.  Flashy.  Yes.

Speaker: SPEAKER_02
Transcript:  Oh, I would order those.  Those are creepy as hell.  I think they'd be amazing.  Oh, that's creepy, it's too bad they're wired.

Speaker: SPEAKER_03
Transcript:  They're tiny wires, but you can see the wire  on the side of the space there.

Speaker: SPEAKER_02
Transcript:  Oh yeah, but you wear them to your rave  or your next acid rift.  No one's gonna see the wire, yeah.  Oh my god.  Dance party.

Speaker: SPEAKER_03
Transcript:  Isn't that awesome?

Speaker: SPEAKER_02
Transcript:  Oh, I wanna look just like him.

Speaker: SPEAKER_03
Transcript:  See, I already have glue in my hair.  Look at that.

Speaker: SPEAKER_02
Transcript:  That's so weird.  If sprockets were allowed today.  Oh, I need these.  How much were they?

Speaker: SPEAKER_03
Transcript:  They were like $40 for the pair.

Speaker: SPEAKER_02
Transcript:  What if I just bought one?  Oh look, there's a little controller  that you put in your pocket.

Speaker: SPEAKER_03
Transcript:  No, it goes in the back of your head.  Again, I have actually researched this.

Speaker: SPEAKER_02
Transcript:  Well, fortunately you just put it under your wig  and it's fine.  This is clearly a drag queen product.  Or Stacey.

Speaker: SPEAKER_03
Transcript:  It's not clearly a drag queen product.  This is for people.  Okay, I'm wearing my wig on the show next to me.  Oh will you please?  You have that wig?  Of course, I have multiple wigs.

Speaker: SPEAKER_02
Transcript:  See, I feel like there's so much about Stacey  we don't really know.  No, it's just.

Speaker: SPEAKER_01
Transcript:  Stacey, wear these when you take your LSD on the show, please.

Speaker: SPEAKER_03
Transcript:  There we go.

Speaker: SPEAKER_01
Transcript:  Man, oh man.

Speaker: SPEAKER_03
Transcript:  I love the concept of this sort of thing.  I would be, you know, like in the Hunger Games,  how they have the capital city people,  I would be one of those people who is dying my skin  crazy stuff and I mean, I dye my hair, but anyway.

Speaker: SPEAKER_02
Transcript:  I'll make you a deal.  If you order them, I'll order them.

Speaker: SPEAKER_03
Transcript:  Oh, but I don't want the wire.  I'm waiting for them to be battery powered.  Because I don't want to wear them to the rave.  I want to wear them out to a night out.

Speaker: SPEAKER_02
Transcript:  There's a Knight Rider one.  Now what I want is a little speaker.  I could play that Spotify speaker  and have the Knight Rider theme going  while my eyes are going back and forth.  There you go.  And I'll say, just call me Kit.  All right, we're going to wrap this up.  I think we've done more.

Speaker: SPEAKER_01
Transcript:  Man, would you buy wet sleeve?  Huh?  What are you wearing?

Speaker: SPEAKER_02
Transcript:  There was wet sleeve.  No, no, no, stop.  I already, I just bought the lashes, please.  I've had enough.  You really did.  Oh yeah, absolutely.

Speaker: SPEAKER_01
Transcript:  There's a liquid plastic welder.

Speaker: SPEAKER_02
Transcript:  No, stop it.  Welding tool.  You know I'm going to order it.

Speaker: SPEAKER_01
Transcript:  Stop it.  Sonnet, world's most advanced off-grid mobile machine.  Stop it.

Speaker: SPEAKER_03
Transcript:  This makes for a great gift right here.

Speaker: SPEAKER_02
Transcript:  Ladies and gentlemen, we do this week at Google  every Wednesday, 1.30 Pacific, 4.30 Eastern,  20.30 UTC with Stacey Higginbotham of Stacey on IoT.  IOTpodcast.com for the podcast,  at Gigastacey on Twitter.  Thank you, Stacey.  Always a pleasure.  Always a pleasure.  Oh, somebody's at your door.

Speaker: SPEAKER_03
Transcript:  I was about to say, yes.  If my show was right here, I could see.

Speaker: SPEAKER_02
Transcript:  Time for the pizza.  We also have a fabulous time with Jeff Jarvis every week.  He is at CUNY and there are some very lucky journalism  students who get to work with him.  Does school, when does school start?

Speaker: SPEAKER_01
Transcript:  August.  You get to brainwash then.

Speaker: SPEAKER_02
Transcript:  How fun.  We will also see him at buzzmachine.com,  his blog, he writes on Medium frequently.  Sometimes on politico.eu.  I like the response from Axel Springer to your post  on the politico.eu.  The fight is on.

Speaker: SPEAKER_01
Transcript:  He never much liked that Jarvis.

Speaker: SPEAKER_02
Transcript:  Yeah, didn't like him and don't like him now.  We do this show as, oh, I already did that part.  You can get a copy of it at twitter.tv slash twig.  You can also get it if you subscribe  in your favorite podcast appliance.  Please do.  We want you to be here for each and every episode.  Thanks for joining us.  And I will see you next time on This Week in Google.  Bye bye.

