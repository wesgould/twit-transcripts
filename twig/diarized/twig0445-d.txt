;FFMETADATA1
title=The Mortician's Wife
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=445
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Speaker: SPEAKER_02
Transcript:  It's time for Twig this week in Google. We have a really packed show. Kevin Tofel is  back from the IoT podcast. He's filling in for Stacey Higginbotham, Jeff Jarvis, of course,  and Joan Donovan from Data and Society. We're going to talk about the troll factories. We're  going to talk about Twitter. What was the hot Twitter hashtag? Twitter lockout. What  that all means. We've got a big story in the New York Times saying Google has gotten too  big and needs to be broken up. We'll talk about all that and a whole lot more next on Twig.  Netcasts you love. From people you trust. This is Twig. Bandwidth for this week in  Google is provided by Cashfly. C-A-C-H-E-F-L-Y dot com. This is Twig this week in Google. Episode  445 recorded Wednesday, February 21st, 2018. The Mortician's Wife. This week in Google is  brought to you by WordPress. Make WordPress.com your online home. Plans start at just $4 a month.  Go to WordPress.com slash Twig to get 15% off your brand new website today. And buy Rocket  Mortgage from Quicken Loans. Home plays a big role in your life. That's why Quicken Loans created  Rocket Mortgage. It lets you apply simply and understand the entire mortgage process fully  so you can be confident you're getting the right mortgage for you. Get started at  RocketMortgage.com slash Twig. It's time for Twig this week in Google, a show where we cover  the latest news from the Googleverse. That's Facebook, Twitter, the media, everything,  anything. Jeff Jarvis is here, professor of journalism at the City University of New York,  author of What Would Google Do? Public Parts, etc., etc. Hello, Jeff. Hey, how are you? I'm  great. You're in the country for two days in a row. I am. Yeah. Amazing. Yeah. Well, there comes  the cat. Yay. Yay, kitty cat. Hey, I'm really we've got Stacy's in Berlin. So we have decided to take  her place with not one but two great panelists. To my right, Kevin Tofel, Kevin C. Tofel of giga  ohm fame for years. We couldn't talk to him because he was at Google briefly doing marketing. He's of  course, Stacy's partner on Stacy on IOT. Hello, Kevin. Hey, hey, it's good to be back after all

Speaker: SPEAKER_00
Transcript:  this time. What have you been doing? We miss you. Lots of Netflix, Nintendo Switch. Listen to The Beatles, of course.  Absolutely. Absolutely. Yeah. So yeah, I was over at Google for about 18 months, but had to deal  with some health issues last summer, which, oh, I'm sorry, maybe focus on on, you know, myself for a  little bit and some kind of chilling out and relaxing and now working with Stacy and enjoying life.

Speaker: SPEAKER_02
Transcript:  You couldn't pick a better partner and you guys do a really good job on that IOT podcast. It's really  good. Appreciate that. And we are welcoming back and boy, it couldn't be more timely. From data and  society, Joan Donovan. Great to see you, Joan. Oh, she is responsible for reputation and media and fake  news. You you are in the hot seat right now at data and society.

Speaker: SPEAKER_03
Transcript:  Yeah, it's been quite a week of troll hunting, I have to say. It's been overwhelming.

Speaker: SPEAKER_02
Transcript:  Was it an 18 alarm fire when the indictment came out last week?

Speaker: SPEAKER_03
Transcript:  There's been that and then conspiracy after conspiracy about Parkland and then Twitter purge or what are  they calling it? Twitter lockout last night.  Twitter lockout.  We're going to talk about that.

Speaker: SPEAKER_02
Transcript:  Yeah.

Speaker: SPEAKER_03
Transcript:  Weep of the bots and so really trying to understand how all of these things relate to one another.

Speaker: SPEAKER_02
Transcript:  So after Parkland, we're told the Russian trolls came out in force almost minutes later. And is it  primarily Twitter? Do they still use Facebook?

Speaker: SPEAKER_03
Transcript:  There I you know, it feels like they're everywhere. But it's interesting because it's like Nats, right?  They're just a swarm of flies. You can't really measure the impact of what it is that they do.  But they do tend to intervene in debates that are highly polarized already and then share specific kinds  of accounts and conspiracy theories to confuse the narrative.  And so it's been a busy, busy week trying to map that online, but then also trying to understand, is it  really having an impact on the way that we're debating these issues or is it noise? Right?  I mean, we're constantly trying to understand signal.

Speaker: SPEAKER_01
Transcript:  What's your view, Joan? What's your view about that?  Rasmus Nielsen at Oxford Institute has been posting stuff questioning how impactful it is.  What do you think?

Speaker: SPEAKER_03
Transcript:  From my point of view, it's interesting in the sense that the amplification effect when they're retweeting  known celebrity accounts or known provocateurs accounts, they do tend to spread the disinformation much further.  But, you know, we don't have anyone really studying the impact of this on people's lives.  And if they're even reading what is being shared, right, lots and lots of things get shared on social media that no one ever really reads.  They might glance at it and roll their eyes and keep moving.  So we don't know the impact it's going to have on shared reality or public understanding.  And the other part of this is the media, right?

Speaker: SPEAKER_01
Transcript:  You know, the data society has been arguing for strategic silence.  And there was a case today, of course, where the survivors of the terrorist attack in Parkland, let's call them that, were being accused of being  actors. And that's the kind of thing you want to just not give it more air.  But when the president's son tweets it, then you've got to go on TV.  So Ali Velshi and Stephanie Rule today on MSNBC did a great debunking end to end, but it also gave it more air, right?

Speaker: SPEAKER_02
Transcript:  Why? What is to what?  So, first of all, I want to correct because I imply that you're in charge of fake news.  You're not actually in charge.  It's all Joe's fault.  If you were, it would make it much easier.  But in fact, you study media manipulation and you're the research lead for platform accountability at data and society, which means you're an expert on fake news and media manipulation.

Speaker: SPEAKER_03
Transcript:  Yes. And we have a report that came out today that we are calling Dead Reckoning Navigating Content Moderation After Fake News, because whatever interventions we  pose on fake news or or on what are these conspiracy channel news is going to affect the nature of all content online.  And so one of the things that we've been talking about is this notion of strategic silence, which is when should you and when should you not amplify stories?  And so when we see the crisis actor conspiracy taking hold in places like Twitter, on the one hand, if you fan the flames, that's exactly the kind of attention they're looking for.  But also because David is it last name is Hogg or Hogg?  Oh, no.

Speaker: SPEAKER_01
Transcript:  Two G's. I guess it's Hogg.

Speaker: SPEAKER_03
Transcript:  Yeah. So David's way of presenting himself has been extremely poised in the media.  And that's what makes that's what makes him as a survivor a very, very powerful advocate for gun reform in America.  And that is very, very scary to certain conservatives.

Speaker: SPEAKER_02
Transcript:  And, you know, we should point out he's one of the survivors of this.

Speaker: SPEAKER_03
Transcript:  And he's the one that's being charged with being a crisis actor.

Speaker: SPEAKER_02
Transcript:  Oh, they say this guy's an actor.

Speaker: SPEAKER_01
Transcript:  Yeah, because they argue that because he used to live in California.  So they say, see, he doesn't even go to that school.  Oh, my God.  Meanwhile, this is this is the amazing, amazing young man who, while they were locked up in classrooms, was interviewing his classmates.

Speaker: SPEAKER_02
Transcript:  That's a little weird, but OK.  Well, he was well, he has a lot of stuff.

Speaker: SPEAKER_00
Transcript:  He's a journalist.

Speaker: SPEAKER_03
Transcript:  He knew that conspiracy was coming, you know, and so he was really doing due diligence.

Speaker: SPEAKER_02
Transcript:  Yeah, there are, of course, immediately people saying it's a false flag that there is was no shooting, things like that.  So normally that stuff, I mean, you know, this has been not just in the Twitter era or the Internet era, but always.  And normally you just ignore this stuff.  And frankly, I guess the first thing I'd say is why does Twitter?  I mean, is it just the media that pays attention to Twitter?  Twitter only has, you know, a 300 million active users.  I think the vast majority of Americans that are not on Twitter.

Speaker: SPEAKER_03
Transcript:  So this was also being shared on Facebook and through YouTube.  And you think that every wars and the Gateway Pundit.

Speaker: SPEAKER_02
Transcript:  So all these people in aggregate reach a majority of Americans, you think?

Speaker: SPEAKER_03
Transcript:  No, definitely not.  I think what happens is, is you have this narrative of a crisis actor that starts probably before Sandy Hook.  But that's the first time that I've heard of it.  I remember hearing.  And then it gets replayed through every mass shooting.  And so you no longer have to explain generally what you mean when you're talking about the crisis, the conspiracy theory of the crisis actor.  Now, what you have to combat is debunking these stories if you need to debunk them.  And then also, I think that right now, those students that are survivors that are turning into advocates and organizers are really under attack.  And showing the media, showing as well as public support, showing through Twitter that they believe those students and that they believe in their cause is one way to combat some of this disinformation.  And I think it's really important for people to stand up and say that they believe these students because these students are not calling for radical gun reform.  It's very, very.

Speaker: SPEAKER_02
Transcript:  I want to set aside the politics of it because this is a technology show.  But what's interesting to us as a technology show is what is the Internet's responsibility?  What are these companies responsibilities?  What is the power of the Internet?  And so, but I gather it's enough to plant the seed and then all some, you know, I just imagine a small town where there's a couple of people who, you know, they're on the Internet, they see that.  Then they go to the coffee shop and they tell people in the coffee shop, you know, that guy was a crisis actor and that it spreads that way.  It spreads beyond the Internet to the majority of people not using technology, I would assume.

Speaker: SPEAKER_03
Transcript:  Yeah, it does. And it's and it's a provocative story to tell.  But what is dangerous about that?

Speaker: SPEAKER_02
Transcript:  We love these kinds of conspiracy theories.

Speaker: SPEAKER_03
Transcript:  Oh, it's true. But this kid is a teenager and his real name is being used and he's being smeared all over the Internet.  So now when you search for him, not only do you get his name and his likeness, but you also get these conspiracy theories that are disinformation about him, which constitutes harassment.  And so the videos that are popping up on YouTube and being shared through Facebook and being shared through Twitter are a kind of networked harassment that will plague him until we come up with some kind of regulatory framework that will.  Allow him to get his name back.

Speaker: SPEAKER_02
Transcript:  Welcome to the Internet.

Speaker: SPEAKER_00
Transcript:  I actually have a question.  I don't disagree with anything you just said, Joan, but you mentioned how his his real name is out there and he's a teenager.  Does he put his own videos out on YouTube?  Like, has he prior put his name out there?  I'm thinking he has.

Speaker: SPEAKER_03
Transcript:  To be honest with you, I don't know.  I haven't investigated in his own social media.  But teenagers, the way that they use social media, of course, they do have a public presence.  And as we grow older, of course, things happen and things get tied to our names.  But the fact that there's no remedy for this and there's no pushback and that there's no formal process that this teenager can go through in order to get his name and reputation back, I think is I think it's important that we start to think about what is the lifelong effects that he's going to suffer.

Speaker: SPEAKER_02
Transcript:  Well, I agree.  But what would be the mechanism of that?  I don't see any.  I mean, that's the right to be forgotten.

Speaker: SPEAKER_01
Transcript:  That's the right to be forgotten.  But ironically, hearing you and Joan talk about this, the right to be forgotten is about taking down facts about you that you don't like.  This is about taking down lies.  I don't know how you would do this.

Speaker: SPEAKER_02
Transcript:  I don't know. I don't know either how it would even begin.  I mean, we all I mean, look, it's worse, of course, as a 17 year old.  But it happens all the time on the Internet that people are a tard with a brush that and are stained in a way that there's no way to fix it.  That happens all the time.  And there's a risk business and reputation defenders and things like that that are completely worthless.

Speaker: SPEAKER_01
Transcript:  The argument that I made and I think this is why it's a very big story today.  Put three things together here.  The argument I made about this with Google in the spring after the election was that you're being manipulated.  You have to understand the manipulation, measure it, be transparent about it and counteract it.  And so when Google announced they were going to account for the reliability, authority and quality of sources in search ranking, that was them doing that.  Now you have Facebook that is also trying to say we're going to throw out all this public stuff, get in trouble and just bring back the quality stuff.  And now today you have Twitter, which we'll get topic we'll get to in a few minutes, doing a block out of Russian bots.  So all three of the platforms are beginning to make decisions about quality and credibility.

Speaker: SPEAKER_02
Transcript:  Is it naive of me to say that really the burden is on in us as people to just not believe this crap?

Speaker: SPEAKER_01
Transcript:  If we can give people more signals that enable them to make that decision well, which which is where I believe that I would guess they're well predisposed towards it.

Speaker: SPEAKER_02
Transcript:  It's not that it's like if you if I if I told you, oh, you know, that guy's an actor, nobody was shot in Parkland.  A normal person would say, get out of here. You're nuts. Right. Right.

Speaker: SPEAKER_01
Transcript:  This is where the lack of trust in media goes. Sorry, John.

Speaker: SPEAKER_03
Transcript:  Yeah, no, I agree that there's a lack of trust, but also you are hosting content that is harassing someone.  Right. And we don't all get away with that.  And so there has to be a new way of thinking about disinformation in particular because of the way that it's being used against platforms and to spread information that is not it's what's what's difficult about conspiracy theories.  If there's no falsifiability, there is no evidence.  You can't prove the negative.  Yeah, that's always been the problem.

Speaker: SPEAKER_02
Transcript:  That's life.  Yes.

Speaker: SPEAKER_03
Transcript:  So in these situations, when you know that you have hundreds of hours of content accumulating in your platform and you know that this this teenager is being harassed and he's being harassed because you are providing the distribution system in the archive for this content, then, you know, maybe he becomes the first person to sue one of these platforms for digital harms.

Speaker: SPEAKER_01
Transcript:  Well, the case of Google, when YouTube is one matter, but Google search, it's not really wouldn't be the platform.  It would be the originating site, but where it's come from, Google will argue strenuously that you should be able to find anything, including bad stuff.  If you want to say who is out there saying the Holocaust is a hoax, you should be able to find that.  Now, if you ask, is the Holocaust real?  You shouldn't find them.  But if you want to find the bad actors, Google will say you should still be able to find them because that's part of their job so that you can do your work, Joan.

Speaker: SPEAKER_03
Transcript:  Yeah, I understand.  But I do not like being a wash in disinformation.  And I know that when it's targeting a specific person, that that is a solvable and bounded problem.  Right.  And so the the the evidence is in the metadata.  And these platform companies do know who's uploading this content.  They do know where it's being linked to.  And they do have systems in place to deal with these issues, especially when it has to do with the network harassment of an individual.  And ultimately, this kind of harassment will not stop.  This will go on for years.

Speaker: SPEAKER_02
Transcript:  It's going to go on for this is trolls be trolling.  This is trolls be trolling.  I feel bad for David.  Absolutely.  And he's you know, he's on the side of the angels doing the right thing.  And it's a sad thing.  But that's what happens nowadays.

Speaker: SPEAKER_03
Transcript:  But it's not that we can't think about another Internet or another way of interfacing with the Internet and these platform companies.

Speaker: SPEAKER_02
Transcript:  Well, I'm open to the idea.  But what would you propose?

Speaker: SPEAKER_03
Transcript:  Well, I don't work there.

Speaker: SPEAKER_02
Transcript:  But if they want to, I mean, really, though, I think this is a challenging thing.  I mean, we've we've, you know, railed against the right to be forgotten.  The Internet. I mean, look, I hate trolls as much as anybody.  I've been trolled for a long time.  It's but trolls be trolling.  What are you going to do about it?  I don't know how you stop it.

Speaker: SPEAKER_03
Transcript:  This is this is a problem.  If we believe that the trolls own the Internet and that anyone should be able to do whatever they want to do at any moment,  what's what's going to end up happening is that you are going to continue to accumulate so much garbage that YouTube is going to become landfill.

Speaker: SPEAKER_02
Transcript:  It's true. I mean, this is any any public network.  If you don't maintain it, we for instance, we have many, many mods in our chat room and lots of technical tools to prevent trolling in our chat room.  And you have to be on it constantly to prevent that.

Speaker: SPEAKER_01
Transcript:  Well, so I think you're both headed to maybe a new standard here.  The right to be forgotten again is a different thing because that's about erasing or rewriting history.  This is about Joan. What Joan said is you're getting rid of harassment and you with your mods are getting rid of harassment.  So part, you know, Twitter has a very low bar standard right now, which is child porn and such.  Right. And Twitter, I think, is showing that they want to raise that bar.  So the question is, where's the bar?  And and and there have been many complaints that women particularly get harassed and threatened on Twitter.  If harassment and threatening no longer is is acceptable behavior on Twitter.  Is that a good standard?  And is that something that's doable?

Speaker: SPEAKER_02
Transcript:  Is harassment in the eye of the beholder?  Well, that's the question.  If somebody responds to a presidential tweet saying you're a nitwit, is that harassment?  Is he is that person blocked on Twitter?

Speaker: SPEAKER_03
Transcript:  Well, I think that in some instances, Twitter has allowed for bad behavior from people that are of a certain status or of a certain distinction.  Here we have a unique case that we can look at and say, here's a minor and this is someone that we should strive to protect.  I agree. This is someone's reputation that we should that we should create a terms of service around.  That there should be a process for making these appeals and there should be rapid attention to these disinformation campaigns, because part of them, you know, if you live in this world like me and my research team do, there are so many that don't hit this strongly.  There's probably hundreds of Parkland conspiracy theories out there.  Right. There's only a few that have been picked up and amplified.

Speaker: SPEAKER_02
Transcript:  So pick the most damaging ones.  And actually, I think a very good job has been done to refute the conspiracy theory about Hogg.  Mm hmm.  Right. But if I search for David Hogg now on Twitter, I mean, on Google, all I find is articles saying he's not a crisis actor.

Speaker: SPEAKER_01
Transcript:  That's not if you're if you're people who don't believe media, the reputation doesn't matter.  The Twitter fact checking flag, in fact, drove more traffic to those things.  They fact check false.  Yeah, the Facebook.

Speaker: SPEAKER_00
Transcript:  That's actually the problem.  This is partly a technology problem and partly just a human problem.  Just the other day, folks in the chat room noticed it to CNN, went back to a Trump supporters house and said, look, it's been found that you were actually interfacing with Russian trolls, known trolls.  We found this out.  You were organizing events with them and so on and so forth.  This person was like, no, that's all BS.  No, no, no.  I don't believe you.

Speaker: SPEAKER_02
Transcript:  You're you're fake news.  Yeah, exactly.  It's a very good piece to be shown.

Speaker: SPEAKER_00
Transcript:  And that's the other half of it.  So how do you fix that?  You can't with technology.

Speaker: SPEAKER_01
Transcript:  We have to recognize that the Internet is Times Square.  You know, I had an editor today on Twitter said, well, we should be editing everything.  You can't.  It's it's it's an open conversation.  So we've got to create.  I don't want to go to an elitist hierarchy.  I don't want to go to a paywall quality world, but I don't want to imagine that,  that, you know, if we just train people, things, OK, we got a big trust issue to deal with.  And journalism has a huge trust problem.  But at some point, if you recognize that it's Times Square, you're not going to listen  to everybody on Times Square and think that they're right about everything.  You're going to have some mechanism to judge.

Speaker: SPEAKER_03
Transcript:  And the other the other point that we should make is that these are known information  pathways where there are content creators that make and monetize this content,  knowing full well that it is false.  Sometimes they'll slap a this is satire on it, on the content to make it something  that cannot be flagged and taken down.  And so they know what they're doing and they know why they're doing it and their  economic incentives for it.  And so it's not just true believers that are doing it because they're creating user  generated content. These are these are content creators and, you know, quote unquote,  media organizations that are making money off of this.

Speaker: SPEAKER_02
Transcript:  Yeah, I like your dead reckoning.  This is opposed to data and society where really what you're saying, you're urging the  platforms to to well, news platforms to ignore this sort of not to to not spread, not

Speaker: SPEAKER_01
Transcript:  spread it by unless it's passed over a line where you kind of have to write down.

Speaker: SPEAKER_03
Transcript:  Yeah. And one of the findings from this report is that what we're seeing on these  platform companies is that we're at a moment where every action or every direction  forward seems impossible.  And so it doesn't surprise me to hear that you're like, how would we ever solve  something? And I think that my approach or the approach we should take is reason  in terms of service, but then also looking at case by case, does this information  need to come offline?  And can you create a process by which people can make those appeals and those  appeals become transparent?

Speaker: SPEAKER_02
Transcript:  But there there has always been I mean, Jeff and I are old enough to remember  mainstream media.  There was always a maybe you do, Kevin.  There was always I mean, you didn't say the names of minors.  I mean, there were always you talk about suicide.  There are understood rules that just were I mean, I hate to use the phrase, but they  were gentleman's agreements.  You know, I agree with you.

Speaker: SPEAKER_03
Transcript:  Those are called standards.

Speaker: SPEAKER_02
Transcript:  Standards. There's the better word.  There were standards and there were even there used to be in the networks whole  departments called standards and practices that would enforce those standards.  And that was a good thing.  But we don't live in a world of mainstream media anymore.  And no, we don't.  Even the mainstream media is not behaving like the mainstream media.

Speaker: SPEAKER_03
Transcript:  But the problem with broadcast that we've really failed to reckon with is, you know,  that this there is an incentive to create this content because it makes money.  There's an incentive to create this content because it creates political

Speaker: SPEAKER_02
Transcript:  opportunities. And you've got a 24 hour news cycle.  You got to fill it. Yeah.

Speaker: SPEAKER_01
Transcript:  And we have an ethic that says openness, openness.  I mean, after I just found this clip after Robin Williams death, there was a 10  percent spike in suicides.

Speaker: SPEAKER_02
Transcript:  Yeah. So you don't say it right.

Speaker: SPEAKER_03
Transcript:  Yeah. And that's part of the knowing what to amplify and what not to amplify and  what are the public health benefits of amplifying certain information.

Speaker: SPEAKER_02
Transcript:  But I'm kind of with Kevin that it's also that the human problem is pretty big here.  I don't I think it's it's kind of to blame it to say, well, it's all up to you  platforms because because we're just too stupid.

Speaker: SPEAKER_03
Transcript:  Yeah. Well, this is the other intervention that these platforms are coming up with.  Is that they're a third party fact checking organizations as well as media  literacy organizations that are under resourced and they don't have enough  personnel to deal with the scale of the problem and implement sort of national  digital literacy program that would cover a lot of what it means to debunk and read  news critically these days.

Speaker: SPEAKER_02
Transcript:  Is it a bigger problem bigger than it used to be?

Speaker: SPEAKER_03
Transcript:  Like, I would say, yes, because well, it has to be because I have a job now.  Right. And we have a team and we have lots of very smart people across the world  working on these issues in every country.  And it isn't just political disinformation.  It isn't just foreign spies.  There are real incentives to use the broadcast capacity of the Internet, which  as an infrastructure has rapidly scaled without any regulation.  It used to be that you, you know, I mean, you remember the days of downloading a JPEG,  right? Right.  And it would sometimes take five minutes to get a picture.  And so as it's become easier to transfer data and we've been we've moved into this  mobile web moment, we haven't thought about what are the educational campaigns and the  necessary tools that we all will need to be able to be critical.  It's happened so fast.

Speaker: SPEAKER_02
Transcript:  But let me let me also argue just not prepared for it.

Speaker: SPEAKER_01
Transcript:  Sorry. I'm doing research now on kind of look at the post mass world.  And so I'm reading a lot of stuff.  I just reread Moosing Ourselves to Death and other things about 1960 to 1990.  You know, so the TV is huge.

Speaker: SPEAKER_02
Transcript:  What's the people like postman saw this coming, though?

Speaker: SPEAKER_01
Transcript:  Well, but they said it about TV.  Right. Right. And they decried television.  They decried what was going to happen.  If you look at about 1960 after, you know, less than a decade of very popular television  under our belt, there's a huge panic that goes on around then.  And I think mass media has empowered this, but we burned witches in the 1600s, too.  Yeah, exactly. And I think that, you know, the problem, Joan, that I have with this notion  media literacy and I get in trouble for this, but it's media centric.  It's a little paternalistic to say if you just read all of our media and if you understood  how to do our media, then everything be OK.  Maybe there's something wrong with our media.  And we got started there.  And then we have more respect to the public.  You listen to these Margaret Sullivan's column this week about the teenagers in  Parkland is really wonderful.  You hear the narrative is, oh, teenagers are all apathetic and they're all illiterate  and they can't spell and they can't speak.  The teenagers of Parkland disabuse every such notion.  And what made them this way?  What made them savvy?

Speaker: SPEAKER_02
Transcript:  The Internet did, by the way, right on the front of that article, a video of David Hogg.  Yeah, I admire these students because they as much as anybody knew, he knew that  come that be becoming the public face of this would expose him to this.  Maybe he didn't, but I would.

Speaker: SPEAKER_01
Transcript:  He's being very mature about it.  I heard him today on TV saying about all this hoax about him.  He said, well, it did a job for me.  It doubled my followers today.  Yeah. Yeah.

Speaker: SPEAKER_03
Transcript:  So I just point about mass media.  I think that we also have to, you know, remember that we learned how to watch TV  War of the Worlds.  We learned how to listen to the radio.  That's right. There's a format to it.  And, you know, one of the Jesse Daniels, who's a researcher that wrote the book  Cyber Racism, has a really beautiful earlier paper for maybe 10 years about using a  usability study where she looked at how students learn to read the Web.  And she was looking at these websites called cloaked websites.  So back 10 years ago, if you search for Martin Luther King, you actually got a white  nationalist website that had bought the domain and then was serving disinformation  about Martin Luther King.  And so students were taught to read into the infrastructure of the website, into the  way that the content was presented.  And in doing so, they they were able to assess the quality of the news and the  quality of the presentation in these websites and make an assessment of them.  And so part of the way that we're doing media right now, though, is we have these  generalized templates.  Everything starts to look the same.  And so it's very difficult to tell the difference between legitimate news and  what are these like incentivized, monetized news outlets?

Speaker: SPEAKER_01
Transcript:  Same is true in the news outlets themselves.  I mean, our business model drives us to clickbait, drives us to polarization.  We in media have not been nearly honest enough with ourselves about our  responsibility in all of this.

Speaker: SPEAKER_00
Transcript:  Mm hmm.

Speaker: SPEAKER_01
Transcript:  Well, what are some of the main recommendations that your report makes,  Joan?

Speaker: SPEAKER_03
Transcript:  In terms of what we're what we're trying to understand here is that the report  really does an overall assessment of these these credibility indicators, as  well as looking at what does it mean to disincentivize or to ban content or to  remove content from your platform.  And, you know, there are there are really mixed feelings about this in the sense  that there are edge cases that get caught up in banning content.  If you're banning all content that has to do with, you know, war or political  speech, obviously that's a problem.  But what we know is lots of disinformation flows in these content in this content  specifically.  And so it's it's a it's a fraught problem that the platform companies have,  especially YouTube, has done a lot of work to demonetize certain accounts.  And then, of course, you know that Facebook has changed the way that they  serve information in the newsfeed.  And so I think we're seeing a lot of experiments and time will tell as we  move on what this, you know, Twitter attack on the bots situation will also  do to improve the information quality online.  But for us, we talk about that now.

Speaker: SPEAKER_01
Transcript:  Yeah, I'm eager to talk about that, too.

Speaker: SPEAKER_03
Transcript:  Yeah. Improving the information quality is is something that's it's time has  come. And then also to think about what is the editorial and the curatorial  strategies that these trending algorithms are going to make that pick the content  that you should look at.

Speaker: SPEAKER_01
Transcript:  So did I woke up this morning and I saw the I saw a Twitter lockout going crazy  and I looked up the hashtag and it was it was amazing reading with people that had  been followed by thousands of bots suddenly saying I have fewer followers.  And it was on the right.  I didn't lose any followers.  I don't know if you guys did.  Russian bots don't like me.  I guess I don't know.  And and it was really, I think, an important moment for us to be able to  moment where Twitter decided to make a stand here.  What did you guys think?

Speaker: SPEAKER_02
Transcript:  Well, just plays right into the narrative of those people who believe in the  conspiracy theories and the left wing media and left wing Silicon Valley.  And it just plays what I do.  Leave the bots. I don't know what you do.  I feel like I just you know, I don't my problem is I don't understand the  mentality of people like Dinesh D'Souza who, you know, I don't understand how  people I don't understand why are people confused about this?  And I think that's part of the problem we have.  And maybe we could thank Russian bots for that.  I don't know. Is that we're so polarized at this point that there is there is kind  of a gulf, a massive gulf.  Forget the generation gap.  We have a gap of massive proportions.  Reality.  A reality.

Speaker: SPEAKER_03
Transcript:  Did you see the New York Times article from about two weeks ago called The  Follower Factory, which really went through how bots are sold to influencers and  celebrities?  We talked a lot about it.

Speaker: SPEAKER_02
Transcript:  It's fascinating.  Yeah.

Speaker: SPEAKER_03
Transcript:  Yeah.  And so this is another iteration of that, which is that sometimes these aren't  just what they call, quote unquote, suspicious automated activity, but that  there are groups of people that are coordinating these accounts that are  acting as a kind of flock.  And so if you were to imagine a social media as a territory and the social graph  is something that these bots can really push content from one quadrant to  another.  Right.  And so it isn't just about intervening on and staying within the neighborhood of  conservatives on the social graph.  It's about pushing that kind of content into another vector and sometimes  trolling other partisan groups or creating highly polarized debate.

Speaker: SPEAKER_02
Transcript:  Did Twitter just kill a bunch of bots?  I mean, they didn't pay attention to who they were following.

Speaker: SPEAKER_01
Transcript:  They know that they also they did.  They killed bots and then they also apparently, I think accounts that seemed  to have suspicious behavior, they made them verify with phone numbers.  Okay.  Right.  Okay.  Yes.

Speaker: SPEAKER_03
Transcript:  So verification by phone number is something that will also allow them to see  if you were running two, three, 10 different accounts.

Speaker: SPEAKER_02
Transcript:  So when Richard Spencer says I lost a thousand followers in the past few hours,  it's not because the Twitter's targeting Richard Spencer's followers.  It's just that he has a lot of these bots following him because that's the job of  these of the internet research agency and these other bot factories is to amplify  these voices.  What I find interesting is also that what is their agenda?  Like why did the Russian bots leap in in Parkland?  Is it because they don't want gun control or is it as I would imagine more likely  because they want strife period?

Speaker: SPEAKER_03
Transcript:  Yeah, I would agree with you that strife is part of it and part of it is making it  seem that the terms of the debate are so unreasonable that you are so far apart on  this that it can't possibly be reconciled.

Speaker: SPEAKER_02
Transcript:  And so what I was just talking about that golf.  In other words, I've been influenced by that.

Speaker: SPEAKER_03
Transcript:  Yeah.  And the other thing that's difficult about this is they've been around before the  election and they've been influencing other social movement groups.

Speaker: SPEAKER_02
Transcript:  According to the indictments since 2014, but I think probably forever.  I mean, I don't think.

Speaker: SPEAKER_03
Transcript:  Yeah, but that's that's another problem of degree.  So Adrian Chen had an investigative report in 2015 where he went to the Internet  Research Agency and basically said that it was a small time operation.  But it doesn't mean that this operation hasn't grown since then.  And because we lack the ability to assess the impact and researchers, it's very  frustrating in the sense that you find out about these things generally after the  content has been deleted and we don't have access to the deleted information.  There was a cache of Russian tweets that were released this week.  I think about 200,000 tweets that people are able to do a social autopsy on.  But generally speaking, outside auditing is impossible.  And so it's been a difficult moment to assess and evaluate impact, to say if it's  anything at all or if part of the troll itself, which is what I suspect is getting  the American public to think that Russia has a much more in, has much more impact  on American politics than they do.  I mean, this is this is another tactic, which is if you can fan the flames of discontent  in the mainstream media, it's just as good as doing it.  Or it's actually much better than doing it online because the audience is so much bigger.

Speaker: SPEAKER_02
Transcript:  So impressed now.  But see, the bots, that's the bots doing their job, right?

Speaker: SPEAKER_03
Transcript:  Yeah.  And the other thing is, is, you know, it's really suspect to me that people were able  to go back to the IRA and they're still in the same building.  And, you know, like, wouldn't you just like move your office if you are a cause of  international investigation and indictments, right?  Like what, why do these people go back to work?

Speaker: SPEAKER_01
Transcript:  Pays well.

Speaker: SPEAKER_03
Transcript:  I don't think it does.

Speaker: SPEAKER_01
Transcript:  No, I've seen stories that say that relatively it pays well.

Speaker: SPEAKER_03
Transcript:  OK, relatively, but it's still to me, the whole thing feels orchestrated.  But also they they've created such incitement around bots that it's been interesting to  see the relationship of bots to known disinformation, disinformation artists  online. And so watching people respond in this Twitter lockout has been really  interesting to me because I've also seen several people that I follow having lost  quite a bit of followers that are would be considered leftist.  And so that to me has been interesting to think about in terms of what is that?

Speaker: SPEAKER_01
Transcript:  What is that? Is that the Bernie effect?  The what the indictment said was that they tried to benefit both Trump and Bernie.  Sanders. Yeah.

Speaker: SPEAKER_03
Transcript:  And so and I think part of it is, is that some of the people that you follow or that I  follow are would be considered, quote unquote, hyperpartisan.  That is, or they're non-voters in the sense that they are so left of left that the  system cannot survive.

Speaker: SPEAKER_02
Transcript:  However, if you really want to visit the upside down, just read the hashtag Twitter

Speaker: SPEAKER_01
Transcript:  lockout. Oh, yeah, it's pick out some some random accounts in there.  OK. Do we know how many do we know whether Trump lost followers today?

Speaker: SPEAKER_02
Transcript:  Oh, that's interesting. I have not been paying.

Speaker: SPEAKER_01
Transcript:  I couldn't find a service to know where to see a lot of people.

Speaker: SPEAKER_02
Transcript:  A lot of people are saying, just follow me if you got kicked off as if these aren't  bots that have been kicked off.  Yeah. Project Veritas added again, of course, saying, you know, with fake videos  asserting that Twitter engineers are working to ban right wingers.  Here's the famous Ben Garrison.  Big Bird Brothers watching you trying to mute somebody wearing a Make America Great  Hat shadow band.  So but but I don't know, what do you tell people who say, no, no, those aren't bots.  You're banning conservative thinkers and tweeters.  And, you know, I mean, that's this is clearly what these people think.

Speaker: SPEAKER_03
Transcript:  In that, I mean, we don't know what signals Twitter is using in order to understand  what is an automated account and what is not one of the signals that has been used in  the past is related to does this account only do retweets and do they have an  authentic voice?  Do they tend to post at the same time using the same exact tweet as a as a group of  other accounts? So that would indicate a kind of net that's being controlled by a  single individual.  Another way that I've heard, but I cannot confirm in any way a signal that they look  for is related to does this account click with a mouse, which is something that can  be tracked. And so if the account isn't clicking with a mouse, then it might be  automated and coming from other places.  Or is the account using a service, a social media service to broadcast the same  information between Twitter and Instagram and and other platforms?  And so they have a mishmash of signals that they look to in order to talk about which  accounts are bots.  And then the other thing that I think serves them over time is that you get the same  network effects related to certain stories.  And so the same groups of people that are promoting the crisis actor narrative here  have been creating or promoting crisis actor narratives in the past.  And you can analyze those accounts and look at those networks and then look at those  other signals to see if they're automated or only doing retweets and assess from  there. And so I think that Twitter knew roundly what they were doing.  And we're looking at many signals to assess if something was a bot.  But also, you know, back to this is a socio-technical problem.  Bots are controlled by people.  And so that just means the difference between me having one account and me having

Speaker: SPEAKER_02
Transcript:  10,000. I don't know why anybody pays any attention to Twitter at all, to be honest

Speaker: SPEAKER_01
Transcript:  with you. It's it's well, but no, but here's the thing, Leo.  It's what I've said about Facebook, too.  The problem is you go through your feed and I go through my feed.  Joan has a job looking at this crap.  But we don't. And I don't see Russians.  I don't see bots. I don't see Nazis.  I see people I like and respect.  And the problem is we still this media mindset that says if one if one page is  schmutz, that there's a bad word somewhere on the Internet, the entire Internet is  ruined. All of Facebook is ruined.  All of Twitter is ruined. It's not the case.  And we've got to keep that kind of perspective in mind.

Speaker: SPEAKER_02
Transcript:  Yeah. Well, I don't know if there's a lot of hope for Twitter.  I don't. Well, there's certain does the world need Twitter?

Speaker: SPEAKER_03
Transcript:  Well, I don't know. I don't know about that.  Does the world need anything? I don't know.  What are we really?

Speaker: SPEAKER_02
Transcript:  There's a philosophical book, a nice, a nice glass of Chardonnay.

Speaker: SPEAKER_03
Transcript:  And I'm happy at night, you know, 40.

Speaker: SPEAKER_01
Transcript:  Kevin's thinking, boy, this I just deal with devices now.  So much nicer. It is a lot easier.

Speaker: SPEAKER_02
Transcript:  But, you know, here's where my guilt shows up is.  So we're going to switch over to some other topic.  And I feel like we're it's almost bearing your head in your sand in the sand to talk  about all Android phones and  when when, you know, this this mess is occurring on this thing that we loved called  the Internet. So I don't I I don't I don't know.  Maybe it's too easy. This is you're you're you're right.  They're Joan. They're getting to me.  I'm I want to. Yeah, they shouldn't get to getting to me.

Speaker: SPEAKER_03
Transcript:  You know, I've listened to you for years in California.  I just want to celebrate.  I want to celebrate technology.  But it's not, you know, put down the Kindle and looking at a book.  What are you thinking? What are you doing with your time?  Well, the other thing is that these things are bound to certain features online.  Jeff's right to say that if you curate your feed and you don't look at hashtags,  right, generally speaking, you're not going to fall prey to this.  This kind of disinformation happens in breaking news cycles.  It happens in crisis.  And those are bounded problems that happens to individuals that can be solved for.

Speaker: SPEAKER_02
Transcript:  And just don't click the moments button, whatever you do, in other words.  Yeah.

Speaker: SPEAKER_01
Transcript:  See, the other thing here is I think that the two people I know who have  for their careers have had to deal with the worst crap of the Internet  are two of the nicest people I know.  That's Joan Donovan and Matt Cutts.  So somehow they've managed to keep their sanity, but we can't.

Speaker: SPEAKER_03
Transcript:  Well, I do.  I do. I do a lot of this work, but at the same time,  I have to have faith in a humanity or else, you know, ultimately, I love I.  What pains me, Leo and Jeff, is that I love the Internet.  I do. I love technology.  I love toys.  I love things that move.  I love things that blink.  I love tape and telephones.  And so but I don't think we've actually lost the fundamental  infrastructure of the Internet.  These products are built on top of it. Right.  And so if we think about them as the end all be all of the Internet,  then we're really only looking at one.  You know, we have a one dimensional problem.  But fundamentally, the Internet is still there.  It's still critical infrastructure.  And there's still many opportunities for us to either create smaller,  small worlds networks where people are  cloistered away from this or that it's more difficult to move across  the social graph or we can temper this with a good dose of  what I remember from the 90s, which is that  we didn't believe what happened on the Internet was real anyway.

Speaker: SPEAKER_02
Transcript:  That's where we went wrong.  Starting to believe this crap.

Speaker: SPEAKER_03
Transcript:  Well, part of it was, you know, all all of our institutions moved online,  education, media, you know, we all started, you know, and our banking moved online.  And then things got really serious.  And I think that we can, you know, one look back, one step forward  and try to understand that the fundamental infrastructure is still there  and that we can remake it in another way.

Speaker: SPEAKER_02
Transcript:  Let's take a break and we'll come to something Kevin can talk about.  Poor Kevin.  Kevin Tuffell is here.  It's great to have you back, Kevin. I really am.  Kevin's been able to read through the rundown.  Yeah, now you know all the stories we're going to talk about next.  I was getting rid of my bots.  Did you did anybody?  I didn't see. I don't remember what my Twitter followers were, but it's I mean,  it's roughly the same.  It tells you it tells you whether they've gone up or not.

Speaker: SPEAKER_01
Transcript:  Mine went up. Where does it tell you that?  Where does it tell you that?  If you go to your your your Twitter page.

Speaker: SPEAKER_02
Transcript:  That's part of the problem. I don't even know how to use this thing.  I didn't know it either. Is it on?

Speaker: SPEAKER_01
Transcript:  OK, if you look at where the heck is it?  You look at stats, follow analytics, followers analytics analytics.

Speaker: SPEAKER_02
Transcript:  Yeah, I do. I do have some analytics somewhere.  Yeah, thank you. Here we go.  View your top tweets, your tweet activity.  Is it is it is there a link to analytics?

Speaker: SPEAKER_00
Transcript:  What is the your profile picture at the top?  Right, your icon or profile photo.  Pull that down. Thank you for helping me use this.

Speaker: SPEAKER_02
Transcript:  That's wonderful.  Yeah, so this will tell you whether you've lost followers or gained  new followers. I'm down 244 bots.  I mean, followers.

Speaker: SPEAKER_01
Transcript:  I'm up seven 26 followers.

Speaker: SPEAKER_02
Transcript:  Kevin, what's your what's your I'm up 39.  So obviously, I'm the right winger here.

Speaker: SPEAKER_03
Transcript:  Joan, I'm looking.  I can't find it, though.

Speaker: SPEAKER_01
Transcript:  Go to your Twitter page, go to the picture.  Kevin just said this. I'm just like your head.  Choose analytics. OK.

Speaker: SPEAKER_03
Transcript:  Click on my head.

Speaker: SPEAKER_02
Transcript:  Choose analytics unless you don't have your head as a.  You know, it's really interesting.  Some of the most vile people on Twitter don't use their own pictures.  Isn't that interesting?

Speaker: SPEAKER_03
Transcript:  Oh, well, the frog is real.

Speaker: SPEAKER_02
Transcript:  Pepe, whatever happened to the egg?  The egg is gone.  No, they don't use an egg anymore. Yeah.  So I've lost 244, which I'm I'm perfectly happy to lose.  I don't pay any attention to the number of my followers anyway.  Not since not since Kevin Rose beat me in 2007  for the number one most followed person on Twitter ever since then.  I'm still bitter about that.  We were on a race to 5000 and he beat me 5000 followers,  which was everybody. Yeah, it was.

Speaker: SPEAKER_03
Transcript:  All right.  What am I looking for in audiences?  Where do I analytics?

Speaker: SPEAKER_02
Transcript:  It's over. And then once you get to that page, it's on the right hand side.  There's a column.  That's February 2018 summary.  Oh, that's 244 for February.

Speaker: SPEAKER_01
Transcript:  So it's on the top.  It says followers down 436. Oh, look, there you go.

Speaker: SPEAKER_02
Transcript:  This is a 28 day summary.  It's a followers 28 day.  That's probably because I'm just boring. I don't.  I don't really I don't post anything of interest on Twitter.  I just point and post news stories.

Speaker: SPEAKER_03
Transcript:  I get 81 clicks a day, 25 repeat tweets a day,

Speaker: SPEAKER_02
Transcript:  43 likes. Actually, I should I should pay more attention to Twitter.  Apparently, I have one point nine one million impressions over the month.  That's a pretty good number.

Speaker: SPEAKER_03
Transcript:  I guess. I guess.  Compared to what?

Speaker: SPEAKER_02
Transcript:  What does an impression mean?  Does that mean somebody scrolled past my tweet?  Yes. Yeah, it's a big deal.  Big, big deal.

Speaker: SPEAKER_03
Transcript:  Yeah, I'm still not seeing followers for some reason.  I don't know what's going on with me.

Speaker: SPEAKER_02
Transcript:  But you have been blocked.  It's a state secret for you.  Yes. Let's take a break.  Come back with more.  Joan Donovan is also here from data and society.  She is in charge of fake news  today.  She is she is actually doing the most interesting job  you can even imagine at data and society.  She's her technical  technical your title is project lead on media manipulation  and platform accountability, which is fascinating.

Speaker: SPEAKER_03
Transcript:  So couldn't have if you want to work for me, I'm hiring.  Wow. Come on.

Speaker: SPEAKER_02
Transcript:  What kind of skills does somebody need to to come to work for you?

Speaker: SPEAKER_03
Transcript:  Yeah, probably a lead line stomach. Yeah.

Speaker: SPEAKER_02
Transcript:  Yeah, I want to come back the next day.  I honestly I took Twitter and Facebook off my phones.  I don't want to.  I never feel good afterwards.  And mostly I use things like Nuzle to look at what's going on on Twitter  because it just aggregates news stories.  I it just makes me feel bad.

Speaker: SPEAKER_03
Transcript:  I don't like to. Well, I mean, it's it's like anything.  You know, it can get once you get stuck in those echo chambers, right?  You know, you start seeing the same content over and over and over again.  And it's it just feels obnoxious, right?  It just feels like what am I even doing here?  I'm reading the same thing over and over again.

Speaker: SPEAKER_02
Transcript:  Yeah. Those Russian trolls are bringing me down, man.

Speaker: SPEAKER_03
Transcript:  I can't believe they got you of all people.  I don't even know.

Speaker: SPEAKER_02
Transcript:  Are they all Russian or are they from other places, too?

Speaker: SPEAKER_03
Transcript:  This is the other thing is this is an agency for hire.  They could be from anywhere.

Speaker: SPEAKER_02
Transcript:  So like if Erdogan and Turkey decided I need  to get my my word out on Twitter, he could go to the Internet  Research Association, say, can I get a few bots to help me out?  They're not bots.  They're by the way, we shouldn't call them bots.  That's not fair.  They're actual people.

Speaker: SPEAKER_03
Transcript:  They are using they're using two technologies.  One is there's just the sort of human element where they're using sock  puppet accounts pretending to be either organizations or individuals.  And then the second layer of it is some of it is automated  and they have bots set up to amplify those accounts, to follow  those accounts. And so it's that's what we refer to when we refer to a botnet.  OK. And then the other thing that's  important to understand is like there's this, but then there's also an entire  industry devoted to fake followers  that has it has cropped up in order to gain these algorithm  and algorithmic system. Right.

Speaker: SPEAKER_02
Transcript:  That's just commerce. Yeah.

Speaker: SPEAKER_03
Transcript:  Yeah. But you can still buy and use those same followers  in order to do the work that you're trying to do.

Speaker: SPEAKER_02
Transcript:  What are the chances that the NSA or other federal  US federal agencies don't have the same capabilities?

Speaker: SPEAKER_03
Transcript:  I mean, like, I don't want to sound like a conspiracy theorist, but,  you know, in my work, anybody has a right to Joan, you do  In my work with movements, you know, we know that movements have been  infiltrated for years, entire Cointel Pro programs have been set up  to infiltrate movements and infiltrating movements through social media and use  I think to, you know, influence movements.  I think we have a bot cap.

Speaker: SPEAKER_02
Transcript:  I think we need to get some bots in Russia.  Let's go after the Russians.

Speaker: SPEAKER_03
Transcript:  Yeah. Leo Laporte hacks Russia.

Speaker: SPEAKER_02
Transcript:  We need a bot. There's a bot cap.  We need our own Internet research agency there in McLean, Virginia, to get  chat room. You got a new job.  Go get the Russians. Screw with them.

Speaker: SPEAKER_03
Transcript:  This is the other thing is like, you know, they've dedicated  a multi-year propaganda plan here and getting Americans to do things  for that long without any specific reward.  I mean, it's going to be hard to engage, you know, formalize that kind of  civic engagement.  Of course, I'm being facetious.

Speaker: SPEAKER_02
Transcript:  It helps when you're a totalitarian regime.

Speaker: SPEAKER_03
Transcript:  It does. It really does.  And as well, we do know that the US has run social media operations  in other countries in order to influence, you know, networks of actors.  And so that stuff is well known.  And so one of the things that I often refer to when I talk about  our understanding of social media is that it's not a reflection of reality.  It's a bit of a funhouse mirror.  And if we don't understand its distortions through manipulation,  then we don't understand the reality that we're living in, which is partly  mediated by screens.  And then there's the stuff we see with our own eyes.

Speaker: SPEAKER_02
Transcript:  Jeff, it's your fault. I'm looking at August.  I lost eight hundred seventy eight followers because of your Trader Joe's  case. So tweet, I blame you.  I blame you, Jeff Jarvis, City University, New York,  professor of journalism, helping us navigate the mainstream  and otherwise media.  And Kevin Toffle, his triumphant return.

Speaker: SPEAKER_00
Transcript:  And I don't tweet about politics or case.  Yeah, me neither. Safer that was safer.

Speaker: SPEAKER_02
Transcript:  Kevin is at the IOT podcast with Stacey and Stacey's in Berlin.  What's she doing in Berlin?

Speaker: SPEAKER_00
Transcript:  She is freezing her behind.  Is it cold there? Very cold.  Yeah, she's at the Bosch IOT event that they have for several days.  Yeah, that's right. Not my thing.

Speaker: SPEAKER_02
Transcript:  Well, we're glad you're with us. Thank you.  Thank you. Yes.  How do you feel about Chipotle Queso?

Speaker: SPEAKER_00
Transcript:  I've only had Chipotle once, to be honest.  He's too healthy.  He doesn't need that stuff.  Don't let the running every day fool you.  That's why you run.  I had a meatball parm sandwich for lunch that I put on Facebook today  because the dog was trying to eat it.  Oh, hmm.

Speaker: SPEAKER_02
Transcript:  Now, see, I don't follow any meatball parm account.  No problem. That's my people.

Speaker: SPEAKER_00
Transcript:  Jeff probably knows Wawa.  Best meatball parms. Yeah, yeah, I do.

Speaker: SPEAKER_01
Transcript:  My son loves Wawa.  There you go. My son works at Wawa.

Speaker: SPEAKER_02
Transcript:  Oh, wow. How have I not heard of Wawa?  Because it's an East Coast thing.

Speaker: SPEAKER_01
Transcript:  It is. It is an odd.  It's a 7-Eleven, but it's an oddly cult like.

Speaker: SPEAKER_02
Transcript:  It's a it's a convenience store.  Yeah. With sandwiches more.

Speaker: SPEAKER_01
Transcript:  They have more fresh made food.  Well, fresh might be a stretch, but they have more made food.

Speaker: SPEAKER_00
Transcript:  It's fresh. I've seen that.  I've seen that how the sausage is made.  They started. They started out as just a milk delivery way, way, way back  in the day in Pennsylvania, and they've expanded to hundreds of stores  throughout the tri-state area and all the way down to Florida now.

Speaker: SPEAKER_01
Transcript:  Yeah.  And you go in and it's very it's very techy.  You order on a little screen.  Screen control. Yeah.

Speaker: SPEAKER_00
Transcript:  Yeah. They don't serve bots either.

Speaker: SPEAKER_02
Transcript:  Savor Savor Wawa's hot hoagies.  That is a mouthful.  They are not our sponsor today, however.  I wish they were.  I could use some of that Wawa hoagie money, but  but actually, I'm very happy to have WordPress as a sponsor because I use WordPress.  I'm very I've been I've been a WordPress fan since they started in the early 2000s.  And if you are a business or even an individual  and you don't have your own personal website, if you're, you know,  trying to make it as a Facebook page or a Twitter account, no, man.  Get yourself a website, a WordPress WordPress dot com makes it easy.  You don't I know you're intimidated.  Maybe you think, oh, I have to know about web design. Right.  No, you don't need to experience.  You don't need to hire somebody.  WordPress dot com guides you through the entire process from start to finish.  They do all the technical stuff, including keeping it up to date.  They've got hundreds of beautiful templates to choose from designs.  They've got the all the plug ins that you could turn on Google  app for speeding up your mobile loading.  I do that.  Built in search engine optimization makes Google happy.  Social sharing.  So you don't have to put it on Twitter.  Your fans will tweet about you or Facebook about you.  If you're a business and you don't have your own personal website  with your own domain name, I feel like in this day and age, you barely exist.  You've got to do this.  This is the this is the this is table stakes.  And what a great customer support team.  You'll never be at sea because they're there 24 hours a day,  Monday through Friday, weekends, too, to help you.  They love helping you.  Plan start as little as four dollars a month.  And here's the thing.  29% of all the websites in the world, 29% run on WordPress.  You'll be joining a community of nice people.  Get started today with 15% off any new plan purchase.  Go to WordPress.com slash twig.  I'm there.  Will you, will you join me there?  15% off your brand new website, WordPress.com slash twig.  We thank WordPress so much for their support of this week in Google.

Speaker: SPEAKER_01
Transcript:  All right.  I just hired a new president or CEO.  I forget which it is named Kinsey Wilson.

Speaker: SPEAKER_02
Transcript:  I wanted to mention this because I saw your tweet and you said, this is so good.  And so why is that so Kinsey was USA Today top editor?

Speaker: SPEAKER_01
Transcript:  And then he was in charge of digital and then all news content at NPR.  So he's a journalist.  And he was at the New York Times.  Yeah, he's Kinsey's a really top notch media executive.  So I think it's it's good for us in media.

Speaker: SPEAKER_02
Transcript:  That's a wonderful guy.  That's really good.  So just now he's been hired.  I mentioned this last time and I couldn't remember his name because I saw your  tweet about this.  Um, nice, nice.  He is now at WordPress.  Fantastic news.

Speaker: SPEAKER_01
Transcript:  I think, I don't know, CEO or president or I think Matt Mullenweg is chair or

Speaker: SPEAKER_02
Transcript:  yeah, Matt, I've known Matt for years.  This is him, right?  Yeah.  Does, does, uh, delighted to be joined the growing team at WordPress.com and  parent company, automatic, iconic champion of the open web.  Many more champion, many more chapters to write.  So that's pretty, pretty awesome.  It is.  Yeah.  Yeah.  Well, we're, you know what?  I, we only do advertisers for companies I feel good about.  And I, you know, one that's easy to feel good about.  It's easy to feel good about them.  I completely agree with you.  Uh, let's see here.  All right.  Let's change the subject.  Let's find something exciting about technology, something wonderful.  Google removes the image view button from search because Getty talked him into it.

Speaker: SPEAKER_01
Transcript:  Now this is going to lead into, might be a, might be a gentle way to say that.

Speaker: SPEAKER_02
Transcript:  This is going to lead into this big New York times Sunday feature that's coming  up this Sunday, uh, about the case against Google, that's the name of it, but it's a  little more nuanced that article than that.  But, uh, Getty was mad because, uh, like, uh, other sites, Google in their image  search would put Getty's custom images there and you could click a view image  button and just download it and, uh, Getty felt like that was, uh, well, foul play.  They actually sued and it's believed this is part of the settlement.

Speaker: SPEAKER_01
Transcript:  Um, you can still right click on the image and download it, right?

Speaker: SPEAKER_02
Transcript:  Yeah.  Yep.  And there are already Google Chrome plugins that restore the download image  button, but I don't tell Getty about that.  Um,

Speaker: SPEAKER_00
Transcript:  say this is the problem when you want to be the purveyor of all the world's  information, you know?

Speaker: SPEAKER_02
Transcript:  Yeah.  So Google's mission statement is what to, uh, to, uh, put all the organized the  world's accessible, make it easily accessible, right?  So, but as, uh, Charles Duhigg points out in his New York Times magazine piece,  Google's business is advertising and the search is really just a way of, of  driving advertising traffic and they, uh, and he tells some stories in here that  are pretty compelling.  Google doesn't seem to be unwilling to, uh, inconvenience competitors.  He starts with telling the story of a company called, uh, found me.  Found them.  Found them was a, what they call a vertical search.  So Google's regular search is horizontal.  It searches everything.  Found them was designed to help you shop.  And it's something Google historically wasn't very good at searching for white  tennis shoes with free shipping that have wide sizes under $40.  That's a hard thing to do on Google, but found them was designed to do that.  And apparently they were very good at it, but you may never have heard of them  because as soon as found them went public, they disappeared from Google's search index.  Um, wow.  The Google, they, they have been chasing after Google for a while.  They went to the, they actually met with the FTC in the United States.  As we know, the FTC declined to prosecute Google over this, but the EU did, and they  felt vindicated when the EU find Google a record $2.7 billion just a few months ago.  Um, there are many, there are kind of examples in here and, and, uh, Duhigg  who, uh, has written a couple of books, um, basically implies that it's time to  break up Google, that Google is not only a monopoly, but is willing to use their  monopoly position in search to get rid of competitors.  Jeff Jarvis.

Speaker: SPEAKER_01
Transcript:  So give me a minute.  Then I'll, I'll, then I'll leave.  I think this piece is manifestly unfair to Google.  Uh, Google has no word at all until six paragraphs from the end where  it's also kind of blown off.  We're savvy enough on this show to have talked about Panda and the  changes that were made in Panda.  And if you go to the data, it was a new search algorithm that did, in fact, hurt.

Speaker: SPEAKER_02
Transcript:  Found them.

Speaker: SPEAKER_01
Transcript:  It hurt, found them and it hurt others.  So about.com where I, where I consulted with the times bought it, um, was, was  invented a whole new form and then demand media came along and messed it up.  And then there were all these content farmers messing it up.  And Google had to have a formula for its algorithms to say, what are we going to do  about that?  We're going to get rid of a bad content experience.  And yes, the man media was put down, but so about.com went out, you know, was  that, was the dolphin caught in the tuna net and it went out too, basically.  It went way down the case of found them.  And I looked at found them back in the day when this, this, these complaints  came up, Google's complaint is they don't want sites that are just a whole  bunch of lists of links to make money off those links and found them.  In fact, appears to be just that it may be better than that.  It may be fine that, but, but the, but the mechanism here, although

Speaker: SPEAKER_02
Transcript:  doing points out that that's exactly what Google is.  Well, that's exactly what Google does.  A bunch of links to make money.  The mechanism here.

Speaker: SPEAKER_01
Transcript:  No, Google actually has links to content.  This has links to just deals and advertisers.  Yes.  Cause it's a shopping search engine.

Speaker: SPEAKER_02
Transcript:  Exactly what it should have.  Give me my minute.

Speaker: SPEAKER_01
Transcript:  Give me my minute.  Okay.  So the mechanism of, of, of taking an algorithm to take down the latest trick  of the spammers or of the manipulators.  Um, in this case, there are lots and lots of sites that were just link farms.  Found them looked like that.  Now, Google may have done a bad job or found a man fact had been that.  I think that they're, they're being martyred a bit.  Uh, I don't think it was that good a site.  I don't think it was that wonderful, but I saw it back in the day.  Now it's down, so you can't really compare, but this is the way that Google operates.  And there is in this story, there is zero acknowledgement of that kind of  manipulation and spam management.  If we had Matt cuts here, he could talk about, I think that from a higher level  that's not in that story whatsoever.  This is an effort to say, this is advocacy is pure as it comes to say, let's  break up Google and here's my sob stories about what happens, but a lot of those  cases, a, they weren't necessarily good sites or B like about.com, which is a good  site when that formula got manipulated too much, it went out with that end of spiel.

Speaker: SPEAKER_02
Transcript:  What about, this is a different technique.  Google uses sky hook wireless.  We've talked about sky hurt before.  This is a different methodology, sky.  And I don't know the facts of this case.  I'm just taking do Higgs, uh, assertions as fact.  So if somebody has a counter story, that's fine.  Skyhawk we know about, they were, they were basically a location service using  wifi and they went around and they mapped everything so that if you didn't have  GPS in a device, you could, based on triangulating the wifi signals, you  could see, figure out where you were.  This competed obviously with Google's location software.  In fact, Google street view went out and started to do the same thing.  Right.  So a lawsuit filed by skyhook against Google, uh, in the discovery revealed an  email from a Google manager, an internal email that said skyhooks accuracy is  better than ours long, not long after that note, it was written according to  do Higgs and the lawsuit, a high ranking Google official pressured Samsung and  Motorola to stop using skyhook and said, if you were, if you don't, we could make  it difficult for you to ship your phones on time.  Google's denied this obviously.  Uh, so soon after Samsung and Motorola canceled their skyhook accounts, skyhook  sued Google and though one suit was dismissed, Google ended up paying $90  million to settle a patent infringement claim.  But by then it was too late.  Skyhook founders bereft of other partnership options had been forced to  sell their company at a large discount.  Now I don't know the facts of this case, so I'm just quoting here, but if that's  true, is that not exactly the kind of anti-competitive behavior that a monopoly  uses to, to protect itself and keep, and to enter new businesses, keep others out  of that business, it's exactly what antitrust law is meant to do.

Speaker: SPEAKER_01
Transcript:  But I'm just going on the evidence of how the Fondom case was handled.  I don't think it was handled journalistically very well.  So I don't know.  Maybe he's got it wrong.  Maybe, maybe, and listen, Google is not pure as the driven snow.  Google is a gigantic company where people can do bad things.  All these companies can, and they can mess up.  And so I'm not defending them wholeheartedly against all possible sins  by any means, just this, this Fondom case, I think is a red herring that was  also jumped on by Vestager in the EU.  She wanted an excuse to go after Google.  But did Google do other things that were bad or misuse their authority or their  power? Maybe they did.  I don't know.

Speaker: SPEAKER_00
Transcript:  So a couple of things here, just from having the perspective of having worked for  Google, I cannot name a single Googler that doesn't want to do the best thing for  the end users.  I just couldn't.  They were all fantastic in that regard.  And I think Google's vision was to do that.  But once you become beholden to shareholders, you have incompatible goals now.  And I think that's a large part of the problem, trying to balance that, because  quite honestly, if Google's got a competitor such as a Skyhook wireless, that  does have a better solution.  And I remember when this all happened and I remember Skyhook and it was a good  solution. The folks, the rank and file, you know, they want the best for the  users. But at some point, management knows the buck stops with them and with  the shareholders. So what do they do?  I don't know how you reconcile that.  And Google's now a big entity that is beholden to shareholders.  So there's a big issue there.

Speaker: SPEAKER_01
Transcript:  But, Kevin, you could be beholden to shareholders in an evil way, Uber, or you  could be beholden to shareholders and say that the company that we are has a  standard that we're going to behold, because that's our business.  I think that's closer to Google.  Are they perfect? No.  But I think you're right. Everybody I've ever met at Google holds rather  religiously to users.  And so that's at least the pressure that's within.  That's the don't be evil.  That's the license to be able to say that.

Speaker: SPEAKER_02
Transcript:  So we can put that this particular conversation aside, because I would like to  say and we talked about this in Windows Weekly, maybe the higher level  conversation. And it brings us back to Scott Galloway's book, The Four, in which  he says that these big tech behemoths, these companies that are so big, they  in do-higs words blot out the sun.  Amazon, Facebook, Apple and Google are bound to come under scrutiny soon  because they are getting so big.  Well, they're underage.  There's nothing, by the way, I would not buy into the notion that just because  a company is big, it's bad.  I don't I think that that's a value judgment that some people make, but I  don't think that it's going to stay big on its own.  Yeah. Microsoft.  But I think, yeah, well, and do-hig uses the Microsoft example.  He says if the DOJ hadn't sued Microsoft and gotten them looking over their  shoulder, there might not be a Google.  That's it.  I don't, I don't, I don't.  Microsoft's taken its foot off the pedal gave Google an opportunity.  And that's so that's really the larger philosophical question.  I'd love to know what you guys think.  There's really no, there is one current of thought that says technology is  different than any other monopoly situation.  Do-Hig mentioned Standard Oil.  There's AT&T's breakup and the sixties in the world of technology.  Some innovators going to come along and you're going to get out innovated.  And no matter how big you are and all these companies, including, by the way,  Standard Oil got big because of technological innovations they, they  owned that somebody's going to come along and disintermediate you.  There might be some evidence that's already starting to happen.  Facebook's starting to slip a little bit.  So there's some who say in the 21st century, we don't have to worry about this.  Don't worry.  Trust, antitrust regulation takes so long, took more than a decade.  In the case of Microsoft, it's too slow.  It's not effective.  Just let the market handle it because technology, it's the nature of technology.  The innovation will, will solve this problem.  But there's the other side that says maybe that's true, but if there's going to be a  point where Google, Facebook, Microsoft and Apple and Amazon, particularly, are  so big, Amazon's already getting there.  Look at Walmart.  Just stock just tanked.  It lost $31 billion in market cap.  10% of its stock value.  Toys R Us is gone.  That there'll get to be a point, a tipping point beyond which you can't fix it  because all you got is Amazon.

Speaker: SPEAKER_03
Transcript:  So yeah, I've been, you know, in the article, one of the things that was compelling to me is,  and one of the things that I wanted to know more about in terms of found them was a worthy  relative competitor that could make a kind of Google shopping service irrelevant.  Right.  And so, and then, you know, showing the case of Skyhook where, you know, that the company  eventually had to sell out because it couldn't compete.  You know, there's some evidence that even if Google isn't doing it on purpose, downranking  websites or forcefully pushing apps or technologies out of business is that it's not a  good look for a company that really has expanded to a bunch of different features and is  known for acquiring technologies and sometimes, you know, either killing them or integrating  them poorly into the system.  And then the other thing that I'm wary of, and Jeff, we can argue over this is the algorithm  made me do it is, you know, one of the most difficult excuses for me to, you know, to swallow  at this point, knowing that these algorithms aren't, you know, they're they we know what they  do. And in the design of them, these these these what engineers would love us to believe as  accidents are designed by design.  And so I don't know the case.  I don't know. I never worked for Google.  And so I can't say that this is the case with that algorithm.  But we've started to see a pattern of these companies blaming the technology and how the  technology sorts things without taking accountability for the effects or the consequences  of those algorithms.

Speaker: SPEAKER_01
Transcript:  Yeah, let me respond, because I think it's not so much blaming the algorithm as it is the  ever present desire to have a rule set under the excuse of scale.  And ironically, paradoxically, it's almost saying this is this is their definition of  fairness. Well about dot com.  We now have 100 competitors to you who who take your formula and schmutz it up.  But we got to treat all of you exactly the same, because that's what we do.  We have a formula that says if you look like this, this is how we're going to treat you now.  And so we're not going to make a gradation difference between about dot com, which is  good and demand media, which is bad.  Same thing happened to Facebook.  Facebook said Facebook was far was not nearly nuanced enough about its non social public  content. It considered all public content to be basically the same point you made earlier  about media. And so when bad social content got him in trouble or public content got him in  trouble, they threw out all public content because their formula wasn't nuanced and smart  enough. So I'm not really defending them so much as to say,  this is how they think.  They try to come up with that formula.  They're not blaming the algorithm so much as they're saying we have to have a rule set.  Now, why? I think I'll agree with you, Joan, is they need to have a smarter rule set.

Speaker: SPEAKER_02
Transcript:  And I agree with Kevin that I'm sure everybody at Google, I'm sure, is wonderful and really  just wants to help the customer.  You could probably say the same thing about Facebook and Amazon and Apple.  But companies, corporations act in aggregate sometimes in ways that the individuals  wouldn't necessarily support.  Would you say the same thing about Uber?  Well, that's an interesting question.  Right. So I don't think if Uber had a monopoly, I think there'd be no question.  Yeah, that's company culture. But I mean, well, in Europe, it is a monopoly.

Speaker: SPEAKER_01
Transcript:  I mean, if you're in, you know, it's being kicked out of places.  But if you're in Berlin or London, there's no there's no competitor.

Speaker: SPEAKER_02
Transcript:  There's also and you put I think you probably put this article in this opinion piece in  Bloomberg from Leonid Bershidzky, which is a Russian troll name, a bot name, if I ever  heard one. Now, he's saying that that Margarete  Vestager was influenced by not by a desire to help end users or even improve competition,  but by lobbying.  And you've always mentioned this from publishers in Germany and so forth who didn't like the  fact that Google was beating them in the marketplace.  And that is for sure another avenue for this stuff is that competitors sue instead of

Speaker: SPEAKER_01
Transcript:  winning, you know, which is the case of some of those in the Google story.  These are some competitors and they are disadvantaged competitors because they're smaller.  True. But yeah, that's that's an issue.

Speaker: SPEAKER_00
Transcript:  Yeah. But that's not entirely.  Jeff, are they just disadvantaged because they're smaller?  I mean, in the article, you know, Google is portrayed as the 800 pound gorilla.  It's not so much that they're smaller, it's just that they just don't have the influence.  I grew up when when the Internet was AOL, it was synonymous.  Now, Google is synonymous with search.

Speaker: SPEAKER_02
Transcript:  You're not on Google. You don't exist.

Speaker: SPEAKER_01
Transcript:  Yeah, but I'm not what I'm saying is that I don't I don't think Foundam was a competitor.  I think Foundam was a type of site making money that Google in its rule said this this  sites that look like this are almost always bad for users.

Speaker: SPEAKER_02
Transcript:  I mean, I have to say I'm a I'm a I'm a tweet is an example of a company that struggles  because Google and Facebook are so good at selling advertising that it's hard for us  to sell against them.  That's a difference. I don't blame them as I wouldn't sue them saying you're putting me  out of business. They're doing their job and they're doing a better job of it.  For some advertisers, they want all that data.  They want all that information about who they're selling to.  I'm not going to give them that.

Speaker: SPEAKER_01
Transcript:  Well, I've long argued that where Google is most in trouble and Facebook are most in  trouble when it comes to antitrust and monopoly is not in search.  It's not in social. It's not in any of those areas.  It is in the advertising market.

Speaker: SPEAKER_02
Transcript:  But it's all but see, that's the point of this article, which is that Google's advertising  revenue drives all these decisions.

Speaker: SPEAKER_01
Transcript:  Well, I'm not saying that I'm saying that Google has the power of God in advertising.  If its rule puts you out, if they decide that you are a bad actor, then you're out.  They might have done that.  Do we want any company to have that capability?  So I have argued that I've long said I've said this on the show a dozen times over the  years since the beginning.  I think Google would be wise to have juries of peers.  If you look at this way, if they had 100 advertisers, trusted good advertisers and said  this place has come along and they've complained, they found them and said we're treating them  wrong. Now, the advertisers have an interest in having a credible marketplace.  And if the advertisers say, no, no, no, they're they're actually OK.  They're all right.  Then you go to Jones question of how do you change the rule to allow them in and say this  defines good and this defines bad.  But Google does have the power of God in that one instance.  And I think that's what's going to get in trouble in the long run.  Yes. And they should have come up with structures that were different to account for that.

Speaker: SPEAKER_02
Transcript:  I mean, I believe I should say very clearly in our advertising model that it's more  efficient, it works better than automated ads placements in Facebook and Google.  But it's hard to get above the noise that Facebook and Google make and convince advertisers  of that. But that's my job.  That's not my job particularly.  But that's our job as a company is to say, well, we believe we have a credible alternative.  But if Google should decide for some reason that we were a threat, see, that's why I want to  stay small. That's the end.  And say, oh, well, we're not going to put you in the search rankings.  I mean, if that's what happened to found them, that's appalling.  If.  So now, so that's the higher level question is we don't know.  I think we I think we could agree we don't have enough data to know if this stuff will  rent right itself automatically, if it's the nature of the technology business cycle.  But the problem is, if we if we don't act, there will be a tipping point beyond which  there's no recovery. I mean, it'll just be like, well, that's it's Google's.  You can't compete with Google. You just can't beat Amazon.  You just Facebook owns this. Right.

Speaker: SPEAKER_00
Transcript:  Well, that gets to your question that you asked earlier about, you know, monopolies  and competition. You know, there's always been some new innovation to dismantle or take  the place of a large company at some point.  Let me backtrack. Google's.  Currency is information.  It just the product is information.  All these prior examples of standard oil and Microsoft and all that, those were like  physical products. But at such a granular level, can it be any more granular than information?  How does somebody out Google Google at this point?  Is, you know, with IOT, with connected cars, it's everything is information and information  is currency today. What would it take to out Google?  Google? I don't know what there could be.

Speaker: SPEAKER_01
Transcript:  Here's the question. I think that if you go back to you following money, I think that,  yeah, it's hard to be Google and information.  I do think that the message based ad model at scale scale for scale sake is can be challenged.  You see what ad agencies are finally hitting some rocks.  That's why we do handmade advertising.

Speaker: SPEAKER_02
Transcript:  Exactly.  That's the name of our agency, by the way, is Artisanal Jones.  So thank you.  Oh, my goodness. Do you also make pickles?  No, no, we don't have pickles or beer.

Speaker: SPEAKER_01
Transcript:  But that'd be a better business, Joe.

Speaker: SPEAKER_02
Transcript:  All our ads are handmade by craftsmen in our little workshop here in Petaluma, California.  Actually, that's literally true.  And that's so that but that's our that's kind of our way of trying to compete.  And that's fine.  I'm not against I'm not against Google because of scale.  But I but they do have a lot of power.  And Joan, you're an expert on how much power Facebook has in the political arena.

Speaker: SPEAKER_03
Transcript:  Yes, yes.  And this is one of the things that people have been trying to measure over the last  decade is how much political influence and opportunity does that present to  political clients, right?  You know, in running social media through politics and running your politics through  social media, rather. But also, I think that what's difficult about this case, in  particular with Foundem is that you have a part of the search engine that is devoted  to making money, right, about, you know, sharing shopping links, which often has  some kind of advertising revenue attached to it.  And so people in their mind find Foundem on Google and then know to go to Foundem  every time they want to search for a thing, then it presents a problem for Google  because there's no longer that starting point.  And that's an incentive to move people or to move other search engines off the platform.  For instance, if you're searching for a flight, you might have Google now owns travel,

Speaker: SPEAKER_02
Transcript:  right? They buy.

Speaker: SPEAKER_03
Transcript:  Well, they're trying to. But I'll tell you, if you search for flights, depending on the  machine that you're using and the platform that you start at, you will get the same  flight offered to you at different prices and location.  I think data is implicated in this.

Speaker: SPEAKER_01
Transcript:  And so finding Joan is that I'm a United Flyer, fly everything United because that's  where my miles are. And I have one trip that I was going to do coming up and I couldn't  find the right flight fares.  And somebody used Google search and found far better fares on United than I was finding.

Speaker: SPEAKER_02
Transcript:  Wow. Really interesting.  So here's here's what Google says.  When you come to Google, when you search for what's the weather on Google, you don't want  a link to weather dot com.  You want the weather. So we're going to show you the weather.  Now, if I'm weather dot com and they've scraped my weather and put it there so the  searcher no longer comes to weather dot com, I think both sides, there's merit in both  arguments. It's true. Google is serving the user's interests.  They're giving you the temperature and forecast.  But boy, weather dot com has a very good reason to be pissed off.

Speaker: SPEAKER_03
Transcript:  Well, yeah, and this happened. This used to happen as an interesting story.  And Phil Lapsley's exploding the phone about this, where people were calling operators  for information and this small town, there were two mortuaries.  And so when someone died, they call the operator and the operator happened to be married to  someone who owned a mortuary.  So she would automatically give her husband's business name.  And in that, you know, the other mortician wasn't getting any business and he couldn't  understand why. And then he figured out customers had died.  That's one that would be good for business.  Right. In that case. But what was interesting is because we didn't have a telephone switch  system, but we had humans networking the calls, is that this this business got a lot  more attention. And so in some ways we have someone networking the information in a way  that advantages them and advantages in-house products.

Speaker: SPEAKER_02
Transcript:  Google is basically the mortician's wife in this.

Speaker: SPEAKER_01
Transcript:  OK, but well, but OK, but let's look where Google gets it from all sides.  So we talked about this before we were on the air.  Edible Arrangements is suing Google because one hundred flowers is buying a search to  give people an alternative to Edible Arrangements if you search for Edible Arrangements.  And Edible Arrangements is trying to say, no, people search for us.  That's all you should show them.  And that's going to be a hard case to win.  Shouldn't get any alternatives.

Speaker: SPEAKER_02
Transcript:  There's no that's going to be a very hard case to win.  And that's an example. That would be like me saying, oh, Google, you're too good at  advertising. I want to sue you.  That's that's a company.  Just, you know, you got to compete.  You got to be better than, you know, Sherry's Cherries or if the information were arranged

Speaker: SPEAKER_03
Transcript:  in such a way that even if you Google that, Edible Arrangements or one hated one eight  hundred flowers, what you'd come up with would be a sort of telephone book style  information where, you know, it's all slotted under gifts.  Right. Or, well, here, I think their position is a way of serving the information  differently in terms of the way that you organize the content related to the category

Speaker: SPEAKER_02
Transcript:  itself. Right. So here's the I did an incognito page because as you point out, it won't  look the same if I do it with my own search.  But here's I think Edible Arrangements point is, well, look, somebody searched for Edible  Arrangements. Clearly, all they're interested in is us.  Why do you allow our competitors to buy ads on the right hand side?  But that's that's the ad unit right there.

Speaker: SPEAKER_01
Transcript:  Right. And yeah, I mean, I may not.  I'm now used to saying that if I if I search for Nike, maybe I want to see what

Speaker: SPEAKER_02
Transcript:  now if Edible Arrangements didn't buy this ad at the top of the page, they would not  be at the top of the column in search results.  You see what happens here.  And I think this is defensive.  So that the first this is these are all ad units.  These this block and this block ad units.  This is the first organic search.  It's Edible Arrangements, but it's almost off the page.  If Edible Arrangements hadn't purchased this ad, the number one result from the point  of view of a consumer, it doesn't matter that it says ad there is shop fruit  arrangements from a competitor.  So I could see their point of view.  You Leo search for Edible Arrangements instead.  The first result kind of organic resistance.

Speaker: SPEAKER_01
Transcript:  Actually, the prior law on this is a trademark case.  So I forget who it was.  It was it was it was some cosmetics manufacturer said that if you search for Chanel, you  shouldn't get right.

Speaker: SPEAKER_02
Transcript:  Yeah, that's a that's a counterfeit result.

Speaker: SPEAKER_01
Transcript:  Interesting. Well, that's what counterfeit is that you were you were you I was using  somebody else's trademark.  Oh, and what happened in that case?  I forget.

Speaker: SPEAKER_02
Transcript:  Oh, she's the real problem here is that there you can't trust jurists and juries in  cases like this to come up with consistent answers.  That's the real problem.  And and I point to this weird link embedding case.  Do you mind if we move on to that one from Edible Arrangements?

Speaker: SPEAKER_01
Transcript:  That's fine.  Tipsy Elves versus ugly Christmas sweater ink.  I'm serious.

Speaker: SPEAKER_02
Transcript:  What?

Speaker: SPEAKER_01
Transcript:  This is I just search for this.  I haven't read it yet.  But how can we resist this?  Hold on.  But OK, here we go.

Speaker: SPEAKER_02
Transcript:  Is this is this in the is this in the Westlaw database?

Speaker: SPEAKER_01
Transcript:  Is trademark use in Google AdWords trademark infringement?

Speaker: UNKNOWN
Transcript:  Wow.

Speaker: SPEAKER_01
Transcript:  On May.  Oh, yeah.  Tipsy Elves is those ugly Christmas sweaters.  Yeah.  I'll have to complain against ugly Christmas sweater ink based on ugliest Christmas  sweater advertisement material that appeared as a result of Googling the term tipsy elves.

Speaker: SPEAKER_02
Transcript:  See, that's the same thing.  You're searching for tipsy elves instead.  You're getting ugly Christmas sweater.  And did they win?

Speaker: SPEAKER_01
Transcript:  It's similar to a case of Rosetta Stone.  I don't know.  This is June 2017.  It's if they filed a complaint in 2017, so it's probably still litigation.  Rosetta Stone.  I don't know.

Speaker: SPEAKER_02
Transcript:  Well, I just hope tipsy elves wins.

Speaker: SPEAKER_01
Transcript:  So if you if you use tipsy elves as a show title, are you are you?

Speaker: SPEAKER_02
Transcript:  Only if I tell people to buy tipsy elves, ugly Christmas sweaters, not ugly  Christmas sweaters, ugly Christmas sweaters.

Speaker: SPEAKER_00
Transcript:  You know, one aspect we haven't touched upon.  What about when everybody's got a Google Home or a that's right?  Sorry, shouldn't have said her name canceled.  She's talking right now.  An echo, etc.  Now you say, show me, you know, a product or whatever it is, it's just going to come  in, you're not going to get a list to choose from.

Speaker: SPEAKER_01
Transcript:  You're absolutely right.  Absolutely right.  And and and that's an issue all around is that is that is the how do you are you  are they going to sell that position?  Google's never sold search.

Speaker: SPEAKER_02
Transcript:  Amazon has Amazon has implied that it will sell its echo results.  In some way, they said they've already said we're going to we're we're going to  do some sort of ad sales around Echo.  That doesn't mean they're going to sell the recommendations.

Speaker: SPEAKER_01
Transcript:  So if you're Kevin and you ask for deodorant, I don't know why I came up with that.  Yeah.

Speaker: SPEAKER_02
Transcript:  What Amazon will do is to say now what it does right now, if I say I need I have  stinky pits, Amazon Echo, get me some deodorant.  Amazon Echo, get me some deodorant.  It was it right now will say in your prime in your prime search results, you know,  what you've bought before is this.  But what if it said in the past, you've bought this.  But what about this?  We've got a great deal.  How about a coupon for this?

Speaker: SPEAKER_01
Transcript:  Well, in fact, if you say to Pepsi, somebody searches for Pepsi, then you can buy the  opportunity to push Coke.  Yes.  Which is which is a holy grail.

Speaker: SPEAKER_02
Transcript:  Amazon is currently, according to CNBC and talks with Clorox, Procter & Gamble and  others to promote their products on Echo.  They've they're testing various ad types, including videos and promoted paid search  results.  So this is exactly what you were talking about.

Speaker: SPEAKER_01
Transcript:  It's also a huge issue for media.  How so?  You know who?  Give me the news.  Right.  Well, who do you want?  And you can you can go on Google and you can choose places.  But that's like doing my Yahoo.  Nobody ever did that.

Speaker: SPEAKER_02
Transcript:  So for for for the new Apple HomePod, if you say that to hey, slow mo, she will say I'm  playing NPR.  But if you want me to play Fox News or CNN, let me know.  That's right at the first time you'd play news.  And from then on, you don't get a choice.  Cameron, I'm going to do it.

Speaker: SPEAKER_01
Transcript:  I'll turn the mic.  Do you have a home?  Give me the news.

Speaker: SPEAKER_02
Transcript:  NPR News.  Yeah.  Is that home pod or Amazon?  That's of course not.  I didn't think it was.  I was kind of interested.

Speaker: SPEAKER_01
Transcript:  It's my Google home.  Yeah.

Speaker: SPEAKER_02
Transcript:  So how dare you?  How dare you?  I have them all.  In fact, I have a stack.  I have a Google Home Max.  And on top of that, I have an Echo show.  And on top of that, I have the HomePod.

Speaker: SPEAKER_01
Transcript:  And are they leaving rings on each other?  Yeah, you can.  All the way down.

Speaker: SPEAKER_02
Transcript:  That's my by the way.  That's my joke is I don't have to worry  because like any sensible person,  I put a HomePod on top of an Echo.  Actually, I put it on top of the Sonos.

Speaker: SPEAKER_01
Transcript:  So you were going to change subjects  a while ago.  I was going to talk about  I stopped you.

Speaker: SPEAKER_02
Transcript:  Lincoln betting, but I can't find the here it is.  This in the EFF is all in a tizzy.  Federal judge says embedding a tweet  can be a copyright infringement.  Did you see this?  This is this is tizzy worthy.  You bet.  Tizzy, tizzy worthy.  So a photographer is upset.  Justin Goldman, he put on Snapchat  a picture that he took of Tom Brady.  Somebody tweeted his Snapchat picture,  at which point Breitbart, Time, Yahoo,  Vox Media and Boston Globe, among others,  retweeted the tweet with his picture in it  without giving him credit.  Goldman is suing saying or sued,  saying those stories infringe my copyright.  Now, this is not settled yet  because this is he asked for a  I guess the newspapers asked for  a summary judgment, and the judge said,  No, I don't think so.  We're going to trial on this one.  I think there's some merit in this.  Judge Catherine Forrest of which circuit?  I can't remember the New York circuit  said you can infringe copyright  by embedding a tweet in a web page  contrary to the longstanding  perfect 10 versus Amazon test.  She said this this test, which is whose server  does the infringing material  lie on is based in part.  On a Catherine Forrest  rejected the Ninth Circuit  server test based in part on a surprising approach,  I'm quoting the EFF to the process of embedding.  The opinion describes a simple process  of embedding a Twitter image,  something done every day by millions  of ordinary Internet users,  as if it were a highly technical process done by coders.  She says that process puts publishers,  not servers in the driver's seat.  When defendants cause the embedded tweets  to appear on their websites, their actions violated  the photographer's exclusive display right.  The fact that the image was hosted on Twitter's server  does not shield them from this result.  Watch out Internet.

Speaker: SPEAKER_00
Transcript:  So crazy, call me crazy.  But if you are going to share,  if I'm going to share a photo on a social sharing service.

Speaker: SPEAKER_02
Transcript:  Well, he shared it on Snapchat.  I don't know if he shared it publicly.  I'm not sure that's unclear.

Speaker: SPEAKER_00
Transcript:  Then don't share it at all.  Right, right. Right.

Speaker: SPEAKER_02
Transcript:  You know, sell it to get it.  But sharing it on Snapchat,  I don't think abrogates his copyright.

Speaker: SPEAKER_00
Transcript:  No, no.  And from a legal standpoint,  I understand and agree with you.  I'm just thinking, you know, just common sense.  We're setting ourselves up to fail and we forget  how easy these tools are to use, how much they're used  and what they're used for.  So. Absolutely.

Speaker: SPEAKER_02
Transcript:  So. So, yeah, I'm in a tizzy, too.  You're in a tizzy, too.  I think there's still going to be a trial on this, but I  I might be mistaken.  I think this was a lot of places to file friends of the court

Speaker: SPEAKER_01
Transcript:  applications in an appeal.  Yeah.

Speaker: SPEAKER_03
Transcript:  What it's like, I don't know.  This is spinning my brain because isn't a retweet  posting an embedded tweet like isn't it like wouldn't this trouble  the entire platform?

Speaker: SPEAKER_02
Transcript:  Yes. Oh, it'd be a huge problem.

Speaker: SPEAKER_03
Transcript:  Any sense for copyright to intervene in this way?  Because that is the fundamental technology.  And yeah, sharing and amplification  are part and parcel of that.  So I'm just like, like, I'm just like, you know,  I'm like looking into a mirror of a mirror of a mirror,  trying to understand, like, where would it even end  when it comes to sharing other people's thoughts  and commenting on them and the conversant nature of social media?  But yeah, if you do want copyright protections,  then you're best to watermark your photos and crop them  in such a way that if someone wants to use the whole thing,  they have to contact you directly.  You know, there are lots of ways in which people get paid for their content  and in those avenues are very clear.  And so what is not clear is the avenues that are,  you know, places where we know content production is intended to be shared  for free.

Speaker: SPEAKER_02
Transcript:  She, the judge at the end said, do not.  We don't view this as being a decision that will have global consequences.  She says there are a number of strong defenses  to liability that separate this issue, in particular,  genuine questions about whether the plaintiff effectively released  his image of the public domain, we posted it to Snapchat.  So she says is also a very serious and strong fair use defense,  defense under the DMCA and limitations on damages from innocent infringement.  So she's merely throwing out the summary judgment without without.  She's saying, I don't I think she doesn't want to set a precedent.  It's an interesting it's an interesting decision, though, and interesting to read.  Not not the least of which, because her first sentence says,  when the Copyright Act was amended in 1976, the words Tweet,  Viral and Embed invoke thoughts of a bird as a disease and a reporter.  This is a tech savvy judge.  Decades later, they've taken on new meetings.  Yeah, there is the EFF was upset about the way she understood embedding.  But I don't know if she's I don't I don't know.  This interesting anyway. Not over yet.

Speaker: SPEAKER_03
Transcript:  Well, like, shooting is different than taking a screenshot, right? Right.  And so in proper attribution, then.

Speaker: SPEAKER_02
Transcript:  Well, to the tweeter, not to the photographer.  So then the first violation is really from the person  who took it from Snapchat posted on Twitter.

Speaker: SPEAKER_01
Transcript:  And it's a section 230 question of the safe harbor. Right.

Speaker: SPEAKER_02
Transcript:  And no, Twitter is not a defendant in this. Right.  The publishers who retweeted the tweet are the defenders.

Speaker: SPEAKER_01
Transcript:  Defend because they they they purposely did not.

Speaker: SPEAKER_02
Transcript:  They were they not with knowledge, took that picture and retweet,  let's say Time magazine is one of the defense retweeted that tweet.  So it's an interesting case.  I'm sure we'll be talking about it on Friday and this week in law.  Now, here's the good stuff. Google does.  Google, I can predict heart attacks just by looking at your eyes.  Now, I know all the privacy advocates are going to say, oh, that's terrifying.  This comes from this comes from Verily, Google's life extension moonshot.  They can use photographs of the retina to predict factors for cardiovascular disease.  It works about as well  as currently used predictive methods and is far less invasive.

Speaker: SPEAKER_00
Transcript:  Right. We we actually talk about this on tomorrow's IOT podcast.  Just because of the machine learning aspect of it,  because that's what they've done here.  They have gone back and scanned the retinal images of prior patients from years back.  And then knowing five years later that those same patients did have heart disease,  they looked for the signs in the retina.  And then now apply that through machine learning to current retinal scans.  And they come up, I think it was 70 percent accuracy in the current.  Right. And it's 72 percent if they take blood,  which is how today's typical process works.

Speaker: SPEAKER_02
Transcript:  So here's the based on the eye scan, the algorithm was able to predict a person's  age to within three and a quarter years, smoking status with 71 percent accuracy  and blood pressure within 11 units of the upper number reported in the measurement.  And using that data, they could then predict major cardiovascular events.  Huh? Huh. With with, as you say, 70 percent accuracy.  That's very interesting.

Speaker: SPEAKER_01
Transcript:  This technology is not so bad.

Speaker: SPEAKER_02
Transcript:  Yeah. Until your insurance company starts taking pictures of you on the street,  looking to see if you're going to have a heart attack and denies you,  sends you a picture with their red light camera saying, sorry, Jeff,  you can't get a insurance because we could see from your eyes.  You're going to get sick.

Speaker: SPEAKER_03
Transcript:  That is very panoptic, Leo.

Speaker: SPEAKER_02
Transcript:  Hey, I'm all about the panopticon, man.

Speaker: SPEAKER_03
Transcript:  A bad path on the show.  One of the things that is intriguing to me about networked medicine and medicine  derived from A.I. at this stage is, you know, a lot of people gave those samples  and never really were informed of the uses and the possibilities for what.  You know, so I'm wondering, you know, did at any time the people who's had  their retinas scanned and their medical records released, you know,  what is the process by which Google created and contained that data set?  Because there's a lot of questions in medicine, particularly that raise those  very concerned concerns, which is that we have the Health Insurance Privacy  and Portability Act for a reason, which is that we are somewhat suspect  of corporations finding out our health information and using it against us.  And so to me, you know, this leads to a different, you know, this is a similarly  bad path, but I do wonder, you know, how that data set was generated.

Speaker: SPEAKER_01
Transcript:  Joan, there was a case in the UK not that long ago where there was data that would  have enabled the prediction of kidney disease that was disallowed because that  was not a use that was anticipated when the data was gathered, which sends me  into a tizzy because you can't anticipate it in a rule of A.I.  You by definition are not anticipating all future uses of data because you don't  know what you're going to see.

Speaker: SPEAKER_03
Transcript:  Yeah.  And, you know, there's I mean, there are ways when you go to the hospital, you  sign, you know, that research is, you know, part of, you know, if you get a  biopsy, often your blood that's collected is they only need a tiny, tiny bit of it  to run those tests.  And then the bio waste, as it's called, circulates in in a tissue economy.  And there's a heavy price on that bio waste in order to make those scientific  findings. And so I'm interested to think about, you know, what is the waste of our  X-rays and of our scans and of our MRIs?  And how is that being how is that comprising a market at this point?

Speaker: SPEAKER_02
Transcript:  So here's an interesting story from the information.  What if you were a little startup?  Maybe you have a smart lock and you took money from Amazon's fund, investment  money to help you work better with Amazon's Echo.  Then what if Amazon came along and made it a hundred million dollar offer to buy  you an offer you considered too low.  So you turn it down.  Then what if Amazon came along and said, well, we're just going to build our own  and announced Amazon Key.  That's what happened to August.  And I know, Kevin, you know all about these.  In fact, I think Stacey loves the August locks, right?  I can't remember.

Speaker: SPEAKER_00
Transcript:  She yeah, she does.  She does. And it's a great lock.  This it's interesting that this is coming up with August only it's a timing thing  because they were just purchased by the people making out locks.  Yeah, right.  One hundred fifty million.  But one of the less recent instances of this was a company called Nucleus.  And they made with the fund backing they made cancel.  Sorry. They made.

Speaker: SPEAKER_02
Transcript:  I'm sorry, too, but we can't call it the Echo Fund because that's not its name.

Speaker: SPEAKER_00
Transcript:  Right. They they made a touch screen device, probably about eight inches square.  It would hang on your wall.  You could do video chats with it.  It would integrate with the Echo Voice Services to provide data and so on and so  forth. Then you could play music from it and whatnot.  Well, doesn't that sound a lot like the Echo show?  Yeah. Yeah, because that came out after Nucleus got their funding from Amazon  and tried to put the product out.  And then the show came and basically the nucleus people were like, what just

Speaker: SPEAKER_02
Transcript:  happened? Amazon said, of course, told the information the company doesn't use  information gained through investments to help it develop a competing product.  But if we should happen to learn a thing or two, what would it height?  The information also tells a story, of course, of in from imagination  technologies, which is a GPU company that made graphics processors for Apple.  Apple hired a few of their employees, considered buying the firm and then just  said, no, we're going to make our own by an imagination is pretty much gone.  Interesting. You know, these companies are so big and so powerful.  At the same time, you don't want to you want to reward them for the reason  they're big and powerful.  They're the reason they're big and powerful is they're changing the world.  They're making great products.  They didn't get big and powerful by screwing people.  Or did they?

Speaker: SPEAKER_03
Transcript:  Well, in that case does prove that point.  What's interesting to me as sort of a scholar of technology is to think about,  you know, when you talk about a smart home, so if you're making a product for a  smart home, you start to think about, OK, so what are the things in the home  people are going to want to control?  Temperature, definitely the locks, you know, ventilation.  If they're if they have a swimming pool, the you know, if the you know, if the  filters on and off, right.  So they're, you know, the electricity.  Do you want to be able to shut the lights on and off?  And so it's not outside the bounds to reason that if you are someone that's  building a smart home technology, that locks would be on your list of things to do.  Yeah. But at the same time, you know, if you make a play and you get caught,  you do have to own up to that and say, well, we knew this technology was already  built and we didn't want to have to build it from the ground up.  Or they wanted to, you know, to me, this is anti-competitive in the sense that  they know that this is a rising star on this market and they want to acquire and  then probably kill.

Speaker: SPEAKER_02
Transcript:  Right. But at the same time, I mean, I think about what Facebook did with  Snapchat. They you know, Facebook's pattern is to buy competitors like Instagram,  like WhatsApp and fold them into the Facebook family.  That way, if you're going to leave Facebook to use WhatsApp, well, at least to  be using a Facebook product when they couldn't buy Snapchat, they just they  enhanced Instagram to beat Snapchat.  And it worked, by the way, it seems to be working.  But then I don't I don't doesn't feel like that's illegal.  That's just that's competitive.  So this is the problem. It's hard.  And boy, Microsoft's famous for, you know, engulf and devour when I can remember  what the term was we used to use about Microsoft.  But that was the idea. They would do exactly the same thing.  They'd pretend to want to buy a company.  They'd find out all about it.  Then they'd not buy them and do something competitive.  But Microsoft was famous for being a hard charging competitor.  Bill Gates always wanted to win.  He played really hard and you want companies to play really hard.  But so it's a it's tricky.

Speaker: SPEAKER_03
Transcript:  Yeah, there's that. And then, you know, ultimately, they can't be everything  to everyone. Right.  And so part of it is is understanding as they expand the possibilities  of these technologies and get into different markets and aggregate,  you know, all of these users into a very large  platform, that also makes it really difficult for anyone new  to step into the market in in in small  sections or subsections of those technology spaces, because  starting up a technology company is extremely expensive.  And so one of the things that not only do you shift  the kinds of innovation that are possible,  but you also really limit the product space in a way that,  you know, it'd be nice if if we had, you know, many different  phone cameras to pick from and that we, you know,  instead of having just a few that work well.

Speaker: SPEAKER_02
Transcript:  Here's a New York supermarket, Tops  files bankruptcy sites, debt and Amazon.  I might just be a convenient, a convenient fall guy.  Yeah, it's debt. We had a lot of debt. Oh, and Amazon.  It's got to be. I mean, if you're if you're a brick and mortar store,  if you're selling anything on the Internet, if you're doing any commerce of any kind,  you even if you're just doing health health insurance, you got to be worried  about Amazon in every respect.  But that's ultimately good for consumers as long as they play fair, I guess.  Is that it play fair?  We just don't know if they are. That's I think it's hard to know. Yeah.  That's why we have courts.  Let's see. Samsung S9.  We're going to have live coverage on Sunday.  Father Robert Balasare and Ron Richards begins 9 a.m.  Pacific noon Eastern time of the Samsung event  in Barcelona from Mobile World Congress.  They are expected to announce a new S9.  For a lot more money with dual lenses.  The FCC is inspecting Agile Pile.  We already talked about that. I just can't resist bringing it up again.  Let me say that again.  The FCC is is investigating its own chairman.  Because, well, it's a little suspicious that the FCC  at his behest dropped their media ownership rules  right before Sinclair  announced its intention to buy Tribune Media for three point nine billion dollars.  What do they know and when do they know it? Right.  That's always the question.

Speaker: SPEAKER_03
Transcript:  Yeah. All right.

Speaker: SPEAKER_02
Transcript:  I could tell you're losing energy, so we're going to take a break.  And we will wrap this up with your any picks or plugs or tips or tricks.

Speaker: SPEAKER_01
Transcript:  Any any did we just mention that Daymore lost his case against Google?  Yeah. Record. Yes.

Speaker: SPEAKER_02
Transcript:  Yeah. For the record.  Let the record show just let the record show that  the National Labor Relations Board says, no, you can't create a hostile environment.  Sorry. That's a good reason for getting fired.  Mm hmm. Jimmy.

Speaker: SPEAKER_03
Transcript:  Yeah, and there was a very interesting Q&A that happened with him.  He was on a panel at Portland State University  either late last week or over the weekend.  And I watched the Q&A on YouTube and students had some pretty strong  criticisms of the biological theories that he was using to support.  Oh, good. His position that women  aren't excellent coders and engineers.  And so I was really proud of the students that stood up to him,  as well as stood up to the moderator and his co-panelist and said that,  you know, we have a history of scientific racism  and we thought that was good data at the time.  And now we have you picking and choosing certain  biological data to support your case.  And how should we know that this is verified and trusted data?  And so I think the students are taking a really critical approach  to thinking about what DeMore was trying to push in terms of a public conversation.  And I don't think they're taking the bait. Yep.

Speaker: SPEAKER_02
Transcript:  OK, anything else? Any last?  I just want to get that one. I agree. I agree.  Jeff, prepare your number.  Kevin, if you've got a IoT device, we should all be buying.  I've got my checkbook on the ready.  Joan, if you got a new troll and Joan, if you have any fake news  you want to spread getting I'm getting back

Speaker: SPEAKER_03
Transcript:  handled by a reporter at Politico who's chasing down a troll right now.  And I'm trying to help him in the midst of all this.

Speaker: SPEAKER_02
Transcript:  I love this. Joan Donovan, Troll Hunter. I can. Yeah.

Speaker: SPEAKER_03
Transcript:  This is a YouTube red series.  Once you know where they hang out, you know, they they're creatures of habit.

Speaker: SPEAKER_02
Transcript:  As we all are. I need to talk to you.

Speaker: SPEAKER_03
Transcript:  Yeah. You come hang out in the office. I'd love to have you.

Speaker: SPEAKER_02
Transcript:  I need some help. This is good. I like this.  Our show today brought to you by Rocket Mortgage.  If you are buying a new home, you probably are not bringing out  the checkbook to pay for it in cash. You got to get a loan, right?  A mortgage. Did you know the word mortgage comes from the French word for death?  I think it's I think the intention was more like  this is something you owe until you die.  But really, if anybody's ever gone to a bank to apply for a loan,  you understand where that derivation comes from. It's not fun.  That's why Rocket Mortgage came along from Quicken Loans, the best lender  in the country, number one in customer satisfaction year after year.  And I tell you, they're guaranteed to win that award again this year  because of Rocket Mortgage.  They put the entire mortgage process in your hands, in your phone,  literally in your hands.  You don't need to go to a bank.  You don't need to go to the attic to find paperwork.  All you need is to go to rocketmortgage.com slash twig.  Answer a few simple questions.  Allow them to contact your financial institutions.  They're all trusted partners.  And boom, based on your income, assets and credit, they crunch the numbers.  And in minutes make you an offer.  You can choose the rate, the term, the down payment.  It's all up to you.  It's completely transparent once you find a loan option you like.  They say, good, you're approved.  It's fast enough you could do it at an open house.  You literally get approved in minutes.  This is such a revolution compared to the old way of doing it.  Rocket Mortgage from Quicken Loans.  Apply simply, understand fully and mortgage confidently.  To get started, go to rocketmortgage.com slash twig.  Rocketmortgage.com slash twig.  They're an equal housing lender, of course, licensed in all 50 states  and MLS consumer access dot org number 30 30.  Rocketmortgage.com slash twig.  By the way, interest rates are, we know, going to be going up.  You would be behoove you to lock in a low interest rate with a refi.  So they do that to rocketmortgage.com slash twig.  Kevin, let's get a tip from Mr.  IOT podcast and IOT podcast dot com.

Speaker: SPEAKER_00
Transcript:  Oh, can it can it be more Chromebooky?  Yeah.  Heck yeah. Google show.  Heck yeah. Jeff lives on his Chromebook.  He loves his Chromebook.

Speaker: SPEAKER_02
Transcript:  Are you Kevin, let me ask you, do you use a Chromebook like Jeff does exclusively?  Is that like your go to?

Speaker: SPEAKER_00
Transcript:  Well, it wasn't up until about two weeks ago.  Oh, when I was working at Google, I was using a Chromebook.  I either my own Chromebook Pixel or a work issued Chromebook.  And then I got away from it for a while.  But with my free time lately, I've been doing online coding.  And I'm like, oh, that that how am I going to  learn my programming classes and such with with the Chromebook?  Right. There's tons of cloud based programming things out there,  but they still just weren't doing it for me.  So, Jeff, I don't know if you're like learning how to code or want to.  It's really cool, I think. But that's neither here or there.  You can do it on a Chromebook pretty easily if you use the secure shell web app,  which just find it right in the Chrome Web Store.  And what you do is one of the things you can do just by a cheap raspberry  pie for 30 bucks.  So what I did was I put a raspberry pie.  Actually, we're running our IOT voicemail that I built in Python on that.  And I just it's got Python installed.  And I just use SSH, the secure shell to log in.  And it's a very native experience in the Chromebook.  But here's the best part.  So I actually write my code using a text editor on the Chromebook.  Their native Chrome apps or that text or carrot or two are the decent ones.  I just save the files over to the pie on my network.  And the funny thing is the secure shell client allows for SFTP.  So I can mount the pie in the files app of the Chromebook.  So it's just right there. It's a beautiful thing.

Speaker: SPEAKER_02
Transcript:  Yeah. Well, I'm going to top you.  I'm going to give you I'm going to give you one that I used this SFTP for a long time.  But if you can, and since you do control your raspberry pie,  if you can control the server that you're logging into, put Mosh,  M-O-S-H on it and then get the Mosh Chrome extension.  It will look exactly the same to you.  It's still SSH. It's SS secure.  They have SFTP as well.  But what Mosh does is it preserves the connection.  So the one problem is sometimes the connection drops or whatever.  So your session is preserved across disconnections, across disruptions.  And it's that's handy. Yeah, I really like Mosh.  It's an open source project.  And actually, now I'm looking.  I know there's a Mosh extension because I use it on my Chromebook,  but I don't see it here.  But you have to put Mosh on the Raspberry Pi  because basically you're connecting with a Mosh server.  It's easy to do. It's you can do an apt get and get it.  But take a look at that as another option for a mobile shell.  Because it really helps. It's a little faster.  It just helps with the trickiness of doing what you're doing,  which is pretending that you're on the Raspberry Pi in effect.

Speaker: SPEAKER_00
Transcript:  Right. I'm actually blown away by how much the Android apps  and the Chrome OS experience has improved in the past year or so.  It's been still has little ways to go.

Speaker: SPEAKER_02
Transcript:  Just a little. Yep.  We love we all love our Pixelbooks, though, I think.  I do. Right. It's fair to say. Yeah.  I mean, when you spend that much money on a Chromebook,  you're better. You're better.  You better. And you're doing are you learning Python?  What do you plan with some Java, some Python?

Speaker: SPEAKER_00
Transcript:  Python just seems to be easiest for me to pick up these days.

Speaker: SPEAKER_02
Transcript:  It's a great language to start with. Yeah. Yeah. Very nice.  Mr. Jeff Jarvis, your pick of the week.  This would just be a little bit.

Speaker: SPEAKER_01
Transcript:  So analysts says on CNBC that Twitter and Snap  will grow at the expense of Facebook.  What just amused me about that is that how long ago was it?  About three weeks ago when, oh, Snap Twitter, they're nearly over.  Over. Over.  And now now suddenly the fortunes change.  So listen, analysts, I think is the rule.  Yeah.

Speaker: SPEAKER_02
Transcript:  Actually, Snap is not I like it that Snap is not giving up.

Speaker: SPEAKER_01
Transcript:  No, I do, too.  Gums should be the word for them. Yeah.

Speaker: SPEAKER_02
Transcript:  They're getting a lot of heat from more than a million users  who say, I hate the new interface.  But, you know, I think I think I should check the the change.org  petition, but the last time I checked it, I think we had something in the rundown

Speaker: SPEAKER_01
Transcript:  where you where you can revert or something.

Speaker: SPEAKER_02
Transcript:  Yeah, I don't know how well that works.  Here's how to reverse.  Yeah. Update on Android. In theory.  But, you know, yeah, you think that's not going to be on.  Oh, here's Snap's response.  One point two million signatures to Nick and all of the Snapchatters  to sign the petition. We hear you.  We appreciate you took the time to let us know how you feel.  We this is how a company should respond to these petitions.  They're explaining why they're doing it.  We are going to do some more changes.  The new foundation is just the beginning.  In other words, we're not going to do what you want us to do,  which is right, but which is very Facebook.  Oh, you know, at least they're responding.

Speaker: SPEAKER_01
Transcript:  Everybody hated the news feed and said, no, no.

Speaker: SPEAKER_02
Transcript:  Yeah, I think companies have to have a strong vision  and follow it.  So I'm going to make your number one point two, two, six, two, five, two million.  That's how many people  are signed the petition.  Joan, is there anything you'd like to plug or pick?

Speaker: SPEAKER_03
Transcript:  Yeah, so there was a book that came out today  that is really interesting for people who are interested in technology.  It's called Algorithms of Oppression, How Search Engines Reinforce Racism.  By Sophia Noble.  And so she's a information studies scholar at UCLA,  has been working on this book for several years.  And what's interesting is the way that she challenges  the notion of the algorithm here and then looks at  what are the inputs and outputs and how do search engines  discover and create and reinforce  the biases that we are all very familiar with related to racism  and sexism and homophobia.  And she's got some really interesting ways of doing search,  as well as of cataloging these instances and case studies.  And I should say that the kind of research that she does is  impactful in the sense that these Google and corporations,  they don't have teams devoted internally that are doing this kind of work  in the way that she does.  And so her research to me is really provocative in the sense that  it gets us an outsider's perspective on how to reimagine  what it means to serve, curate and distribute information.  And so, yeah, I'm really, really happy that the book is out  and available through Amazon.  And last I heard this morning, it was actually sold out right now.  And so I don't know if it's still true, but it's ranking, I think,  number one, according to your screenshot there.  So, yeah, and so it's a very popular book.  And there's already a lot of conversation on social media about it  and about what it would take to think about  an information first perspective on  and also to think about search engines as having dimensions  where people are affected or where groups are affected and where,  in a lot of ways, our most  our most harmful prejudices are are amplified.

Speaker: SPEAKER_02
Transcript:  Yeah, this is another approach to the same thing  we've been talking about the whole show, which is how these companies  affect us and and sometimes unconsciously affect us.  And I'm glad that people are doing the studies and looking and  and bringing it to the surface, because it's so easy to have unconscious  inputs and affect you and change your point of view in a way that's not right.  So I think this is really true.

Speaker: SPEAKER_03
Transcript:  And there are a series of questions in the book, even on the cover,  that if you were to search in autocomplete to this day, certain keywords  and questions, you know, I know that Google is working on the problem,  but definitely hasn't solved for it. And so  what's dangerous about the autocomplete in that sense is it  is bringing you directly to biased information by suggesting it.  And I think that part of that has to do with the way people are asking questions  of the platform itself when they are searching.  And so it's a really interesting way of understanding  how society gets encoded into the algorithms.  So, oh, come on, Leo.  I have fun.  Are you an optimist? I hope you are.

Speaker: SPEAKER_02
Transcript:  I am. I am.

Speaker: SPEAKER_03
Transcript:  And I also picked out this book, which I should say is a very good read.  It's called The Witches.  We just talked about burning.

Speaker: SPEAKER_02
Transcript:  We just talked about burning people at the stake.

Speaker: SPEAKER_03
Transcript:  Well, this book has made me think a lot about  what it means to do fake news, because it's a really neat  historical take on the Salem witch trial.  And, you know, I grew up near Boston and had many, many experiences in Salem.  And so it was an excellent read from a historian,  which is called The Witches, Salem 1692, a history.  I want to read that. That sounds great.  It's yeah, it's really dense and goofy and everything I love about a good history book.

Speaker: SPEAKER_02
Transcript:  I was just reading somewhere that it's kind of that we kind of misunderstood  what happened in Salem, that we have a lot of myth, urban myths or legends  about it that are accurate. Mm hmm.  Well, I will read it.  Thank you for being here, Joan Donovan.  It works at Data and Society.  You could find her at data society dot net on the Twitter at Boston Joan.  She's Boston strong.  And I hope you got to talk with your aunt a little bit because we think I did.  Thank you.  Spending a little time with us instead of your family.

Speaker: SPEAKER_01
Transcript:  Joan, we appreciate you dumping your aunt for us.  OK, that's what I wanted to say.

Speaker: SPEAKER_03
Transcript:  Yeah. You know, right place, right time.  And so I appreciate you all having me on.  It's it's truly like always a pleasure.  You're a hit to be able to hang out and talk.  We love your brains.

Speaker: SPEAKER_02
Transcript:  It's nice to get your brains and boy, there's no your your  beat is the most timely beat there can be right now.

Speaker: SPEAKER_03
Transcript:  I know, I know. The work doesn't stop.  But, you know, I feel like a normal job.  You know, when I'm ready for retirement, I can start, you know, go.  I can go back to the university and teach my classes and, you know.

Speaker: SPEAKER_02
Transcript:  We need you on the front lines.

Speaker: SPEAKER_03
Transcript:  I know. I know.  It's a it's a strange job.

Speaker: SPEAKER_01
Transcript:  It's between you're all stands between us and Putin.

Speaker: SPEAKER_03
Transcript:  I still haven't evaluated that that claim.

Speaker: SPEAKER_02
Transcript:  Well, do some research, OK, and get back to us.  I will. You are your arsenal.  That's Jeff Jarvis, professor of journalism, City University of New York.  He's all that stands between us and the Harvard comma.  We are.  Oxford, Oxford, comma.  Actually, I'm sure you're a fan of the Oxford comma.  Yes, I am. OK, so it's the other way around.

Speaker: SPEAKER_01
Transcript:  Not just a fan, it's a it's a moral responsibility.

Speaker: SPEAKER_02
Transcript:  Yes, he's all the stands between us and hanging participles.  How about that?  That's what that bus machine dot com whatever happened to copy editors.  That's what I want to know.  Dang it. At Jeff Jarvis on the Twitter.  Gone, gone, gone, gone.  And he joins us every week.  You'll be back next week, I hope.  I plan to be. I feel happy.  I plan on it.  Maybe we get Stacey back to she's in Berlin right now with Bosch.  But she sent an able replacement in Kevin Toffler, a cohost on IOT podcast.  IOT podcast dot com at Kevin C.  Toffler on the Twitter.  Great to see you, Kevin.  Happy to be here.  Well, any new Beatles in news?  Anything worth like those all those Beatles documentaries on Netflix?  Anything good I should look for?

Speaker: SPEAKER_00
Transcript:  Nothing recent. Yeah.  Recent. I know Ringo had some reissues of his first albums and whatnot,  but I can't live without those, I think.

Speaker: SPEAKER_02
Transcript:  Yeah, I'll be OK without those.  I'll let him know.  I almost bought a turntable the other day.  I came this close.  Then I thought, well, then I have to buy records.

Speaker: SPEAKER_00
Transcript:  They make it easy.  Come out one whole set on Amazon, of course.  Yeah.

Speaker: SPEAKER_02
Transcript:  How many times have I bought the Beatles?  Actually, if I counted, it would be depressing.  Many, many, many.  That's a business model.  Yeah. Just keep buying it.  We don't have to make new music.  Just keep buying remixes.  Thank you, everybody, for being here.  We do this week in Google.  It's my last show of my week because now I take Thursday and Friday off  and I'll be back on Saturday.  But I do it about 1.30 Wednesday afternoon.  That's Pacific Time, 4.30 Eastern Time, 21.30 UTC.  You do the math.  You can watch live at twit.tv slash live.  If you're live, you should, by all means, go in the chat room.  And boy, the chat room has been great today.  As ever.  As ever.  IRC.twit.tv.  If you have an IRC client, you can use that.  But if you don't, there's a website and a web client.  But we do love having you in chat.  Thank you for being here.  You can also visit us in studio.  We had a nice studio visitor today who ran out of the room, ran out of the room.  No, he actually it's interesting.  He plays the Contra bass clarinet for the United States Navy Band.  He's performing at Sonoma State tonight.  And he just thought he had a little time and come and watch the show.  But I was afraid it was something I said he had to leave.  No, no, he has to go tune up his clarinet.  The reads on those Contra basses take a long time to moisten.  I don't know if that's true or not.  If you want to be in studio, please don't surprise us.  Please just email tickets at twit.tv so we can have a nice comfy chair set out for you.  Give you the roll out the welcome mat and all of that.  Tickets at twit.tv.  While you're at the website, twit.tv, don't forget our podcast, twit.tv slash twig.  On demand versions of the show available there, audio and video.  Of course, you can always subscribe either there or on any podcast client of your choice  and get it every single week automatically delivered to your phone or your tablet or your computer.  And man, I love these new voice assistants because you can listen to the show on every single one of them,  whether it's the Apple HomePod or the Amazon Echo or even like the Cortana device from Harman Kardon,  the Google Home device.  All you have to do is basically in most almost every case is say, I want to listen to  this week in Google or listen to twig and you should be able to get the most recent.

Speaker: SPEAKER_01
Transcript:  OK, Google. Play this week in Google.

Speaker: SPEAKER_02
Transcript:  This is going to be a very inception moment.  Yeah. Is it playing?  You didn't know it could do that?  No, I didn't. Oh, yeah. You can also.  Sorry. You can also listen to twit live in many cases, just say, say, listen to live.  Yeah, you know, the live stream.  Yeah, I think this is the biggest thing that's ever happened to podcast, frankly, is this.

Speaker: SPEAKER_00
Transcript:  Yeah, Jeff, you could just hold that up to the microphone and take the week off, you know.

Speaker: SPEAKER_02
Transcript:  Play last week's show and go.

Speaker: SPEAKER_01
Transcript:  Always says the same things anyway.

Speaker: SPEAKER_02
Transcript:  No, you don't, Jeffrey. You do not.  We are doing, I think, a few more weeks of the survey.  If you haven't done it yet, twit TV slash survey, because we don't collect information  about you like Google and Facebook, we don't know anything about you.  And sometimes it's nice when an advertiser says, well, do any women listen  to be able to say, yes, there are a couple.  So go to twit dot TV slash survey and fill that out.  Represent. Let us know.  Yes. Thank you. Probably wrong, but I did it.  Yeah. You know what? We do it in aggregate.  We usually get more than 20,000 responses, so it'll dilute you.  Anyway, we don't save any information about you personally.  We don't share any information about you personally.  Don't worry. Your information is safe.  But it does help us a lot.  Twit dot TV slash survey.  Thanks for joining us. I'll see you next week.

