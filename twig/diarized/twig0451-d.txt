;FFMETADATA1
title=B055man69
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=451
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Failed to align segment (" ."): no characters in this segment found in model dictionary, resorting to original...
Speaker: SPEAKER_03
Transcript:  It's time for Twig this week in Google.  Stacey's got the day off, but Wendy Nader's sitting in for Stacey from Duo Security.  Also, Ant Pruitt stops by and Jeff Jarvis.  We will talk, of course, about Facebook.  Jeff and I are going to get in a big fight over this one, I can tell.  And Google and a whole lot more.  I want you to stay tuned.  This is a fun one.  This week in Google's next.

Speaker: SPEAKER_04
Transcript:  Netcasts you love.

Speaker: SPEAKER_05
Transcript:  From people you trust.

Speaker: SPEAKER_02
Transcript:  This is Twig.

Speaker: SPEAKER_03
Transcript:  Bandwidth for this week in Google is provided by Cashfly.  C-A-C-H-E-F-L-Y dot com.  This is Twig this week in Google.  Episode 451 recorded Wednesday, April 4th, 2018.  Bossman 69.  It's time for Twig this week in Google.  The show where we talk about so much more than Google.  It's really poorly named.  Facebook, of course, is going to be a big topic today and almost every day, every week this year.  But also Twitter and whatever else we want to talk about.  Stacey's got the day off.  That's good news.  It means we have room for other people, although we will miss Stacey.  Jeff Jarvis is here.  It's great to have you, Jeff.  Hey, good to be here.  Where he teaches journalism.  BuzzMachine.com is his blog.  So many books.  Public parts.  What would Google do, et cetera, et cetera.  Ant Pruitt is also with us.  Ant is a contributor to Tech Republic.  He's been on Twitter before.  I don't think he's ever been on Twig before.  So it's great to have you, Ant.

Speaker: SPEAKER_02
Transcript:  Thank you for having me.  Yes, sir.  This is my first time on Twig.

Speaker: SPEAKER_03
Transcript:  A drone operator at Par excellence who has told me I should never again get a drone.  He's also a great photographer.  Not for you.  Great photographer and a Clemson fan.  And always a pleasure to have Ant on.  And for the first time on the show also, but thrilled to have her, Wendy Nather.  She is a CSO, what a chief information security officer.  And in fact, runs the advisory CSOs group at Duo Security, which is a great security firm.  Well, welcome, Wendy.  Great to have you.

Speaker: SPEAKER_01
Transcript:  Thank you.  Good to be here.

Speaker: SPEAKER_03
Transcript:  Wendy was on our panel, Stacey and my panel at South by Southwest last month.  And I met her and I said, we've got to get her on.  In fact, we were slowly getting everybody on.  I met in Austin.  By then, because I had such a good time.

Speaker: SPEAKER_01
Transcript:  Despite the KSO jokes.  I'm really sorry about that.

Speaker: SPEAKER_03
Transcript:  Despite the KSO jokes.

Speaker: SPEAKER_05
Transcript:  Aha.

Speaker: SPEAKER_03
Transcript:  Aha.

Speaker: SPEAKER_07
Transcript:  Wendy, Wendy, it's a test.  Have you had Taco Bell queso?  I mean, Chipotle queso?

Speaker: SPEAKER_01
Transcript:  A Chipotle, the Chipotle queso.  No, I haven't tried it.  No.

Speaker: SPEAKER_07
Transcript:  She lives in Austin, Jeff.  This is for your protection.

Speaker: SPEAKER_03
Transcript:  Don't do it, Wendy.  Don't do it.  Do they even bother having a Chipotle in Austin?  Now they do, which is weird, but I don't know.

Speaker: SPEAKER_01
Transcript:  We do right across from the Duo building, as a matter of fact.  Oh, wow.  We've got one.  Yeah.

Speaker: SPEAKER_03
Transcript:  So you had an opportunity, but you've been wiser than that.

Speaker: SPEAKER_04
Transcript:  Wisely declined.

Speaker: SPEAKER_01
Transcript:  It's not your concern anymore.

Speaker: SPEAKER_04
Transcript:  Oh, she's going to do it again with those puns.

Speaker: SPEAKER_03
Transcript:  Uh-oh.  So Jeff, you just got off a conference call  that Facebook had with reporters.  What was the, what was the, well, there's  a few pieces of news about Facebook  we might as well mention.  Mark Zuckerberg will be testifying  in front of Congress a week from Thursday, April 11.  Excuse me.  That's actually next Wednesday.  Oh, it's Wednesday.  Sorry.  Yeah, he's going to testify before the House Energy  and Commerce Committee.  That'll be very interesting.  Preparatory to that, Facebook's been getting very active,  talking, oh, you know, before I even bring up Facebook,  I forgot.  We really probably should mention.  Our thoughts and prayers and hearts and mind  go out to our friends at YouTube in San Bruno.  Of course, there was a shooting yesterday.  The good news, it looks like nobody except the shooter  died in that shooting.  So that's relatively good news.

Speaker: SPEAKER_07
Transcript:  It's so unnerving to see someone you know.  I saw Vadim Lavrusak tweeting that he was holed up  in a closet in a room because there was an active shooter.  And you see that, and it brings it all the more home.

Speaker: SPEAKER_03
Transcript:  The weird thing about Vadim is her account was hacked.  And that, I mean, his account was hacked.  His account.  Some of his account, some of his tweets  were in fact fake during the event.  But I think the closet one was real.  So it was real.  There was a mix of tweets on his account.  But you know him.  Yeah, that was a very strange thing.  Actually, one of the stories about all of this  is how instantly Russian trolls, bots, bad actors in general  jump into the fray to create a mass of phony news,  phony stories, phony tweets.  They're like predators now, just leaping into the action.  It's sickening.  It's depressing.

Speaker: SPEAKER_02
Transcript:  It makes you wonder, what can Twitter do about that?  Because that's just going to continue to happen.

Speaker: SPEAKER_03
Transcript:  Yeah, I mean, his account was hijacked  while he was still near the scene of the attack.  It was 20 minutes after Lavrusak reported himself safe.  One of the tweets leaked to a picture of a popular YouTuber  saying, please help me find my friend.  I lost him in the shooting.  That's just, I mean, there's something  wrong with these people.  Twitter immediately jumped on it and removed the hoax tweets.  And then even though more hoax tweets came in,  eventually, I think, cleared it up.  So somebody was sitting at Twitter watching  with a finger on the button.  Anyway, just our thoughts are with all of our friends.  Yeah, that's all the worse that it's someone

Speaker: SPEAKER_07
Transcript:  who was disgruntled with YouTube, who  decided to go after YouTube.  And when everyone is public, anyone  can become a target of this kind of public rage and sickness.

Speaker: SPEAKER_03
Transcript:  I was actually a little disheartened.  Maybe it's inaccurate.  But I'd heard that there wasn't much security at YouTube.  She got in through a public parking garage.  She didn't need a badge or anything.

Speaker: SPEAKER_07
Transcript:  I find that hard to believe.  I mean, I have been to YouTube's offices in the years.  But at Google, by god, you cannot tailgate.  You are checked.

Speaker: SPEAKER_03
Transcript:  Good.  I mean, any media company these days has security.  Our doors are locked.  We have an armed guard at the door, an armed guard,  a former Marine at the door.  He's got both lethal and non-lethal ways  of stopping people and will.  And it's really important.  In fact, because of this, Mo told me  he's going to be doing some exercises on, what do you call  it, active shooter exercises.

Speaker: SPEAKER_07
Transcript:  Yeah, that's very heroin.  I've gone through that in my school.  And it really is disturbing.  It's a shame that we have to do this,

Speaker: SPEAKER_03
Transcript:  that we live in this world.  It's so sad.  But this isn't even a gun control conversation.  She owned the gun.  It was a handgun.  It wasn't.  It's just sad.  It makes me so sad.  Anyway.  It's the fact that someone thinks

Speaker: SPEAKER_02
Transcript:  it's OK to go in and cause serious harm on another human  being.

Speaker: SPEAKER_03
Transcript:  Well, she was obviously disturbed.  She was a vegan.  She hated cruelty to animals, but she'd go shoot humans.  Obviously, this is a disturbed person.  It's not.

Speaker: SPEAKER_07
Transcript:  Yeah, his father had reported this to police.  The police had talked to her.  But the laws are such, too, that until you've done something,  it's the terrible paradox of our harm laws.  You can't stop them until they've done something,  and then it's too late.

Speaker: SPEAKER_03
Transcript:  We have a fan who unfortunately has some mental illness issues  who has threatened me many times.  And I've talked to police about it.  They know about it.  It's nothing you can do.  Yeah.  Nothing you can do.  It's unfortunate.  Yeah.  Anyway, so there's nothing much to say except how sad that is.  And I don't know what you do.  This is the way it is in the world today.  Now, on to Facebook.  Among other things we learned today,  that Facebook has just told, maybe it was on this call,  I bet it was, told reporters that, oh, it  wasn't 50 million people.  Cambridge Analytica had information on it was 87 million.

Speaker: SPEAKER_07
Transcript:  It was before the call.  But what Zuckerberg did say on this call  was that the 50 million figure never came from Facebook.  That they wanted to, and they should have said,  we're not sure about that number.  But they did the research and said that today,  said that they looked at the maximum number of accounts  that could, one person plays the game, all the people,  this is back in 2014, all the people who  were friends with that person, their public data  could have been scraped at the time.  What was the maximum number of friends  each user of that game had at that,  or that quiz had at the time?  And that leads to the 87 million.  And he said that's the maximum they believe.  That's the first number they came out with.  He was also asked about, again, this goes back to 2014.  They were told that the data had been deleted.  They got rid of the app.  And so on at the time, but more learned since.

Speaker: SPEAKER_03
Transcript:  April 9th, Monday, Facebook is going to notify  what people who were exposed to this?

Speaker: SPEAKER_07
Transcript:  Let's be clear here.  This was your public data.  So a researcher was able to get access to through the API,  easily, but nothing you probably couldn't have done  through search, to the public data that you had  in your account at the time.

Speaker: SPEAKER_03
Transcript:  All of your, for instance, all of your likes are public data.  Your likes, right.  And Cambridge Analytica was particularly interested  in likes because it turns out with enough likes  on any individual, you can predict fairly accurately  a lot of things about that individual,  including their mental state, their political views,  their race, their religion, their sex, on and off.

Speaker: SPEAKER_07
Transcript:  And I worked with media companies at the time  that were eagerly doing the exact same thing.

Speaker: SPEAKER_03
Transcript:  Sure, and don't you think people still are?

Speaker: SPEAKER_02
Transcript:  That's what I wanted to ask.  Where do you draw the line?  Because it seems like every online business,  or heck, just broadcasting company or whatever,  they have to do some type of data analytics  and they're going to go out and scrape  whatever they can scrape.  You're right, I mean, heck, even the Twitter network  does an annual survey.  Well, that's voluntary.  I should point out.

Speaker: SPEAKER_04
Transcript:  We go to you and say, take it if you want.

Speaker: SPEAKER_03
Transcript:  Advertisers want that information,  but that's kind of the rock and hard place  that a lot of media companies are in between radio and TV.  They don't know that much about their viewers  and that's one of the reasons.  What is it, 80% of advertising is now snarfed up  by Google and Facebook?

Speaker: SPEAKER_07
Transcript:  No, I don't think it's 80% of advertising.  It's a large number.  It's that much growth in advertising goes there  because they can offer that.  And you're right, if you go back when I worked  in the old ancient days of magazines and worked at Time Inc,  they had data from you in places like Axiom,  big data warehouses, where they had tons of behavioral data  about you as an individual with your name and your address  and your phone number and your credit card number  going way back.  In some ways, there's actually less data available  through the social platforms when it comes to  that kind of PII and behavior.  Facebook and Google.  Now there's more analytical ability to now say,  what are these likes and what are your habits say about you?  In the old days, you drove a Volvo.  You were liberal.

Speaker: SPEAKER_03
Transcript:  According to Pivotal, Facebook and Google account  for 73% of all digital advertising in the US.  Digital, yeah.  Big difference.  Yeah, but I would be willing to venture  that a lot of broadcast advertising's moving digital.

Speaker: SPEAKER_07
Transcript:  Oh yeah.  The other thing that Zuckerberg said today  was the report yesterday that he had told Reuters  that he would not be extending Europe's GDPR privacy  regulations to the world.  That's a little disappointing.  He said that was, see, you're already heading down  the fake news path there, Leo.  You're already heading down the presumptions.  Zuckerberg said today that that was not true.  What he told the reporter was that yes,  they'd be extending the standards of GDPR globally.  He said they're gonna be different in some countries  in how it's done because there's different laws and stuff.  They would be setting the standards of GDPR globally.  That's a very good point.  He told that to the Reuters reporter.

Speaker: SPEAKER_03
Transcript:  So the reporter just misreported it.  That's what Facebook is saying.  Okay.  You'll forgive me if I don't fully trust everything  that comes out of Mark's mouth.

Speaker: SPEAKER_04
Transcript:  I know he's a nice guy, I'm sure he is.

Speaker: SPEAKER_07
Transcript:  The other weird moments were when,  and I listened into the whole call,  that's why we're delayed starting.  No, I'm glad you did, yeah.  And so then I thought awkward moment.  The FT reporter asks,  well has your board of directors discussed  whether you're the right person to lead the company?  Beat, pause.  Zuckerberg said, not to my knowledge.  That is another reporter.  NPR reporter basically asked the same thing again.  They're going after, they're trying to fuel  this narrative of firing Zuck.  Then a Buzzfeed reporter.

Speaker: SPEAKER_03
Transcript:  Did Zuck act, pause, as if he had not heard that?

Speaker: SPEAKER_07
Transcript:  No, it's kind of shocking to,  somebody's asking you that to your face.  Does your board think you should be fired?  Leo, does Lisa think you should be fired?

Speaker: SPEAKER_03
Transcript:  Probably.

Speaker: SPEAKER_07
Transcript:  There's a little bit there.

Speaker: SPEAKER_05
Transcript:  Almost certainly at times.

Speaker: SPEAKER_07
Transcript:  Certainly from loading the dishwasher, yeah.

Speaker: SPEAKER_03
Transcript:  Well, I mean, so,  does Mark sit in on all the board meetings?  Is he?  Oh sure, I'm sure.  He's on the board, but I mean, I wonder.  Yes, except for executive session.  I wonder though, yeah, I wonder if,  yeah, I mean, I wonder if the board might say,  Mark, could you leave the room?  We'd like to have a private conversation.

Speaker: SPEAKER_07
Transcript:  Every board meeting I've ever been a part of,  there is always executive session built in.  Yes.  And you don't sit in on a compensation committee  here. Exactly.  It's an executive session.

Speaker: SPEAKER_03
Transcript:  Yeah.  And he's not in on those.  And yeah, and they don't have to say  what they're going to talk about.  It's normal.

Speaker: UNKNOWN
Transcript:  No.

Speaker: SPEAKER_03
Transcript:  So he doesn't know.

Speaker: SPEAKER_07
Transcript:  The other thing that was interesting  was a BuzzFeeds reporter.  And BuzzFeed depended greatly on Facebook  and now it tends to be a little bit bitter  because of the public content shift.  And so the BuzzFeed reporter said,  this is wonderful naivete of the journalist.  Well, couldn't you, everything would be better  if you just made less money.  Oh my God.

Speaker: SPEAKER_03
Transcript:  Yeah, everything would be better  if we all made less money.  Mark should just say, wouldn't it be better  if you made less money?

Speaker: SPEAKER_00
Transcript:  Good boy.

Speaker: SPEAKER_07
Transcript:  Tristan Harris has been out there attacking Facebook  along with Roger McNamee.  I was at sessions where Tristan goes further  and says, get rid of all advertising.  That's the solution.  How? How is that?  Well, exactly.  And then I did a post last week  and I started it all.  At the end of the post,  I'm very demanding of Facebook in a lot of ways.  But at the beginning, I took on Matthew Iglesias,  who's a very good political commentator at Fox.  But I took him on.  He was telling Zuckerberg to shut down Facebook.  Come on, people.  Come on.  It's got, this is what I talk about.  No, no, and why should it?  Even Steve Varinathian, who's wonderful  and who's doing a critical book on Facebook  coming out soon, he answers and says,  when you people say delete Facebook,  you're leaving, that's a position of privilege to say.  There are people who depend upon it.  Oh, that's BS.  I don't buy that.  You stay and fix it.  No, there are people in countries,  if you go to India, people depend upon Facebook.  You go to some countries,  and what he's saying is don't delete it, fix it.

Speaker: SPEAKER_03
Transcript:  Stay in impression.  No, I deleted it.  I'm sorry.  So equating Facebook with privilege is BS.  Facebook is, I mean, maybe it's a luxury.  It's a thing.  You don't need Twitter.  You don't need Facebook.  For crying out loud.  I don't buy that.

Speaker: SPEAKER_07
Transcript:  That's ridiculous.  Let's see, hold on.  The link is in there to see if it's post.

Speaker: SPEAKER_03
Transcript:  I mean, I can't claim to have a deep understanding  of why Facebook might be critical to life in India,  but I find that hard to believe.

Speaker: SPEAKER_07
Transcript:  Hold on here.  Let me go to see that.

Speaker: SPEAKER_02
Transcript:  I think about the use case of Facebook  with like my family back home.  That's all they use.  There's no phone calls.  There's always Facebook Messenger  or Facebook post or what have you  to keep in touch with all of the family that's abroad  that actually got out of town.  So you're saying if you were to delete Facebook,

Speaker: SPEAKER_03
Transcript:  you would just be disconnecting from them?

Speaker: SPEAKER_02
Transcript:  I have gotten rid of Facebook and deleted it.  I did so back in January.  And yeah, I don't hear from anybody in my family  except for my mother.  That's too bad.  I mean, it's just, it is what it is.  Facebook has turned into the telephone.

Speaker: SPEAKER_03
Transcript:  It strikes me that that's all the more reason  to delete Facebook, but okay.  Not because you want to disconnect from family,  but because we don't want to have a world  in which Facebook is a necessity.

Speaker: SPEAKER_07
Transcript:  So Siva wrote this in the New York Times, and I quote,  people in those countries, which is to say,  India, Egypt, Indonesia, Philippines, Brazil, Mexico,  people in those countries are getting value out of Facebook.  In some places, it's one of the few reliable ways  to keep in touch.  In much of the developing world,  Facebook is also the only news source that matters.  This should horrify us, but it's not a problem  that will be solved by indignant Americans  leaving the service.  Why?  Moreover, putting Facebook lets Google and Twitter  off the hook.  It lets AT&T and Comcast and its peers off the hook.  The dangers of extremist propaganda and hate speech  are just as brave on YouTube, which is owned by Google.

Speaker: SPEAKER_03
Transcript:  Okay, true.  It's a very good option.  Are you saying I can't quit Facebook  because unless I quit everybody else?

Speaker: SPEAKER_07
Transcript:  No.  No, he's saying- That's ridiculous.  No, he's saying you rich, white Americans says,  well, I did my part.  I quit Facebook for the world's fix now.

Speaker: SPEAKER_03
Transcript:  I agree.  I'm not gonna say I did my part or it's done  or I've done everything I can do for privacy.  No, but at the same time, you cannot give me any argument  that says I have to be part of that piece of crap.

Speaker: SPEAKER_07
Transcript:  You don't have to be part of it,  but to act like you've solved the problem by doing that.  No, I'm not saying that.  And that's why we're still talking about it.

Speaker: SPEAKER_03
Transcript:  But no, absolutely not.  But I don't think I'm gonna stay on Facebook  to save it from within.  That's an illusion as well.

Speaker: SPEAKER_07
Transcript:  He's not telling you to stay on Facebook.  He's telling you that to stand up  as people have been doing in their Twitter campaign  and trumpeting, we quit Facebook, is glib.

Speaker: SPEAKER_03
Transcript:  I just find it creepy  and I don't want anything to do with it.  There's no justification.  You could stay.  I'm not saying you should leave,  but I don't want to have anything.  I don't want to go anywhere near it.  And everything I hear about Facebook  makes me glad I'm not there anymore.

Speaker: SPEAKER_07
Transcript:  I quote his end.  So go ahead and quit Facebook  if it makes you feel calmer or more productive.  Please realize though,  that you might be offloading problems  under those who may have less opportunity  to protect privacy and dignity  and are more vulnerable to threats to democracy.  If the people who care the most about privacy,  accountability and civil discourse  evacuate Facebook and disgust,  the entire platform becomes less informed and diverse.  Deactivation is the opposite of activism, says Siva.  Couldn't disagree more.  And Siva is no friend of Facebook.

Speaker: SPEAKER_03
Transcript:  I love Siva a lot, but I couldn't disagree more.

Speaker: SPEAKER_02
Transcript:  Mr. Jarvis, now just listening to that.  And I think about the gazillion conversations  that I've tried to have with people  that were in my circles, if you will, on Facebook,  about privacy and about just being careful  with what's posted and what's being liked and so forth.  And about nth percent gave a crap.  Nobody cares outside of the,  you try to inform people and they don't care.  What they care most about is the,  this is me right now and this is the braggadocious,  be happy for me, or this is the woe is me,  y'all need to send out good vibes.  That's all Facebook is.  When you wanna try to share legitimate quality information,  personally, I've gotten nothing from it, nothing.  Nobody gave a crap.

Speaker: SPEAKER_03
Transcript:  I just don't wanna add any value to Facebook  by being a member of Facebook.  I think that that's.

Speaker: SPEAKER_07
Transcript:  No, seriously.  See, I do think that's clever.  I think that, again, what I've said on the show before  is I think that you're doing what Matthew Iglesias did  and you're declaring it broken.  And for most people, it is not.  That's the media narrative that drives me kinda crazy here.  And when you do that to Facebook, by the way,  I'm gonna contend, that you're doing it to the internet.  Because what you're opening the door to  is regulation that I believe is gonna be highly damaging  to the internet as a whole.  Quite the contrary.

Speaker: SPEAKER_03
Transcript:  I think the existence of Facebook  is damaging to the internet.  That Facebook is eating the internet alive.  That Facebook would like to be the internet,  especially in developing nations,  where internet.org is really facebook.com.  And Facebook should be shut down, frankly.  I think Facebook should be shut down.  Oh, come on, Leo.  I know you're playing me.  No, I absolutely believe that.

Speaker: SPEAKER_02
Transcript:  I'm not gonna say shut it down.  I'm not gonna say that.  Thank you, Ant.

Speaker: SPEAKER_03
Transcript:  I think.  You can take over now, Ant.  I think it should be shut down.  I think it's a blight on the face of the internet.

Speaker: SPEAKER_07
Transcript:  Ant, we've been waiting for Stacey.  She should have a device that comes out of her screen,  with a little fist on it,  and pops Leo when he goes overboard, right?  You should have that.

Speaker: SPEAKER_04
Transcript:  Stacey, you should have that.  I owe an apology to Wendy,  because she's been dragged into this show,  and she's gone, what the hell did I agree to be part of?

Speaker: SPEAKER_03
Transcript:  This is just how we are, Wendy.  Don't mind us.  We just like to bicker.  All right.  There's the two polar points of view.  Here's another story.  Facebook apparently scans your Facebook Messenger messages  for offensive content, and then blocks them.  Did you know that, if you're using Facebook Messenger,  that Facebook's reading every message you send,  and looking for offensive content?  Facebook has decided.

Speaker: SPEAKER_07
Transcript:  Both sides.  People are trying to say  Facebook should be cleaning up the world,  and when Facebook cleans up the world,  I don't like that either, but.  Don't people have the presumption  that their messages are private?

Speaker: SPEAKER_03
Transcript:  I mean, if you're a bad guy,  you're not using Facebook anyway.  You're using Siggy.  Yeah, that's true.  Right?  If you're a bad guy using Facebook,  you probably, the word should go forth.  Right.  You're not very good at using Facebook.  You're not very good at your job.

Speaker: SPEAKER_04
Transcript:  Yeah.

Speaker: SPEAKER_03
Transcript:  Yeah, somebody's saying I sound like a temperance evangelist.  Facebook is demon rum.

Speaker: SPEAKER_07
Transcript:  You tell them, chat room.  Who said that in the chat room?  We're giving them credit.  Punter Joe.  Who said that?  Punter Joe.  Punter Joe, right you are.  Yes, this is moral panic.

Speaker: SPEAKER_03
Transcript:  No, I so disagree with you, Jeff, as you know.  And the more we learn about Facebook,  the more evil it appears to be, and I just.

Speaker: SPEAKER_07
Transcript:  It quotes researcher Ashley Crossman,  defining moral panic as, quote,  a widespread fear, most often an irrational one,  that someone or something is a threat to the values,  safety and interests of a community or society at large.  Wait a minute.  Typically, a moral panic is perpetuated by news media.  Do you think I'm ill informed?

Speaker: SPEAKER_03
Transcript:  Do you think I'm ill informed on Facebook?

Speaker: SPEAKER_07
Transcript:  I think this, yes, I think that you're acting.

Speaker: SPEAKER_03
Transcript:  I think I'm very, very well informed on Facebook.  I actually question your support for Facebook.

Speaker: SPEAKER_07
Transcript:  Do you think for every one of the two billion people  who are on Facebook, that they are just a thrust  into the faces of Nazis every day?

Speaker: SPEAKER_03
Transcript:  I think they don't know what they're giving up to Facebook.  How elitist, how elitist.

Speaker: SPEAKER_07
Transcript:  No, it's not elitist.

Speaker: SPEAKER_03
Transcript:  Facebook hides that.  Facebook actively hides that.  Did they tell you they were scanning your messages?  I just said I'm not reading that.  Did they tell you they were collecting  your Android call history?

Speaker: SPEAKER_05
Transcript:  Did they tell you?  Yes, they did.

Speaker: SPEAKER_03
Transcript:  Did they say, hey, by the way, word of warning,  we're keeping track of all the phone calls you make,  how long they last and who you're calling.  Did they tell people that?  Absolutely not.  Facebook actively dissembles.  When they get caught, they apologize  and then they go right ahead and do it.

Speaker: SPEAKER_07
Transcript:  And in my post, I argue that they need to do  a very harsh and outside moral audit of the company.  I don't disagree that they're doing this.  That's moral panic, how dare you?  How dare you criticize them?  In this way, says Crossman,  moral panic can foster increased social control.  That's what I fear.  Here's the social control.

Speaker: SPEAKER_03
Transcript:  Comic books are ruining youth.  I'm not suggesting that Facebook be banned.  I would like to see it regulated, but I don't have any.

Speaker: SPEAKER_07
Transcript:  You said shut it down.

Speaker: SPEAKER_03
Transcript:  No, I didn't say shut it down.  I said it should be shut down, but I didn't say you.  I would be offended if,  but no, government doesn't shut down private industry  unless they break laws.

Speaker: SPEAKER_07
Transcript:  Well, this president, who knows?  He's going after Amazon.

Speaker: SPEAKER_04
Transcript:  He's never going after Facebook.  I can pretty much guarantee that.  He's looking forward to the year 2020.

Speaker: SPEAKER_03
Transcript:  He's got his Facebook team already put together.  Don't you think Jared's already thinking about  how are we going to use Facebook in 2018?  Don't you think?  Don't you think?  Not that they should be stopped.

Speaker: SPEAKER_01
Transcript:  I'm sorry, let me just finish this post.  I'll be right with you.

Speaker: SPEAKER_04
Transcript:  All right, thank you.  Thank you, Wendy.

Speaker: SPEAKER_07
Transcript:  I think we agreed to leave Wendy out of this.  Leave me out of this.

Speaker: SPEAKER_04
Transcript:  Leave me out of this.  I hate it when mommy and daddy fight.

Speaker: SPEAKER_07
Transcript:  I don't think the audience thinks we were purposely.  I think Wendy is the same one  who opted out of the beginning  and we can move on to other things.  That's why she's here.

Speaker: SPEAKER_03
Transcript:  Let's see.  Should we talk about Google?  Sure, but changes in Google.  Letters, yes.  Well, for one thing, now here's the question.  Did Gian Andrea get hired away by Apple  and then Google said, oh yeah, he's not here anymore?  Or did he leave and then go to Apple?

Speaker: SPEAKER_07
Transcript:  What's the timeline?  Well, the story was, so Ben Gomes, who I like,  who got elevated as the head of search  and what's his name, Jeff Dean takes over AI,  that got announced and they said that their former boss  was going to stay at the company.  So if he knew he was leaving, you'd think that  they wouldn't have announced it that way.

Speaker: SPEAKER_03
Transcript:  So he was the AI genius at Google.

Speaker: SPEAKER_07
Transcript:  I think Apple pounced is what that looks like to me.  Apple saw an opportunity.  We'll cover whatever separation agreement stuff,  we'll pay for that, we're gonna steal their AI guy.  There was some obviously political fight about AI  within the company, I don't have any idea what it was.  It's fascinating.

Speaker: SPEAKER_02
Transcript:  There's always something else going on  that the media is not gonna know for sure  and there's always some type of water cooler talk  that we're not gonna get.

Speaker: SPEAKER_03
Transcript:  John Andrea was the founder of something called MetaWeb,  which Google bought in 2010 and that's how he joined Google.  MetaWeb helped websites link information based on connections  between people, places and things instead of words.  Does anybody remember MetaWeb?  I don't even know either.  It must have been doing something kind of interesting.  So the idea was it was more natural language search queries.  Developed Freebase.  Okay, Freebase was.

Speaker: SPEAKER_07
Transcript:  An open shared database of the world's knowledge.  Right, right, it was an open database.

Speaker: SPEAKER_03
Transcript:  Danny Hillis.  Oh, Danny Hillis, all right.  Well, there's another legendary name in technology.

Speaker: SPEAKER_07
Transcript:  So acquired in 2010, shut down Freebase 2016.  God bless Wikipedia.

Speaker: SPEAKER_03
Transcript:  So John Andrea was then became head of,  after I'm sure a little bit of time, search at Google, right?  As well as AI.  As well as AI.  He is now going to run Apple's Machine Learning  and AI Strategy, one of 16 executives  who report directly to Tim Cook.  Time said the higher is a victory for Apple.  Apple's been behind, of course, with AI and Siri.  They don't have as much data.  You know, I think Apple would say that's not our problem.  That's not the problem.  But it's, I mean, sure, on the outside, it looks like,  you know, Google, which knows everything,  is easily able to make a smart assistant  because it's collecting all the signals,  has all this training material.  Apple says we don't collect all that stuff.  But at the same time, Apple wants Siri  to be as good as Google Assistant.  So that's, apparently, you know, why they,  Gian Andrea was running Google Brain for a while,  which is their primary AI lab.  So yeah, I think you could say that Apple had a score.  They sure moved fast.  I wonder, I mean, I wonder.

Speaker: SPEAKER_02
Transcript:  How hard is it to send a text message  of a couple dollar signs?

Speaker: SPEAKER_07
Transcript:  A lot of dollar signs, though,  because he must have had deferred income

Speaker: SPEAKER_03
Transcript:  and all kinds of things.  It strikes me that that kind of hire takes a long time.

Speaker: SPEAKER_02
Transcript:  Yeah, there had to be some serious negotiations.

Speaker: SPEAKER_03
Transcript:  They had to be talking.  I'm thinking they were talking before this.

Speaker: SPEAKER_07
Transcript:  But then why would they have announced,  but then, so then he played a game.  He acted like he was going to stay there,  and then the next day says, never mind.

Speaker: SPEAKER_02
Transcript:  This happens every day, though.  This happens everywhere besides these huge companies.  This happens at middle America, you know,  somebody's out there busting their hump  for the last five, six years  and get an itch to put their foot in the water  somewhere else.  They're not gonna just up and leave.  They're gonna see what's available to them.  They'll talk to the headhunters in the background  and just play the role.  It happens.

Speaker: SPEAKER_03
Transcript:  I would, though, if you're Apple,  you don't wanna hire this guy just because  he's, I mean, you throw a lot of money at him  doesn't mean he's gonna be able to turn around Siri.  You want him to come to Apple  because he thinks he can turn around Siri,  because he has some ideas about what Apple needs to do  to be competitive with Google.  He's also, remember, gonna be highly constrained  in what he can do, because I've gotta think Google  has all sorts of restrictions on the,  just look at the Uber Waymo suit on the kinds  with Levandowski went from Google to Uber.  Right.  All sorts of restrictions on what he can,  what technologies he can bring to Apple,  what he could talk about at Apple.  He's not gonna just, he's not just taking Google Assistant  and saying, come on over, let's,  so I wonder how effective this,  Mike, I guess the bottom line on this is,  I wonder how effective this is gonna be for Apple.

Speaker: SPEAKER_02
Transcript:  Is it safe to assume that Apple has been actively looking  for someone of this caliber?  Yes, that's what I would guess, yes.  So if that's safe to assume,  who were the other candidates out there?  Why wouldn't they be available or make the cut, if you will?

Speaker: SPEAKER_03
Transcript:  Well, there's Chi Lu, who worked at Yahoo for a while.  He's now at Baidu in China.  He was a VP, EVP at Microsoft for Bing,  but he's also very,  but he just left Microsoft for Baidu last year.  I don't know all the players in this.  Google's got like the theoretical smart guys,  the Ray Kurzweils of the world,  the Peter Norvigs of the world.  All of those guys work for Google.  I don't know.  I bet you're right.  I bet that there were a lot of dollar signs  in that text and that Apple message.

Speaker: SPEAKER_02
Transcript:  It's one of those things like, what else could Apple do?  They know they're lagging behind in this part of the game  and you do what you gotta do as long as it ain't cheating.

Speaker: SPEAKER_03
Transcript:  I do think that, I think you make an interesting point at  that there are a limited number of people  who are really top of the field  and those people are worth a lot.  This is a elite field.  Wendy, let's talk about something you're interested in.  Yeah, let's do that.  I feel so bad to drag you into a nice scene warfare.  Yeah, let's do a safe topic like security.

Speaker: SPEAKER_01
Transcript:  Security's safe.  Security's safe.  Is my VPN on right now?

Speaker: UNKNOWN
Transcript:  Hold on.  Yeah, no kidding.

Speaker: SPEAKER_03
Transcript:  No kidding.

Speaker: SPEAKER_02
Transcript:  Did you switch to the new DNS?

Speaker: SPEAKER_03
Transcript:  I did, 1.1.1.1.

Speaker: UNKNOWN
Transcript:  Yeah.

Speaker: SPEAKER_07
Transcript:  I did.

Speaker: SPEAKER_03
Transcript:  Steve Gibson has a DNS benchmarking tool  and I'm not sure if you can see it.  I'm not sure if you can see it.  I have a DNS benchmarking tool and I ran it  and 1. is actually not the fastest DNS available to me.  In most cases, most people, I think he said this,  most people's own ISP will be faster.  But the point of 1. which is created by CloudFlare  is that it prevents your ISP from seeing your internet  DNS lookups.  Your ISP's leaking that information.  So it's a privacy point.  Speaking of people who know a hell of a lot about you.

Speaker: SPEAKER_07
Transcript:  Oh yeah.  That's a lot more than any social platform.

Speaker: SPEAKER_03
Transcript:  Well, yes and no.  I don't think that's necessarily true  because for instance, your conversation,  I agree with you that ISPs absolutely are problematic,  but your conversation with Google and Facebook,  both of those are protected by HTTPS.  They can't see your Google searches.  They can't see your Facebook likes.  Your ISP can see a lot more.  I mean, certainly Comcast we know and AT&T and Verizon  we know, quickly will hand that information  over to third parties if they can get paid for it  and have no barrier to law enforcement.  So in that respect, ISPs know an awful lot.  But on the other hand, I think both Google and Facebook  and many other sites have for a variety of reasons  started to hide that information, not just from ISPs,  but from open wifi and other places that you.

Speaker: SPEAKER_07
Transcript:  We need a sophisticated discussion about this.  I just wanna go back for one second to the Facebook thing.  The Washington Post just put up their story  on the Zuckerberg press conference  and I quote the headline.  Facebook said the personal data of most of its 2 billion  users have been collected and shared with outsiders.  Well, yeah.  I mean, that's such an ignorant headline.  Every single profile you have anywhere on the internet  has been scraped and used.  That's not news.  But now we're acting as if, oh my God, oh my God,  the world's coming down.  Look at that graphic.  Like, oh, the world's unzipped, right?  And so we need to talk a lot more about  what's really going on with ISPs and with others.  Anyway, sorry for that.

Speaker: SPEAKER_03
Transcript:  Well, here's.  Screech.  I guess we're gonna get back into this, but.  Well, no, we can, I apologize.  Very apologize.  Here's the thing.  You know normal people.  I can't pretend to.  We don't.  Jeff and I know nobody normal.  No, we don't.  But a normal person isn't really aware of that.  The promise, at least the superficial promise of Facebook,  I can show you that BBC interview again with Mark Zuckerberg,  is that you can share your personal information with us  because we'll keep it private.  And you get to choose which of your friends  has access to it.  That's that whole rigmarole about,  oh, aunt wants to be your friend.  Do you wanna agree?  The implication, yeah, you can read the fine print.  You're smart, Jeff.  You probably understand there's more to it than this.  But the implication is until you agree  that that information is gonna,  those pictures you post are gonna be shared with somebody,  it's not.  So this may not be a revelation to you, Jeff,  but I think it is a revelation to a lot of people.

Speaker: SPEAKER_07
Transcript:  Okay, but now the way that puts it is if,  oh my God, Facebook's been doing this to us.  Every single advertiser, every single media company,  every single everybody who has anything public  has been doing it.  Put it in context, please.

Speaker: SPEAKER_03
Transcript:  Yes, well we do.  Don't you think we do that?  Don't we talk about that all the time  on every show I do on this network?  We talk about that.  And on the radio show where I feel like  I'm trying to talk to normal people,  I try to let them know.  And I certainly raise this specter of ISPs  knowing a lot about you and being very willing to sell it.  We know that that's the case.

Speaker: SPEAKER_02
Transcript:  So-  I know some people that were running,  what's that service, Kodi?

Speaker: SPEAKER_03
Transcript:  Yeah.

Speaker: SPEAKER_02
Transcript:  And-

Speaker: SPEAKER_03
Transcript:  Pirated probably, right?  The pirate version of Kodi, which-

Speaker: SPEAKER_02
Transcript:  The Amazon sticks?  Was it Amazon?  Yeah, you put Kodi on an Amazon stick.

Speaker: SPEAKER_03
Transcript:  Kodi itself is just a media platform,  but you can put Kodi plugins on there  that will get pirated media.  It makes it very easy to watch pirated streams.

Speaker: SPEAKER_02
Transcript:  You know, and I'm talking to Joe Schmo or what have you,  and they were just super excited about this thing.  And they tell me they got this fire stick and whatnot.  And I say, well, where do you get this from?  And they say, it comes up on the stick and yada, yada, yada.  And I say, did you pay for it?  No, and I'm trying to go about it.

Speaker: SPEAKER_04
Transcript:  You're having a Socratic dialogue with them.

Speaker: SPEAKER_02
Transcript:  You know, and trying to help them put the pieces together.  And then I finally just had to tell them,  look, that's pirated material.  You could get in some serious trouble about that.  And they're like, oh, okay.  And they just keep doing it.  Yeah.  You know, they just don't care.  And then I tell them, hey, your cable provider  sees every single thing that you're doing.  Your internet provider sees every single thing  that you're doing.  So don't be surprised if you get a phone call  or something in the mail, or better yet,  someone knocks on your door because you got caught up  watching the latest episode of Black-ish,  even though you don't own a television, you know.

Speaker: UNKNOWN
Transcript:  Right.

Speaker: SPEAKER_07
Transcript:  Well, so Wendy, I apologize.  I did that.  I caused that detour.  What are we proving here?  Get back to safe territory.

Speaker: SPEAKER_03
Transcript:  It's just people are ignorant, and willfully so.  That's why I think this headline from the post kind of...

Speaker: SPEAKER_07
Transcript:  I understand what you're saying.  It has no context.  It acts as if Facebook just invented that today  and confessed that today.  That's what the internet has been from day one.

Speaker: SPEAKER_03
Transcript:  You could probably take this headline.  Maybe I'll, let me get my red pencil out,  and cross out Facebook, and then just,  and Facebook said, and just,  and then say the internet users.  Yeah.  Personal data of most internet users  has been collected and shared with outsiders.  Oh yeah.  That would not change the accuracy of that headline at all.

Speaker: SPEAKER_07
Transcript:  So I linked to that.  Siva himself came in.  I said in my Facebook, Facebook, sorry, oh, excuse me,  linking to this, this kind of headline writing  will get the internet screwed.  How will it get the internet screwed?  Because of the regulation.  Now what's gonna happen, mark my words, friends,  mark my words, GDPR is nothing.  There's gonna be a crackdown on the internet.  The internet's evil.  It's gonna be used by bad guys around the world,  including some in this country.  And because it comes out of this panic,  it comes out of misinformation.

Speaker: SPEAKER_05
Transcript:  Yeah.

Speaker: SPEAKER_03
Transcript:  Well, yeah, we don't wanna shut down the internet.  We just wanna tell users to be aware.

Speaker: SPEAKER_07
Transcript:  We just wanna raise awareness, right?  I said, we'll call it, well, the internet's screwed.  Siva said deservedly.  And so I said, so you're anti-internet?  No, that's not good.  Is the internet anti-people?  This is the kind of discussion that's going on.  Right.  It's affecting the whole net.

Speaker: SPEAKER_03
Transcript:  Point, yes, well proven there.  If that's where that discussion goes.

Speaker: SPEAKER_07
Transcript:  Meanwhile, Wendy is saving us from the real bad guys.  Right, Wendy?  There are real bad guys on the net  who are doing really bad things  and we're paying attention to this kerfuffle.

Speaker: SPEAKER_01
Transcript:  I was going to say that this kind of discussion  really happens in much smaller circles  than you would imagine.  And the people who are happily using social media  all over the place are not privy to it  unless they see it in a headline,  like the one you just read.  So it may not be news to any of us,  but I remember the times when it was a very,  very small internet community  and we all had the same level of knowledge.  We all considered everything to be intuitively obvious  because we all thought the same way.  And now that the rest of the globe is using this,  they have their own concerns  and we have to think very carefully about what they know,  which is not the same as what we know.  What information is it important for them  to know and understand?  And do we need to change our practices in technology  to accommodate the way the rest of the world  is going to be using this tech  because it's not up to us anymore?

Speaker: SPEAKER_03
Transcript:  Do you think it's possible, I guess really,  is it possible to have services like Facebook and Google  and not be subject to surveillance capitalism?  Are there business models?  Are there, I'm getting Shoshana Zuboff on here.  The minute that book comes out, Jeff,  just to give you a heart attack.  I want to talk about loaded ways to say this.

Speaker: SPEAKER_02
Transcript:  That's entire, this is on all media.

Speaker: SPEAKER_04
Transcript:  I'm chumming, is that what you're saying, Ed?  I'm just chumming the water.  Well, but I mean, look, I understand.

Speaker: SPEAKER_03
Transcript:  We're getting great free services.  Like the show.  And they're advertising supported  and God knows that's what I do, right?  So I believe that I do it, now maybe this doesn't scale,  but I do it in a way that doesn't infringe  on the privacy of our listeners.  But is it possible to run a Facebook or a Google  at a great expense without, I guess you could,  could you have advertising?  There are really two concerns.  One, I don't actually really mind if advertisers know  where I live, how old I am.  There's a lot of stuff, it's fine with me.  I want to see targeted ads.  I far prefer to see targeted ads.  I'm a little nervous.  Ding, ding, ding, ding, ding, ding, ding, ding, yes.  But then I'm a little nervous about ads  that are hyper-targeted to maybe my state of mind.  So then set that standard.

Speaker: SPEAKER_07
Transcript:  Yeah, yeah.  Right, so Zuckerberg said in the conference today,  he said people want quality ads  and they define quality as relevant  and the way to get relevance  is to know something about you, okay?

Speaker: SPEAKER_03
Transcript:  Yeah, but don't advertise against my depressive personality  or something, right?  All right, then set the standards.

Speaker: SPEAKER_07
Transcript:  On the other hand,  I told a story on the show before,  someone who had MS who didn't know it  and it actually had a big impact on him.  And so, you know.  They could have gone to the doctor

Speaker: SPEAKER_03
Transcript:  and had the same impact.  I mean, it's not.  He didn't know that he should.  I understand.  He didn't know that he should.  I mean, I understand.

Speaker: SPEAKER_07
Transcript:  I don't think we go, we use Facebook  for its diagnostic value.  What are the standards of targeting ads?  And targeting is not evil.  It's the way to hire value in advertising.  The existence of a show like this,  where 10 people in the world  are willing to watch this for two hours.  It democratizes it.

Speaker: SPEAKER_03
Transcript:  It democratizes. It's highly targeted.  Yeah.  Yeah, but it's targeted.  I decided to do it.  Is to do niche programming  that would by default say,  you don't have to know anything about this audience  because anybody would listen to this  is a certain kind of person.  And so that's that advertisers appreciate.  And nobody apparently was to advertise the show today.  Not enough advertisers appreciate it, but.

Speaker: SPEAKER_02
Transcript:  I'm so sorry.

Speaker: SPEAKER_04
Transcript:  Oh, no, no, no.  I'm just kidding.

Speaker: SPEAKER_03
Transcript:  I like working for free.  That's beautiful.  I don't mind it at all.

Speaker: SPEAKER_01
Transcript:  Let's think a little bit about,  I mean, taking it up a level above just advertising.  Please, yes.  Thinking about how data is being used  and recombined and used again for very specific purposes.  I think one of the discussions we need to have  is not just what kind of data is being collected,  but how it's being used in different contexts.  You can almost think of it as chemicals  that produce, in certain formulas,  produce specific reactions.  So one example I was just thinking of was  after the Newtown massacre,  something that the Journal News did  was they published the names and addresses  of all handgun permit holders  in New York's Westchester and Rockland counties.  Wow.  So this information was always available  to the public upon request,  but it was the act of collecting it  at the individual level and highlighting it  to an internet-wide readership  in the context of having just been,  there's a big political context there  right after the massacre.  That was the use that was found  to be an invasion of privacy and so objectionable.  So it was a combination of data  that actually was publicly available,  but it was highlighting it in a certain context.  So that's the sort of activity with data  I think we should be taking a closer look at.

Speaker: SPEAKER_03
Transcript:  That's a really good point.  For instance, you can go to the county seat  and get information about who owns every property  in the county.  That's public information.  But then a company that does that  and then puts it online for quick search,  it was always public information,  but it was never that accessible.  We used to call that a phone book,

Speaker: SPEAKER_07
Transcript:  and we didn't panic about it.  No, but there's this-  Do you accuse Steve Martin now?

Speaker: SPEAKER_03
Transcript:  Yeah, but it's more than a phone book.  I mean, you can find out where I live.  Now it used to be you'd have to go  to the Sonoma County seat to find that out.

Speaker: SPEAKER_07
Transcript:  Actually, I found out.  Meanwhile in Scandinavia, your income is public for all.  Right.  It's public.  And you thus pay different fees.

Speaker: SPEAKER_01
Transcript:  When I was working for the state of Texas,  all of the salaries of state employees  are publicly available if you file  a Public Information Act request.  But the Houston Chronicle took all of that data  and put it in a database and published it.  And the act of publishing it suddenly raised  the visibility of that.  And again, the focusing of public attention on it  to a level that it hadn't been before.  And you can imagine that that was an issue,  not just for the employees of the state  who could now spend the time  and compare their salaries with somebody else's,  but anybody could now access that very, very easily.  So again, it's what you do with the data  and how you combine it in the context of our society  that I think we're gonna have to have discussions around.

Speaker: SPEAKER_03
Transcript:  How do you solve that?  Do you say you can't publish it?  Do you say, I mean,

Speaker: SPEAKER_07
Transcript:  or you change our norms in society?

Speaker: SPEAKER_01
Transcript:  Yeah, I think there's a lot of discussion  that points out that our norms in society  have not caught up to our technology.

Speaker: SPEAKER_03
Transcript:  And this is what norms are.  Yeah, but norms won't protect you, Jeff,  if your home address is public  and somebody decides they don't like you.  There's reasons why I would prefer my-

Speaker: SPEAKER_07
Transcript:  Ever thus, though, ever thus.  Leo, come on.

Speaker: SPEAKER_03
Transcript:  But now they can do it in five seconds  instead of having to go- They can put it on Twitter.  I mean, doxing is- They can tweet it.  They can dox me, yeah.

Speaker: SPEAKER_01
Transcript:  Yeah, doxing is a new activity  that is very different from calling information  and saying, I want Jeff Jarvis' home phone number.  Right.

Speaker: SPEAKER_03
Transcript:  So, and I don't see that we've really addressed that at all.  I mean, that's a big problem.  I look, poor Brianna Wu had to move.  So I don't think we've addressed that at all,  and that's been a known problem.

Speaker: SPEAKER_07
Transcript:  Right, but what's the real problem?  The problem's not the internet.

Speaker: SPEAKER_03
Transcript:  I don't know what the solution is, though.

Speaker: SPEAKER_07
Transcript:  The problem is that we've got a screwed up society.  Well, you can't fix that.  That's humans. And we don't know  how to deal with people who threaten each other.  Well, we just, what he said about the YouTube case.  The cops were called.  They talked to the woman.  She was sleeping in a car.  The father was worried.  There was nothing they could do.  And rightly so.  I, when I was in California,  I tried to get a very dear friend of mine  when I lived there, who was bipolar,  when he was running naked through the woods of Monterey,  the effort it would take to get him committed,  because, because one threw over the puku's nest.  We got into such a, pardon me, moral panic  about psychiatric care in this country  that we did everything we could  to keep people from being cared.  That's a much higher level problem.  Addresses on the internet, not the problem.

Speaker: SPEAKER_03
Transcript:  How about this one, Grindr,  which is Tinder for gay men.  Now, I've really mixed opinions on this one.  I don't know what you guys think.  When you put your Grindr profile up, apparently,  one of the things you can fill in is your HIV status  and date of last test.  I guess if you're a gay guy dating,  that's probably important information  that you'd want to share with other gay guys  who might go out with you.  But Grindr was sharing that information,  including location and HIV status, with third-party firms.

Speaker: SPEAKER_07
Transcript:  But, but those firms, pardon me,  read on because they were not sharing it  for it to be used in any way.  They were sharing, it was in the data  that was being used to check the app.

Speaker: SPEAKER_03
Transcript:  Right.  It was for, yeah.  But I know the people at Grindr know  that this is very sensitive information, right?  What's their responsibility there?  I mean, the users posted that information in their profile.  The Grindr only shared it with other companies  for purposes of making their app more reliable.  Right.  Grindr knew it was sensitive information.

Speaker: SPEAKER_07
Transcript:  Grindr should have been smart enough  to have massed that information  for any possible use anywhere except by that user.  Yes, that was dumb, but it wasn't venal.

Speaker: SPEAKER_03
Transcript:  Right, and who's at fault?  I mean, if you're a user, you did put that stuff

Speaker: UNKNOWN
Transcript:  on Grindr.

Speaker: SPEAKER_01
Transcript:  But only for that context, not for it to be shared.  And I think the problem is that most of the world  doesn't understand the technological implications  of just how easily their data can be collected, used,  misused, shared, recombined.  And it wouldn't occur to them to ask,  hey, you're not gonna use this for anything else, are you?

Speaker: SPEAKER_07
Transcript:  Right.  Well, but you see, here's the paradox we enter into.  Sorry, sorry, go ahead.

Speaker: SPEAKER_02
Transcript:  Is it in the terms of service  when someone signs up for Grindr that,  hey, yes, you have to provide this data?

Speaker: SPEAKER_03
Transcript:  No, you don't have to provide the data,  but it may be that it said, as most terms of service do,  your personal information is private,  but from time to time, for purposes of improving the service,  we may share information with third parties.  Yeah, they cover their rubs.  Yeah, they cover it.

Speaker: SPEAKER_02
Transcript:  Yeah, so they're covered.  Other than they should have, you know.

Speaker: SPEAKER_03
Transcript:  They claim they anonymized it.  As an industry standard practice,  Grindr does work with highly regarded vendors  to test and optimize how we roll out our platform.  These vendors are under strict contractual terms  that provide for the highest level of confidentiality,  data security, and user privacy.  I mean, you could probably also say  that Grindr's stuff is stored on a server  that some other third party owns  and presumably might have access to that information.  All those things.  Can you put that back up?  I wanted to see what the next.  When working with these platforms  who restrict information shared,  except as necessary or appropriate,  sometimes this data may include location data  or data from HIV status fields,  as these are features within Grindr.  However, it's always transmitted securely with encryption,  and there are data retention policies  in place to further protect our users' privacy  from disclosure.  This is the one that he got.  This is the Grindr's.  Read number four.  This is the one he got some heat for.  It's important to remember that Grindr is a public forum.  Some might question that.  We give users the option to post information  about themselves, including HIV status and lab test date.  We make it clear in our privacy policy  that if you choose to include this information  in your profile, the information will also become public.  But I mean, if I'm a user, I'm thinking become public  with somebody who's using Grindr  and looking for somebody to go out with.  Exactly.  That's why I shared it.  Context, yeah.  What does public mean in this context?  Does it mean you're gonna put it up  on a Times Square billboard?  Because that's also public.

Speaker: SPEAKER_07
Transcript:  Could I come along and go through 10 Grindr accounts  and get that information?  Yeah, I could.  You could.  Public is public.  Public is public.

Speaker: SPEAKER_03
Transcript:  I don't think real people would say that.

Speaker: SPEAKER_07
Transcript:  Well, you see, I keep saying that.  I'm sorry.  As a journalist, I also want to defend  the definition of public.  I wrote a book about this.  Where I think that there is not a presumption  of privacy in public.  When I see the mayor walking into a brothel,  he can't turn around and say,  well, you're not allowed to see that.  That only happens in totalitarian, authoritarian regimes.  In this country, I am allowed to see that.  And I am allowed to repeat that.  The knowledge that I have then becomes mine.  That is just reality.

Speaker: SPEAKER_01
Transcript:  I think the problem is that now with technology  and the social media that we have,  anyone can become a public figure at the drop of a hat  without realizing, without having signed up for it.  In other words, yes, the mayor is a public figure.  It comes with a job.  They can expect certain exposure  and certain highlighting in their activities.  But the person who is caught in the middle  of a news breaking event and tweets something  and suddenly becomes famous,  that can happen to any of us at any time.  I don't think anybody's prepared to deal with that.

Speaker: SPEAKER_07
Transcript:  Well, but so Wendy, I walked down the street  and I throw litter on the street and you're walking along  and you say, shame on that bozo.  You take a picture of me, you put it on Instagram.  That's my tough luck.  I'm on the public street.  I did something in public.  No, I wasn't intending to be famous,  but you make a cause, celeb out of me.  Smart ass, loud mouth, journalism prof and podcaster,  people we really wanna get because we don't like them,  are slobs.  Well, yeah, I did it.  I did it in public.  Didn't intend to afford the role, but tough.  Let me propose a hypothetical.

Speaker: SPEAKER_03
Transcript:  I'm gay, I live in one of the 28 states,  28 states more than half in which I could be fired  for being gay, period.  28 states.  Wow, didn't know that.  Yeah, so let's say I live in one of those 28 states.  Now I wanna use Grindr cause I wanna meet guys.  Is it fair to say, oh, well, if you're in one  of those 28 states, don't use Grindr or is it?  Yeah, I mean, I guess that's true, but really.

Speaker: SPEAKER_07
Transcript:  Because what you change in that case is that law.  That is exactly the right case.  This is what Dana Boyd taught me years ago.  The gathering of knowledge is not what you go after,  it's the use of the knowledge.  And if that's the case, then yeah,  you shouldn't use Grindr in that state  because you are liable and that's wrong.  What you change is the law.  You change the law.  That's what a democracy is about.

Speaker: SPEAKER_03
Transcript:  So don't use Grindr until the law has changed.  No, no.

Speaker: SPEAKER_07
Transcript:  Because you are at risk.  You're in a situation.

Speaker: SPEAKER_03
Transcript:  That's the technically right answer,  but I think there's a lot of people who say,  well, I'm gonna use Grindr because only other gay people  would use Grindr so it's safe.

Speaker: SPEAKER_07
Transcript:  What's the fundamental problem in that equation?  You and I have to agree with that.  What's wrong there is the law.  What's wrong there is the behavior of firing people

Speaker: SPEAKER_03
Transcript:  because they're gay.  I agree, but.

Speaker: SPEAKER_07
Transcript:  Technology can't fix that.

Speaker: SPEAKER_03
Transcript:  No, but I think that it wouldn't,  I wouldn't be surprised.  I wouldn't look at somebody and say,  well, you asked for it, dude, if they use Grindr,  assuming that only other gay people will see this  so I'm safe.

Speaker: SPEAKER_07
Transcript:  But you can't, that's why number four warns you  and says, you put this up here.  Well, they need to put that in big letters

Speaker: SPEAKER_03
Transcript:  when you first get Grindr.  They need to put in big letters.  I don't know. Just so you know,  you shouldn't use it in these 28 states  because you're posting publicly in effect

Speaker: SPEAKER_07
Transcript:  that you're gay by using this.  Having watched people in the day be frightened to death  of losing their jobs, they know.

Speaker: SPEAKER_03
Transcript:  Well, but I don't think they know now.  I think that they may assume that they're safe.

Speaker: SPEAKER_01
Transcript:  The big issue of our society today is we are  still discovering what can be done and misused about  at scale with data, especially personal data.  And I think the big reaction that we see over and over  again is, well, not like that.  And that's again, where social norms have to be adjusted.  They have to come back in because nobody, I think,  really understands the extent of where we're going  with all of this data.  And every time we run up against something like this  and think, yeah, I realized that it was public,  but I did not understand just how widely, you know,  it could be interpreted as public.  I made certain assumptions based on my understanding  and they turned out to be wrong,  but I had no way of knowing.  And that's-

Speaker: SPEAKER_07
Transcript:  So Wendy, what do you suggest that the standard should be  then that you can't, nobody can do anything public  unless they've signed lots of releases and waivers?

Speaker: SPEAKER_01
Transcript:  See, I think that's all very extremist.  I think because we have more visibility  into people's actions and can do activities such as,  for example, public shaming at a scale  that we have never experienced before as a human race,  we're having to re-examine all of the assumptions  that we have.  And there used to be social norms about what you could do  to shame somebody, for example, what was over the top,  what was appropriate.  And we simply have to readjust these based on the contact  that we all have around the globe now  because it's unprecedented in our human history.

Speaker: SPEAKER_07
Transcript:  I certainly agree, Wendy, this is about readjusting norms  and we're in the process of doing that.  And I find great hope if you look at the Laura Ingraham case  where somebody famous went after a teenager  and the reaction that then occurred was society saying,  yeah, we're gonna make up a new norm now,  you just went over it.

Speaker: SPEAKER_03
Transcript:  So you disagree with the Hill who says  that's a troubling precedent.

Speaker: SPEAKER_07
Transcript:  I do disagree, I do disagree.  We each have, each company has a right to decide  what they wanna associate with, we as consumers  have a right to decide what we associate with.  And Martin Luther King on this day we know,  did a lot of boycotts.  And that's how he got a lot of the economic pressure.  The only pressure that his community had was economic.

Speaker: SPEAKER_03
Transcript:  Yeah, yeah, no, I don't have a problem with it either.  But it's, there are those.

Speaker: SPEAKER_07
Transcript:  It can be used for bad too, every tool can be.

Speaker: SPEAKER_03
Transcript:  Yeah, here's an interesting example.  So Wendy's right.  Here's an interesting example.  I don't know if this is moral panic,  you can be the judge of that, Jeff, you're the king.  I am the judge.  You're the judge of moral panic.  Chrome is scanning files on your computer  and people are freaking out.

Speaker: SPEAKER_07
Transcript:  But what's the last line of that subhead says?

Speaker: SPEAKER_03
Transcript:  There's no reason to freak out, says Motherboards  Lorenzo Franceschi Picchiere.

Speaker: SPEAKER_07
Transcript:  The big headline says freak out,  the little headline says no, don't freak out.

Speaker: SPEAKER_03
Transcript:  So the reason people are freaking out is,  well, it's one of those things that's benign, right?  So Wendy, it's Chrome, your browser saying,  well, let me look at your documents folder  and see if there's any malware in there.

Speaker: SPEAKER_01
Transcript:  No, they're not even looking at the documents folder.  If you look at the postings on Twitter from Justin Shue  who I think is quoted in that article  that you're highlighting,  he leads Google Chrome Security and Desktop Engineering.  He talks about what this does, the Chrome cleanup tool.  It's not a system wide scanner filter, as he writes,  it runs weekly, it scans browser hijacking points,  which may cause it to follow links elsewhere.  In other words, it's patrolling the security of the browser,  which is, you would expect the browser to do that.  I think that's a great feature for it to be doing.  It's a very heavily sandboxed subset of ESET.  And, but in checking some things out to see where they go,  they may follow other links.  So again, there's a lot of technical detail  in what Google has done here  that was completely lost in the discussion.  And the problem is that Google itself,  their security team doesn't have marketing per se.  All the information about what they're doing  with consumer features and securities  on their security blog, which is great,  except consumers usually don't know it exists  and they don't go read it.  So this is another case where, you know,  most of the rest of the world does not understand  the technical details of this.  And, you know, they're not being communicated  in a very user-friendly way.  They're being communicated in a tech-friendly way.  And you and I might go look for that security blog,  but the rest of our neighbors down the street  won't think to do that.

Speaker: SPEAKER_03
Transcript:  Well, so here's the, the way it was, by the way,  it is, if you read the Terms of Service,  which nobody does, it is stated  in the Terms of Service, Chrome will do this.  So it isn't something undisclosed.  As you said, it wasn't disclosed by a marketing team,  it was disclosed by a technology team.  But Kelly Shortridge, who is a sophisticated user,  discovered it because she had a Canary token  in her document folder.  So by the way, we should mention Canary is,  the Thinks company is a sponsor,  but so she had a phony document file  that was there to warn her  if somebody was accessing her document folder,  and it was triggered and it was Chrome.  So you can, so this is a good example of-

Speaker: SPEAKER_07
Transcript:  But are we better off with Chrome?  Wendy, are we better off with Chrome doing this than not?

Speaker: SPEAKER_03
Transcript:  Oh, I would say so, yes, Wendy, yeah.

Speaker: SPEAKER_01
Transcript:  I believe that they have worked very, very hard  on protecting users and they've done more than,  you know, a lot of other companies have.  But the problem is that, you know,  nothing happens in isolation.  And these sorts of features,  the more sophisticated they get,  the more they have to branch off into areas  where we start, you know, getting nervous and thinking,  well, what about our privacy?  So yeah, it's a very difficult line for them to walk.

Speaker: SPEAKER_03
Transcript:  Yeah, so they do, they may go in following these hijackers,  they may go into your documents folder,  but they're not looking randomly at the documents.

Speaker: SPEAKER_01
Transcript:  Yeah, if they're following links  that they may have reason to believe is, you know,  are suspicious, they may need to go check them out  at the hijack points within the browser and say,  okay, you know, what are we really looking at here?  So the question is, how far do you want your software  to go in an effort to protect you from attackers?  How much of this do you want them to do for you?  And, you know, do you have the knowledge to be able to say,  I want you to go this far, but not any further  and really understand the implications  of what you're asking for?

Speaker: SPEAKER_03
Transcript:  I have to say, sometimes I feel like Google  acts a little bit nanny-ish.  You know, in maybe, you know,  things like kind of pushing HTTPS,  yes, that's all well and good and everybody should use it.  Deprecating, what was it, it was the 1020,  the URL shortener?  Well, no, yeah, we can talk about that in a bit,  but remember they deprecated keys,  1024 keys a little early.  Earlier than that was a problem,  or maybe there were 2048 bit keys.  It was earlier than it was a problem.  Both Microsoft and Google agreed to do this,  but Google advanced the deadline.  Causing problems, people had to go out  and get new certificates.  And I understand, this is a really good example  of engineers have a different mindset.  They don't really, well, this is good for everybody.  We're gonna just do this.  And they maybe don't understand the political issue,  the issue of dealing with humans quite as well.

Speaker: SPEAKER_07
Transcript:  Well, I think it's, but it's the atmosphere of trust  or lack thereof.  We trusted Google to do this, we trusted Facebook.  Now, because of all this hoo-ha,  and we have been debating legitimacy of that hoo-ha,  there is now a lack of trust,  and they have to deal with that in a whole different light,  and they're not used to it.

Speaker: SPEAKER_03
Transcript:  Well, I trust Google and you trust Google,  but wouldn't you be surprised if you saw,  if you had a thing in your documents folder  that said, hey, Chrome just was looking  in your documents folder, you would kind of want to know,  well, what, why was that?

Speaker: SPEAKER_02
Transcript:  I guess I don't quite understand it, the technology here,  but isn't this the same type of security  that can try to stop the mining software  from being installed on my machine,  because I went to some whatever website?

Speaker: SPEAKER_01
Transcript:  There's a lot of safe browsing work that Google has done,  both from a search perspective  and from a Chrome engineering perspective.  And the stuff is all there in their security blog,  but again, is it in a format that typical users,  not us, but typical users,  will know to look for and understand,  there's a lot of usability issues  that we have to re-examine right away.

Speaker: SPEAKER_03
Transcript:  All right.  So I'm just gonna quickly show you where it says this.  This has been in the Chrome terms of, what is this?  This is the Chrome Security Blog.  They've been saying this since January 2017.  It's actually a white paper on Chrome security.  And if you scroll really far down  into unwanted software protection,  Chrome periodically scans your device  to detect potentially unwanted software.  Actually, this is another example  where the marketing team might have said,  you shouldn't call this heading unwanted software protection  because what you're protecting against is unwanted software,  but it sounds like what you're saying  is that your software protection is unwanted.  Anyway, so-

Speaker: SPEAKER_07
Transcript:  A lead for a hyphen.  Yeah.  This is a, it shoots a lead.

Speaker: SPEAKER_03
Transcript:  This is an engineer writing this.  And I love engineers.  I love that mindset.  But maybe they don't quite get  that people might misunderstand it.  Chrome periodically scans your device  to detect potentially unwanted software.  That's what they said.  Look, we told you we were gonna do this.  It's right here in paragraph 34 subsection A  under unwanted software protection.  Surely you read that.  Anyway, I'm glad they do it.  I don't think it's, I think it's harmless,  but I understand people's concern.

Speaker: SPEAKER_01
Transcript:  Yeah, I mean, by contrast,  I have to tell you the story of one of my kids  who we caught, we used to let him use a computer  before he could actually read.  And he was clicking around on software.  And one day we caught him in the middle of downloading  and almost installing a browser plugin.

Speaker: SPEAKER_03
Transcript:  Right.

Speaker: SPEAKER_01
Transcript:  And we couldn't figure out what was going on there  until we figured out that even though he couldn't read yet,  he had learned that if the pop-up window appeared-  Click yes.  And there were two choices.  One of them would be highlighted more than the other one.  And if you click that one,  then it would go away and things wouldn't work again.  I'm a good boy.  Look what I did, I'm a good boy.  So he figured out how to do that.  He intuited that by himself until he got to the EULA.  And the EULA agree or disagree,  neither choice was highlighted by default  so he didn't know what to pick.  And he got stuck.  So this is the sort of thing that users of all ages  and all different cultures  and different levels of understanding are dealing with.  And we have got to re-engineer how we work with users  and what the user experience is like  because nobody's gonna read these white papers.  I can't, nobody outside of technology  is gonna read these white papers.

Speaker: SPEAKER_03
Transcript:  I didn't even read it.  Put it on Facebook, they'll read it there.  Yeah, right.

Speaker: SPEAKER_07
Transcript:  Make it into a meme, then it's okay.  Right.

Speaker: SPEAKER_01
Transcript:  Now at Carnegie Mellon University,  there's a usability and privacy research group  that is working on a lot of these issues,  trying to figure out what privacy means,  what usability actually means  and working to redesign these things  so that they can be understandable.  And I think that's a very important effort,  but it's going to have to spread a lot further  throughout technology.  We really have to emphasize usability  and better cultural understanding.

Speaker: SPEAKER_03
Transcript:  Yeah, it's really an interesting issue.  I think, correct me if I'm wrong,  I'm trying to synthesize a general statement.  And I think that the problem really is,  and we've said this before,  that 99% of users are reliable and trustworthy  and respectful and so forth.  There are bad actors, though, 1%.  And what we really underestimated was that the power  that all of these internet tools would give the 1%.  And it's now overwhelming us,  whether it's on Facebook or Twitter, malware.

Speaker: SPEAKER_07
Transcript:  Which is a problem of responsibility.  I mean, I have William said that South by Southwest.  He said we didn't anticipate the bad behavior.  We should have, we know that now.  We didn't have enough people like Wendy, seriously,  to say, let me look at the dark side here,  anticipate the problem and protect against it.

Speaker: SPEAKER_03
Transcript:  Goes back to the days of operating systems.  When they designed operating systems,  they weren't designed to defend against, you know,  malefactors.

Speaker: SPEAKER_01
Transcript:  And they weren't designed for people  who didn't know how to use them.  Yes, they're designed for engineers.  By engineers, for engineers.  By engineers, for engineers, exactly.  And so the first step when you start looking at software  is seeing how it can be accidentally broken  and accidentally misused.  And you need to protect against that.  And then from there, it's just another short step  to malice and say, now, if somebody were trying  to break this on purpose, what would happen?  And yeah, there are a lot of us in the security community  that sit around thinking these bad thoughts all day,  but it's certainly not what normal people think about.

Speaker: SPEAKER_03
Transcript:  When did that shift happen, Wendy?  When did we start really kind of thinking,  oh, we gotta really think of worst case scenarios?

Speaker: SPEAKER_01
Transcript:  I think it's been, well, those who have been defending  against state actors for decades  have already been thinking this way.  I think just as technology has spread out  into the hands of the rest of the world and regular users,  the expansion of bad actors has increased proportionately.  And the types of different bad actions  that are being taken, all sorts of fraud  and abuse and monetization and bullying.  There was a great talk by Alex Stamos at Facebook  about what they consider to be their threat model.  And at the very top, there's just a little tiny bit  that has to do with state actors and those sort of attacks.  Way at the bottom, the biggest thing  that they have to defend against  is users of their platform abusing other users.  And that's their biggest problem.  So yeah, these sorts of threat models change very much,  depending on the software, depending on the user base  and the functionality.  And we don't understand all of it yet,  but we need to spend a lot more time thinking about it.

Speaker: SPEAKER_03
Transcript:  When you learn software design,  in fact, even if you don't learn it,  you might even intuit it,  but especially when you learn it,  you learn to test for edge cases.  You learn to look for crazy inputs.  The bad actor for software design is,  that's how you avoid bugs, is just crazy inputs,  unexpected things.  And as a good software designer,  you design software, really testing for the edge cases.  That's very, very, very important.  Sanitize it.  Yeah.  And then it gets to, if you've got user input,  you've got to sanitize your inputs.  And this is well known,  but I think we're now seeing this at a more macro scale  with Twitter and Facebook and everything else,  that you have to plan for the worst,  even at a higher level.  And we're not very good at planning for software errors  and sanitizing our inputs.  We're even worse at planning for bad actors.  We just, I think most of us just assume people are like us.  They're nice.  And what kind of design do you do?

Speaker: UNKNOWN
Transcript:  Nice.

Speaker: SPEAKER_01
Transcript:  And they understand the same sorts of things,  but yeah, nobody is getting into the head  of the four-year-old and saying,  how are they going to do it?  That's a good point.  As user in effect.  That's a good point.  Nobody's thinking of the edge case where  one person in a family has one social security number  and they share it throughout the family  because nobody else has one.

Speaker: SPEAKER_03
Transcript:  Right.

Speaker: SPEAKER_01
Transcript:  There are so many cultural differences  that diversity is going to have to solve.  There's a lot of research, for example,  that we put into our usability at Duo,  but we still run into edge cases all the time.  And you just have to realize  that whatever you're designing it for  is going to be around for much longer  than you ever anticipated it was going to be.  It's going to be used by user base  you cannot fully picture and imagine in your head.  And you have to be ready to adjust at a moment's notice.

Speaker: SPEAKER_03
Transcript:  Sina had a...

Speaker: SPEAKER_01
Transcript:  Did I just cast a bummer over?

Speaker: SPEAKER_03
Transcript:  No, not at all.  No, no, no, no, no, no, no, no.  I think this is really the fundamental conversation  we've been having all along, really.  And how do you do that now, especially retroactively,  which is really challenging.  How do you do that?  How do you solve for this problem?  How do you democratize speech and still handle the bad actors?  I don't know.  I think it's very, very hard.  It's very hard.  How Chromebooks became go-to laptops  for security experts.  Would you agree?  Are CISOs using Chromebooks?  Yay.  Yes indeed, says Wendit.

Speaker: SPEAKER_01
Transcript:  Yeah, we use them heavily at duo.  In fact, my travel laptop is a Chromebook  because there's nothing resident on it.  Although, those of us who have been around a long time  are seeing the fat and thin client thing  waxing and waning over the decades.  And now we're going back to thinner is better.  The less you have on that particular piece of hardware,  the better.  But again, because of the additional security functionality  that Google is engineering in there,  yes, it is turning out to be a very practical use case  for enterprises as well as for individual users.

Speaker: SPEAKER_03
Transcript:  If you go to a DEF CON or Black Hat,  you don't bring a Windows laptop, you don't bring a Mac,  you bring a Chromebook.  Swift on security five years ago, no, three years ago,  mentored someone on teaching computing basics to seniors.  What antivirus should I buy?  Buy a Chromebook.  But what about buy a Chromebook?  That was three years ago, but that's true.

Speaker: SPEAKER_07
Transcript:  And if you get on the school bus,  what do you bring with you?

Speaker: SPEAKER_03
Transcript:  Oh, I love this story.  So Google, this was a pilot program they did  in North Carolina.  They did it in some rural areas  where people spend a lot of time,  poor students spend a lot of times on school buses  with bad shocks.  Yes.  Bouncing along rural country roads.  You're in, where are you in North Carolina, South Carolina?

Speaker: SPEAKER_02
Transcript:  I grew up in South Carolina,  but right now live right outside of Charlotte.  Charlotte.  North Carolina.

Speaker: SPEAKER_03
Transcript:  So a lot of kids.

Speaker: SPEAKER_02
Transcript:  I know all about those country roads, trust me.

Speaker: SPEAKER_03
Transcript:  Spend as much as three hours a day in a school bus.

Speaker: SPEAKER_02
Transcript:  Yep.  Oh my God.  I know all about that.  You get on the bus at 6 a.m.  and you're at the school at eight.

Speaker: SPEAKER_03
Transcript:  Oh my God.  So what do you do?  Besides throwing spit wads.  You give them all Google buses.  You give them Google buses  and they're gonna roll out more of these.  It's been a successful pilot for a while,  I guess in North Carolina and South Carolina  over the last couple of years.  They put wifi in the school bus.  They put Chromebooks in the school bus.  They call it the Rolling Study Halls Initiative.  I'm thinking that probably a lot of kids  are not studying on these.  I like the initiative,

Speaker: SPEAKER_02
Transcript:  but you just think about how often you can walk outside.  I don't care if it's small town Petaluma  and you see someone that's under the age of 18,  they're doing this.  And I guarantee you they're not researching  for whatever assignment that they had that week.

Speaker: SPEAKER_07
Transcript:  Unless the paper is due that morning  and they didn't do it last night.  Yeah.

Speaker: SPEAKER_02
Transcript:  Not if you're my kids, I'd dare them to do it.

Speaker: SPEAKER_04
Transcript:  No last minute studying for them, huh?  No.

Speaker: SPEAKER_03
Transcript:  Each Rolling Study Hall also has an onboard educator  who could provide direct assistance.  This is really- Really?  This is, yeah, to me, this is what Apple should have done  instead of releasing a not much cheaper iPad  with a pencil support.  Apple really could have done something  innovative and supportive.  This is in 12 states now, 16 districts,  Alabama, Colorado, Georgia, Kansas, Minnesota,  New Mexico, Oregon, Pennsylvania, South Carolina,  Tennessee, and Texas, and Virginia.  Of course, it's gonna work best  where people are spending a lot of time.  The average bus route  in the GameWell middle school population  is one and a half hours in the morning  and one and a half hours in the afternoon.  That's Caldwell County, North Carolina.  Wow, wow.  Your kids don't spend that much time in the bus, do they,  Aunt?

Speaker: SPEAKER_02
Transcript:  Yes, sir, they do.  Oh my God. One of them does.  Really? Wow.  You do.  And the funny thing is  the school is roughly  six miles from my home.

Speaker: SPEAKER_03
Transcript:  Oh no!  What?  They can walk faster.

Speaker: SPEAKER_02
Transcript:  Right, and that's the thing.  There's been a time or two where I said,  hey, go ahead and walk.

Speaker: SPEAKER_07
Transcript:  They don't have enough bus routes?  What is it?

Speaker: SPEAKER_02
Transcript:  Right, I think it comes down to budget.

Speaker: SPEAKER_03
Transcript:  They're on the wrong side of the bus route.  They pick them up on the way out,  and send them on the way back.

Speaker: SPEAKER_02
Transcript:  That's exactly what happens.  And there's only so many buses out here.  There's been times where I've found that  my younger son's bus driver,  after he or she finishes the route,  they go to the other route for the high school.  It's just double duty,  and I think it's all budget myself.

Speaker: SPEAKER_01
Transcript:  It probably is.

Speaker: SPEAKER_07
Transcript:  But how can you arrive at school,  number one, high school starting earlier is ridiculous  because the high school kids are more so an ambulance.  I would just sleep on the bus, yeah.  But yeah, but how can you arrive at school fresh to think  when you're an hour and a half on the bus?  Jesus.  Yeah, I always slept.

Speaker: SPEAKER_02
Transcript:  They probably nap if they can.  I wasn't a normal kid either.

Speaker: SPEAKER_03
Transcript:  You could bicycle pretty quick.  Oh well, that's sad.

Speaker: SPEAKER_07
Transcript:  So soon we'll have the self-driving buses,  and then the bus driver can be the teacher  or the classroom and it'll be fun.  I mean, I don't know how well this scales.

Speaker: SPEAKER_03
Transcript:  I'm sure it's expensive,  but I just commend Google for doing it.  I think it's a-

Speaker: SPEAKER_02
Transcript:  Yeah, I think it's a great idea.  It's just the matter of policing it  and seeing what all is going on within that network.  I like the idea that my kids can use that classroom.  Is that what it's called?  Google Classroom?  Yes.  And they can share information with me  and the teachers can do the same thing.  Do they use it?  Everybody's connected.  Oh yeah.  Oh nice.  And everybody's connected and I'm sort of always  in the loop, but I got a hunch.  When they're on the school bus, especially after school,  the last thing on their mind is I need to make sure  I read chapter 10 tonight.  They're probably trying to get on Snapchat.

Speaker: SPEAKER_04
Transcript:  I'm so glad my kids are grown.  I couldn't handle it if my kids are grown.

Speaker: SPEAKER_02
Transcript:  And I'm counting down.

Speaker: SPEAKER_03
Transcript:  Well, my stepson's 15, so I have to have,  but he'd rather play video games than Snapchat.  How old are your kids?

Speaker: SPEAKER_02
Transcript:  I still don't know.  There's sixth grade and ninth grade.  I don't know the ages yet.  You asked me that before.  Yeah, that's not his father.

Speaker: SPEAKER_04
Transcript:  Dad doesn't need to know that.  Not old enough to work.  Yeah, we have a ninth grader as well.

Speaker: SPEAKER_03
Transcript:  He actually can take the train, which is nice.  We now have a light rail from Petaluma to Marin.  That's where he goes to school.  That sucks.  That is really great.  So we got him a little electric scooter.  So he picks up the train in Petaluma,  gets on the light rail.  It's a really nice, beautiful 20 minute smooth ride.  There's another mile and a half to school  and he rides his electric scooter to school.

Speaker: SPEAKER_02
Transcript:  Or some Charlotte kids do that.  They take the light rail instead of the bus.

Speaker: SPEAKER_03
Transcript:  Mass transit, hallelujah.  We need more of that.  Google has added now, well, they call it  making it easier to plan for the weekend.  Google search on Android and soon iOS will, oh boy.  If you're Fandango or Flickster,  you got to be nervous about this.  In search, you can say what movies are showing.  They'll show you the movies in the theaters near you.  You can even buy tickets on your phone  all without leaving the Google search results.

Speaker: SPEAKER_07
Transcript:  Oh, I didn't see that in the run down.  That's cool.

Speaker: SPEAKER_03
Transcript:  Yeah, I didn't either.  It was ScooterX in our chat room said this just came out.  Yay.  Nice.  Nice.  I saw Ready Player One, by the way.  Have you seen it yet?  Yes, I've seen it.  What'd you think, Wendy?

Speaker: SPEAKER_01
Transcript:  You know, I grew up in that era and everything,  but I was not a gamer boy.  Right.  And so, yes, I played games,  but I'm probably not of the right mindset  to appreciate it as much as it should be.  I think Spielbook did a great job with it.  I sat up right in the front row  to get as much of the VR experience as I possibly could.  Holy crap.  That's very brave.  It was just so 80s in terms of the protagonist  who I could not identify with at all.  And all of the 80s references, I was like, yes, yes,  that's very nice.  I remember all of those.  I don't know why the nostalgia didn't grab me.

Speaker: SPEAKER_03
Transcript:  I loved it, but I was that kid.  And the game that they play at the end,  I won't say anything about it,  but it has an Easter egg.  And I remember when that game was the hot game,  I played it and I found the Easter egg  and I did all of that stuff.  So it kind of resonated a little more for me.  I think geeks will enjoy it,  or anybody who likes 80s trivia.

Speaker: SPEAKER_01
Transcript:  Yeah, although I feel that when you have something  that's wonderfully broader, culturally speaking,  and high tech, like Black Panther.

Speaker: SPEAKER_00
Transcript:  Oh, I love that.  I just think there's no comparison.

Speaker: SPEAKER_01
Transcript:  It just makes something like Ready Player One  look a lot more dated.

Speaker: SPEAKER_03
Transcript:  That's actually a good point.  Black Panther was remarkably good.

Speaker: SPEAKER_01
Transcript:  It was amazing.

Speaker: SPEAKER_03
Transcript:  Yeah, it really was.

Speaker: SPEAKER_02
Transcript:  My friend Charlie Hoover and also Dan Patterson  had gotten me onto Ready Player One to book.  And I just kept putting it off and putting it off  and ended up using Audible to do the audio book.  It's a great book.  It reads it, yeah.  And I thought it was okay.  I think I would have enjoyed that book  probably five, six years ago.  But it just didn't do much for me.  I get all of the 80s stuff.  I grew up in that time.  But I didn't start playing D&D until maybe two years ago.  You know?  It just is.

Speaker: SPEAKER_01
Transcript:  Oh, you got some catching up to do.

Speaker: SPEAKER_02
Transcript:  You know, I played ball.  When I was a kid, I had all of those gaming systems  and whatnot.  But at the same time, I went outside  and we played basketball and hide and seek  and things like that.  I didn't spend a lot of time with the video games  the way the book portrayed kids spending time in the 80s  playing video games.

Speaker: SPEAKER_01
Transcript:  You had a life.  No, I ain't gonna say all that.

Speaker: SPEAKER_02
Transcript:  I had a mom that said,  you better get your butt outside, that kind of thing.  Yeah.

Speaker: SPEAKER_03
Transcript:  I really liked Mark Rylance in it.  He plays James Halliday.  Yes.  He's one of my favorite actors  and normally a very serious actor.  He was in Wolf Hall and he's really good.  And he plays almost borderline autistic game developer  who kind of starts this whole ball rolling in this book,  James Halliday.  And he does it with, I think it's so charming.  He really is the innocent.  And I really enjoyed his performance in this.  He was really, really good.  I agree with you though.  I didn't like the book that much initially.  And I thought it was kind of cliched and not great.  But then I've seen-

Speaker: SPEAKER_02
Transcript:  I look forward to seeing the movie either way  because of Spielberg and I love CGI and all that.

Speaker: SPEAKER_03
Transcript:  Yeah.  I actually, I'm reading the book now  I started the book four or five times.  I've had it in my Audible account for a couple of years.  But now that I saw the movie, I'm reading the book  and really enjoying it actually.  I've kind of mad at myself.  But yeah, it's worth seeing.  It's worth seeing.  Let's see.

Speaker: SPEAKER_07
Transcript:  Ba ba ba ba ba bum bum Google.  You want a little break here?  Yeah.  We're almost done.  There's nothing new in technology.  It's my favorite story.  Okay.  For written forever.  Yes.

Speaker: SPEAKER_03
Transcript:  I saw you put this in the rundown.

Speaker: SPEAKER_07
Transcript:  People have been talking about this.  It is, it's long.  It is the greatest.  It is the greatest, the greatest, the greatest.  Guy goes to hotel in Vancouver.  He's from Halifax.  He brings a suitcase filled with pepperoni  because his Navy buddies want the pepperoni.  He has a whole suitcase filled with it  because it's Navy, but for a whole ship.  Yeah.  He gets it.  They lost the bag.  He gets the bag.  He gets in the hotel.  There's no refrigerator.  But he figures he better kind of cool it  and it's cold outside because it is after all Canada.  So he opens the window and he puts the pepperoni on a table.  He leaves for four or five hours.  He comes back.  He had no way to know that seagulls must like pepperoni.  They like anything.  Anything.  He walked into the room and the room was filled  with seagulls with pepperoni.  Now, when seagulls do eat the pepperoni,  you can imagine what it does to their digestive system.  It comes out the other end.  Yeah, there was that.  Plus they tend to slobber.  He didn't know seagulls slobbered.  So that was all over the room.  He's going crazy.  He opens the windows trying to get the seagulls out.  One seagull, he throws his shoe out.

Speaker: SPEAKER_03
Transcript:  He threw the shoe at the seagull  and it goes out the window.  The shoe goes out.

Speaker: SPEAKER_07
Transcript:  Then he puts a towel around it,  around another one to get it out.  It goes out with the towel.  That wasn't hurt, but it was like the BKRP scene.  Seagulls surrounded in towels can't fly.  There's some kind of nice, wonderful little tea going on.

Speaker: SPEAKER_03
Transcript:  This is in a fancy hotel, I have to tell you.  Very fancy.

Speaker: SPEAKER_07
Transcript:  Very fancy.  So then he comes back and he...

Speaker: SPEAKER_03
Transcript:  He says, it's all happened fairly quickly  and this is mid-afternoon.  The Empress hosts a very famous, very popular high tea.  I suspect this is where the large group of tourists  was heading when they were struck first by my shoe,  then by a seagull bound up in a towel.

Speaker: SPEAKER_07
Transcript:  So then he goes out, he sneaks out,  he gets the shoe, he gets the towel.  He comes back, he cleans off the shoe,  but he's a big important business being,  and then one shoe is wet.  So he puts the hairdryer into the shoe to dry it.  The hairdryer buzzing.

Speaker: SPEAKER_04
Transcript:  This is not true.

Speaker: SPEAKER_07
Transcript:  Is this made up?  It is.  The hotel verified it.  The hotel verified it.  The hairdryer vibrates itself out while he's on the phone  and goes into a sink.  Oh no.  But it wasn't working well,  so he took out the power in half the hotel.

Speaker: SPEAKER_03
Transcript:  Oh my God, the GFI didn't protect the hotel.  It fries the hotel circuitry.  He calls the fric desk and says,  can someone help me clean up a mess?  He says, I can still remember the look on the lady's face  when she opened the door.  I had absolutely no idea what to tell her.  So I just said, I'm sorry, and I went to dinner.  When I came back, my things had been moved  to a much smaller room.  I thought that was the end of it all  until I was told my company had received a letter  banning me from the Empress Hotel,  a ban I have respected for almost 18 years.  I have matured and I admit responsibility for my actions.  I come to you, Empress Hotel,  hat in hand to apologize for the damage  I had indirectly come to cause.

Speaker: SPEAKER_07
Transcript:  Because after all, in Canada,  apologizing is an art.  It is an art.  This is a most artful apology.  This is the best Canadian apology ever.

Speaker: SPEAKER_02
Transcript:  He immediately became a peasant.

Speaker: SPEAKER_07
Transcript:  Did the Empress let him back in?  They let him back in.  They let him back in and he brought a box  of Brothers pepperoni from Halifax.

Speaker: SPEAKER_03
Transcript:  For them.  The Empress is a Fairmont property.  It's a very fancy hotel.

Speaker: SPEAKER_07
Transcript:  So I just, I thought, I just loved that story so much.  It has nothing to do with technology,  nothing to do with Google, but what do we care?  I love that story.  It's going all around the internet.  That is gold.

Speaker: SPEAKER_03
Transcript:  That is, and you see, this is why we need Twitter.

Speaker: SPEAKER_07
Transcript:  This is exactly why the internet's good.  I found it on Facebook, by the way.

Speaker: SPEAKER_03
Transcript:  Oh, well it's on Twitter.  You wouldn't have seen it there, but I did.  Yeah.  I, there's still, it's not too late.  You know, they give you two weeks to back out.  And I backed out once before cause my poor wife said,  but now I'm not married to anybody.  I'm merely married.  It doesn't say a name.  So I relented and then I thought, no,  I'm not going to relent.  I'm going to, so I deleted it again.  And, but I'm still the, so I extended the two week.

Speaker: SPEAKER_01
Transcript:  Are you still married?  I am.

Speaker: SPEAKER_03
Transcript:  Well, that's the funny thing, isn't it, Wendy?  She's married to me.  She's still married to me.  She never stopped being, it's just on Facebook.  She just says she's not.  So.

Speaker: SPEAKER_07
Transcript:  What did Ant just do?

Speaker: SPEAKER_02
Transcript:  Did you just do something, Ant?  I had to fix some of the lighting.  Oh, okay.  I thought you were encouraging me.

Speaker: SPEAKER_07
Transcript:  I thought you were walking our view.  I thought you were going private on us, Ant.

Speaker: SPEAKER_03
Transcript:  Google employees have written 3,100 strong saying  Google should get out of, this is like Gollage,  get out of the Pentagon research.  Yeah, but they got a point.

Speaker: SPEAKER_07
Transcript:  Cause it's, it's, it's research to do AI,  to do identification of photos, to guide drones.  Oh, well.

Speaker: SPEAKER_03
Transcript:  So you think that maybe there's some merit to that,  that they shouldn't be doing that.

Speaker: SPEAKER_07
Transcript:  I do a company, when people get freaked out by seeing,  now they don't own Bosch Dynamics anymore,  but they got freaked out by, by Google, you know,  having cute dog robots.  Right.

Speaker: SPEAKER_03
Transcript:  That's one matter.  Dear Sundar says, begins the letter.  We believe that Google should not be in the business of war.  Therefore we ask that project Maven be canceled.  The Google draft publicized and enforced a clear policy  stating that neither Google nor its contractors  will ever build warfare technology.  And I know a lot of people watching this show are saying,  pretty typical California, right?

Speaker: SPEAKER_02
Transcript:  I'm not sure what to think of that though.  I-  Either side of it.

Speaker: SPEAKER_03
Transcript:  No, I'm also conflicted because you could make the argument  that we're, you know,  they're helping the defense of the United States.  My freedoms.  Yeah. So I'm not, I don't know.  Mixed feelings about this.  This is pretty much like a college campus.  I can remember these battles going on all the time  when I was a kid.  Oh yeah. Oh yeah.  Back in our day.  Yeah. Cause universities routinely took  defense department contracts.  The company Google describes its work on project Maven  as non-offensive.  I don't mean, I don't think they mean it's not offensive.  They mean it's not for use in offensive warfare.

Speaker: SPEAKER_04
Transcript:  Again, engineers really need to work on English.  The language.

Speaker: SPEAKER_02
Transcript:  I love engineers.  It's all binary.

Speaker: SPEAKER_07
Transcript:  And by the way, in this case,  non-offensive does not take a hyphen.  No.  Because non as a prefix does not take a hyphen.  They could have said maybe,

Speaker: SPEAKER_03
Transcript:  if they had said maybe something like not  for offensive purposes, something like that.  You know, you're going to have to teach me  the red pencil techniques.  I need to learn how to red pencil here.

Speaker: SPEAKER_07
Transcript:  Do the little squiggle, the squiggle.  Squiggle.  Oh, that's like red.

Speaker: SPEAKER_03
Transcript:  I need a, I need a, I need a tighter line here.  And then  Jeff, do you use those students' papers?  Do you?  You've seen that before, huh?

Speaker: SPEAKER_07
Transcript:  Oh yeah.  I did it with my kids' papers.  My poor kids.

Speaker: SPEAKER_04
Transcript:  Do you have a red pencil?

Speaker: SPEAKER_03
Transcript:  See, with the new Surface Studio,  I got a pencil of any color at any time.

Speaker: SPEAKER_02
Transcript:  Let's just see here.  Well, aren't you fancy?  Aren't I fancy?  I still dig my Wacom tablet.  Stet.

Speaker: SPEAKER_03
Transcript:  Um, yeah, this is like a Wacom tablet right on the screen.  The Pentagon uses video analysis in counterinsurgency  and counterterrorism operations.  So, but that's not offensive.  That's defensive, right?  Or is it offensive?  I don't know if it's offensive.  I'm not offended.

Speaker: SPEAKER_07
Transcript:  Wendy, do you know this stuff?  You're in security.

Speaker: SPEAKER_01
Transcript:  Sometimes offensive can be both.  But has anybody looked at the Wikipedia page for IBM?

Speaker: SPEAKER_00
Transcript:  Oh no.

Speaker: SPEAKER_01
Transcript:  International business machines during World War II.

Speaker: SPEAKER_03
Transcript:  They were surely used in defense.  They were used in Nazi Germany.  By Nazis?  Yeah.  Oh, that's right.  They were used to tabulate, like tabulate census and counts.  And that's a good point.  IBM did that.  And I drove a Volkswagen for years.

Speaker: SPEAKER_01
Transcript:  The IBM product line, according to the Wikipedia artist,  shifted from tabulating equipment  to a Sperry and Norden bomb sites,  Browning automatic rifle and the M1 turbine.  And engine parts.  So, you know, there's a long and storied precedent for this.

Speaker: SPEAKER_03
Transcript:  There's a book published in 2001 called  IBM and the Holocaust,  the strategic alliance between Nazi Germany  and America's most powerful corporation.  Yikes.  They supported genocide through tabulation  and generation of punch cards.  They created gun sites.  Oh my goodness.  Company's response.  Let's see what the company said.  That was a long time ago.

Speaker: SPEAKER_01
Transcript:  Yeah, I think the point is that,  especially with the sort of widely used  and all purpose software and data that we make today,  you can use it for just about anything.

Speaker: SPEAKER_05
Transcript:  Yeah.

Speaker: SPEAKER_01
Transcript:  And...

Speaker: SPEAKER_03
Transcript:  Yeah, it's that same thing again, right?  It's the same problem.  It's a double edged sword.  You know, here's the problem with face recognition.  It can be used in a lot of less benign ways.  For instance, Google employees are concerned  that it might be used in analysis of drone video  to pick out human targets for drone strikes.  But it could also be used to pick out civilians  to make sure that they don't get hit.  Safety, yeah.  So.  But Sundar Pichai said yesterday,  any military use of machine learning  naturally raises valid concerns.  We're actively engaged across the company  in a comprehensive discussion on this important topic.  He says, these exchanges are hugely important  and beneficial.  I think that's true.  The company also said that Project Maven  was specifically scoped to be for non-offensive purposes.  Let's see, what else?  Google might be making a new Pixel phone,  a cheaper model, perhaps.  But not for us.  Not for us.  For the developing world, probably, right?  This is particularly for India.  According to four senior industry executives  who talked to ET Tech,  Google is working on a mid-range Pixel 3 phone.  Actually, there are several types of products for India,  including smart home products like the Nest  and the Google Home, even the Pixelbook.  Maybe we'd see a cheaper Pixelbook.  Boy, that would be nice.  That'd be nice.  Yeah.

Speaker: SPEAKER_02
Transcript:  Yeah, I'd like to have that.  Oh, I can't get it here.

Speaker: SPEAKER_03
Transcript:  You can't get a Pixelbook?  Oh, yeah.  That's the cheap one.  That's the cheaper one.

Speaker: SPEAKER_02
Transcript:  Maybe.  I'm sure there's ways.  There will be ways.

Speaker: SPEAKER_07
Transcript:  Do you use Pixelbook, Ed?  Pixel?  I used to use a Chromebook.

Speaker: SPEAKER_02
Transcript:  I used to use a Chromebook quite heavily,  but the more I got into editing video,  I had to step away from it.

Speaker: SPEAKER_03
Transcript:  Right, right.  I would love to see Chrome extensions  for some of the more professional uses.  You know, we were talking earlier today,  Windows Weekly, about the fact that Microsoft  is, in Mary Jo Foley's words, demoting Windows.  That they're focusing, they've reorganized again,  and they're focusing more on services and cloud  than they are on Windows.  That they see their future in the cloud.  And what it really is, is a long-standing trend  away from operating systems and desktop computing  toward cloud computing.  Don't like that idea at all.  What were they doing that ages ago?  Well, and Apple's doing the same thing, right?  Apple's starting to do the same thing with Macintosh.  It doesn't, they really don't seem like  they care much about the Mac at all.  But I think that's as much users as it is,  you know, iOS is so successful.  I don't know if Microsoft says that in so many words,  but the fact that they fired or let go,  or really, I don't know what.  They demoted the guy, Terry Meyers,  and the guy in charge of Windows.  And they split, and they protect the Windows  and devices division and split it up.  Really is a demotion.  It means it's less important to their overall future.  You're right, there's people who are,  so there's two groups of people  who are really disadvantaged by this.  One is creatives like you, Ant, videographers, photographers.  The other is gamers who still use Windows machines.  Those are the top games.  Game machines, yep.  Meanwhile, Intel released today the i9,  which is very confusing.  Six core mobile processor,  I think for the mobile gaming segment, I guess,  I don't know, for laptops.  All right, I think we got it, we got it.  Before we wrap this up,  we've got to talk about President Trump and Amazon.  Oh, boy. Yeah, yep.

Speaker: SPEAKER_04
Transcript:  I think it's pretty obvious that-

Speaker: SPEAKER_02
Transcript:  Let me take another drink.

Speaker: SPEAKER_03
Transcript:  The President's not a fan of Jeff Bezos.  Because of the Washington Post,  he really does think that the Washington Post  is the Amazon's propaganda arm.

Speaker: SPEAKER_07
Transcript:  But most of the coverage isn't really focusing on that.  Most of the coverage is focusing on the postal stuff,  which is complete lies, complete lies.

Speaker: SPEAKER_03
Transcript:  Yeah, I mean, I think it's not a good precedent  for the President of the United States to target companies.  Amen.

Speaker: SPEAKER_07
Transcript:  And full disclosure, I own the stock, so I'm pissed.

Speaker: SPEAKER_03
Transcript:  Yeah, and it certainly has hurt the stock, right?  Although I think eventually the stock market  kind of wakes up and says, oh, come on.  And the postal service, we should point out  the postal service is going to every house,  almost every house in the country anyway.  It's on the way.  Right.  So if Amazon doesn't use them for delivery,  it doesn't save them money.  And in fact, even if Amazon has a negotiated lower rate  with the postal service, which I expect they do,  I'm sure they do.

Speaker: SPEAKER_07
Transcript:  Which is a standard open rate that everybody has.

Speaker: SPEAKER_03
Transcript:  Right. Yeah.  Then every box that Amazon gives the postal service  is money to the postal service.  They're going there anyway.

Speaker: SPEAKER_07
Transcript:  Tomorrow I'm going to be a part of a panel  for the eighth version of the Postal Vision 2020  conference in Washington.  You did this last year.  I think this is great.  I did this before.  It's great.  It's a postal conference.  They had Amazon speak today and they couldn't be there.  Tomorrow they have Jamie Siminoff speaking.

Speaker: SPEAKER_03
Transcript:  From Ring, our sponsor.  And the newest Amazon acquisition.

Speaker: SPEAKER_07
Transcript:  And rethinking delivery entirely as an industry.  And the poor postal service is saddled  with all this pension stuff  that Congress won't fix them with.  But the postal service does not use tax dollars.  Well, there's two things going on here.  One is Washington Post.  And the other one is, some say that Trump  is just wildly jealous of a real billionaire.

Speaker: SPEAKER_03
Transcript:  No, no, no.  Oh, true.  And the reason the market's reacting  is not so much this postal service thing,  but the fact that Trump's trying to get the Pentagon  to cancel Amazon's pending  multi-billion dollar cloud services contract.  With the Pentagon.

Speaker: SPEAKER_07
Transcript:  Well, Sarah Sanders said, no, no, no.  He's not involved in that.

Speaker: SPEAKER_03
Transcript:  No, he's not even allowed to.  It would, actually, if the president interferes  with bidding or contractual, that's actually illegal.  But that doesn't mean he won't try  and it doesn't mean he won't succeed.  Exactly.  So no love lost between Trump and Bezos.  Trump has told advisors, according to Vanity Fair,  that he believes Bezos uses the paper as a political weapon.  One former White House official said,  Trump looks at the Post  the same way he looks at the National Enquirer.  What?

Speaker: SPEAKER_07
Transcript:  Well, the National Enquirer is a political weapon  in his behalf.  Ah, all right.  Let me just say, let me just say for a minute,  I now believe that the Washington Post  is the finest newspaper in America.  It's the one I start with every morning.  More than the times.  I do.  And Marty Barron is the best editor in America.  And I have complete, absolute, and utter trust  and respect for Marty that he would never, ever  allow a Sinclair to be pulled on him  and have words put in his mouth.

Speaker: SPEAKER_03
Transcript:  Oh, you must love that Sinclair story.  Wow.  Oof.  Oof.  I watched John Oliver on Sunday.  What happened with Sinclair?  So Sinclair Media, which is a conservative-owned media group  and is currently trying to get approval  for it to buy all the Tribune stations,  Sinclair owns a huge number of TV stations.

Speaker: SPEAKER_07
Transcript:  They own 40, they're in 40%, they're in 40,  they have 193 stations, they're in 40% of markets  of households covered.  With the Tribune acquisition,  they would be in 71% of the country.

Speaker: SPEAKER_03
Transcript:  And what's happening is that, as happened all along,  is that Sinclair then sends memos to each station  saying you must run this editorial,  you must run this story.  They've been using Boris Epstein  and putting him on all the stations.  And they sent a script out  and had all their anchors record it, saying-  You got the video?  Let me see, where is it?  Is there a link in our show notes?  There is, but I'll get it up right now.  Because there's a great video of all of the stations  in a montage saying the same thing.  And it's essentially parroting the Trump line  that major news outlets are creating fake news  because they don't like him.  And let me see if I-  Now, although-  I just put it in the-  The way it's worded, it doesn't specifically say that.  It says, well, I'll play it for you.  This is NPR created this, I guess, yeah?  No, this is Deadspin.  Deadspin did this.  Deadspin, okay.

Speaker: SPEAKER_07
Transcript:  They deserve all credit for this.  This is brilliantly done.

Speaker: SPEAKER_03
Transcript:  I hope that's the full version.  This is Deadspin's tweet on the subject.  Let's see if I can play it.  Oh, I always have trouble with video.  You know what, I'm gonna put this in-  Let me put this in Edge.  For some reason, Microsoft Edge seems happier with video.  I wonder if it has anything to do  with the fact that I'm on a Windows.

Speaker: SPEAKER_02
Transcript:  I was gonna say, wait a minute.

Speaker: SPEAKER_04
Transcript:  Wait a minute, why would that be?

Speaker: SPEAKER_07
Transcript:  Wait, okay.  Remember when Microsoft was evil?

Speaker: SPEAKER_03
Transcript:  Yeah, yeah, they used to be evil, not anymore.  Here you go, let me put the-

Speaker: SPEAKER_06
Transcript:  And I'm Ryan Wolf-  Hi, I'm Fox and Antonio's Jessica Headley.  And I'm Ryan Wolf.  Our greatest responsibility is to serve  our Treasure Valley communities.  The El Paso, Las Cruces communities.  Eastern Iowa communities.  Mid Michigan communities.  We are extremely proud of the quality, balanced journalism  that CBS4 News produces.  But-  We are concerned about the trouble  that's trying to get responsible.  One side of the story is plaguing our country.

Speaker: SPEAKER_01
Transcript:  Plaguing our country.

Speaker: SPEAKER_00
Transcript:  The sharing of biased and false news  has become all too common on social media.  More alarming, some media outlets publish  these same fake stories without checking facts first.

Speaker: SPEAKER_06
Transcript:  The sharing of biased and false news  has become all too common on social media.  More alarming, some media outlets publish  these fake stories simply because they're true  without checking facts first.  Unfortunately, some members are using  the media platforms to push their own-  They're all saying exactly, holy crap.  This is extremely dangerous to our democracy.  This is extremely dangerous to our democracy.  This is extremely dangerous to our democracy.  This is extremely dangerous to our democracy.

Speaker: SPEAKER_03
Transcript:  I feel bad for these people.

Speaker: SPEAKER_00
Transcript:  This is extremely dangerous to our democracy.  Yeah.

Speaker: SPEAKER_03
Transcript:  Deadspin became aware of this with some of these anchors  anonymously.

Speaker: SPEAKER_06
Transcript:  This is extremely dangerous to our democracy.  We have to do this.  This is extremely dangerous to our democracy.  Well, yeah, because it turns out their contracts-

Speaker: SPEAKER_07
Transcript:  I saw a story today that a journalist paid-  This is extremely dangerous to our democracy.  40 grand would have to pay 25,000 to break the contract.

Speaker: SPEAKER_03
Transcript:  Oh, so they can't even just quit.  They can't walk out the door and say, I'm not going to say that.  So they actually literally have to do this.  Strong-garbed.  Yep.  Well, there you go.

Speaker: SPEAKER_07
Transcript:  And so you're not going to see anybody put words in Marty  Barron's mouth.  These poor schmucks.  And by the way, for the folks out there, you probably don't  know whether your station is Sinclair or not, because you  go by the brand of ABC, ABC, CBS Fox.

Speaker: SPEAKER_03
Transcript:  Well, that's the other thing.  They still run network programming.  It's these local-  Yeah, they still use that brand for their local news.

Speaker: SPEAKER_07
Transcript:  Right.  But Sinclair owns them as Sinclair puts Boris Epstein  and that kind of stuff in there.  Wow.

Speaker: SPEAKER_03
Transcript:  Yep.  Wow.  They are the ones, of course, that had a special deal with  the Trump campaign during the campaign to get access to  Trump in return for positive coverage, basically.  Yep.  Let's see.  Wendy Moore breaches Panera Bread.  What?  Here's one.  What?  This one's a good one.  I'm sure, Jeff, you have from time to time gone to Panera  Bread online.  I do indeed.  Ordered a sandwich.  And then you go and you pick it up.  Well, it turns out about seven months ago, a security  researcher noticed that the website was leaking this  information.  They had sequential customer numbers and all you'd have to  do is enter the next number and the next number and the next  number and the next number.  So he sent a notice to them, August 2nd, 2017, saying,  hey, you know, you can do this.  They dismissed him as a likely scam.  Uh-oh.  A week later, though, they responded and said, oh, thanks  for the information.  We're working on a resolution.  Fast forward to last week, he still was able to exfiltrate  all that information in exactly the same way.  Eight months later, he finally wrote a note to Brian Krebs and  said, hey, you really ought to know about this.  Brian published the story.  And shortly after he had spoken to Panera's chief  information officer, the website was taken down.  Eight months later.  Now, you didn't get credit card information.  You only got the last four of the credit cards, but you would  get a user's name, address, phone number, last four of their  credit card number.

Speaker: SPEAKER_07
Transcript:  Actually, I've used the terminals in the place and it's  not very secure at all.  Loyalty number.  Yeah.  But here's the scariest leak.  The underwear company leaked.  Wait a minute.

Speaker: SPEAKER_04
Transcript:  Which underwear company?

Speaker: SPEAKER_07
Transcript:  I mean, Jesus, well, your underwear is not secure.  And then Lord and Taylor and Saks Fifth Avenue.

Speaker: SPEAKER_03
Transcript:  Oh, you're talking about My Fitness Pal.  Yeah.  Under Armour.  Under Armour.  Yeah, My Fitness Pal.  150 million accounts.  But Wendy, these are most of the time not including credit  card numbers.  They may include passwords.  In the case of My Fitness Pal, they reset the passwords or  credit to everybody to re-log in.  What's the risk?  What's the danger of all of these leaks?

Speaker: SPEAKER_01
Transcript:  I think the largest danger of these sorts of information  leaks in general is twofold.  If there's information about the users, they can either be  used and automated in account takeover attacks on other  sites or the information, and this is something that I saw  when I was working for the retail intelligence sharing  and analysis center, is that the information that's being  shared on the retail intelligence center is that  criminals can take the information about users and turn  that into a scam against each user.  In other words, they can contact the user and pretend to be the  retailer and sort of authenticate themselves by  saying, we have this information on you, your order  number, 45678, on this date, and get them to give up even  more information in response.  So that's another danger that criminals can authenticate  themselves as a retailer by using information that a  customer would only expect that retailer to have.

Speaker: SPEAKER_03
Transcript:  That's a really good point.  They're much more credible in phishing scams as a result.

Speaker: SPEAKER_07
Transcript:  So, Wendy, is your job depressing?

Speaker: SPEAKER_01
Transcript:  Not anymore, now that I work where I do, because I think  our company has a very optimistic look on being able to  make security better, but certainly I spend a lot of time  talking with chief information security officers, and they  can turn into therapy sessions where they're telling me about  what they're doing, and I'm like, I know, I know, I'm not  surprised by any of this.  It is very, very hard, especially in areas like retail  where the margins are so slim, they often don't necessarily  get the budget that they need to address this properly.

Speaker: SPEAKER_03
Transcript:  Today's leak of the day.  Thank you, ScooterX, in our chat room.  I want to just do something to go back earlier.

Speaker: SPEAKER_07
Transcript:  Wait a minute, I haven't given you the leak of the day.  Hold on, Delta Airlines.  I thought that was the leak of the day.

Speaker: SPEAKER_03
Transcript:  No, no, no, I'm not even done.  There's Lord and Taylor, Saks Fifth Avenue, the leak of the  day.  Delta says online chat, cybersecurity breach puts some  customer payment info at breach.  Son of a b***h.  That's a big one.  Payment info, that's a little more serious.  Yeah.  Go ahead, Jeff.

Speaker: SPEAKER_07
Transcript:  Just one earlier story we had on, I just saw a tweet from  Patrick Grafini, who's a conservative consultant,  reacting to the Facebook reading messenger.  Grafini says on Ezra Klein's podcast, Zuckerberg said the  ability to do this is what stopped messages from coming  out that incited further ethnic violence in Myanmar.  Damned if you do, damned if you don't.  Yeah.

Speaker: SPEAKER_03
Transcript:  No, and they got a lot of heat for Myanmar.

Speaker: SPEAKER_07
Transcript:  Yeah, so where the stuff is happening now is in private  messaging.  Yeah.  And what do we expect?

Speaker: SPEAKER_03
Transcript:  Well, I just need, you need to tell people if you use  messenger, we will be scanning your messages for content that  violates our terms of service.  If you don't, then there's a problem.  They need, it's all about disclosure.  If people clearly understood what was going on and then  still use the messenger, I wouldn't have a problem with it.  They need to clear, they need to disclose.  Do you not agree, Jeff?

Speaker: SPEAKER_07
Transcript:  Yeah, but this is the irony of some of this is that, and Wendy  jump in here, at a security level, you could argue that the  more transparent you are about it, the less likely you are to  then catch the bad guys, stuff the bad things.

Speaker: SPEAKER_03
Transcript:  Well, it's not their job to create a honey pot for racial  cleansing in Myanmar.  Their job is not to create a honey pot.  Their job is to tell users what they're getting involved in.

Speaker: SPEAKER_07
Transcript:  Oh, but I'm hearing, oh boy, do I hear a lot right now about  how, yes, their job is to recognize the responsibility of  their role of how it's being used in Myanmar.

Speaker: SPEAKER_03
Transcript:  Well, that's true, but not be a honey pot, not hide what, that  we're going to look at it so we can catch you.  That's not their role.  That's not at all their role.

Speaker: SPEAKER_07
Transcript:  Well, but there's a question of how transparent are you, how  I agree with you on this one.  I agree with you, but it has nuance.  OK.  That's all I'm saying.

Speaker: SPEAKER_03
Transcript:  And we're going to leave it at that.

Speaker: SPEAKER_07
Transcript:  That's the greatest discussion ender there is, you know?  Can I has nuance?  Yes, I can has nuance.  I can has nuance?  Oh, no.  I've got a nuance headache.  No.

Speaker: SPEAKER_01
Transcript:  And the answer is maybe.

Speaker: SPEAKER_04
Transcript:  I use duo.  I love duo, Wendy.

Speaker: SPEAKER_03
Transcript:  I want to thank you for being here, duo.  I don't know all of your businesses, but the two factor  authentication that duo does, I use with LastPass.  Instead of a number, it sends you a notification which you  can agree to, which is to me not only the easiest way, but  it's a more secure way to offer second factor.  And actually, we are now looking at putting duo into our  office and requiring that everybody who has access to our  password vault in LastPass use duo as well, because we have a  people who have a password which they set to our enterprise  LastPass, but I would like them to have to have two factor on  that as well and require that.  I think duo is a simple way to do it.

Speaker: SPEAKER_01
Transcript:  Yeah, that's very important, especially for LastPass.  Yeah, there's just too much in there.  Or any password manager.  Yeah.

Speaker: SPEAKER_03
Transcript:  It's great to have you, Wendy.  Thank you so much for joining us.  Wendy runs the advisory CISO group at Duo Security.  She's director there and she's at Wendy Nather on the Twitter.  So nice to talk to you in Austin and have you back on the  show today.  Thank you for having me.  Thank you.  Jeff Jarvis is an SOB who works at the City University of New  York.

Speaker: UNKNOWN
Transcript:  Professor SOB to you.

Speaker: SPEAKER_07
Transcript:  Professor SOB.

Speaker: SPEAKER_04
Transcript:  No, I know there is no doubt, but I love Jeff and Jeff loves  me.

Speaker: SPEAKER_03
Transcript:  We're good friends and that's why we argue, right?  BuzzMachine.com.

Speaker: SPEAKER_07
Transcript:  That's exactly why, because we know we can.  Yeah, we love each other.

Speaker: SPEAKER_03
Transcript:  So thank you, Jeff, for being here as always.  Are you traveling in the near future or are you going to stay  home for a little bit?

Speaker: SPEAKER_07
Transcript:  Yeah, next week is in Perugia, Italy.  Oh, you son of a...  Now I'm just jealous.

Speaker: SPEAKER_03
Transcript:  All in life.

Speaker: SPEAKER_02
Transcript:  Now I'm just jealous.  I have to rush back, so I'm there for two days.

Speaker: SPEAKER_07
Transcript:  Two dinners of pasta.

Speaker: SPEAKER_03
Transcript:  It's a mixed thing because he gets to go to Italy next week,  but tomorrow he has to spend time with the post office.  So, you know.  Yeah, exactly.  Comes and goes, comes and goes.

Speaker: SPEAKER_07
Transcript:  I've got to take my trade off.

Speaker: SPEAKER_03
Transcript:  We love Ant Pruitt.  It's great to have you on this show.  We're going to have you on more on this.  He's a contributor to Tech Republic.  You can follow him on Twitter at and underscore Pruitt.  P-R-U-I-T-T.  And where can people see your...  I guess Instagram is a good way to follow you, right?

Speaker: SPEAKER_02
Transcript:  Yes, sir.  Follow me on Instagram.  There's no underscore there.  It's just Ant Pruitt.  But I'd appreciate it if everyone would subscribe to my  YouTube channel as well, because I'm doing a few more  tutorials.  Oh, that's great.  Tech Republic has asked me to do a few more tutorials as well.  It's just YouTube.com slash Ant Pruitt.  Do we have a moment so I can ask Miss Wendy a question?  Yes.  Miss Wendy.  Yeah, go right ahead.  Now, I know he, Mr. Jarvis was asking if you're depressed  when you're with your clients and whatnot.  Because I'm an SOB.  But it just, it also made me think about a shameless plug,  a video session that I did with Mr. Dan Patterson,  where I wrote about IT users are like the worst when it  comes to security inside of the enterprise.  Have you found that?  I wouldn't say that.

Speaker: SPEAKER_01
Transcript:  I would say that it's more that we don't build things in a  very usable way in general.  Now, we're trying to improve on that.  Certainly, you know, at Duo, we actually have people coming  up to us saying, oh, I love Duo.  And when do you ever see that?  When do you ever say that about a security product?

Speaker: SPEAKER_03
Transcript:  I always say I do love Duo, actually.

Speaker: SPEAKER_01
Transcript:  But no, it's that we don't understand our users' needs  and their imperatives very well.  And if we can design things better so as not to get in  their way, then they're perfectly happy with it.  So I think, you know, everybody has their, has, you know,  friction that they have to deal with with technology.  I get cranky as hell whenever any SaaS application that I  use makes a gratuitous UI change.  They move something from one side of the screen to the  other, like in the middle of my session.  I get really cranky about that.  So, you know, we just have to get a lot better about not  assuming that people are just as happy and can overlook some  of the things that we overlook.

Speaker: SPEAKER_02
Transcript:  Yeah, I was thinking more along the lines of like,  They're lazy.

Speaker: SPEAKER_03
Transcript:  They have post-it notes on the side of their screen with  their passwords.

Speaker: SPEAKER_02
Transcript:  Well, that, then you have, it's just that whole God complex.  I'm an IT, I can do whatever I want kind of thing.  You know, at the previous company that I worked for,  I ran into a lot of that with the upper tier IT folks.  And I'm like, dude, you know, that's a security risk.  Just slow your roll.  You know, there's a scene in Ready Player One, and it's

Speaker: SPEAKER_03
Transcript:  actually a lot of the movie turns on the fact that the bad  guy has his password on a post-it note in his VR chair.

Speaker: SPEAKER_04
Transcript:  He can't remember it.  So it is bliss.

Speaker: SPEAKER_01
Transcript:  Yeah, that's now become a trope.  It's a trope.  It's the bad design.  You know, whoever thought that storing primary authentication  in fragile human memory was a good idea.  It was widespread and it was cheap at the time.  But, you know, that was our bad designing that and then  telling them not to write it down.  But now I agree that in some cases there are, you know,  IT people who still have the attitude of, you know,  I control all of this and I'm, you know,  I'm going to make you do what I want.  But the other thing is we tend to moralize a lot around  technology and say that users are lazy or, you know,  they're ignorant when it's really we who have failed them.  And that attitude is starting to get better.  It used to be, you know, that users were just called losers  and they were called stupid.

Speaker: SPEAKER_02
Transcript:  Stupid users.  Exactly.

Speaker: SPEAKER_01
Transcript:  And luckily that's going away because, you know,  at some point the users are going to rise up and say,  how exactly is this our fault?  Yeah.  And I don't think we'll have a good answer for them.

Speaker: SPEAKER_03
Transcript:  Go see Ready Player One and look for the post-it note.  And then I want to know, Wendy,  if he had a good password or a bad password.  It looks good, but...

Speaker: SPEAKER_01
Transcript:  It was so typical.  It was typical.  Did you think that?

Speaker: SPEAKER_04
Transcript:  Are you sitting in the movie thinking,  oh, that's so typical?

Speaker: SPEAKER_01
Transcript:  Yeah, I mean, it was Boss Man, you know, with fives for S.  Oh, it was?  Oh my God.  See, I looked at it.  I examined that password very thoroughly.  But yeah, it was like Boss Man.  Actually it was Boss Man 69, if I remember correctly.  In Leet.  Oh my God.  I didn't notice it.  It was so juvenile.  So yes, that was part of the trope itself.

Speaker: SPEAKER_03
Transcript:  Here's Ant's Instagram, but don't forget his YouTube account,  which is youtube.com slash Ant Pruitt.  Thank you all for being here.  Really a fun show today.  Thank you, sir.

Speaker: SPEAKER_07
Transcript:  May I leave you with this?  I just saw Mike Godwin, creator of Godwin's Law.  I just saw.  Yes.  He has a new law.  Yes.  He didn't call it a law, but we call it a law.  It is this.  The difficulty with high Dugin is that the clarity of the analysis  is inversely proportional to the height of the Dugin.

Speaker: SPEAKER_04
Transcript:  Oh, I like that.  Are you accusing me of high Dugin?

Speaker: SPEAKER_07
Transcript:  I said nothing.

Speaker: SPEAKER_04
Transcript:  I just so greet you.  That's his new phrase.  Forget moral panic.  We got high Dugin.  Hi, Dugin.  Hi, Dugin.

Speaker: SPEAKER_07
Transcript:  The Dugin's getting up there.  Dugin's getting higher.

Speaker: SPEAKER_04
Transcript:  Dugin's getting higher, man.  Dugin's got a dudge.  Thank you all for joining us.  We do this week at Google every Wednesday afternoon,  1.30 Pacific, 4.30 Eastern, 20.30 UTC.

Speaker: SPEAKER_03
Transcript:  If you want to stop by and watch live, go to twit.tv slash live.  And if you do that, be in the chat room by all means, irc.twit.tv.  You can download on-demand audio and video, of course,  of everything we do from our website.  In this case, twit.tv slash twig.  We've got every show there, all of our shows.  But also, you can subscribe in your favorite podcatcher,  whether it's Overcast or Pocket Casts, Apple Podcasts, Google Play,  whatever you use, subscribe because you don't want to miss an episode.  Thanks for being here.  We'll see you next time on This Week in Google.  Bye-bye.

