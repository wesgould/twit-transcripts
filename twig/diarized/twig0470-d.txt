;FFMETADATA1
title=Sparkle Vamps
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=470
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2018
encoder=Lavf58.76.100
Speaker: SPEAKER_03
Transcript:  It's time for Twig this week in Google. Jeff has the week off. Joan Donovan sits in for him from dataandsociety.net.  Of course, Stacey Higginbotham will be here as well. So will the changelog, its triumphant return.  Some interesting new tips and tricks from Google. We'll talk about Facebook and Twitter and why I'm leaving the mall.  It's all coming up next on Twig.

Speaker: UNKNOWN
Transcript:  This is Twig.

Speaker: SPEAKER_03
Transcript:  This is Twig. This Week in Google. Episode 470 recorded Wednesday, August 22, 2018.  Sparkle Vamps. This Week in Google is brought to you by DigitalOcean.  The easiest cloud platform to deploy, manage and scale applications.  Over 150,000 businesses rely on DigitalOcean to remove infrastructure friction and deliver industry-leading price performance.  Sign up today and receive a free $100 credit at do.co.twig.  And buy LastPass. Secure every password-protected entry point to your business.  Join over 33,000 businesses and start managing and securing your company's passwords today.  Learn more at lastpass.com.  And buy Rocket Mortgage by Quicken Loans. Introducing Rate Shield Approval.  If you're in the market to buy a home, Rate Shield Approval locks up your rate for up to 90 days while you shop.  It's a real game changer. Learn more and get started at rocketmortgage.com.  It's time for Twig. This Week in Google. The show where we talk about the latest from the Googleverse, which means really anything and everything.  Stacy Higginbotham is here from Stacy on IoT. She likes to cover IoT and hardware, but everything else too. Hi, Stacy.  Hello, Leo. Good to see you. And Joan Donovan is here from Data & Society. So great to have Boston Joan.  In fact, we were talking about you. We were using your name in vain because we were talking about a study that just you guys just put out at Data & Society.  And I forgot what it was about.

Speaker: SPEAKER_00
Transcript:  Now there's there's new studies all the time. Was it? Yeah. Give me a give me a hint.

Speaker: SPEAKER_03
Transcript:  Say it again, Carson, because Alex Jones. Oh, we were talking about. Oh, yeah. Yeah. And about how actually was great.  It was the article that started off with Rockwell and the Nazis in the 60s. And we were talking about how he knew very well that his story wouldn't really get any traction by itself.  But if you could get the mainstream media to pick it up, it would amplify it.

Speaker: SPEAKER_00
Transcript:  Yeah, yeah, no, that is it's been sort of the bane of my existence for the last year has been tracking what happened after that Unite the Right rally.  There was lots and lots of action from platform companies to remove accounts, especially ones associated with known white supremacists, white nationalists that organized that rally.  And overwhelmingly, what we find is that, yeah, if platforms don't give them the tools to coordinate, they have a really hard time gaining audience.  And so it'll be interesting to see the fallout from the partial no platforming of Alex Jones.  But I don't know what's going to happen. I mean, he's still got stuff on Twitter. There's still plenty of content on YouTube.  It's really hard. You know, the adage that the Internet is forever is still sort of true in this strange way.

Speaker: SPEAKER_01
Transcript:  The Internet, if you're a dedicated hunter of information, you probably can find it on the Internet.  And I think I think his diehard followers are dedicated hunters of information, although there are probably plenty who will be like, OK, like, yeah, I do think making it harder to link to inflammatory stuff.  That he has written or said is probably not a bad thing.

Speaker: SPEAKER_00
Transcript:  And I think the biggest concern that I've had about this for the last year is really about content recommendation systems.  Right. So how does it end up getting served to people that are looking for information?  You know, he's probably got the most comment content online about Sandy Hook.  And so if you're looking for information about what happened or even searching for information about should I rent an apartment in that town, you end up being served Infowars content.  So there's a recommendation and search is something that we need to think a lot more about as we start to restructure information online.

Speaker: SPEAKER_03
Transcript:  Was it your article that suggested quarantining?

Speaker: SPEAKER_00
Transcript:  Yeah. So that's one of the things that Dana Boyd and I have been looking at for the last year is if we go back into the 60s and 70s and understand what was the major shift in journalism that happened related to coverage of the KKK or the American Nazi Party, which is Rockwell's Rockwell's.  The head of that. What you see is that media thought a lot about strategies for ensuring that they don't get coverage through violence.  And so they would talk about quarantining.  Journalists would talk about it as well as civil rights organizers would talk about quarantining certain extremist ideas or rallies.  And so that it doesn't turn into a big public discussion.  And what was particular about the KKK at that time was also that they were using really, you know, like with cross burnings and their parades and things, they really wanted to look intimidating.  And so they often used fire as part of the imagery of their movement.  But part of it was strategic to get front page coverage and so that they would end up in everybody's, you know, in everybody's view.  And so the use of optics we saw directly translate into the organizing of that Unite the Right rally on that Friday night.  The Tiki torches.  Using those torches. Exactly.  This is straight from the Norman Lincoln Rockwell playbook.  Exactly. And so the notion of optics and how do you get...  Wrong Rockwell.

Speaker: SPEAKER_02
Transcript:  I can't remember. There's Lincoln in there somewhere.  George?  Yeah, George.  You know, it's great. We've forgotten his name. Awesome.

Speaker: SPEAKER_03
Transcript:  I know, right?

Speaker: SPEAKER_00
Transcript:  George Lincoln Rockwell.  But yeah, just the idea of like spreading content, especially through the images that they want to present about themselves.  We're seeing these deep resonances with what we're going through now where lots of people are using social media.  We're spreading images like this.  And these images are really about two things.  One is recruitment. That is, they want to look really strong and powerful and cool.  And then the other thing is about spreading terror and mayhem, right?  Making people feel as if they are more powerful.  So we are looking at what it might think.  You know, we're thinking through how platforms could adopt what we might call strategic amplification so that when events like this happen,  they aren't susceptible to spreading ideologies or the images that these white supremacists really want to share,  but rather are doing more responsible and more ethical recommendation.

Speaker: SPEAKER_01
Transcript:  Got it. So turn the cameras off the flaming crosses and back to the counter protesters who might be holding up signs saying,  Hey, we love everybody or nice people doing nice things.

Speaker: SPEAKER_03
Transcript:  It was always something that bothered me and way back to my college years about a certain category of propagandists.  And we see them a lot more now.  They tend to be on the right, but not always that do a lot of I'm joking, wink, wink stuff, dog whistling kind of.  But in a joking way, I'm just joking so that if anybody confronts them on their evil rhetoric,  their Nazi rhetoric, they just, oh, no, you know, can't you take a joke?  You got a sense of humor. Yeah.

Speaker: SPEAKER_00
Transcript:  And that's one of we have a report coming out.  Hopefully next month, we're still waiting on the some of the, you know, editing and and whatnot to come back.  But it's about the uses of irony in these spaces.  So this moment where you'll see tried and true neo-Nazis recruiting on social media platforms.  And if they get caught, they move into this space of, oh, it's just parody.  Oh, I'm being, you know, I'm joking around.  You can't take a joke.  That's what something awful and 4chan insert to some degree.

Speaker: SPEAKER_03
Transcript:  It's a very common trope.  Oh, come on. Yeah. This is where the lulz.

Speaker: SPEAKER_00
Transcript:  Yeah. And that that kind of hedging is difficult if you're running a content moderation protocol.  Right. Because at the same time, you don't want to over moderate content and you want to have room for humor.  But we see that that that ironic that ironic hedge is really running cover for getting out of, you know, strikes or bans on accounts that are spreading this not just content.  And you'll see there's one very particular meme I'm thinking of right now, which is the Hitler did nothing wrong.  And so you'll see this on all of these other spaces.  And and it's become a joke.  And even in some of the subtext of, you know, conversations online with other people, they'll make reference to this meme.  Maybe they'll substitute not Hitler.  But you'll see people tweeting, you know, Alex Jones did nothing wrong.  And it's a wink and a nod to this other meme that is, you know, done out of irony and jest, but also useful to the recruitment by some of these white nationalists online.

Speaker: SPEAKER_03
Transcript:  This is why I've just wiped, washed my hands of social media.  I really tried to fight this for the longest time and say, no, there's good stuff there.  Stacey, you've always said, you know, there's real value in it.  I hear that a lot from people despite the pollution.  You know, there's something good in there, but I'm just tired of drinking from that stream.  There's too much pollution.

Speaker: SPEAKER_01
Transcript:  So how do you. So this is.  Beyond the issues of white supremacy and the kind of doing it for the lolz aspect of it, this is something that I know women face all the time just in counteracting sexist language and behavior.  Right. So I'm thinking about Joan from a, I guess, a strategic point of view as a platform, as a media company, because there there is a subset.  You know, I remember myself in my teen years because teenagers are all a bunch of jerks, you know, we're like, ha ha ha ha.  We're so cutting edge.  And so I'm trying to think about how you both recognize that and adapt to it, because that is how some of these people do get sucked in at some point in time.  You or I, not that I joked about Hitler or Nazis, but, you know, you do have a blacker sense of humor, perhaps.  And so.  I don't know, like, how do you engage those people or not engage those people and help them not be recruited further in?  I don't know.  There's a lot of questions.

Speaker: SPEAKER_00
Transcript:  No, and I think that there's no one solution that we can just adopt and say, oh, this is the method that's going to work.  Right. So there are groups of people that are dedicated to engaging with people who post much, much more violence rhetoric online and in a one to one scenario will try to understand their motivations.  This is especially done with people who are posting more anti-immigrant sentiments.  Then there's other de-escalation techniques where people will go and redirect the content online.  So people will be talking about one thing and then people start, you know, people might intervene by spamming the thread to get people talking about something else, especially if things start to get too dark or too serious.  But one of the things that I think we've been wholly unprepared for is understanding the relationship across all of these platforms and where content on something like YouTube is being gamed, but not on YouTube.  It's being gamed in off platform chat rooms or message boards where they're saying, oh, I noticed that YouTube is starting to moderate for the use of X, Y, and Z speech.  So let's change how we talk about these people to use this other dog whistle.  And so they're constantly updating their terminology, updating through, you know, other platforms ways of getting around the terms of service on much, you know, much larger platforms that are capable of doing content moderation.  But we see that the gaming of systems usually is happening in spaces that have a lot less moderation than YouTube, Facebook or Twitter.  And then Facebook and Twitter and YouTube are really the spaces where these techniques are deployed.

Speaker: SPEAKER_01
Transcript:  OK, I think it's kind of funny mentioning the gaming of the system because my daughter, who is she just turned 12, she plays an online game called Star Stables.  And they're not allowed to do.  They're not allowed to talk about a lot of things as a means to protect kids who are playing it.  But it is hilarious how the kids get around it.  Just and this is innocuous.  My child is not, you know, being a jerk.

Speaker: SPEAKER_03
Transcript:  An exciting online game where adventures, horses and mysteries are waiting to be explored.

Speaker: SPEAKER_01
Transcript:  Yes.  So but the point is, I think that's as light as kids trying to get around that so they can kind of make friendships on this game or talk to each other about things that the moderators don't want them to talk about on global chat all the way to censorship in China.  So, I mean, this is just people, but I appreciate.  I don't know, Joan.  It feels like you've got to be.  Is it tilting at windmills?  I don't know.  I'm just like, oh, yeah.

Speaker: SPEAKER_00
Transcript:  Well, you know, the way that we do our research, I think, is really about bringing to light these different techniques and understanding where design decisions might make a difference, but also understanding where this is a broad social problem.  Right.  And so we don't want to put all the blame on platforms and technology companies because we do know that there are social networks of real people involved that are doing, you know, they're doing quite a quite a bit of ingenuity to get around these systems.  And I think, you know, it speaks to a longer history that we have here where now we have had the Internet in people's homes for long enough that now that I'm seeing journalism is tilted towards reporting what's online and we're seeing less and less reporting about what's happening in meat space.  And so it's been interesting to see that shift where the online world is becoming more and more real as we lose less and less of a hold and a grip on what's happening offline.

Speaker: SPEAKER_01
Transcript:  I don't know if it's more real, but it is an easier thing to cover.  And you can get, you know, one of the challenges of local journalism is that you can only get however many people care about your local issues to read it.  Right. And in an era of scale, talking about something online matters to everyone who's online, which is all the possible clicks.  Right. So I think that is one of the challenges.  And I will give you so much money, Joan, if you never say the word meat space again.

Speaker: SPEAKER_02
Transcript:  It is disgusting.

Speaker: SPEAKER_03
Transcript:  It's making me want to be a vegetarian, but I understand what you're saying.

Speaker: SPEAKER_00
Transcript:  It's because I can't, you know, I can't in good faith use the word offline anymore.  I mean, I've got cell phones.  IRC?

Speaker: SPEAKER_03
Transcript:  I was watching TV last night and there were successive ads, several, that began and end with people looking at their smartphones.  And what I realized is it wasn't a coincidence.  It's just so much part of the way life is that everybody's always looking at the smartphone that if you're going to represent it in an advertisement,  if you're going to represent people, they're going to be looking at their phone.  It had nothing to do with smartphones.  It's just that's what they were doing.  So meanwhile, your smartphone is tracking you.  We talked about this last week.  AP discovered that even when your location history is turned off, if you launch certain apps, Google will keep track of where you are.  I got a little battle yesterday with Steve Gibson, who says, well, they really shouldn't.  And, you know, it's complicated because there are other settings as well.  And Google does kind of hide these settings.  But they do warn you when location history is turned off that you still will be sending location to Google.  Anytime you do searches, it says some location data may be saved as part of your activity and other services like search and maps.  Actually, that's the new language that Google stuck in there last Friday.

Speaker: SPEAKER_01
Transcript:  Yeah, I was going to say I haven't ever seen that.  I've never seen that. And I turn my location off all the time.

Speaker: SPEAKER_03
Transcript:  That's different.  You're not. So you're turning location off and location history off.

Speaker: SPEAKER_01
Transcript:  I turn location history off.  And sometimes I actually well, now I don't think I can turn the GPS off unless I go into airplane mode.  But I used to be able to turn all of my location off.  It used to be a setting that you could turn off location.  I wish I'd like I'll be honest.  My mom no longer takes her phone with her when she leaves to go places unless she abs.  How are we going to find her if she does that?  So my favorite thing is she brings it to places if she has an online coupon she needs to show the store clerk.  So then she'll bring her phone. But the rest of the time she's like, no phone.

Speaker: SPEAKER_03
Transcript:  Well, now Google's being sued by a San Diego man.  Activists in Washington are urging the FTC to, and I think this is probably appropriate, investigate whether the company is in breach of its dissent, its consent decree from 2011.  The lawsuit which was filed on Friday in San Francisco for representing a guy named Napoleon Patasiel argued that Google is violating the California Invasion of Privacy Act and the state's constitutional right to privacy.  We're trying to get class action suit on this epic.  We talked about the Electronic Privacy Information Center that wrote a sternly worded, according to Aris Technica, three page letter to the FTC.  This is a tricky one because it's clear that Google didn't really want to make it too easy to turn off location.  On the other hand, it's not hard. It's not. I don't think it's a stretch to say, well, when you use maps and search, Google's it's it's helpful for Google to save that information so you can find your way back so that your search is location based.  But ultimately, it's in their commercial interest that they save your location information.  So I think it's a good thing that this came to the surface and that Google probably will modify its settings and verbiage to reflect really what should be reflected, which is how to do this and whether you've actually done it.

Speaker: SPEAKER_00
Transcript:  Yes.

Speaker: SPEAKER_01
Transcript:  Yes. Yes. Again, I will say for a company that wants to suck up as much data as it does, and I will give it full credit for using that data to make a lot a hugely better experience for me.  I love it. But I'm kind of like Google. I've given you all this. Yeah. Let's work on the trust here. Yes. That seems fair.  I'll give it to you if you like say, hey, this is what I'm going to do with it. When you get all cagey with me, I'm like, oh, well, I don't know.

Speaker: SPEAKER_03
Transcript:  And here is an example of why you might not want Google to always keep all of the information about where you are. Google's fighting this.  But nevertheless, it's concerning the FBI investigating a spate of armed robberies across Portland, Maine, made an unprecedented request of Google.  This is back in March, but it's coming forward now. The feds said we would like the information of everybody who uses a Google phone or uses Google services, who was within the vicinity of at least two of these nine robberies within the 30 minute time frames of the robberies.  The space covered is I don't know why it's in hectares, but it is and I can't convert, but it's a large area, 45 hectares, includes anyone with an Android or iPhone using Google's tools.  And then they said not only we want a list of everybody who was in that area. I mean, this is a fishing expert. They don't even know that the suspects were carrying phones.  They're just this is exactly what a fishing the definition of a fishing expedition. Well, let's just find out everybody who was in that area. They wanted to know of those people in that area within that 30 minute time frame, full names, addresses, Google account activity, all affected users, historical locations.  Google did not provide the information, but the fact is they probably had it right. And we know they had it. And by the way, this happened in March and they did find their suspect in the end without Google's assistance.  But it's extremely concerning. We just had a Supreme Court case on this and Lord help me. I know and I can feel you know the details.  It didn't unfortunately limited as much as we would have liked. We I thought and this was all about the guy who'd robbed a number of convenience stores. Yes. And Baltimore in Baltimore. Yeah, somewhere.  Yeah, somewhere. And the and the they had ended up getting his location history for a long period of time without using only a pen register. And right. And by the way, I've been corrected, at least in the state of California, pen register does now require a warrant. So and I and I'm sure this request of Google required a warrant of the FBI. That's the sad thing is I think the court approved it.  In any event, the real concern was about these warrantless location searches and the Supreme Court decision essentially said what they did wrong in that case was they collected too much information that they were getting days of information.  But they did. But the the opinion implied that a day or two would be fine. It's the days of information that exposed all sorts of other information about the suspect. And that was a violation of his rights.  So I did not it did not in any way really limit. In fact, didn't limit this specific kind of search because all they're saying is we just want 30 minutes.

Speaker: SPEAKER_01
Transcript:  So what would be interesting perhaps is if in this fishing expedition, if like I knew I happened to be there and I was at some sort of dicey location, maybe I was at a planned parenthood getting an abortion or I was at a sex shop or something like that.  I could, you know, count countersue I could argue that, you know, this is violating my privacy. I don't know. I mean, but it would be tough because you'd have to have known about it.

Speaker: SPEAKER_03
Transcript:  That's part of the problem. The ACLU said it's unlikely the average user of Google services would know such government searches were even possible.  And another attorney said the warrant amounts to a completely indiscriminate search of a large group of people. This is from an article in Forbes.  Even though they limited the search to users who had been at the two of the locations within certain time frames, that is a general search. It is prohibited under the Constitution.  It should be. I mean, it should be. You can't rummage around in people's stuff hoping to find illegal material. You have to have probable cause.

Speaker: SPEAKER_00
Transcript:  I wonder though if there is a way that they could have gotten this kind of data by purchasing data from these companies, right?  If you want people to do that.

Speaker: SPEAKER_03
Transcript:  Well, that's that pen register thing. So I had a law enforcement guy in a couple of days ago. He said, let me I think you misunderstand, at least in California, how pen registers are handled.  They are not warrantless searches. So I had for a long and they were until like a few years ago. And that's my that's where I was confused that the law changed in California. I don't know where else.  A few years ago that you couldn't just ask the phone company for location information. You had to get a warrant to do that.

Speaker: SPEAKER_00
Transcript:  So, but nevertheless, show that we should have some kind of system of transparency and auditing where these companies have to, you know, either every six months or every year disclose when and how they have shared your data with others.  Be it law enforcement or whatever companies they've they've sold your data to. I've looked at, you know, in Facebook and on Twitter. Now you can look at the ads that are targeted to you and find out why they're targeted to you and what specific metadata categories they were using to find you.  But to me, this system like this, if it is going to go through and there's going to be little we can do to stop these companies from sharing data between other institutions, organizations selling it, that there should be a system at least in the very, very least where there's disclosure of when, where, why and how and what data was shared.

Speaker: SPEAKER_03
Transcript:  The FBI agent in justifying the need for the warrant wrote, quote, It would identify which cellular devices were near two or more of the locations where the robberies occurred at the date and time the robberies occurred and may assist law enforcement in determining which persons were present or involved with the robberies under investigation.  I, you know, it was signed off by a warrant, signed off by a judge. The judge also sent a gag order to Google, which is the only reason we only are learning about this now because they were required to keep the warrant secret for 180 days for six months.  So that's why we're learning now about it. Google didn't do it. They were expected to return the information April 19. They did not. The FBI filed a motion to extend the time it had to get the data. A judge granted it.  That's really what's scaring me more than Google collecting the information that the judges are granting these warrants.  And I think that's not the end of it. Now that now that law enforcement knows that that treasure trove of information exists, they're going to go after it more and more.

Speaker: SPEAKER_01
Transcript:  And you can get judges to, I mean, there are crazy judges. I mean, I live in Texas where we elect our judges. So we have those who are often politicized.  They're like, yes, I will give all those crazy data, especially on those illegals and crazy.

Speaker: SPEAKER_03
Transcript:  Well, but I've had debates with normal, completely reasonable people who say, no, if you can help law enforcement, Google should, Apple should. You can help law enforcement. It's hard to explain to them.  Not in this way.  Well, it's hard to explain to people why this is a bad thing. In the case of the encrypted iPhone and the San Bernardino issue, it's hard to explain to people that, well, yeah, but if you get the government a backdoor, then the risk of others, hackers and bad guys getting access through that backdoor is very high.

Speaker: SPEAKER_01
Transcript:  Have they not read their history? I just don't understand.

Speaker: SPEAKER_03
Transcript:  Well, here's what there isn't any history of. There's never been a data collection device as good as this.  No.  These smartphones are a law enforcement officer's dream come true.  And this is where we're going to really face a battle, I think, going forward between people say, but we want to give police every weapon possible to fight crime.  And it turns out that everybody's carrying a surveillance device all the time. So why wouldn't you give police access to that?  And this is not the end of this. This is going to be. Now Google, to their credit, and I want to point this out as well, deny, deny, deny, they denied four motions. Eventually, the feds gave up.

Speaker: SPEAKER_01
Transcript:  Well, so is there you know what would be an interesting app is something that would generate false information about where someone is.  So services that you would run, maybe their VPNs that you run your data through that send basically fake data. Is that even technically possible?  Sure.

Speaker: SPEAKER_03
Transcript:  So that's the but here's my real point.  Criminals like good criminals. There's a lot of stupid criminals. This stuff only works on stupid criminals.  Smart criminals are not going to carry. They're going to carry burner phones that don't identify them. They're not going to carry.  I'm not going to carry my iPhone into into my robbery.  They're going to learn how to obfuscate their data. If tools like that exists, they see they're going to use them.  The rest of us are going to say, well, I have nothing to hide.  And we're the ones who are vulnerable, not the criminals. The criminals are going to get away with it.  It's normal people who are going to get screwed.  And frankly, if you get a government that is willing to use this against its populace, and we're seeing this more and more all over the world in Turkey and China and all over the world.  I really fear for the future.

Speaker: SPEAKER_01
Transcript:  I feel like we're already living in it.

Speaker: SPEAKER_03
Transcript:  That's why I killed my Twitter, Facebook, Instagram account today.

Speaker: SPEAKER_01
Transcript:  Your Twitter, Facebook and Instagram account are not the culprits here. The culprits are things like.

Speaker: SPEAKER_02
Transcript:  You can't have my phone.  You can't have my phone.

Speaker: SPEAKER_01
Transcript:  I mean, as much as I may mock my mother.

Speaker: SPEAKER_03
Transcript:  It's kind of putting my head in the sand, isn't it?

Speaker: SPEAKER_01
Transcript:  I'm an ostrich. You have a point.

Speaker: SPEAKER_03
Transcript:  So, OK, I'm taking my phone.  I'm just not tweeting about it.

Speaker: SPEAKER_00
Transcript:  But where does the intervention need to happen? Right.  Is the intervention that the apps are collecting all this data.  And so the infrastructure is built in such a way that you can't run appropriate search without knowing where people are located.  That's definitely true for maps.  But I'm like, you know, where do where would if we were to try to tackle this issue or to harness it in some way, is is the idea to change the hardware in the phone or to make the or to make the operating system easier for users to customize so that they can turn off geolocation.

Speaker: SPEAKER_01
Transcript:  So your carrier to whenever you ping to so your phone to work has to ping a cell tower and that cell tower has a physical location based on where you are because of physics.  Basically, it has to send data packets over the air and they can only go so far.  So your cell company, so the company who's handling the phone, they know exactly where you are.  And that's so and then there's other layers.  I mean, so the cell guys know where you are.  There have been rules about how they can use that data.  Those rules are somewhat in flux now on the Google and those sites.  Those guys also they were like, oh, that's beautiful data.  I must have that data.  So they built services that make it compelling for you to give it to them.  And they built these services so you will use their platforms.  It's not, you know, it sounds nefarious when I say it, but it's not nefarious.  They are offering a vital service.  But in return, they're taking that data in trying to glean insights from it.  And then there's these random other companies like Euclid and others that have come around looking for things like when your when your cell phone is trying to attach to a Wi-Fi network, it broadcasts information and it goes through previous data.  It goes through previous networks that it's joined.  It kind of creates a fingerprint that says, hey, this is this person.  They don't know that I'm Stacey Higginbotham necessarily, but they know that they have seen this phone before.  And so there's companies that do that without your consent, without anything.  And, you know, so there's there's many layers to this at an infrastructure perspective.

Speaker: SPEAKER_02
Transcript:  I just want to point out.

Speaker: SPEAKER_03
Transcript:  Thank you, Prawn, in the chat room.  To prove my point that if you're a crook, you know about this and you avoid using this is this guy, they call him the Govna.  He's 76.  He's the oldest Hatton Garden burglar.  He traveled to the burglary, the 14 million dollar jewel heist on a bus.  But he didn't use his own senior oyster pass to travel on the bus.  He used somebody else's.

Speaker: SPEAKER_02
Transcript:  So just even this guy knows don't use your own transit.

Speaker: SPEAKER_03
Transcript:  But cars to get on the bus if you're going to rob.  If you're going to do a jewel life.

Speaker: SPEAKER_01
Transcript:  Right. If you're going to escape from the law and run, you should not.  You should swap out your toll tags with somebody else's.

Speaker: SPEAKER_03
Transcript:  That's another one. Those toll tags, man.  They know exactly when you're crossing the bridge, when you're crossing the.  So the guy who eventually got caught for these these main robberies.  It's kind of interesting. They caught him because he they found footprints on the snow at the crime scenes and he had lost his shoe.  And they found the shoe and they took DNA samples.  They matched his DNA samples.  But they also had easy pass toll records for his work truck, historical cell phone location.  He ended up pleading guilty. But his attorney said, hey, if he had gone to trial, if he hadn't pled guilty, we'd gone to trial.  We would have brought up this overarching over over broad warrant.  And we think we could have it would have helped us win the case.  So there's a there's a blowback to something like this.  When an investigation violates the Constitution, the evidence can't be used to trial, which often results in dismissals of the charges.  So maybe the FBI ought to think twice about some of these overreaching warrants.  But Google's still in the heat in the heat because they they have that information.  They fought it on this one, but they know where you are.  All the time. Let's see.  We're going to do the change log a little bit. I'm bringing it back.

Speaker: SPEAKER_01
Transcript:  Oh, with with the cool graphics. Yeah.

Speaker: SPEAKER_03
Transcript:  And everything and the trumpets.  I think we investigated the theme I wanted to use last week.  And I think we investigated and determined that we couldn't use it.

Speaker: SPEAKER_01
Transcript:  We don't know the tiger tiger. Yeah.

Speaker: SPEAKER_03
Transcript:  Yes. Louis Armstrong's Tiger. Tiger rag.  Where did Elon Musk's Instagram account go?  That's my next question.  We had an Instagram account. Yeah, of course he did.  And was it a Zellia Banks? It was Instagramming.  He's holding me prisoner in the house. Yes. Yes.

Speaker: SPEAKER_01
Transcript:  I don't like I don't even want to understand what's happening there.  I see the headlines and I'm like, yep. No. Yeah.

Speaker: SPEAKER_03
Transcript:  Yeah, I think the next thing for me is to stop watching 24 hour news.  That's pretty bad as Twitter.

Speaker: SPEAKER_01
Transcript:  Pretty sure my desire not to know anything about that is the biggest signifier that I am a nerd.  I was just like, oh, look, there's a new article about about risk five.  Let me read that. It's much more interesting.

Speaker: SPEAKER_03
Transcript:  Let's look at the arm roadmap when we come back.  First, a word.  Actually, I bet you have some things to say about the arm roadmap.

Speaker: SPEAKER_01
Transcript:  Oh, you know, I do. I thought you might.

Speaker: SPEAKER_03
Transcript:  Stacy Higginbotham, Stacy on iot.com.  Joan Donovan from data society dot net.  We will continue with this week in Google.  Jeff's odd assignment. He's in Argentina right now.  Lucky dog. Our show today brought to you by Digital Ocean.  I love Digital Ocean. If if you're a coder,  if if you want to deploy an application on the net,  there is no easier way than Digital Ocean.  I use it all the time. It's a fun way for me.  Let me log into my Digital Ocean account.  It's a fun way for me to try new web technologies very affordably.  It's the easiest cloud platform to deploy, manage and scale applications.  They call them droplets like droplets in the ocean.  Right. I'll show you how easy it is to create a droplet.  Droplets are virtual machines. They're scalable compute platforms.  When you create a droplet, you choose either an operating system.  You see we have Ubuntu, FreeBSD, Fedora, Debian, CentOS,  or choose a container. CoreOS, Fedora, Atomic, RancherOS,  or a one click app.  Discourse, Django, Docker, GitLab, Ghost, Doku, Lamp.  Let's say I wanted to set up a ghost blog.  Press that button. How big?  I'm just beginning here. I don't want to spend too much money.  Let's do the 0.007 cents an hour tier.  Gives me a CPU, a gigabyte of memory, 25 SSD, a terabyte of transfer,  a lot of transfer. You can enable backups if you want.  Add block storage. You can even choose the data center region.  I always choose San Francisco too. I don't know why.  But you can use New York, Amsterdam, San Francisco, Singapore, London,  Frankfurt, Toronto, Bangalore. Lots of other options.  I always use SSH because I have uploaded my SSH keys to Digital Ocean.  Makes it easy for me to log in.  So now I've got a ghost server.  This is the host name, although I can change it to Leo's Ghost.  Great Caesar's Ghost. How about that? Great Leo's Ghost.  I can add tags. I can say which project, and I can create.  Now watch. Within a minute, that server will be provisioned  and ready to use. You could choose from standard to CPUs,  optimized droplets, customized as I just did, easy to use control panel  and API. Let's developers spend more time coding,  less time managing their infrastructure.  You can access the compute resources you need very affordably,  save up to 55% compared to other cloud providers.  It's a great way for you to try, but you can still scale it up  and make it a full production server if you need to.  Keep it on this because it's almost done creating my droplet.  That's how fast it is.  You always know what you'll pay per month with flat pricing structure  across all data center regions. Great Leo's Ghost is up and running.  How about that? That's how fast and easy it is.  $5 a month, 99.99% uptime SLA, four nines, cloud firewalls,  monitoring and learning, full DNS management, global data centers,  enterprise grade SSDs. They're fast, easy to use APIs.  Look, it's no wonder more than 150,000 businesses,  including many of the world's fastest growing startups,  rely on DigitalOcean to remove infrastructure friction  and deliver industry leading price performance.  You know who would love this? Kevin Toffle, who set up a Raspberry Pi  so he could program in Python. Just do this.  Set up an Ubuntu server on DigitalOcean. It's affordable.  Sign up today. You'll get a free $100 credit.  Go to do.co.twig for a free $100 credit.  DigitalOcean makes it so easy. I just love these guys.  DigitalOcean, do.co.twig and you'll get a free $100 credit.  One of the reasons I love DigitalOcean is no matter what you want to do  online, there is a tutorial. If you Google, I want to set up anything.  I want to set up a WordPress instance at DigitalOcean.  Just Google it and there'll be a whole tutorial.  I'll walk you right through it. It's awesome.  DigitalOcean, do.co.twig and we thank them for their support.  They've been with us for some time this week in Google.  I haven't talked about Facebook in so long.  In fact, I wonder if getting rid of my Facebook maybe will impair my ability to cover Facebook.  Fortunately, you guys are going to stay on Facebook, right?  I don't have to worry about that.

Speaker: SPEAKER_01
Transcript:  Me? I'm not on Facebook.

Speaker: SPEAKER_03
Transcript:  Oh, sorry.  Stay on Facebook.  Well, we know one person who will. Jeff Jarvis.  I bet Joan, I bet you're not either. Are you?

Speaker: SPEAKER_00
Transcript:  What? On Facebook?  Yeah.  But I have.  Well, I mean, it's hard to figure it out.  I know I just have I have real and fake accounts.

Speaker: SPEAKER_03
Transcript:  Oh, don't say no more. Say no more.

Speaker: SPEAKER_00
Transcript:  Say no more. But yeah, as good as an art to a blind man.  You know, there's ways in which you can enjoy these platforms without being publicly available to everyone for everything.  So I am an avid fan of having multiple accounts for multiple things.  And yeah. And so I yeah.  And the other thing is, is that is just kind of the habit I learned with when I first started AOL.  Right. We all had you had access to five screen names.  So I had five screen names. And so yeah.  Yeah. Yeah.  Yeah. I even segment some of my Netflix stuff so that, you know, if I want to watch, you know, like documentaries and things that I want to be recommended that I have a persona on there that has different kinds of content.

Speaker: SPEAKER_03
Transcript:  You are paranoid.

Speaker: SPEAKER_00
Transcript:  I'm not so much paranoid. It's just that the recommendation systems can be so terrible.  If you have this is something that a friend of mine complained about.  I wanted to borrow his Hulu to see if I liked it.  And he said, no, you're going to mess up all my recommendations.

Speaker: SPEAKER_01
Transcript:  And that's so mad when Hulu asked me for it.  Like Hulu used to just be like you would hang out on it.  And then suddenly it was like they ask you for a lot.

Speaker: SPEAKER_03
Transcript:  Yeah.

Speaker: SPEAKER_01
Transcript:  Can we can we find out who you are? What do you like?  And I'm like, I'm not taking a quiz to watch a freaking TV show.  TV is supposed to be like brain dead.  You figure it out.

Speaker: SPEAKER_02
Transcript:  Yeah.  I'm giving you signals. You figure it out.

Speaker: SPEAKER_00
Transcript:  Yeah.  Well, he didn't want me to mess up.  You know, he's really into, you know, early Saturday Night Live and different sketch comedy stuff.  And he was like, no, you're going to get in there.  You're going to watch some like, you know, cooking show or you're going to watch this other thing.  And it's going to it'll never forget that.  It's true.  Yeah.  And so you should have a guest mode.

Speaker: SPEAKER_03
Transcript:  Oh, no, they say they don't want you to do that because they don't want you to share the password.  Yeah.

Speaker: SPEAKER_00
Transcript:  I mean, I'm in favor of a delete button, right?  There should be a way to hit reset on some of these where, you know, you're able to just start again.  You know, it used to be that you could erase your history and your cookies and get, you know, a fresh install or something.  And you could start over.  But a lot of these apps, they just retain, retain, retain.

Speaker: SPEAKER_01
Transcript:  And it's unfortunate because they're like, man, some of my things have like me down this weird rabbit hole.  And I'm like, OK, granted, I did watch that once when I was recovering from like wisdom.  But this is not who I am.  Please stop giving me this.

Speaker: SPEAKER_00
Transcript:  Yeah, you can blame every James Franco recommendation I get on, yeah, you know, a sick day out of the office.  I watched Twilight, y'all.

Speaker: SPEAKER_01
Transcript:  Let me tell you.  Yeah, you did.  We are done.  I mean, it was I was like, I got to see what the Sparklevamps are about.  And I saw it and I was like, oh, yeah, I'd watch the heck out of these if I were drunk.  But I really don't want that forever influencing my choices, you know?

Speaker: SPEAKER_00
Transcript:  Well, I, you know, even though I have two computers, one that I use at home, one that I use for work stuff,  because of the nature of what I research and because I can't just sign out of all of my accounts on my work computer,  my Amazon and my YouTube are perpetually infected with nonsense.  And so I cannot hand my phone to a young person who's like, let me watch, you know, videos on YouTube.  I'm like, nope, because I don't know what you're going to get recommended.  So, you know, I have learned my lesson, but there's really no way to stop at least as far as I can tell those two apps from from like really,  you know, bunching all of your interests and keeping keeping with the recommendations.

Speaker: SPEAKER_03
Transcript:  You know, come to think of it, this is really true.  I am actually reluctant to watch stuff on Netflix.  You know, like I actually like my mom is watching stuff.  Yeah. It's like, oh, I better not watch that because you need an incognito mode.  It's going to then pop up.  And the worst thing is if you use your Apple TV, then the Apple TV blasts everything you've just watched across in a banner across the screen as soon as you turn it on.

Speaker: SPEAKER_01
Transcript:  Oh, yeah. This is how I get in trouble. So like, you know how couples have this battle about like you shouldn't be watching with that.  I watched. Yes. Something with that one.  Do it. Don't do it. Don't do it.  And and yeah, he found out and it was it was grim.  You guys, I mean, it really tested our 16 year marriage.

Speaker: SPEAKER_02
Transcript:  How dare you watch Better Call Saul without me.

Speaker: SPEAKER_00
Transcript:  It's true. And like now with like Chromecasting.

Speaker: SPEAKER_01
Transcript:  So my daughter is constantly like checking on my phone, you know, just to see stuff like what you're saying, Joan.  And 90 percent of my videos are core.  He's and, you know, we're gadgets.  So we're fine. But I can totally see that someone in your position would be like, yeah, I don't mean Joan has to watch it.  Right. Yeah, I do.

Speaker: SPEAKER_00
Transcript:  Yeah. And that's I mean, that is just not even the worst of it.  But what's been really hard, I think, is something that is sort of tests the boundaries with my wife is I will order a bunch of stuff related to history and, you know, books online about neo-Nazis and white supremacists.  And then it starts to, you know, our Amazon starts to have this particular flavor to it and the recommendations.  And she's like, do not do this on our home account.

Speaker: SPEAKER_03
Transcript:  Yeah, I don't share at least and I will not share Amazon accounts for that reason.

Speaker: SPEAKER_00
Transcript:  But the thing is the prime, you don't want to pay twice for shipping.

Speaker: SPEAKER_03
Transcript:  That's a good point.

Speaker: SPEAKER_00
Transcript:  Well, you know, like if they're going to ship it.

Speaker: SPEAKER_01
Transcript:  No, because you could have your own account and be in a family with your wife.  So you could just because my husband and I don't share accounts, but he's part of our family.  So he gets it. He has his own account.  But he's also part of.  Yeah. Oh, that's cool.  It's not. It's a feature.  So we actually can share our Kindle titles, too.  So like when he buys something, this is actually something I wish didn't always happen.  But when he buys something on Amazon, if it's something that's shareable, his Kindle titles show up on my Kindle and I can download them.

Speaker: SPEAKER_03
Transcript:  Lisa has so polluted my audible stream.

Speaker: SPEAKER_02
Transcript:  I just want to show you.  So stranger in a strange land.

Speaker: SPEAKER_03
Transcript:  That's that's me. White Fang.  That was a freebie. Jack London, Valley of Genius, Bourdain, Stephen King.  It's good stuff, right?  Then James Comey, that's hers, never split the difference negotiating as if your life depended on it.  Carl Hyacin, the plant paradox, hidden dangers and healthy foods.

Speaker: SPEAKER_01
Transcript:  And then back.  Carl Hyacin is awesome.

Speaker: SPEAKER_03
Transcript:  I love Carl Hyacin.  And actually, I have a whole bunch of Carl Hyacin earlier on in my feed.  But it's funny because the mix, it's these are just completely different people.  She's it's all mixed into my feed.

Speaker: SPEAKER_01
Transcript:  I saw Autonomous, the book I recommended a couple of months ago.

Speaker: SPEAKER_03
Transcript:  And we interviewed the author. Thanks to you, Annalene Newitz.  That's a great book.  But you see now it's giving it away.  It says five hours and twenty two minutes left.  A lot of my books have stuff left.  I you know, it's for a long time.  I've always had this problem with physical books like my bedside table.  It's dangerous. It could fall on you and hurt you because I always have a lot of reading materials.  But for a long time with audible was like no one book.  Finish the book and you do the next book.  But it's too easy to just to dip in.  And so I have forty three hours left on Shogun.

Speaker: SPEAKER_01
Transcript:  I can't I can't dip. I am I am.  And then out. I can't do it.  Not a dipper. It's you know, I even read the New Yorker cover to cover.  What? I know it is.  And I'm like a completist, too. It's terrible.  That's bad. I just unless it's a baseball article or God help me another fly fishing article.  Yeah. But other than that, I'm I'm all in.

Speaker: SPEAKER_03
Transcript:  That's so funny.  Yeah, that was actually that hurt my New Yorker subscription because I couldn't become completed.  And so then I said, well, I'm just not going to get it because I can't complete it.  Facebook is being asked. Well, let me ask you this.  I really want to know your opinion.  Facebook's artificial intelligence lab right there.  That those four words bother me is working with New York University's medical school to make MRI exams ten times faster.  NYU is giving an anonymous, they say, data set of 10000 MRIs with as many as three million images of knees, brains and livers to Facebook.  So now Facebook shouldn't have an artificial intelligence lab.  First of all, no, it should give it to Google.  Give it to somebody with who cares about the world.  Don't give it to the worst spy agency in the history of mankind.  It's like saying we're going to give it to the KGB.  You don't mind, do you?

Speaker: SPEAKER_01
Transcript:  OK, well, maybe they could have given it, you know, maybe they could have made it an open data set.  That would have probably been better.

Speaker: SPEAKER_00
Transcript:  But yeah, I mean, it's anonymous in its pictures.

Speaker: SPEAKER_03
Transcript:  I don't think Facebook should be in the AI business.  And they say we want to make MRIs faster.  What does Facebook care if MRIs are faster?  They don't care about that. That's not what they're.  That's not their goal.

Speaker: SPEAKER_01
Transcript:  They're trying to test different models, but testing models for the benefit of humanity or against anonymous data sets makes other things more powerful.  I don't think that's. Yeah, this is.  I think it should have made it open.

Speaker: SPEAKER_03
Transcript:  This is what the AI research group at Facebook said.  They started to talk about this with NYU last year because Facebook's AI team wanted to work on something with real world benefits, even as it performs basic research on how to spy on you.

Speaker: SPEAKER_01
Transcript:  Think about it. If you're trying, I mean, AI researchers, man, you've got a couple of ways to get them.  You can get them notoriety by giving them great data sets and let them publish awesome papers that people love.  You could pay them a lot of money and give them fabulous benefits.  So Facebook, everybody can pay them lots of money and give them fabulous benefits.  So Facebook just wants them to be able to also like cure liver cancer.  That's a nice way to recruit people.

Speaker: SPEAKER_03
Transcript:  It's not. Yes, it's not really, though, Facebook's business model cure liver cancer.

Speaker: SPEAKER_01
Transcript:  No, it's not. But it's their business model to have happy AI researchers that want to work for them.

Speaker: SPEAKER_03
Transcript:  That's true. But I don't know.

Speaker: SPEAKER_00
Transcript:  There's also a big division. I don't know how big it is.  I'll take that back as a sociologist. I shouldn't be making estimates about size.  But within Microsoft, there's a research division related to AI and genetics and and machine learning.  And so I can see that part of this is probably related to a tax write off that has to do with developing this kind of good for the world data.  You know, like when you make that much money as an organization, you can really spend on any kind of lucrative lab based research,  whether or not you intend on implementing it or using it.  That's what worries me is that, you know, you give privileged access to this group that doesn't have any plans to do anything for society.  Oh, yeah. And the other thing is, is there's lots of computing power and lots of great researchers in public universities that could really do some wonderful stuff with this.  And at NYU itself. So I'm wondering where and how the partnership came together and why Facebook becomes the best group for the job when we have so many other medical facilities that could really use that kind of data,  as well as, you know, they can produce different and more interesting outcomes by having it done in a way that it can be implemented.  I wonder what the implementation strategy is or like how the machines will eventually change.

Speaker: SPEAKER_03
Transcript:  I guess it's silly of me to worry about Facebook when Google is doing the same thing and they're just as interested in personal information and stuff.

Speaker: SPEAKER_01
Transcript:  I just feel like. Well, what if, like, just bear with me here, but old people, we're getting up there in the world, right?  There's a lot of us and there's apparently not a lot of young people on Facebook.  So maybe this is a potential revenue source. I'm not saying it's, but, you know, you don't close those avenues off if you have access to them.  Yeah. You're like, oh, OK, we'll work. You can kill lots of birds with this one stone.

Speaker: SPEAKER_03
Transcript:  It's good. I'm getting all my Facebook hate out now before Jeff gets back.

Speaker: SPEAKER_00
Transcript:  I mean, it would be a very interesting science competition, though, around AI, machine learning, computer vision, all those, you know, image modeling.  You know, if we're going to go full, you know, full capitalism here, you know, that kind of competition is what's going to spur development in science, not by siloing off the data into, you know, the already biggest, one of the biggest companies in the world that doesn't always make the best assessments and judgments.

Speaker: SPEAKER_03
Transcript:  It bothers me in the same way that it bothered me when research on the human genome was done by both commercial and nonprofit organizations.  I kind of. But I guess it's unrealistic.  Our government is not funding science. Yeah, it's unrealistic to expect AI research to be done by nonprofits.

Speaker: SPEAKER_00
Transcript:  Yeah. And that.  Well, I was going to say, you know, project, you know, the way that that's ended up, you know, we're still straight talk about data surveillance.  You know, we're still struggling with, you know, corporations like 23andMe providing base level data to police and governments.  And so, yeah, there's a there's a whole other host of privacy concerns that are about, you know, bio material.

Speaker: SPEAKER_03
Transcript:  Yeah, I mean, it ended up if we had relied on government or nonprofit to analyze the genome, we would be still waiting because it was Craig Venter's commercial venture that ended up doing it fastest.  But it just but I don't want to see people patent parts of the genome.  And that's one thing that's happening. I just I don't know. Maybe it's it's unrealistic to me, I guess, to expect.  It's not. It's just socialistic of you. It's socialistic of me. And I'm a socialist. What can I say?

Speaker: SPEAKER_01
Transcript:  Like in here, those are those are still you're trained to think that's a bad word.

Speaker: SPEAKER_03
Transcript:  No, it's not a bad word. I don't want the I don't want the US government to own all businesses that that kind of so not government socialism.  But I think I think a little society should go in there a little bit. We should have we should have parity with big businesses.  Google says, Hey, don't it's not just Lenovo. We're going to make a display equipped AI speaker before the holidays.

Speaker: SPEAKER_01
Transcript:  I think this is so weird. Why? I mean, Amazon and other companies have kind of as they've gotten let other companies into this realm, they've limited some of the functionality.

Speaker: SPEAKER_03
Transcript:  So I'm like, is the smart display the Lenovo Smart Display limited compared to I don't know.

Speaker: SPEAKER_01
Transcript:  So like, well, there is no equivalent to Google. So right. No, but it but it doesn't have Google Home.

Speaker: SPEAKER_03
Transcript:  It does it does everything a Google Home would do. Right. Well, that's what I'm saying.

Speaker: SPEAKER_01
Transcript:  But if like Amazon when I buy light switches are a terrible example.  But you know, some of the other products that use the Amazon Echo, they don't do things like play Spotify.

Speaker: SPEAKER_03
Transcript:  I know. I know that Sonos with the built in with Echo built in is very limited.  I can't even ask it for the weather. I mean, it's it's very limited.

Speaker: SPEAKER_01
Transcript:  So so that's what I'm concerned about. I'm like, oh, so Google's going to get in this game.  What is it going to change about possibly Lenovo or future devices?

Speaker: SPEAKER_03
Transcript:  So they when they announced this at I.O., they said that it wasn't just Lenovo, JBL, LG and Sony would all be making screen based smart display play platforms.

Speaker: SPEAKER_01
Transcript:  Yeah, I saw JBL's at CES. Did we see Sony's? I can't remember. I mean, yes. Some of those are we saw at CES.

Speaker: SPEAKER_03
Transcript:  Lenovo was the only compelling one, as I remember. Yeah.

Speaker: SPEAKER_01
Transcript:  Yeah, Lenovo was the one that we were all like, oh, yeah, that's pretty.

Speaker: SPEAKER_03
Transcript:  A lot of people even around here have have them. I still have held off.

Speaker: SPEAKER_01
Transcript:  I wanted the Costco deal. And now that I know that people got it at Costco for 200, I really resound like heck and I know like, oh, man.  Joan over here is like, OK, were we not just talking about misuse of data and privacy implications?

Speaker: SPEAKER_03
Transcript:  I'm trying to mix it up. I'm trying to gadgets society.

Speaker: SPEAKER_00
Transcript:  I am all for interesting gadgets. I last time I was on, I think we talked a bit about video cameras and the nest.  And now I'm seeing them everywhere, everywhere.  I am not attuned to them, but they're outside of all the buildings in New York City, you know, and they're just really small and discreet.

Speaker: SPEAKER_02
Transcript:  And or now I just feel.

Speaker: SPEAKER_01
Transcript:  Yeah, the Google the Lenovo screen is nice because unlike the Amazon Echo devices, it has a physical cover on the camera, which all the old school.  I'm just like, that's good. Now I feel secure because I have that little spot, the Amazon spot Echo.

Speaker: SPEAKER_03
Transcript:  And Lisa won't let me put it in the bedroom, even though it's a perfect alarm clock.

Speaker: SPEAKER_01
Transcript:  Yeah, I wouldn't let you put it in the bedroom either. Not just my closet.  I talked to a security firm and this freaked me out.  Just to see what will happen.  They said that they actually dealt with a internet camera company whose staff was looking at videos from the customer.  So they actually they were touting this as like a win for their customer.  But I'm like, actually, that is a huge loss for everybody who wants to buy this.  They didn't say what brand it was, did they?  They did not say the brand. I was like, look.

Speaker: SPEAKER_03
Transcript:  I don't think Amazon's going to let that happen.  But who knows? That's why I dance naked in front of mine.  That'll stop them.

Speaker: SPEAKER_00
Transcript:  God, I used to think I researched terrorism.

Speaker: SPEAKER_03
Transcript:  That's really terrorism.  This is one kind of extremism.

Speaker: SPEAKER_00
Transcript:  I think I'm going to have to moderate.

Speaker: SPEAKER_03
Transcript:  Joan, I set up last night a camera to monitor our cat door.  Oh, my goodness.  One of these cheap, wise pan cam.  They're 30 bucks. Why not?  So it's plugged in because we were trying to figure out if which cats were coming in, what animals are coming in.  So now I get a notification whether an animal comes in and the camera pans and follows the animal.  But then about midnight, I should show you one of our cats discovered it and ate it.

Speaker: SPEAKER_01
Transcript:  She can't beat it.  Pan cams are bad for cats.

Speaker: SPEAKER_03
Transcript:  Yeah, because the pan cams go zzzz.

Speaker: SPEAKER_01
Transcript:  Yeah, they zzz and move.  So I'm like, eh.

Speaker: SPEAKER_03
Transcript:  Is this a new kind of mouse?  What is this?  What is this in the house?  Here, I don't know if you can see this, but the cat found it and it went dark.  Did you see that? Let me do that again.  Let me do that again.  The cat found it. Midnight.

Speaker: SPEAKER_02
Transcript:  I'll show you.

Speaker: SPEAKER_03
Transcript:  I don't know what she did, but then she got out of the way.  But that's I think that's a good use for camera, a cat door cam.

Speaker: SPEAKER_01
Transcript:  We've put our wise camera in front of the fish tank when we travel so we could see if any fish die.  We've also I actually thought about putting it in front of the dog door because I don't think my dog goes to the bathroom in the middle of the night.  And I'm like really concerned about this.  So these are the sort of neurotic things I have.

Speaker: SPEAKER_03
Transcript:  Wait, let me get this straight.  Do you want your dog to go to the bathroom in the middle of the night or not?

Speaker: SPEAKER_01
Transcript:  Like, I don't think she goes to the bathroom after like six o'clock at night until like seven the next morning.  You know what? Neither do I.

Speaker: SPEAKER_03
Transcript:  I think that's completely reasonable.

Speaker: SPEAKER_01
Transcript:  I don't want to know this much about your bathroom house, but I feel it's weird for my dog.

Speaker: SPEAKER_03
Transcript:  I don't know. It's nighttime.  The dog goes to sleep, wakes up in the morning like any normal dog, goes outside.  Seems reasonable anyway, but now you know, right?

Speaker: SPEAKER_01
Transcript:  Well, yeah, this is this is the plan.  I'm like, oh, OK.

Speaker: SPEAKER_03
Transcript:  That's what happens, Joan, when these cameras are so cheap, which they are now.  Twenty dollars for the static camera.  Well, there's no reason not to have them everywhere.

Speaker: SPEAKER_01
Transcript:  Well, I told someone you had to put it in their garage because they were like, I need to open closed garage door sensor.  I was like, actually, twenty bucks.  Just pop that sucker in there. If it's bright in there, your door is open.

Speaker: SPEAKER_00
Transcript:  I don't know. I'm looking at these screens on these smart speakers and I'm just like, why don't you just plug a speaker into your your old iPad?  And here you go.

Speaker: SPEAKER_01
Transcript:  So some people do there. You can use your it's the Kindle fire tablets as an Echo show, basically.  So that is something that can happen.

Speaker: SPEAKER_03
Transcript:  You can have this Lenovo.  You can have it. You can have it monitor any of the cameras, too.  So it's like a multi-camera interface.

Speaker: SPEAKER_00
Transcript:  And you can. It's funny because it's like Leo doesn't want to be on Facebook because he's afraid of other people watching him.  And now he's like, I can watch myself.

Speaker: SPEAKER_03
Transcript:  I know I am not afraid of other people watching in front of his spy cam.  The decision not to be on social media is not because they're spying on me because I just don't want to participate.  OK, that's separate because it makes me feel bad. I don't like this.  The content it makes me feel bad.  Actually, that's all I need to say. It makes me feel bad.  So I don't want it's just bad. I would notice I feel much happier when I'm not looking at that crap, even Instagram of late.  So that's why I just shut shuttered those accounts.  I don't like Facebook because I do feel like they're a very I'm and I know Jeff hates it when I say this, but I really feel like they're an evil company.  Maybe that's maybe that's wrong, but I feel all the evidence is that Jason Calacanis was here on Twitter the other day.  He knows these guys. He said, oh, yeah, they're evil. Oh, OK.  He said their whole their whole deal is do what they want, do whatever they want.  They get caught, they apologize and then they go on doing it.  And there's a lot of evidence that that's true.  So that's why I don't want to give them a 10,000 MRI records from NYU.  And I think that's a poor choice for NYU to make. Yeah, they're anonymized.  But as we all know, anonymous is not really that anonymous.

Speaker: SPEAKER_01
Transcript:  Where has been but hasn't OK, didn't Mark Zuckerberg and his wife donate a lot of money to solve some disease or something?

Speaker: SPEAKER_03
Transcript:  Oh, in that case, let me join the Facebook. I'm just going to log right in.

Speaker: SPEAKER_01
Transcript:  Who cares? No, I'm just saying they may have established a link through NYU.  I see. Yeah, yeah, yeah. But I don't remember how they donated to or how that work.

Speaker: SPEAKER_03
Transcript:  OK, happy news, happy news, happy news, happy news.  Would you like some happy news? I'm looking.  Do you have some happy news? I do.  Because hot chips. Oh, hot chips is here.

Speaker: SPEAKER_01
Transcript:  It was this week and they talked about this is actually Google related.  So you get a two for one. Stacey nerds out on chips and it's Google related.  They did the pixel visual core. They broke it down for people at the event.

Speaker: SPEAKER_03
Transcript:  So this is their was this Google Next event? What event was this?

Speaker: SPEAKER_01
Transcript:  No, this was hot chips. It's called hot chips.

Speaker: SPEAKER_03
Transcript:  Do you not know about hot chips?

Speaker: SPEAKER_01
Transcript:  Only the most exciting, exciting event of the season.

Speaker: SPEAKER_03
Transcript:  The only hot chips I'm interested in come with KSO.  It is a annual chip conference.  It's a symposium on high performance chips.  It's amazing. Sponsored by the IEEE technical committee on microprocessors and microcomputers.  They know how to throw a party. Let me tell you.

Speaker: SPEAKER_01
Transcript:  OK, I guarantee you like a good third of your audience is probably like, yeah, they are.

Speaker: SPEAKER_03
Transcript:  No, they already are. No, the chat room already said.  Scooter X in the chat room. I said you should be talking about hot chips.  So it was this. So tell me what you learned at hot chips this year.

Speaker: SPEAKER_01
Transcript:  Well, I did not go because I don't officially cover chips anymore, but I get a lot of the briefings.  So but I didn't go to this. So I was reading about the Google one.  So everybody launches both like fancy innovations and making their server chips better design new architectures.  And then you get a lot of researchers talking about like crazy, wacky, cool stuff that they can do.  So Google talked about their pixel visual core chip that they designed.  And this was they this was what they used in this is in the pixel to.  Yes, I was like the phone. I'm currently using.

Speaker: SPEAKER_03
Transcript:  I'm holding up here. This guy.  This is what makes this crappy little lens single lens camera looks better than any other camera phone on the market.

Speaker: SPEAKER_01
Transcript:  Yeah. So they did this whole talk about how they decided everyone's like, oh, you know, use a dedicated chip.  They're like, oh, CPUs didn't work. GPUs didn't work.  So we designed our own ASIC. And this is and they baked the algorithms that they wanted to use in.  But that's really hard because algorithms change all the time.  So they basically talked. It was really nerdy on like how they like the tradeoffs and engineering compromises.  Is this field programmable? I mean, can you can you update?  No, no, it is not. It is not an FPGA. It's a it's an ASIC.  So they design it and then it it's set in not stone, silicon, haha, sand.

Speaker: SPEAKER_03
Transcript:  It's set in sand. Well, now I'm looking at this slide, though. Maybe I got confused by this slide.  So here's the CPU, which is fully programmable.  Here's an ASIC, which is fully not programmable.  The right side of the slide is performance.  So ASICs are higher, much higher performance and CPUs are much higher energy per operation.  They they say this is the this is a PVC, the picture of visual visual cores,  IPU, which they say is not an ASIC, but a programmable image processing unit.  So it is programmable. Oh, crap.

Speaker: SPEAKER_01
Transcript:  You're right. It's that's why it does say that.  That is not the takeaway I got from this at all.  Well, you got to look at the slides because I look at the pictures.

Speaker: SPEAKER_03
Transcript:  I can't understand the text, so I look at the pictures.  This is actually a non-text live blog of it.  But I thought that was interesting. And that and that is in response to what you said,  which is it's very hard to bake the algorithms in as you designing this,  because things change. Yeah, but this isn't an FPGA.  This is not it's not quite an FPGA either.  So right. That's why I'm like, yeah, it's a so the high level program module model is Halide,  which is actually interestingly a program camera program.  But I think that's a coincidence domain specific language for image processing.  The IPU supports a subset of the Halide language.  It's not floating points. It's very simple language.  And they're sad about the loading point.  Halide back end generates kernels and all API calls proprietary API for resource allocation and execution control.  So that's interesting. So it is it is like a CPU in that you can write software to it.

Speaker: SPEAKER_01
Transcript:  Well, yeah, all of this. I mean, it's a piece of silicon. It's a chip.  But they say it's kind of more dedicated than that.  It is. But you do write. I mean, you write software for it.

Speaker: SPEAKER_03
Transcript:  Yeah, I could write a glue code around it, I guess. But it's a it's a it's a done deal.

Speaker: SPEAKER_01
Transcript:  Well, now I need to call Google and talk to them. All right.  Well, we won't. We won't.

Speaker: SPEAKER_03
Transcript:  Asics do stencil operations. The value of a pixel is a function of a pixel.  The pixels are routed computers over a pixel.  Right. You calculate a new picture requires a lot of data.  See, this is why I don't read the text. Let me look at the pictures. Hardware.

Speaker: SPEAKER_01
Transcript:  I'm just going to I'm going to talk to the Google guys. I'll figure it out.

Speaker: SPEAKER_03
Transcript:  It's interesting. It has its own RAM. It's DDR4 RAM.

Speaker: SPEAKER_01
Transcript:  Well, yeah, because it's it's you have to have access to like you have to have access to memory so you can optimize really quickly.

Speaker: SPEAKER_03
Transcript:  That is it. It's got eight cores. Wow.  Wow. This is a sophisticated thing. Did they talk about  because one of the things we knew about the pixel visual core actually we didn't know about it.  They didn't tell us until after they started selling the phone.  And it wasn't even enabled at first. You suspected they were doing something. Yes.

Speaker: SPEAKER_01
Transcript:  Yeah. Yes. It wasn't enabled. And now I guess it is.  But the other thing that was there is Arm announced their what I think of is their their own CPU roadmap.  Yeah. This is fascinating, too.  Yeah, because that gets them that they're really gunning for the laptop market here.  And we didn't talk about it. Kevin and I didn't talk about it on the show like our show IOT show because it wasn't really an IOT news thing.

Speaker: SPEAKER_03
Transcript:  But he's super pumped about it for Chromebooks, although it's it's basically what they're saying is we are going to in the next two years we will be desktop class.

Speaker: SPEAKER_01
Transcript:  I don't think they're saying we'll be just.

Speaker: SPEAKER_03
Transcript:  Yeah, they're saying we'll be the equivalent of an i5.

Speaker: SPEAKER_01
Transcript:  Sorry, I don't believe that they're going to be desktop class.

Speaker: SPEAKER_03
Transcript:  You don't think so. Huh? Wouldn't that be interesting?  Don't get me wrong. But that's the Cortex A76 is 10 nanometer and seven nanometer.  Yeah, they'll be followed by seven nanometer and five nanometer chips by 2020.  They'll be five nanometers.  What? What? What?  Our roadmap of client CPUs has been designed to take advantage of the disruptive innovation 5G will bring to client devices.  I think this is what arms aiming at is an always on all day battery life.  Maybe not top of the line processor performance, but good enough desktop class performance to give you a laptop that in the next couple of years that will be a completely different thing.  Right. They say to break through the dominance of x86, aka Intel and AMD and gauge substantial market share in Windows laptops and Chromebooks over the next five years.

Speaker: SPEAKER_01
Transcript:  Right. That's why when you say desktop, I think of like higher end gaming.  No, no, no, no, no, no, no, no, no, no.  And I'm like, they're not going to get you there. They're going to get you the laptop.

Speaker: SPEAKER_03
Transcript:  Laptop. OK, laptops. Good, though. I have an arm based Windows laptop, the HP and VX2 and it's unusably slow.  It's an 835 based and it's just it's not you can use it. I shouldn't say unusable. It's just you've got to have patience.  But if they could get that and this is what they say next year, they'll get that to the equivalent of a 2013 i5.  That's fine. Especially if you have all day battery life.  When's 5G happening? I keep asking this every week.  Goodness, who knows? It's already happened, Leo. What did you blink and miss it?

Speaker: SPEAKER_01
Transcript:  I missed it.  The smartphone should be out next year, 2019 smartphones that are capable of using 5G.  I can't remember. I think some of them are going to be sorry.  No, the phones actually will be out. Modules will be out first. Phones later.

Speaker: SPEAKER_03
Transcript:  Yeah, we have a Moto X phone that they say they'll have a 5G Moto Mod for in a year. Right.  But will the carriers be there?

Speaker: SPEAKER_01
Transcript:  The carriers plan to be there in some markets with actual 5G. Yes.  Wow. Yes, they will. That is a true statement.

Speaker: SPEAKER_03
Transcript:  All right. One more story and then we'll take a break and the changelog.  Because there are a few things that Google has announced and I know you're interested.  Was there anything else from Hot Chips you were excited about besides the ARM roadmap and the Pixel Pro?

Speaker: SPEAKER_01
Transcript:  No, Microsoft showed off their SOPR stuff again, which I was kind of...  Their what stuff?  Their IoT security stuff. We've talked about it in the past. They keep talking about it like it's a new thing.  And I'm still like, Microsoft, what are you doing?

Speaker: SPEAKER_03
Transcript:  They still talk about HoloLens like it's a new thing.

Speaker: SPEAKER_01
Transcript:  Oh, HoloLens was nice.

Speaker: SPEAKER_03
Transcript:  I want to take a little break. If you are using passwords that you generate in your head,  or worse, using the same password over and over, you need to know about the best password manager ever made, LastPass.  And if you're a business that trusts employees with passwords,  you really need to know about the best password manager ever made, LastPass.  According to a survey, 32% of employees share passwords with others.  In our case, it was one employee, an engineering manager, who shared all the passwords with others on an open public website.  That's when we immediately installed LastPass Enterprise.  It has saved our bacon more times than I can even think.  It makes it convenient to share passwords without sharing the keys to the kingdom.  In fact, I can share a password, say, to our QuickBooks, to our bookkeeping,  and the person who gets it doesn't even get the password.  They just get the ability to log in until I revoke it at any time.  So if an employee leaves or doesn't need access, I can take it away.  In fact, you can configure over 100 policies, access security reports, create shared folders.  We have, for instance, an Ops folder that our DevOps team has access to, but nobody else does.  You could set master password requirements so that they have to, you know,  they can't use change me123 as their password for the LastPass.  We require two-factor. That's nice, too.  In fact, LastPass has its own authenticator app, which makes it really easy.  An authentication, a verification button pops up on an employee's phone when they try to log in to say, you know,  hey, are you you? Make sure they're the only ones with access to their accounts.  We give as a as a benefit of employee, everybody who works here not only uses the LastPass enterprise,  of course, at work, but they get their own LastPass personal for home.  So that's nice, too.  Even if credentials might be compromised through phishing attacks or malware, having two-factor on keeps outsiders out.  LastPass's password generator makes it easy to use or create unique random passwords.  Your employees don't have to remember or write down.  And if you use Microsoft Active Directory, here's a great benefit.  You can use it to log on to your LastPass.  So now they really only have one password to remember to get into everything.  Data is encrypted and decrypted at the device level.  Data stored in the vault is kept secret even from LastPass.  They don't have access to it either.  And I know that's true because Steve Gibson has seen the code and he's given it his seal of approval.  From easy onboarding to password autofill, LastPass makes it easy for businesses to take control of passwords and reduce the threat of breach.  I know that as a individual, you're using it by now, right?  But get it for your work, too.  LastPass Premium for personal use, LastPass Families for the entire family.  That's what we use at home.  LastPass Teams for teams of 50 or fewer.  There are so many great features.  The LastPass Families has an emergency access feature where you can designate.  I designate my wife.  If something should happen to me, she would get access to the password vault.  You see so many, you hear so many stories about people who pass away and they're next of kin, have no access to the bank accounts, anything.  Makes it very difficult to resolve your estate.  So I actually gave access to my daughter and Lisa, but they don't have access to my passwords yet.  If something should happen to me, they request it.  LastPass checks with me.  If I don't respond, and I said it so if I don't respond within a week, but you can set the time frame, then they pass along the keys so that Lisa can get in there and settle my accounts.  I don't need a death certificate.  No, no, it's a dead man switch, which I think is better, frankly.  But I think that that really works well because I could say, well, I have a month or I have a week or I have a day to respond.  And they so they email.  If you and she doesn't get access.  Unless I just don't respond.  So I think that that's a really good way to do it.  And you would only do it with somebody you really trust.  Obviously, your attorney or your family members, that kind of thing.

Speaker: SPEAKER_01
Transcript:  So if the government picks you up and takes you away, but you're still alive, she might then want access to my accounts.

Speaker: SPEAKER_03
Transcript:  Right.  Exactly.  Right. Yeah.

Speaker: SPEAKER_01
Transcript:  Like, all right.

Speaker: SPEAKER_03
Transcript:  He's not dead yet.

Speaker: SPEAKER_02
Transcript:  But he's not available.  He's not around.  And I just want to watch Netflix.

Speaker: SPEAKER_03
Transcript:  More than 13 million people, including me, for the last 10.  You know, LastPass is 10 years old this July.  It's the first part of a program I install on any new device.  I installed Chrome and then I install LastPass.  You got to have it.  The number one most preferred password manager.  13 million individual users.  Thirty three thousand business users.  LastPass.com slash twit.  It really is very, very important.  LastPass.com slash twit.  Facebook.  Okay, Joan, I want to know what you think about this.  Facebook, back to Facebook, is rating the trustworthiness of its users.  They say on a scale from zero to one, but that could just as well be zero to a hundred.  Right. It doesn't really matter what the scale is.  So they're assessing your reputation as part of an effort against fake news.  So what Facebook says it'll do is look at the stories you post.  And if they're true, you will get a higher rating.

Speaker: SPEAKER_00
Transcript:  Yeah, it's I don't know.  I don't know where they're getting these kinds of recommendations from.  Right. Because, you know, I could post only things that are satirical and be the funniest person in someone's feed.  Because I post things and my comments are, look at this.  It's ridiculous. Right.  And then so it's just to me, it seems like there's all these moments around, you know, thinking about how fake news is going to be used going into the midterms or the 2020s.  And so, but in this instance, right, pinning it on users, right, as if the users are the ones that are responsible for vetting all of the content and then only posting what is absolutely true.  It just seems like another way that they're shifting responsibility for the system that they've built.  Right.

Speaker: SPEAKER_03
Transcript:  We'll solve it with code. That's their attitude.  We'll solve it with code.

Speaker: SPEAKER_00
Transcript:  And like who wants only, you know, people who share true things in their feed anyway, right?  That stuff isn't interesting.  You know, if I want to read a dictionary and an encyclopedia, sure I will.  But I think, you know, one of the things that our research we've learned over this last year and a half or so of dealing with these stories is that people know they're false.  They share them anyway because either they cohere to a certain political belief or they think it's funny or it's outlandish.  And which is why I think they should really focus on the extremist stuff.  They're like conspiracy stuff and the hate speech and stop trying to, you know, stop trying to walk or walk through this gray zone.  And I wonder too, is this really only for people that are influencers or is it about, you know, like people who have pages?  I mean, we all have they limit the amount of friends you can have.  You can only have five thousand friends.  And so that's not a ton of impact per individual user.  So I wonder where or how they're going to apply this to those places where we see this stuff really proliferate, which is in groups and on pages.  And so, you know, I just feel like blaming the user just isn't it's not going to go very far.  And that is every tech company strategy, though.

Speaker: SPEAKER_01
Transcript:  Privacy, blame the user. Security, blame the user.

Speaker: SPEAKER_03
Transcript:  You ought to have known better.  So the Washington Post interviewed Tessa Lyons, who they identify as the product manager who is in charge of fighting misinformation.  And as she says, this came about because, you know, they had this reporting system, right?  Where as you're as you're reading a post, this started a couple of years ago, you could there was a tab in the upper right hand corner that said, is this, you know, problematic content?  But Lyons says she soon realized many people reporting posts is false, not because they were false, but because they didn't agree with it.  And so they that said then they had to step back and say, OK, now we got to figure out who we're getting the signal from and whether we can trust them when they say it's false.  So they're trying to assess whether the people who are flagging posts is false are themselves trustworthy.  Instead of just looking to see if the so the idea is they don't want as many they don't want to have to get as many articles that they then have to look at.  She says, I like to make the joke. If people only reported things that were false, this job would be easy.  People often report things they just disagree with.  So now they're that's why they're giving you a trust score so that if you're trustworthy and you say it's false, they're they're going to take a look at it.

Speaker: SPEAKER_00
Transcript:  We've seen similar systems like this deployed around, you know, trusted flaggers.  You know, hard to do. It's hard to do.  And also, you know, people flag for multiple different kinds of reasons.  And, yeah, I would say that, you know, sure, I disagree with things and some things are partially true.  That's the other thing that's been so difficult about talking with these companies about conspiracy theories, which is there's always elements of the theory that are true, that are verifiable, that circulate with the stuff that is false.  You know, and it's sort of like decoding, you know, it's like living in the X files in some instances where we're like, yeah, there are clues and there are things that we can point to and say, yeah, this thing happened.  But maybe the grays didn't land specifically in New Hampshire.  So, you know, it's just it's hard to understand why the user then would become the thing that they want to assess, other than to say that what it'll help them do is downrank certain people's content so that everybody's Uncle Larry, who every family already knows is untrustable,  is then seen as untrustable by the algorithm and therefore their content doesn't get seen or shared beyond their own page.  And so I think that's like a self driving car.

Speaker: SPEAKER_03
Transcript:  It would be so much easier if there just weren't any humans around.

Speaker: SPEAKER_00
Transcript:  Yeah. And that's the thing is, though, is they depend so much. You have to understand these systems are really like they're like libraries without books, right?  They're just shelves for things. That's what they've built is infrastructure.  And so without the users putting things on the shelves and sharing them and renting them out, there's no there's nothing there.  Right. Yeah. Yeah.

Speaker: SPEAKER_03
Transcript:  I never that's a very good analogy. That's I get that. Yeah.

Speaker: SPEAKER_00
Transcript:  Yeah. And so ultimately, they need to have some measure of good patronage.  But, you know, rating every single user based on what they flag, you know, ultimately, I think that they're one of one of the things that I think we're going to see over the next 10 years is that we're going to see less and less user generated content on these platforms and more and more.  You know, you're allowed to circulate things that have been verified and vetted, which will then open up new markets for things. Right.

Speaker: SPEAKER_03
Transcript:  You'll see earning. You can see the temptation if you built this library with just shelves.  The first thing you're going to want is come on in everybody just fill it up.  Yeah, we don't care what you put in there. Just put it in there.  And I think it's not unreasonable. If I put myself in Mark Zuckerberg's shoes to say, well, well, you know, put everything in there.  And it's up to the user to figure out if it's good or bad. That's not our job.  But then you get all this heat on you because your system inadvertently allowed all sorts of bad things to happen.  I don't know what it is, but so now they're saying, well, now we want to police what's on the shelves.  But you can't it's hard to retroactively do that.

Speaker: SPEAKER_00
Transcript:  Yeah. And that's where I think also the pace of technology is an interesting question, which is that we moved so quickly from being able to upload one picture, one song, one 10 second video to just, you know, full blown streaming.  HD content from people's bedrooms. And in the in that massive technological change, there was very little regulation.  There was very little foresight. There was very little, you know, turn on the faucet.  Yeah, come on. And so every, you know, now everyone isn't just, you know, their own printing press.  They're their own, you know, author. And and it's really hard because people now have shifted into thinking of themselves as, you know, citizen journalists and documentarian.  How dare they?  And so everybody feels a right to the Internet and they feel a right to broadcast and they feel a right to amplification.  But the downstream effects of that on democracy, for instance, are, you know, that's what we're seeing here is that when everybody can do political advertising, then it becomes really hard to assess what the issues are and who to trust.

Speaker: SPEAKER_03
Transcript:  This is a really interesting conundrum.

Speaker: SPEAKER_00
Transcript:  Yeah.  You should get into research, Leo. There's plenty to do.

Speaker: SPEAKER_03
Transcript:  I feel that I fear that any solution that you apply to this is going to have a worse outcome than the problem itself.

Speaker: SPEAKER_00
Transcript:  I don't know, because I, you know, I still really like the Internet.  There's still things that are useful on Web pages and and like even just the ability to be able to, you know, talk to you and Stacey today.  I mean, these are all positive, I think, outcomes of like having access to these technologies.  But there has to be a better governance model. There has to be some management.  There has to be, you know, and we can't reduce it all to technology.

Speaker: SPEAKER_03
Transcript:  No, I don't deny the value of it. It's certainly worth saving.  But I when as soon as you say there has to be some governance, that's very difficult to do.  Oh, yeah. People freak out.  And I don't know how you do it without actually creating a worse monster is all I'm saying.  Yeah, we just talked about that. If you do this, this trust thing, well, then there's all these other issues that come up.  Part of the problem is that we set up the Internet without really considering the consequences.  Now we've got consequences.  So now we're rushing to set up some solution without considering the consequences, which is going to give us worse consequences.

Speaker: SPEAKER_00
Transcript:  Yeah, and but that's part of why you would want to, you know, bracket some of these concerns and work on things.  You know, some some of these are easier to solve than others.  Like, for instance, the ad tech problem that we've identified and we know that, you know, bad actors online have been using advertising technology in order to force audiences to see disinformation that can be solved.  But the revenue cost to these platform companies would be enormous because they would have to check every ad.  You know, so there are bits and pieces of this that can be dealt with and can be moderated.  And but there are other parts of it that just feel so overwhelming when, you know, when you when you take it all as, you know, one big problem.  I'm for disaggregating things and then also starting to understand where there needs to be nuance and then where there's, you know, room for these platform companies to use some of their revenue in order to either bolster local journalism or to invest in more robust content  moderation or even teach people how to use these systems.  And, you know, some of the things that I've seen where people do share, you know, copious amounts of fake news has to do with that.  They they don't think anybody else is seeing what they're posting.  And so they just keep posting more and more and more things because nobody's engaging with it.  And so even learning how to use these platforms and having limits would be useful for some.

Speaker: SPEAKER_02
Transcript:  Let's take a break. I'm exhausted.  Like, okay.

Speaker: SPEAKER_03
Transcript:  It just often seems so daunting to me that I just I just want to move to an island and give up.  I know we can't.

Speaker: SPEAKER_00
Transcript:  You can't. Well, you can't go without your, you know, your display speaker.  You don't want to go there. Come on.  You still need access to movies and good, good TV.

Speaker: SPEAKER_03
Transcript:  Completely unfeasible to say, let's just not mess with it at all and just let's see what happens.  Or if we already know what happens.

Speaker: SPEAKER_00
Transcript:  I think, yeah, I mean, it's a funny question, right?  I mean, eventually, like you would imagine that it that what I see happening is actually what you've done, which is that good people leave.  Right. And so you end up like the bad forces out the good.

Speaker: SPEAKER_03
Transcript:  You know, we've seen that over and over again in social networks online that if you don't tend to your garden, the weeds will push out all the flowers and all you'll have is crap.

Speaker: SPEAKER_00
Transcript:  Yeah. And this I think we've seen and shed other social media as we've, you know, moved through different cycles of the Internet.  So and I think that you're one of many people that are having this reckoning.  I think this is happening right now. Yeah, I think it's happening.

Speaker: SPEAKER_03
Transcript:  I think there's an earthquake going on right now and people are moving out.

Speaker: SPEAKER_00
Transcript:  Yeah, they definitely are. And they're and they're not just leaving, though, but they're also, you know, a lot of people are trying new things.  They're trying smaller systems. They're more interested in privacy.  They're more interested in things that disappear online.  They're much more cognizant of what it means to put up information online.  You know, younger people are definitely at the forefront of this.

Speaker: SPEAKER_03
Transcript:  I'm using Mastodon more. Yeah.

Speaker: SPEAKER_01
Transcript:  Are you really? OK, I was going to ask because Wired did that story and I was like, oh, I know that we talked about it for a while ago.

Speaker: SPEAKER_03
Transcript:  And yeah, I have an account lying around.  It's actually one account lying around. It was an instance that is gone.  So fortunately, I had a backup account on Mastodon.social, which you can't join now, I think, because it's just so big.  Let me log in. I don't know if I can log in quickly here.  The. My suspicion is it's only good because nobody's using it.  And that as soon as it becomes as popular as Twitter, it will have all the problems Twitter has, although it's structurally somewhat different.  It's a federated social network. So there are many, many different servers.  And whoever runs the servers responsible for the rules, you can say, well, I don't want to have any Nazis on mine.  In fact, most of them say that there are probably Nazi instances.

Speaker: SPEAKER_01
Transcript:  But I was about to say somewhere. Well, they probably are.

Speaker: SPEAKER_03
Transcript:  But what happens is the other instances don't federate with them.  So it effectively it allows it, but it keeps it out of my feed, which is, you know.

Speaker: SPEAKER_01
Transcript:  If they do that in secret, is that.

Speaker: SPEAKER_03
Transcript:  Well, that's the other thing we've talked about this before that I always thought you lift the rock up and you let sunlight disinfect.  And that's how you cure this stuff. But it's become clear.  And thanks to researchers like Joan, that in fact, sunlight does not disinfect.

Speaker: SPEAKER_00
Transcript:  It just spreads the word. Yeah, it's definitely something that we've we've you know, when people are operating bot accounts and, you know,  social using social media amplification tools and SEO strategies, they're just so much louder than any other rational voice.  And so it's not the same relationship as you would have to speech in, say, a public space.  So there is a lot to be and there's also a lot to be gained from thinking about the design of Mastodon itself,  which kind of echoes the early Internet around decentralization.  People, you know, have an issue based interests where they, you know,  that the name of the chat room or the name of the service describes the thing that you're interested in or the subculture.

Speaker: SPEAKER_03
Transcript:  Well, you know, I'll give you a really interesting example that this might be a little controversial,  but sex workers were forced off by FOSTA and SESTA public forums.  But they say we have a right to if it's in our interest and it's in our safety to have a place where we can be and find clients and clients can find us.  So there is a sex worker Mastodon.  Now, if I don't want to see that, it's a trivial thing for me to say, well, I just don't want to see any traffic from there.  So it solves the problem, I think, in a really interesting way, because it can exist.  Some Mastodon instances confederate to it, but you don't have to see it if you don't want to.  It has very good controls for that kind of thing.  It doesn't allow quoted retweets.  It does allow retweets. They call it boosts.  And I think retweets are part of the problem on Twitter because they amplify the outrage.  I think it's a really interesting experiment because is it possible to design structurally something that will be less prone to the problems that Facebook and Twitter and others are prone to?  Or does everything in the long run just become like Twitter?  I don't know. If you look at it, it looks just like Twitter.  So what you're seeing here, this is the instance I'm on.  Or actually, no, this is my feed.  So these are people I'm following.  This is the instance I'm on the local timeline.  So this is everything going on on that server.  What I don't have turned on, I'll turn it on briefly, is the federated timeline.  That's everything.  And so there's a little more stuff on here that you might not want to see.  Notice there's another feature which I think is really, really interesting.  Sensitive content.  And there's a, when you post something, when you toot, as they call it, you can press the CW button, which is a content warning.  And you can write your warning.  I posted, for instance, a toot about the meat meal, meat-based meal I made yesterday.  And I, in my content, I hid the content and I put, warning, you know, non-vegetarian content here, meat.  So if somebody's bothered by that, if people responsibly use it, that also has a very nice impact.

Speaker: SPEAKER_01
Transcript:  Did you feel that that was a responsible use? I'm just curious.

Speaker: SPEAKER_03
Transcript:  I think it was. I put cooking colon meat.  So that, because I was going to talk about ways to cook an animal.  And I wanted to be sensitive to the fact that some people may not want to see that.  And there is right now, anyway, culturally in Mastodon, that kind of thing.  People, if they talk about Twitter, for instance, that becomes a content warning.  We're going to talk about bird site.  If it's anything that could be triggering, if, you know, I think that's really interesting.  People are very thoughtful about the other people on there.  And then because it's federated, the person who runs the instance really gets to set whatever rules they want.  And there's also then that generates a culture, right, that one hopes persists.  I don't know. I think it's a very, we've talked about it before.  It was very hot for a while. It's kind of gone down.  Oddly enough, without much publicity, it's coming back now.  And I think that that, what I sense is that's people fleeing Twitter.

Speaker: SPEAKER_00
Transcript:  Yeah. And the other thing that's probably going to be the tail of the tape is how good the mobile app is  and how much the mobile app can incorporate the user features that people want.

Speaker: SPEAKER_03
Transcript:  Well, here's an interesting thing. It's, it's, it's, there is no official mobile app.  All the mobile, there are many third party mobile apps because it's got an API.  So you can choose a mobile app that lets you do what you want to do.  Different mobile apps have different features.  Isn't that interesting?

Speaker: SPEAKER_00
Transcript:  Yeah. I mean, this might be the wave of the future, right?  I mean, around podcasts and things, you know, it's been really helpful to have multiple different podcast apps to be able to run, you know,  whatever way in which you want to download and sort your content.  And so it might just be that you might use one instance, you might use one app for Mastodon for, you know, your sex work channels.  And then you've got another app running where you have other channels.

Speaker: SPEAKER_03
Transcript:  There actually is a, the one I use on iOS, the app that I use on iOS has exactly that feature.  Let me see what it's called. It's called Toot Don.  And you can say, I want to follow this instance. You can actually have a timeline.  That's just the instant. There's that instance.  So if you wanted to follow Nazis specifically, you could.  Yeah. And if you didn't want to, you wouldn't have to ever. You could block it.  So I'm so this is an example, isn't it?  But I think it's very hard to retrofit Twitter or Facebook.  I mean, that's exactly what these companies are facing. It's very hard to retrofit.  But I think if you thought and you looked and carefully thought about it, read all of Jones postings on data and society and then said, well, what can we make that might solve some of those problems?  I think it might be possible to create something that didn't have those same problems.  I hope that that's the case.

Speaker: SPEAKER_00
Transcript:  Yeah, I think you're I mean, you're the best user, you know, test case in this scenario because, you know, so much about how the things work.  But also you're invested in having a stream of information that mirrors the way that you want to live in this world.

Speaker: SPEAKER_03
Transcript:  Right. And I do. There is valuable stuff in the sewage of Twitter.  And I would love to get that over here.  I despair on being able to create any sort of sewage treatment system on Twitter.  That's not going to happen. Right.

Speaker: SPEAKER_00
Transcript:  They're trying. They're like public health conversation, public or healthy conversations.  Do you feel like they are?  I mean, I mean, there's a lot of research being done.  I'll be interested to see how it shows up in features.  You know, there's a lot of this talk about shadow banning and what that actually looks like.  And you've seen some modifications to the replies so that replies that have certain words in them are hidden behind.  You know, you have to click on this show me more button.  So there there's a sort of, you know, there's a concerted attempt to change the interface.  But I mean, so much of what is terrible is just stuff we already know about.  Right. Right.  So unless they're willing to not just moderate content, but also think about certain users differently or not treat celebrities badly, you know, differently, you know, like then, you know, things could change.

Speaker: SPEAKER_03
Transcript:  I was so sad when I read the New York Times editorial by the woman who was in Star Wars.  Oh, yeah.  And how she fled. She had to basically flee social media because she was so mistreated because she was an Asian woman.

Speaker: SPEAKER_02
Transcript:  Hmm. Yeah.

Speaker: SPEAKER_00
Transcript:  I mean, harassment online has been, you know, at the same moment that we're seeing women really step into the four of different industries becoming CEOs, like stepping into male dominated markets around gaming.  We're seeing more and more harassment online.  The top that's happening in public.  Right.  You know, it used to be you'd get harassed and show up in your email or maybe your voicemail would get attacked.  But now it's just flagrant and it's so visible.  And part of that is the strategy of of letting other people know that follow that person.  That, you know, that the harassment is happening and that if they were to speak up, they would get harassed, too.  And so, you know, that public the public harassment and the public shaming is something that these platform companies, especially Twitter, need to act quickly, but also very decisively.  Right. And and it would make people think twice if they thought they were going to lose their account forever or that it was going to be harder and harder for them to, you know, stay online or, you know, if there were cross platform policies where you didn't just lose your Twitter account.  Maybe you lost your medium account as well or you lost your YouTube channel and and you would you wouldn't keep on doing this.  You wouldn't behave in this way.

Speaker: SPEAKER_03
Transcript:  If you want to understand this a little better, read the New York Times opinion piece by Kelly Marie Tran.  I won't be marginalized by online harassment.  She talks about her experience.  She says you might know at the end, she says you might know me as Kelly.  I am the first woman of color to have a leading role in a Star Wars movie.  I am the first Asian woman to appear on the cover of Vanity Fair.  My real name is Loanne and I am just getting started.  And that's really what she's saying.  I'm not going to let this keep me down.  Good for her.  But the fact that she even has to say this is sad.  Do the platforms, are they in touch with you and Dana and reading what you're saying?  I mean, are they are they open to what you have to say?

Speaker: SPEAKER_00
Transcript:  Yeah, we have different researchers that have gone out to myself included to to talk with product design people.  Policy people.  We often if we do see a noxious problem, you know, we don't wait to research it.  We reach out directly to them and say, hey, we see this is happening.  Hope you can see it, too.  And, you know, what's interesting actually is the camaraderie around researchers within these companies and researchers that exist in my world, as well as other academics that are at, you know,  Harvard and Stanford, as well as UT Austin.  So, like, for instance, the Social Science Research Council has a new initiative to help with Facebook recruiting university researchers to do research with this really big bucket of Facebook data that they're releasing through the Social Science Research Council that academics can then apply to do research on.  So normally that kind of data is kept in house and the researchers at these companies will be the ones to analyze it.  But we see more and more that these companies realize that they're not going to attract the talent and the rigor of academics that work in universities or work in research institutes like myself, because we don't want to be the only ones to do research on.  Our interests actually lie in understanding how these products influence elections, how they impact society.  And so we do have quite a few different meetups and gatherings and to talk through these these problems.  But it's from our vantage point, there are design decisions that can be made that haven't been made that, you know, we would like for platform companies to implement.  But ultimately, we do see that they reach out, they listen.  And, you know, when we release reports, they definitely react and let us know what what they what they want to know.  And then they obviously always have questions.  So that's been a different, you know, the mood of that research has definitely changed over the last year.  It used to be that they were taking interest in fake news and thinking about it more like a problem of spam.  And how do we get spam off of the the websites?  And then is it involved into, oh, this is a you know, this was a concerted effort by foreign, you know, media manipulators to manipulate elections, the tenor around the seriousness of what was at stake changed.  And we've had some really important conversations with Twitter, Facebook, Google.  And so I, you know, to be honest with you, I wouldn't stay in the field if I felt like we weren't getting somewhere.  It would, you know, it would it does sometimes feel like we're like beating the game.  And we're like, what are we what are we trying to do here?  But we are getting we are getting, I think, closer to understanding.  And we're learning, I think, from our vantage point as researchers, how complex the problem looks from the inside of these companies.  And I think that the companies are learning from us that there are different ways in which they can engage and think about doing research, which hopefully will end up in their design decisions.  I want to take a little break.  We will come back and get the change log, all the new stuff happening on Twitter.

Speaker: SPEAKER_03
Transcript:  All the new stuff happening on Google.  But first, our show today brought to you by Rocket Mortgage.  Your new home will be brought to you by Rocket Mortgage.  If you pay attention closely to the words, I am about to speak Rocket Mortgage from Quicken Loans, the best lender in the country, number one in customer satisfaction for eight years in a row, according to JD Power.  Number one, that probably is why they're also, as of December, the number one largest in terms of volume mortgage lender in the country.  They listen, they think about their customers and they decided to make something that's fast and easy and entirely online.  It's called Rocket Mortgage and it lets you apply for a home loan on your phone.  It's so fast you could do it in an open house.  It just takes minutes.  And now they've really enhanced it.  They have something they're calling the power buying process.  So let me walk you through it step by step.  First, on your phone, you log into your account.  Go to rocketmortgage.com slash twig, set that account up so you'll be ready.  You'll log into your account.  You answer a few simple questions.  You give them permission to get your data.  You don't have to go get it yourself.  You don't have to go to the attic.  You don't have to call your previous employers or anything.  They get everything they need to basically figure out what you're good for.  And then they give you all the loans for which you qualify.  You choose the rate, the term and everything.  That's step one.  Step two, 24 hours later, you get verified approval.  A loan officer goes over the information, verifies income, assets and credit,  and they give you verified approval.  You now have the strength of a cash buyer.  You get that verified approval letter, which you can take with you.  When you make an offer, you go right to the front of the line because you're good for it.  You're verified.  You got the money.  And once you're verified, step three, rate shield approval, all new and exclusive.  And frankly, we didn't need this last year.  Interest rates were flat.  They've been going up, haven't they?  And that means there's stress.  That means there's like, we got to buy this house.  It could cost us a lot more tomorrow if the rate goes up.  No, with rate shield approval, they lock up your rate for up to 90 days.  You have three months to look.  Your rate cannot go up.  If your rate goes up, your rate stays the same.  If rates go up, your rate stays.  If they go down, your rate goes down, either way you win, this is why they're the best.  Quicken Loans and Rocket Mortgage.  All you have to do right now, go to rocketmortgage.com slash twig and get started.  Rate shield approvals only valid on certain 30-year purchase transactions.  Additional conditions or exclusions may apply based on Quicken Loans data in comparison to public data records.  Equal housing lender, license in all 50 states, and MLSconsumeraccess.org number 3030.  You don't have to remember all that.  Just remember this, rocketmortgage.com slash twig.  And we thank Quicken Loans and Rocket Mortgage for their support of this week in Google.  And now get the bugles ready, Karsten, because it's time for the Google Change Log.  The Google Change Log.  You missed it. You demanded it. Back by popular demand.  Leo's Salad. It's the change log. New stuff from Google.  Interesting article in Google's Keyword Blog about new ways search is helping you.  Imagine you're remodeling your kitchen.  I think Stacey's always remodeling her kitchen.  And you want to know about how Quartz compares to Granite.  You could enter a search term, Quartz vs. Granite, and it would give you these.  This is a new search box.  Look at this. Cost, benefits, weight, durability.  When you search for something, you'll see a panel with a set of relevant subtopics to explore.  Another example, if you search emergency fund, you'll get a quick view of information that relates to the recommended size, purpose, and importance of an emergency fund.  Wait a minute. I got to try that.  Emergency fund.  No, maybe it's not on yet. Or maybe I just have Google set.

Speaker: SPEAKER_01
Transcript:  Maybe you can't spell.

Speaker: SPEAKER_03
Transcript:  Did I spell it wrong?  No, you did.  I frequently spell things wrong.

Speaker: SPEAKER_01
Transcript:  I am terrible at spelling and Google is constantly like, did you perhaps mean this?  I'm like, oh, yes, I did.

Speaker: SPEAKER_03
Transcript:  The single biggest use of Google these days for me is spell check.  This is a new feature in search, but that's not the only thing.  Are you ready for some good news?  Now you can ask your Google home for good news.  You say Google, tell me something good.

Speaker: SPEAKER_01
Transcript:  Mine doesn't work on that.

Speaker: SPEAKER_03
Transcript:  Well, I think some of the things we talk about in the change log, we should give you a disclaimer.  Some of the things mentioned in the chain log are not available yet, but will be soon.  Tell me something good.  Tell me something good is a new experimental feature.  Maybe that's why you don't get it.  For assistant users in the US, it delivers your daily dose of good news.  Just say, hey, Google, tell me something good to receive a brief news summary about people who are solving problems for our communities and the world.  It comes from the Solutions Journalism Network, a nonpartisan nonprofit.  So don't expect to hear things about, I don't know, Trump associates going to jail.  It's not going to be in there.  It's a nonpartisan nonprofit dedicated to spreading the practice of solutions journalism.  I didn't even know that was a practice.  But if you feel bad, ask Google to tell you something good.  I've been using the Apple Watch for some time with the activity rings.  Now Google's doing it.  The new Google Fit has, well, they're not rings.  They're octagons, but it's the same idea.  The activity rings, they don't have the stand ring, but they have movement.  It's in heart points.  It's an all new Google Fit.  Also on Android Wear, notice.  Don't expect this on the iPhone.  I don't know if you get these new features yet on the iPhone, but the Google Fit on Android and on the Android Wear.  You get move minutes for all your activity.  You get heart points when you get your heart pumping harder.  So do some kickboxing.  I think this is a good thing. Yes.

Speaker: SPEAKER_01
Transcript:  I guess so.  I mean, Android Wear was so crappy.  I just went with Fitbit.  And I don't see myself going back to it anytime soon.

Speaker: SPEAKER_03
Transcript:  And then, okay, I'm going to do a couple.  What do you think, Stacey?  Should the change log include things that might be happening or are probably going to happen but haven't happened yet?  Or should it only be things that are happening?  For instance, have you seen the pictures of the new, let me see if I can find it.  Pixel 3 XL in Russian.

Speaker: SPEAKER_01
Transcript:  So a change log is actually things that have changed.  So I think you should keep it that way.  Damn it.  But we can talk about that outside of the change log.  Okay, I'll save that.

Speaker: SPEAKER_03
Transcript:  They probably don't want me to mention the experimental podcast app, Shortwave, because that's not out yet either.  I'll save those for after the change log.  So a brief, a truncated, but I think sufficiently interesting, Google Change Log.  Thank you and God bless.  So now we'll mention the Pixel 3.  You use a Pixel 2, right, Stacey?  I do.

Speaker: SPEAKER_01
Transcript:  The smaller, not the XL.

Speaker: SPEAKER_03
Transcript:  So somebody in Russia has, this is an XL obviously, and it's very similar except, look, there's a notch.  Oh, nuts.  No one knows when this is going to come out.  The rumor is October.  But I have to tell you with Pi out now and all of these leaks of packaged Pixel 3s, I wonder.

Speaker: SPEAKER_01
Transcript:  Who were they sending these to?  I don't know.  How were they getting out into the world?  That was my, can I just tell you, Pi is confusing me.  Is it? You don't like Pi?  I don't, I used to get the weather.  Now I don't get the weather.  I actually followed this lovely blog post that told me all the ways I could get the weather and I tried to troubleshoot that way.  You're talking about the widget.  There is no weather widget.  It used to be a weather widget.

Speaker: SPEAKER_03
Transcript:  There is. There's a widget.  So if you use the, let me turn up the.  I looked for the widget.  If you use the default Pixel launcher at the top here, you get this changing, you can't really see it very well, can you?  This changing widget.  Mine says six minutes to home because it knows I'm almost done.  No delays, moderate traffic.  Then it gives me a little sun and 76 degrees.  I could tap that and the weather pops up.  Or if I text six minutes to home, it shows me the commute.  Right.  So my son went away.  No, son went away.

Speaker: SPEAKER_01
Transcript:  My son went away and then it came back briefly.  Well, no, it does.  That's what's confusing about this.

Speaker: SPEAKER_03
Transcript:  It changes all the time.  It doesn't give me any other information.

Speaker: SPEAKER_01
Transcript:  Sometimes I get a calendar.

Speaker: SPEAKER_03
Transcript:  Like if I had an appointment, it would show me a calendar.  It does give me the calendars.

Speaker: SPEAKER_01
Transcript:  But you don't get the weather.

Speaker: SPEAKER_03
Transcript:  I don't get the weather anymore.

Speaker: SPEAKER_01
Transcript:  I used to get the weather and I loved getting the weather.  I love the weather too.  Why?  And then the other thing is I'm constantly putting my phone into do not disturb.  And when I use the nifty little.  The rocker.  The rocker to turn it off.  It doesn't actually turn it off.  I have to turn it off.

Speaker: SPEAKER_03
Transcript:  There is a there are I notice there are a lot of people complaining because this this old do not disturb thing.  You have to go here for that.  The rocker.  The rocker is just the three different states of the bell and the level of the media.  If you touch the gear, you'll see more about you'll get an idea of what you're getting.  That's not do not disturb.  You have to go up here and turn that do not disturb icon offer on still.  How about the gestures?  Are you somebody people be complaining about this instead of the three buttons at the bottom.  We now have a pill swipe up all the way.  You get apps swipe up halfway.  Oh, you have to turn the pill on.  Oh, so let me help you turning on the pill.  That's in settings.

Speaker: SPEAKER_01
Transcript:  Why am I on the show again?

Speaker: SPEAKER_03
Transcript:  I think I showed Jeff how to do this last week, but you were apparently asleep.  It's possible.  They don't for some reason they don't turn it on, which I think they should because I think it's a big part of it.  Right. I can Google this.

Speaker: SPEAKER_01
Transcript:  You don't actually have to show me.  We have other things we can do.  If you type in a home in the search, you can I don't know.

Speaker: SPEAKER_03
Transcript:  Screw it.  Yeah, just figure it out.

Speaker: SPEAKER_01
Transcript:  I can Google this.  I am a depth to Google.

Speaker: SPEAKER_03
Transcript:  Okay, story to and then we're going to we're going to take a break and get because everybody has to go home.  We've been going on way too long.  Google, according.  No, not your fault.  It's Joan's fault.  Google.  No, just teasing my fault.  It's always anything that goes wrong in this show is my fault because I'm your emcee.  I'm your master of ceremonies.  Google is developing experimental podcast app called shortwave.  This is according to the Verge.  It's a trademark filing they found.  Reached by the Verge, a Google spokesperson emphasized confirmed it emphasized the app is being developed within the company's area 120 incubator not related existing Google projects.  Quote, one of the many projects we're working on within area 120 is shortwave, which helps users discover and consume spoken word audio in new ways.  It's a very early experiment.  So aren't there aren't many details to share right now.  What do you think transcriptions maybe?

Speaker: SPEAKER_01
Transcript:  I can't talk about it.

Speaker: SPEAKER_03
Transcript:  Stacey Denise Higginbotham.  I'm making up your middle name because I don't know.

Speaker: SPEAKER_01
Transcript:  You are. I'm like interesting.  Okay.

Speaker: SPEAKER_02
Transcript:  Well, you're Denise, your brother's to nephew.

Speaker: SPEAKER_00
Transcript:  Like the best guess you can give is Marie.  So why?  Why?  Marie Marie's for middle, you know, Stacey Marie Higginbotham that does have a ring to it.

Speaker: SPEAKER_03
Transcript:  No, it's just everybody.

Speaker: SPEAKER_00
Transcript:  It's my clothes.  Always Mike.

Speaker: SPEAKER_01
Transcript:  It's close.  Yeah, it's that's my mom's middle name and my mom's first name is my middle name.  Joan Donovan.

Speaker: SPEAKER_03
Transcript:  You are so smart.  Joan.

Speaker: SPEAKER_02
Transcript:  So good.

Speaker: SPEAKER_00
Transcript:  If you ever need to socially engineer your way into something, just remember it's a woman's name.  Marie might be the way to go.

Speaker: SPEAKER_03
Transcript:  Wow. Fascinating.  So Joan Donovan, Data and Society, data society dot net, your pick of the week.

Speaker: SPEAKER_00
Transcript:  So this is actually something you might like, Leo.  I have it.  I interviewed Siva.

Speaker: SPEAKER_03
Transcript:  I love it.

Speaker: SPEAKER_00
Transcript:  Okay.  So this book, I just started it and I'm loving it.  And so I'm hoping that the conclusion is as good as I hope it is.

Speaker: SPEAKER_03
Transcript:  I think this is why I'm not on Facebook anymore.  Frankly.  Yeah.  How Facebook disconnects us and undermines democracy.  That was this.  That was the seed.  And Siva's great.  Yeah.  He's on this week in.  No, I'm sorry.  A triangulation episode.

Speaker: SPEAKER_00
Transcript:  Yeah.  And then I have one other one, which is another book about the Internet, Custodians of the  Internet, Tarleton Gillespie recently.  And I read a pre print of this a few months back and was really impressed.  And so I'm going to now take my pen to the paper and and really dig in.  But I think these two books right now are couldn't be more timely thinking about content  moderation, thinking about these platforms and you know how they're shaping our lives.

Speaker: SPEAKER_03
Transcript:  By the way, Gillespie is a principal researcher at Microsoft Research New England and an  affiliated associate professor at Cornell.  It's published by the Yale University Press.  And it's exactly what we were just talking about.  Platforms, content moderation and the hidden decisions that shape social media.  Custodians of the Internet.  Put that on our list, Karsten.  That looks like a good one.  Stacey Higginbotham.

Speaker: SPEAKER_01
Transcript:  OK, you guys, y'all are going to hate me, but I'm under bargaining.  You're going to hate me, but I'm under bar go for a bunch of devices that break like the next couple of weeks.

Speaker: SPEAKER_02
Transcript:  And clearly for something new from Google.

Speaker: SPEAKER_01
Transcript:  Oh, so being under embargo for all these crazy things, I had to reach into the the old book world again.  Sorry for the device lovers out there.  But this is actually an old book that I saw because of an Axios article citing Bill Gates.  So it was Bill Gates in his blog talking about this.  So the book is called Capital, sorry, Capitalism Without Capital.  And it's the idea.  And I'm interested in this because, you know, everything I talk about is basically being sold as a service.  So the idea is for out much of history, when you make a product, your as demand increases.  Oh, I can never.  This is why I'm terrible with economics.  I can't read charts at the same time and talk as demand increases.  Prices drop until you reach some sort of magic equilibrium.  What happens with software is your cost of producing goods doesn't really mesh necessarily with how much you can charge for them.  And so there's this whole area of the economy that we're not really dealing that we're not really talking about.  So I got this book so I could learn more about this because I love economics.  And I don't know.  It's exciting.

Speaker: SPEAKER_03
Transcript:  I think in a way, in a nutshell, that's exactly what's happening with everything, which is a lot of the old rules no longer apply to the new way of, you know, technology, the new way of being.

Speaker: SPEAKER_01
Transcript:  Yeah.  And they're like, you know, I talk about this when I was in Germany earlier this year at this Bosch event, they have actually an entire lab dedicated to business models for the service economy, which is kind of crazy to think about, but also kind of awesome.  I keep trying to talk to people in that lab, but I don't speak German.  So maybe I should get Jeff over there.  So, yeah, very nice.

Speaker: SPEAKER_03
Transcript:  The book, Capitalism Without Capital, The Rise of the Intangible Economy, written by Jonathan Haskell.  I don't have a pick, but I have a reminder that we've had some very good triangulations over the last few weeks.  Last two weeks was Saul, I'm sorry.  That's what Steve Jobs calls him.  And I'm going to start with Saul Segoian with some great anecdotes about Steve Jobs.  He's the guy who was in charge of Apple script and automator at Apple until he was let go a couple of years ago and he has some very pungent things to say and some great demos to.  This week, 3pm Friday, 6pm Eastern.  We're going to talk to, on triangulation, to Bill Atkinson, who is really the heart and soul of the Macintosh, the Lisa, and General Magic.  He's going to bring some toys and props and tools, and we're going to talk about Apple, but we'll also talk about General Magic.  This is going to be a lot of fun.  Bill's always a great interview.  That's this Friday, 3pm Pacific, 6pm Eastern time.  The following week, Ken Koshenda will be our guest.  Megan Maroney interviewed him last week.  She was one of the designers of the iPhone and talks about the culture at Apple and how it was designing the iPhone in the very beginnings.  So we have some really good triangulations coming up, and those come out for download Friday afternoon.  But you can watch it, watch us do it live, usually 3pm Pacific time on Friday.  Thank you, Stacy.  Higginbotham, Stacy on iot.com.  At the gig of Stacy on the Twitter still.  You know, I haven't I haven't listed my Twitter handle in years, so I guess I don't have to say.

Speaker: SPEAKER_01
Transcript:  That's where you know, that's one of the best places to find me because I actually check that most every day.  Whereas Facebook, I think you get an automated message that says I'm not very good at Facebook.  I do check it.  I just I'm not on it like all the time.

Speaker: SPEAKER_03
Transcript:  I I've slowly been eliminating all ways of reaching me.  I don't read email.  I don't accept tweets.  You just I don't want to talk to you, so don't try.  Joan Donovan, I love talking to you.  Data society dot net.  She's a researcher there and as you can tell, talks a lot about fake news, platforms, social media.  It's always a pleasure.  Anything you want to plug at Boston Joan on Twitter?

Speaker: SPEAKER_00
Transcript:  No, it's yeah, just keep on Internet and that's about it.  Keep on the Internet.

Speaker: SPEAKER_02
Transcript:  Keep online.

Speaker: SPEAKER_01
Transcript:  Keep it on on Internet and I'll teach you on Macedon.

Speaker: SPEAKER_03
Transcript:  I'll teach you.

Speaker: SPEAKER_00
Transcript:  I'm not.  Yeah, now you made me a believer.  I'm going to open it back up.  I haven't been on mass in on a few months, but I think I think I need to try.

Speaker: SPEAKER_03
Transcript:  I'd be really curious what you think about it.  You're a good person.  I think you're a good person, Joan.  Well, you're just a good person.  Let's just leave it at that.

Speaker: SPEAKER_00
Transcript:  Show's over.  Show's over.

Speaker: SPEAKER_03
Transcript:  She's a good person.  Thank you all for being here.  We do this.  We can Google every Wednesday, 1 30 Pacific, 4 30 Eastern, 20 30 UTC.  You can watch us live at twit.tv slash live.  You can join us in the studio.  Email tickets at twit.tv.  If you're going to be in Petaluma, California anytime soon, but do email us because sometimes I'm not here.  Sometimes the door is locked.  It's just a good idea to check ahead and make sure we're here.  You can also listen on demand to anything or watch.  We make audio and video of all our shows available at twit.tv.  In this case, twit.tv slash twig.  The show comes out Wednesday afternoon after the live taping usually takes us an hour or two to get it out, maybe a little bit longer.  You could subscribe to just find your favorite podcast or that way you don't have to worry podcast application.  You don't have to worry about schedules.  It'll just appear on your phone when it's ready and you'll be able to listen the minute it's available.  Thank you so much for being here and I'll see you next time on This Week in Google.  Bye bye.

