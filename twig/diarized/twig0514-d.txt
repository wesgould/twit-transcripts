;FFMETADATA1
title=Alphabetical
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=514
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2019
encoder=Lavf58.76.100
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 1970."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" 1911."): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" You don't want to reveal..."): backtrack failed, resorting to original...
Failed to align segment (" Facebook can make the same..."): backtrack failed, resorting to original...
Failed to align segment (" Do they give people time to do that?"): backtrack failed, resorting to original...
Failed to align segment (" Yeah."): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" I just didn't know that was even possible."): backtrack failed, resorting to original...
Failed to align segment (" Verizon never did respond."): backtrack failed, resorting to original...
Failed to align segment (" It's not clear."): backtrack failed, resorting to original...
Failed to align segment (" Yeah."): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" I'm getting this right now."): backtrack failed, resorting to original...
Failed to align segment (""): no characters in this segment found in model dictionary, resorting to original...
Failed to align segment (" Debates are going to be fun."): backtrack failed, resorting to original...
Speaker: SPEAKER_03
Transcript:  It's time for Twig this week in Google. Jeff Jarvis is here, Stacey Higginbotham's here, Matthew Ingram is.  Congratulations to Matthew. He's winning a major journalism award this week.  We will talk about McLuhan, because it's an award from the McLuhan folks.  We'll also talk about the president. He's mad as heck about Twitter.  And he's not going to take it anymore. And what they're doing in Toronto with Sidewalk.  It's all coming up next on Twig.  Netcasts you love.

Speaker: SPEAKER_06
Transcript:  From people you trust.

Speaker: SPEAKER_05
Transcript:  This is Twig.

Speaker: SPEAKER_03
Transcript:  This is Twig this week in Google. Episode 514, recorded Wednesday, June 26th, 2019. Alphabetical.  It's time for Twig this week in Google, the show where we cover the latest from the Googleverse,  Facebook, Twitter, a little bit of Google too. Jeff Jarvis is in Toronto today.  I don't want to admit this. Jeff's here, Professor at the townite center.  Craig Newmark, official chair of the thing at the CUNY graduate school of townmark journalism.  And then, I'm sorry. I'm sorry, Jeff. I don't have it. If I can't read it.  BuzzMachine.com. If people watch the show and don't know who you are, forget it.  Also with us, of course, Stacey Higginbotham and her new digs in the Pacific Northwest. Hello, Stacey.

Speaker: SPEAKER_07
Transcript:  She unpacked her microphone.

Speaker: SPEAKER_09
Transcript:  Look at that.

Speaker: SPEAKER_06
Transcript:  I did. And I put up my little sound panels. I've got one more thing coming and then I'm done.

Speaker: SPEAKER_03
Transcript:  This is your studio now.

Speaker: UNKNOWN
Transcript:  Yep.

Speaker: SPEAKER_03
Transcript:  Nice. It looks great.

Speaker: SPEAKER_07
Transcript:  Is that a brother or an HP behind you?

Speaker: SPEAKER_03
Transcript:  It's a brother.  All right. Better be an Epson. Hey, is your reformer in there? Your Pilates machine?

Speaker: SPEAKER_06
Transcript:  No, this is a very tiny office. So it's downstairs in our gym where we have an  elliptical, the reformer and a weight bench.

Speaker: SPEAKER_03
Transcript:  Boy, you really have embraced the Washington lifestyle.  Washington State.  And joining us also from Canada, because he and Jeff are at the same conference,  the great Matthew Ingram from the Columbia.  Matthew's here.  Yeah. Well, you know, he didn't have to go very far. Of course, chief digital writer at CJR.

Speaker: SPEAKER_07
Transcript:  Matthew's also in a new home, I believe. Yes.

Speaker: SPEAKER_08
Transcript:  Yeah, this is not it. I'm at the lake currently.

Speaker: SPEAKER_09
Transcript:  Oh, you're at the lake.

Speaker: SPEAKER_06
Transcript:  Matthew is at the lake.

Speaker: SPEAKER_07
Transcript:  You should have done the show on the kayak, Matthew. We're very disappointed.

Speaker: SPEAKER_03
Transcript:  I know.

Speaker: SPEAKER_08
Transcript:  The connectivity is not great.

Speaker: SPEAKER_03
Transcript:  In the summertime, Matthew's Instagram is taken over by feet in a kayak.  Just all lake all the time. But Matthew, I do have to point out one little thing. I think it's  probably the rise and fall of the Third Reich or something like that. But there is a swastika  over your right shoulder. Yeah. And I don't want to give people the wrong impression.  Hang on.  Yeah.  Oh, yeah, there is.  Yeah. It does jump out at one.

Speaker: SPEAKER_08
Transcript:  I think it is the rise and fall.

Speaker: SPEAKER_03
Transcript:  Yeah, I recognize the spine because it's one of my favorite books.  Oh, there it is. Oh, I see it.

Speaker: SPEAKER_07
Transcript:  Oh, that is it. Yes.

Speaker: SPEAKER_03
Transcript:  I just want to get this show banned in Germany or anything.  Cover your swastika? Is that what the request is here?  Please cover the swastika.  Is that the show title?  Wait a minute. No, we can do it. We have the technology. Go ahead. I just have to tell you.  There we go. We zoomed in and now the lower third covers it all up.

Speaker: SPEAKER_08
Transcript:  More of me, less swastika.

Speaker: SPEAKER_03
Transcript:  Actually, I don't know a lot of people with bookshelves in their houses with glass doors.  That's very, very...

Speaker: SPEAKER_08
Transcript:  So this is actually my mom and dad's bookcase that they bought in Germany in the eighties.  Ah ha.

Speaker: SPEAKER_03
Transcript:  That explains the swastika.

Speaker: SPEAKER_08
Transcript:  It weighs about 1,100 pounds.  How did they get it? Did they live there?  They did. Yeah.  Oh.

Speaker: SPEAKER_07
Transcript:  So they didn't just go there on vacation and bring back an 1,100 pound bookcase.

Speaker: SPEAKER_08
Transcript:  They lived in Germany for four or five years.  Oh, neat.  They lived in Holland for four or five years.  Oh, that's neat.

Speaker: SPEAKER_03
Transcript:  Were you raised in those countries? Were you raised in the low countries?

Speaker: SPEAKER_08
Transcript:  I was born in Germany, but we only lived there for I think about a year or two.  Yeah, my dad was in the high north.  Stricter Kind Deutsch.  He was stationed there. No.  Nein. Nein is the word.

Speaker: SPEAKER_03
Transcript:  Nein.  So Matthew is going to be winning a major award on Friday.  Actually, I'm sorry I laughed.  Let me do that again.  Matthew is winning a major award on Friday.  Very proud of him.

Speaker: SPEAKER_06
Transcript:  Did we introduce him as an award-winning journalist yet?

Speaker: SPEAKER_03
Transcript:  Award-winning journalist.  What is the award and what is it for?

Speaker: SPEAKER_08
Transcript:  It's called the James W. Carey Award for Outstanding Journalism.  And it's from the Media Ecology Association.  Wow, that's pretty sweet.  Carey was a media theorist.  Yeah, fascinating guy.  I'm really glad to be winning this award because he's been a kind of  not a hero, but a guy I've looked to to sort of understand modern information.  And Jeff, I think is an admirer.

Speaker: SPEAKER_07
Transcript:  He's a hero of mine.  I've read his quotes on this show often.  He's the one who talks about how society is a conversation.  Media properly consented to conversation, our roles in conversation,  which is also McLuhan, who's the inspiration of the conference we're going to, Media Ecology.  He understood conversation and morality.

Speaker: SPEAKER_08
Transcript:  Carey talked about two sort of alternative views of information.  One that journalists often think about is it's media just transmits information.  Journalism tells people facts and they understand things.  End of story.  But the other way of looking at media is that it's about community.  And so people don't necessarily look to or share information because it's factually true or accurate.  It's because it makes them feel a certain way or because they want to belong to a certain group.  And I think you see that a lot on social networks, for example.  Oh, yeah.

Speaker: SPEAKER_03
Transcript:  So this conference is about the, it's called the Media Ecology Conference.  Is that the name of it?  What is it?

Speaker: SPEAKER_08
Transcript:  So Media Ethics is the, it's the Media Ecology Association.  And this conference is called Media Ethics, Human Ecology and a Connected World.

Speaker: SPEAKER_03
Transcript:  It's interesting because I'm just looking at Wikipedia's article on media ecology.  And in place of the word media, you could easily use the word internet in this context.  Media ecology, according to, I guess, Neil Postman,  looks into the matter of how media of communication affect human perception,  understanding, feeling and value and how our interaction with media facilitates  or impedes our chances of survival.  Boy, that couldn't be a hotter topic right now.

Speaker: SPEAKER_07
Transcript:  Amen, brother.  So I saw the conference, I saw Matthew was speaking at the conference.  I didn't know about the word yet.  And I asked him to introduce me to the organizer so I could,  I already bought the ticket immediately.  I'm geeking out.  It's a great conference.

Speaker: SPEAKER_03
Transcript:  Yeah, Postman, I guess, is the one who first coined that term,  but it was based on McLuhan's work.  So I asked a shameful question before the show.  Because Marshall McLuhan, when I was in high school,  that was the medium is the message.  In fact, there was a little book that all us high school kids read called  the medium is the massage.  I don't know what that meant, but I never did ever figure out what that meant.  But it was about media.  I guess it was about this, how the media is the context,  the Petri dish we're growing in and our culture grows in.  And it was very cool then in the 70s.  And I just was wondering if it was still au courant today, if people,  if it was considered, as Matthew said, people think a lot.  I think about Alvin Toffler and Future Shock, which was also big.  In that time, and that hasn't aged all that well.  How is Marshall McLuhan's philosophy even more relevant?

Speaker: SPEAKER_08
Transcript:  Like, I think, you know, at the time, and even even well into the sort of 80s,  I would say he seemed so out there, like his views seem to be so  beyond what people were accustomed to thinking about.  But as the Internet and the digital age and disinformation and cyberspace and so on,  have become more and more part of our lives,  I think the way he thought about media and information and culture  is just becoming more and more relevant.  And I use this or I referred to this quote when we were talking about it before,  one that I think sums up the disinformation environment that we're living in right now.  He said the Third World War was going to be a guerrilla information war  with no division between military and civilian participation waged in cyberspace.

Speaker: SPEAKER_03
Transcript:  The Third World War will be an information war, a guerrilla information war.

Speaker: SPEAKER_08
Transcript:  No division between military and civilian participation.

Speaker: SPEAKER_06
Transcript:  Yeah.  Wait, guerrillas can't type.

Speaker: SPEAKER_03
Transcript:  But that's kind of what a guerrilla war implies is that  there aren't combatants and non-combatants, that everybody's a combatant.  Right.  Right.  And he said that in 1970.

Speaker: SPEAKER_08
Transcript:  The other thing he said.  Go ahead, Brad.  Yeah.  Wow.

Speaker: SPEAKER_03
Transcript:  But he didn't have any conception of cyberspace at the time.  I mean, that didn't.  He did, actually.  Did he?  He did.  He had a sense of the electric age.  The electric.  So for him, it was TV, much as for Neil Postman.  It was TV.  Yes.  Yeah.  Yes.

Speaker: SPEAKER_07
Transcript:  Okay.  He also talked about how this I've talked about the Gutenberg parenthesis on the show,  where how we cognate the world in an age of text that when things are in packages  and we think of the world in a linear fashion with a beginning and an end.  And the line he said, this sentence, this example becomes our organizing principle.  So he really looked, he wasn't necessarily a fan or a hater of what he wrote about,  but he tried to look at the impact it had on our lives and how it affected our worldview.  That's the ecology.

Speaker: SPEAKER_08
Transcript:  And if you think about the internet, my friend Hussain Dirakshin has written about how,  for him at least, the internet is becoming more and more like TV.  So a lot of the things that Postman and McLuhan said about TV or saw in the future  as TV grew have really come to pass, I think.

Speaker: SPEAKER_07
Transcript:  So I think that's going to be temporary.  I think it's an attempt at a reversion to form.  We'll see.  As I always say, I'm too old to know.  And back to your toffler point, Leo, the problem is what McLuhan didn't predict the  future. McLuhan understood transition.  I think futurist is the most ridiculous job title on earth.  And toffler tried to predict that future.  By the way, medium as a massage, McLuhan's son, who died about a year ago, a year and a half ago,  said that McLuhan loved puns, absolutely loved puns.  Son argued that it was a typo that came back from the printer,  that they had been a little too convenient.  But he also liked the idea that it was the mess age.

Speaker: SPEAKER_03
Transcript:  Right. It's the mess age.  The way it hyphenated.  Yeah. It's good because I never understood for a minute what that meant.  I didn't either.

Speaker: SPEAKER_07
Transcript:  It was like watching 2001 of Space Odyssey.  What does the obelisk mean?

Speaker: SPEAKER_03
Transcript:  Yeah. Well, that was the era that we grew up in.  It was the era we grew up in.  It was an era full of mysteries.  Because it was a youth culture and youth are basically clueless.  It's just perfect timing.  Well, what do you think is profound?

Speaker: SPEAKER_07
Transcript:  Say again?  Heavy man.  Plus, I want drugs.

Speaker: SPEAKER_03
Transcript:  We were all stoned. We didn't know. We thought it was cool.  Massage.  I like the thing about McLuhan.

Speaker: SPEAKER_08
Transcript:  McLuhan also talked about surveillance and how the sort of electric future would enable  universal womb to tomb surveillance.

Speaker: SPEAKER_03
Transcript:  It's a shame. How long ago did he pass away?  He would have been 108 today, I think.

Speaker: SPEAKER_07
Transcript:  Okay, Google.

Speaker: SPEAKER_03
Transcript:  When was Marshall McLuhan born?  Now we mention Google for the first time on the show.

Speaker: SPEAKER_07
Transcript:  He was born in 1980.

Speaker: SPEAKER_03
Transcript:  So he missed all of this.

Speaker: SPEAKER_05
Transcript:  Yeah.

Speaker: SPEAKER_08
Transcript:  Well, it's the early days of the internet.

Speaker: SPEAKER_07
Transcript:  Without trying to foresee it, he foresaw it.  So I'm going to bring up, as I often do on this show, one of my favorite...

Speaker: SPEAKER_03
Transcript:  We've got to get her on the show.  Zeynep Tufekci?  Tufekci.  Tufekci.  It's a Turkish name and of course we're inevitable.  She's great.

Speaker: SPEAKER_08
Transcript:  Yeah. Wonderful, Professor of Sociology.

Speaker: SPEAKER_03
Transcript:  Article this week on Wired.  The internet has made dupes and cynics of us all.  She has become the kind of Paul Revere of the internet era.  But what she's talking about here, I thought maybe is kind of timely.  Professor at University of North Carolina at Chapel Hill.  Is this notion of trust that if we have been in the past, in the United States,  a high trust society, low corruption, you could pretty much trust what people said.  But that in the internet era, we become increasingly a low trust society.  Fake reviews on Amazon, Russian bots on Twitter, conversational AIs posing as humans.  And of course, a political class that seems to be corrupt, endlessly corrupt.  Malware in your computers, ad click fraud, and on and on and on.  And she warns that this is a bad trend.  This trend to becoming a low trust society.  She says, the internet is increasingly a low trust society.  One where an assumption of pervasive fraud is simply built into the way many things function.  She says, people do adapt to low trust societies.  World of mouth recommendations from familiar sources become more important.  Doing business with family and local networks start taking precedence.  But also mafia like organizations spring up, imposing a kind of accountability to brutal  costs.  And ultimately, and this is maybe the most scary sentence in this article,  people in low trust societies may welcome an authoritarian ruler, someone who will impose  order and consequences from on high.  Sure, the tyrant is also corrupt and cruel, but the alternative is the tiring,  immiserating absence of everyday safety and security.  I love this line.  During the reign of Kublai Khan, it was said a maiden bearing a nugget of gold on her head  could wander safely throughout the realm.  The great Khan required absolute submission and even repression has some perks.  What do you think?  I'll let you start, Jeff, because I think latency is kind of killing your ability to  converse.  So why don't you start?

Speaker: SPEAKER_07
Transcript:  Sorry.  No, it's not your fault.  Well, I also just put another piece up in the rundown, the bottom of the rundown,  which is related, I think, which is Mike Godwin wrote a piece in Reason,  inspired by Neil Stephenson's new and very thick 800 page novel.  Which I have finished.  He's not through it yet.

Speaker: SPEAKER_03
Transcript:  Which I have finished.  Ah, you're ahead of Mike.  Yeah.

Speaker: SPEAKER_07
Transcript:  In which he argues that maybe the cure for disinformation is disinformation.  Maybe when we all distrust everything, maybe that's where we need to get to.  And-

Speaker: SPEAKER_03
Transcript:  Yeah, you could tell Mike hasn't finished the novel, by the way.  So what happens in the novel?  And I think I might have brought this up.  It's fascinating.  What happens in the novel is one character, one important character,  Maeve, is being slimed by trolls.  Never happens, right?  On the internet.  Completely her reputation is being trashed for no apparent reason.  It's almost a Gamergate situation.  And a geek comes up with a great idea.  He creates many, many bots to put out misinformation, misinformation,  information of all kinds about Maeve, flood the internet with it,  so that when you go on the net, you know anything you read about Maeve is bogus.  Because there's so much of it.  She's a leftist.  She's a rightist.  She's a feminist.  She hates women.  You put up enough contradictory, bogus information, none of it is trusted.  And so it drowns out the trolling.  Well, he hasn't finished the novel because the consequence of this is,  and I think I mentioned this, that any-  Is this a spoiler?  People haven't-  It's a spoiler, but it's not going to spoil the novel.  It's a great novel.  People who have enough money will hire editors on the internet,  human curators to try to give you decent information.  People who can't afford that, which is the vast majority,  will be fed such a volume of phony, fake news that the country splits into faction,  people who believe in vaccinations, people who don't.  Does that sound familiar?  Mm-hmm.  They were there already.  Yeah.  And that there's no crazy theory that doesn't have its adherence.  And as a result, it is very dangerous because as you travel through the country,  you go into the different zone.  There's a zone where people don't believe in Christ's crucifixion.  They think that that was a fiction that was promulgated by somebody who didn't want anybody,  for whatever reason.  They had some crazy, cracked reason.  So they go around crucifying people to prove it's not real.  It's just weird.  Neil Stevenson is a great thinker about the future.  I think sometimes not a great writer.  Some of his, he wrote some of my favorite novels,  but he also has some difficulty finishing them.  I'm sad to say the fall does not end in a very coherent way.  However, it's a fascinating novel full of great ideas,  but that is a very interesting idea.  Is it worth reading or no?  Is it worth reading or no?  888 pages.  I know.  Did you listen?  I listened and read.  I have a new method, which really works well,  is to buy the Kindle version and the audiobook version and go back and forth.  So I could really, and I was trying to remember we talked about that New York Times article  by a novelist saying people should stop binging TV and start binging novels.  I wanted to give that a chance.  He said, you know, if there were novels written to be binged,  to be immersed, immersive in your, in this world.  So immerse yourself.  Don't read eight pages at a time, which is what I do.  Like most people.  I feel like Neil also.  Go ahead, Matt, and then Stacey.

Speaker: SPEAKER_08
Transcript:  I love his books, but I would agree that I'm concerned if the book is that length.  Lots of times he spends pages and pages describing,  you know, the rotation of the earth or the way that certain,  and it's fascinating, but I often wonder whether, you know, maybe just a paragraph or two about  that would be better.

Speaker: SPEAKER_03
Transcript:  Yeah.  Well, you will.  Okay.  Here's the best part about this novel.  It's still shorter than Infinite Chest.  Yeah.  No, it is.  And I still haven't finished Infinite Chest.  I have tried and tried and tried.  I did.  You're better man than I.  It was like Everest.  Yeah.  It was like Everest.  The funny thing about this novel was it will make you question reality.  So that's a, you know, that's interesting.

Speaker: SPEAKER_08
Transcript:  It sounds like reality.  It basically sounds like it's just describing what's happening right now.

Speaker: SPEAKER_03
Transcript:  I mean, you know, it is worth reading.  It is well worth reading.  It's hard to say whether it's a great novel or just well worth reading,  but it's well worth reading.  Go ahead, Stacey.

Speaker: SPEAKER_06
Transcript:  I have no idea now what I was going to say.  So it wasn't that important.

Speaker: SPEAKER_03
Transcript:  I'm sorry.  My fault.  The thing, and people have been talking about this with Stevenson,  and he's even been giving interviews about this,  is this novel is clearly written as a commentary on modern society  and what the internet and fake news and trolling and all of this has done.  But the central theme of the novel is, you know how they say,  they always said they cut off Walt Disney's head and froze it  so that in a future culture, he, that would figure out how to revive the brain,  they could revive the brain.  Well, in this near future, they realized that's a terrible kind of mechanical way  of doing it.  All we really need to do is scan the brain to create the connectome of all of the  interconnections between all the neurons,  and then we can easily simulate the brain's activity  in some future computer that has the capacity.  It turns out to be quantum computers, but some future computers  that have the capacity to recreate life.

Speaker: SPEAKER_07
Transcript:  Which is the plot of coercion, isn't it?  I haven't read it yet.  I haven't read that either.  It's another new novel that's out.

Speaker: SPEAKER_03
Transcript:  At least half the book is the upshot of that.  It goes into the distant future as some of many.

Speaker: SPEAKER_07
Transcript:  In coercion, having to do with reviews, people have false memories.  They believe they have a child they don't have,  and when the child they don't have dies, they can't handle it.  So even in their own life.  So we're grappling with this question of...  Fake? Yes.

Speaker: SPEAKER_03
Transcript:  What is reality?  What are facts?  The big change of the internet was that it made facts inexpensive,  which was a big shift in the way of what we think of as knowledge.  Facts were universal, but then what happened is  facts got so devalued that you got alternate facts,  and they were indistinguishable from factual facts.

Speaker: SPEAKER_08
Transcript:  And I think that to go back to what Zeynep was saying, the idea of trust,  this is something I've talked with a bunch of people about  as trust relates to journalism, lots of projects and resources and experiments  and companies are devoted to trust and increasing trust  and journalistic outlets want to build trust, and all of which is great.  And I'm not saying those things aren't valuable,  but the concept of trust as it applies to journalism  is a very, very squishy concept and very difficult to grapple with.  Lots of people trust Breitbart, lots of people trust their crazy uncle  who believes all these incredible conspiracy theories.  It just means I trust this person or this news outlet to give me what I expect.

Speaker: SPEAKER_06
Transcript:  Right. That's why it's so dangerous to have word of mouth become everyone's de facto standard.  And yeah.

Speaker: SPEAKER_08
Transcript:  Yeah. And this is the, again, what Jeff was saying about moving back towards a more oral culture.  Twitter in a lot of ways is a lot more like speaking than it is like writing or publishing,  where it's in a weird place in between those two things.  But to the extent that it's a lot more the way oral cultures used to be,  it can actually exaggerate problems in a way that text did not.

Speaker: SPEAKER_07
Transcript:  In the early days of text, text was not trusted because text was full of mistakes.  Anybody could make text and all you trusted was the people you trusted telling you what was going on.  So we've been here before.

Speaker: SPEAKER_09
Transcript:  We've been here before.  Oh yeah. We've been here.  Yeah. We've definitely been here before.  Yes.  Yeah.

Speaker: SPEAKER_04
Transcript:  I love you, Stacey.

Speaker: SPEAKER_09
Transcript:  No. I was like, no.  I love you, Stacey.

Speaker: SPEAKER_06
Transcript:  No. We're going to talk about tech in a minute.

Speaker: SPEAKER_03
Transcript:  Not going to go there.  Well, yeah, but this is in a global way kind of what has tech wrought.  And I think it's important to talk about the outcomes as much as this.  And this is very related.

Speaker: SPEAKER_08
Transcript:  YouTube has a disinformation problem.  YouTube's recommendation algorithm has a disinformation problem.  That's a tech partially.

Speaker: SPEAKER_03
Transcript:  And boy, is YouTube in trouble now.  Right.  The FTC is active.  You know, in the end, it's not a tech problem.

Speaker: SPEAKER_07
Transcript:  It's a human problem.  No, it's a human problem.  People feed it, it doesn't impress them and exploit it.  Right.  Go ahead, Stacey.

Speaker: SPEAKER_06
Transcript:  Well, so we trust people.  We see people and we don't as people make the distinction between expertise.  Like, I trust you, Matthew, on media issues.  But if you tried to explain to me quantum computing,  I probably wouldn't trust you that much.  But for most people, we don't make those distinctions because, you know, like,  I like you, Matthew.  Of course, you're going to not lead me wrong.  And I don't think you intentionally would.  But, you know, and I think we're stuck in this.  And then as so you've got that layer.  People are not very they don't appreciate the nuances of what they should trust from people.  And then the other thing is we have this abusive culture,  this capitalistic culture where you're like, you need to monetize your followers trust.  And you may end up doing that to their detriment.  And, you know, that's that's it.  You're not doing that, Matthew.  But, you know, that's kind of where we are in the influencer culture.  Right.  So I don't know how to get out from that.  And I don't know if.  And I think it was a problem, too, in writing.  It's just it costs more to write.  So you wouldn't want to have to.

Speaker: SPEAKER_03
Transcript:  That's a good point.  There's a lot more of it now.  Exactly.  But again, we can also hear voices who were not heard before.

Speaker: SPEAKER_07
Transcript:  Right.  So we've got to come back to the positives that we were in a controlled old white man world.  Right.  Right.  That the world was supposedly trusted was old white men saying, trust me.  And there were a lot of people who didn't and didn't have the opportunity to say so.  And now Stacey can say right here, I don't trust you.  All white guys.

Speaker: SPEAKER_03
Transcript:  But that's why this is but that's why this is so challenging,  because of course we wanted to get rid of that.  But at the same at the same time, a lot of the voices who are now empowered are not  good, trustworthy voices.

Speaker: SPEAKER_08
Transcript:  Right.  We'll figure it out.  And it's we'll figure it out.  OK.  You know, be be careful what you wish for.  I mean, if I know in the early days, and I'm sure Jeff was the same and Leo, you probably were, too.  We were early days of Twitter, early days of Internet, early days of blogging.  This is great.  The democratization of information.  That's super fantastic.  It's going to be awesome.  Everybody's going to be able to speak and exchange information.  And that is all true.  But we've seen many, many downsides to that.

Speaker: SPEAKER_03
Transcript:  So Stacey, I think you and I agree, maybe not, but I think you and I agree that the  best solution to this is a literate and educated public.  Right.  That you can't.  Yes.  The tech the tech community can't be expected to fix this fix this unilaterally.  The best thing would be for York.  I mean, you're right in the middle of it.  You have a seven year old or eight year old and you're dealing with this right now.

Speaker: SPEAKER_06
Transcript:  I have a 12 year old.  12 year old.  Yes, she is.  But I am teaching her to be more literate.  I will say, though, that there are very insidious things that the tech companies do for engagement  purposes that make it hard.  It's not just dark patterns.  It's also I mean, as educated as I might make my daughter, she's still  12, right?  And up until she's probably 20 something, she's going to have some certain thought  patterns that are, you know, just the same as young people everywhere.  She's going to tend towards.  Yeah, she's going to tend towards extreme.  She's going to see the world much more in black and white.  And these aren't bad things.  These are good things in some cases.  But it also means that people can take advantage of that.  And it's very easy to harness a lot of take advantage of that.  And then direct that through the Internet for good or ill.  I mean, that's that's kind of why Obama's campaign way back in 2008 was so successful  because it harnessed some of that youthful idealism and directed it towards action.

Speaker: SPEAKER_08
Transcript:  Did you read that article about the written by the mother whose team became radicalized?  Yes.  YouTube wasn't that?  Yes, that was hard.  It had a happy ending.  But yeah, horrible.

Speaker: SPEAKER_07
Transcript:  So Google has a deal was said earlier.  Sorry. Go ahead.

Speaker: SPEAKER_03
Transcript:  Go ahead, Jeff.  No.

Speaker: SPEAKER_07
Transcript:  If we go back to our youth, us two old white guys here,  Matthew, you're an idiot.  So we were going to run to you.  I was like, there are three of you.  I'm pretty young.  I'm leaving him off.  But I mentioned the novel revolutionaries, which I finished recently too.  And it goes through the downfall of the 60s.  I took the kind of to go to the 60s.  Then the worst of 60s, then 60s becoming a parody of itself.  And yeah, when we were young, we were that mob.  And we had a good cause trying to get out of the Vietnam War and equal rights, civil rights.  But yeah, Stacey, we were like that too.

Speaker: SPEAKER_06
Transcript:  Yeah. I mean, it's not about the way your brain works at that age and the lack of experience.

Speaker: SPEAKER_03
Transcript:  So Google has a digital safety and citizenship curriculum.  They call it B, Internet Awesome.  I'm not sure what age this is aimed at, but I would guess middle school.

Speaker: SPEAKER_07
Transcript:  85. I think about 95 is what it should be.

Speaker: SPEAKER_03
Transcript:  Smart, alert, strong, kind, brave.  This is the newest part.  This just came out this month.  This is a collaboration between Google, the Net Safety Collaborative,  and the Internet Keep Safe Coalition.  So the idea here is digital citizenship and safety.  The Internet Code of Awesome.  This is according to Google.  I'll read it to you.  This is aimed at middle schoolers.  Share with care.  Be Internet smart.  Don't fall for fake.  Be Internet alert.  Secure your secrets.  Be Internet strong.  It's cool to be kind.  Be Internet kind.  When in doubt, talk it out.  Be Internet brave.  Be Internet brave.  Those seem like good precepts, especially for younger kids, kids your daughter's age.

Speaker: SPEAKER_07
Transcript:  Stacey, what do you think your daughter's view of that would be?

Speaker: SPEAKER_06
Transcript:  She does a lot of this already.  They've had training on this.  I will say it's a little vague, maybe?

Speaker: SPEAKER_03
Transcript:  Well, no, no, that's just the...  So that's the table of contents.  Okay, I was like...  There are in each of these, there are many activities.  There's a lot.  There's a lot.  But let's go to the new one, which is don't fall for fake because this is...

Speaker: SPEAKER_08
Transcript:  I think that could actually be valuable.  The rest of it, I think, is pretty...

Speaker: SPEAKER_03
Transcript:  Remember, well, I'm all for it and I'll tell you why.  I think that parents and educators don't have a guideline for this.  And so, okay, maybe it's not perfect, but this gives them...  I don't disagree with anything that's in here.  It gives them a good starting point for this conversation with kids.  The new part here, we'll go right to it, which is don't fall for fake.  And this is designed to teach media literacy with kids.  Let me see if I can...  Let's share with care.  This is all available online for educators.

Speaker: SPEAKER_06
Transcript:  And I can tell you what she's already been doing.  Her teachers have done, at least for the...  Since she was in fourth or even maybe third grade, she's been doing digital literacy online.  So they even had me come as a journalist and talk to them about how I find...  Oh, good.

Speaker: SPEAKER_03
Transcript:  Is that a public school or private school?

Speaker: SPEAKER_06
Transcript:  That was a private school.

Speaker: SPEAKER_03
Transcript:  I wonder what kind of education they were getting in the public schools in Austin.  I don't know.

Speaker: SPEAKER_06
Transcript:  Well, it's Texas, so...

Speaker: SPEAKER_03
Transcript:  All right.  Let's see if you can do the lesson two.  Be internet alert.  Don't fall for fake.  Staying away from phishing and scams.  That's kind of an interesting...  The themes, it's important for kids to understand the content they find online.  Is it necessarily true or reliable?  And could involve malicious efforts to steal their information or identity.  I don't know if that's the focus I'd want to take on this, but...

Speaker: SPEAKER_08
Transcript:  Did you, speaking of phishing, did you see that horrible story from Alaska?  A teen killed her friend because someone online told her they'd pay her millions of dollars.  So this is what you want to avoid, right?

Speaker: SPEAKER_03
Transcript:  So there's cat phishing, there's click bait, there's spear phishing and phishing.  They define all these terms.  Should we look through and see if we would pass this test?  These are...  It has activities.  Is it...  You know, things to ask.  Is it asking for your personal information?  Is the email offering you something for free?  I think a lot of online games that my daughter plays, they actually do a lot of this training there.

Speaker: SPEAKER_06
Transcript:  There are apps designed to do that, aren't there?  Well, no, no, no.  It's just as part of like she plays.

Speaker: SPEAKER_03
Transcript:  I know I've talked to you about Star Stables, good Lord.

Speaker: SPEAKER_06
Transcript:  But she still plays that.  But she learned a lot of her chat room etiquette.  Both I think in school and maybe a little bit for me.  And then a ton from both the kids on the forum and then the forum rules itself.  That's great.  Wow.  And peer education at that age is the most valuable education, isn't it?

Speaker: SPEAKER_09
Transcript:  I mean, your peers are who teach you.

Speaker: SPEAKER_03
Transcript:  Yeah.  And I wonder if there's value.  Like when I was in high school, I did a thing called PALS and it was peer assisted leadership,

Speaker: SPEAKER_06
Transcript:  I think is what it stood for.  And we went to the forum and we talked about it.  And peer assisted leadership, I think, is what it stood for.  And we went to elementary and middle schools and buddied up with a kid and we'd hang out  with them for that period once a week.  And I wonder if having that, like creating some sort of digital PAL program where high  schoolers, you know, just hang out and spend a computer period with younger kids and try  to explain the world.  Parents are just so afraid of telling their kids the world is an awful, scary, bad place.  They want to do Santa Claus and the Tooth Fairy.

Speaker: SPEAKER_03
Transcript:  And lots of them aren't that savvy either.  Yeah, that's why I think curricula like this is great because you don't have to be savvy  to go through this.  I mean, in fact, parents could do this with their kids.  They give you fake and real phishing scams.  You know, is this real?  Who are you?  Is it okay to steal profile photos?

Speaker: SPEAKER_08
Transcript:  Before you get to the sort of teens, because I know when I was a teen, this stuff would  have been ridiculed and, and scorned.  And so if you get them earlier than that, everything from an adult is both for teens.

Speaker: SPEAKER_03
Transcript:  Yeah.

Speaker: SPEAKER_06
Transcript:  I think if you gave this to a teenager right now, they'd laugh at you.  They know all this stuff.  Like my daughter knew this at the age of 10.  Yeah.  She, I mean, I think the most important thing.

Speaker: SPEAKER_07
Transcript:  Grandpa doesn't.

Speaker: SPEAKER_03
Transcript:  Yeah, honestly, you're right.  That's what you're, that's what you were saying is this is really for old parts.

Speaker: SPEAKER_07
Transcript:  The kids aren't messing up the world.  Yeah.  There was a study I mentioned on the show before that was done out of Princeton and NYU  that the 90 odd percent of a corpus of fake news that they got was being shared by people  who looked like the three of us except you, Stacey.

Speaker: SPEAKER_03
Transcript:  Well, how about this one?  Here's a story by a guy named Robert Heaton.  He's a software engineer.  And he says, I was seven words away from being spear fished.  He got, he got what can seem to be a real email from the university of Cambridge  asking him to judge the Adam Smith prize for economics.

Speaker: SPEAKER_07
Transcript:  Even though you sure your reward is real.

Speaker: SPEAKER_08
Transcript:  Matthew, are you positive?  I should maybe look into it.

Speaker: SPEAKER_03
Transcript:  I should point out that Robert is not an economist.  He's a software developer.  He says, I've read capital in the 21st century, but  so, but he didn't, he wasn't suspicious.  Well, he was suspicious enough to do all the things we would say do.  For instance, he looked at the link in the email, which was to Cambridge university.  And in fact, a personal account, he, he did was the address.  He said, it did strike me a little odd.  The page was hosted inside a personal directory, but it was on the Cambridge website.  He visited the route to make sure it really was the domain.  He, he Googled the fella.  He couldn't find much, but he said, not everybody has a Twitter profile.  He noticed some grammatical or typos errors, but he did reply.  He said, thank you.  I'm certainly interested, but tell me more.  What would it involve and who recommended me?  They went back and forth.  He actually visited the page.  He realized though, he realized that he was just lucky because the page he visited,  had he visited it with Firefox, would have stolen his passwords.  It's an attack we talked about yesterday on security.  Now there was a zero day in Firefox.  And he fortunately visited on Google Chrome.  The seven words he said, if, if the page had just said,  you know, must be viewed in Firefox, he might've launched Firefox.  He had it.  And he would have crypto.  Yeah.

Speaker: SPEAKER_08
Transcript:  They got coin.

Speaker: SPEAKER_03
Transcript:  Yeah.  So what happened is they used it to attack Coinbase employees.  And because if you store, and this is just a great tip for everybody,  don't use your browser to store passwords.  Use a password manager.  In this case, Firefox, which is normally a very secure browser,  had a flaw that allowed an attacker to, on a webpage without your knowledge,  to steal your passwords, your Firefox passwords.  It was used against Coinbase.  In fact, a lot of crypto was stolen from Coinbase, I believe.  And so that's what he was, he got bit by.  And he said, you know, in every respect, this looked kind of real,  except it wasn't.  And so that just points out, this is hard stuff.  Yeah.

Speaker: SPEAKER_07
Transcript:  So what did he pull back?  What made him finally pull back and say, somebody, what was the last straw?

Speaker: SPEAKER_03
Transcript:  He did.  He just didn't, he didn't pull back.  The point is he did the research.  Had he done it in Firefox, he would have been hacked.  He was lucky.  He used Chrome.  The next one might be Chrome.  So the point is, is merely that he was lucky  and had the attackers just gone one step forward for farther and said,  you know, use Firefox to view this.  He, he, but I thought, oh, those guys can't figure out how to make it work in Chrome.  Okay.

Speaker: SPEAKER_08
Transcript:  And I think, and I think we've talked about this before, a lot of the most sex successful  sort of phishing and, and even hacking is, is,  is just relationship management or, you know, it's, it's, it's getting people like,  convincing people to give you things, not necessarily zero day exploits.  It's all social engineering, right?  Exactly.  Social engineering.  And I know at least I've got half a dozen friends whose parents, elderly parents have  been this close to sending money to somebody or, you know, because they believe the story.  Yeah.  You know, because they believe the story that somebody told them.

Speaker: SPEAKER_03
Transcript:  But this is how easy it is.  And this is a sophisticated guy.  He's a software engineer and I'm glad he wrote that.

Speaker: SPEAKER_07
Transcript:  It's really a generous act for it.  Yes, it is.  It's not easy on your own to admit that you're right.  Yeah.  But that's really important.

Speaker: SPEAKER_03
Transcript:  And the reason this worked is because he was, he was flattered that they would ask him to  judge the Adam Smith prize for economics, even though he's not an economist.

Speaker: SPEAKER_06
Transcript:  I'm just sitting here thinking like, I would totally never even fall for that.  I'd be like, what a no, this is not real because my ego would be like,  This has been around.  I'm not an economist.

Speaker: SPEAKER_03
Transcript:  This has been around for decades because I know, Jeff, you've received this snail mail  and I have too, inviting you to be in Who's Who.

Speaker: SPEAKER_06
Transcript:  Yeah.  Oh yeah.  The Who's Who piece.

Speaker: SPEAKER_04
Transcript:  You have to pay.

Speaker: SPEAKER_03
Transcript:  You end up, you have to buy it.  Well, certainly you would want a copy of Who's Who with your name in it.  I think back because I remember my dad was included in Who's Who.  And I'm thinking maybe that was the same scam.

Speaker: SPEAKER_06
Transcript:  I mean, they were doing it when I was in high school.

Speaker: SPEAKER_07
Transcript:  If you care, Zuck is on stage, I think now at the Aspen Institute.  Should be.  Can we pull it up?  I don't know.  I just saw so.

Speaker: SPEAKER_03
Transcript:  What is he talking about?

Speaker: SPEAKER_07
Transcript:  It just seems to be a surprise appearance.  Cass Sundstein is interviewing him.  People complain that it's not a journalist.  I missed your line, Andrew.

Speaker: SPEAKER_08
Transcript:  I said he announced he was stepping down.

Speaker: SPEAKER_03
Transcript:  From the stage.  Yeah, it doesn't look like they stream that.  I guess you have to pay some money.  Oh, okay.

Speaker: SPEAKER_08
Transcript:  It's a pretty expensive conference.

Speaker: SPEAKER_03
Transcript:  It's the Aspen Institute.  So we'll read about that in TechCrunch tomorrow.  All right, let's take, oh, we don't need to take a break.

Speaker: SPEAKER_07
Transcript:  It is streamed, if you care.  Oh, it is.  It's on YouTube.

Speaker: SPEAKER_00
Transcript:  I don't think that the controversial part of this is choice.  I think that the harder part to define is your information.  Take it in the context of a social system.  One of the things that Facebook does is it shows you your friend's birthdays.  So it can remind you of your friend's birthdays.  Okay.  We try to enable a developer ecosystem so that way people can  bring their information out to other developers.  I don't think anyone, I would be very surprised if anyone in this room  disagreed with the notion that you should be able to take your information  from a service to another service.  Right?  I mean, that's non-controversial.  The question is, all right, I have my friends on Facebook.  You're my friend.  You share with me your birthday.  Facebook reminds me of that.  Am I allowed to take that birthday and put it in my calendar app?  And should Facebook enable doing that so that now my other calendar that I use  It's just helping people do what they want.  Is your birthday my information or yours?  Who gets to decide that?  If I want to export my friend's birthdays to a calendar,  do I need to ask every single one of them for their permission?  Because if I do, then that app probably isn't going to get built  because that's a lot of friction.  Or let's talk about another example.  Newsfeed.  One of the things that people have talked about for a while is,  hey, wouldn't it be nice if I could bring my newsfeed,  what would I, the content that I see for my friends to another app,  either so that there could be competing news feeds, right?  So another company could innovate on top of that,  or academics could do research on top of that.  A lot of people want to be able to have people come in for studies and say,  all right, can I see what's in your feed?  And can I pull that data and then do a study on the content that's there,  including for reasons like the election issues.  There are a lot of academics who want to study this stuff.  Same issue.  The content that you see in your feed,  it's photos and links that your friends have shared.  Is that your information or theirs?  And if it's theirs, then, and you give them a choice  over whether you're allowed to pull it out.  And let's say, we're overwhelmingly successful and say that 90% of people  hopped in and say, I'm willing to let my friends share that information.  Then, are the studies that are done on that going to be valid?  Are you really going to be able to build a competitive newsfeed  if 10% of your friend's most interesting information is not there  and the only way to get the full experience is through Facebook?  These are really hard questions, I think.  I actually come out more on the side of where you are,  that this should be left to individual choice.  But I don't want to leave the impression that these are obvious choices  that don't have competing equities that we all value greatly.  If your paramount concern is around innovation and competition  and research and data portability,  then it's not clear that you want to give every individual the right to say,  I don't want my information to be able to be taken to another service.  I think that this is very connected to the set of privacy debates  and things that we're having as well.  There's no question in my mind that people need to have the right  to be able to say who has access to their information.  But I do think that as a society, there is,  we need to decide where we want to be on the spectrum between  asking companies to fully lock down people's information  and on the other hand, making it portable.  Because right now...  I think he's making a reasonable point.

Speaker: SPEAKER_03
Transcript:  I hate to say it.  He is, but he also doesn't let academics access the newsfeed.

Speaker: SPEAKER_06
Transcript:  One of his examples is something that he doesn't actually let...  It doesn't happen.

Speaker: SPEAKER_07
Transcript:  Well, they started SSRC, but they're gun-shy  because of Cambridge.  Well, a lot of people would point out...

Speaker: SPEAKER_03
Transcript:  They were gun-shy way prior to...

Speaker: SPEAKER_06
Transcript:  They came down very hard on people in 2015.

Speaker: SPEAKER_03
Transcript:  Nobody really is disputing that Facebook guards the information  it has about you carefully.  That's frankly a value to them.  It's a financial value.  That's not the problem.  It's what they do with the information they have about you.  Not what I do with my birthdays or the newsfeed  It's what they do with the information that's problematic.

Speaker: SPEAKER_08
Transcript:  And it's in his interest to take the most innocuous example.  Yes.  Right.  And get you...  Of course.  Because of course you would agree.

Speaker: SPEAKER_03
Transcript:  And by the way, it's also in his interest,  and this is something everybody does now,  to say, oh no, we protect your data carefully.  We'd work really hard to protect your data.  They do because they don't want...

Speaker: SPEAKER_04
Transcript:  They want it.

Speaker: SPEAKER_03
Transcript:  A competitor to get it.  They do protect it.  Nobody's disputing that whatever Facebook knows about you,  it keeps to itself.

Speaker: SPEAKER_08
Transcript:  Well, and it reminds me of those congressional hearings  when everybody focused on, why do you sell data?  You shouldn't be allowed to sell data.  And that was an easy argument to refute  because they don't sell data.  So Al Mark had to say, we don't sell data, which is true.  We give it away.  And then people give us money in exchange for what they can do with it.

Speaker: SPEAKER_03
Transcript:  But they don't...  I mean, if you go to Facebook and say,  I want to know how Leo Laporte is,  you can't, as an advertiser, you can't get that information.  You can say, I want everybody between 45 and 55.  I want a real white man.  You can do it.  Yeah.  Well, I can't do it anymore.  Because they don't want it.  Yeah, they don't.  But they wouldn't want to give my information to some other person  because somebody could then compile a database and sell against them.  They keep...  All these companies keep this private to themselves  unless they can sell the data in aggregate.  And usually that's for advertising purposes.  So...

Speaker: SPEAKER_07
Transcript:  Stacey, you're quite right about the research.  It's been a huge frustration for researchers.  They love this information.  Who want to be able to find out the impact.  And Alex Stamos is really articulate about this.  He's saying, okay, well, here's where there's a stock.

Speaker: SPEAKER_03
Transcript:  Sorry, now my computer's making too much noise.  Go ahead, I've muted it.  I'm done.  Stacey, did you want to respond?  Or he's just saying you're right.  Wait, what?  Yeah.

Speaker: SPEAKER_06
Transcript:  I'm sorry.  You're right.  I couldn't hear.  Just say thank you.

Speaker: SPEAKER_08
Transcript:  I was saying you're right.

Speaker: SPEAKER_07
Transcript:  Thank you.  I said you were right.  Oh no, Jeff.

Speaker: SPEAKER_06
Transcript:  This is terrible.  This can't go on.  This whole show is predicated on us disagreeing.  Come on, man.  No.  No.  Oh, but it's more fun.  No.  And I'm feeling feisty today.  I think you're wrong about that.  No, you're wrong, Stacey.  Are you ready to engage Stacey?

Speaker: SPEAKER_03
Transcript:  Are you going to...

Speaker: SPEAKER_07
Transcript:  Stacey just said Stacey just disagreed that it's good to agree.  So there we are.  Who's right?

Speaker: SPEAKER_06
Transcript:  I'm just having fun now.

Speaker: SPEAKER_07
Transcript:  That's what Stacey called fun.  See, we got it.  Yeah, Stacey, I got it.  Yeah.

Speaker: SPEAKER_03
Transcript:  A new bipartisan bill, Mark Warner from Virginia and Josh Hawley,  our favorite Republican from Missouri.  Great law.  The Dashboard Act.

Speaker: SPEAKER_07
Transcript:  Stupidest idea for legislation ever made.

Speaker: SPEAKER_03
Transcript:  By the way, an acronym, maybe a retronym,  Designing Accounting Safeguards to Help Broader Oversight in Regulations on Data Dashboard.  The idea is consumers should know what their information is worth  to Google, to Facebook, to Amazon.

Speaker: SPEAKER_08
Transcript:  Sounds great, doesn't it?  Yeah.  What could be wrong with that?

Speaker: SPEAKER_09
Transcript:  Stupid as hell.  Wait, what about...  What could go wrong?

Speaker: SPEAKER_06
Transcript:  What about...  You know how we talked last week about ambient privacy?

Speaker: SPEAKER_09
Transcript:  Yeah.

Speaker: SPEAKER_06
Transcript:  I think sometimes you can't sell your information without outing other people, right?  There's a lot here.  You shouldn't be allowed to sign away your data rights or your privacy rights for money  because that puts the onus on people who don't have money.

Speaker: SPEAKER_03
Transcript:  So they're not saying here we're going to give you money for it.  They're saying under this act, companies are required...  I think this sounds like GDPR to disclose what kind of data they collect,  the value of that data.  Okay, we could say...  That's the funny thing.  That's silly.  And how the data is used.  So we'll just take that value part out.

Speaker: SPEAKER_07
Transcript:  Find our points one and three.  Point two is what's got the headlines though.  Point two is the stupid part.

Speaker: SPEAKER_08
Transcript:  Yeah, we'll take that.  I mean, transparency is good.  Transparency, although...

Speaker: SPEAKER_03
Transcript:  They would have to file an annual report disclosing the harvested user's data aggregate value along  with any third party contracts regarding such information.  Again, this is all a red herring, which by the way...

Speaker: SPEAKER_07
Transcript:  So Leo, I think you have to reveal the value of every viewer.

Speaker: SPEAKER_03
Transcript:  Yeah, yeah.  Well, I could do a math calculation, say.  But you wouldn't want to do that.  No, I could gladly do that.  You're horrible at others.  No, in fact, I know what the value of every viewer is  because that's how we charge for advertising.

Speaker: SPEAKER_06
Transcript:  It's like you all are priceless.

Speaker: SPEAKER_03
Transcript:  We charge $90 per thousand listeners or viewers.  So that means you're each worth about a nickel or a dime.  I don't know.  Yeah, money, man.  So that value thing...  This is ridiculous.  Data is aggregate value, third party contracts regarding such information.  We already know that doesn't work.  But this is important.  Give users the ability to delete all or specific portions of their data.  This is like GDPR.  What data you collect, how the data is used...

Speaker: SPEAKER_07
Transcript:  Like what Zuckerberg just said, I tell you it's my birthday.  You say, congratulations, Jeff, it's Jeff's birthday.  You make a post out of that.  Do I have the freedom to make you take that down?  That's the kind of question you get into.

Speaker: SPEAKER_03
Transcript:  Well, and Facebook has intentionally intermingled all of this to make it hard.  In fact, when you delete your Facebook account...  It's reality.  When you delete your Facebook account, they even say,  well, we're going to delete everything you in your account,  but there may be pictures of you.  There may be stuff that people have saved that you've said,  we can't do anything with that.  And of course you can.  I wouldn't expect that.  I put it on the internet.

Speaker: SPEAKER_08
Transcript:  I guarantee if they implemented some of the deletion or some of the other  points that they mentioned in there, it would be buried 15 submenus deep  on a page that would be incomprehensible and no one would ever do it.

Speaker: SPEAKER_03
Transcript:  They also said that the additional transparency would encourage market competition  and allow antitrust enforcers to identify potentially anti-competitive practices.  That might be the reason for the dollar amount.  Maybe, I mean, we're not senators.  Maybe there's some technical...

Speaker: SPEAKER_07
Transcript:  No, the reason for the dollar amount is it got up headlines and it worked.

Speaker: SPEAKER_03
Transcript:  Yeah.

Speaker: SPEAKER_07
Transcript:  You guys can be cynical.  So can I.

Speaker: SPEAKER_06
Transcript:  Well, it may not just be for headlines.  It could also be like, hey, each person is really only 10 cents for us.  This isn't worth it.  You could make a lot of arguments about, look, this is not...  We measure most of our harms today in economics, right?  In dollars.  So if we can put a value on the data or a value on the harm it might cause,  then we can actually...  Our court systems can deal with it.

Speaker: SPEAKER_03
Transcript:  Facebook can make the same calculus I just did.  Based, if you divide their revenue by the number of users,  it's $6.42 per user worldwide.  $30 per user in the US.  Yeah, in the US and Canada, you're worth more.  30 bucks.  That's all...

Speaker: SPEAKER_07
Transcript:  With Google, you can't really do that because you've got other services.  And Amazon, you've got other services like AWS and things.  Yeah.

Speaker: SPEAKER_03
Transcript:  By the way, MarketWatch is glad to say, just a factoid,  2.5 quintillion bytes of data are created every day.  If you laid 2.5 quintillion pennies out flat, they would cover the earth five times.

Speaker: SPEAKER_07
Transcript:  That was useful.  Okay.  That's handy.

Speaker: SPEAKER_03
Transcript:  This is why Jeff teaches journalism students...  That data journalism...  This is not data journalism.

Speaker: SPEAKER_08
Transcript:  I'm disappointed they didn't use the international measuring system,  which is the football field.

Speaker: SPEAKER_09
Transcript:  I'm surprised they didn't tell us how many Library of Congress it would...

Speaker: SPEAKER_03
Transcript:  It cracks me up that they decided to illustrate the fact that 2.5 quintillion bytes of data are  created every day by saying, if those were pennies, they would cover the earth five times.

Speaker: SPEAKER_04
Transcript:  It just cracks me up.  They didn't even say what a quintillion was.

Speaker: SPEAKER_06
Transcript:  They probably didn't know.  Sometimes, I'll be honest, when I'm looking up some of these big data numbers,  I'm like, oh, God, how many zeros is that?

Speaker: SPEAKER_03
Transcript:  They must have known because that's a lot of calculations.  You've got to divide the total surface area of the globe.

Speaker: SPEAKER_06
Transcript:  That was in a press release somewhere and they just cut and pasted.

Speaker: SPEAKER_03
Transcript:  Would somebody please check that for us?  What is the area of a penny?  You'd have to do it in squares, even though a penny is round.  And what is the total surface square footage of the earth or square penny of the earth?

Speaker: SPEAKER_07
Transcript:  However, in Canada, you couldn't do that because I learned today, I paid for my latte,  $6.03 with three cents.  And the woman said, oh, you're using pennies.  We don't use pennies anymore.  Why did you explain this to me?

Speaker: SPEAKER_03
Transcript:  So the surface area of the earth is 5.49 times 10 to the 15th square feet.  So there we're going to help you a little bit.  Now, Google, what is the surface area of a penny?  I bet Wolfram Alfre could do this calculation.  Surface area of a penny.  Well, wait a minute, front and back?  No.  It is 0.442 square inches.

Speaker: SPEAKER_07
Transcript:  Was it surface area or depth?  Were they stacked or were they laid side to side?  They were laid side to side.

Speaker: SPEAKER_06
Transcript:  Michael, wait, well, some of them are stacked because it's five times over.

Speaker: SPEAKER_08
Transcript:  If it was going to the moon, you would stack them.

Speaker: SPEAKER_03
Transcript:  It is a quarter the area of a human retina.  It is 60% of a typical postage stamp.  So I'm sure if I do surface area of the penny, cover, how many?  Let's just ask it.  How many pennies would it take to cover the earth?  Wolfram Alfre is amazing on stuff like this.  Oh, there you go.  1.4 times 10 to the 18th.  So it's done.  That's it.  Wolfram Alfre.  How many is in a quintillion?  Is that the same number?

Speaker: SPEAKER_06
Transcript:  Yeah, so now we just have to define what a quintillion is.

Speaker: SPEAKER_07
Transcript:  What about going up and down mountains?  Do pennies float?  I think the number is actually wrong.

Speaker: SPEAKER_03
Transcript:  Yeah, I think their number is wrong.  Their number is wrong.  In fact, a quintillion, what is it?  Two and a half quintillion, four and a half?  It's 10 to the what?  Two and a half quintillion pennies would barely cover a quarter of the earth.  Okay, a quintillion is 10 to the 18th.

Speaker: SPEAKER_06
Transcript:  What was the original stat that we're trying to get to?  I forgot.

Speaker: SPEAKER_08
Transcript:  2.5 quintillions.

Speaker: SPEAKER_03
Transcript:  Okay, so a quintillion, so 2.5 quintillions.  No, it would cover the earth twice.  So you're wrong.  You're wrong, Mark and Watch.

Speaker: SPEAKER_08
Transcript:  Said five times.

Speaker: SPEAKER_03
Transcript:  They said five times.

Speaker: SPEAKER_08
Transcript:  Pretty sure they just made it up because who's going to change?

Speaker: SPEAKER_07
Transcript:  That's because they used all the extra Canadian pennies nobody's using anymore.

Speaker: SPEAKER_03
Transcript:  Well, that's a good point.  What kind of penny?  A British penny has a lot more surface area.

Speaker: SPEAKER_08
Transcript:  You know, it costs I think three cents to make a penny.  That's why they won't take it.

Speaker: SPEAKER_07
Transcript:  Matthew, so when my bill was 603 and she was so amazed I gave her exact change.  Did they round up to 605?

Speaker: SPEAKER_09
Transcript:  Yeah.

Speaker: SPEAKER_08
Transcript:  Usually, yeah.  Why did they?  Where did you get pennies?

Speaker: SPEAKER_06
Transcript:  You paid in dollars at a Canadian place?  I had a bag of change at home.

Speaker: SPEAKER_07
Transcript:  Canadian dollars.  I carry it with me and I had tons of change and I had a lot of pennies because you don't use them.  So I shocked her.  I gave her 603.  She said, oh, we don't do that.  Were they American pennies?

Speaker: SPEAKER_06
Transcript:  No, they were Canadian pennies.  They were vintage Canadian pennies.

Speaker: SPEAKER_03
Transcript:  I have Canadian pennies at home as well as a matter of fact.

Speaker: SPEAKER_06
Transcript:  Yeah.  So did she accept them?  Is it still legal tender?  Yes, she did.  She said, oh, it's okay.  I'm an American.

Speaker: SPEAKER_07
Transcript:  Okay, it's all right.  We have to take it.  Yeah, they're Canadian.

Speaker: SPEAKER_06
Transcript:  They're going to take it.

Speaker: SPEAKER_03
Transcript:  Stock up on loonies.  That's the best.  Loonies are the best.

Speaker: SPEAKER_07
Transcript:  I tried to give a guy a euro instead of a loonie today and he said,  I'll take the euro.  I'll be happy to but it's not the right one.  Canadians are so nice.  While we're in stupid legislators ideas, there's another one in the government section.  Tune, Tune.

Speaker: SPEAKER_08
Transcript:  Is it the section 202.31?  No, no.

Speaker: SPEAKER_09
Transcript:  That's another one.  That's just dangerous.

Speaker: SPEAKER_07
Transcript:  This one is that he wants Google to require to give you search without an algorithm.

Speaker: SPEAKER_08
Transcript:  Oh, right.  No algorithms.  Yeah.

Speaker: SPEAKER_06
Transcript:  What is that?  I'm going to have a trash fire?  It's like going to the dump and asking to see your mail.

Speaker: SPEAKER_07
Transcript:  I'm going to give you the entire screen, the entire internet.  Good luck.

Speaker: SPEAKER_03
Transcript:  I think Senator Thune does not know what an algorithm is.  I do not think that word means what you think it does.

Speaker: SPEAKER_07
Transcript:  Or Google.  He says, hey, so you want these guys to be running the internet?

Speaker: UNKNOWN
Transcript:  No.

Speaker: SPEAKER_03
Transcript:  Well, wait a minute though.  There is some reasonable.  So for instance, in the Facebook newsfeed, if they would just give me in chronological order  all the shares from the people I follow.  You can have that now.  But it turns it off.  And Twitter, you can have that now.  Yeah, but it turns it off.

Speaker: SPEAKER_08
Transcript:  Yeah, you can have it.  They turn it back.

Speaker: SPEAKER_07
Transcript:  I'm constantly fighting back.  It's a horrible experience, but fine.  You want the order?  Go ahead.  Go ahead.  Let's get off on this.

Speaker: SPEAKER_03
Transcript:  It's a better.  No, I always did that.  It's a much better experience than the algorithmic one.  So what he's saying is not unreasonable.  Although Facebook would say, oh no, we already give you that.  Google, I don't know how a Google search could be non-algorithmic.  What does that even mean?

Speaker: SPEAKER_08
Transcript:  It's it wouldn't work.  It means browsing.

Speaker: SPEAKER_07
Transcript:  It means you.

Speaker: SPEAKER_06
Transcript:  Maybe it would look like Yahoo or as you said, alphabetical or maybe it could be chronological.  Like this is the most true.  Yahoo is highly.

Speaker: SPEAKER_03
Transcript:  Oh, I love this.  Imagine if you do an internet search and it gives you the results in alphabetical order.

Speaker: SPEAKER_06
Transcript:  It'd be like the phone book.  Conspiracy theory 102.

Speaker: SPEAKER_04
Transcript:  Taxi company.

Speaker: SPEAKER_03
Transcript:  And then gaming it would be easy.  Just like they do the phone book.  That's why there's so many muffler shops named a muffler shop.

Speaker: SPEAKER_07
Transcript:  Were you and I on a Twitter discussion this week about great old website of the day stuff?

Speaker: SPEAKER_08
Transcript:  Yeah, I mentioned dog pile.  Do you remember that one?  Oh, yeah.

Speaker: SPEAKER_09
Transcript:  Yeah, yeah.

Speaker: SPEAKER_03
Transcript:  That was that was an a aggregator would aggregate the results from many different sites.

Speaker: SPEAKER_08
Transcript:  I also pointed out that this is another little humble brag.  I had a website called High Tech Investor if you can believe it because I worked for the  stock market section of the paper and it was literally just a list of places you could get  stock quotes because there were only about a dozen of them at the time.  And this was 1995.  So that was Worth magazine's website of the day in 1995.

Speaker: SPEAKER_05
Transcript:  Congratulations.

Speaker: SPEAKER_07
Transcript:  I had a few cool sites for the day.  Thank you.  Yuckiest site on the internet was a cool site of the day.

Speaker: SPEAKER_03
Transcript:  Wait a minute.  That was your site was the yuckiest site on the internet?  Were you doing porn?  Wait a minute.  Tell me this again.  You had a site called?

Speaker: SPEAKER_07
Transcript:  The yuckiest site on the internet.  It was in collaboration with Liberty Science Center.  It was about snot and cockroaches and how to make sites.  My very first site I made on the internet was called Rainer Shine because I hate TV  weathermen and I said just give me the damn five day forecast and nothing but.  So it was a site that gave you nothing but the five day forecast.  Oh, it's single.  We sold to AccuWeather and we sold yuckiest site to Discovery.

Speaker: SPEAKER_08
Transcript:  Because later on, one of my favorite sites was  Do I Need a Jacket?  I think it was called.  And that's all I told you.

Speaker: SPEAKER_03
Transcript:  By the way, I think you can now do that with Amazon's Echo.

Speaker: SPEAKER_07
Transcript:  It was just a gift that said yes.

Speaker: SPEAKER_06
Transcript:  Always.

Speaker: SPEAKER_03
Transcript:  Where are you?  Oh yeah, you need a jacket.  Always.  So that's so John Thune, somebody needs to explain to him that you could do that with Facebook,  but it's nonsense to say a Google search that has no algorithm is nonsense.  Would be useless, yeah.

Speaker: SPEAKER_08
Transcript:  And to pass a law.  And I would say this also plays into something else we've referred to, which is this tendency  on the right and in the Trump administration to argue that these sites are biased against them.

Speaker: SPEAKER_04
Transcript:  Oh, should we play?  Should we play their video?

Speaker: SPEAKER_07
Transcript:  Yes, play the video.  It's unbelievable.  And notice that Maria Bartiromo doesn't question his assertion at all.

Speaker: SPEAKER_03
Transcript:  Maria Bartiromo talked about finance.  I used to like her.  Oh, she went to the dark side.  She kind of did go over.  She's a TV host.  Yeah, that's part of the problem.  She's a TV host.  All right, so let me pause this.  This is the president on the phone with Fox Business with Maria Bartiromo.  Let me see.  Oh, I've muted him again.  I keep doing that.  Let me unmute.

Speaker: SPEAKER_07
Transcript:  I think that's against the law now, Leo.

Speaker: SPEAKER_03
Transcript:  I'm not allowed to mute the president.  All right.

Speaker: SPEAKER_02
Transcript:  And they're going to do this right up to the 2020 election.  Well, you got to go back to Twitter.

Speaker: SPEAKER_01
Transcript:  I mean, what they did.  I thought that was the beginning.

Speaker: SPEAKER_02
Transcript:  And they're going to do this right up to the 2020 election.

Speaker: SPEAKER_01
Transcript:  Well, they're doing it to me on Twitter.  I mean, what they did to me on Twitter is incredible.  I have millions and millions of followers.  Wait a minute.

Speaker: SPEAKER_03
Transcript:  What did they do to him on Twitter?  Keep going.  Nothing.

Speaker: SPEAKER_01
Transcript:  He's saying the algorithm is-  I will tell you, they make it very hard for people to join me on Twitter.  And they make it very much harder for me to get out the message.  They make it-  Really?  It's incredible.  How did they do that, Mr. President?  What are they going to do about it?

Speaker: SPEAKER_02
Transcript:  These companies have an enormous amount of power.

Speaker: SPEAKER_03
Transcript:  Oh, shut up, Maria.  Wait a minute.  He says all you have to do is go to twitter.com slash the real Donald J. Trump.  She didn't question it.  She just took it and ran with it.

Speaker: SPEAKER_07
Transcript:  Oh, they're being so mean to you, Mr. President.  Click follow.

Speaker: SPEAKER_02
Transcript:  If they could even stop the president of the free world in terms of getting his message out.  Wait a minute.

Speaker: SPEAKER_03
Transcript:  He's now the president of the free world?

Speaker: SPEAKER_06
Transcript:  That is what we call him as president a lot.

Speaker: SPEAKER_01
Transcript:  It's totally biased toward Democrats.  No, no.

Speaker: SPEAKER_03
Transcript:  We call him the leader of the free world.  The president implies that he's elected.  Leader is more a position of authority.  The president implies, hey, yeah, no, he got elected president of free world.  Weren't you watching?

Speaker: SPEAKER_01
Transcript:  I announced tomorrow that I'm going to become a nice liberal Democrat.  I would pick up five times more followers.  I was picking up a hundred thousand followers every few days.  And all of a sudden, and I'm much hotter now than I was a number of months ago.  Okay.  A number of months ago, then all of a sudden it stopped.  And now I pick up a lot, but I don't pick up nearly what I did.  If you're  That's why Devin Nunes is suing Twitter.  Devin Nunes is suing Twitter right now.

Speaker: SPEAKER_02
Transcript:  Who's suing Twitter?  Devin Nunes, Congressman Nunes.

Speaker: SPEAKER_01
Transcript:  That's great.  I think he's great.  There's a lot of ways he's great and he'll probably do well.  He's right about it.  Twitter is just terrible what they do.  This is so ironic.  I've had so many people come to me.

Speaker: SPEAKER_03
Transcript:  Twitter is his platform.  Twitter is his platform.  He owns Twitter.  He owns Twitter.  They have a special room with a shrine Donald J. Trump in it.

Speaker: SPEAKER_06
Transcript:  For him to say  He violates their terms of service all the time and they let him go.

Speaker: SPEAKER_03
Transcript:  That's hysterical.  Yeah.

Speaker: SPEAKER_04
Transcript:  It's the newsworthy exception.  So he's going to sue Twitter.  You know, Matthew, right?

Speaker: SPEAKER_03
Transcript:  He's going to sue Twitter, Facebook and Google.  Because they're totally biased towards Democrats.  By the way, it's not illegal to be biased towards Democrats.  Or we would be in trouble.

Speaker: SPEAKER_07
Transcript:  They say may soon be.

Speaker: SPEAKER_08
Transcript:  He means biased in favor of Democrats.

Speaker: SPEAKER_03
Transcript:  Yeah, no, but I'm saying it's not illegal for a private company to have a bias.

Speaker: SPEAKER_08
Transcript:  Well, maybe soon it will be.  Okay.  I mean, that's where the Section 230 stuff comes in.  Right.  There's a bunch of people in the government who are arguing  that platforms should be neutral, that their algorithms should not favor one thing or another,  or that they shouldn't remove certain types of content.  And their argument is-

Speaker: SPEAKER_06
Transcript:  That's the point of an algorithm.

Speaker: SPEAKER_07
Transcript:  If they are not so-called neutral, they will lose Section 230 protection.  I'm telling you.  That was last week's stupid law.

Speaker: SPEAKER_03
Transcript:  I know Larry Page is up in his special mountain lair thinking,  we'll just make it all alphabetical.  Then you'll see.  Then you'll see.  Enjoy the internet, morons.  He's made enough money.  He doesn't, you know.

Speaker: SPEAKER_07
Transcript:  I think there's a Roadrunner cartoon in this of ACME winning, finally.

Speaker: SPEAKER_03
Transcript:  Wow.  That's just amazing.  Google, by the way, has told its employees not to protest Google at the Pride Parade.  That's disturbing.  Do not.  So it was actually a debate about whether the Pride Parade should allow Googlers.  And then because of harassment of LGBTQ plus community members.

Speaker: SPEAKER_06
Transcript:  Oh, is that a thing that's been happening?  I'm so sorry.  I have not paid attention to that.  I don't know.

Speaker: SPEAKER_03
Transcript:  And then, according to some, yes.  Yes.  Yeah.

Speaker: SPEAKER_07
Transcript:  I also saw somebody I trust on Twitter.  They were saying that now you've got far right within Google doing things.  You had Veritas went after, was it Google or Facebook executives?  So it's become the technology companies have become red hot.  Well, they're terrified.

Speaker: SPEAKER_03
Transcript:  I can't say anything in any direction because somebody will be mad about it.  So anyway, now the Pride Parade will feature Googlers,  but they won't be protesting against Google.  Because it's Google said, and this is probably the case for every company,  you have non-disparagement clause and you can't disparage the company you work for.  So please don't.  And you know what?  What are they going to do?  Arrest them?  There's not, I mean, maybe I don't even think they'd fire them.

Speaker: SPEAKER_07
Transcript:  I think there's also a point of don't use the Pride Parade as the opportunity.  As a protest, you let the Pride Parade have its own dignity.  Yeah.

Speaker: SPEAKER_06
Transcript:  I guess.  Have you been to a Pride Parade?  I mean, they're a heap of fun.  Gravitas is not what I associate.

Speaker: SPEAKER_04
Transcript:  It's hard to talk about if you're wearing assless chaps.

Speaker: SPEAKER_07
Transcript:  I covered Pride Parades in San Francisco when they started.

Speaker: SPEAKER_03
Transcript:  Good for you, Jeff.  By the way, the last time I used the phrase assless chaps,  somebody wrote to me and said, all chaps are assless.  Fair point.  Fair point.  Fair point.  It's a redundancy.  It's the day of fair points.  It's just a great phrase.  That's all.  Wow.  This show takes it out of me.  I don't know.  Does it take it out of you guys?

Speaker: SPEAKER_06
Transcript:  Let's see.  Oh, can we talk about Blue Dot?  Because I think that's really interesting.  Yes.  Blue Dot.  What is Blue Dot, Stacey?  I thought it was really good.  Oh, let me make sure.  It is Blue Dot.  Okay.  That's also a furniture company.  So I was like, did I just screw that up?  This is an employee.  It's a peer-to-peer, they call it counseling, but it's really  training a subset of your employees in compassionate listening,  which is just open-minded listening, not trying to solve a problem and not making judgments.  That's nice.  And-

Speaker: SPEAKER_03
Transcript:  Oh, this is Google's mental health company-run mental health project.  Yeah.

Speaker: SPEAKER_06
Transcript:  It is, yeah.  It's an employee-run mental health effort.  And these employees who are trained this way,  mark themselves with a blue dot on their badges.  And I like the example of how this happens, which is you might be hanging out with somebody  and, or just like passing by and if you're having a bad day or something,  you're just like, oh, hey, you're a blue dot.  I love this idea.  Can you, can I talk to you?  Great idea.  Yeah.  So we should do this.  Google collects no data on it.

Speaker: SPEAKER_03
Transcript:  Blue Dot volunteers don't coach people or even offer opinions.  They practice compassionate listening, promising openness and kindness to co-workers who come to them.  It's stuck on its own.

Speaker: SPEAKER_07
Transcript:  And then Google saw that they needed, they all they wanted, they added training to it.  Which is a good idea.  Of quality.

Speaker: SPEAKER_09
Transcript:  Yeah. 400 people.  I think it's great.

Speaker: SPEAKER_06
Transcript:  So it sounds like this one woman uses her 20% time to manage like any sort of  administrative tasks associated with it.  So I guess-

Speaker: SPEAKER_07
Transcript:  The joke is 20% time is 120% time.

Speaker: SPEAKER_06
Transcript:  Right.  Yes. I'm just pointing it out that that's where they say.  And I would assume that it would be difficult because if someone's like, hey, can I talk?  You know, it's not like if you're working on something pressing, you don't want to be like,  I have to get this out the door.  There is-  I know you're troubled right now, but-

Speaker: SPEAKER_03
Transcript:  There is definitely a trend in technology companies and I would guess it's all companies  these days, but there's definitely a trend in technology companies to acknowledge  that there's depression, there are other psychological impacts to the long work hours,  the hard work, the isolative nature of some of the work.  And I think there's a very active movement within Silicon Valley and in tech companies  in general to kind of acknowledge that and address it.  And not in the more formal traditional ways that an HR department might.  Every company in the world has a sign saying, here's the 800 number if you feel like  you know, it's not worth living, call this number.  This is something much, I think much more effective, much better.  We just had to all take our harassment training and among one of the things I really liked about  this is a state of the California mandated, so everybody had to do it.  Management, including me, had to do an extra two hour, we had like a special two hour training.  But the point of it, they kept emphasizing it.  Yeah, they said the point of it is not to keep your company from getting sued.  That's the point of it, by the way.

Speaker: SPEAKER_06
Transcript:  But in public they say the point of it is not to be a jerk to your coworkers.  That's right.

Speaker: SPEAKER_03
Transcript:  The point of it is to make the workplace a respectful place to other, you know,  and I thought that was really good.  And they talked about listening and not have judging, not having an opinion.  If there's an incident to immediately take, you know, take action.  So it was really, I thought it was really, I was surprised.  I was prepared to hate it.  I had to take it.  I hate the, every, anytime you work for a big company, I know you, Jeff, you know this anyway.  And you have to take these trainings for the radio show.  iHeartMedia has so many consent decrees.  I have to take, I have an hour long training on why you shouldn't play the emergency tones  on your radio show unless it's an actual emergency because some dumb DJ in New Orleans did it.  And now every iHeart radio employee has to take this training.  Why not to?  Obviously not a good idea.  And, but there's a lot of them and it's, you know, most of the time I hate it,  but this one was, I thought very, very good.  And it, I guess the state of California is required, requires us to do that.  So I think there is a trend in this direction to making a workplace,  the workplace a kinder, gentler, more inclusive place.  In California, you can't discriminate against somebody because of their gender choice,  for instance, or their pronoun choice or, you know, I mean, there's, there's some really good,  I think fairly good rules that are completely appropriate.  And I want to go on record saying that.

Speaker: SPEAKER_06
Transcript:  Noted.  All right.  Thank you.

Speaker: SPEAKER_03
Transcript:  No, I'm sincere.

Speaker: SPEAKER_07
Transcript:  Don't protest against you in the Pride Parade.  I am sincere.

Speaker: SPEAKER_03
Transcript:  Please don't protest against me in the Pride Parade.  So YouTube is in the hot seat a little bit.  The Washington Post had a scoop that said that the government has in the late stages  of an investigation of YouTube for violating the Children's Online Privacy Protection Act  that forbids tracking and targeting of users younger than the age of 13.  The probe launched after numerous complaints from consumer groups and privacy advocates  because apparently YouTube has been somehow either failing to protect kids  or improperly collecting their data.

Speaker: SPEAKER_06
Transcript:  Are they collecting data knowing it's from kids or just kids on YouTube and  they're another blip in the Google machine?

Speaker: SPEAKER_03
Transcript:  You know, probably it's the latter, but what they're saying is Google has to  ascertain people's age.  You can't just, you know, assume, well, they must be an adult because they have a YouTube account.  Yeah.

Speaker: SPEAKER_06
Transcript:  You have to assume they haven't lied.

Speaker: SPEAKER_03
Transcript:  These companies according to the Post say their services are intended for adults and  they take action when they find users who are underage.  Facebook says you can't join Facebook if you're under 13, but that doesn't stop.

Speaker: SPEAKER_06
Transcript:  Google won't give people email addresses unless they're, you know,  but you know, my daughter has an email, a Gmail address because, you know, I signed up for one  because a 13 year old without an email address is just ridiculous.  Now, why wouldn't you create like a kid's version of an account that just doesn't  track anything?  Because that's totally doable, but that would give up.

Speaker: SPEAKER_07
Transcript:  If you fail at it, your liability is probably higher.

Speaker: SPEAKER_03
Transcript:  Well, reportedly YouTube is considering moving all the kids' videos to YouTube kids  to like really make that a separate place, maybe turn off autoplay on YouTube kids by default.  Turn off all tracking.  Turn off.

Speaker: SPEAKER_07
Transcript:  Yeah.  I think that makes...

Speaker: SPEAKER_08
Transcript:  It's not just collecting info.  I mean, there's been story after story about inappropriate videos showing up in recommendations  and then, you know, pedophiles using like coded messages and comments to...  And I mean, YouTube, I think has admitted, I don't know if they have or not, that nobody  goes to YouTube kids.  Right.  Kids, unless their parents force them to, I guess.  So this was in the Wall Street Journal last week, but according to the post, a person

Speaker: SPEAKER_03
Transcript:  close to the company said that that option is highly improbable, difficult to implement  because of the sheer volume of content and potentially costly because of lost advertising  revenues.  Well, yeah, because you're not supposed to advertise them anyway.  Well, yeah, that's the point.  That's the point.  But the person close to the company said that other changes were on the table.  YouTube kids gets a tiny fraction of YouTube's audience.

Speaker: SPEAKER_07
Transcript:  So could we go to the other end of this for a second?  Yeah.  I'll ruin every conversation.

Speaker: SPEAKER_03
Transcript:  YouTube...  Is there going to be YouTube olds for the olds?  Because I would like that.

Speaker: SPEAKER_06
Transcript:  Full of conspiracy theories and keto diet tips.

Speaker: SPEAKER_03
Transcript:  Yeah.  It's called AARP tube.  Okay, go ahead, Jeff.  Seriously.

Speaker: SPEAKER_07
Transcript:  So a lot of this is going to go to identity, improbable identity.  And so two threads to this, right?  In the UK, they're about to implement a law requiring you to have a certified identity  to see porn.

Speaker: SPEAKER_03
Transcript:  They put that in the back burner.

Speaker: SPEAKER_04
Transcript:  Oh, okay.  Oh, they did.  Yeah, they did.  Go ahead.

Speaker: SPEAKER_06
Transcript:  It came out because they didn't tell the EU.

Speaker: SPEAKER_07
Transcript:  Well, that'll soon not matter.

Speaker: SPEAKER_03
Transcript:  We just thought we wouldn't be part of the EU by now.

Speaker: SPEAKER_07
Transcript:  Yeah.  But then you look at the Libra story, the story you guys put up there about  the hidden interesting thing in the Libra announcement was a new structure of  verifiable identity, which sounds interesting, but also sounds in certain regimes dangerous.  And will you have to verify your identity and thus your age before you can get into  YouTube or an email address or all of that?

Speaker: SPEAKER_03
Transcript:  This is the MIT technology review, Mike Orcutt.  The radical idea hiding inside Facebook's digital currency proposal.  And yeah, that's an interesting point.  That actually goes to the question about the blockchain because the blockchain is the  record of transactions.  And in YouTube's, sorry, Facebook's proposal with Libra coin, the blockchain is not a public  ledger, but is managed by these initial companies, 100 Strong or whatever these that are part of it.  They're going to be the nodes and they're going to manage the blockchain.  So it isn't a completely decentralized cryptocurrency.  It's interesting.

Speaker: SPEAKER_08
Transcript:  It's kind of a hybrid.

Speaker: SPEAKER_03
Transcript:  Yeah.  And there's a reason for that.  If you are completely decentralized, transactions take forever.  And that's been the problem on Bitcoin.  The Facebook coin supposedly will be able to handle a thousand transactions a second  because it is not fully decentralized.  But that's still a tiny fraction for a billion or two billion users.  A thousand transactions a second is not going to make it.  So I don't know.  I wonder about how this is going to work.

Speaker: SPEAKER_08
Transcript:  It is interesting though.  You remember the years ago when open identity standards were, you know, Google was working on  one and there was going to be, there was a consortium of groups that were trying to come  up with a sort of a way of logging into things without requiring you to use Facebook or Twitter  or any other thing.  And none of them went anywhere.  And it was because they couldn't get enough agreement from the places that would then use  that standard.  Not that the standards themselves weren't good, just that it was hard to get kind of buy in.

Speaker: SPEAKER_06
Transcript:  That is the problem with standards.

Speaker: SPEAKER_03
Transcript:  Bitcoin can process about five transactions a second.  That's very, very slow.  Visa does 1700 transactions a second on average.  And I'm sure it peaks at much higher numbers.  So if Librecoin does half what Visa has to do, it's not going to be, it's a non-starter.  Right?  I don't.

Speaker: SPEAKER_06
Transcript:  I thought Visa did many more.

Speaker: SPEAKER_03
Transcript:  Well, the calculate, Visa says we do 150 million transactions a day.  Divide that by 24.

Speaker: SPEAKER_07
Transcript:  If each one were a penny, how long?  No, sorry.

Speaker: SPEAKER_03
Transcript:  It would cover the world, my friend.  Cover the world.  Visa is capable of, this is where that number comes from, Stacy, capable of 24,000 per second.  So that's the peak speed.  That's a lot more.  That's 24 times Librecoin.  I wonder now that I'm thinking about it, what is the point of Librecoin?  Maybe it is this authentication.

Speaker: SPEAKER_08
Transcript:  It's not designed to replace Visa, I don't think.  It's not designed to replace every transaction.

Speaker: SPEAKER_03
Transcript:  But Visa is just one credit card.  I mean, it's not every transaction even.

Speaker: SPEAKER_06
Transcript:  Well, I mean, we buy a lot of stuff.

Speaker: SPEAKER_03
Transcript:  They're a big one, but I'm just saying there's also MasterCard.  There's also American Express.  There's also DiscoverCard.  There's also cash.  There's also checks.  If you really wanted to cover the financial world, a thousand transactions a second is  not even close.

Speaker: SPEAKER_06
Transcript:  Well, they don't want to cover the financial world.  I think they want to cover peer-to-peer kind of quick payments.  Like Venmo.  I don't know.  I think like Venmo or like in China, how everybody can take a picture of a scan of QR code.  Boom, they've paid for something.  I wish we had that.

Speaker: SPEAKER_04
Transcript:  Oh, you may get it.  I wish we had it in a way.

Speaker: SPEAKER_08
Transcript:  Who would you?  Someone said this was more like Western Union than a cryptocurrency.

Speaker: SPEAKER_03
Transcript:  Who would you prefer, Stacey?

Speaker: SPEAKER_06
Transcript:  I would trust Amazon to do it.  I would actually trust my banks to do it.  Apple would probably do it.

Speaker: SPEAKER_03
Transcript:  Apple's got a credit card.  They're on their way.  I don't like Apple.

Speaker: SPEAKER_06
Transcript:  Their ecosystem's too insular for me.  Yeah, I agree.  Sorry.  I'm like, eh.  Amazon you would trust.  I do because I know what Amazon's agenda and goals are.  They want me to buy a bunch of stuff from them.  So I feel like in my data, when it goes into Amazon, it doesn't go out of Amazon.  Amazon keeps that they make stupid choices when they buy companies like Ring and they're stupid.  But Amazon locks that stuff down because they don't want to give the advantage to other people.  And the advantage to them is Stacey will stay in our world  and we'll buy a crap ton of stuff.

Speaker: SPEAKER_03
Transcript:  But not to raise a straw man.  But let me raise a straw man.

Speaker: SPEAKER_06
Transcript:  Okay.

Speaker: SPEAKER_03
Transcript:  Right now, Amazon's goal is to-  What about a straw woman?  Okay, a straw person.  Let's raise a straw person.  Or as they say, a paper tiger.  As Amazon right now wants to just sell you stuff, what if at some point Amazon had other goals?

Speaker: SPEAKER_06
Transcript:  So that is a question.  Like with Amazon's health insurance or health efforts, I'm like,  what could that look like?  That kind of makes me a little nervous.  At some point in time, I would want to make sure my eggs are not all in the Amazon basket.  And if that wasn't an option, then I would cry foul.

Speaker: SPEAKER_03
Transcript:  Isn't actually, isn't that the best way to avoid all of this is to spread yourself out?  Yeah.  And not to be-  It's a lot of work though.

Speaker: SPEAKER_08
Transcript:  Yeah.

Speaker: SPEAKER_03
Transcript:  It's sure easier if you're all Apple, right?  If everything you have is Apple, everything works together.  Stacey and IoT, isn't it all better if it's all HomeKit or all SmartThings or all-  It works better, sure.  Yeah.  That's why these companies try to do this.  You know, one of the companies is not doing that.  There's two, Microsoft and Google actually don't really care.  Google gets-

Speaker: SPEAKER_06
Transcript:  Google just, no, Google with their Nest thing just kind of changed that.  Okay.  So the Nest thing is different.  Yeah.  That was a little different.  Okay.  I'm going to pause for a second without ads.  I have to go run and get a cup of coffee.

Speaker: SPEAKER_03
Transcript:  Have a cup of coffee while I talk about how Verizon-  I'd love a-  Oh yeah.  Get one for Matthew too.

Speaker: SPEAKER_08
Transcript:  Did you get, yeah, an espresso.  Thanks.

Speaker: SPEAKER_03
Transcript:  Honestly, if you're going to do this show, you ought to have a couple of things in the  studio with you.  A coffee maker, a beverage machine, and perhaps a toilet.  Because these shows go on and on and on.  We're almost done.  Without an ad.  Without an ad, there is no break.  I should- wait a minute.  I got an ad.  Don't we have a house ad that we're all supposed to be doing here?  Can you get me a house ad?

Speaker: SPEAKER_06
Transcript:  Okay.  I came back.

Speaker: SPEAKER_04
Transcript:  And now a house ad.  Watch.  Quit.  Watch.  Wait a minute.  No, no, it's better than that.

Speaker: SPEAKER_03
Transcript:  It's subtler.  We truly appreciate you listening to this podcast.  Every day it takes a team of hosts, producers, editors, engineers, and support staff,  not to mention the person who gets Leo's dry cleaning, to get our content to you.  As you know, our podcasts are free.  You didn't pay anything for this, did you?

Speaker: SPEAKER_04
Transcript:  This is a Patreon pitch starting here?  What?  No, no, no.  And it's supported.

Speaker: SPEAKER_03
Transcript:  The easiest thing you can do to help our network, besides sending us cash-  No, no surveys.  To subscribe.  It's that easy.  Subscribe to it.  This show and all your favorite Twitch podcasts, because that way you'll get it  instantly when it's available.  And it helps us.  In some magical way I've never really understood, but I believe Lisa when she says it.  And she gets the dry cleaning, so it's okay.  Thanks for listening.  And remember to subscribe on your favorite podcatcher, or just go to twit.tv slash subscribe,  and we'll tell you.  And send a nice tip to Lisa.  And thank Lisa and all those people who make the-  Actually, there are a lot of people.  It takes about-  I was about to say, they're nice people too.  One, two, three.  They're really nice people.  They deserve your support.  And of course, let's not forget Stacey, Jeff, and Matthew.  They all count.  So this was wild.  On the 24th of June, two days ago, I started seeing tweets that Cloudflare was gone down.  And I thought, oh my God, Cloudflare.  That can't go down.  Cloudflare provides DDoS protection and uptime protection for much of the internet.  And Cloudflare had a post on this and it turns out it was Verizon's fault.  Well, no, it was somebody else's fault, but Verizon was like, they certified it.

Speaker: SPEAKER_06
Transcript:  Basically it was-  So essentially what happened is there's a border gateway protocol, BGP routers, where you

Speaker: SPEAKER_03
Transcript:  essentially broadcast an internet route to the world.  Normally, if it's done properly, you broadcast a route that is just for traffic to you.  And you say, here's how traffic gets to me or to the people I serve.  Unfortunately, a small steel company in Allegheny, Pennsylvania, Allegheny Technologies,  Incorporated.  Now, I'm not sure who specified these routes, but these routes were-  were broadcast that all the internet should go through  Allegheny Technologies in Pennsylvania.  How do they do that?  Well, this is a known massive problem, frankly, with the way the internet works.

Speaker: SPEAKER_08
Transcript:  This has been happening-

Speaker: SPEAKER_03
Transcript:  This has happened a couple of times.  For decades.  Didn't Poland recently, like a year ago, or something like that, or something like that,  Yeah.

Speaker: SPEAKER_04
Transcript:  It's-  I tried.  There are protections that could be introduced to prevent it.

Speaker: SPEAKER_03
Transcript:  Verizon does not.  One of the protections would of course be to notice if a massive amount of traffic  was coming through your network.  Going through a single route.  About 15% of Cloudflare, because Cloudflare was on this route,  Cloudflare's traffic got routed, instead of going to where it was supposed to go,  got routed to the leaky BGP process on Verizon and then went to Allegheny Technologies.

Speaker: SPEAKER_08
Transcript:  So did Allegheny do this?

Speaker: SPEAKER_09
Transcript:  Did they reconfigure something?  I think it's Verizon.

Speaker: SPEAKER_06
Transcript:  They did.  So Allegheny made the original mistake, but what happened is they sent their original mistake  up to Verizon and Verizon-  Rubber Stamper.  Right, which would presumably be better at this than Allegheny.  Yeah.  Allegheny is an internet service provider.

Speaker: SPEAKER_07
Transcript:  So why don't Russians do this all the time?

Speaker: SPEAKER_03
Transcript:  Yeah, be a good way to take down the net.  Well, because, unlike Verizon-

Speaker: SPEAKER_08
Transcript:  Most people catch it.

Speaker: SPEAKER_03
Transcript:  Most of these people, by the way, the stunning thing is Cloudflare tried to reach Verizon,  and they have pictures in their blog post of all of the emails, all of the pager duties,  all of the calls.  Verizon gets a little too busy to respond, route leak from your customer, all of this stuff.  So what Cloudflare says is Verizon and everybody who does this kind of thing should be  implementing a framework they call RPKI, which is, it's very simple.  If a BGP session could be configured with a hard limit of prefixes to be received,  if all of a sudden the entire internet comes a-knockin', you should shut that route down.  Cloudflare writes, had Verizon had such a prefix limit in place, this would not have occurred.  It is a best practice to have such limits in place.  It doesn't cost a provider anything.  And there's good, there is, this is my favorite line in this blog post.  And there's no good reason other than sloppiness or laziness  that Verizon wouldn't have such limits in place.  Ding.

Speaker: SPEAKER_08
Transcript:  Or possibly both.

Speaker: SPEAKER_03
Transcript:  Or both.  And there's also a filtering system that you could use.  Or get greed.

Speaker: SPEAKER_06
Transcript:  Well, it's not even greed.  It's not greed.  I think the challenge here, or a challenge here, is Cloudflare had the luxury of building up  their infrastructure.  Cloudflare literally designed its own servers, right?  This is a true cloudy internet company.  Whereas Verizon's a telco that has all this old line infrastructure.  And they make so little money.  Their mindset is not, it's not proactive or even, they're not seeking to optimize the way  internet companies are because they don't have to until stuff like this happens.  Apparently.  Or even, yeah, I mean, it's hubris.  But it's ingrained into their culture.

Speaker: SPEAKER_08
Transcript:  Like that's a shock to me.  The internet is very...

Speaker: SPEAKER_03
Transcript:  It's surprisingly fragile, to be honest.

Speaker: SPEAKER_08
Transcript:  Just a series of tubes.  Yeah.

Speaker: SPEAKER_03
Transcript:  So what a story though.  I mean, just what a wild story.  It was three hours before DQE fixed the problem.

Speaker: SPEAKER_08
Transcript:  And I remember reading about the Cloudflare problems, but I didn't look into what happened.

Speaker: SPEAKER_06
Transcript:  I don't understand RPKI, so I'm like, I really want to dig into this a little bit more.

Speaker: SPEAKER_03
Transcript:  We're big fans of Cloudflare.  They've been...

Speaker: SPEAKER_08
Transcript:  You could learn about it and then tell us about it.  That would be great.

Speaker: SPEAKER_06
Transcript:  Yeah.  I can.  Cloudflare to me is one of those companies like Amazon that when you talk to them,  they see the way the internet is growing and changing and they're trying to solve  problems that are going to appear three to four years out.  So I always love talking to them.

Speaker: SPEAKER_03
Transcript:  They say AT&T have already enabled this successfully on their network,  so they're not going to be the next one to do this.  And I think there's a little pressure probably on Verizon to do it.  It basically filters the origin network and the prefix size.  So if you advertise a non...  Basically, it's a sanity check on the route that you're advertising.  If you're advertising a nonsense route, it'll be blocked or stopped.  No, this isn't going to happen.  So that's a simple way to...  There's actually many simple ways to do this.  The fact that Verizon didn't is kind of shocking.  How long was it out?  Three hours.  Not completely out.  Same as the Google Calendar.  Yeah.  Now, we don't know what happened with Google Calendar, but that was...  That was lovely.  Did people really not go to work because their calendar didn't tell them they had to?  Because that was the story.

Speaker: SPEAKER_07
Transcript:  I believe they didn't know how to do conference calls  because all the conference call data was in the calendar.

Speaker: SPEAKER_03
Transcript:  Well, that's true.  That's where I put...  Media.  Yeah, no, that's a good point.  Yeah.  I put it in the calendar.

Speaker: SPEAKER_07
Transcript:  But here's the other thing that broke.  Far more important than all of this.  What?  Far more irritating.  What?  Autocomplete in Chrome is borked.

Speaker: SPEAKER_06
Transcript:  I did not notice, but wow.

Speaker: SPEAKER_07
Transcript:  So if I start typing wa, it does washingtonpost.com and I go there, right?  Now I have to type out washingtonpost.  Oh no.

Speaker: SPEAKER_03
Transcript:  Oh my God.  Okay, so I'm doing it right now.  Wa, you're right, doesn't do it.  S does.  But that's because I've been to the Washington Post recently, maybe.

Speaker: SPEAKER_07
Transcript:  They put out a fix that I don't think I have in Chrome OS yet.

Speaker: SPEAKER_03
Transcript:  Jarvis is...  No, autocomplete for domains.

Speaker: SPEAKER_07
Transcript:  It's a problem.  For domains.  Hey, hey, hey, hey, hey, hey.  You know what?  It's autocomplete for domains.  It's a problem.

Speaker: SPEAKER_03
Transcript:  By the way, they fixed that so you can't type it.  It used to be able...  Let me see.  Leo Laporte is a...  You used to be able to type that, right?  And find out and they've stopped it.  Just for people or for everything?  Wait a minute, did you see how fast that happened?

Speaker: SPEAKER_04
Transcript:  They showed it and then...  Wow.  No, we're not going to show you that.  They removed it.  Whoa, whoa.

Speaker: SPEAKER_03
Transcript:  That's pretty funny.  So there's something going on there.  Let's see, Stacey...  There's something going on there.  I should...  But it's still...  Leo wants domains.  Yeah, no, domain completion.  Yeah.

Speaker: SPEAKER_06
Transcript:  But now Leo's having fun.  I'm having too much fun so I don't care.  Right, okay.

Speaker: SPEAKER_03
Transcript:  So it takes three letters for me.  Three or four letters.  I think you have the fix.

Speaker: SPEAKER_07
Transcript:  I can't do that still.

Speaker: SPEAKER_08
Transcript:  Okay.  You should try these things called bookmarks.  You just click on them.

Speaker: SPEAKER_07
Transcript:  Oh, I have 15 years of bookmark mess.

Speaker: SPEAKER_06
Transcript:  Oh, I just deleted my bookmarks today.  It was so happy.

Speaker: SPEAKER_03
Transcript:  Why did you delete your bookmarks?

Speaker: SPEAKER_06
Transcript:  Sorry, I cleaned up my bookmarks.  Yeah, so now I only have six bookmarks.  I'm a condo fanatic.  I know.  I have seven.

Speaker: SPEAKER_03
Transcript:  You want to see how cray cray my bookmarks are?  This is my news folder.  This is my Leo folder.  This is my social folder.  There's just...  This is my favorite one, programming.  Within programming, there's many folders.  A folder per language with many links within each language.  Go, go, go, go, baby.  This is a...  What's wrong with this?  What is wrong with this?  My Lisp folder.  That's nothing wrong with that.  That doesn't occupy any space.  It's just a little folder there.

Speaker: SPEAKER_06
Transcript:  I know.  It's just...  I mean, the point of bookmarks is to get to something quickly.  So if it's cluttered, you can't get to it quickly.

Speaker: SPEAKER_03
Transcript:  Well, it's not cluttered.  See my toolbar.  I don't even go to...  Do you just use a toolbar?  Folders is a secret.  Yeah, I just use a toolbar.  Yeah.

Speaker: SPEAKER_06
Transcript:  I use both.  I have a folder for recipes, but that's about it.  Yeah.  I think I should probably look into that.  Bookmarks are a resource.  I know.  I just...  I don't...

Speaker: SPEAKER_08
Transcript:  If I can remember two words about it, I just search.

Speaker: SPEAKER_06
Transcript:  Yeah, that's me.

Speaker: SPEAKER_03
Transcript:  That's a good point.  I know.  I trust...

Speaker: SPEAKER_06
Transcript:  Who's Josh Benton?

Speaker: SPEAKER_09
Transcript:  What about him?

Speaker: SPEAKER_07
Transcript:  Josh Benton is the editor of...  The Neiman journalism lab.  Neiman lab.  Oh, yeah.  And he talks about how he literally has 500 tabs in the Chrome browser.  I've never understood that.

Speaker: SPEAKER_08
Transcript:  Mike Maznick at Tector, I think, is in the 400 to 500 range at all times.  Wow.  So he must have 100 gigs of RAM.  I don't know how.

Speaker: SPEAKER_03
Transcript:  Because every tab in Google is in Chrome.

Speaker: SPEAKER_08
Transcript:  It's its own process.

Speaker: SPEAKER_03
Transcript:  Yeah.  People joke that's why Apple made a new computer with 1.4 terabytes of RAM, so you could have...  So you could run Chrome.  You could have all your tabs open.  I've never been a tab person.  I close tabs when I'm done with them.

Speaker: SPEAKER_06
Transcript:  Oh my gosh.  I have...  Right now, I'm good.  I only have 12 open.

Speaker: SPEAKER_03
Transcript:  So you really shouldn't be crowing about your bookmark hygiene.  Instead of bookmarking stuff, you just leave the tab open.

Speaker: SPEAKER_06
Transcript:  Well, no, I shut them down at the end of the day.

Speaker: SPEAKER_09
Transcript:  Oh, okay.

Speaker: SPEAKER_06
Transcript:  Oh, you do?  I leave them all open.  Yeah.  Well, I leave...  Okay, that's not true.  I shouldn't say that.  I shut most of them down.  I will only leave like two or three in addition to email.

Speaker: SPEAKER_08
Transcript:  The only time I shut down a tab is when it's autoplaying video with the audio.

Speaker: SPEAKER_03
Transcript:  Every time you close a tab, an angel gets its wings.

Speaker: SPEAKER_06
Transcript:  I believe that.  Yes.  Remember that.

Speaker: SPEAKER_08
Transcript:  640k of RAM should be plenty.

Speaker: SPEAKER_03
Transcript:  Anything else you guys want to talk about?  Because I'm talked out here.  Anything?

Speaker: SPEAKER_06
Transcript:  Do we want to talk about sidewalk labs or...

Speaker: SPEAKER_03
Transcript:  Yeah, yeah, yeah, yeah.  You were interested about this.  Yeah.  So this is actually in Toronto.  This is in Toronto.  They want to build a smart city in the old railroad yards, right?  Or something like that.

Speaker: SPEAKER_08
Transcript:  It's down by the...  Oh, like a port.

Speaker: SPEAKER_06
Transcript:  It's on the quay.  Yeah, the quay.  It's a port.  What is that called?

Speaker: SPEAKER_08
Transcript:  Quayside?

Speaker: SPEAKER_03
Transcript:  Quayside.

Speaker: SPEAKER_08
Transcript:  Yeah, it's Quayside.

Speaker: SPEAKER_07
Transcript:  These whiny Canadians don't know how good they're getting.  Actually, I like Quayside, Toronto.

Speaker: SPEAKER_03
Transcript:  I think that's kind of a neat area.  Yeah, I know that area.  That's where you get the boats to the airport, right?

Speaker: SPEAKER_08
Transcript:  No.  But I used to be able to get a boat to Rochester, but nobody wanted to go there.  Okay.

Speaker: SPEAKER_03
Transcript:  So Sidewalk Labs, which is a Google thing, and Toronto, Waterfront Toronto,  announced a plan to take this area and redevelop it, but make it a smart city.  Which did, of course, stimulate some protests because the smart city meant it would gather  data about you, about traffic, about where people go.  No, what gathered...

Speaker: SPEAKER_06
Transcript:  What generated the protest wasn't that.  It was that basically there's a separate development corporation that was formed to  work with Google or work with Sidewalk Labs on this.  So Sidewalk Labs, an alphabet company just like Google is.  And they basically came up with a plan, and they had no actual input from any of the  citizenry who was going to live there.  And so the protests, I think, were actually very legit in the sense that,  wait, what is happening here?  We live here, and you're doing this deal with Google, and you're treating it like a  real estate deal, but it's really going to put a lot of sensors in and gather all this data.

Speaker: SPEAKER_03
Transcript:  Wait a minute.  Nobody lives there, right?  Nobody lives there.  Well, nobody lives there yet.  Well, and if you don't want to live there, there's a place down the road you could live.

Speaker: SPEAKER_06
Transcript:  Well, but there's also...  Or not.  There's going to be businesses located there.  Only by choice.

Speaker: SPEAKER_08
Transcript:  But the principle is still...  So the principle was who controls the data.  Is it Google?  Does Google get access to that data?  Does the province get access to that data?  Does the federal government get access to that data?  Do other companies get access to that data?  And it's not clear.  So all the benefits are clear.  Everything would run perfectly, and you'd have hot and cold running everything, and  automated cars, and...

Speaker: SPEAKER_03
Transcript:  And if you don't like it, don't live there.

Speaker: SPEAKER_08
Transcript:  Right.  But then the data on your usage, which Google says it would use to make things better,  who controls it, who owns it, who gets to give it to others or use it in different ways.

Speaker: SPEAKER_03
Transcript:  Given the choice between the province and Google, I think I'd choose Google.

Speaker: SPEAKER_04
Transcript:  So...  Yes.  Look with the CBP, the Customs and Border Protection...

Speaker: SPEAKER_07
Transcript:  The leader of this province is right now, Ford.

Speaker: SPEAKER_08
Transcript:  He's a nut job.  Fair.

Speaker: SPEAKER_04
Transcript:  So that's fair.

Speaker: SPEAKER_03
Transcript:  But I don't trust the province as far as I can throw it.  Google at least has a...

Speaker: SPEAKER_06
Transcript:  That's a democratic process, and you can change the rules associated with it.  And Google isn't a democratic process.  And remember what we talked about with ambient privacy, and it's easy to say,  don't go there.  But it's hard to say that if a government office is based there,  or maybe they put a school there, or your kid's daycare is there.  I mean...

Speaker: SPEAKER_03
Transcript:  But you're the one who said you should judge the outcome by who profits, what the business  motive is.  And my...

Speaker: SPEAKER_06
Transcript:  I said that you should judge it based on the outcome and how it affects people.  Yeah, because you can understand...  And specifically how it affects people who don't have power.

Speaker: SPEAKER_03
Transcript:  Okay.  Maybe it wasn't you who said it, but somebody said that the best way to judge whether your  data was safe with the company is what the company's profit...

Speaker: SPEAKER_06
Transcript:  That's what I said about Amazon.  Yes, I understand its profit motive.  But Amazon's not collecting my data outside...  Amazon's collecting my data when I interact with it.  This is a different level of interaction.  This is walking down a city street or driving...  Somebody...

Speaker: SPEAKER_03
Transcript:  Look, even if you're not in Keyside, somebody's collecting your...  The province is collecting your data all the time.  They've got cameras everywhere.  They're collecting your data all the time.

Speaker: SPEAKER_06
Transcript:  But they usually have rules associated with how that data gets seen.

Speaker: SPEAKER_03
Transcript:  But my point being that A, they may have rules which change all the time,  depending on who gets elected and who's corrupt.  And B, they don't have any security policy.  Look what happened to the customs and border protection.  Hackers stole license plate images, travelers IDs, and now as we learn more...

Speaker: SPEAKER_06
Transcript:  So they stole that though from a third party.  From a provider.

Speaker: SPEAKER_03
Transcript:  A third party that had the data because CPB let them have the data.

Speaker: SPEAKER_06
Transcript:  Right, but that Sony was victim of a similar hack.  I understand.

Speaker: SPEAKER_03
Transcript:  I'm just saying who you trust with your data, Google or the province of Ontario?

Speaker: SPEAKER_08
Transcript:  So that's a fair point.  I mean, it's not as though there's an easy answer.  I think Google knows more about security than Mr. Ford.

Speaker: SPEAKER_03
Transcript:  You know what the easy answer is?

Speaker: SPEAKER_07
Transcript:  What?  Toronto, if you want to whine about it, fine.  Google, go to Newark, New Jersey.  They could use this.  Toronto's in great shape.  Real estate costs are insane.  Go to a city that...  Same with Amazon and their damned headquarters.  Go to Newark, New Jersey.  Go to a place that needs it.

Speaker: SPEAKER_06
Transcript:  Nobody wants those people's data.

Speaker: SPEAKER_07
Transcript:  That's kind of where...  Yeah, that's the problem.

Speaker: SPEAKER_06
Transcript:  That's harsh.  I mean, it is.  I mean, you know, is Camden benefit from better traffic management or safer policing tactics?

Speaker: SPEAKER_08
Transcript:  To me, there's a happy medium there somewhere where Google agrees to share data and there's  a sort of arm's length entity that includes Google, but also includes the province.  I mean, this is not an unsolvable problem.  And I think you probably could learn a lot.  You could learn a lot from that city, from people's behavior.  You could learn things that would improve other cities, that would make things easier.  Yes.

Speaker: SPEAKER_06
Transcript:  And they've created a third party to deal with...  I can't think of the name of it right now.  What is it called?  Hold on.  The Urban Data Trust.  I think one of the issues in the plan that they released though was...  It's still not clear who's in the Urban Data Trust,  how they can protect the public's interest in elements associated with that.

Speaker: SPEAKER_08
Transcript:  A lot of this has come only with people pushing Google.  Yes.  Only with the former privacy commissioner resigning and saying,  this is not a workable model.  And I think Google, in the same way they and a lot of other companies do, they thought,  hey, we're going to give you a bunch of free stuff for your city.  You should be thanking us.  It's obviously going to be good because we're Google and we're great.  And instead of trying to meet some of these questions head on, they had to be dragged into it.

Speaker: SPEAKER_03
Transcript:  In 1994, Walt Disney, the company, not the person,  built a town in Florida called Celebration, a planned community.  By the way, it's 88% white in an area where it's only 59% white.  So there are other issues.  There are people who don't like the fact that everything's planned down to the manhole covers.  But there are people who are very happy to live there.  And then there are some people who say it's kind of creepy, but honestly,

Speaker: SPEAKER_07
Transcript:  It's the good place.

Speaker: SPEAKER_03
Transcript:  It's the good place is exactly what it is.  I imagine Disney got a lot of information about people who lived there and all that, right?

Speaker: SPEAKER_06
Transcript:  I don't know.  I mean, they built that in 1947, 49.  No, 94.  Okay.  Oh, I know their hospital.

Speaker: SPEAKER_07
Transcript:  Why is there a sheriff's line there in the picture?

Speaker: SPEAKER_03
Transcript:  It was a crime scene of the first ever murder.  This was the first ever murder 14 years after it was built.  Yeah, this is Gizmodo.

Speaker: SPEAKER_08
Transcript:  Apparently it was a very poor craftsmanship.  All the builders were underqualified.

Speaker: SPEAKER_03
Transcript:  But in other words, it's not, and I mean, Levittown.  Yeah.  It's not a new idea to have a planned community.  And I think there are a lot of people think, oh, that's a great idea.  And if you have digital technology and you could plan traffic and  other things using digital technology, I don't know if that's such a terrible idea.  And who cares if Google knows where the traffic goes?

Speaker: SPEAKER_06
Transcript:  Oh, there's a lot of information that can be gleaned from traffic as we've figured out.

Speaker: SPEAKER_03
Transcript:  Is Google track when you go?

Speaker: SPEAKER_08
Transcript:  Yeah, they, well, they would know when you left your house.  They would know when you got into a cab.  They know right now when I leave my house.

Speaker: SPEAKER_03
Transcript:  And I'm not even in a planned community.

Speaker: SPEAKER_06
Transcript:  They know that now, but if you were an Apple phone user, you might say, okay, well.

Speaker: SPEAKER_03
Transcript:  I have a way of not having them know, but not living in  Keysight, Toronto.

Speaker: SPEAKER_08
Transcript:  But I still think it would be, you're right.  People don't have to choose to live there if they don't want to.  But I still think it would be useful to have some kind of.

Speaker: SPEAKER_06
Transcript:  Assurances about who gets access to the data.

Speaker: SPEAKER_08
Transcript:  Right, assurances about who gets access to the data, what data they get to access.  I'd like to have that from Facebook.  I'd like to have it from lots of companies.  So I would like to have it from Google if they are running what amounts to an experiment.

Speaker: SPEAKER_03
Transcript:  I just would be sad if, because of some imagine, and this is more like.

Speaker: SPEAKER_06
Transcript:  Look at it this way.  Actually, this will appeal to you, Jeff, because you're a journalist.  If I have questions about things in my city today, I can go to a city council.  I can file a FOIA request and I can get whatever data exists, right?  It's a pain, but I can do it.  If Google has that data and this is a quasi government whatever project,  then I find if I want to find out information about,  you know, maybe I notice that there are no people of color in this place.  Maybe I notice, I don't know, that the toilets back up a whole lot.  I can't get any information necessarily about that.  Yeah, so there are reasons to wonder about public access to what is effectively city data.

Speaker: SPEAKER_07
Transcript:  So there are, I think it's a very good point, Stacey, excellent point.  But I think there are some other analogs you can go to, which is condominiums.

Speaker: SPEAKER_09
Transcript:  Yeah.

Speaker: SPEAKER_07
Transcript:  Right.

Speaker: SPEAKER_03
Transcript:  HOAs, homeowners agreements, can be very onerous.

Speaker: SPEAKER_07
Transcript:  Co-ops are the ultimate capitalistic society where there's only one value, that's property.  Right.  Right.  In New York.  And so there are some analogs there where it's quasi public.  So what happens is you have separate, if you look at that as an analog,  you have separate regulation in the government about how apartments are run, right?  Whether you're a landlord or whether you're a co-op or a condo, you can impose things externally.

Speaker: SPEAKER_06
Transcript:  You're basically creating, if you were in Oryx and Craik, you're basically creating those company  based communities where the companies control, it becomes truly a network of company towns, which is...

Speaker: SPEAKER_07
Transcript:  Which exist to some extent today.

Speaker: SPEAKER_05
Transcript:  I don't think it exists.

Speaker: SPEAKER_07
Transcript:  I wouldn't move to a planned community next to us because they said you couldn't put up a flagpole.  We had no desire to put up a flagpole, but we resented the idea that somebody was going to tell us,  you can't put up a flagpole or paint your door red or whatever.  So we have to...

Speaker: SPEAKER_06
Transcript:  I can see you not do it well enough.  ...do it next to us.  But what if...  I would not do it well enough.  What if over time...  But this is well beyond a condo.  Yeah, over time, this is going to be better services.  You should see...  I'm not saying there's precedent.

Speaker: SPEAKER_07
Transcript:  What I'm saying is there's precedent about how to deal with these questions  with things like condos.  So what I'm saying is the role here, I think, should be the government should...  It's regulation and Canadians love regulation.  They should say rather than expecting Google or the private company to do it,  government should be the one that insists upon it and they're going to do the permits.  Just like government can say you have to build so many schools or you've got to make the roads  this big, that's government's job.

Speaker: SPEAKER_08
Transcript:  And I think we're just negotiating how that happens.  That's right.  Good.  Just negotiation.  Right.  As long as...  I just don't want to see...  Google, leave them.  They don't need you.

Speaker: SPEAKER_07
Transcript:  Come to Newark.  Come to Newark.  I'll move in.  You come to Newark, I'll move in.

Speaker: SPEAKER_08
Transcript:  I'll tell you what, Newark looks way better than the port side lands.

Speaker: SPEAKER_03
Transcript:  Does Canada have a FOIA, Freedom of Information Act?

Speaker: SPEAKER_08
Transcript:  We do.  The equivalent?

Speaker: SPEAKER_03
Transcript:  Yeah.  Yeah.  We may not.  We may not in the United States.  The Supreme Court last week, actually two days ago, expanded...  I saw that decision.  Yeah, in the Argus Leader case.

Speaker: SPEAKER_08
Transcript:  So companies, if it involves a company, it can now be determined to be confidential.

Speaker: SPEAKER_09
Transcript:  Private.

Speaker: SPEAKER_03
Transcript:  Private.  It was the...  That's so horrible, horrible.  Yeah.  Food Marketing Institute versus Argus Leader Media.  The Supreme Court ruled that Argus Leader Media does not have the right to that information  because they were doing a FOIA with the US Department of Agriculture, seeking the names  and addresses of all retail stores that participate in the food stamp program, SNAP,  and each store's annual SNAP redemption data.  This would be, of course, from a journalist's point of view, some very interesting data.  But it's a third party.  USDA said no.  Argus Leader sued the Supreme Court, said it's commercial information  and can be kept confidential because it comes from companies.  So they overturned the 8th Circuit.

Speaker: SPEAKER_08
Transcript:  They didn't say that those companies have to meet any test where they say  it's confidential because, or if we release it, X bad thing is going to happen.  It's just ipso facto, everything is considered confidential.  Right.

Speaker: SPEAKER_03
Transcript:  The Institute has standing to appeal the disclosure of the contested data would cause  its members financial injury in the highly competitive grocery industry.  This concrete injury is directly traceable to the judgment ordering disclosure.

Speaker: SPEAKER_08
Transcript:  And Argus won all the way up to the Supreme Court.  Right.  It won every decision, obviously, but it's interesting to read the dissent.  It's quite scathing.  Yeah, because it undermines for you.  I can't remember who delivered the dissent.

Speaker: SPEAKER_03
Transcript:  Let me look at SCOTUS blog here.  An opinion by Justice Neil Gorsuch for a 6th Justice majority.  Justice Elena Kagan.  Oh, wait a minute.  Elena Kagan was on the majority.  Let me see who wrote the dissent.  Anyway, that's an interesting.  Some say this might undermine FOIA.

Speaker: SPEAKER_08
Transcript:  Bad decision.

Speaker: SPEAKER_03
Transcript:  Ruth Bader Ginsburg, Sonia Sotomayor and Justice Stephen Breyer partial dissent.  Weird mixes.  Yeah.  I think weird mixes are good.  At least it's not along party lines here.  Still a bad decision.  Well, FOIA is a great thing.  The Freedom of Information Act has proven to be a very powerful tool for journalists.

Speaker: SPEAKER_06
Transcript:  Not just journalists.  I mean, normal citizens.  Parents use it a lot to figure out.  Right.  Yeah.

Speaker: SPEAKER_03
Transcript:  I want to retract many of the conversations we've had over the past few years about the  distinction between a platform and a publisher.  This has to do with Section 230.  All right.  Your ah can come in a moment.  Mike Masnick, who we do like a lot.  He's with TechDirt.  He's the best.  He said, I'm going to say it again.  There's no legal distinction between a platform and a publisher.  Everybody, the way that Section 230 is written is that everybody is an internet platform.  If you're online, you're an internet platform and you're protected.  Companies don't need to worry about whether they're a publisher or a platform.  If they're online, they're protected.  You disagree, Jeff?

Speaker: SPEAKER_07
Transcript:  In regards to 230, I agree.  But that's why I hate that being the test because there's a lot else that falls into place.  In regards to 230, yeah, it's about enabling conversation.  Many parties do that.  And as 230 protects all, quote, interactive computer services, including publishers who

Speaker: SPEAKER_03
Transcript:  host third-party content.  You don't have to figure out.  You don't have to be as Facebook.  I have said mistakenly, oh, Facebook's got to figure out as a platform or a publisher.  No, it's an internet company.  In regards to 230, no.

Speaker: SPEAKER_07
Transcript:  Okay.  Where does it matter?  That's the point.  You're not considered a publisher.  By the way, I'm going to plug it again.  Everybody out there, read Jeff Kossoff's book, The 26 Words That Created the Internet.  It's an excellent biography of the law and where it stands.

Speaker: SPEAKER_03
Transcript:  And I imagine that he delves into this there.  Oh, quite a bit.

Speaker: SPEAKER_07
Transcript:  You want to have him on the show.  He's really good.

Speaker: SPEAKER_08
Transcript:  The whole point of the law was to make it so that interactive service providers could  delete content and curate and do all those other things without being subject to  different rules.

Speaker: SPEAKER_03
Transcript:  It wouldn't be a slippery slope.  They have the safe harbor protection of Section 230, regardless of what they do to the content  that they're publishing, whether they edit it or delete it.

Speaker: SPEAKER_08
Transcript:  They don't have to just be a pipe that distributes without it.  Highly recommend it.  Have you read the book, Matthew?  No, I haven't.  I highly recommend it.

Speaker: SPEAKER_07
Transcript:  It's the fight that we're going into.  So you see that effort from the right last week to say if you're not neutral,  you're going to lose 230 protection.  You shouldn't have it.  There's going to be efforts to knock down pieces of 230.  And Wyden, who is the co-author with Roth, Wyden in the Senate, Roth in the  House when he was there.  Not Roth.  No.  It's pretty else.  But Wyden in the Senate.  And Wyden's very unhappy that the platform didn't stand up to protect 230.  What was it called?  Fosca Sessa?

Speaker: SPEAKER_09
Transcript:  Fosca Sesta.  Fosca.

Speaker: SPEAKER_07
Transcript:  Because the fear is there's going to be a lot more carve-outs of 230.  So really-  Testimony this week, arguing that there ought to be an additional phrase there  that is extended to those that do responsible moderation.  But then if I want to be HN and everything goes away after 30 seconds or whatever,  it goes away.  That's a choice on the internet.  Why should that be considered bad?

Speaker: SPEAKER_08
Transcript:  And one thing Mike points out, which I think is really important,  is he points out that this doesn't just protect Google and Facebook.  It protects newspapers that have comment sections.  It protects any publisher.  It protects review sites.  It protects literally anybody who offers a service where people comment.  So it's not just that it protects these giant platforms that get away with whatever you think  they're getting away with.  It protects anyone who's offering a service where people are expressing their opinions.

Speaker: SPEAKER_07
Transcript:  When the Guardian started to comment as free many years ago,  their really robust discussion platform, which was groundbreaking at the time,  it was really gutsy because there's no 230 nor a First Amendment, of course, in the UK.  They were liable for things set on the platform.  Against the advice of a lot of people in media, went ahead and did it.  But most people in media didn't want to be anywhere near it because they would have liability.

Speaker: SPEAKER_08
Transcript:  We went through that, the newspaper I worked at when I was involved in  comments and social media.  It was a huge...  Because there's no Section 230 in Canada either.

Speaker: SPEAKER_03
Transcript:  Now that's interesting.  So what's it like with no Section 230?

Speaker: SPEAKER_08
Transcript:  Well, everyone is very, very nervous.  Especially lawyers because you just never know.  There have been a couple of decisions.  I remember taking part in a case involving comments and there have been a couple of  decisions, lower courts, that did uphold the right of publishers to moderate comments  and said that that didn't, by definition, lay them open to lawsuits.  So it wasn't as though you have to keep your hands off or you won't be covered.  But it's still a very gray area.

Speaker: SPEAKER_03
Transcript:  It's very cool that we have this Section 230.  This is part of the...  It's amazing.

Speaker: SPEAKER_07
Transcript:  We've got to defend it.

Speaker: SPEAKER_03
Transcript:  Yeah, we've got to defend it.  And I just...

Speaker: SPEAKER_07
Transcript:  It's the last smart thing Congress did.

Speaker: SPEAKER_03
Transcript:  It was 1996.  Really it's been that long, huh?

Speaker: SPEAKER_07
Transcript:  It was...  When it was...  You think about how early it was in the process of the internet starting.  It was very prescient to realize the principle of...  This goes to James Carey, the principle of defending conversation in a democracy.  Yeah.

Speaker: SPEAKER_08
Transcript:  And I guarantee nothing like that would ever be passed now.  Oh, God, no.  Not in a million years.

Speaker: SPEAKER_03
Transcript:  Well, that's why it's under assault.  I just ordered the book.  Libraries...

Speaker: SPEAKER_08
Transcript:  If you try to create a library now, if there weren't libraries,  you said, we're going to have a bunch of books.  We're going to give them away to anybody who wants them.  That would never happen.  No one would ever allow you to create a library.  You're a socialist.

Speaker: SPEAKER_07
Transcript:  You're going to give away books.  So in Cosmist's book, there was a case of a bookstore that had  literature viewed as pornographic.  And the argument was the bookstore owner was responsible.  But the contrary argument was the bookstore owner doesn't read everything in the bookstore.  Right.  And therein, that debate leads you to 230.  It's fascinating.

Speaker: SPEAKER_08
Transcript:  Yeah.  I find it interesting that there's a debate about...  Do you remember the Shitty Media Men list?  Yes.  Was it Google Doc that went around?

Speaker: SPEAKER_03
Transcript:  Yeah, it was a list of Me Too.  People accused of Me Too.

Speaker: SPEAKER_08
Transcript:  Right.  And so someone sued, has sued over being named in that list.  Oh, really?  And the creator of the list is trying to argue that that Google document was effectively  an interactive service.  And therefore, she shouldn't be responsible for things that were contributed to that list  because they were contributed by...  She's got a point.  Yeah, it's an interesting topic.  Everyone else added things to that document.  It was effectively an interactive document.  Right.  Anyway, interesting case.

Speaker: SPEAKER_03
Transcript:  Jeff K-O-S-S-E-F-F, the 26 words that created the internet, if you want to follow up.  I just ordered it.  I'm going to read it.  I think I need to.

Speaker: SPEAKER_07
Transcript:  There was a case in Australia on the rundown today of a woman who lost $500,000  case from a plastic surgeon she had libeled, defamed, in a Google review  about her cheek reduction.  Right.  That's not me right there.  A cheek reduction?

Speaker: SPEAKER_03
Transcript:  Well, if you had big cheeks, if you were one of us, one of the sufferers,  one of us who suffer from big cheek syndrome or BCS, yes, you would not make light...  Jeff does not have big cheeks.  ...of this...  No, he's a scrawny little cuss.  Oh, God, no.

Speaker: SPEAKER_07
Transcript:  But anyway...

Speaker: SPEAKER_03
Transcript:  Old moon face Leo, I know how she feels.

Speaker: SPEAKER_07
Transcript:  You got to reduce your cheeks, Chipmunk there?

Speaker: SPEAKER_03
Transcript:  Yeah, I'm thinking.  I'm not going to this plastic surgeon.  I can tell you, I read the review.

Speaker: SPEAKER_07
Transcript:  The plastic surgeon won.

Speaker: SPEAKER_03
Transcript:  He won.  See, that's shocking to me.  If you can't...

Speaker: SPEAKER_07
Transcript:  No, no, no, because it was it was it was de-bondially false.

Speaker: SPEAKER_03
Transcript:  Oh, she lied about it.

Speaker: SPEAKER_07
Transcript:  Oh, she lied about it.  Oh, that's different.  It was a false review.  And so people think on the internet, oh, I get to put this stuff up.  No, libel law pertains.

Speaker: SPEAKER_09
Transcript:  Okay.  Yeah.  So this is a good outcome.

Speaker: SPEAKER_06
Transcript:  Just like if I said something slanderous, slander would still pertain.  Yeah, yeah.

Speaker: SPEAKER_08
Transcript:  So Twitter has been involved in a bunch of cases like that.  I think didn't Courtney Love was sued for defaming somebody on Twitter?

Speaker: SPEAKER_03
Transcript:  In this case, Yelp wouldn't be liable.  Twitter wouldn't be liable.

Speaker: SPEAKER_08
Transcript:  Twitter was not liable.

Speaker: SPEAKER_03
Transcript:  No, but the person who posted it might be, you know.  All right.  That makes sense.  And that probably is the answer to that spreadsheet that was going around is that, well,  the person who created the spreadsheet might not be liable, but whoever put...  People who contributed.  Liable statements in it would be liable.  By the way, libel, L-I-B-E-L versus L-I-A-B-L-E.  I should pronounce those differently.

Speaker: SPEAKER_06
Transcript:  You should be liable for your libel.

Speaker: SPEAKER_03
Transcript:  Liable is liable.  Liable.  Liable.  Don't lie.  Oh, the other book, Dryer's English.

Speaker: SPEAKER_07
Transcript:  Dryer's English.  Have you read that one?

Speaker: SPEAKER_03
Transcript:  No.  Oh, man.

Speaker: SPEAKER_07
Transcript:  The Copy Chief of Random House.  It's delightful.  It is, believe it or not, it's a book about copy editing and it's delightful.

Speaker: SPEAKER_03
Transcript:  I love that kind of stuff.  That one I might buy in hardcover.  Benjamin Dryer.

Speaker: SPEAKER_01
Transcript:  Oxford comma.  Yeah.

Speaker: SPEAKER_03
Transcript:  Yeah, right on, dude.  We've had this battle before.

Speaker: SPEAKER_08
Transcript:  You should also read Eats, Shoots, and Leaves.  Yes.  Oh, I have that.  That's an Oxford...  Oh, I have that.

Speaker: SPEAKER_03
Transcript:  Yeah, great book.  Actually, I think...

Speaker: SPEAKER_06
Transcript:  I have tons of grammar books, actually.

Speaker: SPEAKER_03
Transcript:  Stacey might have written this one.  Miss Thistlebottom's Hobbogloblins.  Careful writers, dead to taboos, bugbears, and outmoded rules of English.

Speaker: SPEAKER_08
Transcript:  Thistlebottom are cousins, I think.  Stacey Thistlebottom.

Speaker: SPEAKER_06
Transcript:  That is my British cousin right there.

Speaker: SPEAKER_09
Transcript:  Cousins from the North.

Speaker: SPEAKER_06
Transcript:  Are we actually doing our picks?  Yes.  I don't know what to do now that we're...  Give us a pick.  The show goes on forever.  Give us a pick, Thistlebottom.

Speaker: SPEAKER_08
Transcript:  Tell us about the Thistlebottoms first, though.

Speaker: SPEAKER_06
Transcript:  All right. Well, my pick is not a tech pick because I bought the most ingenious thing  that I love and I must share it with you.

Speaker: SPEAKER_09
Transcript:  Okay.

Speaker: SPEAKER_06
Transcript:  It is the Oxo Good Grips salad dressing shaker.  I love everything Oxo Good Grips does.  So what, man?  I didn't know they made this, but I just have been shaking up my dressings in an old  dressing jar, but when we moved, I didn't have a mason jar and I didn't have a cup or anything,  so I just bought this because I was like, you know, I might use this.  Oh my gosh, it's awesome.  And if you want to make it even better for people, if there's like one or two dressings  that you guys normally make all the time in your house, take a Sharpie and write the amounts on  the dressing, make the dressing and write like oil to this point.

Speaker: SPEAKER_03
Transcript:  Oh, that's a good idea because anybody can make it.

Speaker: SPEAKER_06
Transcript:  Then anyone can use it, but it doesn't leak.  You can use it to shake stuff up.  It's very easy to clean.

Speaker: SPEAKER_03
Transcript:  Because I use...  I have...  I bought a six pack of squeeze bottles, you know, like the mustard and ketchup bottles.

Speaker: SPEAKER_06
Transcript:  Yes, yes, because somebody told me to do that and it was a great idea.  Yeah.  We bought some too.

Speaker: SPEAKER_03
Transcript:  Yeah, and so I make my dressing and put it in there, but this would be better because  you have to put your finger over the hole when you're shaking it.  So this would be better.  Yeah.

Speaker: SPEAKER_08
Transcript:  We use the ketchup bottles, the squeezable bottles for barbecue sauce that we make.  Yeah.

Speaker: SPEAKER_03
Transcript:  I keep a bottle of olive oil by the stove all the time.  That's really the best use because then you can always squirt a little olive oil on a pan  or whatever and it's very fast and easy.

Speaker: SPEAKER_06
Transcript:  Yeah, this comes in two sizes, a one and a half cup or a one cup.  I want the big...  I want the big...  Smart?  I would get...  Can you connect anything by Bluetooth or...  There is nothing smart.  Unless you do your little dressing recipes on it, then it's smart.  Oh, mine's green.  I don't know why yours is black, but there you go.  There you go.  There you go.  You should get one in each color and that way you can have...

Speaker: SPEAKER_08
Transcript:  Could you make martinis in it if you wanted to?  Yes, actually.

Speaker: SPEAKER_06
Transcript:  You totally could.  That is a great option.  There you go.  They don't have the large and green here.

Speaker: SPEAKER_03
Transcript:  What?  Huh.  Well, maybe that's because I'm on the wrong page.  There you go.

Speaker: SPEAKER_06
Transcript:  There you go.  I don't know, but I love this thing.  Now, I've only had it for four weeks now, but man, I've washed it.  I've used it.  It has a gasket, so when you put it in the fridge, it doesn't smell of the place.  Nice.  So yeah, it's good.  I have not found a problem with it yet.

Speaker: SPEAKER_03
Transcript:  And you can also get the two-in-ones dressing shaker with a citrus juicer on top of it.

Speaker: SPEAKER_06
Transcript:  Yeah, that seemed like a lot of...  Yeah.  That seemed like more.  Too much.  But if you want, let me know how that works.

Speaker: SPEAKER_03
Transcript:  I'm buying this.  This is awesome.

Speaker: SPEAKER_06
Transcript:  Yeah, I didn't even know these existed.  I was very excited.

Speaker: SPEAKER_03
Transcript:  I should just take one of everything OXO does.  Wait though.

Speaker: SPEAKER_06
Transcript:  Oh, I should tell you before you buy it.  I bought mine for $9.99 at Target.  This is like 15 bucks.

Speaker: SPEAKER_03
Transcript:  You know what?  This is one of those guys who goes to Target, buys 100 of them,  and sells them on Amazon for five bucks more.  Guaranteed.  Yeah.  Yep.

Speaker: SPEAKER_06
Transcript:  So that's my only caveat, but I liked it.

Speaker: SPEAKER_03
Transcript:  Nice.  Good pick.  Any cooking pick is okay with me.  Oh, now that I've gone to the one that's more expensive, I swear to God.  I'll show you the cheaper one.  I swear to God, Amazon has raised the price on the one that was $9.  Is now also $15.

Speaker: SPEAKER_07
Transcript:  Because it was higher than being indecisive.

Speaker: SPEAKER_03
Transcript:  I swear to God.  Am I wrong, folks?  Wasn't this $9?  And now it's $15?  They don't have data window.

Speaker: SPEAKER_08
Transcript:  Geez.

Speaker: SPEAKER_03
Transcript:  Amazon's algorithmic pricing at work again.

Speaker: SPEAKER_07
Transcript:  I don't know where I can look back.  Hey, stay chat room.

Speaker: SPEAKER_03
Transcript:  Matthew Ingram picked something for me.

Speaker: SPEAKER_08
Transcript:  So I picked something out of the rundown that we didn't get to.  It looks like Twitter has finally answered my prayers from about six years ago, maybe.  And they're highlighting lists.

Speaker: SPEAKER_04
Transcript:  They're back, baby.  Twitter lists are back.

Speaker: SPEAKER_08
Transcript:  They're much more prominent in the redesign.  So there's a menu and list is right in there.  Oh, nice.  So instead of having to click six nested submenus to get to your lists, I use lists a lot.  I don't know if other people do, but it's one of the only ways I can.

Speaker: SPEAKER_03
Transcript:  So where do I get?  How do I get?  So here's my Twitter page.  And then I may not have it yet, but would it be over here on the left?

Speaker: SPEAKER_08
Transcript:  It'd be on the left.  Yeah.

Speaker: SPEAKER_03
Transcript:  Yes.  Where it used to be when they first created lists.

Speaker: SPEAKER_08
Transcript:  Yeah.  So I've got home, explore, notifications, messages, bookmarks, lists, profile are all in a menu on

Speaker: SPEAKER_09
Transcript:  the left instead of sort of up at the top.  Oh, I hope to get that.  Yeah.  I use lists all the time.  Yeah.

Speaker: SPEAKER_08
Transcript:  And in fact, I remember, I think it was, uh, Ev Williams or somebody admitted that they  should have done way more with lists.  It was such an obvious way of how people curate their streams and they just,  just ignored them forever.  It was like the redhead had stepped out of Twitter.

Speaker: SPEAKER_03
Transcript:  I use, uh, in twit deck, I make columns out of, so I have, for instance, here's a list of tech  journalists.  And so I just have the tech journalist list as one of the columns in tweet deck.  And that way I'm going to make sure I see all the tweets.  There's a way of doing that without, without tweet deck.

Speaker: SPEAKER_08
Transcript:  Basically.

Speaker: SPEAKER_03
Transcript:  Yeah.  Well, this is using list.  Yeah.

Speaker: SPEAKER_08
Transcript:  You can make them public.  Yep.

Speaker: SPEAKER_03
Transcript:  Nice.  Very nice.  So thank you.  Good.  Thank you, Twitter.

Speaker: SPEAKER_08
Transcript:  But get rid of the analysis as well.

Speaker: SPEAKER_03
Transcript:  Jeff Jarvis, do you have a number or a pick or something?

Speaker: SPEAKER_07
Transcript:  So I was going to talk about how Google has bought up almost all the real estate between  15th and 16th streets and eighth Avenue, the river to start our own little tech village  and how I actually think maybe they should put some apartments in there and I would have.

Speaker: SPEAKER_06
Transcript:  Oh, Toronto is saying he would happily live there.

Speaker: SPEAKER_03
Transcript:  Toronto is censoring.  Yes, I would.  Rogers has finally had it with Jeff.

Speaker: SPEAKER_07
Transcript:  But I'm not going to do, I'm not going to do that because it's an old joke.  Now.  So I just want to, so Benjamin Dreier, I mentioned before he's great on Twitter too.  His today he has a copy editing pro tip.  If you spit on the president's son today, tomorrow you can say that you spit on him  or that you spat on him.  Either is correct.

Speaker: SPEAKER_03
Transcript:  So past tense spit is spit or spat.

Speaker: SPEAKER_07
Transcript:  He would say spat.  You saw that story by the way.  Yes.

Speaker: SPEAKER_06
Transcript:  What if you spit on him in a spat?

Speaker: SPEAKER_03
Transcript:  If I'm having a spat with him and I spit on him, did I spit during the spat or spat  during the spat?  I don't know.  I spat during the spat.

Speaker: SPEAKER_08
Transcript:  Alternate usage is spoot.

Speaker: SPEAKER_03
Transcript:  I did not see that story, but I am not going to fall for your leftist plan.  That's right.  So there I presume that you will be glued to the television later this evening when  the 3000 candidates for president on the Democratic Party will be on stage each trying  to get one word in edgewise.  It'll be much like this show was.  Five hours.

Speaker: SPEAKER_08
Transcript:  Five hours.

Speaker: SPEAKER_06
Transcript:  No, I don't.  This was not five hours, was it?  No.  No.

Speaker: SPEAKER_08
Transcript:  I'm not hungry yet.  No, the debates are going to be fun.  Aren't they constrained?

Speaker: SPEAKER_03
Transcript:  I mean, aren't they like over when they can't have just keep going like this show can?  Sure they can.  They can?

Speaker: SPEAKER_06
Transcript:  No, they have a moderator.  That's what the moderator is for.  Yeah.

Speaker: SPEAKER_08
Transcript:  Hurry up.  Dream job.

Speaker: SPEAKER_03
Transcript:  I'll be the moderator.  Technology will be the topic.  Any bets on how many candidates will demand the breakup of Google?

Speaker: SPEAKER_07
Transcript:  Well, we know Warren.  Elizabeth Warren on tonight.  She will.  Yeah.  But don't you think that that will then make everybody else do that?

Speaker: SPEAKER_03
Transcript:  Like, oh, we got to keep up with the Warrens?

Speaker: SPEAKER_06
Transcript:  No, because a lot of their funding is going to come from these companies.

Speaker: SPEAKER_07
Transcript:  Oh.  Because they are, after all, all Democrats.

Speaker: SPEAKER_06
Transcript:  Oh, yes, all of them.  Man, I can't wait for people like, you know, the Uline people.  The problem is right now tech, tech is such a not, you know what?  Let's end the show.  We're good.  We're good.

Speaker: SPEAKER_05
Transcript:  Yeah.  I'm not going.

Speaker: SPEAKER_03
Transcript:  I'm not open to any more.  A bunch of words.  I don't know what the hell they mean, but I'm going to assume that they were cogent  and say thank you for your contribution.  Stacey Thistlebottom.  Hip, cherry-o.  Hello, Stacey.  Johnny Gord.  Stacey on iot.com is her website.  That's where you can sign up for a free newsletter on the Internet of Things.  You should also listen to her IOT podcast with Kevin Toffle every week.  And if I have not offended her to the marrow, she will be back next week  on This Week in Google.  Maybe.  Could be, perhaps, perchance.  I'm not easily offended.  Thank you, Stacey.  Thank you for being here and putting up with us old white men.  Chief of Wuhum is, of course, the great Jeff Jarvis, professor of journalism at CUNY.  The whitest, oldest white man around.

Speaker: SPEAKER_07
Transcript:  I think, though, I think we're of an age.

Speaker: SPEAKER_03
Transcript:  So I don't know if you can actually say you're the whitest, oldest man here.

Speaker: SPEAKER_07
Transcript:  But you know, my Chromebook camera sure beats the heck out of that independent camera.  I actually look like I'm human.  This one looks good.  It's doing well.

Speaker: SPEAKER_03
Transcript:  Yeah.  Yeah.  Nice.  Yeah.  Jeff.

Speaker: SPEAKER_06
Transcript:  Maybe you're just meant to be seen via Chromebook, Jeff.  Could be.

Speaker: SPEAKER_03
Transcript:  Will you be appearing on MSNBC or as a TV guide, former TV guide critic, anytime soon?

Speaker: SPEAKER_07
Transcript:  Nothing.  Nothing.  No schedule.  Nothing planned?

Speaker: SPEAKER_03
Transcript:  Okay.  Want to give you a chance to plug that.  And ladies and gentlemen, of course, the great Matthew Ingram.  He is in charge of digital writing and soon to win the fabulous  James W. Carey Award.  James W. Carey Award.  I shouldn't forget that name.  I used to work with a guy named James Carey.  He was a home of-  Jim Carey.  No, not Jim Carey.  James Carey.  He was one of the Carey brothers.  They were home improvement specialists.  But that's not the same one.  I don't think the James W. Carey Award for media ethics or something.  Thank you.

Speaker: SPEAKER_08
Transcript:  That's the official name or something.

Speaker: SPEAKER_03
Transcript:  Thank you.  Chief digital writer at CJR.org.  I'm just jealous, Matthew.  I'm just jealous.  That's all.  I'm just jealous.  Thank you all for joining us.  We do this week in Google.  The car wreck that it is every Wednesday, 1.30 Pacific, 4.30 Eastern.  I love it.  It's the messiest show we do and I love it.  20.30 UTC.  If you want to watch or listen live, you can do that at twit.tv slash live.  The chat room awaits if you're doing it live at irc.twit.tv.  A bunch of great people.  Congratulating Matthew right now on his major award.  We also invite you to get on demand versions at our website, twit.tv slash twig.  Or as I mentioned earlier, we really appreciate you supporting us by subscribing.  That way you'll get it automatically every single week, the minute it's available.  And then you don't have to worry.  You just say, hey, it's Thursday morning.  What can I listen to?  Oh yeah, twig.  Thanks everybody.  We'll see you next time on this week in Google.

