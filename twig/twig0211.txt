;FFMETADATA1
title=We Just Installed the Internet
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=211
genre=Podcast
comment=http://www.twit.tv/twig
copyright=These netcasts are released under a Creative Commons Attribution Non-Commercial Share-Alike license. TWiT and TWiT Logo are registered trademarks of Leo Laporte
publisher=TWiT
date=2013
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:02.240]   It's time for Twig this week in Google.
[00:00:02.240 --> 00:00:03.240]   What a great show.
[00:00:03.240 --> 00:00:04.800]   Bruce Schneier will join us.
[00:00:04.800 --> 00:00:09.240]   The many time lauded security guru expert
[00:00:09.240 --> 00:00:13.280]   to talk about the NSA privacy and what we can do about it.
[00:00:13.280 --> 00:00:15.200]   Kevin Marks, Matt Cutts from Google.
[00:00:15.200 --> 00:00:16.040]   Jeff Jarvis, too.
[00:00:16.040 --> 00:00:17.680]   A great twig is next.
[00:00:17.680 --> 00:00:23.040]   Netcast, you love.
[00:00:23.040 --> 00:00:24.400]   From people you trust.
[00:00:24.400 --> 00:00:29.760]   This is Twig.
[00:00:30.640 --> 00:00:34.480]   Bandwidth for this week in Google is provided by Cashfly,
[00:00:34.480 --> 00:00:37.880]   C-A-C-H-E-F-L-Y.com.
[00:00:37.880 --> 00:00:44.080]   This is Twig this week in Google,
[00:00:44.080 --> 00:00:48.280]   episode 211, recorded August 14, 2013.
[00:00:48.280 --> 00:00:50.320]   We just installed the internet.
[00:00:50.320 --> 00:00:54.000]   This week in Google is brought to you by LegalZoom.com.
[00:00:54.000 --> 00:00:56.640]   Visit LegalZoom.com for affordable legal solutions.
[00:00:56.640 --> 00:00:59.520]   You can trust LegalZoom can provide self-help services
[00:00:59.520 --> 00:01:02.720]   at your specific direction or connect you with an attorney.
[00:01:02.720 --> 00:01:04.440]   They're not a law firm, they're better.
[00:01:04.440 --> 00:01:07.560]   Visit LegalZoom.com and use the promo code Twig
[00:01:07.560 --> 00:01:10.800]   to receive $10 off at checkout.
[00:01:10.800 --> 00:01:13.480]   It's time for this week in Google to show the covers.
[00:01:13.480 --> 00:01:15.560]   Google the cloud, the Google version, anything.
[00:01:15.560 --> 00:01:17.000]   Frankly, Jeff and Gina.
[00:01:17.000 --> 00:01:18.160]   And I want to talk about it.
[00:01:18.160 --> 00:01:20.280]   And we just consider yourself warned.
[00:01:20.280 --> 00:01:23.560]   I'm Leo LaPorte joining us, Jeff Jarvis, as always.
[00:01:23.560 --> 00:01:26.800]   Professor of Journalism at the City University of New York.
[00:01:26.800 --> 00:01:29.120]   Author of what will Google do in his latest public parts.
[00:01:29.120 --> 00:01:30.920]   Look, he's zooming in.
[00:01:30.920 --> 00:01:31.920]   I'm not.
[00:01:31.920 --> 00:01:34.160]   Well, maybe we are.
[00:01:34.160 --> 00:01:35.760]   What are you building in there?
[00:01:35.760 --> 00:01:38.120]   It looks like you've got a scaffolding holding up the wall
[00:01:38.120 --> 00:01:38.960]   over your left shoulder.
[00:01:38.960 --> 00:01:42.680]   That's my Ikea thing for holding whiteboards.
[00:01:42.680 --> 00:01:43.400]   Oh, OK.
[00:01:43.400 --> 00:01:45.760]   Now I have on my windows trying to block the light
[00:01:45.760 --> 00:01:47.960]   so I don't look so incredibly white.
[00:01:47.960 --> 00:01:48.680]   Nice to have you.
[00:01:48.680 --> 00:01:49.400]   It's very pink.
[00:01:49.400 --> 00:01:50.320]   Now I look very white.
[00:01:50.320 --> 00:01:51.000]   I can't win.
[00:01:51.000 --> 00:01:52.920]   White is the man in journalism.
[00:01:52.920 --> 00:01:54.520]   Thanks for joining us.
[00:01:54.520 --> 00:01:56.000]   I'm the little higher.
[00:01:56.000 --> 00:01:58.800]   Gina has the day off today, but we've
[00:01:58.800 --> 00:01:59.960]   got some great replacements.
[00:01:59.960 --> 00:02:02.200]   Matt cuts from Google is here via audio.
[00:02:02.200 --> 00:02:03.120]   We'll get his video on a sec.
[00:02:03.120 --> 00:02:03.920]   Oh, and there he is.
[00:02:03.920 --> 00:02:05.800]   Hey, Matt.
[00:02:05.800 --> 00:02:08.040]   I like it because Matt's always sitting in a comfy chair
[00:02:08.040 --> 00:02:08.600]   when he joins.
[00:02:08.600 --> 00:02:09.600]   Always leaning back.
[00:02:09.600 --> 00:02:12.080]   He's always relaxed.
[00:02:12.080 --> 00:02:16.160]   Also with us, Kevin Marks of Salesforce.com, formerly
[00:02:16.160 --> 00:02:19.480]   of Google, Apple, and the BBC.
[00:02:19.480 --> 00:02:20.760]   Hey, Kevin.
[00:02:20.760 --> 00:02:23.000]   So Jeff, you have booked somebody I've
[00:02:23.000 --> 00:02:25.920]   been trying to get on Twitch for seven or eight years now.
[00:02:25.920 --> 00:02:30.360]   One of the premier guys in security.
[00:02:30.360 --> 00:02:34.800]   Frankly, if Bruce Schneier says it, I believe it,
[00:02:34.800 --> 00:02:40.680]   he, among other claims to fame, you helped Neil Gaiman--
[00:02:40.680 --> 00:02:45.040]   I'm sorry, Neil Stevenson was the crypto in crypto Nomicon,
[00:02:45.040 --> 00:02:45.240]   right?
[00:02:45.240 --> 00:02:47.360]   His card deck crypto.
[00:02:47.360 --> 00:02:51.120]   Yeah, I built a playing card cipher that he used in the plot.
[00:02:51.120 --> 00:02:53.880]   And the neat thing was I got to write an afterword in the book.
[00:02:53.880 --> 00:02:54.400]   So it was.
[00:02:54.400 --> 00:02:57.320]   The extra neat thing is I got to come and see him on some book
[00:02:57.320 --> 00:03:01.440]   signings and learn that cipherpunk writers get way better
[00:03:01.440 --> 00:03:04.800]   groupies than the part that they ever do.
[00:03:04.800 --> 00:03:07.440]   Bruce, it is such an honor to talk to you.
[00:03:07.440 --> 00:03:09.200]   Really, you are a legend in the business.
[00:03:09.200 --> 00:03:14.040]   And especially now more than ever, we need Bruce Schneier.
[00:03:14.040 --> 00:03:18.280]   S-C-H-N-E-I-E-R.com.
[00:03:18.280 --> 00:03:20.320]   If you want to read his blog, Schneier on security,
[00:03:20.320 --> 00:03:21.880]   there is really nobody who is more
[00:03:21.880 --> 00:03:27.680]   trenchant or accurate, entertaining even on the subject.
[00:03:27.680 --> 00:03:31.120]   So Jeff, since you were the guy who got us this great book,
[00:03:31.120 --> 00:03:34.480]   and I'll let you take the lead on this one.
[00:03:34.480 --> 00:03:35.040]   So much.
[00:03:35.040 --> 00:03:36.200]   We have so little time.
[00:03:36.200 --> 00:03:37.560]   We have Bruce to the top of the hour.
[00:03:37.560 --> 00:03:39.200]   But start here, Bruce.
[00:03:39.200 --> 00:03:41.240]   You wrote a great piece for the Atlantic.
[00:03:41.240 --> 00:03:43.240]   And about a topic that I was trying to tackle too,
[00:03:43.240 --> 00:03:45.880]   but you frankly did it far better than I did,
[00:03:45.880 --> 00:03:49.160]   is the fear that the NSA is commandeering the net.
[00:03:49.160 --> 00:03:51.000]   I was thinking about it in terms of what they're doing,
[00:03:51.000 --> 00:03:53.000]   maybe to individual companies where
[00:03:53.000 --> 00:03:54.760]   there are people with security clearance
[00:03:54.760 --> 00:03:55.920]   and their bosses don't have it.
[00:03:55.920 --> 00:03:57.520]   They don't know what they're doing inside the company.
[00:03:57.520 --> 00:03:59.760]   And I couldn't figure out how to express that.
[00:03:59.760 --> 00:04:02.200]   And you just came up with a very clear review
[00:04:02.200 --> 00:04:05.320]   that they're just plain commandeering the internet.
[00:04:05.320 --> 00:04:07.720]   And then you're also arguing that what technology companies--
[00:04:07.720 --> 00:04:09.440]   it's time for them to fight back.
[00:04:09.440 --> 00:04:11.800]   Why don't you talk about that for a second?
[00:04:11.800 --> 00:04:15.760]   It's really part of this very broad trend of surveillance
[00:04:15.760 --> 00:04:16.880]   being everywhere.
[00:04:16.880 --> 00:04:19.320]   I mean, if you think about it, surveillance
[00:04:19.320 --> 00:04:20.760]   is the business model of the internet.
[00:04:20.760 --> 00:04:22.680]   I mean, that's how Google makes its money.
[00:04:22.680 --> 00:04:25.600]   It surveils us and serves us personalized ads.
[00:04:25.600 --> 00:04:27.080]   That's how Facebook makes its money.
[00:04:27.080 --> 00:04:28.560]   That's everyone's making their money
[00:04:28.560 --> 00:04:31.680]   by mining us for our data and then buying, selling,
[00:04:31.680 --> 00:04:32.840]   and using it.
[00:04:32.840 --> 00:04:37.240]   Then it turns out that the government wants access to it too.
[00:04:37.240 --> 00:04:40.080]   And stuff they can't get for legal reasons
[00:04:40.080 --> 00:04:41.880]   or technical reasons, they're learning
[00:04:41.880 --> 00:04:43.760]   to get from these corporations.
[00:04:43.760 --> 00:04:45.400]   Either they're asking nicely.
[00:04:45.400 --> 00:04:48.080]   We've seen example, after example, of companies
[00:04:48.080 --> 00:04:50.120]   willingly subverting their security
[00:04:50.120 --> 00:04:54.200]   or willingly handing the NSA copies of everything.
[00:04:54.200 --> 00:04:55.800]   They'll do it to national security letters.
[00:04:55.800 --> 00:04:57.800]   They'll force companies to do it.
[00:04:57.800 --> 00:05:00.560]   Kalea is something that's going through Congress,
[00:05:00.560 --> 00:05:04.200]   running with the FBI, has gotten phone companies
[00:05:04.200 --> 00:05:07.120]   to make their networks eavesdropping ready.
[00:05:07.120 --> 00:05:09.840]   So I mean, I think of this as a public-private surveillance
[00:05:09.840 --> 00:05:11.480]   partnership.
[00:05:11.480 --> 00:05:14.560]   So yes, the NSA is coming during the internet
[00:05:14.560 --> 00:05:16.200]   for its own purposes.
[00:05:16.200 --> 00:05:22.000]   But also, companies are surveilling us for their own purposes
[00:05:22.000 --> 00:05:24.480]   and using law to protect them.
[00:05:24.480 --> 00:05:27.600]   So it kind of goes both ways, unfortunately.
[00:05:27.600 --> 00:05:29.240]   First, I've always been much more worried, though,
[00:05:29.240 --> 00:05:34.320]   about a government surveilling us than about private corporations
[00:05:34.320 --> 00:05:37.160]   trying to sell us.
[00:05:37.160 --> 00:05:39.600]   Doesn't that seem a little bit more nefarious?
[00:05:39.600 --> 00:05:43.400]   Well, I mean, sell us is just the beginning of it.
[00:05:43.400 --> 00:05:46.080]   It's being used to deny people loans
[00:05:46.080 --> 00:05:47.200]   to deny people banking--
[00:05:47.200 --> 00:05:48.040]   Redlining.
[00:05:48.040 --> 00:05:49.480]   Digital redlining.
[00:05:49.480 --> 00:05:54.000]   But redlining, not just even denying people access to banking.
[00:05:54.000 --> 00:05:57.440]   There's an article recently about people
[00:05:57.440 --> 00:06:00.840]   judged by computer algorithms and being denied bank accounts.
[00:06:00.840 --> 00:06:04.080]   So now they're forced to use these more expensive unbanks
[00:06:04.080 --> 00:06:05.760]   and check-cashing services.
[00:06:05.760 --> 00:06:08.520]   You know, these corporations are not
[00:06:08.520 --> 00:06:11.160]   just selling us consumer products.
[00:06:11.160 --> 00:06:12.880]   They're very much controlling our lives.
[00:06:12.880 --> 00:06:16.320]   If you can't get a cell phone, you
[00:06:16.320 --> 00:06:17.680]   can't live the same life.
[00:06:17.680 --> 00:06:19.520]   You can't get a credit card.
[00:06:19.520 --> 00:06:22.840]   So looking at corporate power, it's different than government
[00:06:22.840 --> 00:06:23.360]   power.
[00:06:23.360 --> 00:06:26.400]   But corporate power is pretty darn extreme.
[00:06:26.400 --> 00:06:26.920]   And--
[00:06:26.920 --> 00:06:28.880]   Go ahead.
[00:06:28.880 --> 00:06:30.040]   Sorry.
[00:06:30.040 --> 00:06:34.000]   No, I mean, I just really see both types of power
[00:06:34.000 --> 00:06:35.160]   working together.
[00:06:35.160 --> 00:06:37.760]   And this is weird libertarian fantasy
[00:06:37.760 --> 00:06:39.680]   that if a government does something, it's bad.
[00:06:39.680 --> 00:06:42.480]   And then if a corporation does it, it magically becomes good.
[00:06:42.480 --> 00:06:45.840]   It actually had to look at the thing and not
[00:06:45.840 --> 00:06:50.000]   who writes the paycheck of the people in power that are doing it.
[00:06:50.000 --> 00:06:52.720]   Yeah, I'm more afraid of guns, though, than I am of redlining.
[00:06:52.720 --> 00:06:55.800]   But I'll acknowledge that both are problems.
[00:06:55.800 --> 00:06:56.560]   How do you fight it?
[00:06:56.560 --> 00:07:01.080]   Right now, the rock paper scissors in Egypt
[00:07:01.080 --> 00:07:03.280]   is the army always wins over the internet.
[00:07:03.280 --> 00:07:04.280]   Right.
[00:07:04.280 --> 00:07:08.520]   You know, they continue on with Leo's question, Bruce.
[00:07:08.520 --> 00:07:11.160]   When I talked to Vince Serf about this Guardian
[00:07:11.160 --> 00:07:12.880]   in fact, of 8 in London, someone asked him
[00:07:12.880 --> 00:07:15.960]   whether the solution of this is technological or institutional.
[00:07:15.960 --> 00:07:19.400]   That is to say laws and policy and principles.
[00:07:19.400 --> 00:07:22.640]   How far does the technological solution take us here?
[00:07:22.640 --> 00:07:23.920]   And what are its limitations?
[00:07:23.920 --> 00:07:26.320]   And how do we solve it institutionally?
[00:07:26.320 --> 00:07:28.560]   So I don't think a technology takes us very far at all.
[00:07:28.560 --> 00:07:29.760]   And so here's a great example.
[00:07:29.760 --> 00:07:31.360]   I'm asking email all the time.
[00:07:31.360 --> 00:07:33.200]   I want to use a secure email service.
[00:07:33.200 --> 00:07:34.520]   Who should I use?
[00:07:34.520 --> 00:07:36.240]   And the truth is I don't know.
[00:07:36.240 --> 00:07:38.640]   I don't know what companies have
[00:07:38.640 --> 00:07:40.440]   been subverted by the government.
[00:07:40.440 --> 00:07:43.080]   What claims are true or claims are lying.
[00:07:43.080 --> 00:07:47.520]   Last week we saw two small secure email services.
[00:07:47.520 --> 00:07:49.840]   Lava bit and--
[00:07:49.840 --> 00:07:50.840]   Silence circle.
[00:07:50.840 --> 00:07:52.080]   Silence circle.
[00:07:52.080 --> 00:07:52.560]   Shores on circle.
[00:07:52.560 --> 00:07:53.560]   Shores on circle.
[00:07:53.560 --> 00:07:53.920]   Right.
[00:07:53.920 --> 00:07:55.440]   They shut themselves down.
[00:07:55.440 --> 00:07:58.920]   One after they received national security letters, one
[00:07:58.920 --> 00:08:00.360]   before.
[00:08:00.360 --> 00:08:03.640]   And so these independents are going away.
[00:08:03.640 --> 00:08:06.360]   What's left of the big corporations that really
[00:08:06.360 --> 00:08:08.840]   have no choice but to cooperate.
[00:08:08.840 --> 00:08:11.680]   So the technology only takes you so far,
[00:08:11.680 --> 00:08:13.040]   but you can't trust the technology
[00:08:13.040 --> 00:08:15.040]   because you can't trust anybody's claims.
[00:08:15.040 --> 00:08:18.720]   These are very much political problems.
[00:08:18.720 --> 00:08:20.280]   And the solutions are going to be political.
[00:08:20.280 --> 00:08:22.920]   Now once we have the correct politics in place,
[00:08:22.920 --> 00:08:24.920]   there's a lot technology can do because there
[00:08:24.920 --> 00:08:26.360]   are a lot of tech problems.
[00:08:26.360 --> 00:08:29.720]   But they are subservient to the political problems.
[00:08:29.720 --> 00:08:30.600]   Right now--
[00:08:30.600 --> 00:08:32.720]   Which goes to your point.
[00:08:32.720 --> 00:08:33.680]   Goes to your point--
[00:08:33.680 --> 00:08:35.640]   I'm trying to get the tech companies to fight now
[00:08:35.640 --> 00:08:37.680]   that if they want to prove who's side they're on,
[00:08:37.680 --> 00:08:39.800]   are they on our side, or are they collaborators
[00:08:39.800 --> 00:08:42.200]   with the government, or are they victimism, it's overreach?
[00:08:42.200 --> 00:08:44.200]   But isn't an am meaningless question.
[00:08:44.200 --> 00:08:46.080]   I think Bruce is probably right.
[00:08:46.080 --> 00:08:47.200]   They are collaborators.
[00:08:47.200 --> 00:08:49.560]   But even if they weren't, they don't have--
[00:08:49.560 --> 00:08:51.600]   NSL-- and I know Matt Cutts works at Google,
[00:08:51.600 --> 00:08:53.520]   so he's going to chime in there.
[00:08:53.520 --> 00:08:55.840]   But even if they weren't--
[00:08:55.840 --> 00:08:58.000]   I think it's moot because even if they weren't,
[00:08:58.000 --> 00:08:59.640]   the law requires them to participate.
[00:08:59.640 --> 00:09:00.960]   And because they're public companies,
[00:09:00.960 --> 00:09:04.480]   they can't do as Lava bit and Silence circle did shut down.
[00:09:04.480 --> 00:09:05.920]   They have to keep cooperating.
[00:09:05.920 --> 00:09:07.000]   They have to cooperate.
[00:09:07.000 --> 00:09:08.360]   They have to cooperate.
[00:09:08.360 --> 00:09:11.320]   Well, just as they had to cooperate in China.
[00:09:11.320 --> 00:09:12.880]   They don't have to cooperate willingly.
[00:09:12.880 --> 00:09:14.920]   They don't have to do more than the law allows.
[00:09:14.920 --> 00:09:16.640]   And they don't have to go silently.
[00:09:16.640 --> 00:09:22.240]   So both Yahoo and Google have been great at fighting back.
[00:09:22.240 --> 00:09:25.280]   And they will-- they mostly lose.
[00:09:25.280 --> 00:09:27.360]   It's sometimes we win.
[00:09:27.360 --> 00:09:29.080]   Bruce decaled the internet archive
[00:09:29.080 --> 00:09:31.200]   for the national security letter and won.
[00:09:31.200 --> 00:09:33.280]   And his story was in the New Yorker, I think,
[00:09:33.280 --> 00:09:35.400]   last year, earlier this year.
[00:09:35.400 --> 00:09:38.640]   And there are sort of only way to beat this back
[00:09:38.640 --> 00:09:39.960]   is to fight back.
[00:09:39.960 --> 00:09:42.040]   And even if you lose, you're going
[00:09:42.040 --> 00:09:46.040]   to lose on the narrowness of the letter.
[00:09:46.040 --> 00:09:47.360]   You're not going to cooperate more.
[00:09:47.360 --> 00:09:49.000]   There's a lot of articles now of companies
[00:09:49.000 --> 00:09:51.400]   that are cooperating because they're afraid if they get
[00:09:51.400 --> 00:09:54.160]   the letter, it'll be more annoying and more expensive.
[00:09:54.160 --> 00:09:55.720]   And it turns out not to be true.
[00:09:55.720 --> 00:09:56.720]   You fight.
[00:09:56.720 --> 00:09:58.320]   You keep the moral high ground.
[00:09:58.320 --> 00:10:01.280]   When this is all exposed, like, you know, what happened to Yahoo,
[00:10:01.280 --> 00:10:03.000]   what's happened to Google, we're all
[00:10:03.000 --> 00:10:05.440]   thinking, well, these companies are fighting for us.
[00:10:05.440 --> 00:10:08.600]   So even if they lose, I'm going to trust them more
[00:10:08.600 --> 00:10:10.880]   than I will, a company that isn't fighting.
[00:10:10.880 --> 00:10:17.840]   I also consider that we don't know what's going on because
[00:10:17.840 --> 00:10:24.160]   of the silence requirements of many NSL.
[00:10:24.160 --> 00:10:27.840]   So it may be much more than we even know.
[00:10:27.840 --> 00:10:29.360]   And they can't--
[00:10:29.360 --> 00:10:30.960]   And it probably is.
[00:10:30.960 --> 00:10:33.200]   A lot of these silence requirements are being fought,
[00:10:33.200 --> 00:10:35.360]   and sometimes successfully.
[00:10:35.360 --> 00:10:35.880]   That's a--
[00:10:35.880 --> 00:10:38.320]   But I ask your letters to go away, but the gag order does.
[00:10:38.320 --> 00:10:39.240]   I look at Law of the--
[00:10:39.240 --> 00:10:41.880]   --the reporter-- --with founder who apparently got something,
[00:10:41.880 --> 00:10:44.280]   but is so constrained about what he can talk about.
[00:10:44.280 --> 00:10:47.160]   He has to sit there with a lawyer next to him saying,
[00:10:47.160 --> 00:10:48.960]   no, whispering back and forth.
[00:10:48.960 --> 00:10:49.520]   What can you say?
[00:10:49.520 --> 00:10:50.680]   What can't you say?
[00:10:50.680 --> 00:10:53.480]   He risks prison by saying anything.
[00:10:53.480 --> 00:10:53.920]   That's right.
[00:10:53.920 --> 00:10:54.640]   But the company's--
[00:10:54.640 --> 00:10:56.280]   It's no change.
[00:10:56.280 --> 00:10:58.880]   And they can stand up and say what ought to be.
[00:10:58.880 --> 00:11:01.600]   If they get away from specifics of the cases against them,
[00:11:01.600 --> 00:11:03.720]   the companies need to stand up on the basis of principle
[00:11:03.720 --> 00:11:06.400]   and say, this is what we'll fight.
[00:11:06.400 --> 00:11:08.400]   This is what will stand up for you.
[00:11:08.400 --> 00:11:10.320]   You can be assured that we will do this for that.
[00:11:10.320 --> 00:11:11.360]   Because if they don't even say that,
[00:11:11.360 --> 00:11:12.640]   right now they're being silent.
[00:11:12.640 --> 00:11:14.600]   The companies are not coming out and saying much of anything.
[00:11:14.600 --> 00:11:16.240]   And that doesn't lead to trust.
[00:11:16.240 --> 00:11:19.200]   Plus, we, the users, have to give them cover.
[00:11:19.200 --> 00:11:20.960]   We have to demand that they fight.
[00:11:20.960 --> 00:11:22.360]   So they can say that the government, amen,
[00:11:22.360 --> 00:11:23.840]   we're caught in the middle here.
[00:11:23.840 --> 00:11:27.240]   Bruce's most recent book was about trust.
[00:11:27.240 --> 00:11:28.440]   It couldn't have been more timely.
[00:11:28.440 --> 00:11:31.800]   It came out last year, but you couldn't be more timely.
[00:11:31.800 --> 00:11:34.040]   I don't know if we can trust anybody at this point.
[00:11:34.040 --> 00:11:37.440]   And when you see, for instance, the FISA Court itself
[00:11:37.440 --> 00:11:41.440]   two years ago trying to put out a report saying
[00:11:41.440 --> 00:11:43.000]   that the government is overreaching
[00:11:43.000 --> 00:11:47.000]   and then that being quashed by the Department of Justice,
[00:11:47.000 --> 00:11:49.320]   it is all being suppressed at this point,
[00:11:49.320 --> 00:11:51.440]   as much as the government can.
[00:11:51.440 --> 00:11:51.880]   There is.
[00:11:51.880 --> 00:11:54.240]   And it's actually-- it really amazes me
[00:11:54.240 --> 00:11:58.760]   that the NSA had no contingency plans for our secret programs
[00:11:58.760 --> 00:12:00.680]   get on the front page of the newspaper.
[00:12:00.680 --> 00:12:06.120]   You'd think with the major budget and security mindset
[00:12:06.120 --> 00:12:09.840]   that it have some plan B. Here it is about a couple of months
[00:12:09.840 --> 00:12:13.800]   after General Alexander was at Black Hat.
[00:12:13.800 --> 00:12:16.080]   And like the best he could do was explain
[00:12:16.080 --> 00:12:20.360]   how the FISA Court works, talk about this Iranian cab driver
[00:12:20.360 --> 00:12:22.560]   who has sent $5,000 back home.
[00:12:22.560 --> 00:12:24.840]   I mean, this is his defense.
[00:12:24.840 --> 00:12:28.840]   It just amazes me how flat-footed they were caught
[00:12:28.840 --> 00:12:32.720]   and how even now they're just making it up
[00:12:32.720 --> 00:12:35.200]   as they go along, hoping for the best.
[00:12:35.200 --> 00:12:37.960]   And they have to believe that these thousands of documents
[00:12:37.960 --> 00:12:40.960]   are going to become public, all of them, sometimes soon.
[00:12:40.960 --> 00:12:45.400]   It's just not going to stay undercover much longer.
[00:12:45.400 --> 00:12:49.600]   So could I take a little bit of the worry
[00:12:49.600 --> 00:12:51.360]   that we're painting with a little bit of a broad brush?
[00:12:51.360 --> 00:12:52.920]   That cuts from Google.
[00:12:52.920 --> 00:12:53.880]   Go ahead, Matt.
[00:12:53.880 --> 00:12:56.040]   Yeah, and I don't know whether my video can come through or not.
[00:12:56.040 --> 00:12:57.720]   If my video does come through, I'm actually
[00:12:57.720 --> 00:13:00.680]   holding up a copy of Bruce's book.
[00:13:00.680 --> 00:13:02.000]   Liars and outliers.
[00:13:02.000 --> 00:13:02.520]   Good.
[00:13:02.520 --> 00:13:03.240]   You're reading it.
[00:13:03.240 --> 00:13:03.960]   That's excellent.
[00:13:03.960 --> 00:13:05.520]   Well, this one's actually--
[00:13:05.520 --> 00:13:08.280]   Oh, the other one's Shira is security, which is the classic.
[00:13:08.280 --> 00:13:09.720]   Yeah, I have that too.
[00:13:09.720 --> 00:13:11.480]   I am a fan.
[00:13:11.480 --> 00:13:13.680]   So I very much enjoy and agree with that.
[00:13:13.680 --> 00:13:14.520]   That's a must-have.
[00:13:14.520 --> 00:13:16.960]   Security theater.
[00:13:16.960 --> 00:13:19.680]   But I do think we don't want to paint with two broad of a brush,
[00:13:19.680 --> 00:13:22.200]   like talking about collaborators and talking
[00:13:22.200 --> 00:13:25.040]   about private public partnership on some of this stuff.
[00:13:25.040 --> 00:13:27.840]   Because from a lot of the coverage,
[00:13:27.840 --> 00:13:29.840]   you get the idea, the sense that a lot of this
[00:13:29.840 --> 00:13:32.880]   is more like a shotgun wedding, where companies are compelled to.
[00:13:32.880 --> 00:13:36.320]   And I think you can look at the history of companies
[00:13:36.320 --> 00:13:38.560]   and get a sense for which ones are fighting for you,
[00:13:38.560 --> 00:13:41.720]   versus which ones are like, hey, please give us a government
[00:13:41.720 --> 00:13:44.800]   request so we can hand over all the phone-calling records
[00:13:44.800 --> 00:13:45.800]   of various Americans.
[00:13:45.800 --> 00:13:49.520]   So for example, Google was one of the first to really double
[00:13:49.520 --> 00:13:52.840]   down on encryption, both of Gmail and on Search.
[00:13:52.840 --> 00:13:57.440]   Whenever we got a 2005 Department of Justice,
[00:13:57.440 --> 00:14:00.360]   subpoena that wanted to turn over two months of users' queries
[00:14:00.360 --> 00:14:04.000]   for a lawsuit related to pornography, we fought that,
[00:14:04.000 --> 00:14:06.600]   and we won, and 33 other companies didn't fight that.
[00:14:06.600 --> 00:14:08.640]   We've been very big on two-factor authentication.
[00:14:08.640 --> 00:14:11.560]   There's an article in Wired that talks about a little device
[00:14:11.560 --> 00:14:14.200]   that lets you do two-factor authentication a little bit better.
[00:14:14.200 --> 00:14:19.160]   So I think to say that all these companies are just
[00:14:19.160 --> 00:14:22.840]   falling over themselves on this topic to help out the government
[00:14:22.840 --> 00:14:24.360]   is not a correct characterization.
[00:14:24.360 --> 00:14:26.720]   I think a lot of engineers in Silicon Valley
[00:14:26.720 --> 00:14:28.560]   are thinking about different ways that they
[00:14:28.560 --> 00:14:32.680]   can try to protect users' rights and protect security and privacy
[00:14:32.680 --> 00:14:34.600]   as best they can.
[00:14:34.600 --> 00:14:37.240]   It was really wild to watch the events around Lava Bit.
[00:14:37.240 --> 00:14:39.240]   And I think hopefully that will give a lot of people
[00:14:39.240 --> 00:14:42.440]   in the government pause and make them think a little bit
[00:14:42.440 --> 00:14:44.160]   about just what they're doing.
[00:14:44.160 --> 00:14:46.840]   They're really removing a lot of trust in the internet
[00:14:46.840 --> 00:14:47.960]   and in the cloud.
[00:14:47.960 --> 00:14:49.760]   Yes, that's wrong.
[00:14:49.760 --> 00:14:52.960]   You know, CDT just came out with, I guess, a blog post.
[00:14:52.960 --> 00:14:56.000]   And they have been fighting the extension of Kalea.
[00:14:56.000 --> 00:14:59.360]   Kalea is the law that required phone companies
[00:14:59.360 --> 00:15:02.000]   to make their phone switches eavesdropping friendly.
[00:15:02.000 --> 00:15:04.120]   And the FBI's were trying to extend that law
[00:15:04.120 --> 00:15:06.720]   to the things like Gmail.
[00:15:06.720 --> 00:15:09.920]   And it's being fought, the law hasn't passed.
[00:15:09.920 --> 00:15:13.600]   But CDT's pointing out that these attacks
[00:15:13.600 --> 00:15:16.120]   against the smaller companies that are really forcing them
[00:15:16.120 --> 00:15:19.160]   to close or collaborate, the inability for the larger
[00:15:19.160 --> 00:15:23.320]   companies to close so they have to basically hand over NSA data
[00:15:23.320 --> 00:15:26.120]   and then light their customers about it,
[00:15:26.120 --> 00:15:30.640]   is effectively getting this actually Kalea extension passed
[00:15:30.640 --> 00:15:33.480]   without the trouble of going through Congress.
[00:15:33.480 --> 00:15:37.400]   That effectively, right, all we have left are the large companies.
[00:15:37.400 --> 00:15:39.160]   And it's sort of impossible.
[00:15:39.160 --> 00:15:41.440]   You can't imagine Mark Zuckerberg saying, well,
[00:15:41.440 --> 00:15:42.720]   we're just not going to comply.
[00:15:42.720 --> 00:15:44.120]   We're going to shut Facebook down.
[00:15:44.120 --> 00:15:45.680]   That's what we have to do.
[00:15:45.680 --> 00:15:46.520]   He can't do that.
[00:15:46.520 --> 00:15:47.800]   It's a large public company.
[00:15:47.800 --> 00:15:48.880]   He'd be fired.
[00:15:48.880 --> 00:15:50.840]   They'd find a less moral CEO.
[00:15:50.840 --> 00:15:51.600]   And they'd keep going.
[00:15:51.600 --> 00:15:51.800]   Right?
[00:15:51.800 --> 00:15:53.320]   And it would continue.
[00:15:53.320 --> 00:15:56.480]   So we're now entering a world where you only
[00:15:56.480 --> 00:15:58.760]   have the big companies that collaborate.
[00:15:58.760 --> 00:16:01.760]   And they're forced to in some fight and some don't.
[00:16:01.760 --> 00:16:05.080]   And maybe we win around the edges, but largely we lose.
[00:16:05.080 --> 00:16:08.280]   And no small companies left.
[00:16:08.280 --> 00:16:08.920]   And that's--
[00:16:08.920 --> 00:16:11.120]   Let me ask you another question, though,
[00:16:11.120 --> 00:16:13.120]   since you're the technologist here.
[00:16:13.120 --> 00:16:15.760]   In my field in journalism, we yammer on a lot
[00:16:15.760 --> 00:16:16.840]   about professional ethics.
[00:16:16.840 --> 00:16:20.520]   And I have threatened to quit jobs over matters of ethics.
[00:16:20.520 --> 00:16:22.720]   And I know a lot of people who have.
[00:16:22.720 --> 00:16:27.040]   And I know that Janetton Zolotarov, right?
[00:16:27.040 --> 00:16:28.240]   No, Janetton Zoner.
[00:16:28.240 --> 00:16:28.760]   Yeah, Janetton.
[00:16:28.760 --> 00:16:32.560]   The architect of Google+ wrote a great post saying, listen,
[00:16:32.560 --> 00:16:33.880]   the thing you have to trust here is
[00:16:33.880 --> 00:16:36.160]   that if this stuff were going on and I knew about it,
[00:16:36.160 --> 00:16:38.000]   I'd leave the company.
[00:16:38.000 --> 00:16:40.840]   How much discussion is there among technologists?
[00:16:40.840 --> 00:16:43.240]   Is there enough, do you think, about the ethics
[00:16:43.240 --> 00:16:44.680]   of a technologist?
[00:16:44.680 --> 00:16:47.200]   And how much can we trust those individuals?
[00:16:47.200 --> 00:16:48.760]   Is that where the wellspring of reaction
[00:16:48.760 --> 00:16:50.960]   is going to come up and say, no, I refuse to do that,
[00:16:50.960 --> 00:16:54.040]   or I'll have to quit or whatever?
[00:16:54.040 --> 00:16:55.600]   Where does it get down to the individual
[00:16:55.600 --> 00:16:57.560]   or the individual of them, the company who has security
[00:16:57.560 --> 00:17:00.480]   clearance, who's treated differently from everybody else?
[00:17:00.480 --> 00:17:01.960]   Well, thank goodness for the Edward Snowden's
[00:17:01.960 --> 00:17:06.880]   and the Lidar Levissons of Lava Bit of the World, who
[00:17:06.880 --> 00:17:10.880]   have put their, in a way, put their life on the line.
[00:17:10.880 --> 00:17:13.360]   Is there discussion of these ethical principles
[00:17:13.360 --> 00:17:17.360]   among developers, technologists, security people, and so on?
[00:17:17.360 --> 00:17:19.960]   Yeah, certainly within Google, I think it's safe to say,
[00:17:19.960 --> 00:17:21.960]   this is hotly debated.
[00:17:21.960 --> 00:17:24.000]   And every week, we have weekly discussions
[00:17:24.000 --> 00:17:27.360]   where we can ask larian-surge questions.
[00:17:27.360 --> 00:17:31.160]   And it's entirely safe to say that even though we might not
[00:17:31.160 --> 00:17:34.280]   say that much externally, because there's
[00:17:34.280 --> 00:17:36.720]   discipline about external communications,
[00:17:36.720 --> 00:17:39.160]   you can believe any hot topic outside of Google
[00:17:39.160 --> 00:17:42.120]   gets a firestorm of debate inside of Google.
[00:17:42.120 --> 00:17:44.440]   And so that's an entirely safe assumption.
[00:17:44.440 --> 00:17:46.600]   I assume that happens at a lot of companies as well.
[00:17:46.600 --> 00:17:54.680]   So the president gave a press conference last Friday,
[00:17:54.680 --> 00:17:56.800]   and he talked about-- he did a couple of things,
[00:17:56.800 --> 00:17:58.640]   which I applaud him for.
[00:17:58.640 --> 00:18:01.560]   One is acknowledged while he said,
[00:18:01.560 --> 00:18:05.480]   while our national law enforcement agencies are patriots
[00:18:05.480 --> 00:18:07.080]   and trying to protect our country,
[00:18:07.080 --> 00:18:09.080]   he also said-- and I hope he believes this--
[00:18:09.080 --> 00:18:12.960]   that those who are fighting for privacy
[00:18:12.960 --> 00:18:18.480]   are also patriots and fighting for very fundamental constitutional
[00:18:18.480 --> 00:18:20.280]   tenets in this country.
[00:18:20.280 --> 00:18:22.440]   He also said-- and I thought this was really telling--
[00:18:22.440 --> 00:18:26.400]   we have an unprecedented ability to gather this information.
[00:18:26.400 --> 00:18:29.240]   And I think perhaps what happened
[00:18:29.240 --> 00:18:32.920]   is that unprecedented ability to gather the information,
[00:18:32.920 --> 00:18:35.040]   snuck up on us.
[00:18:35.040 --> 00:18:36.520]   And we got this ability.
[00:18:36.520 --> 00:18:38.680]   And of course, somebody whose job is to protect the country
[00:18:38.680 --> 00:18:41.600]   is going to embrace anything.
[00:18:41.600 --> 00:18:44.040]   And the problem is the controls and the oversight
[00:18:44.040 --> 00:18:46.920]   have not been there, have not kept up.
[00:18:46.920 --> 00:18:51.760]   Is it enough to say to Congress, let's get this under control?
[00:18:51.760 --> 00:18:53.080]   I mean, you can say it.
[00:18:53.080 --> 00:18:55.360]   It has to get done.
[00:18:55.360 --> 00:18:55.920]   So Obama has to--
[00:18:55.920 --> 00:18:58.160]   Well, what else should we do?
[00:18:58.160 --> 00:19:00.360]   I agree that's probably the mechanism,
[00:19:00.360 --> 00:19:01.520]   or at least one of the mechanisms.
[00:19:01.520 --> 00:19:02.560]   Are there other mechanisms?
[00:19:02.560 --> 00:19:04.200]   There are court cases going through.
[00:19:04.200 --> 00:19:06.440]   Obama said he'd do four things.
[00:19:06.440 --> 00:19:08.560]   And of course, the proof is in the pudding.
[00:19:08.560 --> 00:19:11.040]   Talk about reforming Section 215 of the Patriot Act.
[00:19:11.040 --> 00:19:12.640]   That's the section that has to deal
[00:19:12.640 --> 00:19:14.280]   with national security letters.
[00:19:14.280 --> 00:19:16.800]   So what does that mean we don't know?
[00:19:16.800 --> 00:19:19.280]   To increase transparency, the FISA court--
[00:19:19.280 --> 00:19:22.280]   I mean, it's a good idea, but the devil's in the details.
[00:19:22.280 --> 00:19:24.480]   The third is to make more information public,
[00:19:24.480 --> 00:19:26.360]   as can be made public.
[00:19:26.360 --> 00:19:28.000]   Again, good idea.
[00:19:28.000 --> 00:19:31.080]   And fourth is to appoint some kind of independent review
[00:19:31.080 --> 00:19:33.840]   board, which is either a good idea or a way
[00:19:33.840 --> 00:19:37.360]   to make the problem go away and put in a document.
[00:19:37.360 --> 00:19:41.520]   So these are four generalizations.
[00:19:41.520 --> 00:19:42.920]   The details matter.
[00:19:42.920 --> 00:19:45.840]   I mean, yes, Congress could do a lot.
[00:19:45.840 --> 00:19:48.840]   We saw a few weeks ago, the House
[00:19:48.840 --> 00:19:52.680]   tried to unfund one particular NSA surveillance program, the one
[00:19:52.680 --> 00:19:55.920]   that collects phone metadata of every American.
[00:19:55.920 --> 00:19:58.400]   That failed, but failed very narrowly.
[00:19:58.400 --> 00:20:00.040]   There are things the courts could do.
[00:20:00.040 --> 00:20:05.800]   EFF, ACLU, EPIC are all filing lawsuits
[00:20:05.800 --> 00:20:07.800]   trying to challenge the constitutionality
[00:20:07.800 --> 00:20:09.840]   of this aspect of that aspect.
[00:20:09.840 --> 00:20:11.160]   Those are ways.
[00:20:11.160 --> 00:20:13.280]   There's a lot of public pressure now.
[00:20:13.280 --> 00:20:15.440]   I mean, Congressmen are feeling this.
[00:20:15.440 --> 00:20:17.200]   The president is feeling this.
[00:20:17.200 --> 00:20:18.680]   And views are changing.
[00:20:18.680 --> 00:20:24.840]   Even some of the Congressmen and senators
[00:20:24.840 --> 00:20:30.280]   who are pretty much on the side of security at all costs
[00:20:30.280 --> 00:20:34.080]   and don't really care about this are starting to change.
[00:20:34.080 --> 00:20:35.880]   So there's a lot we can do.
[00:20:35.880 --> 00:20:37.480]   You have to just push it all fronts.
[00:20:37.480 --> 00:20:38.280]   Yeah.
[00:20:38.280 --> 00:20:39.800]   Is it enough or those four things
[00:20:39.800 --> 00:20:42.240]   enough presuming they're done properly?
[00:20:42.240 --> 00:20:45.280]   Or is there more that you would like?
[00:20:45.280 --> 00:20:49.000]   I think fundamentally, our privacy laws are outdated.
[00:20:49.000 --> 00:20:50.240]   I mean, it's what you said.
[00:20:50.240 --> 00:20:52.600]   Technology continues to advance.
[00:20:52.600 --> 00:20:57.080]   The FBI, the NSA are continually grabbing this new technology
[00:20:57.080 --> 00:21:00.520]   because it's a gray area and not really covered under the law.
[00:21:00.520 --> 00:21:05.320]   They assume the most broad, expansive powers they can think of.
[00:21:05.320 --> 00:21:09.240]   And because the law is written in the '80s,
[00:21:09.240 --> 00:21:11.000]   or sometimes even the early '90s.
[00:21:11.000 --> 00:21:12.560]   Sometimes the 1880s.
[00:21:12.560 --> 00:21:15.480]   You know, it's not that bad, but it's still pretty bad.
[00:21:15.480 --> 00:21:17.560]   It's still pretty internet.
[00:21:17.560 --> 00:21:22.200]   So we really need the entire body of laws
[00:21:22.200 --> 00:21:23.920]   to catch up to technology.
[00:21:23.920 --> 00:21:27.480]   And if we're really good to write them technologically
[00:21:27.480 --> 00:21:30.440]   invariant, so you don't go through the same problem again
[00:21:30.440 --> 00:21:31.520]   in 20 years.
[00:21:31.520 --> 00:21:33.640]   Yeah, that's where I'll disagree a little bit, Bruce.
[00:21:33.640 --> 00:21:35.480]   I think what we have to do is write the laws at a level
[00:21:35.480 --> 00:21:37.960]   of principle where, then I agree, they're
[00:21:37.960 --> 00:21:39.240]   invariant to the technology.
[00:21:39.240 --> 00:21:42.680]   The principle is that you don't suck up
[00:21:42.680 --> 00:21:43.680]   all the communication that occurs.
[00:21:43.680 --> 00:21:45.800]   Here's a better example.
[00:21:45.800 --> 00:21:51.320]   Our first class letters and packages only
[00:21:51.320 --> 00:21:54.680]   are secured so that they can't be open without a warrant.
[00:21:54.680 --> 00:21:57.720]   The metadata can be taken, but the package cannot be opened.
[00:21:57.720 --> 00:21:58.920]   Any else can be opened.
[00:21:58.920 --> 00:22:01.320]   Our email does not have that security.
[00:22:01.320 --> 00:22:03.640]   Our private chats, of course, don't have that security.
[00:22:03.640 --> 00:22:05.160]   While the principle at work here should
[00:22:05.160 --> 00:22:08.360]   be that private communication is private and is secure
[00:22:08.360 --> 00:22:10.760]   unless with a lawful warrant.
[00:22:10.760 --> 00:22:12.600]   That should be the principle that should exist
[00:22:12.600 --> 00:22:15.560]   against any technology, whether that's a letter, or a phone
[00:22:15.560 --> 00:22:17.600]   call, or a chat, or an email.
[00:22:17.600 --> 00:22:19.040]   So what we have to do is actually, I
[00:22:19.040 --> 00:22:22.360]   think, raise this discussion, hide at the level of principle
[00:22:22.360 --> 00:22:26.000]   so that we can then know what's being protected as citizens.
[00:22:26.000 --> 00:22:27.800]   And then the problem now is that, in a way,
[00:22:27.800 --> 00:22:31.560]   you don't blame the spies, say, in the words of Alexander,
[00:22:31.560 --> 00:22:32.200]   gather it all.
[00:22:32.200 --> 00:22:33.800]   The more they can gather, they think that's their job.
[00:22:33.800 --> 00:22:35.480]   They're going to go as far as they can.
[00:22:35.480 --> 00:22:38.360]   And if the law is too specific to the technology
[00:22:38.360 --> 00:22:39.720]   and doesn't catch up, they're going
[00:22:39.720 --> 00:22:41.320]   to walk through that loophole.
[00:22:41.320 --> 00:22:45.360]   Whereas if the principle is set up that says, you cannot listen
[00:22:45.360 --> 00:22:48.360]   to or in any way spy on private communication
[00:22:48.360 --> 00:22:50.720]   at an individual level until you have a warrant,
[00:22:50.720 --> 00:22:53.240]   that to me is pre-darned clear.
[00:22:53.240 --> 00:22:54.080]   That's right.
[00:22:54.080 --> 00:22:58.760]   And it's resistant to whatever the next thing is.
[00:22:58.760 --> 00:23:02.400]   Our problems have been we had this with videotape rentals
[00:23:02.400 --> 00:23:04.760]   versus DVDs versus streaming video.
[00:23:04.760 --> 00:23:05.840]   We'll have it right.
[00:23:05.840 --> 00:23:12.400]   Letters versus email, phone calls versus Skype calls.
[00:23:12.400 --> 00:23:14.720]   If you write the laws to the technology,
[00:23:14.720 --> 00:23:16.520]   the technology changes, and your laws now
[00:23:16.520 --> 00:23:18.880]   no longer apply or no longer work well.
[00:23:18.880 --> 00:23:19.880]   If we can somehow--
[00:23:19.880 --> 00:23:21.600]   We had to figure out the laws to the idea
[00:23:21.600 --> 00:23:24.080]   that technology is going to constantly change.
[00:23:24.080 --> 00:23:24.640]   Right.
[00:23:24.640 --> 00:23:26.280]   But this stuff is hard.
[00:23:26.280 --> 00:23:29.280]   Fundamentally, it's very hard, members of Congress,
[00:23:29.280 --> 00:23:31.200]   and I applaud the ones who managed to do it,
[00:23:31.200 --> 00:23:35.240]   to say to law enforcement, no, you can't have this.
[00:23:35.240 --> 00:23:38.240]   No, we're going to stand up for what's right,
[00:23:38.240 --> 00:23:40.000]   and we're not going to give you what you want.
[00:23:40.000 --> 00:23:43.400]   It's very easy just to come to fear.
[00:23:43.400 --> 00:23:45.520]   I feel their pain.
[00:23:45.520 --> 00:23:48.080]   No, I have sympathy, even though I don't want them to do it.
[00:23:48.080 --> 00:23:48.920]   Yeah.
[00:23:48.920 --> 00:23:51.240]   And I think the judiciary also is going
[00:23:51.240 --> 00:23:52.640]   to be a big part of this.
[00:23:52.640 --> 00:23:56.640]   Interpreting the laws to support the Fourth Amendment
[00:23:56.640 --> 00:23:58.120]   is going to be a big part of it.
[00:23:58.120 --> 00:24:00.280]   Bruce, we have a promise to let you go at this time,
[00:24:00.280 --> 00:24:02.160]   and I thank you so much for being here.
[00:24:02.160 --> 00:24:04.360]   All right, let's not be back, but I can stay longer.
[00:24:04.360 --> 00:24:05.720]   I would love to have you back.
[00:24:05.720 --> 00:24:07.720]   Liars and outliers is the latest book
[00:24:07.720 --> 00:24:10.600]   enabling the trust that society needs to thrive.
[00:24:10.600 --> 00:24:15.920]   snire.com is the website, really a hero of mine, Bruce.
[00:24:15.920 --> 00:24:16.840]   So thank you for being here.
[00:24:16.840 --> 00:24:17.560]   We really appreciate it.
[00:24:17.560 --> 00:24:18.200]   Hey, thank you.
[00:24:18.200 --> 00:24:19.640]   Take care.
[00:24:19.640 --> 00:24:21.480]   We'll bring Matt cuts now into the screen.
[00:24:21.480 --> 00:24:22.320]   Matt's thumbnail.
[00:24:22.320 --> 00:24:23.680]   You've come to full size.
[00:24:23.680 --> 00:24:25.360]   Well, no, it's not that.
[00:24:25.360 --> 00:24:27.680]   Unfortunately, we're having some weird problem with hangouts,
[00:24:27.680 --> 00:24:31.040]   and the best we can do is a thumbnail.
[00:24:31.040 --> 00:24:32.520]   We can't get him to join.
[00:24:32.520 --> 00:24:34.200]   I don't know.
[00:24:34.200 --> 00:24:35.800]   It's 20 pixels by 20 pixels.
[00:24:35.800 --> 00:24:36.720]   It's technology.
[00:24:36.720 --> 00:24:37.920]   I don't understand it.
[00:24:37.920 --> 00:24:38.920]   Oh, no, wait a minute.
[00:24:38.920 --> 00:24:39.440]   I'm going to see myself.
[00:24:39.440 --> 00:24:40.520]   Look, you're big.
[00:24:40.520 --> 00:24:42.720]   Was it just the wrong machine?
[00:24:42.720 --> 00:24:43.240]   We fixed it.
[00:24:43.240 --> 00:24:44.600]   What do we short Matt?
[00:24:44.600 --> 00:24:47.040]   We unshrunked them at.
[00:24:47.040 --> 00:24:49.960]   So Bruce is gone, but we could continue this conversation.
[00:24:49.960 --> 00:24:51.960]   Or if either of you or any of you
[00:24:51.960 --> 00:24:54.600]   have thoughts that you want to make about what we just said,
[00:24:54.600 --> 00:24:57.600]   Kevin, you're not even from here, from around here.
[00:24:57.600 --> 00:24:58.600]   But you can--
[00:24:58.600 --> 00:24:59.960]   I don't know if it can be what I say.
[00:24:59.960 --> 00:25:01.160]   I'm going to make it.
[00:25:01.160 --> 00:25:03.280]   You're actually from a surveillance state yourself.
[00:25:03.280 --> 00:25:03.800]   I mean, Britain--
[00:25:03.800 --> 00:25:05.320]   I'm not even talking to a foreigner,
[00:25:05.320 --> 00:25:07.040]   everything we say can be snooped upon.
[00:25:07.040 --> 00:25:07.480]   That's the--
[00:25:07.480 --> 00:25:08.160]   Oh, God.
[00:25:08.160 --> 00:25:10.040]   I didn't even think of that.
[00:25:10.040 --> 00:25:13.120]   Britain is no laggard in using technologies
[00:25:13.120 --> 00:25:15.760]   to surveil its citizens.
[00:25:15.760 --> 00:25:16.760]   That's true.
[00:25:16.760 --> 00:25:18.720]   Q has been doing that for a very long time.
[00:25:18.720 --> 00:25:19.720]   Yeah.
[00:25:19.720 --> 00:25:22.360]   It goes back to ballsing them in the 1500s,
[00:25:22.360 --> 00:25:24.560]   opening letters and putting the plots against Elizabeth.
[00:25:24.560 --> 00:25:26.000]   So, yeah, there's a--
[00:25:26.000 --> 00:25:28.560]   That was the perfect Kevin Marks comment.
[00:25:28.560 --> 00:25:30.040]   That was perfect.
[00:25:30.040 --> 00:25:31.560]   Kevin Marks comment.
[00:25:31.560 --> 00:25:33.240]   Do I make that clear?
[00:25:33.240 --> 00:25:36.360]   I just-- I try hard not to get depressed.
[00:25:36.360 --> 00:25:39.040]   I guess the best thing that we can encourage people to do,
[00:25:39.040 --> 00:25:41.400]   I think it's going to have to go through Congress.
[00:25:41.400 --> 00:25:43.720]   At least that's where we can exercise our influence,
[00:25:43.720 --> 00:25:46.320]   is to support people like the EFF,
[00:25:46.320 --> 00:25:49.880]   the Center for Democracy and Technology, CDT.org.
[00:25:49.880 --> 00:25:50.400]   Epic.
[00:25:50.400 --> 00:25:51.560]   We also have to give cover to--
[00:25:51.560 --> 00:25:52.560]   We also have to give cover to the UK.
[00:25:52.560 --> 00:25:54.560]   --to the US Congress.
[00:25:54.560 --> 00:25:55.080]   Yes.
[00:25:55.080 --> 00:25:56.160]   We have to give cover to those Congress people.
[00:25:56.160 --> 00:25:58.440]   We have to give cover to the technology companies.
[00:25:58.440 --> 00:26:00.160]   I wish I could vote for Ron Wyden.
[00:26:00.160 --> 00:26:01.960]   I would.
[00:26:01.960 --> 00:26:03.520]   But you can send him a contribution.
[00:26:03.520 --> 00:26:05.360]   I've sent Ron Wyden money to say--
[00:26:05.360 --> 00:26:05.920]   That's a good idea.
[00:26:05.920 --> 00:26:06.320]   --that's a good idea.
[00:26:06.320 --> 00:26:07.560]   --that represent our interests, you know.
[00:26:07.560 --> 00:26:08.080]   Yeah.
[00:26:08.080 --> 00:26:09.880]   And don't be afraid to call up, you know,
[00:26:09.880 --> 00:26:12.280]   Diane Feinstein as chairman of the committee.
[00:26:12.280 --> 00:26:14.760]   If this is how you feel about the subject and say, look,
[00:26:14.760 --> 00:26:17.480]   if you really feel that this surveillance is a good idea,
[00:26:17.480 --> 00:26:20.000]   then I respectfully disagree with you
[00:26:20.000 --> 00:26:21.360]   and I'll support other candidates.
[00:26:21.360 --> 00:26:21.840]   Yeah.
[00:26:21.840 --> 00:26:24.920]   You've got to let Congress know how you feel about these issues
[00:26:24.920 --> 00:26:27.480]   or they won't have anything to go on.
[00:26:27.480 --> 00:26:30.600]   And really, it is geeks who unfortunately kind of tend
[00:26:30.600 --> 00:26:34.440]   to want to turn our backs on politics,
[00:26:34.440 --> 00:26:35.840]   because it's messy.
[00:26:35.840 --> 00:26:37.680]   It's not binary.
[00:26:37.680 --> 00:26:40.640]   It involves compromise, which we're not so good at.
[00:26:40.640 --> 00:26:44.000]   But we are the ones who best understand what the issues and risks
[00:26:44.000 --> 00:26:44.520]   are here.
[00:26:44.520 --> 00:26:49.680]   And so it is us geeks who have to step forward and be heard.
[00:26:49.680 --> 00:26:51.680]   Well, and this is-- I want to go back to what Matt was talking
[00:26:51.680 --> 00:26:53.840]   about a minute ago, because I think this is highly important.
[00:26:53.840 --> 00:26:56.600]   And Matt's right to say let's not paint the broad brush
[00:26:56.600 --> 00:26:58.360]   that every technology company is evil.
[00:26:58.360 --> 00:27:00.440]   We hear that kind of stuff too often.
[00:27:00.440 --> 00:27:03.440]   But we also need-- you know, I wrote a piece for the Guardian
[00:27:03.440 --> 00:27:05.520]   before Bruce did for the Atlantic,
[00:27:05.520 --> 00:27:07.520]   trying to tackle the same way he did a better job.
[00:27:07.520 --> 00:27:11.400]   But I see three tiers of companies that are ensnared in this.
[00:27:11.400 --> 00:27:13.600]   And at the highest level of the broadband companies
[00:27:13.600 --> 00:27:16.520]   that are letting the NSA and the GCHQ
[00:27:16.520 --> 00:27:18.360]   apparently listen in to the entire damn internet.
[00:27:18.360 --> 00:27:19.760]   Yeah, they're the worst.
[00:27:19.760 --> 00:27:20.440]   They're the worst, right?
[00:27:20.440 --> 00:27:23.920]   Then there's telcos who hate us anyway, and we hate them anyway.
[00:27:23.920 --> 00:27:26.040]   But then there's the companies with whom
[00:27:26.040 --> 00:27:29.600]   we have a personal relationship-- Google, Facebook, Twitter,
[00:27:29.600 --> 00:27:30.240]   and so on.
[00:27:30.240 --> 00:27:32.640]   And perhaps your ISP as well, throw them in the mix.
[00:27:32.640 --> 00:27:34.960]   Well, hey, you know what?
[00:27:34.960 --> 00:27:37.160]   If you don't have a good ISP, get one.
[00:27:37.160 --> 00:27:38.360]   There are good ones.
[00:27:38.360 --> 00:27:40.400]   Locally, here's SonicNet.
[00:27:40.400 --> 00:27:43.440]   Historically, has fought the best for our rights.
[00:27:43.440 --> 00:27:44.600]   That's the three points about that.
[00:27:44.600 --> 00:27:47.080]   And when we're imprisoned by an oligopoly or a monopoly,
[00:27:47.080 --> 00:27:47.480]   we don't.
[00:27:47.480 --> 00:27:50.000]   But what we do have is-- my argument here
[00:27:50.000 --> 00:27:53.720]   is that the Googles and Twitters and Facebooks at all
[00:27:53.720 --> 00:27:58.320]   are our best hope, because they're the ones who lose the most
[00:27:58.320 --> 00:28:00.040]   if we lose trust in them.
[00:28:00.040 --> 00:28:01.560]   Whether that's individual consumers,
[00:28:01.560 --> 00:28:03.440]   or whether that's companies canceling contracts
[00:28:03.440 --> 00:28:05.920]   with American cloud providers, because they don't trust us
[00:28:05.920 --> 00:28:08.080]   anymore, they have the most to lose.
[00:28:08.080 --> 00:28:09.400]   They have the most aligned interest.
[00:28:09.400 --> 00:28:11.480]   They have an actual relationship with us.
[00:28:11.480 --> 00:28:13.040]   And they're also ensnared.
[00:28:13.040 --> 00:28:16.240]   And this is why this collaborator versus victim
[00:28:16.240 --> 00:28:18.520]   is still important, I think, because sometimes you
[00:28:18.520 --> 00:28:20.080]   can do this stuff very willingly.
[00:28:20.080 --> 00:28:22.920]   Or you can say, I'm only doing what I have to do.
[00:28:22.920 --> 00:28:24.280]   And the more that we can give cover
[00:28:24.280 --> 00:28:27.160]   to those technology companies, too, as Bruce says, fight,
[00:28:27.160 --> 00:28:31.960]   but also to make clear these principles on our behalf,
[00:28:31.960 --> 00:28:33.080]   I think they're our best hope.
[00:28:33.080 --> 00:28:34.320]   Congress is going to be mixed.
[00:28:34.320 --> 00:28:35.920]   Courts are going to be slow.
[00:28:35.920 --> 00:28:37.960]   Diplomacy is going to take forever.
[00:28:37.960 --> 00:28:42.360]   The executive branch is full FOS on this.
[00:28:42.360 --> 00:28:44.520]   Telecos and bandwidth companies don't care about us,
[00:28:44.520 --> 00:28:45.440]   and never will.
[00:28:45.440 --> 00:28:47.200]   So to me-- and I know I get accused
[00:28:47.200 --> 00:28:50.080]   of being a Google love boy and apologist--
[00:28:50.080 --> 00:28:52.600]   we need these companies to stand up and speak,
[00:28:52.600 --> 00:28:55.240]   and we need to give them the cover and the demand to do so.
[00:28:55.240 --> 00:28:56.160]   End of sermon.
[00:28:56.160 --> 00:28:57.920]   Yeah, I'm not sure I agree that you're
[00:28:57.920 --> 00:29:01.520]   going to ever get these companies as an entity to do any
[00:29:01.520 --> 00:29:03.720]   of this, because they are, for the most part,
[00:29:03.720 --> 00:29:04.520]   publicly held.
[00:29:04.520 --> 00:29:06.640]   They have a fiduciary responsibility stakeholders
[00:29:06.640 --> 00:29:09.200]   to maximize profits.
[00:29:09.200 --> 00:29:11.000]   Corporations are a more--
[00:29:11.000 --> 00:29:12.200]   They've got a fight for the cloud.
[00:29:12.200 --> 00:29:13.480]   I mean, you've got a cloud company
[00:29:13.480 --> 00:29:14.480]   that before you--
[00:29:14.480 --> 00:29:16.040]   You know, I agree that Google--
[00:29:16.040 --> 00:29:16.560]   They've got a fight for it.
[00:29:16.560 --> 00:29:18.800]   We've lost Matt because I would love to get his comment on this,
[00:29:18.800 --> 00:29:21.360]   but I would agree that I'm sure that Google--
[00:29:21.360 --> 00:29:22.760]   I would hope that Google understands
[00:29:22.760 --> 00:29:25.000]   that this is bad for Google.
[00:29:25.000 --> 00:29:28.360]   However, they are sort of tied by the law
[00:29:28.360 --> 00:29:31.880]   from doing as much as they might want to to fight it.
[00:29:31.880 --> 00:29:34.560]   I like what you said.
[00:29:34.560 --> 00:29:36.640]   Companies are made of individuals.
[00:29:36.640 --> 00:29:42.280]   And if this goes against an individual's deepest values,
[00:29:42.280 --> 00:29:43.880]   walk.
[00:29:43.880 --> 00:29:45.680]   That's maybe-- I mean, that's--
[00:29:45.680 --> 00:29:50.320]   I don't have hope for the board of directors of any big company
[00:29:50.320 --> 00:29:51.240]   to do anything.
[00:29:51.240 --> 00:29:53.040]   But the individuals who run that company,
[00:29:53.040 --> 00:29:55.960]   especially an engineering driven company like Google--
[00:29:55.960 --> 00:29:58.400]   I've got hope for Larry Page and Sergey Brin.
[00:29:58.400 --> 00:29:59.400]   Yeah.
[00:29:59.400 --> 00:30:00.360]   I'm Mark Zuckerberg.
[00:30:00.360 --> 00:30:01.120]   I mean, I do.
[00:30:01.120 --> 00:30:04.200]   And I think that Mark Benioff--
[00:30:04.200 --> 00:30:06.480]   not to put now Kevin on the rare hot spot,
[00:30:06.480 --> 00:30:08.080]   because usually it's Matt who's there.
[00:30:08.080 --> 00:30:12.920]   But Mark Benioff has helped make the cloud what it is.
[00:30:12.920 --> 00:30:15.600]   And it's in his interest to defend that cloud
[00:30:15.600 --> 00:30:19.120]   against forced lack of trust from companies and government.
[00:30:19.120 --> 00:30:21.480]   Is he?
[00:30:21.480 --> 00:30:22.240]   I don't know.
[00:30:22.240 --> 00:30:23.240]   OK.
[00:30:23.240 --> 00:30:25.080]   [LAUGHTER]
[00:30:25.080 --> 00:30:29.200]   So I think there-- corporate politics is a complicated mix.
[00:30:29.200 --> 00:30:32.640]   Larry Page does not have free hand to do whatever he wants.
[00:30:32.640 --> 00:30:37.640]   Well, but I honestly believe that Google has intuited for a long time
[00:30:37.640 --> 00:30:40.200]   that if we do the right thing for our users,
[00:30:40.200 --> 00:30:42.280]   then the right things will happen in terms
[00:30:42.280 --> 00:30:43.920]   of engendering long-term loyalty.
[00:30:43.920 --> 00:30:47.240]   And you feel that's still the core value of the company?
[00:30:47.240 --> 00:30:48.440]   I want to hear that.
[00:30:48.440 --> 00:30:48.960]   That's good.
[00:30:48.960 --> 00:30:49.460]   Yes.
[00:30:49.460 --> 00:30:51.360]   I do believe that-- and I completely
[00:30:51.360 --> 00:30:53.840]   grew-- Google is composed of individuals who each
[00:30:53.840 --> 00:30:55.840]   have to make their own ethical decision.
[00:30:55.840 --> 00:30:59.920]   And I don't-- I can't speak for other companies.
[00:30:59.920 --> 00:31:01.880]   And other companies have different cultures.
[00:31:01.880 --> 00:31:05.960]   But at least at Google, when Jeff is exactly right,
[00:31:05.960 --> 00:31:08.000]   we have set ourselves a motto of don't be evil.
[00:31:08.000 --> 00:31:10.600]   And so people should call us on that when they think
[00:31:10.600 --> 00:31:11.600]   that we're being evil.
[00:31:11.600 --> 00:31:14.400]   And when that resonates with individuals within the company,
[00:31:14.400 --> 00:31:18.040]   then we get the chance to bang the drum and make noise about that.
[00:31:18.040 --> 00:31:22.520]   And so I think giving the company's cover by criticizing us,
[00:31:22.520 --> 00:31:24.600]   calling us out when you think we're not doing the right thing,
[00:31:24.600 --> 00:31:28.440]   is exactly the best way to lobby the companies to take
[00:31:28.440 --> 00:31:30.120]   the action that you think they should be doing.
[00:31:30.120 --> 00:31:33.520]   And certainly at Google, I feel like we have
[00:31:33.520 --> 00:31:37.480]   a bend towards protecting our users and their security.
[00:31:37.480 --> 00:31:40.640]   And so looking for ways to make the defaults encrypted,
[00:31:40.640 --> 00:31:43.520]   for example, I think is something we have a long history
[00:31:43.520 --> 00:31:45.960]   of doing, and we'll probably keep thinking about ways
[00:31:45.960 --> 00:31:49.520]   to keep making Gmail secure and all those sorts of things.
[00:31:49.520 --> 00:31:51.000]   Well, this is a good time for me then
[00:31:51.000 --> 00:31:55.480]   to bring in this filing in the class action data mining
[00:31:55.480 --> 00:32:00.560]   lawsuit, a filing from Google's attorneys in which they say,
[00:32:00.560 --> 00:32:05.400]   quote, this is Google talking about Gmail.
[00:32:05.400 --> 00:32:08.280]   Just as a sender of a letter to a business colleague,
[00:32:08.280 --> 00:32:11.040]   cannot be surprised that the recipient's assistant opens
[00:32:11.040 --> 00:32:12.400]   the letter.
[00:32:12.400 --> 00:32:16.200]   People who used web-based email today cannot be surprised
[00:32:16.200 --> 00:32:19.800]   if their emails are processed by the recipient's email
[00:32:19.800 --> 00:32:22.240]   provider in the course of delivery.
[00:32:22.240 --> 00:32:26.600]   Indeed, a person has no legitimate expectation of privacy
[00:32:26.600 --> 00:32:31.520]   and information he voluntarily turns over to third parties.
[00:32:31.520 --> 00:32:35.000]   That's been misquoted and misinterpreted like mad
[00:32:35.000 --> 00:32:36.600]   and headline writers have gone berserk.
[00:32:36.600 --> 00:32:37.600]   But that's the quote.
[00:32:37.600 --> 00:32:38.600]   Please also--
[00:32:38.600 --> 00:32:40.760]   No, there's actually quotes within that.
[00:32:40.760 --> 00:32:42.520]   It's quoting previous cases.
[00:32:42.520 --> 00:32:43.600]   Read the next webinar.
[00:32:43.600 --> 00:32:44.400]   No, I understand it.
[00:32:44.400 --> 00:32:47.160]   It's quoting Smith v. Maryland's Supreme Court decision.
[00:32:47.160 --> 00:32:48.200]   And what it's saying--
[00:32:48.200 --> 00:32:52.040]   But he's quoting it to say, this is what the Supreme Court said.
[00:32:52.040 --> 00:32:55.960]   And this is in our argument and in our favor.
[00:32:55.960 --> 00:32:59.320]   Doesn't that say we embrace that statement as well?
[00:32:59.320 --> 00:32:59.840]   No, no.
[00:32:59.840 --> 00:33:01.520]   It's a specific case of--
[00:33:01.520 --> 00:33:03.320]   and I'm not fully well versed.
[00:33:03.320 --> 00:33:04.680]   But if you go to the next web story,
[00:33:04.680 --> 00:33:07.080]   it's a far better expression of this.
[00:33:07.080 --> 00:33:12.320]   That it's specific to a case involving whether or not Google--
[00:33:12.320 --> 00:33:16.080]   the point is, what is the expectation of privacy?
[00:33:16.080 --> 00:33:19.200]   Your ISP sees the metadata go back and forth.
[00:33:19.200 --> 00:33:20.600]   They know that that's there.
[00:33:20.600 --> 00:33:23.880]   Your secretary can open your mail and so on and so on.
[00:33:23.880 --> 00:33:27.040]   And that that was relevant in a limited discussion
[00:33:27.040 --> 00:33:28.160]   of a larger case.
[00:33:28.160 --> 00:33:30.520]   And it's been blown way out of proportion.
[00:33:30.520 --> 00:33:32.480]   And I know that I'm Google apologist often here,
[00:33:32.480 --> 00:33:34.600]   though I'm also pushing them hard on NSA.
[00:33:34.600 --> 00:33:39.080]   But in this case, this thing has been blown way, way out.
[00:33:39.080 --> 00:33:41.040]   It's beyond.
[00:33:41.040 --> 00:33:42.440]   I think if you consider the source,
[00:33:42.440 --> 00:33:44.600]   a lot of this was coming from Consumer Watch Dog,
[00:33:44.600 --> 00:33:46.520]   which if you're a Google connoisseur,
[00:33:46.520 --> 00:34:07.640]   I know they hate you no
[00:34:07.640 --> 00:34:08.880]   impartial source.
[00:34:08.880 --> 00:34:12.480]   So what is-- I'm still reading that quote in that brief.
[00:34:12.480 --> 00:34:14.640]   And maybe Google didn't say it their lawyers did.
[00:34:14.640 --> 00:34:16.960]   But what's wrong with what they said it is true,
[00:34:16.960 --> 00:34:21.760]   you cannot have expectation of privacy in a web-based email.
[00:34:21.760 --> 00:34:23.320]   Right?
[00:34:23.320 --> 00:34:28.320]   Far bit for me to speculate as an engineer on a legal question.
[00:34:28.320 --> 00:34:32.800]   But so hey, Google don't fire me.
[00:34:32.800 --> 00:34:34.480]   I mean, there is a privacy policy.
[00:34:34.480 --> 00:34:36.720]   Google has a privacy policy.
[00:34:36.720 --> 00:34:38.760]   And they are bound legally and morally
[00:34:38.760 --> 00:34:40.880]   to that privacy policy.
[00:34:40.880 --> 00:34:43.760]   But I think that they're making an argument that is not wrong,
[00:34:43.760 --> 00:34:46.520]   that if you are-- I've always said this.
[00:34:46.520 --> 00:34:47.800]   You put it on the internet.
[00:34:47.800 --> 00:34:51.720]   You cannot have an expectation that it is guaranteed private.
[00:34:51.720 --> 00:34:53.600]   Let me read this from the next web.
[00:34:53.600 --> 00:34:56.680]   The case that Google is currently defending itself is
[00:34:56.680 --> 00:34:58.240]   in is a class action lawsuit.
[00:34:58.240 --> 00:35:00.080]   Are you in the Gmail's feature for scanning emails
[00:35:00.080 --> 00:35:02.840]   to target ads goes against wiretap laws?
[00:35:02.840 --> 00:35:05.080]   It's technically accurate that Google used the quote
[00:35:05.080 --> 00:35:06.400]   in its legal defense.
[00:35:06.400 --> 00:35:08.880]   But using that fact to claim that Google has completely
[00:35:08.880 --> 00:35:12.640]   given up on user privacy is both sensational and disingenuous.
[00:35:12.640 --> 00:35:16.080]   The company is, after all, bound by its own privacy policy.
[00:35:16.080 --> 00:35:18.240]   Google's use of the quote does make me uncomfortable,
[00:35:18.240 --> 00:35:20.600]   says the writer, especially in the current Snowden climate.
[00:35:20.600 --> 00:35:22.920]   But most of us already had this debate when Gmail first
[00:35:22.920 --> 00:35:24.560]   arrived in 2004.
[00:35:24.560 --> 00:35:26.800]   Google was open about using email content
[00:35:26.800 --> 00:35:28.800]   to serve ads at the time.
[00:35:28.800 --> 00:35:32.240]   They're being accused of that act being against wiretap.
[00:35:32.240 --> 00:35:34.600]   And they're saying that, whoa, that doesn't work.
[00:35:34.600 --> 00:35:36.880]   Because in that case, there was not
[00:35:36.880 --> 00:35:39.040]   that ironclad expectation of privacy.
[00:35:39.040 --> 00:35:41.840]   And people understood what they were doing with that.
[00:35:41.840 --> 00:35:42.880]   That's what this is about.
[00:35:42.880 --> 00:35:47.760]   OK.
[00:35:47.760 --> 00:35:49.920]   Well, that sure was a conversation stopper.
[00:35:49.920 --> 00:35:54.280]   I mean, when the brief says, indeed quote,
[00:35:54.280 --> 00:35:56.920]   and then quotes that the Supreme Court decision,
[00:35:56.920 --> 00:35:59.960]   a person has no legitimate expectation of privacy
[00:35:59.960 --> 00:36:03.040]   and information he turns over to third parties, indeed,
[00:36:03.040 --> 00:36:06.200]   is coming from Google and saying, yes, indeed,
[00:36:06.200 --> 00:36:07.880]   emphatically, that's correct.
[00:36:07.880 --> 00:36:10.440]   Now, they're defending a case, and lawyers
[00:36:10.440 --> 00:36:12.800]   are going to use every fact to defend the case.
[00:36:12.800 --> 00:36:14.480]   I don't think what they're saying is wrong.
[00:36:14.480 --> 00:36:17.080]   If you think that when you're using email,
[00:36:17.080 --> 00:36:20.040]   you have privacy, you're nuts.
[00:36:20.040 --> 00:36:23.640]   When you turn your information over to third parties,
[00:36:23.640 --> 00:36:26.320]   you're turning it over to third parties, right?
[00:36:26.320 --> 00:36:26.880]   Exactly.
[00:36:26.880 --> 00:36:29.520]   The sentence before that says, people who use web-based email
[00:36:29.520 --> 00:36:32.360]   today can't be surprised if their emails are processed
[00:36:32.360 --> 00:36:34.960]   by the recipients email provider in the course of delivery.
[00:36:34.960 --> 00:36:36.000]   It's not all Gmail.
[00:36:36.000 --> 00:36:38.040]   It's every step along the way.
[00:36:38.040 --> 00:36:38.560]   Yeah.
[00:36:38.560 --> 00:36:40.520]   And in fact, it's especially ironic,
[00:36:40.520 --> 00:36:42.640]   because Gmail has been quite good about trying
[00:36:42.640 --> 00:36:47.480]   to encrypt email between email providers more so than anybody
[00:36:47.480 --> 00:36:48.000]   calls them.
[00:36:48.000 --> 00:36:50.800]   Google's SMTP support, as we talked about on security,
[00:36:50.800 --> 00:36:55.200]   that supports encryption, whereas many SMTP providers do not.
[00:36:55.200 --> 00:36:56.000]   So it's very strange.
[00:36:56.000 --> 00:36:58.120]   Which is why it isn't encrypted, because in order
[00:36:58.120 --> 00:37:01.040]   to send an email to most people, it's unencrypted.
[00:37:01.040 --> 00:37:01.480]   Right.
[00:37:01.480 --> 00:37:04.200]   So if you were to actually snoop on those connections,
[00:37:04.200 --> 00:37:06.240]   you could see unencrypted emails going by,
[00:37:06.240 --> 00:37:08.360]   whereas Gmail does better than any other else
[00:37:08.360 --> 00:37:09.880]   that I know of off the top of my head,
[00:37:09.880 --> 00:37:12.440]   and actually trying to transmit those emails
[00:37:12.440 --> 00:37:13.560]   in an encrypted fashion.
[00:37:13.560 --> 00:37:14.760]   So it's especially ironic to get
[00:37:14.760 --> 00:37:17.720]   skewered for privacy, given those kinds of facts.
[00:37:17.720 --> 00:37:20.760]   This is actually a guy who says, I signed up--
[00:37:20.760 --> 00:37:22.280]   I mean, it's a BS lawsuit.
[00:37:22.280 --> 00:37:25.080]   I signed up when I was a minor, and I didn't know any better.
[00:37:25.080 --> 00:37:27.760]   And here you are scanning my email.
[00:37:27.760 --> 00:37:28.800]   We talked about this before.
[00:37:28.800 --> 00:37:32.440]   If you have anti-spam, somebody's scanning your email,
[00:37:32.440 --> 00:37:34.280]   because that's the only way you can prevent spam,
[00:37:34.280 --> 00:37:35.840]   as Mac cuts well knows.
[00:37:35.840 --> 00:37:38.080]   You can't imagine what's inside and say, hm,
[00:37:38.080 --> 00:37:39.240]   I think it might be spam.
[00:37:39.240 --> 00:37:40.800]   You have to look.
[00:37:40.800 --> 00:37:42.520]   Which is also part of our bit with Bruce,
[00:37:42.520 --> 00:37:45.160]   that there is a gradation and a difference here.
[00:37:45.160 --> 00:37:48.000]   I enter a new transaction with a company knowingly saying,
[00:37:48.000 --> 00:37:50.640]   this is what's going on, and I have the ability to leave it.
[00:37:50.640 --> 00:37:52.200]   The government, that's not the case.
[00:37:52.200 --> 00:37:52.680]   Right.
[00:37:52.680 --> 00:37:53.600]   Right.
[00:37:53.600 --> 00:37:54.160]   Right.
[00:37:54.160 --> 00:37:56.360]   Although, at this point, if you're using the internet,
[00:37:56.360 --> 00:38:00.840]   you're using so many interlocking companies that are--
[00:38:00.840 --> 00:38:04.400]   you should assume your choice is not to not use Gmail.
[00:38:04.400 --> 00:38:07.200]   Your choice is not to use the internet.
[00:38:07.200 --> 00:38:08.280]   Really?
[00:38:08.280 --> 00:38:08.800]   Yeah.
[00:38:08.800 --> 00:38:11.320]   Well, your choice is also not to talk to people.
[00:38:11.320 --> 00:38:13.520]   At the end of the day, what's going to get violated
[00:38:13.520 --> 00:38:14.560]   is when somebody--
[00:38:14.560 --> 00:38:15.480]   Yeah, don't go outside.
[00:38:15.480 --> 00:38:17.280]   There might be cameras.
[00:38:17.280 --> 00:38:18.120]   You know?
[00:38:18.120 --> 00:38:20.040]   I mean, here--
[00:38:20.040 --> 00:38:22.440]   but that gets down to the--
[00:38:22.440 --> 00:38:24.800]   well, question I always end up at is, well, what the hell
[00:38:24.800 --> 00:38:25.840]   do we do about it?
[00:38:25.840 --> 00:38:27.880]   Do you go with Scott McNealy and say, just give up,
[00:38:27.880 --> 00:38:29.000]   privacy's dead?
[00:38:29.000 --> 00:38:29.520]   No.
[00:38:29.520 --> 00:38:30.520]   No.
[00:38:30.520 --> 00:38:34.240]   I don't have a huge hope that we can convince our Congress
[00:38:34.240 --> 00:38:38.000]   to somehow judiciously change the--
[00:38:38.000 --> 00:38:43.120]   it's such a fine parsing to say, well, we want some security,
[00:38:43.120 --> 00:38:47.080]   but we also want some privacy, and you guys figure it out.
[00:38:47.080 --> 00:38:49.840]   I don't know if, A, they have the capability
[00:38:49.840 --> 00:38:51.880]   or the motivation to do that.
[00:38:51.880 --> 00:38:55.600]   So I don't have a lot of hope that we can do anything about it.
[00:38:55.600 --> 00:38:59.320]   But my biggest fear then is that if we lose trust in the net,
[00:38:59.320 --> 00:39:01.960]   if people-- if individuals lose trust,
[00:39:01.960 --> 00:39:04.360]   and if companies lose trust in the net,
[00:39:04.360 --> 00:39:06.440]   and then this whole notion of the cloud,
[00:39:06.440 --> 00:39:10.360]   then that's going to affect our jobs, all of us,
[00:39:10.360 --> 00:39:11.920]   but it also affects the economy.
[00:39:11.920 --> 00:39:14.160]   Here's what I would say.
[00:39:14.160 --> 00:39:16.360]   I think you're-- then this is what I'm saying
[00:39:16.360 --> 00:39:18.040]   about this Gmail story.
[00:39:18.040 --> 00:39:19.800]   You're foolish if you think it's private.
[00:39:19.800 --> 00:39:20.760]   It's not.
[00:39:20.760 --> 00:39:25.360]   So it's far better to be a realist about what it is and isn't.
[00:39:25.360 --> 00:39:27.600]   The internet is a public sphere.
[00:39:27.600 --> 00:39:29.960]   It's like you're in a mall.
[00:39:29.960 --> 00:39:31.560]   You're in public.
[00:39:31.560 --> 00:39:35.360]   And the only way it's going to work is if we're realists about it.
[00:39:35.360 --> 00:39:36.160]   It's on you.
[00:39:36.160 --> 00:39:39.240]   Where do you put your company accounts?
[00:39:39.240 --> 00:39:41.880]   On the internet, we use QuickBooks Online.
[00:39:41.880 --> 00:39:43.920]   Right.
[00:39:43.920 --> 00:39:46.920]   Well, and I think you have to look at every company's track record
[00:39:46.920 --> 00:39:47.960]   and make your choices.
[00:39:47.960 --> 00:39:50.280]   And one of the good things that's going to come out
[00:39:50.280 --> 00:39:54.320]   of the whole Snowden situation is people will be a lot more aware.
[00:39:54.320 --> 00:39:56.920]   And maybe privacy will be more of a factor
[00:39:56.920 --> 00:39:58.720]   in people's equations.
[00:39:58.720 --> 00:40:00.840]   And I think that's an entirely good thing.
[00:40:00.840 --> 00:40:04.600]   I mean, in some sense, it feels like some of the tech companies
[00:40:04.600 --> 00:40:07.480]   got thrown under the bus because there were claims
[00:40:07.480 --> 00:40:09.760]   that then people had to back off of.
[00:40:09.760 --> 00:40:12.400]   But if that ends up galvanizing Silicon Valley
[00:40:12.400 --> 00:40:14.680]   or galvanizing a large fraction of the populace
[00:40:14.680 --> 00:40:16.560]   to be aware of these issues, ultimately,
[00:40:16.560 --> 00:40:18.920]   that's a really good thing.
[00:40:18.920 --> 00:40:23.080]   Oh, I think these conversations need to be had.
[00:40:23.080 --> 00:40:26.680]   I don't have a hold out a lot of hope that there'll be a positive
[00:40:26.680 --> 00:40:27.680]   outcome.
[00:40:27.680 --> 00:40:29.120]   How about this, though?
[00:40:29.120 --> 00:40:31.320]   Do you remember, right, with SOPA, right?
[00:40:31.320 --> 00:40:35.440]   We managed to turn back what would have been a really bad law
[00:40:35.440 --> 00:40:38.840]   with about a month or two of the net starting to self-organize.
[00:40:38.840 --> 00:40:39.360]   Yeah.
[00:40:39.360 --> 00:40:42.600]   It's kind of like 300 Spartans turning back
[00:40:42.600 --> 00:40:44.360]   part of the Persian army.
[00:40:44.360 --> 00:40:46.760]   There's a whole other army coming.
[00:40:46.760 --> 00:40:48.680]   There is, but we have reinforcements, too.
[00:40:48.680 --> 00:40:51.120]   So my argument would be way back to be a SOPA.
[00:40:51.120 --> 00:40:52.120]   You're trying to be a SOPA.
[00:40:52.120 --> 00:40:53.120]   It would be historical.
[00:40:53.120 --> 00:40:53.640]   Smart.
[00:40:53.640 --> 00:40:54.360]   Well, I saw the movie.
[00:40:54.360 --> 00:40:56.560]   I saw the movie.
[00:40:56.560 --> 00:41:00.440]   But in the SOPA days, we said, look, within 20 years,
[00:41:00.440 --> 00:41:02.880]   the people who are in Congress will have a much better idea
[00:41:02.880 --> 00:41:04.680]   about how the internet works.
[00:41:04.680 --> 00:41:08.280]   And they'll be much less likely to make legislative mistakes
[00:41:08.280 --> 00:41:10.560]   and bad laws and bad regulations about the internet.
[00:41:10.560 --> 00:41:12.720]   Because anyone with a Facebook account who's
[00:41:12.720 --> 00:41:15.120]   been using the internet since they were born,
[00:41:15.120 --> 00:41:16.640]   they have a much different conception
[00:41:16.640 --> 00:41:17.920]   of how the internet works.
[00:41:17.920 --> 00:41:20.960]   So we kind of have to defend the net for another 10 or 15 years.
[00:41:20.960 --> 00:41:24.240]   And then you won't have people who have their email printed out
[00:41:24.240 --> 00:41:26.120]   by secretaries on paper and bring it to them
[00:41:26.120 --> 00:41:28.440]   and don't understand how laws really work.
[00:41:28.440 --> 00:41:32.640]   If we can just get to there, I think we'll be mostly safe.
[00:41:32.640 --> 00:41:34.800]   Well, I think we're already at least partly there.
[00:41:34.800 --> 00:41:37.200]   But a big chunk of this is changing
[00:41:37.200 --> 00:41:40.200]   the sort of cultural expectations about what things are
[00:41:40.200 --> 00:41:41.360]   and how they behave.
[00:41:41.360 --> 00:41:44.400]   And that is the bigger, a trickier part.
[00:41:44.400 --> 00:41:47.640]   And people like Jeff and Bruce who talk about this in public
[00:41:47.640 --> 00:41:51.800]   all the time are a key part of that in terms of making it clear
[00:41:51.800 --> 00:41:55.760]   and coming up with different narratives that other than
[00:41:55.760 --> 00:41:58.560]   there are scary people out there and we need to track everything
[00:41:58.560 --> 00:42:02.560]   on them and reconstruct these in different ways.
[00:42:02.560 --> 00:42:05.680]   We've seen that happen with the patent staff.
[00:42:05.680 --> 00:42:08.280]   With patents, there was this historic narrative
[00:42:08.280 --> 00:42:10.800]   of little inventor against the big company
[00:42:10.800 --> 00:42:12.800]   and the big company will always lose.
[00:42:12.800 --> 00:42:16.040]   And that has been exploited by the patent trolls
[00:42:16.040 --> 00:42:18.080]   for a couple of decades.
[00:42:18.080 --> 00:42:20.480]   But we're actually seeing a change in mindset now
[00:42:20.480 --> 00:42:23.000]   in public narrative around that because people are starting
[00:42:23.000 --> 00:42:25.000]   to see the damage that's been done there.
[00:42:25.000 --> 00:42:29.400]   I think the same definitely what we've seen with Snowden
[00:42:29.400 --> 00:42:32.880]   and Manning is that that narrative has got a bigger hold
[00:42:32.880 --> 00:42:33.680]   on the public.
[00:42:33.680 --> 00:42:41.160]   There's still a lot of genius surveillance narrative out there.
[00:42:41.160 --> 00:42:45.840]   There are TV programs like Spooks and--
[00:42:45.840 --> 00:42:47.120]   what's the other one?
[00:42:47.120 --> 00:42:48.920]   That's a personal interest.
[00:42:48.920 --> 00:42:53.760]   Basically glorify spying on everyone as a force for good.
[00:42:53.760 --> 00:42:58.160]   And that's a problematic structural narrative
[00:42:58.160 --> 00:43:00.640]   that's out there.
[00:43:00.640 --> 00:43:04.680]   And it's also one that is taken advantage of by the security
[00:43:04.680 --> 00:43:08.520]   services, the NSA types, appreciates two types as well
[00:43:08.520 --> 00:43:11.880]   to say, well, if you knew what we knew, then you'd trust us.
[00:43:11.880 --> 00:43:14.320]   Look, we convinced Obama when he came into office,
[00:43:14.320 --> 00:43:15.400]   he didn't believe this.
[00:43:15.400 --> 00:43:20.240]   And there's a lot of self-regarding.
[00:43:20.240 --> 00:43:21.680]   There's this sort of weird psychological effect
[00:43:21.680 --> 00:43:24.520]   that if you were told something came from secret information,
[00:43:24.520 --> 00:43:28.240]   you're more likely to believe it than if you actually
[00:43:28.240 --> 00:43:30.680]   got public information to back it up.
[00:43:30.680 --> 00:43:31.680]   Oh, isn't that cool?
[00:43:31.680 --> 00:43:32.680]   I like that.
[00:43:32.680 --> 00:43:33.680]   It's true.
[00:43:33.680 --> 00:43:34.840]   I don't like that too.
[00:43:34.840 --> 00:43:36.400]   And that's also one of the cultural--
[00:43:36.400 --> 00:43:38.520]   --exposable scripts.
[00:43:38.520 --> 00:43:39.920]   The cultural piece of this is interesting.
[00:43:39.920 --> 00:43:42.720]   I joked on Google+, that I expect
[00:43:42.720 --> 00:43:44.120]   on this season of Homeland Kerry is
[00:43:44.120 --> 00:43:46.640]   going to use X key score and read all our emails
[00:43:46.640 --> 00:43:50.400]   and then go off and find Snowden and stupid.
[00:43:50.400 --> 00:43:52.280]   Hey, that show I'd watch.
[00:43:52.280 --> 00:43:53.840]   Yeah.
[00:43:53.840 --> 00:43:55.360]   But they did that in the first series.
[00:43:55.360 --> 00:43:59.040]   The first or second episode, she illegally planted cameras
[00:43:59.040 --> 00:43:59.720]   in his house.
[00:43:59.720 --> 00:44:00.800]   Oh, yeah, that's right.
[00:44:00.800 --> 00:44:01.880]   That's right.
[00:44:01.880 --> 00:44:05.800]   And we rooted for her as she's watching it make love to his wife.
[00:44:05.800 --> 00:44:06.800]   Yeah.
[00:44:06.800 --> 00:44:09.000]   Ah, one of the more reason they're legal.
[00:44:09.000 --> 00:44:14.160]   No, but seriously, Hollywood has some complicity in this,
[00:44:14.160 --> 00:44:15.480]   too, don't they?
[00:44:15.480 --> 00:44:17.800]   Well, it's interesting to see how many movies
[00:44:17.800 --> 00:44:20.120]   we've seen with dystopian futures recently.
[00:44:20.120 --> 00:44:22.200]   You start with any of the state 10 years ago
[00:44:22.200 --> 00:44:24.640]   and you get more and more dystopian.
[00:44:24.640 --> 00:44:28.440]   And I think that's partly reflecting popular culture
[00:44:28.440 --> 00:44:30.720]   and partly that might shape popular culture.
[00:44:30.720 --> 00:44:35.760]   So let's get some movies and TV shows celebrating privacy
[00:44:35.760 --> 00:44:36.640]   privacy's boring.
[00:44:36.640 --> 00:44:38.200]   Somebody already in the chat and said,
[00:44:38.200 --> 00:44:40.600]   I know this is important, but this is the least entertaining
[00:44:40.600 --> 00:44:42.080]   episode of "Twig Ever."
[00:44:42.080 --> 00:44:43.080]   Oh, dear.
[00:44:43.080 --> 00:44:44.080]   [LAUGHTER]
[00:44:44.080 --> 00:44:45.080]   Oh.
[00:44:45.080 --> 00:44:46.080]   Oh.
[00:44:46.080 --> 00:44:49.120]   So one book you might try reading is "Cory Doctor O's,
[00:44:49.120 --> 00:44:50.120]   Little Brother."
[00:44:50.120 --> 00:44:51.120]   Oh, it's such a good one.
[00:44:51.120 --> 00:44:52.120]   And that's entertaining.
[00:44:52.120 --> 00:44:55.120]   It's entertaining and it makes you realize the web should be
[00:44:55.120 --> 00:44:57.120]   encrypted and that would solve a lot of problems.
[00:44:57.120 --> 00:44:58.120]   And how am I to see that?
[00:44:58.120 --> 00:45:02.120]   But you know what the problem with that then is,
[00:45:02.120 --> 00:45:04.400]   and I've said this before on the show, but there are services
[00:45:04.400 --> 00:45:06.880]   that Google gives me because it can read my email.
[00:45:06.880 --> 00:45:08.200]   It can give me that boring pass.
[00:45:08.200 --> 00:45:09.880]   It can remind me of the meeting.
[00:45:09.880 --> 00:45:11.680]   It knows that I want that.
[00:45:11.680 --> 00:45:13.080]   Most of my life has been out.
[00:45:13.080 --> 00:45:14.400]   It's fine.
[00:45:14.400 --> 00:45:17.880]   So I don't want to have to-- I don't want us all to become
[00:45:17.880 --> 00:45:21.560]   hermits in cottages like the Unibomber away from all the
[00:45:21.560 --> 00:45:22.560]   world.
[00:45:22.560 --> 00:45:23.560]   I like that we can connect.
[00:45:23.560 --> 00:45:25.560]   Why wrote a book called "Public Parts on sale now?"
[00:45:25.560 --> 00:45:27.560]   Because it connects us, right?
[00:45:27.560 --> 00:45:28.560]   And if we--
[00:45:28.560 --> 00:45:32.840]   But you can have a private connection with Google and keep
[00:45:32.840 --> 00:45:34.640]   the government out of it.
[00:45:34.640 --> 00:45:36.760]   I think we spoke about saying.
[00:45:36.760 --> 00:45:38.480]   No, I don't think you can.
[00:45:38.480 --> 00:45:40.200]   Well, for instance, I'll give you an example.
[00:45:40.200 --> 00:45:41.920]   I like what you said, encrypt everything.
[00:45:41.920 --> 00:45:44.600]   And in fact, Google does use HTTPS.
[00:45:44.600 --> 00:45:47.320]   They use SSL encryption.
[00:45:47.320 --> 00:45:51.760]   But then there's the issue of the NSA stores everything
[00:45:51.760 --> 00:45:53.360]   encrypted or not.
[00:45:53.360 --> 00:45:56.320]   We know that X-KeyScore told us that.
[00:45:56.320 --> 00:45:58.520]   And then the NSA coming to Google and saying, you know,
[00:45:58.520 --> 00:46:01.360]   those expired SSL keys, the ones you don't use anymore?
[00:46:01.360 --> 00:46:02.840]   Let's get those.
[00:46:02.840 --> 00:46:04.360]   And Google, we don't know.
[00:46:04.360 --> 00:46:07.320]   But Google, we believe, has been asked for those.
[00:46:07.320 --> 00:46:10.480]   And of course, if it's an SSL, cannot say.
[00:46:10.480 --> 00:46:11.640]   And maybe hand it over.
[00:46:11.640 --> 00:46:14.320]   So maybe they don't know exactly what I'm saying today.
[00:46:14.320 --> 00:46:16.440]   But even if I've encrypted it, they might know what I said
[00:46:16.440 --> 00:46:18.040]   six months ago.
[00:46:18.040 --> 00:46:20.760]   I think that was one of the main reasons why Google was one
[00:46:20.760 --> 00:46:23.080]   of the first to adopt a perfect forward secrecy.
[00:46:23.080 --> 00:46:24.600]   Yay!
[00:46:24.600 --> 00:46:28.520]   Yeah, sets up different keys such that if you can record a
[00:46:28.520 --> 00:46:32.560]   conversation and then decrypt it six years later, that
[00:46:32.560 --> 00:46:33.760]   might still have an impact.
[00:46:33.760 --> 00:46:38.400]   But if the keys change every single session, then, and those
[00:46:38.400 --> 00:46:40.160]   keys go away, then there's nothing that you can do about it.
[00:46:40.160 --> 00:46:43.120]   And by the way, if anybody has any doubts that Google wants
[00:46:43.120 --> 00:46:45.720]   to protect you going forward, perfect forward secrecy,
[00:46:45.720 --> 00:46:48.160]   implementing that is proof, right?
[00:46:48.160 --> 00:46:51.880]   Because there's no business argument for that.
[00:46:51.880 --> 00:46:52.600]   It's just because--
[00:46:52.600 --> 00:46:54.640]   That's the interesting story that I'd love to have Matt
[00:46:54.640 --> 00:46:59.320]   can't tell us or else we'd have to kill him, is those
[00:46:59.320 --> 00:47:02.560]   changes that Google did make recently about encrypting and
[00:47:02.560 --> 00:47:06.000]   about core HTTPS and doing those things, how much those
[00:47:06.000 --> 00:47:08.920]   were motivated by what the government was doing?
[00:47:08.920 --> 00:47:10.960]   Why else would they do it, right?
[00:47:10.960 --> 00:47:15.040]   We actually started doing encrypted.google.com in 2008.
[00:47:15.040 --> 00:47:17.960]   And one of the guys who did a lot of heavy lifting on that, his
[00:47:17.960 --> 00:47:20.040]   name is Evan, he actually reports to me.
[00:47:20.040 --> 00:47:22.480]   And we started that after I read "Little Brother," and we
[00:47:22.480 --> 00:47:23.000]   said, "Little Brother."
[00:47:23.000 --> 00:47:24.920]   That's awesome, Matt.
[00:47:24.920 --> 00:47:27.840]   So does Corey know that?
[00:47:27.840 --> 00:47:29.160]   I haven't talked to him about it.
[00:47:29.160 --> 00:47:29.880]   So I should--
[00:47:29.880 --> 00:47:31.040]   You should send him a note.
[00:47:31.040 --> 00:47:32.040]   Oh, wow.
[00:47:32.040 --> 00:47:33.920]   He would love that.
[00:47:33.920 --> 00:47:34.920]   Take that chat room.
[00:47:34.920 --> 00:47:35.920]   That's entertaining.
[00:47:35.920 --> 00:47:36.480]   But you know--
[00:47:36.480 --> 00:47:37.680]   By the way, that--
[00:47:37.680 --> 00:47:42.280]   So we just said about Hollywood, which is that fiction,
[00:47:42.280 --> 00:47:45.320]   which "Little Brother" is, whether it's books or movies or
[00:47:45.320 --> 00:47:49.520]   TV show, can influence where we go going forward.
[00:47:49.520 --> 00:47:51.080]   Yeah, absolutely.
[00:47:51.080 --> 00:47:52.440]   I love that.
[00:47:52.440 --> 00:47:53.680]   And I think it really--
[00:47:53.680 --> 00:47:57.880]   So five years before all this controversy erupted, and I
[00:47:57.880 --> 00:47:58.840]   think the other--
[00:47:58.840 --> 00:48:02.080]   to be fair, the other thing that made a big difference was
[00:48:02.080 --> 00:48:05.800]   the idea of the Chinese hackers back in 2009.
[00:48:05.800 --> 00:48:07.240]   So you put those two together.
[00:48:07.240 --> 00:48:09.360]   And suddenly, I think Google got a little bit of a head
[00:48:09.360 --> 00:48:11.360]   start on realizing you really need--
[00:48:11.360 --> 00:48:17.360]   We may never know what Matt Cutz was going to say.
[00:48:17.360 --> 00:48:19.840]   We didn't know that the NSA has a kill switch.
[00:48:19.840 --> 00:48:26.480]   At 22452, Pacific Daylight Time, Matt was frozen and never
[00:48:26.480 --> 00:48:27.160]   appeared again.
[00:48:27.160 --> 00:48:31.640]   We'll fix Matt Cutz.
[00:48:31.640 --> 00:48:34.160]   While we're doing that, let's take a break.
[00:48:34.160 --> 00:48:36.160]   Corey's got to know that because that's a great story.
[00:48:36.160 --> 00:48:38.080]   And for those who don't know what
[00:48:38.080 --> 00:48:40.800]   the fourth perfect forward secrecy is, it's complicated.
[00:48:40.800 --> 00:48:42.160]   I don't fully understand it.
[00:48:42.160 --> 00:48:45.000]   But the gist of it is what you just heard, which is it
[00:48:45.000 --> 00:48:48.120]   prevents this ability of the government to go back and ask
[00:48:48.120 --> 00:48:50.440]   for keys to prior conversations.
[00:48:50.440 --> 00:48:53.320]   And they have done that we know.
[00:48:53.320 --> 00:48:56.240]   And so that is, to me, very encouraging.
[00:48:56.240 --> 00:48:59.520]   It means at the very least that the Google understands
[00:48:59.520 --> 00:49:02.440]   what you've been saying, Jeff, that it's good business
[00:49:02.440 --> 00:49:06.160]   to protect your users' privacy.
[00:49:06.160 --> 00:49:09.040]   And I think they're just as likely doing it because people
[00:49:09.040 --> 00:49:12.840]   like Evan and Matt go, nobody should be able to read that.
[00:49:12.840 --> 00:49:13.840]   Just because it's right.
[00:49:13.840 --> 00:49:14.800]   It's the right thing to do.
[00:49:14.800 --> 00:49:17.680]   And that's why I love engineers.
[00:49:17.680 --> 00:49:20.880]   And heaven help us if a company ever
[00:49:20.880 --> 00:49:23.600]   becomes such a big business that the people who do this stuff,
[00:49:23.600 --> 00:49:26.200]   the engineers on the floor, don't
[00:49:26.200 --> 00:49:28.040]   get to express their ethical standards.
[00:49:28.040 --> 00:49:29.960]   Because I trust engineers.
[00:49:29.960 --> 00:49:30.520]   Not all of them.
[00:49:30.520 --> 00:49:32.760]   That's the essence of don't be evil.
[00:49:32.760 --> 00:49:35.840]   But what is the previous thing about the national security
[00:49:35.840 --> 00:49:39.200]   leaders, which is that you are then forbidden for not only
[00:49:39.200 --> 00:49:41.280]   talking about the letter, but saying
[00:49:41.280 --> 00:49:44.600]   that you've received the letter or what's underway.
[00:49:44.600 --> 00:49:49.520]   The thing with the guy who shut his email service down,
[00:49:49.520 --> 00:49:50.120]   I thought his name--
[00:49:50.120 --> 00:49:52.120]   Lava Bicca, yeah.
[00:49:52.120 --> 00:49:52.960]   Al-Adar.
[00:49:52.960 --> 00:49:54.960]   Yeah.
[00:49:54.960 --> 00:49:58.360]   Having to say, I'm not sure I can talk about that.
[00:49:58.360 --> 00:49:59.680]   I can't tell my lawyer about that.
[00:49:59.680 --> 00:50:00.480]   It's amazing.
[00:50:00.480 --> 00:50:01.760]   I'm not talking about this.
[00:50:01.760 --> 00:50:05.520]   That was the very Kafka-esque part of this.
[00:50:05.520 --> 00:50:09.040]   Watch the Ladar-Elevenson interview on Democracy Now.
[00:50:09.040 --> 00:50:11.040]   And he's sitting there with his lawyer next to him.
[00:50:11.040 --> 00:50:13.720]   And the fine line that they have to narrow line,
[00:50:13.720 --> 00:50:15.480]   they have to walk.
[00:50:15.480 --> 00:50:17.840]   What's great, though-- and Google's done this too-- is you
[00:50:17.840 --> 00:50:21.720]   can, because now we know enough about Prism and so forth,
[00:50:21.720 --> 00:50:25.760]   you can say just enough to not break the law,
[00:50:25.760 --> 00:50:29.360]   but to give people who are paying attention the information
[00:50:29.360 --> 00:50:30.360]   they need to know.
[00:50:30.360 --> 00:50:34.360]   And I think it's pretty clear what they asked him for.
[00:50:34.360 --> 00:50:36.800]   The way that Lava Bit worked-- we were talking about this
[00:50:36.800 --> 00:50:38.400]   with Steve Gibson.
[00:50:38.400 --> 00:50:40.120]   It was an encrypted store, and you set--
[00:50:40.120 --> 00:50:41.880]   you use your own key.
[00:50:41.880 --> 00:50:44.360]   But of course, in order for email to work,
[00:50:44.360 --> 00:50:46.520]   has to be decrypted on transports,
[00:50:46.520 --> 00:50:49.280]   since most SMTP does not support encryption.
[00:50:49.280 --> 00:50:53.880]   And so Lava Bit had to have your key to the store.
[00:50:53.880 --> 00:50:56.400]   And Steve speculated-- I think he's probably right based
[00:50:56.400 --> 00:50:58.600]   on what Ladar said-- that the government was saying,
[00:50:58.600 --> 00:51:01.760]   OK, well, just give us the keys.
[00:51:01.760 --> 00:51:03.600]   And he said, I don't want to do this, because I don't--
[00:51:03.600 --> 00:51:06.000]   so instead of, I'm not going to fight it,
[00:51:06.000 --> 00:51:07.400]   but I'm going to do to shut the whole thing down
[00:51:07.400 --> 00:51:09.800]   and raise the hard drives, then give him the keys.
[00:51:09.800 --> 00:51:11.360]   But then I wonder if he's going to be--
[00:51:11.360 --> 00:51:14.280]   is he going to be accused of thus knowingly
[00:51:14.280 --> 00:51:16.600]   erasing evidence, destroying evidence?
[00:51:16.600 --> 00:51:19.120]   Well, I'm sure that he's walking a very tightrope.
[00:51:19.120 --> 00:51:23.200]   And what I do applaud is that instead of leaving the country,
[00:51:23.200 --> 00:51:25.400]   he's staying it out, and he's giving interviews,
[00:51:25.400 --> 00:51:30.840]   and he's doing the best he can to give us information.
[00:51:30.840 --> 00:51:31.400]   Let's take a break.
[00:51:31.400 --> 00:51:32.720]   We're going to get Matt Cutz back.
[00:51:32.720 --> 00:51:34.720]   I mean, I see a little Matt Cutz.
[00:51:34.720 --> 00:51:35.480]   I think I'm back.
[00:51:35.480 --> 00:51:36.240]   I'm sorry.
[00:51:36.240 --> 00:51:38.520]   Somebody's just flipping the switch on the network or so.
[00:51:38.520 --> 00:51:39.640]   Oh, no, no, no.
[00:51:39.640 --> 00:51:40.760]   We know who's in charge here.
[00:51:40.760 --> 00:51:41.480]   It's the NSA.
[00:51:41.480 --> 00:51:43.720]   So it's OK.
[00:51:43.720 --> 00:51:45.040]   Let me do an ad anyway.
[00:51:45.040 --> 00:51:46.040]   We can get that all in.
[00:51:46.040 --> 00:51:46.720]   All that working.
[00:51:46.720 --> 00:51:47.520]   New York time.
[00:51:47.520 --> 00:51:51.160]   Yeah, is the New York Times back?
[00:51:51.160 --> 00:51:51.800]   Yes, it is.
[00:51:51.800 --> 00:51:52.600]   I believe so.
[00:51:52.600 --> 00:51:53.720]   Yeah, I just checked it.
[00:51:53.720 --> 00:52:00.040]   So what all morning, HTTP 1.1, nobody home?
[00:52:00.040 --> 00:52:01.160]   What the hell was that all about?
[00:52:01.160 --> 00:52:01.880]   Were they being hacked?
[00:52:01.880 --> 00:52:02.920]   Well, wasn't they have a story up?
[00:52:02.920 --> 00:52:05.600]   I don't know.
[00:52:05.600 --> 00:52:08.600]   Or somebody just flipped the switch.
[00:52:08.600 --> 00:52:09.240]   Oops.
[00:52:09.240 --> 00:52:11.960]   I think they said they just said I had a guy.
[00:52:11.960 --> 00:52:14.760]   I hired a CTO.
[00:52:14.760 --> 00:52:17.360]   This is my worst hire ever.
[00:52:17.360 --> 00:52:19.240]   Because he seemed like he was bald.
[00:52:19.240 --> 00:52:19.880]   He was old.
[00:52:19.880 --> 00:52:20.840]   He had maturity.
[00:52:20.840 --> 00:52:22.160]   I was not hiring kids.
[00:52:22.160 --> 00:52:23.760]   And they were causing problems with my boss.
[00:52:23.760 --> 00:52:25.200]   And so I hired this guy.
[00:52:25.200 --> 00:52:27.880]   And the server room got too hot.
[00:52:27.880 --> 00:52:29.560]   And so he started turning off servers.
[00:52:29.560 --> 00:52:35.840]   [LAUGHTER]
[00:52:35.840 --> 00:52:37.880]   He was-- I had to fire him very soon.
[00:52:37.880 --> 00:52:39.720]   But he was comfortable.
[00:52:39.720 --> 00:52:45.240]   What were you going to say, Kevin?
[00:52:45.240 --> 00:52:48.200]   About the times, did they say what was going on?
[00:52:48.200 --> 00:52:49.760]   There was a thing that they said--
[00:52:49.760 --> 00:52:50.160]   There's an article.
[00:52:50.160 --> 00:52:54.240]   --they applied a service like an upgrade patch.
[00:52:54.240 --> 00:52:55.040]   And then there's a--
[00:52:55.040 --> 00:52:56.040]   Yeah, that's the usual.
[00:52:56.040 --> 00:52:58.880]   It was a failure during regular maintenance of NYTimes.com.
[00:52:58.880 --> 00:53:00.920]   And not the result of a cyber attack.
[00:53:00.920 --> 00:53:03.240]   Eileen Murphy, a spokeswoman for the New York Times Company,
[00:53:03.240 --> 00:53:06.080]   gave this interview to the New York Times reporter.
[00:53:06.080 --> 00:53:07.880]   No, I'm Cohen.
[00:53:07.880 --> 00:53:09.920]   Outage occurred within seconds of a scheduled maintenance
[00:53:09.920 --> 00:53:10.760]   update being pushed out.
[00:53:10.760 --> 00:53:11.920]   We believe that was the cause.
[00:53:11.920 --> 00:53:14.800]   It went down 11 10 AM Eastern.
[00:53:14.800 --> 00:53:17.480]   A sporadically returned around 1 15 PM.
[00:53:17.480 --> 00:53:19.520]   Boy, two hours outage for the New York Times.
[00:53:19.520 --> 00:53:21.320]   That's a long time.
[00:53:21.320 --> 00:53:23.400]   So this is-- this I just got this headline from the Washington
[00:53:23.400 --> 00:53:25.880]   Post, a calm post, which was obvious there.
[00:53:25.880 --> 00:53:27.040]   They're a joke blog.
[00:53:27.040 --> 00:53:27.880]   But nonetheless.
[00:53:27.880 --> 00:53:29.960]   New York Times website goes down.
[00:53:29.960 --> 00:53:33.600]   Panic mobs stream into street demanding to no trends.
[00:53:33.600 --> 00:53:35.360]   [LAUGHTER]
[00:53:35.360 --> 00:53:38.520]   Where's my bits blog?
[00:53:38.520 --> 00:53:42.520]   The site had 7.1 million visits on Monday.
[00:53:42.520 --> 00:53:47.520]   So that's millions who were turned away.
[00:53:47.520 --> 00:53:51.160]   Although the Times has been in dimension this in January,
[00:53:51.160 --> 00:53:54.200]   the Times reported that hackers, Chinese hackers,
[00:53:54.200 --> 00:53:56.600]   had repeatedly attacked the website.
[00:53:56.600 --> 00:53:57.840]   And it had in fact broken in.
[00:53:57.840 --> 00:54:02.600]   Yeah, it must be hard.
[00:54:02.600 --> 00:54:03.280]   Must be hard.
[00:54:03.280 --> 00:54:05.560]   It's merely making Arthur Salzberger think,
[00:54:05.560 --> 00:54:07.320]   do we really want to stop printing?
[00:54:07.320 --> 00:54:10.320]   [LAUGHTER]
[00:54:10.320 --> 00:54:11.800]   Really?
[00:54:11.800 --> 00:54:14.160]   That was what one comment was.
[00:54:14.160 --> 00:54:15.160]   The website is down.
[00:54:15.160 --> 00:54:16.680]   But don't worry, I printed it all out for you.
[00:54:16.680 --> 00:54:20.520]   [LAUGHTER]
[00:54:20.520 --> 00:54:23.600]   Here, look.
[00:54:23.600 --> 00:54:24.640]   I love it.
[00:54:24.640 --> 00:54:27.680]   Our show today brought to you by LegalZoom.com.
[00:54:27.680 --> 00:54:29.440]   We're not talking a lot from despite the name.
[00:54:29.440 --> 00:54:33.880]   What we are talking is legal paperwork that can really
[00:54:33.880 --> 00:54:36.440]   make a difference in your business and your personal life
[00:54:36.440 --> 00:54:41.600]   for a very low cost that you can do yourself at LegalZoom.com.
[00:54:41.600 --> 00:54:42.600]   You wouldn't be alone.
[00:54:42.600 --> 00:54:45.280]   Millions of people have used LegalZoom.com.
[00:54:45.280 --> 00:54:47.680]   I think it's been like 12 million people over the last 12
[00:54:47.680 --> 00:54:48.920]   years.
[00:54:48.920 --> 00:54:53.360]   It is national make-a-will months.
[00:54:53.360 --> 00:54:54.960]   So August, yes.
[00:54:54.960 --> 00:54:56.120]   So now is the time.
[00:54:56.120 --> 00:54:58.720]   If you don't have a last-will and testament to get over
[00:54:58.720 --> 00:55:01.760]   to LegalZoom.com, they'll get you 15% off your last-will.
[00:55:01.760 --> 00:55:02.680]   Offer does end soon.
[00:55:02.680 --> 00:55:04.600]   Don't waste time.
[00:55:04.600 --> 00:55:07.280]   Your life might be ending soon, and it'll be nice to have a will.
[00:55:07.280 --> 00:55:09.480]   If you don't, well, then the government
[00:55:09.480 --> 00:55:12.440]   decides what happens to your money, your kids, your assets.
[00:55:12.440 --> 00:55:15.840]   You can do so many things at LegalZoom.com, LLC,
[00:55:15.840 --> 00:55:18.400]   incorporation, trademark.
[00:55:18.400 --> 00:55:21.360]   If you've already got a will, let me point another thing--
[00:55:21.360 --> 00:55:25.280]   I can point you at the durable health care power of attorney.
[00:55:25.280 --> 00:55:30.800]   Really a good thing to have so that if you are incapacitated,
[00:55:30.800 --> 00:55:34.200]   somebody you trust is making medical decisions for you,
[00:55:34.200 --> 00:55:37.640]   you might assume that that's-- oh, well, my next akin
[00:55:37.640 --> 00:55:38.440]   will be able to do that.
[00:55:38.440 --> 00:55:40.440]   No.
[00:55:40.440 --> 00:55:41.360]   No.
[00:55:41.360 --> 00:55:43.040]   So you can make this very simply.
[00:55:43.040 --> 00:55:43.960]   You can do a living will.
[00:55:43.960 --> 00:55:49.200]   In fact, if you want, if you go to LegalZoom.com,
[00:55:49.200 --> 00:55:52.560]   you can do a living trust, and they will give you a pour
[00:55:52.560 --> 00:55:55.240]   over will absolutely free.
[00:55:55.240 --> 00:55:56.120]   Here's what I want you to do.
[00:55:56.120 --> 00:56:00.240]   Visit LegalZoom.com, use the offer code TWIG.
[00:56:00.240 --> 00:56:02.040]   You'll get $10 off any service.
[00:56:02.040 --> 00:56:06.040]   15% off a living-- or a will or a living will.
[00:56:06.040 --> 00:56:07.240]   It's National Make a Will Month.
[00:56:07.240 --> 00:56:10.480]   This is really a good stimulus to get you doing this.
[00:56:10.480 --> 00:56:12.760]   And by the way, LegalZoom, most of the stuff
[00:56:12.760 --> 00:56:13.440]   you can do yourself.
[00:56:13.440 --> 00:56:15.760]   But if you want help from an attorney, they've negotiated.
[00:56:15.760 --> 00:56:17.000]   I think this is so great.
[00:56:17.000 --> 00:56:19.760]   Fixed rate legal plans with attorneys
[00:56:19.760 --> 00:56:23.120]   in your state who can give you advice at a cost you know.
[00:56:23.120 --> 00:56:25.560]   It's not going to get out of spiral out of control.
[00:56:25.560 --> 00:56:27.240]   You choose the attorney based on their profile
[00:56:27.240 --> 00:56:30.440]   and unedited user reviews.
[00:56:30.440 --> 00:56:31.680]   Love LegalZoom, you will too.
[00:56:31.680 --> 00:56:35.600]   LegalZoom.com, make that well.
[00:56:35.600 --> 00:56:41.120]   Durable power of health is really important.
[00:56:41.120 --> 00:56:42.120]   All of that stuff.
[00:56:42.120 --> 00:56:45.080]   LegalZoom.com.
[00:56:45.080 --> 00:56:48.040]   We're talking TWIG with Matt Cutz of the Google.
[00:56:48.040 --> 00:56:50.080]   He's the man in charge fighting web spam,
[00:56:50.080 --> 00:56:53.160]   keeping those search results clean and beautiful,
[00:56:53.160 --> 00:56:58.160]   sparkling, fresh and new, smelling like linen.
[00:56:58.160 --> 00:56:59.880]   Miss somebody.
[00:56:59.880 --> 00:57:00.360]   Meantie--
[00:57:00.360 --> 00:57:02.880]   I'm going to say like Kevin Marks backyard.
[00:57:02.880 --> 00:57:03.880]   Yeah, Kevin.
[00:57:03.880 --> 00:57:05.280]   Kevin always does it from his garden.
[00:57:05.280 --> 00:57:07.560]   I'm going to say garden because he's British.
[00:57:07.560 --> 00:57:08.880]   It's beautiful out there.
[00:57:08.880 --> 00:57:10.080]   It's pretty nice out here.
[00:57:10.080 --> 00:57:13.520]   Kevin Marks at Salesforce, but he's been everywhere,
[00:57:13.520 --> 00:57:16.760]   including the Google itself as well as--
[00:57:16.760 --> 00:57:20.760]   Are you sad to see Chris Messina move on?
[00:57:20.760 --> 00:57:22.680]   In some ways, I'm not-- is my guide to see me move on?
[00:57:22.680 --> 00:57:24.120]   Because he's going to be able to talk a bit more.
[00:57:24.120 --> 00:57:25.760]   Because one of the challenges he had there
[00:57:25.760 --> 00:57:27.600]   was he didn't get to speak as much.
[00:57:27.600 --> 00:57:31.720]   Chris, like you, an advocate for open standards, for APIs,
[00:57:31.720 --> 00:57:33.560]   for making the world a better place.
[00:57:33.560 --> 00:57:37.160]   And that's kind of what he was doing at Google.
[00:57:37.160 --> 00:57:41.200]   Quite famously, the guy who created the first hashtags
[00:57:41.200 --> 00:57:42.400]   on Twitter.
[00:57:42.400 --> 00:57:43.200]   Yes.
[00:57:43.200 --> 00:57:44.760]   An advocate for open web.
[00:57:44.760 --> 00:57:48.960]   He was on the board of OpenID and the Open Web Foundation.
[00:57:48.960 --> 00:57:50.040]   Founded bar camp.
[00:57:50.040 --> 00:57:50.400]   Great.
[00:57:50.400 --> 00:57:51.040]   He's not dead.
[00:57:51.040 --> 00:57:53.280]   It sounds like I'm eulogizing him.
[00:57:53.280 --> 00:57:54.880]   He's still alive, folks.
[00:57:54.880 --> 00:57:57.720]   He's just leaving the Google.
[00:57:57.720 --> 00:58:01.240]   And he's going to a startup now.
[00:58:01.240 --> 00:58:02.240]   Is that right?
[00:58:02.240 --> 00:58:02.240]   Yes.
[00:58:02.240 --> 00:58:04.120]   An art startup, right?
[00:58:04.120 --> 00:58:04.880]   Oh, that's cool.
[00:58:04.880 --> 00:58:06.400]   Good for him.
[00:58:06.400 --> 00:58:07.920]   I really-- I always liked Chris a lot.
[00:58:07.920 --> 00:58:10.120]   And I think the work he did at Mozilla
[00:58:10.120 --> 00:58:13.000]   and at Google was really valuable.
[00:58:13.000 --> 00:58:15.080]   Promoting the Open Web, which is kind of what you're all
[00:58:15.080 --> 00:58:15.640]   about, Kevin.
[00:58:15.640 --> 00:58:16.440]   That's why I bring it up.
[00:58:16.440 --> 00:58:18.000]   Also here, Jeff Jarvis.
[00:58:18.000 --> 00:58:19.960]   He's a professor of journalism at the City University
[00:58:19.960 --> 00:58:20.300]   of New York.
[00:58:20.300 --> 00:58:22.480]   And his blog is buzzmachine.com.
[00:58:22.480 --> 00:58:24.120]   If you're just tuning in, Gina has the day off.
[00:58:24.120 --> 00:58:26.320]   She'll be back, I hope, next week.
[00:58:26.320 --> 00:58:29.680]   She's fine.
[00:58:29.680 --> 00:58:33.280]   You want to look inside the TARDIS?
[00:58:33.280 --> 00:58:34.520]   Did you see this?
[00:58:34.520 --> 00:58:36.400]   That's the geekiest thing ever.
[00:58:36.400 --> 00:58:37.560]   You guys at Google.
[00:58:37.560 --> 00:58:40.040]   It's so cool.
[00:58:40.040 --> 00:58:41.800]   It's Comic Con every day there.
[00:58:41.800 --> 00:58:43.160]   It's Comic Con every day.
[00:58:43.160 --> 00:58:47.240]   So you have to go to a specific place in Google Maps, right?
[00:58:47.240 --> 00:58:49.320]   Walk me through this because I've not done this before.
[00:58:49.320 --> 00:58:51.800]   So I click the link and I am at--
[00:58:51.800 --> 00:58:52.360]   wait a minute.
[00:58:52.360 --> 00:58:53.680]   No, that's where I am right now.
[00:58:53.680 --> 00:58:55.120]   So that can't be where the TARDIS is.
[00:58:55.120 --> 00:58:56.760]   Let me click that link again.
[00:58:56.760 --> 00:58:58.040]   Oh, it could be.
[00:58:58.040 --> 00:58:59.560]   We thought you were the next Doctor Who.
[00:58:59.560 --> 00:59:03.200]   [LAUGHTER]
[00:59:03.200 --> 00:59:05.040]   Try opening up in your browser's incognito.
[00:59:05.040 --> 00:59:05.680]   There you got it.
[00:59:05.680 --> 00:59:06.280]   OK.
[00:59:06.280 --> 00:59:08.280]   So when you do Street View in this location, which
[00:59:08.280 --> 00:59:09.600]   looks like it's London, right?
[00:59:09.600 --> 00:59:13.680]   You'll see a pretty traditional blue call box, please call.
[00:59:13.680 --> 00:59:16.440]   Do they still have those in London?
[00:59:16.440 --> 00:59:17.440]   Very few.
[00:59:17.440 --> 00:59:19.240]   Very few.
[00:59:19.240 --> 00:59:21.960]   They did it when a Doctor Who started in the '60s
[00:59:21.960 --> 00:59:23.880]   because they were very common at the time.
[00:59:23.880 --> 00:59:26.720]   And of course, it made a perfect place for a time Lord.
[00:59:26.720 --> 00:59:30.120]   A perfect disguise for a time Lord's spaceship.
[00:59:30.120 --> 00:59:31.400]   Now, you've got to click the--
[00:59:31.400 --> 00:59:33.280]   see the double, Chevron?
[00:59:33.280 --> 00:59:36.120]   You might have to do up arrow if you have the new maps.
[00:59:36.120 --> 00:59:37.560]   Oh my god.
[00:59:37.560 --> 00:59:40.360]   It's bigger on the inside.
[00:59:40.360 --> 00:59:42.440]   If you're not a Hoovian, this will make no sense
[00:59:42.440 --> 00:59:43.760]   or be of any interest.
[00:59:43.760 --> 00:59:47.960]   But look at that.
[00:59:47.960 --> 00:59:50.680]   They've got the whole TARDIS, just a control room.
[00:59:50.680 --> 00:59:52.040]   There's more?
[00:59:52.040 --> 00:59:53.560]   There's a swimming pool.
[00:59:53.560 --> 00:59:55.360]   There's a library.
[00:59:55.360 --> 00:59:59.000]   There's the bedrooms that they had.
[00:59:59.000 --> 01:00:01.000]   I'm not sure they've actually got them here, but they're the actual--
[01:00:01.000 --> 01:00:02.480]   Well, go down those steps.
[01:00:02.480 --> 01:00:05.360]   See if we can go through the door there.
[01:00:05.360 --> 01:00:06.360]   Oh my.
[01:00:06.360 --> 01:00:07.120]   Oh my.
[01:00:07.120 --> 01:00:07.620]   Oh no.
[01:00:07.620 --> 01:00:08.120]   No.
[01:00:08.120 --> 01:00:08.620]   No.
[01:00:08.620 --> 01:00:09.360]   That's not the most accurate.
[01:00:09.360 --> 01:00:09.720]   No.
[01:00:09.720 --> 01:00:10.720]   No.
[01:00:10.720 --> 01:00:12.480]   So is this like a 20%--
[01:00:12.480 --> 01:00:15.640]   would this count as a 20% project matter?
[01:00:15.640 --> 01:00:16.720]   Yeah, I suspect so.
[01:00:16.720 --> 01:00:17.840]   It's a nice Easter egg.
[01:00:17.840 --> 01:00:20.040]   And I think that--
[01:00:20.040 --> 01:00:22.040]   The actual--
[01:00:22.040 --> 01:00:24.040]   The model number on the Chromecast
[01:00:24.040 --> 01:00:26.840]   was the other Easter egg I liked about the Hitchhiker's
[01:00:26.840 --> 01:00:27.440]   Guide to the Galaxy.
[01:00:27.440 --> 01:00:28.680]   We loved that.
[01:00:28.680 --> 01:00:30.720]   Yeah, it was a--
[01:00:30.720 --> 01:00:35.800]   what was the model number as H2G2 and 4.2 or something
[01:00:35.800 --> 01:00:36.280]   like that?
[01:00:36.280 --> 01:00:36.800]   Yeah.
[01:00:36.800 --> 01:00:37.800]   It's 42.
[01:00:37.800 --> 01:00:39.920]   Yeah, I love that.
[01:00:39.920 --> 01:00:41.280]   By the way, thank you for the--
[01:00:41.280 --> 01:00:43.280]   I don't know why I'm thanking you, Matt, but nice job
[01:00:43.280 --> 01:00:44.000]   on the Chromecast.
[01:00:44.000 --> 01:00:45.640]   I just love that thing.
[01:00:45.640 --> 01:00:47.240]   It's a really nice device.
[01:00:47.240 --> 01:00:50.520]   Yeah, it's the whole idea that you can fit a little tiny computer
[01:00:50.520 --> 01:00:53.800]   in $35 worth of plastic is pretty--
[01:00:53.800 --> 01:00:57.000]   So pretty much sold out everywhere
[01:00:57.000 --> 01:00:59.840]   unless you go to eBay and spend $100 on it.
[01:00:59.840 --> 01:01:02.000]   Josh, I should say one of my spare ones.
[01:01:02.000 --> 01:01:03.640]   Yeah, I bought five.
[01:01:03.640 --> 01:01:05.400]   I probably should.
[01:01:05.400 --> 01:01:07.560]   You've probably got at least five TVs there.
[01:01:07.560 --> 01:01:08.760]   Oh, yeah.
[01:01:08.760 --> 01:01:09.920]   Oh, yeah.
[01:01:09.920 --> 01:01:10.720]   Absolutely.
[01:01:10.720 --> 01:01:13.520]   No, I have three of my TVs and I got two for Lisa
[01:01:13.520 --> 01:01:14.960]   because she's got two.
[01:01:14.960 --> 01:01:17.560]   I didn't put on every TV, but most of them.
[01:01:17.560 --> 01:01:18.120]   It's cool.
[01:01:18.120 --> 01:01:20.120]   I use it because I play Google Play music.
[01:01:20.120 --> 01:01:22.280]   And then when I bought Breaking Bad,
[01:01:22.280 --> 01:01:23.920]   this is why it's just brilliant.
[01:01:23.920 --> 01:01:27.280]   Instead of buying it on Amazon or iTunes,
[01:01:27.280 --> 01:01:30.920]   I bought it on Google Play because now I can go over to her house
[01:01:30.920 --> 01:01:33.640]   and we can play it off my phone.
[01:01:33.640 --> 01:01:34.320]   Yep.
[01:01:34.320 --> 01:01:35.520]   Very easy and--
[01:01:35.520 --> 01:01:36.040]   Pretty clever.
[01:01:36.040 --> 01:01:37.400]   Just makes it really convenient.
[01:01:37.400 --> 01:01:38.400]   Yeah.
[01:01:38.400 --> 01:01:38.760]   Nice.
[01:01:38.760 --> 01:01:39.680]   Yeah.
[01:01:39.680 --> 01:01:41.840]   Pretty neat stuff.
[01:01:41.840 --> 01:01:43.080]   Where is this?
[01:01:43.080 --> 01:01:44.480]   Is this the telephone box?
[01:01:44.480 --> 01:01:45.800]   Is this in London?
[01:01:45.800 --> 01:01:46.880]   Looks like it's England.
[01:01:46.880 --> 01:01:50.440]   Yeah, there's an underground station next to it.
[01:01:50.440 --> 01:01:51.320]   What's the station?
[01:01:51.320 --> 01:01:52.120]   Can you read it?
[01:01:52.120 --> 01:01:55.240]   Uh, I don't know.
[01:01:55.240 --> 01:01:57.080]   Can you read it, Chad, on the--
[01:01:57.080 --> 01:01:58.120]   Oh, sure.
[01:01:58.120 --> 01:01:59.320]   Earl, Earl, Earl Court.
[01:01:59.320 --> 01:01:59.880]   Earl's Court.
[01:01:59.880 --> 01:02:00.440]   So it's London.
[01:02:00.440 --> 01:02:00.880]   That's cool.
[01:02:00.880 --> 01:02:01.320]   OK.
[01:02:01.320 --> 01:02:03.200]   Right.
[01:02:03.200 --> 01:02:04.240]   Is that accurate, Kevin?
[01:02:04.240 --> 01:02:06.720]   Is that where it normally is?
[01:02:06.720 --> 01:02:08.680]   Is there actually a police box there?
[01:02:08.680 --> 01:02:11.240]   I was assuming there actually is a police box there.
[01:02:11.240 --> 01:02:12.880]   Isn't that funny?
[01:02:12.880 --> 01:02:17.960]   So what-- what that is like a phone booth for a Bobby to use?
[01:02:17.960 --> 01:02:18.720]   Yeah.
[01:02:18.720 --> 01:02:20.400]   There's actually originally holding cells, I think.
[01:02:20.400 --> 01:02:20.800]   They're the items--
[01:02:20.800 --> 01:02:21.800]   What?
[01:02:21.800 --> 01:02:26.960]   You could lock someone in them pretty fully while you--
[01:02:26.960 --> 01:02:29.880]   there was also a phone in them you could call them resistance.
[01:02:29.880 --> 01:02:30.640]   That's so funny.
[01:02:30.640 --> 01:02:31.800]   Excuse me, sir.
[01:02:31.800 --> 01:02:34.880]   Would you mind stepping in here?
[01:02:34.880 --> 01:02:36.400]   Bye.
[01:02:36.400 --> 01:02:38.800]   You've now been transported to the 28th century.
[01:02:38.800 --> 01:02:42.960]   OK.
[01:02:42.960 --> 01:02:47.640]   Google Play revenue is going well up 67% over the last six months.
[01:02:47.640 --> 01:02:49.560]   A lot of it, by the way, in Asia.
[01:02:49.560 --> 01:02:53.880]   What's your experience with the Play Store?
[01:02:53.880 --> 01:02:56.400]   I don't find that everything I want is in there.
[01:02:56.400 --> 01:02:58.280]   HBO, so far, has not--
[01:02:58.280 --> 01:03:02.840]   has only tapped Amazon and Apple, I think.
[01:03:02.840 --> 01:03:04.320]   I've been using it for the music.
[01:03:04.320 --> 01:03:05.800]   I love the music.
[01:03:05.800 --> 01:03:09.200]   That's because it needs better metadata for classical.
[01:03:09.200 --> 01:03:13.000]   It's actually quite hard to find, like, beta,
[01:03:13.000 --> 01:03:13.960]   and symphonies and things.
[01:03:13.960 --> 01:03:14.560]   Well, I agree.
[01:03:14.560 --> 01:03:18.520]   I type Mozart, and I keep getting those damn operas.
[01:03:18.520 --> 01:03:23.760]   But also, you'll have-- there's lots of variations on there,
[01:03:23.760 --> 01:03:26.120]   but they're all like 100 best Mozart tracks.
[01:03:26.120 --> 01:03:27.560]   It's like, no, just give me the--
[01:03:27.560 --> 01:03:29.120]   don't you can only find a catalog, please.
[01:03:29.120 --> 01:03:29.600]   Right.
[01:03:29.600 --> 01:03:30.240]   So I can exactly.
[01:03:30.240 --> 01:03:31.400]   You can find the ones I want.
[01:03:31.400 --> 01:03:33.920]   But also, when it's even playing on the screen,
[01:03:33.920 --> 01:03:35.600]   they're truncating the movements and things.
[01:03:35.600 --> 01:03:37.200]   So you can't actually read which one it is.
[01:03:37.200 --> 01:03:38.800]   Nothing worse than a truncated movement.
[01:03:38.800 --> 01:03:46.880]   You know, the problem with classical is you need to buy a metadata.
[01:03:46.880 --> 01:03:48.240]   You need to compose a--
[01:03:48.240 --> 01:03:50.720]   I think there's actually literally something wrong with me.
[01:03:50.720 --> 01:03:55.800]   Truncated movement.
[01:03:55.800 --> 01:04:00.080]   It's just another-- there's really something wrong with my brain.
[01:04:00.080 --> 01:04:02.800]   Top five revenue generating apps on Google Play.
[01:04:02.800 --> 01:04:04.800]   Candy Crush Saga number one.
[01:04:04.800 --> 01:04:06.920]   Now, that's-- oh, you like that.
[01:04:06.920 --> 01:04:07.800]   Oh, thumbs up.
[01:04:07.800 --> 01:04:13.440]   One of our studio audience members apparently captured
[01:04:13.440 --> 01:04:15.600]   by the Candy Crush.
[01:04:15.600 --> 01:04:17.960]   Then something from Gung Ho online entertainment
[01:04:17.960 --> 01:04:19.800]   that looks like it's in the--
[01:04:19.800 --> 01:04:22.280]   no, that's Japanese puzzles and dragons.
[01:04:22.280 --> 01:04:25.480]   Number three, a Korean title that I can't read.
[01:04:25.480 --> 01:04:29.720]   And number four, Line, which I think is Line 2, Line Corporation.
[01:04:29.720 --> 01:04:36.480]   Number five, another one from Kakao, a Korean company.
[01:04:36.480 --> 01:04:40.160]   Top five revenue generating apps, Candy Crush Saga,
[01:04:40.160 --> 01:04:43.320]   Clash of Clans, heyday, puzzles and dragons, all games.
[01:04:43.320 --> 01:04:46.880]   The Hobbit Kingdoms of Middle Earth.
[01:04:46.880 --> 01:04:50.760]   So yeah, and this is the App Store.
[01:04:50.760 --> 01:04:57.320]   But the revenue on the App Store is not caught up with Apple.
[01:04:57.320 --> 01:04:58.640]   But it's growing.
[01:04:58.640 --> 01:05:00.360]   Apple is up 15%.
[01:05:00.360 --> 01:05:03.800]   Well, that's the argument I always get when I yell at media companies
[01:05:03.800 --> 01:05:05.640]   for building iOS first instead of Android.
[01:05:05.640 --> 01:05:06.920]   I say, how snotty can you be?
[01:05:06.920 --> 01:05:08.760]   What are you doing here?
[01:05:08.760 --> 01:05:12.760]   And they say, what would the revenue be bigger?
[01:05:12.760 --> 01:05:13.760]   Not much longer.
[01:05:13.760 --> 01:05:16.280]   They're not normally charging for their apps, are they?
[01:05:16.280 --> 01:05:16.960]   Yeah, that's part of it.
[01:05:16.960 --> 01:05:19.880]   A lot of the apps are free.
[01:05:19.880 --> 01:05:25.080]   I think it's still mostly that the developers really
[01:05:25.080 --> 01:05:27.080]   like developing for iOS.
[01:05:27.080 --> 01:05:28.560]   And I think that that's going to change.
[01:05:28.560 --> 01:05:34.120]   Even Fred Wilson, just today, I think on a blog post,
[01:05:34.120 --> 01:05:36.320]   said that Apple's got to be a little bit worried.
[01:05:36.320 --> 01:05:39.200]   Now, we know that Carl Icahn's bullish on Apple.
[01:05:39.200 --> 01:05:40.040]   But for every--
[01:05:40.040 --> 01:05:42.800]   [LAUGHTER]
[01:05:42.800 --> 01:05:44.160]   I don't know what to do.
[01:05:44.160 --> 01:05:44.640]   Who is it?
[01:05:44.640 --> 01:05:45.680]   I love headline.
[01:05:45.680 --> 01:05:47.800]   That was like 77-year-old knows how to use Twitter.
[01:05:47.800 --> 01:05:50.560]   [LAUGHTER]
[01:05:50.560 --> 01:05:53.280]   I mean, just unbelievable.
[01:05:53.280 --> 01:05:56.200]   And then the stock market goes crazy because Carl Icahn
[01:05:56.200 --> 01:05:58.160]   says, yeah, I'm bullish on Apple.
[01:05:58.160 --> 01:06:00.840]   And it goes up like 10% or something.
[01:06:00.840 --> 01:06:02.160]   Oh, it's up again today.
[01:06:02.160 --> 01:06:03.040]   And it's up again today.
[01:06:03.040 --> 01:06:05.360]   It's like these people-- well, if you listen to the stock
[01:06:05.360 --> 01:06:06.800]   market, clearly, that's not the place
[01:06:06.800 --> 01:06:08.640]   to get your technology information.
[01:06:08.640 --> 01:06:13.200]   But Fred Wilson, who was an Android fan, makes a very good point.
[01:06:13.200 --> 01:06:15.320]   He says, I don't want a one-horse race.
[01:06:15.320 --> 01:06:18.360]   And at this point, Android and Google
[01:06:18.360 --> 01:06:21.960]   is about to run the table.
[01:06:21.960 --> 01:06:27.440]   And that Apple better sit up and do something here.
[01:06:27.440 --> 01:06:28.960]   Some say a cheap iPhone.
[01:06:28.960 --> 01:06:30.480]   I don't know if that's the key.
[01:06:30.480 --> 01:06:35.080]   It might be worldwide where they don't have a phone subsidies.
[01:06:35.080 --> 01:06:37.240]   Fred says, I sure hope Apple does announce and ship
[01:06:37.240 --> 01:06:37.920]   a cheap iPhone.
[01:06:37.920 --> 01:06:40.840]   The prepaid users can purchase for less than 200 bucks.
[01:06:40.840 --> 01:06:42.640]   I don't think that's going to happen.
[01:06:42.640 --> 01:06:43.760]   I hope Apple takes a step.
[01:06:43.760 --> 01:06:46.120]   It must take to maintain its market share and grow it outside
[01:06:46.120 --> 01:06:48.440]   the US.
[01:06:48.440 --> 01:06:52.760]   As of Friday, you can buy a Firefox phone on eBay for $85.
[01:06:52.760 --> 01:06:53.400]   Wow.
[01:06:53.400 --> 01:06:54.880]   Yes, I'm looking forward to getting one of those.
[01:06:54.880 --> 01:06:55.440]   Did you order it?
[01:06:55.440 --> 01:06:56.800]   It's very with.
[01:06:56.800 --> 01:06:58.040]   They're Friday, you go some sale.
[01:06:58.040 --> 01:06:59.400]   Coming soon.
[01:06:59.400 --> 01:07:00.920]   A few people have got them already.
[01:07:00.920 --> 01:07:03.440]   But my friends at Mizzetto have had them for a while.
[01:07:03.440 --> 01:07:04.840]   But they've got new ones coming.
[01:07:04.840 --> 01:07:06.520]   But they'll be shipping them abroad first.
[01:07:06.520 --> 01:07:10.840]   The goal is not for this to be a massive high-end phone.
[01:07:10.840 --> 01:07:12.480]   They're competing with the feature phones primarily.
[01:07:12.480 --> 01:07:15.840]   So it's not designed to be as high-end as iOS or the higher-end
[01:07:15.840 --> 01:07:17.160]   of Android.
[01:07:17.160 --> 01:07:20.760]   It's designed to be the feature phone and web-based.
[01:07:20.760 --> 01:07:22.200]   It's democratic.
[01:07:22.200 --> 01:07:22.920]   You know, it's--
[01:07:22.920 --> 01:07:24.640]   And the idea is that you should be able to run the web-based
[01:07:24.640 --> 01:07:26.760]   apps on your Android or iOS as well.
[01:07:26.760 --> 01:07:31.080]   So that's the sort of principle behind it.
[01:07:31.080 --> 01:07:33.240]   I think for HTML5 now, it might be mature enough
[01:07:33.240 --> 01:07:36.920]   that you really could see a credible web app.
[01:07:36.920 --> 01:07:37.440]   It's a trade-off.
[01:07:37.440 --> 01:07:38.800]   It turns what you're trying to do.
[01:07:38.800 --> 01:07:41.600]   So there was a huge--
[01:07:41.600 --> 01:07:44.160]   somebody wrote this long article about why mobile will always
[01:07:44.160 --> 01:07:47.240]   need to be native, which came down to JavaScript performance
[01:07:47.240 --> 01:07:48.560]   and government collection stuff.
[01:07:48.560 --> 01:07:51.280]   And what that one said to me was, we
[01:07:51.280 --> 01:07:53.520]   need to put more high-level abstractions
[01:07:53.520 --> 01:07:56.080]   into the HTML standard so that you're not
[01:07:56.080 --> 01:07:59.000]   trying to write this stuff in JavaScript.
[01:07:59.000 --> 01:08:01.360]   If you've got WebGL abstractions,
[01:08:01.360 --> 01:08:05.360]   you're not trying to do 3D modeling in JavaScript.
[01:08:05.360 --> 01:08:06.240]   And so on.
[01:08:06.240 --> 01:08:08.240]   So what we're seeing in the web platform is that's actually
[01:08:08.240 --> 01:08:08.760]   what's happening.
[01:08:08.760 --> 01:08:10.680]   We've now got a good set of rich abstracts
[01:08:10.680 --> 01:08:11.960]   doing lots of things.
[01:08:11.960 --> 01:08:14.080]   You can then wire together with a little bit of script.
[01:08:14.080 --> 01:08:17.800]   And that's what enables it.
[01:08:17.800 --> 01:08:21.280]   You need to write a native app for certain kinds of things.
[01:08:21.280 --> 01:08:24.960]   But the set of what you can do with the HTML platform
[01:08:24.960 --> 01:08:26.760]   has been growing and growing over time.
[01:08:26.760 --> 01:08:31.520]   And that's a very encouraging trend.
[01:08:31.520 --> 01:08:34.400]   You're using your Pixel still, right, Jeff Jarvis?
[01:08:34.400 --> 01:08:35.400]   Yes, I am indeed.
[01:08:35.400 --> 01:08:37.680]   It has done--
[01:08:37.680 --> 01:08:41.640]   It got wonky, and it does slow down some pages
[01:08:41.640 --> 01:08:42.960]   like you were experience from the beginning.
[01:08:42.960 --> 01:08:43.960]   I don't know what's going on.
[01:08:43.960 --> 01:08:44.520]   I've rebuilt it.
[01:08:44.520 --> 01:08:46.480]   I'm trying to switch to the stable channel.
[01:08:46.480 --> 01:08:48.720]   You have to be on the developer channel right now,
[01:08:48.720 --> 01:08:49.560]   because you're used to--
[01:08:49.560 --> 01:08:51.320]   Well, are you were using Skype?
[01:08:51.320 --> 01:08:52.000]   You've stopped, though.
[01:08:52.000 --> 01:08:52.440]   I was.
[01:08:52.440 --> 01:08:54.360]   But I went off that and I went to the beta channel.
[01:08:54.360 --> 01:08:55.920]   I mean, we got something to go to stable.
[01:08:55.920 --> 01:08:58.080]   But I also saw that developer channel just, I guess,
[01:08:58.080 --> 01:08:59.480]   today came out with a new version
[01:08:59.480 --> 01:09:02.440]   that lets you very easily go back and forth between versions.
[01:09:02.440 --> 01:09:04.360]   It was impossible to go back.
[01:09:04.360 --> 01:09:06.240]   But now you can go back and forth between versions.
[01:09:06.240 --> 01:09:07.480]   You have to wipe the machine when you do it.
[01:09:07.480 --> 01:09:08.680]   But that's the great thing about it.
[01:09:08.680 --> 01:09:10.200]   I thought, oh, it's going to get wonky.
[01:09:10.200 --> 01:09:10.720]   Right.
[01:09:10.720 --> 01:09:12.320]   90 seconds is rebuilt.
[01:09:12.320 --> 01:09:14.840]   So this is one of four new features on the developer channel.
[01:09:14.840 --> 01:09:16.200]   Actually, I think I'm going to--
[01:09:16.200 --> 01:09:18.880]   I'm staying in stable.
[01:09:18.880 --> 01:09:21.400]   But I think I'm going to maybe try doing this,
[01:09:21.400 --> 01:09:23.160]   because I love this idea.
[01:09:23.160 --> 01:09:27.040]   So you can bypass the image recovery process.
[01:09:27.040 --> 01:09:30.720]   A power wash will allow you to change the channel from stable
[01:09:30.720 --> 01:09:33.760]   to beta to developer unstable.
[01:09:33.760 --> 01:09:34.800]   You'll have to power wash.
[01:09:34.800 --> 01:09:37.680]   But that just means fully refreshing it.
[01:09:37.680 --> 01:09:38.680]   But how long does that take?
[01:09:38.680 --> 01:09:39.880]   30 seconds, 45 seconds.
[01:09:39.880 --> 01:09:40.400]   Not very long.
[01:09:40.400 --> 01:09:41.080]   About 90 seconds.
[01:09:41.080 --> 01:09:43.840]   All that you lose lose is if you do
[01:09:43.840 --> 01:09:47.280]   to capture a screenshot and capture it to local memory.
[01:09:47.280 --> 01:09:50.680]   I feel guilty every time I save something to the Pixel.
[01:09:50.680 --> 01:09:51.920]   Like I'm going to run out.
[01:09:51.920 --> 01:09:55.720]   Like, oh, I'm going to run out.
[01:09:55.720 --> 01:09:56.880]   I feel like I shouldn't be sitting.
[01:09:56.880 --> 01:09:58.360]   Are you using the Pixel?
[01:09:58.360 --> 01:09:58.720]   Who me?
[01:09:58.720 --> 01:09:59.960]   I really enjoy my Pixel.
[01:09:59.960 --> 01:10:00.960]   Matt, yeah.
[01:10:00.960 --> 01:10:02.480]   Are you on a Pixel?
[01:10:02.480 --> 01:10:03.480]   I am.
[01:10:03.480 --> 01:10:05.840]   And I did a 30 day challenge in May,
[01:10:05.840 --> 01:10:08.000]   and I never stopped using my Pixel.
[01:10:08.000 --> 01:10:08.840]   So--
[01:10:08.840 --> 01:10:10.160]   Oh, you did that one.
[01:10:10.160 --> 01:10:10.640]   Oh, that's right.
[01:10:10.640 --> 01:10:11.160]   That's right.
[01:10:11.160 --> 01:10:11.520]   I forgot that.
[01:10:11.520 --> 01:10:12.200]   Yes.
[01:10:12.200 --> 01:10:12.800]   Yes.
[01:10:12.800 --> 01:10:13.640]   You didn't stop then.
[01:10:13.640 --> 01:10:14.040]   Same here.
[01:10:14.040 --> 01:10:15.960]   I mean, I did it as kind of a challenge one week.
[01:10:15.960 --> 01:10:17.960]   I don't have as much patience as you do.
[01:10:17.960 --> 01:10:19.880]   But a little longer.
[01:10:19.880 --> 01:10:20.960]   So there's a new--
[01:10:20.960 --> 01:10:22.480]   are you on developer, Matt?
[01:10:22.480 --> 01:10:24.000]   You probably are, huh?
[01:10:24.000 --> 01:10:26.440]   I'm actually on beta, because I use it for my day-to-day work.
[01:10:26.440 --> 01:10:27.520]   So I could draw a go state.
[01:10:27.520 --> 01:10:28.320]   I'll pay pretty--
[01:10:28.320 --> 01:10:30.600]   I'm tempted to go to developer just for these new features.
[01:10:30.600 --> 01:10:32.800]   See all open tabs and windows with one button click?
[01:10:32.800 --> 01:10:33.320]   I love that.
[01:10:33.320 --> 01:10:37.960]   That's like expose on the Macintosh.
[01:10:37.960 --> 01:10:40.040]   There's a Chrome plugin that does that.
[01:10:40.040 --> 01:10:40.520]   Really?
[01:10:40.520 --> 01:10:41.320]   Just three fingers.
[01:10:41.320 --> 01:10:43.200]   Oh, all right.
[01:10:43.200 --> 01:10:46.320]   Touch-based drag and drop.
[01:10:46.320 --> 01:10:48.200]   That's kind of really cool.
[01:10:48.200 --> 01:10:50.160]   Is that within a page?
[01:10:50.160 --> 01:10:51.960]   Yeah, but it's only for the Pixel obviously,
[01:10:51.960 --> 01:10:53.160]   because the Pixel is the only one that has--
[01:10:53.160 --> 01:10:54.160]   Yeah, you got to have touch.
[01:10:54.160 --> 01:10:55.440]   It's not going to be on the other Chrome OS.
[01:10:55.440 --> 01:10:56.960]   Yeah.
[01:10:56.960 --> 01:10:58.600]   That's pretty sweet.
[01:10:58.600 --> 01:11:00.560]   Mine has been getting wonk your crash.
[01:11:00.560 --> 01:11:01.680]   I'm crashing more.
[01:11:01.680 --> 01:11:03.160]   And I don't know if it's the latest build,
[01:11:03.160 --> 01:11:05.240]   so that's why I changed the channel.
[01:11:05.240 --> 01:11:09.200]   There's nothing that can get cruft up in the machine, right?
[01:11:09.200 --> 01:11:10.200]   Yeah.
[01:11:10.200 --> 01:11:12.280]   What could possibly go wrong?
[01:11:12.280 --> 01:11:14.960]   Not really, but I do love the idea
[01:11:14.960 --> 01:11:18.040]   that you could completely rebuild the machine, just log into Chrome
[01:11:18.040 --> 01:11:19.120]   Sync and you're good to go.
[01:11:19.120 --> 01:11:23.880]   To me, that's the single reason to even look at a Chrome OS
[01:11:23.880 --> 01:11:25.480]   device, frankly.
[01:11:25.480 --> 01:11:28.320]   You give up so much from--
[01:11:28.320 --> 01:11:30.160]   the Pixel is the same as a MacBook Air.
[01:11:30.160 --> 01:11:32.120]   You give up all of that stuff.
[01:11:32.120 --> 01:11:35.360]   But what you gain is this kind of rock solid stability
[01:11:35.360 --> 01:11:37.480]   and the ability to just power wash it.
[01:11:37.480 --> 01:11:42.840]   And so my dad actually visited for a week.
[01:11:42.840 --> 01:11:46.600]   And he had a five-year-old Mac laptop,
[01:11:46.600 --> 01:11:48.600]   so we were going to get him a new Mac laptop.
[01:11:48.600 --> 01:11:51.640]   And so I gave him a Chromebook to kind of tidy him over
[01:11:51.640 --> 01:11:52.240]   in the meantime.
[01:11:52.240 --> 01:11:54.520]   And he logged in, and he had all his bookmarks.
[01:11:54.520 --> 01:11:55.880]   Yeah, isn't that nice?
[01:11:55.880 --> 01:11:57.560]   Yeah, by the time we got to the Apple store,
[01:11:57.560 --> 01:12:00.080]   he was like, well, son, this computer
[01:12:00.080 --> 01:12:04.600]   is 10 times as much than this $250 computer.
[01:12:04.600 --> 01:12:06.960]   So why don't I use the $250 computer one,
[01:12:06.960 --> 01:12:09.000]   and I can buy five of them, you know?
[01:12:09.000 --> 01:12:10.080]   Good.
[01:12:10.080 --> 01:12:11.400]   Yeah, make an argument.
[01:12:11.400 --> 01:12:15.480]   No, there's the use case.
[01:12:15.480 --> 01:12:18.040]   My sons moved to using the Chromebook full-time.
[01:12:18.040 --> 01:12:19.040]   Really?
[01:12:19.040 --> 01:12:20.040]   Really?
[01:12:20.040 --> 01:12:21.720]   His school stuff, yeah.
[01:12:21.720 --> 01:12:24.760]   It was partly because he had a PC that he dropped and smashed.
[01:12:24.760 --> 01:12:27.520]   I gave him the Chromebook.
[01:12:27.520 --> 01:12:31.880]   And then he got the older Mac out and set that up for him.
[01:12:31.880 --> 01:12:33.440]   But he switched to that.
[01:12:33.440 --> 01:12:35.920]   And he finds it plenty useful for him.
[01:12:35.920 --> 01:12:39.240]   He does all his most of his stuff is web-based.
[01:12:39.240 --> 01:12:41.960]   He uses Google Docs for his writing.
[01:12:41.960 --> 01:12:43.880]   He's been doing a lot of course error and things.
[01:12:43.880 --> 01:12:45.240]   So he's been pressed with that.
[01:12:45.240 --> 01:12:47.080]   I tell you, when you add last--
[01:12:47.080 --> 01:12:48.080]   Go ahead.
[01:12:48.080 --> 01:12:52.280]   His school has now required them that they all get an iPad,
[01:12:52.280 --> 01:12:54.320]   so they can use digital textbooks, which is interesting.
[01:12:54.320 --> 01:12:55.640]   Oh, that's interesting.
[01:12:55.640 --> 01:12:56.160]   Yeah.
[01:12:56.160 --> 01:13:00.200]   And actually, the iPad 4 screen is actually good enough
[01:13:00.200 --> 01:13:02.320]   to reproduce a physics textbook.
[01:13:02.320 --> 01:13:03.520]   Oh, yeah, it looks good.
[01:13:03.520 --> 01:13:04.520]   Wow.
[01:13:04.520 --> 01:13:06.240]   So that's the intent of the migration.
[01:13:06.240 --> 01:13:08.200]   Well, in fact, Google Play is just--
[01:13:08.200 --> 01:13:11.000]   well, this was promised at the breakfast with Sundar
[01:13:11.000 --> 01:13:14.760]   and now is out, textbook support and book rental
[01:13:14.760 --> 01:13:16.480]   capabilities into the Play Store.
[01:13:16.480 --> 01:13:17.880]   And I have to say, if you have a--
[01:13:17.880 --> 01:13:20.800]   to me, the school will be better off by an Nexus 7.
[01:13:20.800 --> 01:13:23.520]   I guess it depends what textbooks are available and so forth.
[01:13:23.520 --> 01:13:28.960]   But an Nexus 7 also, more than enough to resolution.
[01:13:28.960 --> 01:13:29.240]   Right.
[01:13:29.240 --> 01:13:34.400]   Well, you can use Google Play and Amazon and Apple Book
[01:13:34.400 --> 01:13:36.200]   iBooks all on the iPad, so--
[01:13:36.200 --> 01:13:36.960]   That's right.
[01:13:36.960 --> 01:13:38.840]   There's an advantage there.
[01:13:38.840 --> 01:13:39.680]   Every day--
[01:13:39.680 --> 01:13:41.880]   This is where my school--
[01:13:41.880 --> 01:13:42.640]   I'm sad.
[01:13:42.640 --> 01:13:45.000]   But every day I sign on and I go to play,
[01:13:45.000 --> 01:13:46.520]   and I click on the Nexus 7.
[01:13:46.520 --> 01:13:48.000]   Hopefully, the LTE is going to be there.
[01:13:48.000 --> 01:13:49.240]   And every day I'm disappointed.
[01:13:49.240 --> 01:13:50.520]   And wish they'd just tell me when.
[01:13:50.520 --> 01:13:54.440]   I mean, I just tried--
[01:13:54.440 --> 01:13:55.280]   I mean, I just tried--
[01:13:55.280 --> 01:13:58.040]   In the future, you will be happy.
[01:13:58.040 --> 01:14:01.200]   In the future, we'll all be happy.
[01:14:01.200 --> 01:14:03.360]   That's the nature of the future.
[01:14:03.360 --> 01:14:06.200]   Matt, Matt, what phone are you using?
[01:14:06.200 --> 01:14:08.960]   Oh.
[01:14:08.960 --> 01:14:10.480]   I can neither confirm nor deny--
[01:14:10.480 --> 01:14:14.120]   Oh, I know exactly what phone he's using.
[01:14:14.120 --> 01:14:15.680]   He's doing a little twist--
[01:14:15.680 --> 01:14:17.520]   Twist, twist, twist.
[01:14:17.520 --> 01:14:18.600]   Oh, it's so nice.
[01:14:18.600 --> 01:14:23.400]   Whenever I run my pocket casts to listen to this week in Google,
[01:14:23.400 --> 01:14:24.680]   I have to say, the Moto X--
[01:14:24.680 --> 01:14:27.480]   I've always been a Nexus kind of guy.
[01:14:27.480 --> 01:14:29.880]   But the extra stuff that the Moto X does
[01:14:29.880 --> 01:14:31.360]   is actually really good.
[01:14:31.360 --> 01:14:32.880]   So I'm very conflicted right now.
[01:14:32.880 --> 01:14:37.800]   I went out and bought a Nexus 4 just so I could compare the two.
[01:14:37.800 --> 01:14:38.800]   Stay.
[01:14:38.800 --> 01:14:40.240]   How do you compare them?
[01:14:40.240 --> 01:14:45.040]   Well, I prefer the Moto X. It's a little smaller in the hand.
[01:14:45.040 --> 01:14:45.520]   It's funny.
[01:14:45.520 --> 01:14:47.640]   The Moto X--
[01:14:47.640 --> 01:14:49.400]   The reason people go crazy about this,
[01:14:49.400 --> 01:14:51.720]   and they hate it that I like it, is because--
[01:14:51.720 --> 01:14:52.320]   Wait a minute.
[01:14:52.320 --> 01:14:54.440]   The stats, the specs.
[01:14:54.440 --> 01:14:55.680]   What are you crazy?
[01:14:55.680 --> 01:15:00.120]   But it's really more of a gestalt, the feeling in the hand.
[01:15:00.120 --> 01:15:03.440]   It's smaller than the Nexus 4 with roughly the same resolution
[01:15:03.440 --> 01:15:05.160]   screen.
[01:15:05.160 --> 01:15:07.200]   And it feels lighter in the hand.
[01:15:07.200 --> 01:15:14.680]   I admit that the OK Google now and the dictation
[01:15:14.680 --> 01:15:16.920]   are hitting miss enough that you're not
[01:15:16.920 --> 01:15:17.960]   going to rely on it.
[01:15:17.960 --> 01:15:19.640]   But there's little subtle things.
[01:15:19.640 --> 01:15:22.720]   The camera flip is bigger than one might think.
[01:15:22.720 --> 01:15:25.720]   The fact that you can have authenticated Bluetooth
[01:15:25.720 --> 01:15:28.720]   locales that the phone is unlocked,
[01:15:28.720 --> 01:15:32.680]   that's a surprisingly useful thing.
[01:15:32.680 --> 01:15:34.280]   It really is.
[01:15:34.280 --> 01:15:36.640]   Hopefully, some of this will get folded into the main part
[01:15:36.640 --> 01:15:38.920]   of the main trunk of Android.
[01:15:38.920 --> 01:15:41.520]   And I do feel that people who want a pure Google experience
[01:15:41.520 --> 01:15:44.040]   will be pretty happy with the Moto X.
[01:15:44.040 --> 01:15:48.120]   Aside from the camera app and a few of these additional features,
[01:15:48.120 --> 01:15:49.400]   it is Google experience.
[01:15:49.400 --> 01:15:50.400]   It's very Googling.
[01:15:50.400 --> 01:15:52.680]   In fact, I decided to run my Moto X with it.
[01:15:52.680 --> 01:15:57.080]   I usually put a Nova launcher on all my Android devices.
[01:15:57.080 --> 01:16:01.440]   But I decided to just try it with plain old Android 4.3.
[01:16:01.440 --> 01:16:03.600]   And it's great.
[01:16:03.600 --> 01:16:04.600]   It's a very good question for you.
[01:16:04.600 --> 01:16:05.600]   Here's a question for you.
[01:16:05.600 --> 01:16:05.920]   It's buttery.
[01:16:05.920 --> 01:16:07.120]   And battery life.
[01:16:07.120 --> 01:16:08.120]   What are you getting?
[01:16:08.120 --> 01:16:09.480]   Oh, my goodness.
[01:16:09.480 --> 01:16:11.120]   I was going to say, the one thing that
[01:16:11.120 --> 01:16:12.680]   has been crazy about the battery life
[01:16:12.680 --> 01:16:16.960]   is it sips it like you wouldn't believe in a very good way.
[01:16:16.960 --> 01:16:19.080]   There was a closed sale where we were doing Square.
[01:16:19.080 --> 01:16:22.280]   And so I had the phone on all day to run credit cards
[01:16:22.280 --> 01:16:23.600]   to help people out for this close walk.
[01:16:23.600 --> 01:16:26.640]   And at the end of the day, I was at 50% battery life.
[01:16:26.640 --> 01:16:27.400]   So I thought I'd--
[01:16:27.400 --> 01:16:28.960]   It's kind of mind-boggling when that happens.
[01:16:28.960 --> 01:16:30.160]   Yeah.
[01:16:30.160 --> 01:16:32.840]   The fact that you can have the OK Google Now work
[01:16:32.840 --> 01:16:36.160]   and still have the battery life kind of blows my mind.
[01:16:36.160 --> 01:16:37.480]   I'm really impressed by that.
[01:16:37.480 --> 01:16:39.920]   I know better than predicting what consumers
[01:16:39.920 --> 01:16:41.800]   are going to do, because you can't.
[01:16:41.800 --> 01:16:45.160]   And I don't know-- people don't buy the best phone in anybody's
[01:16:45.160 --> 01:16:45.440]   mind.
[01:16:45.440 --> 01:16:47.280]   They buy whatever phone they buy.
[01:16:47.280 --> 01:16:52.360]   But I think, from a point of view of users,
[01:16:52.360 --> 01:17:01.080]   if they get a chance to hold and try the Google Rolla Moto X,
[01:17:01.080 --> 01:17:04.080]   it is probably the most consumer-friendly phone
[01:17:04.080 --> 01:17:05.120]   there is out there.
[01:17:05.120 --> 01:17:06.400]   It is the one to get.
[01:17:06.400 --> 01:17:07.840]   Now, I'm very curious what Apple's
[01:17:07.840 --> 01:17:09.160]   going to do with the iPhone.
[01:17:09.160 --> 01:17:10.120]   Next iPhone.
[01:17:10.120 --> 01:17:11.000]   Since every 10th, right?
[01:17:11.000 --> 01:17:11.840]   We'll find out.
[01:17:11.840 --> 01:17:12.360]   Yep.
[01:17:12.360 --> 01:17:13.400]   But it's great to have a question.
[01:17:13.400 --> 01:17:15.040]   Well, so my question is--
[01:17:15.040 --> 01:17:15.560]   Is--
[01:17:15.560 --> 01:17:17.040]   You got a great question.
[01:17:17.040 --> 01:17:18.200]   I want to--
[01:17:18.200 --> 01:17:21.080]   I need to replace this one, because I smashed it.
[01:17:21.080 --> 01:17:22.720]   What is that one?
[01:17:22.720 --> 01:17:25.120]   This is the Galaxy Nexus--
[01:17:25.120 --> 01:17:25.760]   Galaxy.
[01:17:25.760 --> 01:17:26.120]   Yes.
[01:17:26.120 --> 01:17:26.440]   OK.
[01:17:26.440 --> 01:17:27.760]   That's what I was just using into a--
[01:17:27.760 --> 01:17:28.640]   Classic.
[01:17:28.640 --> 01:17:29.800]   A classic.
[01:17:29.800 --> 01:17:31.400]   But it's got-- like I showed it's screen.
[01:17:31.400 --> 01:17:33.280]   I'm cheating.
[01:17:33.280 --> 01:17:35.640]   Like a 1959 Cadillac El Dorado.
[01:17:35.640 --> 01:17:36.440]   Exactly.
[01:17:36.440 --> 01:17:38.360]   Suicide doors, baby.
[01:17:38.360 --> 01:17:39.360]   So--
[01:17:39.360 --> 01:17:41.520]   But one of the things I want is I want to be able to--
[01:17:41.520 --> 01:17:44.200]   I want it to take a full-size SIM so I can take it in the UK
[01:17:44.200 --> 01:17:47.440]   and plug random SIMs into it easily, which I think
[01:17:47.440 --> 01:17:49.280]   rules out the Moto.
[01:17:49.280 --> 01:17:49.800]   Yeah.
[01:17:49.800 --> 01:17:50.920]   It's a nano SIM.
[01:17:50.920 --> 01:17:52.280]   It's a nano SIM, yeah.
[01:17:52.280 --> 01:17:53.280]   Yeah.
[01:17:53.280 --> 01:17:54.920]   But--
[01:17:54.920 --> 01:17:56.120]   So that leaves me with--
[01:17:56.120 --> 01:17:56.880]   do I go for the--
[01:17:56.880 --> 01:17:57.480]   Yes, go for it.
[01:17:57.480 --> 01:18:01.360]   I saw a story recently about a SIM vending machine,
[01:18:01.360 --> 01:18:03.560]   I think, in Heathrow, where you got both nano
[01:18:03.560 --> 01:18:05.120]   and micro on the same--
[01:18:05.120 --> 01:18:07.080]   I think we're moving towards nano.
[01:18:07.080 --> 01:18:07.600]   I really do.
[01:18:07.600 --> 01:18:08.600]   OK.
[01:18:08.600 --> 01:18:11.040]   And I have a cutter-- by the way, you can cut a--
[01:18:11.040 --> 01:18:13.440]   Those don't work very well, right?
[01:18:13.440 --> 01:18:15.360]   No, they do.
[01:18:15.360 --> 01:18:17.080]   If you have the right cutter.
[01:18:17.080 --> 01:18:18.720]   And there are cutters that cut down to nano,
[01:18:18.720 --> 01:18:20.240]   and they still work, which I don't understand,
[01:18:20.240 --> 01:18:23.040]   because you're cutting off metal contacts.
[01:18:23.040 --> 01:18:25.120]   I don't understand how it works at all.
[01:18:25.120 --> 01:18:27.800]   But I'm not saying-- you should keep that in mind.
[01:18:27.800 --> 01:18:30.000]   And I think the galaxy is for Google edition
[01:18:30.000 --> 01:18:32.960]   or would be a good choice of the HTC One.
[01:18:32.960 --> 01:18:33.480]   Right.
[01:18:33.480 --> 01:18:34.960]   Yeah, I was missing between those.
[01:18:34.960 --> 01:18:36.640]   Yeah.
[01:18:36.640 --> 01:18:38.680]   So I carry them all, and I just can't decide.
[01:18:38.680 --> 01:18:42.160]   It's one of those things where there is no perfect phone.
[01:18:42.160 --> 01:18:44.000]   But I'm starting to think that there
[01:18:44.000 --> 01:18:47.160]   is this kind of zen state you go into with the Moto X,
[01:18:47.160 --> 01:18:51.080]   where it's just-- it's just a lot of phone.
[01:18:51.080 --> 01:18:52.600]   It's just enough phone.
[01:18:52.600 --> 01:18:54.760]   That there's something appealing about it.
[01:18:54.760 --> 01:18:55.760]   Yeah.
[01:18:55.760 --> 01:18:58.160]   So here's my question.
[01:18:58.160 --> 01:18:58.840]   Go ahead.
[01:18:58.840 --> 01:18:59.760]   You got a question.
[01:18:59.760 --> 01:19:03.240]   So I want to buy the-- I want it, right?
[01:19:03.240 --> 01:19:05.040]   I will not go on contract.
[01:19:05.040 --> 01:19:05.540]   Good.
[01:19:05.540 --> 01:19:07.240]   I also want a locked phone.
[01:19:07.240 --> 01:19:07.740]   Yep.
[01:19:07.740 --> 01:19:11.840]   So if I buy it on AT&T, I can buy at full price.
[01:19:11.840 --> 01:19:15.280]   AT&T policy, I think, is you have no contractual obligation.
[01:19:15.280 --> 01:19:16.040]   They will unlock it.
[01:19:16.040 --> 01:19:17.760]   If you're in good standing, even if you
[01:19:17.760 --> 01:19:19.000]   do have a contractual obligation,
[01:19:19.000 --> 01:19:20.320]   they say they will unlock it.
[01:19:20.320 --> 01:19:21.160]   They're not required.
[01:19:21.160 --> 01:19:21.160]   Really?
[01:19:21.160 --> 01:19:22.640]   OK.
[01:19:22.640 --> 01:19:24.740]   But that's still going to have AT&T.
[01:19:24.740 --> 01:19:28.840]   You know, there will be a Google Play edition.
[01:19:28.840 --> 01:19:29.600]   You will not be--
[01:19:29.600 --> 01:19:30.920]   No, you were quoted.
[01:19:30.920 --> 01:19:31.280]   Yeah, yeah.
[01:19:31.280 --> 01:19:32.280]   You were quoted.
[01:19:32.280 --> 01:19:32.780]   OK.
[01:19:32.780 --> 01:19:33.760]   So here's what guy--
[01:19:33.760 --> 01:19:35.060]   Here's what guy Kawasaki.
[01:19:35.060 --> 01:19:37.740]   I have it in writing.
[01:19:37.740 --> 01:19:40.380]   They're not going to do a Google edition because then it
[01:19:40.380 --> 01:19:44.100]   wouldn't be a Moto X, because what makes the Moto X a Moto X
[01:19:44.100 --> 01:19:45.740]   is those three or four things.
[01:19:45.740 --> 01:19:48.700]   But it's so close to pure Google that they're still
[01:19:48.700 --> 01:19:50.580]   going to sell it on the Google Play store.
[01:19:50.580 --> 01:19:52.740]   Just not a Google edition.
[01:19:52.740 --> 01:19:53.500]   You see what I'm saying?
[01:19:53.500 --> 01:19:54.060]   So what--
[01:19:54.060 --> 01:19:57.620]   Right, but there will be added AT&T crop on the AT&T version.
[01:19:57.620 --> 01:19:58.540]   Yeah, it's not much.
[01:19:58.540 --> 01:19:59.980]   It's two programs.
[01:19:59.980 --> 01:20:00.380]   Yeah.
[01:20:00.380 --> 01:20:01.580]   I think it's like two apps.
[01:20:01.580 --> 01:20:03.580]   And then you can disable them, and then you will see them.
[01:20:03.580 --> 01:20:04.840]   Yeah, I never really--
[01:20:04.840 --> 01:20:05.840]   it's not like you got--
[01:20:05.840 --> 01:20:07.000]   it's taken up a lot of space.
[01:20:07.000 --> 01:20:08.600]   Because the reason I could buy the AT&T
[01:20:08.600 --> 01:20:09.880]   was I could do the customized--
[01:20:09.880 --> 01:20:11.400]   ooh, I have a purple phone.
[01:20:11.400 --> 01:20:12.760]   And you've got more--
[01:20:12.760 --> 01:20:13.760]   That is a big issue.
[01:20:13.760 --> 01:20:14.200]   Yeah.
[01:20:14.200 --> 01:20:16.120]   Because I think basically I'm not going to buy a Moto X
[01:20:16.120 --> 01:20:17.840]   till I can get a wooden back.
[01:20:17.840 --> 01:20:19.320]   That's going to be awesome.
[01:20:19.320 --> 01:20:21.840]   I know.
[01:20:21.840 --> 01:20:25.680]   So that means later this year--
[01:20:25.680 --> 01:20:26.840]   I mean, maybe December.
[01:20:26.840 --> 01:20:27.360]   I don't know.
[01:20:27.360 --> 01:20:29.560]   They said end of Q4.
[01:20:29.560 --> 01:20:30.640]   So I don't think--
[01:20:30.640 --> 01:20:34.500]   I think that's when Motorola's exclusivity ends.
[01:20:34.500 --> 01:20:35.320]   I don't think it lasts.
[01:20:35.320 --> 01:20:36.800]   I mean, I have no knowledge of this.
[01:20:36.800 --> 01:20:39.000]   I keep getting quoted as if I know something.
[01:20:39.000 --> 01:20:40.700]   I know nothing.
[01:20:40.700 --> 01:20:42.320]   You know, a guy Kawasaki said, why
[01:20:42.320 --> 01:20:43.880]   did you say it costs $350 to make?
[01:20:43.880 --> 01:20:44.620]   I said, I didn't say it.
[01:20:44.620 --> 01:20:45.680]   Goldman Sachs said it.
[01:20:45.680 --> 01:20:46.960]   I'm just quoting Goldman Sachs.
[01:20:46.960 --> 01:20:49.720]   But unfortunately, all of these stupid blogs quote me
[01:20:49.720 --> 01:20:50.880]   as if I'm saying it.
[01:20:50.880 --> 01:20:53.000]   I'm quoting an analyst.
[01:20:53.000 --> 01:20:53.880]   I don't know.
[01:20:53.880 --> 01:20:55.700]   How would I know how much it cost?
[01:20:55.700 --> 01:20:57.360]   They think Guy told me.
[01:20:57.360 --> 01:20:59.640]   It's like to be the president of the internet.
[01:20:59.640 --> 01:21:03.000]   I know-- I know-- I'm like Obama.
[01:21:03.000 --> 01:21:05.040]   I know nothing.
[01:21:05.040 --> 01:21:06.680]   They don't tell me anything.
[01:21:06.680 --> 01:21:08.680]   He's the sergeant's Schultz of the internet.
[01:21:08.680 --> 01:21:11.200]   No, nothing.
[01:21:11.200 --> 01:21:15.480]   However, I do like the Moto X. I kind of still think it's
[01:21:15.480 --> 01:21:17.120]   a world beater.
[01:21:17.120 --> 01:21:19.560]   You never know what consumers are going to go for.
[01:21:19.560 --> 01:21:20.320]   It's subtle.
[01:21:20.320 --> 01:21:21.760]   That's part of the problem.
[01:21:21.760 --> 01:21:23.720]   It's kind of a subtle appeal.
[01:21:23.720 --> 01:21:26.000]   You don't know that the battery life is so great to you.
[01:21:26.000 --> 01:21:28.720]   You use it for a couple of weeks and you realize this
[01:21:28.720 --> 01:21:30.720]   just keeps going.
[01:21:30.720 --> 01:21:31.240]   Yeah.
[01:21:31.240 --> 01:21:32.960]   And I'm an assistant.
[01:21:32.960 --> 01:21:34.760]   I would always go vanilla.
[01:21:34.760 --> 01:21:37.400]   The add-ons have actually impressed me quite a bit.
[01:21:37.400 --> 01:21:39.840]   So that takes a lot for me to leave the Nexus.
[01:21:39.840 --> 01:21:41.320]   It's pretty pure, right?
[01:21:41.320 --> 01:21:42.120]   I mean--
[01:21:42.120 --> 01:21:42.960]   Very pure.
[01:21:42.960 --> 01:21:44.040]   That's why I got the Nexus 4.
[01:21:44.040 --> 01:21:46.280]   I wanted to compare 4.3.
[01:21:46.280 --> 01:21:48.880]   And it's only 4.2.2, although I wouldn't be surprised
[01:21:48.880 --> 01:21:50.200]   if they got 4.3.
[01:21:50.200 --> 01:21:52.280]   It hasn't come out yet.
[01:21:52.280 --> 01:21:52.480]   Right.
[01:21:52.480 --> 01:21:55.560]   So Kevin, what are you going to go?
[01:21:55.560 --> 01:21:56.520]   I don't know.
[01:21:56.520 --> 01:21:57.440]   I'm going to kind of look.
[01:21:57.440 --> 01:22:00.800]   But I'm leaning towards the HSC1.
[01:22:00.800 --> 01:22:02.520]   It's a beautiful phone.
[01:22:02.520 --> 01:22:03.080]   Play edition.
[01:22:03.080 --> 01:22:05.240]   Battery life is very challenging on that thing.
[01:22:05.240 --> 01:22:06.200]   You've got to nurse it.
[01:22:06.200 --> 01:22:07.720]   OK.
[01:22:07.720 --> 01:22:08.520]   And it's not-- it's not--
[01:22:08.520 --> 01:22:09.640]   It's not exchangeable batteries, is it?
[01:22:09.640 --> 01:22:12.400]   No, that's the advantage of the GS4.
[01:22:12.400 --> 01:22:13.240]   OK.
[01:22:13.240 --> 01:22:14.000]   Exchangeable batteries.
[01:22:14.000 --> 01:22:17.960]   I would not get the Crapfware version.
[01:22:17.960 --> 01:22:19.360]   I would get the Google Play edition.
[01:22:19.360 --> 01:22:21.240]   Because of all the phones.
[01:22:21.240 --> 01:22:22.000]   Now I'm a big fan of the greatest.
[01:22:22.000 --> 01:22:23.200]   It has no memory.
[01:22:23.200 --> 01:22:24.320]   It's only 16 gigs.
[01:22:24.320 --> 01:22:29.120]   And 12 of them are used by-- watch your eyes go like this.
[01:22:29.120 --> 01:22:30.680]   Who cares?
[01:22:30.680 --> 01:22:32.880]   Wave your hand.
[01:22:32.880 --> 01:22:34.200]   It's got so much junk on it.
[01:22:34.200 --> 01:22:37.280]   I've never seen a worse junked up phone in my life.
[01:22:37.280 --> 01:22:38.280]   And it's not the carriers.
[01:22:38.280 --> 01:22:40.560]   It says Samsung.
[01:22:40.560 --> 01:22:41.240]   But what do you think?
[01:22:41.240 --> 01:22:45.320]   I think Samsung is about to abandon Android.
[01:22:45.320 --> 01:22:49.320]   Well, there's certainly stories that talk about them
[01:22:49.320 --> 01:22:50.680]   wanting to do Tizen and stuff.
[01:22:50.680 --> 01:22:51.720]   But you know, it's--
[01:22:51.720 --> 01:22:52.320]   They have 3OSs.
[01:22:52.320 --> 01:22:53.320]   It's called the OSs.
[01:22:53.320 --> 01:22:54.160]   They have 3OSs.
[01:22:54.160 --> 01:22:56.760]   They've got Tizen, which is a Linux.
[01:22:56.760 --> 01:23:00.960]   They've got a Windows phone, the ATEve series.
[01:23:00.960 --> 01:23:01.880]   They've got Android.
[01:23:01.880 --> 01:23:04.000]   Somebody's going to buy Blackberry, too.
[01:23:04.000 --> 01:23:04.440]   And they know.
[01:23:04.440 --> 01:23:06.640]   They'll probably do a FireFox OS1 as well.
[01:23:06.640 --> 01:23:09.120]   I think their point is they want to do all the things.
[01:23:09.120 --> 01:23:09.640]   Yeah.
[01:23:09.640 --> 01:23:11.040]   That's how-- that's Samsung's thing.
[01:23:11.040 --> 01:23:11.560]   Wave.
[01:23:11.560 --> 01:23:12.800]   They're not a focus company.
[01:23:12.800 --> 01:23:13.520]   They make everything.
[01:23:13.520 --> 01:23:15.160]   We'll do whatever you want.
[01:23:15.160 --> 01:23:18.120]   So I got to visit Korea a couple of years ago.
[01:23:18.120 --> 01:23:19.960]   And I got to ride in a Samsung car.
[01:23:19.960 --> 01:23:22.000]   I didn't realize they made cars.
[01:23:22.000 --> 01:23:25.160]   So that's the full scale stack.
[01:23:25.160 --> 01:23:26.320]   It's a caretsu.
[01:23:26.320 --> 01:23:27.280]   They do everything.
[01:23:27.280 --> 01:23:28.240]   They make bulldozers.
[01:23:28.240 --> 01:23:30.720]   They make washing machines, refrigerators.
[01:23:30.720 --> 01:23:33.640]   1,800 different versions of the Galaxy phone.
[01:23:33.640 --> 01:23:36.120]   So I'm waiting for the Google bulldozer or the Google
[01:23:36.120 --> 01:23:37.160]   and washing machine.
[01:23:37.160 --> 01:23:39.200]   [LAUGHTER]
[01:23:39.200 --> 01:23:41.840]   I just-- you know, Samsung's having a developer conference,
[01:23:41.840 --> 01:23:45.920]   which is very-- to me, intriguing in the fall.
[01:23:45.920 --> 01:23:46.440]   I--
[01:23:46.440 --> 01:23:49.240]   Well, that one last year for Tizen in San Francisco.
[01:23:49.240 --> 01:23:50.200]   Right.
[01:23:50.200 --> 01:23:53.000]   This doesn't say Tizen specifically.
[01:23:53.000 --> 01:23:54.240]   Speaking of developer conferences,
[01:23:54.240 --> 01:23:57.880]   there's also one announced for Chrome.
[01:23:57.880 --> 01:23:58.880]   That's fun.
[01:23:58.880 --> 01:24:00.120]   I'll go to that.
[01:24:00.120 --> 01:24:03.120]   It's on the Chrome Chrome Dev Summit November.
[01:24:03.120 --> 01:24:04.800]   Is that a Google event?
[01:24:04.800 --> 01:24:05.760]   Yes, it thinks so.
[01:24:05.760 --> 01:24:06.520]   Yes.
[01:24:06.520 --> 01:24:06.880]   Yes.
[01:24:06.880 --> 01:24:07.440]   Well, who else?
[01:24:07.440 --> 01:24:09.000]   On the rundown under Google.
[01:24:09.000 --> 01:24:10.960]   I guess Chromium-- the Chromium folks could be doing.
[01:24:10.960 --> 01:24:11.760]   But no, it's a Google event.
[01:24:11.760 --> 01:24:13.120]   OK.
[01:24:13.120 --> 01:24:15.360]   Which is where we have the more development we get on Chrome
[01:24:15.360 --> 01:24:17.360]   apps and stuff, the better.
[01:24:17.360 --> 01:24:19.840]   People are reporting numerous problems
[01:24:19.840 --> 01:24:23.840]   that the Nexus 7-- some say the multi-touch is buggy.
[01:24:23.840 --> 01:24:26.160]   Some say their GPS is not locking.
[01:24:26.160 --> 01:24:29.560]   Others say it's flashing on and off, rebooting.
[01:24:29.560 --> 01:24:31.760]   I haven't had any trouble with mine,
[01:24:31.760 --> 01:24:34.400]   but that's anecdotal.
[01:24:34.400 --> 01:24:35.200]   So I don't know how to--
[01:24:35.200 --> 01:24:37.560]   Who has acknowledged the problem with the multi-touch
[01:24:37.560 --> 01:24:39.720]   and is looking into the problem with the GPS, I think.
[01:24:39.720 --> 01:24:40.400]   That's what they've said.
[01:24:40.400 --> 01:24:44.200]   I use it all the time.
[01:24:44.200 --> 01:24:45.080]   What's the story?
[01:24:45.080 --> 01:24:47.040]   Maybe you can help us mad on this one.
[01:24:47.040 --> 01:24:48.200]   I know it's not your division.
[01:24:48.200 --> 01:24:51.640]   But the fight over the factory images.
[01:24:51.640 --> 01:24:53.200]   And--
[01:24:53.200 --> 01:24:54.200]   Oh.
[01:24:54.200 --> 01:24:54.700]   Oh.
[01:24:54.700 --> 01:24:57.760]   Jean, the Baptiste Clrie.
[01:24:57.760 --> 01:24:59.680]   Yeah, JBQ is an awesome guy.
[01:24:59.680 --> 01:25:02.640]   He's basically the main engineering lead
[01:25:02.640 --> 01:25:05.600]   maintainer of the Android Open Source Project.
[01:25:05.600 --> 01:25:08.120]   And so as part of that, you're always
[01:25:08.120 --> 01:25:11.000]   dealing with OEMs and various manufacturers
[01:25:11.000 --> 01:25:13.640]   trying to get as much of the source code and firmware
[01:25:13.640 --> 01:25:15.440]   open as possible.
[01:25:15.440 --> 01:25:17.880]   And that can be a challenge because sometimes--
[01:25:17.880 --> 01:25:20.200]   I know we might consider firmware or binaries
[01:25:20.200 --> 01:25:21.720]   to be proprietary.
[01:25:21.720 --> 01:25:25.640]   And so I think he got a little bit frustrated trying
[01:25:25.640 --> 01:25:28.600]   to make sure that you can have a phone that booted all the way
[01:25:28.600 --> 01:25:31.600]   up and had as much hardware functional as possible.
[01:25:31.600 --> 01:25:35.120]   And so I think he's maybe taken a break
[01:25:35.120 --> 01:25:37.200]   from the Android Open Source Project.
[01:25:37.200 --> 01:25:39.960]   So we'll see how that goes.
[01:25:39.960 --> 01:25:43.560]   But meanwhile, the version did come out for the Nexus 7,
[01:25:43.560 --> 01:25:44.480]   I think.
[01:25:44.480 --> 01:25:45.080]   It did.
[01:25:45.080 --> 01:25:45.880]   It did.
[01:25:45.880 --> 01:25:49.120]   So I'm not privy to what the negotiations were
[01:25:49.120 --> 01:25:50.360]   and that sort of thing.
[01:25:50.360 --> 01:25:51.960]   It's always a challenge because you're
[01:25:51.960 --> 01:25:54.080]   picking months in advance and you're
[01:25:54.080 --> 01:25:56.200]   trying to figure out how to get things open source.
[01:25:56.200 --> 01:25:58.200]   But you also have to get the device out.
[01:25:58.200 --> 01:26:00.560]   And so there's a lot of different factors
[01:26:00.560 --> 01:26:02.320]   you have to balance there.
[01:26:02.320 --> 01:26:03.280]   Do you think it's Qualcomm?
[01:26:03.280 --> 01:26:05.080]   I mean, the blame has fallen on Qualcomm.
[01:26:05.080 --> 01:26:05.440]   I don't know.
[01:26:05.440 --> 01:26:06.600]   Is that fair?
[01:26:06.600 --> 01:26:09.360]   That's what the reports have been.
[01:26:09.360 --> 01:26:12.200]   That's what the external Android police
[01:26:12.200 --> 01:26:15.480]   and the people who have studied the levels of frustration,
[01:26:15.480 --> 01:26:16.360]   which you can graph.
[01:26:16.360 --> 01:26:18.600]   I know of JPQ.
[01:26:18.600 --> 01:26:19.880]   Seemed a point in that direction.
[01:26:19.880 --> 01:26:21.240]   You know what I love about this, though?
[01:26:21.240 --> 01:26:23.120]   This shows what you were saying, Jeff,
[01:26:23.120 --> 01:26:25.640]   is that even a corporation as big as Google,
[01:26:25.640 --> 01:26:30.040]   individuals still can stand up for doing what they believe in.
[01:26:30.040 --> 01:26:31.280]   And you kind of have to--
[01:26:31.280 --> 01:26:32.440]   that's great.
[01:26:32.440 --> 01:26:33.360]   And have a big impact.
[01:26:33.360 --> 01:26:33.800]   Yeah.
[01:26:33.800 --> 01:26:34.320]   Yeah.
[01:26:34.320 --> 01:26:36.040]   Have a big impact.
[01:26:36.040 --> 01:26:37.960]   Nevertheless, I think the Nexus 7 is fabulous.
[01:26:37.960 --> 01:26:39.360]   I'm glad they got the images out.
[01:26:39.360 --> 01:26:42.040]   That's really cool.
[01:26:42.040 --> 01:26:44.640]   And I hope Qualcomm just chill, man.
[01:26:44.640 --> 01:26:46.680]   Take a chill pill.
[01:26:46.680 --> 01:26:49.200]   It's going to be OK.
[01:26:49.200 --> 01:26:50.400]   My LTE.
[01:26:50.400 --> 01:26:52.480]   I want my LTE.
[01:26:52.480 --> 01:26:54.360]   And get the LTE.
[01:26:54.360 --> 01:26:56.480]   Please, Jeff's waiting.
[01:26:56.480 --> 01:26:59.800]   I will pass that feedback on.
[01:26:59.800 --> 01:27:01.000]   I always expect you to do, Matt.
[01:27:01.000 --> 01:27:01.600]   Yes.
[01:27:01.600 --> 01:27:04.200]   Esther Dyson is going to be our guest in triangulation.
[01:27:04.200 --> 01:27:05.800]   That's going to be a lot of fun.
[01:27:05.800 --> 01:27:08.720]   What a legend she is.
[01:27:08.720 --> 01:27:12.440]   And any questions you want to give me, Jeff, or anybody else
[01:27:12.440 --> 01:27:15.080]   for Esther, I'll be glad to pass along.
[01:27:15.080 --> 01:27:16.520]   That's coming up in just a few minutes.
[01:27:16.520 --> 01:27:18.720]   Esther, she's cleaned up her desk.
[01:27:18.720 --> 01:27:20.760]   I've seen pictures of her office.
[01:27:20.760 --> 01:27:23.440]   Esther ran ICANN for a while so we
[01:27:23.440 --> 01:27:27.640]   can talk a lot about internet governance, absent government
[01:27:27.640 --> 01:27:29.160]   influence.
[01:27:29.160 --> 01:27:33.680]   Of course, her adventures, one of the early tech investors.
[01:27:33.680 --> 01:27:38.560]   I mean, she's big into genetic genome research, one
[01:27:38.560 --> 01:27:41.560]   of the first 10 people to donate her genome publicly
[01:27:41.560 --> 01:27:43.880]   to the public genome project.
[01:27:43.880 --> 01:27:46.720]   Lots of interesting things we're going to talk about with Esther
[01:27:46.720 --> 01:27:49.160]   Dyson in just a little bit.
[01:27:49.160 --> 01:27:51.400]   Just looking-- if there's anything else--
[01:27:51.400 --> 01:27:53.360]   There's an amazing-- have you seen the kids' guide
[01:27:53.360 --> 01:27:54.920]   that the internet, Leo?
[01:27:54.920 --> 01:27:56.240]   No, I haven't.
[01:27:56.240 --> 01:27:57.000]   Oh, you've watched.
[01:27:57.000 --> 01:27:59.080]   It's under other.
[01:27:59.080 --> 01:28:01.240]   Others were all the best stuff is.
[01:28:01.240 --> 01:28:02.240]   All right.
[01:28:02.240 --> 01:28:06.320]   This was made-- I thought this had to be a joke.
[01:28:06.320 --> 01:28:08.760]   Lauren Weinstein said no, it's not,
[01:28:08.760 --> 01:28:09.880]   because he looked at all the stuff.
[01:28:09.880 --> 01:28:10.600]   It's pretty amazing.
[01:28:10.600 --> 01:28:11.640]   It's old, though, right?
[01:28:11.640 --> 01:28:12.640]   This is not--
[01:28:12.640 --> 01:28:13.160]   It's old.
[01:28:13.160 --> 01:28:14.240]   It's '90s.
[01:28:14.240 --> 01:28:16.640]   Adjust the VCR tracking for a clearer picture.
[01:28:16.640 --> 01:28:18.440]   That might be a giveaway.
[01:28:18.440 --> 01:28:18.960]   Yeah.
[01:28:18.960 --> 01:28:20.440]   That was a hack.
[01:28:20.440 --> 01:28:21.280]   That's a bad sign.
[01:28:21.280 --> 01:28:22.200]   It is, man.
[01:28:22.200 --> 01:28:24.920]   It just took a lot of work.
[01:28:24.920 --> 01:28:26.640]   A hometown television presents.
[01:28:26.640 --> 01:28:27.800]   Well, I just want to see the beginning.
[01:28:27.800 --> 01:28:29.080]   I always like to--
[01:28:29.080 --> 01:28:29.440]   I wonder.
[01:28:29.440 --> 01:28:30.280]   I might have worked on this.
[01:28:30.280 --> 01:28:31.280]   I don't know.
[01:28:31.280 --> 01:28:32.280]   [CHEERING]
[01:28:32.280 --> 01:28:33.280]   Oh, yeah.
[01:28:33.280 --> 01:28:34.520]   You could have been dead.
[01:28:34.520 --> 01:28:35.320]   Yeah.
[01:28:35.320 --> 01:28:37.160]   [MUSIC PLAYING]
[01:28:37.160 --> 01:28:39.160]   [MUSIC PLAYING]
[01:28:39.160 --> 01:28:41.160]   [MUSIC PLAYING]
[01:28:41.160 --> 01:28:43.160]   [MUSIC PLAYING]
[01:28:43.160 --> 01:28:45.160]   [MUSIC PLAYING]
[01:28:45.160 --> 01:28:47.160]   [MUSIC PLAYING]
[01:28:47.160 --> 01:28:48.160]   Come on, Kevin.
[01:28:48.160 --> 01:28:49.160]   [MUSIC PLAYING]
[01:28:49.160 --> 01:28:50.160]   [MUSIC PLAYING]
[01:28:50.160 --> 01:28:51.160]   Yeah.
[01:28:51.160 --> 01:28:53.160]   [MUSIC PLAYING]
[01:28:53.160 --> 01:28:54.840]   I've done shows like this.
[01:28:54.840 --> 01:28:57.160]   I got to tell you.
[01:28:57.160 --> 01:28:58.160]   Is that the prisoner for--
[01:28:58.160 --> 01:28:59.160]   Hey, there.
[01:28:59.160 --> 01:29:00.160]   It's us again.
[01:29:00.160 --> 01:29:01.160]   This is my brother, Peter.
[01:29:01.160 --> 01:29:02.160]   I mean, hey, wait a minute.
[01:29:02.160 --> 01:29:03.160]   Have we met you before?
[01:29:03.160 --> 01:29:04.160]   Hey, there.
[01:29:04.160 --> 01:29:05.160]   It's us again.
[01:29:05.160 --> 01:29:06.160]   Huh?
[01:29:06.160 --> 01:29:07.160]   We were the millers.
[01:29:07.160 --> 01:29:09.160]   By the way, she's 48 now.
[01:29:09.160 --> 01:29:10.160]   [LAUGHTER]
[01:29:10.160 --> 01:29:11.160]   OK.
[01:29:11.160 --> 01:29:12.160]   It's Andrew and Lisa.
[01:29:12.160 --> 01:29:13.160]   The internet ruled her life.
[01:29:13.160 --> 01:29:14.160]   Yeah.
[01:29:14.160 --> 01:29:15.160]   And I thought you might want to come along.
[01:29:15.160 --> 01:29:17.160]   She's a little bit of a drinking problem, but otherwise--
[01:29:17.160 --> 01:29:20.160]   --when we installed internet access on our computer,
[01:29:20.160 --> 01:29:21.160]   I got the whole family involved.
[01:29:21.160 --> 01:29:22.160]   It's true.
[01:29:22.160 --> 01:29:24.160]   Everybody had their own tasks to do.
[01:29:24.160 --> 01:29:26.160]   It was a lot of work, but it was really worth it.
[01:29:26.160 --> 01:29:28.160]   Now that I've got along the internet,
[01:29:28.160 --> 01:29:31.160]   I'd rather be on my computer than doing just about anything.
[01:29:31.160 --> 01:29:32.160]   It's really cool.
[01:29:32.160 --> 01:29:34.160]   Well, the internet really messed the whole world up there.
[01:29:34.160 --> 01:29:36.160]   You know, there's naked ladies on it.
[01:29:36.160 --> 01:29:39.160]   So I guess this is a story of how it changed our lives.
[01:29:39.160 --> 01:29:43.160]   Maybe it was yours, too, but the kids died to the internet.
[01:29:43.160 --> 01:29:44.160]   [LAUGHTER]
[01:29:44.160 --> 01:29:45.160]   Take a stand.
[01:29:45.160 --> 01:29:46.160]   Now you're in with the tech news set.
[01:29:46.160 --> 01:29:48.160]   You're going to the internet.
[01:29:48.160 --> 01:29:50.160]   Who is this aimed at?
[01:29:50.160 --> 01:29:53.160]   As Rich told you, we installed the internet on our computer
[01:29:53.160 --> 01:29:54.160]   just a short time ago.
[01:29:54.160 --> 01:29:55.160]   What are our head gals doing?
[01:29:55.160 --> 01:29:58.160]   He even saw the internet on our computer.
[01:29:58.160 --> 01:30:00.160]   That's a short time ago.
[01:30:00.160 --> 01:30:01.160]   Oh, man.
[01:30:01.160 --> 01:30:06.160]   And already is laden with viruses, spyware, and malware.
[01:30:06.160 --> 01:30:08.160]   [LAUGHTER]
[01:30:08.160 --> 01:30:11.160]   And Dad's getting the Viagra spam every minute.
[01:30:11.160 --> 01:30:13.160]   I had the typical computer games that all the kids enjoy,
[01:30:13.160 --> 01:30:16.160]   but their curiosity for learning has skyrocketed.
[01:30:16.160 --> 01:30:17.160]   Oh, yeah.
[01:30:17.160 --> 01:30:18.160]   Peter's constantly quoted.
[01:30:18.160 --> 01:30:20.160]   Dad, I'd like to go into the room, my bedroom now,
[01:30:20.160 --> 01:30:22.160]   and learn some more on the internet if you don't mind.
[01:30:22.160 --> 01:30:24.160]   And Dad, as he is my favorite subject.
[01:30:24.160 --> 01:30:25.160]   [LAUGHTER]
[01:30:25.160 --> 01:30:27.160]   That's a round of low.
[01:30:27.160 --> 01:30:29.160]   Not to mention the improvement in Peter's greys.
[01:30:29.160 --> 01:30:31.160]   And Dasha's too.
[01:30:31.160 --> 01:30:34.160]   Having the internet in our home has had a great impact on our lives.
[01:30:34.160 --> 01:30:37.160]   Rina keeps up with the stock market and our investments,
[01:30:37.160 --> 01:30:39.160]   and I'm able to pay the bills and have the--
[01:30:39.160 --> 01:30:41.160]   He has a few secret cyber affairs on the side.
[01:30:41.160 --> 01:30:43.160]   Dad's been very busy.
[01:30:43.160 --> 01:30:44.160]   [LAUGHTER]
[01:30:44.160 --> 01:30:48.160]   He says he has an internet nickname, Carlos Danger.
[01:30:48.160 --> 01:30:50.160]   [LAUGHTER]
[01:30:50.160 --> 01:30:52.160]   Look at the Netscape browser.
[01:30:52.160 --> 01:30:53.160]   I love the navigator.
[01:30:53.160 --> 01:30:55.160]   I don't think you'll type will be specific.
[01:30:55.160 --> 01:30:58.160]   Directing you to a particular website like MTV.
[01:30:58.160 --> 01:31:00.160]   MTV a co-producer of this, by the way.
[01:31:00.160 --> 01:31:03.160]   Or you can just surf the net using a search engine to help you locate information.
[01:31:03.160 --> 01:31:05.160]   What search engine? Online MTV.
[01:31:05.160 --> 01:31:11.160]   I used the World Wide Web to search the archives of the Smithsonian Museum a few weeks ago.
[01:31:11.160 --> 01:31:15.160]   I also had to do a homework assignment about the Wright brothers for a history assignment.
[01:31:15.160 --> 01:31:17.160]   Can you show us what you found?
[01:31:17.160 --> 01:31:18.160]   Sure.
[01:31:18.160 --> 01:31:19.160]   [LAUGHTER]
[01:31:19.160 --> 01:31:23.160]   Oh, that Smithsonian really does the state of the art, huh?
[01:31:23.160 --> 01:31:24.160]   Oh, wow.
[01:31:24.160 --> 01:31:28.160]   The sad thing is we all remember exactly when the internet looked just like that.
[01:31:28.160 --> 01:31:29.160]   Oh, Street View.
[01:31:29.160 --> 01:31:30.160]   Street View.
[01:31:30.160 --> 01:31:33.160]   [LAUGHTER]
[01:31:33.160 --> 01:31:37.160]   By the way, I do believe you had to set up Windows to do that waving window cursor.
[01:31:37.160 --> 01:31:39.160]   That wasn't the default.
[01:31:39.160 --> 01:31:40.160]   [LAUGHTER]
[01:31:40.160 --> 01:31:44.160]   It wasn't hourglass, right? You had to turn it into the waving, yeah.
[01:31:44.160 --> 01:31:46.160]   [MUSIC]
[01:31:46.160 --> 01:31:47.160]   Oh boy.
[01:31:47.160 --> 01:31:48.160]   Oh.
[01:31:48.160 --> 01:31:49.160]   Oh.
[01:31:49.160 --> 01:31:50.160]   We just figured it out.
[01:31:50.160 --> 01:31:51.160]   Look, I'll show you.
[01:31:51.160 --> 01:31:56.160]   All you have to do is go to playboy.com.
[01:31:56.160 --> 01:31:57.160]   [LAUGHTER]
[01:31:57.160 --> 01:31:58.160]   Wow.
[01:31:58.160 --> 01:32:00.160]   This is great.
[01:32:00.160 --> 01:32:01.160]   Is this amazing?
[01:32:01.160 --> 01:32:02.160]   Isn't this amazing?
[01:32:02.160 --> 01:32:03.160]   That's great.
[01:32:03.160 --> 01:32:04.160]   Oh, oh.
[01:32:04.160 --> 01:32:05.160]   Oh, remember the color wizard?
[01:32:05.160 --> 01:32:07.160]   I remember that.
[01:32:07.160 --> 01:32:09.160]   Oh, wow.
[01:32:09.160 --> 01:32:11.160]   [MUSIC]
[01:32:11.160 --> 01:32:14.160]   Oh, all about rainbows.
[01:32:14.160 --> 01:32:16.160]   [LAUGHTER]
[01:32:16.160 --> 01:32:20.160]   You know, seriously, I worked on shows very much like this.
[01:32:20.160 --> 01:32:25.160]   He did a show, a PBS show, called The Internet.
[01:32:25.160 --> 01:32:26.160]   [LAUGHTER]
[01:32:26.160 --> 01:32:28.160]   And it was pretty much this.
[01:32:28.160 --> 01:32:29.160]   Does it existly?
[01:32:29.160 --> 01:32:30.160]   Oh, have you shown it?
[01:32:30.160 --> 01:32:31.160]   Ah, I hope not.
[01:32:31.160 --> 01:32:32.160]   Oh, please.
[01:32:32.160 --> 01:32:33.160]   Oh, please, you must be it.
[01:32:33.160 --> 01:32:34.160]   I hope it's long gone.
[01:32:34.160 --> 01:32:38.160]   I certainly don't have a copy, but I bet you somebody in the chat room will find it and
[01:32:38.160 --> 01:32:40.160]   humiliate me in public.
[01:32:40.160 --> 01:32:41.160]   [LAUGHTER]
[01:32:41.160 --> 01:32:42.160]   Oh, Lord.
[01:32:42.160 --> 01:32:48.160]   I remember Gina Smith did one where she was driving in a convertible down the information
[01:32:48.160 --> 01:32:49.160]   super high.
[01:32:49.160 --> 01:32:52.160]   [LAUGHTER]
[01:32:52.160 --> 01:32:54.160]   I don't know if there was singing involved.
[01:32:54.160 --> 01:32:55.160]   Oh, excellent.
[01:32:55.160 --> 01:32:57.160]   There's Al Gore over there.
[01:32:57.160 --> 01:32:58.160]   [LAUGHTER]
[01:32:58.160 --> 01:33:01.160]   Look, there's my imaginary family.
[01:33:01.160 --> 01:33:03.160]   [LAUGHTER]
[01:33:03.160 --> 01:33:04.160]   All right.
[01:33:04.160 --> 01:33:07.160]   I think we have to finally found our replacement theme song for this week in Google.
[01:33:07.160 --> 01:33:08.160]   Hey, maybe you know what?
[01:33:08.160 --> 01:33:09.160]   Let's listen to that.
[01:33:09.160 --> 01:33:10.160]   You know what?
[01:33:10.160 --> 01:33:12.160]   Can we use that, you think, with impunity?
[01:33:12.160 --> 01:33:13.160]   Oh, I think so.
[01:33:13.160 --> 01:33:15.160]   Do you think hometown productions would be fun?
[01:33:15.160 --> 01:33:16.160]   Yeah.
[01:33:16.160 --> 01:33:17.160]   [MUSIC PLAYING]
[01:33:17.160 --> 01:33:23.160]   We're riding on the internet, cyberspace, sex-free, hell-o-vertebral reality.
[01:33:23.160 --> 01:33:26.160]   Cyberspace, it says what we wanted to say.
[01:33:26.160 --> 01:33:27.160]   Cyberspace sets us free.
[01:33:27.160 --> 01:33:29.160]   I'm going to appetite searching for a website.
[01:33:29.160 --> 01:33:31.160]   A window to the world got to get online.
[01:33:31.160 --> 01:33:36.160]   Take a spin now, and with a techno set, you're going surfing on the internet.
[01:33:36.160 --> 01:33:39.160]   Hi, can we just steal that and--
[01:33:39.160 --> 01:33:40.160]   [LAUGHTER]
[01:33:40.160 --> 01:33:43.160]   Well, you'll find out who owns the rights when you first was on YouTube, won't you?
[01:33:43.160 --> 01:33:44.160]   Perfect.
[01:33:44.160 --> 01:33:47.160]   They'll let us know if there's a problem.
[01:33:47.160 --> 01:33:52.160]   If it is a tribute to their wonderful work that we want to do this.
[01:33:52.160 --> 01:33:56.160]   Of course, the YouTube comments are even more fun.
[01:33:56.160 --> 01:34:00.160]   [LAUGHTER]
[01:34:00.160 --> 01:34:02.160]   I'm not even going to show these.
[01:34:02.160 --> 01:34:07.160]   [LAUGHTER]
[01:34:07.160 --> 01:34:09.160]   And then they made 4chan.
[01:34:09.160 --> 01:34:14.160]   [LAUGHTER]
[01:34:14.160 --> 01:34:18.160]   A new drinking game, take a shot every time they say internet.
[01:34:18.160 --> 01:34:20.160]   All right, all right.
[01:34:20.160 --> 01:34:25.160]   I think it's time for us to get our picks and tools and numbers and all of that stuff.
[01:34:25.160 --> 01:34:28.160]   Maybe I can get to Matt to throw in a little something.
[01:34:28.160 --> 01:34:30.160]   Mr. Matt cuts, we just love you, Matt.
[01:34:30.160 --> 01:34:33.160]   You are so-- you're so sensible.
[01:34:33.160 --> 01:34:35.160]   You're so normal.
[01:34:35.160 --> 01:34:36.160]   [LAUGHTER]
[01:34:36.160 --> 01:34:39.160]   But in a great way.
[01:34:39.160 --> 01:34:40.160]   I appreciate that.
[01:34:40.160 --> 01:34:41.160]   So thank you for being here.
[01:34:41.160 --> 01:34:44.160]   I mean, you-- and I think in a lot of ways you also reassure.
[01:34:44.160 --> 01:34:47.160]   One of the reasons Jeff and I love Google is because we think of Google.
[01:34:47.160 --> 01:34:50.160]   It's made of people, like Silent Green.
[01:34:50.160 --> 01:34:56.160]   And you're-- and you're like-- we think of you when we think of Google.
[01:34:56.160 --> 01:35:00.160]   Well, and there's so many engineers who like feel exactly the same way.
[01:35:00.160 --> 01:35:03.160]   Like, you wouldn't-- I was in a meeting yesterday and I said,
[01:35:03.160 --> 01:35:06.160]   I'm going to be on a web radio show and they're like, is it this weekend Google?
[01:35:06.160 --> 01:35:07.160]   Oh, that's great.
[01:35:07.160 --> 01:35:08.160]   And look, this weekend Google.
[01:35:08.160 --> 01:35:10.160]   So there's a ton of people who listen.
[01:35:10.160 --> 01:35:13.160]   That's why the feedback that Jeff gives often gets addressed pretty quickly.
[01:35:13.160 --> 01:35:14.160]   Good.
[01:35:14.160 --> 01:35:15.160]   That would really--
[01:35:15.160 --> 01:35:20.160]   Well, I never get invited to-- what's that need conference?
[01:35:20.160 --> 01:35:21.160]   Site-gaste.
[01:35:21.160 --> 01:35:22.160]   Oh, thank you.
[01:35:22.160 --> 01:35:23.160]   That's for sales.
[01:35:23.160 --> 01:35:24.160]   You're not buying ads.
[01:35:24.160 --> 01:35:25.160]   I never get invited either.
[01:35:25.160 --> 01:35:27.160]   I've never been to a single site.
[01:35:27.160 --> 01:35:28.160]   So that's--
[01:35:28.160 --> 01:35:29.160]   Really?
[01:35:29.160 --> 01:35:30.160]   It's all right.
[01:35:30.160 --> 01:35:31.160]   It makes you feel better.
[01:35:31.160 --> 01:35:32.160]   Yeah.
[01:35:32.160 --> 01:35:33.160]   I'm not going to be in sales.
[01:35:33.160 --> 01:35:37.160]   Well, we do send a tip of the hat to all the Googlers who listen.
[01:35:37.160 --> 01:35:41.160]   Yeah, I always feel-- when I ever-- and I do occasionally go down to Google,
[01:35:41.160 --> 01:35:45.160]   whenever I'm there, it's always a great feeling because of all the companies that we visit,
[01:35:45.160 --> 01:35:50.160]   I really feel that Google is still engineering driven and still doing some really, really
[01:35:50.160 --> 01:35:52.160]   exciting stuff.
[01:35:52.160 --> 01:35:57.160]   And if Sarah Gaver wants to have a cookout with his fake meat, we've got a barbecue.
[01:35:57.160 --> 01:35:58.160]   [LAUGHTER]
[01:35:58.160 --> 01:35:59.160]   Mm-hmm.
[01:35:59.160 --> 01:36:03.160]   Yeah, I have no idea how good it tastes, but it sounds like, you know, it's--
[01:36:03.160 --> 01:36:04.160]   It's pretty good stuff.
[01:36:04.160 --> 01:36:06.160]   I have smoking chips.
[01:36:06.160 --> 01:36:08.160]   I have cedar planks.
[01:36:08.160 --> 01:36:11.160]   I can make anything taste good.
[01:36:11.160 --> 01:36:12.160]   With enough barbecue sauce.
[01:36:12.160 --> 01:36:13.160]   Exactly.
[01:36:13.160 --> 01:36:14.160]   Cheese.
[01:36:14.160 --> 01:36:15.160]   It just needs cheese.
[01:36:15.160 --> 01:36:19.160]   Put a little cheese on top, some barbecue sauce, chopped onions.
[01:36:19.160 --> 01:36:21.160]   What more do you need?
[01:36:21.160 --> 01:36:23.160]   It doesn't matter what it tastes like.
[01:36:23.160 --> 01:36:26.160]   You can have the first kosher cheeseburger, too.
[01:36:26.160 --> 01:36:29.160]   So where does that stand?
[01:36:29.160 --> 01:36:31.160]   Do they have that in the cafeteria yet?
[01:36:31.160 --> 01:36:36.160]   No, although they're pretty good about vegan and tofu and all that sort of stuff.
[01:36:36.160 --> 01:36:37.160]   Yeah.
[01:36:37.160 --> 01:36:40.160]   I think they need brin beef in there.
[01:36:40.160 --> 01:36:41.160]   Brin beef.
[01:36:41.160 --> 01:36:42.160]   Okay.
[01:36:42.160 --> 01:36:43.160]   What's for--
[01:36:43.160 --> 01:36:44.160]   Brin beef.
[01:36:44.160 --> 01:36:45.160]   Chip brin beef.
[01:36:45.160 --> 01:36:46.160]   Brin burger.
[01:36:46.160 --> 01:36:47.160]   Brin burger.
[01:36:47.160 --> 01:36:48.160]   So anything you'd like to share--
[01:36:48.160 --> 01:36:50.160]   It took six months to make that one burger.
[01:36:50.160 --> 01:36:52.160]   It took them six months to grow that burger?
[01:36:52.160 --> 01:36:53.160]   To grow it.
[01:36:53.160 --> 01:36:54.160]   Yeah.
[01:36:54.160 --> 01:36:56.160]   You know, the first one's always the hardest, right?
[01:36:56.160 --> 01:36:57.160]   Yes.
[01:36:57.160 --> 01:36:59.160]   Who knows how much they can speed it up after that?
[01:36:59.160 --> 01:37:00.160]   Yes.
[01:37:00.160 --> 01:37:01.160]   A plain morsel.
[01:37:01.160 --> 01:37:03.160]   Kevin, how long does it take to make a cow?
[01:37:03.160 --> 01:37:04.160]   Well, exactly.
[01:37:04.160 --> 01:37:05.160]   This is true.
[01:37:05.160 --> 01:37:06.160]   Good point.
[01:37:06.160 --> 01:37:09.160]   You're being, you know, internet impatient.
[01:37:09.160 --> 01:37:10.160]   That wasn't beef.
[01:37:10.160 --> 01:37:11.160]   That was veal.
[01:37:11.160 --> 01:37:14.160]   [laughter]
[01:37:14.160 --> 01:37:20.360]   No, I, for one, would be glad to give a beef if I could have a synthetic bacon that tastes
[01:37:20.360 --> 01:37:22.160]   everybody as good as the real thing.
[01:37:22.160 --> 01:37:23.160]   That's all I ask.
[01:37:23.160 --> 01:37:24.160]   Make a bit.
[01:37:24.160 --> 01:37:28.160]   By the way, Matt, what's your one-month challenge this month?
[01:37:28.160 --> 01:37:31.160]   I am doing at least 30 minutes of exercise a day.
[01:37:31.160 --> 01:37:32.160]   Good.
[01:37:32.160 --> 01:37:33.160]   You can do the M100s.
[01:37:33.160 --> 01:37:37.160]   You know, the burpees and then the jumps and the running man.
[01:37:37.160 --> 01:37:38.160]   Working money and biking.
[01:37:38.160 --> 01:37:39.160]   [laughter]
[01:37:39.160 --> 01:37:42.160]   30 minutes of exercise a day is a great one.
[01:37:42.160 --> 01:37:43.160]   That's a good one.
[01:37:43.160 --> 01:37:44.160]   Yeah.
[01:37:44.160 --> 01:37:48.160]   Let me know if that becomes a habit because I've done that and it never became a habit, ever.
[01:37:48.160 --> 01:37:51.160]   Yeah, it might not stick, but at least I'll get 30 days of exercise a day.
[01:37:51.160 --> 01:37:56.000]   And for the last year, I did an hour a day, every day of Pilates, every day, and the minute
[01:37:56.000 --> 01:37:58.160]   I could stop, I did.
[01:37:58.160 --> 01:37:59.160]   [laughter]
[01:37:59.160 --> 01:38:02.160]   Well, the best one for me was when I was actually commuting on my bike to Google every day.
[01:38:02.160 --> 01:38:03.160]   That's the way to do it.
[01:38:03.160 --> 01:38:06.160]   I was doing a huge amount of cycling week.
[01:38:06.160 --> 01:38:09.160]   What was the distance for that, Kevin?
[01:38:09.160 --> 01:38:12.160]   I'm not sure exactly, but it was in two phases.
[01:38:12.160 --> 01:38:13.160]   Oh, what made kilometers?
[01:38:13.160 --> 01:38:16.160]   Here's to the station and then the other station there.
[01:38:16.160 --> 01:38:17.160]   It was even south.
[01:38:17.160 --> 01:38:20.160]   It was about 90 minutes of cycling a day.
[01:38:20.160 --> 01:38:21.160]   Oh, wow.
[01:38:21.160 --> 01:38:22.160]   That's a lot.
[01:38:22.160 --> 01:38:23.160]   That's good.
[01:38:23.160 --> 01:38:25.160]   That's good.
[01:38:25.160 --> 01:38:27.160]   So, any tip you want to share with us or anything?
[01:38:27.160 --> 01:38:30.160]   Yeah, actually, I do have a tip.
[01:38:30.160 --> 01:38:33.160]   It's a post that we just did in the last week to the Google's Webmaster blog.
[01:38:33.160 --> 01:38:38.160]   And it's actually a feature we've been wanting to launch for a long time.
[01:38:38.160 --> 01:38:42.160]   So, if you think about how the ideal search engine would work, you would ask yourself,
[01:38:42.160 --> 01:38:45.160]   "Well, why is my website ranking or not ranking?"
[01:38:45.160 --> 01:38:49.160]   And one of the big questions that people have, since I'm head of the Web spam team, they asked
[01:38:49.160 --> 01:38:52.160]   "Well, has the Web spam team taken any action on my website?"
[01:38:52.160 --> 01:38:56.160]   So, we've now rolled out a new feature in Google.com/webmasters.
[01:38:56.160 --> 01:38:58.160]   It's a feature called Webmaster Tools.
[01:38:58.160 --> 01:38:59.160]   It's totally free.
[01:38:59.160 --> 01:39:03.160]   And basically, you just go to it and once you've proven that you own a site,
[01:39:03.160 --> 01:39:09.160]   you can click and you can see whether the Web spam team has taken any manual action on your site.
[01:39:09.160 --> 01:39:15.160]   So, for example, if you're hacked, you know, cloaking, hidden text,
[01:39:15.160 --> 01:39:16.160]   all sorts of different stuff.
[01:39:16.160 --> 01:39:18.160]   We've got like 10 or 11 categories.
[01:39:18.160 --> 01:39:22.160]   We've got brand new documentation and Web pages to explain if you do have problems.
[01:39:22.160 --> 01:39:28.160]   And we actually give you example URLs or sections of your site that we think might be infected
[01:39:28.160 --> 01:39:30.160]   or hacked or have problems with spam.
[01:39:30.160 --> 01:39:33.160]   So, it's a lot more transparent than we've ever been in the past.
[01:39:33.160 --> 01:39:35.160]   I'm really excited that we're able to do this now.
[01:39:35.160 --> 01:39:36.160]   That's cool.
[01:39:36.160 --> 01:39:38.160]   Really? Thank you.
[01:39:38.160 --> 01:39:40.160]   It's a big launch for us.
[01:39:40.160 --> 01:39:42.160]   Yeah, really cool.
[01:39:42.160 --> 01:39:44.160]   I'm playing -- I'm going to play with it.
[01:39:44.160 --> 01:39:46.160]   See if you've ever touched me.
[01:39:46.160 --> 01:39:50.160]   Yeah. I should have checked Twitter.tv before it came on.
[01:39:50.160 --> 01:39:53.160]   I can do that right now.
[01:39:53.160 --> 01:39:55.160]   Good touch and there's bad touch, Matt.
[01:39:55.160 --> 01:39:57.160]   I just want you to know the difference.
[01:39:57.160 --> 01:39:58.160]   That's all I'm saying.
[01:39:58.160 --> 01:40:00.160]   The NSA has touched 1.6% of us.
[01:40:00.160 --> 01:40:02.160]   That's going to hit my numbers.
[01:40:02.160 --> 01:40:05.160]   Oh, well, let's get a number for Mr. Jeffrey Jarvis.
[01:40:05.160 --> 01:40:08.160]   Well, a series of numbers since we didn't do it earlier, I'll do it now.
[01:40:08.160 --> 01:40:12.160]   So, I wrote a little piece for the vlog and the Guardian looking at when the NSA said they touched
[01:40:12.160 --> 01:40:15.160]   only 1.6% of daily internet traffic.
[01:40:15.160 --> 01:40:17.160]   What does that mean?
[01:40:17.160 --> 01:40:21.160]   Well, they say that the net carries 1,826 petabytes of information per day.
[01:40:21.160 --> 01:40:27.160]   And the NSA touches 29 petabytes a day if that proportion is right.
[01:40:27.160 --> 01:40:29.160]   So, what touch means we don't know?
[01:40:29.160 --> 01:40:31.160]   It could be an ingest or an unless we don't know.
[01:40:31.160 --> 01:40:33.160]   So, 29 petabytes a day.
[01:40:33.160 --> 01:40:34.160]   1.6%.
[01:40:34.160 --> 01:40:41.160]   Google in 2010, before they shut up about this, said that they indexed 0.004% of data on the net.
[01:40:41.160 --> 01:40:45.160]   That would make the NSA 400 Google.
[01:40:45.160 --> 01:40:48.160]   7 petabytes of photos are right on Facebook each month.
[01:40:48.160 --> 01:40:50.160]   That's 0.23 petabytes per day.
[01:40:50.160 --> 01:40:52.160]   That would mean that the NSA is 126 Facebooks.
[01:40:52.160 --> 01:40:53.160]   Wow.
[01:40:53.160 --> 01:40:58.160]   Now, mind you, most of the data passing through the net is not email or web pages.
[01:40:58.160 --> 01:40:59.160]   It's media.
[01:40:59.160 --> 01:41:03.160]   San Vine data says that the US fixed net, of course, that's only a portion of it.
[01:41:03.160 --> 01:41:08.160]   In 2013, real-time entertainment accounted for 62% of net traffic.
[01:41:08.160 --> 01:41:11.160]   The DDP file sharing for 10.5%.
[01:41:11.160 --> 01:41:17.160]   Now, HTTP, the web, accounts for only 11.8% of aggregated up and down.
[01:41:17.160 --> 01:41:19.160]   Even though maybe you'll have to look at half of that, right?
[01:41:19.160 --> 01:41:21.160]   Here's the, here's the compuncher.
[01:41:21.160 --> 01:41:22.160]   Punch line.
[01:41:22.160 --> 01:41:23.160]   Communication.
[01:41:23.160 --> 01:41:29.160]   Part of the net that the NSA really cares about accounts for 2.9% in the US.
[01:41:29.160 --> 01:41:36.160]   So, by very rough, beer-soaked napkin calculation, the NSA says 1.6% of net traffic would be about
[01:41:36.160 --> 01:41:38.160]   half of all the communication on the net.
[01:41:38.160 --> 01:41:39.160]   Wow.
[01:41:39.160 --> 01:41:41.160]   It's got a lot of touching, good and bad.
[01:41:41.160 --> 01:41:46.160]   And by the way, let's keep in mind that about 3/4 of email is spam.
[01:41:46.160 --> 01:41:55.160]   So, when the NSA says it touches only 1.6% of traffic on the net, don't be too assured.
[01:41:55.160 --> 01:42:01.160]   That's because there's so much that is the dark net that nobody sees or can touch, including
[01:42:01.160 --> 01:42:02.160]   Google.
[01:42:02.160 --> 01:42:03.160]   Right.
[01:42:03.160 --> 01:42:08.160]   Jeff, I think even just the very high level point you made that a large fraction of the web is
[01:42:08.160 --> 01:42:11.160]   Netflix or YouTube, and that's not as interesting.
[01:42:11.160 --> 01:42:12.160]   Right.
[01:42:12.160 --> 01:42:17.160]   And that's 30, 40, 50, whatever percent of the web it is, that changes the baseline of what
[01:42:17.160 --> 01:42:18.160]   you should look at.
[01:42:18.160 --> 01:42:20.160]   And then I think that's a really important point.
[01:42:20.160 --> 01:42:22.160]   I got to make that point to someone else earlier today.
[01:42:22.160 --> 01:42:25.160]   So, thank you for that blog post that you did.
[01:42:25.160 --> 01:42:26.160]   Wow.
[01:42:26.160 --> 01:42:27.160]   Numbers.
[01:42:27.160 --> 01:42:28.160]   A few numbers.
[01:42:28.160 --> 01:42:29.160]   Lies.
[01:42:29.160 --> 01:42:30.160]   What do we, but numbers?
[01:42:30.160 --> 01:42:31.160]   But numbers.
[01:42:31.160 --> 01:42:33.160]   Damn lies and NSA statistics.
[01:42:33.160 --> 01:42:38.160]   Kevin Marks, do you have anything you'd like a tip, a tool, a number, anything you'd like
[01:42:38.160 --> 01:42:39.160]   to pass on?
[01:42:39.160 --> 01:42:47.320]   Well, it's sort of slightly oblique, but it's, why I did an article this week about Indie
[01:42:47.320 --> 01:42:53.160]   Web Camp, which is an event that I've been involved with, which is trying to rebuild
[01:42:53.160 --> 01:43:03.040]   the independent web, trying to get back to the idea of hosting our own sites and connecting
[01:43:03.040 --> 01:43:04.040]   to each other and that.
[01:43:04.040 --> 01:43:09.840]   So, it's just as a neural thing of like, we need to go back to the web we used to have
[01:43:09.840 --> 01:43:10.840]   it.
[01:43:10.840 --> 01:43:15.040]   It's that kind of thinking, but not saying, oh yes, everyone should have their own website
[01:43:15.040 --> 01:43:17.840]   and that's the only thing they should be, but working out how you can do that and coexist
[01:43:17.840 --> 01:43:21.400]   with the large institutions of things.
[01:43:21.400 --> 01:43:28.720]   And one project from that is something called IndieAuth, which is an interesting project
[01:43:28.720 --> 01:43:32.080]   that's written by Aaron Parecki.
[01:43:32.080 --> 01:43:36.760]   And the idea is, if you want to do authorization logging in, that's actually quite annoying
[01:43:36.760 --> 01:43:39.760]   and a painful thing to implement yourself and you have to do with lots of security and
[01:43:39.760 --> 01:43:40.760]   things like that.
[01:43:40.760 --> 01:43:45.520]   And so, the way it works is you log in with your own site, it looks for links on your
[01:43:45.520 --> 01:43:51.800]   site to big auth providers and uses them to log in and verify that the connection works
[01:43:51.800 --> 01:43:53.000]   both ways.
[01:43:53.000 --> 01:43:58.440]   So you can log in with your own site using Twitter, using Google, using GitHub, using
[01:43:58.440 --> 01:44:00.880]   many different auth providers.
[01:44:00.880 --> 01:44:03.120]   But what the log in is keeping is your own site.
[01:44:03.120 --> 01:44:08.560]   So, there's an interesting twist on authentication and a way to think about that because what
[01:44:08.560 --> 01:44:13.440]   it's saying is instead of you're relying on the giant provider like Facebook, Google,
[01:44:13.440 --> 01:44:19.160]   or Twitter, you're still keeping your own identity with this and you can rely on any
[01:44:19.160 --> 01:44:21.080]   one of these independently.
[01:44:21.080 --> 01:44:24.120]   So if one of them shuts you down, you don't lose everything.
[01:44:24.120 --> 01:44:27.960]   So there's a lot of interesting thinking going on in this group.
[01:44:27.960 --> 01:44:32.920]   And I mean, there was a workshop last week with every 3C where several of the indie where
[01:44:32.920 --> 01:44:37.720]   people presented and that was, I learned a lot of that and it was a very interesting
[01:44:37.720 --> 01:44:39.080]   thing to go to.
[01:44:39.080 --> 01:44:43.200]   So IndieAuth, if you're thinking about developers and authorization, it's an interesting different
[01:44:43.200 --> 01:44:44.200]   perspective.
[01:44:44.200 --> 01:44:45.200]   Very cool.
[01:44:45.200 --> 01:44:53.520]   I guess my tip is, we talked about what you can do about the NSA and privacy and you
[01:44:53.520 --> 01:44:57.080]   should write your members of Congress and join EFF and give them money and I do all that.
[01:44:57.080 --> 01:44:58.080]   But you know what else you should do?
[01:44:58.080 --> 01:45:02.000]   You should learn to code and everybody should learn to code and you get your kids to learn
[01:45:02.000 --> 01:45:05.640]   to code because ultimately the people who are going to be doing the freedom fighting
[01:45:05.640 --> 01:45:08.120]   are the people who are going to be on the right code.
[01:45:08.120 --> 01:45:10.120]   And that should be you.
[01:45:10.120 --> 01:45:11.120]   And it's never too late.
[01:45:11.120 --> 01:45:12.560]   And there's so many ways to do it on the web.
[01:45:12.560 --> 01:45:14.800]   The web is loaded with great resources.
[01:45:14.800 --> 01:45:16.560]   We know we've talked about many of them before.
[01:45:16.560 --> 01:45:18.240]   Codeacademy.com is a great one.
[01:45:18.240 --> 01:45:20.200]   It makes it very simple.
[01:45:20.200 --> 01:45:21.200]   Online courses.
[01:45:21.200 --> 01:45:26.480]   I've mentioned how to design programs, which is the old MIT press and Duke University text
[01:45:26.480 --> 01:45:28.120]   for an introduction to programming.
[01:45:28.120 --> 01:45:30.480]   It will teach you the best way to code.
[01:45:30.480 --> 01:45:37.320]   And of course for kids, Randy Pausch's Alice project, which is still going on even though
[01:45:37.320 --> 01:45:39.320]   we've lost Randy at Carnegie Mellon.
[01:45:39.320 --> 01:45:44.640]   There's a great way for kids who love video games to learn how to program and they don't
[01:45:44.640 --> 01:45:46.560]   even know it.
[01:45:46.560 --> 01:45:55.200]   If you've got a proven way to teach and retain CS majors, Alice.org is a great one to download.
[01:45:55.200 --> 01:45:56.640]   Get your kids programming.
[01:45:56.640 --> 01:45:58.040]   You can learn to code too.
[01:45:58.040 --> 01:46:03.120]   Not only is it a fun hobby, but I think in the long run it's our last best hope.
[01:46:03.120 --> 01:46:04.120]   Thanks for joining us.
[01:46:04.120 --> 01:46:05.120]   I love Kevin Marks.
[01:46:05.120 --> 01:46:06.120]   I love Mac Cuts.
[01:46:06.120 --> 01:46:07.640]   I love you too.
[01:46:07.640 --> 01:46:09.840]   Mr. Jeff Jarvis, Gina, we'll be back next week.
[01:46:09.840 --> 01:46:10.840]   We do this show.
[01:46:10.840 --> 01:46:16.560]   We love you for being here every Wednesday, 1 p.m. Pacific, 4 p.m. Eastern time.
[01:46:16.560 --> 01:46:19.920]   That's 2000 UTC on twit.tv.
[01:46:19.920 --> 01:46:23.680]   You can watch live, but if you can't get it live, we've got on-demand audio and video
[01:46:23.680 --> 01:46:26.520]   always available at our website, twit.tv/twig.
[01:46:26.520 --> 01:46:30.720]   And you can subscribe and get every single episode week by week as they come out on all
[01:46:30.720 --> 01:46:37.160]   the better podcast subscription utilities, downcast, instacast, pocketcast, iTunes and
[01:46:37.160 --> 01:46:38.160]   other rest.
[01:46:38.160 --> 01:46:39.640]   So please subscribe that way you'll get them all.
[01:46:39.640 --> 01:46:41.200]   You'll hear our new theme music next week.
[01:46:41.200 --> 01:46:43.400]   I'm really serious we should do that.
[01:46:43.400 --> 01:46:45.200]   Let's do it.
[01:46:45.200 --> 01:46:47.080]   At least until they cease in the system.
[01:46:47.080 --> 01:46:48.080]   I'm late.
[01:46:48.080 --> 01:46:49.080]   Hold up for it.
[01:46:49.080 --> 01:46:50.080]   Stay tuned.
[01:46:50.080 --> 01:46:51.080]   Esta Dyson on the drag.
[01:46:51.080 --> 01:46:52.080]   She's coming up next.
[01:46:52.080 --> 01:46:53.080]   Thanks for joining us.
[01:46:53.080 --> 01:46:54.080]   We'll see you next time.
[01:46:54.080 --> 01:46:55.080]   On this week in Google.
[01:46:55.080 --> 01:47:00.080]   We'll take a spin now and with a techno set you go to session on the end of the day.
[01:47:00.080 --> 01:47:01.080]   Gina's on from Mac Cuts.
[01:47:01.080 --> 01:47:03.080]   What have you done to my show?
[01:47:03.080 --> 01:47:13.080]   [MUSIC]

