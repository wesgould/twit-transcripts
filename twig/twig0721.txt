;FFMETADATA1
title=Why Would Google Do That?
artist=Jason Howell, Jeff Jarvis, Mike Elgan
album_artist=TWiT
publisher=TWiT
album=This Week in Google
TRDA=2023-06-22
track=721
language=English
genre=Podcast
comment=<p>Reddit CEO goes ape, Google Domains acquired, Quest VR age, Tailwind</p>\

encoded_by=Uniblab 5.3
date=2023
encoder=Lavf60.3.100

[00:00:00.000 --> 00:00:04.560]   Coming up next, it's this week in Google. I'm Jason Howl, Phil and Infralio, who's a Disneyland.
[00:00:04.560 --> 00:00:10.240]   We've got Mike Elgin joining me as well as, of course, Jeff Jarvis.
[00:00:10.240 --> 00:00:16.960]   We talk all about Reddit and kind of the collapse of social media. It feels like nothing is safe right now.
[00:00:16.960 --> 00:00:22.480]   The Reddit CEO, we've got words for him. We talk about Google domains, getting the axe,
[00:00:22.480 --> 00:00:28.000]   not necessarily getting killed, but being sold to Squarespace and how you just really can't trust
[00:00:28.000 --> 00:00:34.400]   Google anymore these days. And Chromebook X, what is that? Is that a new Chromebook by Google?
[00:00:34.400 --> 00:00:38.480]   No, it is not, but it's interesting nonetheless. That's up next on this week in Google.
[00:00:38.480 --> 00:00:42.640]   Podcasts You Love.
[00:00:52.480 --> 00:01:00.720]   This is Twig. This week in Google, Episode 721 recorded Wednesday, June 21st, 2023. Why would
[00:01:00.720 --> 00:01:06.080]   Google do that? This episode of This Week in Google is brought to you by Bitwarden. Get the
[00:01:06.080 --> 00:01:11.680]   password manager that offers a robust and cost-effective solution that drastically increases your chances
[00:01:11.680 --> 00:01:18.560]   of staying safe online. Get started with a free trial of a Teams or Enterprise plan, or get started
[00:01:18.560 --> 00:01:23.680]   for free across all devices as an individual user at bitwarden.com/twit.
[00:01:23.680 --> 00:01:32.800]   And by ACI learning CIOs and CIOs agree that attracting and retaining talent is critical.
[00:01:32.800 --> 00:01:38.000]   With an average completion rate of over 80%, your team deserves the entertaining and cutting-edge
[00:01:38.000 --> 00:01:45.760]   training that they want. Fill out the form at go.acilarning.com/twit for more information on a free
[00:01:45.760 --> 00:01:53.360]   two-week training trial for your team. And by ZipRecruiter. Did you know that hiring can take up to 11
[00:01:53.360 --> 00:02:00.400]   weeks on average? Do you have that time to wait? Of course not. Stop waiting and start using ZipRecruiter.
[00:02:00.400 --> 00:02:06.320]   ZipRecruiter helps you find qualified candidates for all your roles fast. And right now you can try
[00:02:06.320 --> 00:02:16.480]   it for free at ziprecruiter.com/twig. It's time for this week in Google. I'm Jason Howell, filling in
[00:02:16.480 --> 00:02:21.680]   for Leo LaPorte, who literally just kind of stepped out of the office yesterday morning and said
[00:02:21.680 --> 00:02:27.520]   I'm going to Disneyland. You just finished Macbreak Weekly. What are you going to do next?
[00:02:27.520 --> 00:02:33.840]   I'm going to Disneyland. That was basically Leo. So Leo, I think, is a Disneyland? Maybe he's on a
[00:02:33.840 --> 00:02:37.680]   roller coaster right now. I don't know. Maybe he's on a small world after all.
[00:02:37.680 --> 00:02:44.880]   Only Leo knows. But I'm happy to be here. Joined this week by, of course, Jeff Jarvis. Good to see you,
[00:02:44.880 --> 00:02:51.360]   Jeff. Good to see you, boss. How you doing? I'm doing all right. Doing all right. It's great to
[00:02:51.360 --> 00:02:59.280]   see you and get a chance to have you here to hang out with you today. And then Stacey has a migraine.
[00:02:59.280 --> 00:03:06.560]   So she had to unfortunately miss today's episode as well as Ant, who already has the week off.
[00:03:06.560 --> 00:03:14.080]   So, but in advance, we had already booked Mike Elgin to join. And I think this was even before I
[00:03:14.080 --> 00:03:17.920]   knew that Leo was not going to be here. So when I found out that I was going to be hosting with you,
[00:03:17.920 --> 00:03:25.280]   Mike, I was trying to think, have I podcasted with you since I produced your show when you
[00:03:25.280 --> 00:03:33.120]   worked at Twit? Wow. I can't remember. I can't remember if we've actually done a show.
[00:03:33.120 --> 00:03:41.120]   Twit once upon a time. Maybe maybe on some point. Yeah. Not sure. Yeah. Yeah.
[00:03:41.120 --> 00:03:46.960]   This was this was a while ago, of course. I'm guessing probably when when were you done at
[00:03:46.960 --> 00:03:54.480]   Twit? When did you leave Twit? Was that 2017-ish time? That sounds about right. 2016-2017.
[00:03:54.880 --> 00:04:01.920]   It was a while ago. Yeah. That sounds about right. Well, I know it must have been 2016 because in
[00:04:01.920 --> 00:04:08.480]   2017, we started doing experiences and stuff like that. So yeah, it must have been
[00:04:08.480 --> 00:04:15.200]   I think I worked there for 2015 and 2016. Sounds about the year, both years. Sounds about right.
[00:04:15.200 --> 00:04:20.800]   And you're doing TNT, of course, Tech News today. I was producing at the the TD desk,
[00:04:21.520 --> 00:04:26.080]   helping you with that show. And here we are again. So I kind of can't believe it.
[00:04:26.080 --> 00:04:28.800]   That was a lot of fun. There was a different era. Different era.
[00:04:28.800 --> 00:04:33.680]   It was much more innocent than in a number of ways. Yes, life was very different
[00:04:33.680 --> 00:04:37.600]   back then. But it's great to see you, Mike. And it sounds like you are
[00:04:37.600 --> 00:04:43.840]   doing what you do so well. You're in the midst of traveling. You're in Provence, is that right?
[00:04:43.840 --> 00:04:50.400]   That's right. We're in a little town in Provence. We've been in France, I guess, for about a week and
[00:04:50.400 --> 00:04:56.400]   half. We'll be here another week and a half or so. And yeah, Provence for a bit and then Paris
[00:04:56.400 --> 00:05:02.640]   for a week. And then we're back to California for a little while. So it's a lot of fun.
[00:05:02.640 --> 00:05:07.040]   What a fun life. We were talking about how many air miles do you do a year? How many
[00:05:07.040 --> 00:05:13.280]   free can fly or miles? Amira handles all of that and the details of that. But I know that
[00:05:13.280 --> 00:05:19.920]   that she is we're always executive platinum. So just the miles boost us to the stratosphere.
[00:05:19.920 --> 00:05:24.400]   And lately, we've been upgrading a lot, getting a lot of those kind of perks. But it's a lot.
[00:05:24.400 --> 00:05:29.600]   And it's going to be a lot more because we are starting to plan trips that are much further away.
[00:05:29.600 --> 00:05:35.200]   We're going to be in Australia, Tasmania, etc. We're going to be going to Asia. So we're going to
[00:05:35.200 --> 00:05:41.520]   be actually increasing the miles that we put in South America. So that's something to look forward
[00:05:41.520 --> 00:05:46.640]   to. This is pretty great, actually, to get upgraded. And this is all my first trip.
[00:05:46.640 --> 00:05:49.840]   Oh, no, next week, I haven't traveled three. I mean, I said, for going to Florida,
[00:05:49.840 --> 00:05:56.080]   rest of my father, I haven't traveled. And I'm going to St. Andrew's, Edinburgh and London next
[00:05:56.080 --> 00:05:59.120]   week. And for you, that's nothing for me. I have another, so three years.
[00:05:59.120 --> 00:06:05.120]   It's fantastic. And actually, that would be really something for me because we've been to the UK
[00:06:05.120 --> 00:06:11.040]   a bunch of times, but never outside of London. So going to Edinburgh is something we always wanted
[00:06:11.040 --> 00:06:15.680]   to do. Unfortunately, I'm going to a conference or something dying to go to a very wonky book
[00:06:15.680 --> 00:06:20.400]   history conference. Nice. Beautiful. But then I have to go right down to London to do a book event
[00:06:20.400 --> 00:06:24.480]   for me at my book. And so I won't see Edinburgh, which is just awful, but what the hell?
[00:06:24.480 --> 00:06:29.600]   Yeah. I hate those kind of business trips. The place you want to check out is right there.
[00:06:29.600 --> 00:06:31.520]   Like you're just literally right there, but you're not.
[00:06:31.520 --> 00:06:37.840]   Yes, exactly. I saw them by that way. And that was very frustrating.
[00:06:37.840 --> 00:06:43.680]   Oh, I should mention, number one, if you're in London, July 3rd, I'll be speaking with
[00:06:43.680 --> 00:06:49.520]   Alan Russperger Prospect magazine. Sorry, I'm going to get my plug in now. And then July 8th,
[00:06:49.520 --> 00:06:54.880]   I'm going to be at the Museum of Printing in the Haverhill Mass with our friends Glenn Fleischman.
[00:06:54.880 --> 00:07:01.520]   Oh, nice. And Marcin Wichery and Doug Wilson, who created the
[00:07:01.520 --> 00:07:07.920]   Planetite film. And we're going to be geeking out there on the 8th in Haverhill. And if you
[00:07:07.920 --> 00:07:11.680]   haven't been to the Museum of Printing and you're anywhere nearby, oh, it's great. You know, he comes
[00:07:11.680 --> 00:07:15.120]   in here, obviously, latte types, and lug loaves and all kinds of great stuff.
[00:07:15.120 --> 00:07:18.240]   That is a very particular type of geeking out.
[00:07:18.240 --> 00:07:24.800]   I donated my Osborne 1 to the Museum, so it is on this way there, along with my moral pivot.
[00:07:24.800 --> 00:07:32.480]   Yeah. Wow. Wonderful. So, Mike, I'm assuming that these new places that you're getting ready to go
[00:07:32.480 --> 00:07:37.200]   to are all part of the Gastro Nomad experience. Is this like an expansion of that or is this
[00:07:37.200 --> 00:07:46.720]   different? Potentially, eventually, we basically do experiences in five countries and six countries
[00:07:46.720 --> 00:07:53.360]   now and seven locations where we have a lot of friends. And so it's like, we wouldn't do an
[00:07:53.360 --> 00:07:57.280]   experience in a place unless we spent months and months and months and months there and have made
[00:07:57.280 --> 00:08:02.880]   a lot of friends and got in the know it very well. So it could open the door. I mean, if my
[00:08:03.840 --> 00:08:09.680]   wife is inspired, but we just right now we're in France, Spain, and Italy, Mexico, Morocco,
[00:08:09.680 --> 00:08:14.560]   and we just added El Salvador. So that's a place where she knows everybody because she was born
[00:08:14.560 --> 00:08:22.240]   there. And we've traveled there, you know, 34. I think the Tasmanian experience is, is,
[00:08:22.240 --> 00:08:28.480]   has to happen. Has to happen, right, it's roasted Tasmanian devil. I mean, it's just the food there,
[00:08:28.480 --> 00:08:36.560]   fantastic. Australia is an incredible food country. Melbourne is an incredible food country city.
[00:08:36.560 --> 00:08:41.840]   And so, and we also, you know, we're also going to be traveling to South America. The new,
[00:08:41.840 --> 00:08:49.600]   the new top 50 restaurants came out last week and two of the top 10 restaurants are in Lima, Peru.
[00:08:49.600 --> 00:08:55.760]   Yeah, it was amazing. I'm friend of mine, Dr. Krupali on Twitter has a picture of herself in
[00:08:55.760 --> 00:08:58.720]   front of it. She went there, it's a vegetarian restaurant, one of them, right?
[00:08:58.720 --> 00:09:05.760]   I don't know the details about it, but I just think you can feel them rising in the global ranks
[00:09:05.760 --> 00:09:11.760]   as a food city by looking at this thing. So not a good Ceviche. I've never been.
[00:09:11.760 --> 00:09:18.880]   Well, I've never been to Europe. Really, I've never been, yeah, anywhere in Europe,
[00:09:18.880 --> 00:09:25.440]   been overseas to places like Thailand and the Philippines and places like that. But I've never
[00:09:25.440 --> 00:09:29.840]   been to Europe and we've decided that next summer, probably about this time next summer,
[00:09:29.840 --> 00:09:35.120]   we're going to Rome, definitely to Rome. We're going to visit Padre. He's going to stoke us out.
[00:09:35.120 --> 00:09:40.720]   We're already in contact with him to explore the catacombs and do all the fun stuff. It's kind of
[00:09:40.720 --> 00:09:45.520]   a perfect opportunity to take our girls and go educate them on what it's like. You know,
[00:09:45.520 --> 00:09:50.240]   we've taken them traveling. We just went to Costa Rica, but I think this is like next level where we
[00:09:50.240 --> 00:09:58.640]   go to some place with just this insanely rich history and show them something that none of us
[00:09:58.640 --> 00:10:02.480]   have ever experienced, all of us together. I know that while we're over there, we're probably
[00:10:02.480 --> 00:10:06.560]   going to want to go at least one other place. We don't want to jam-pack it with like five different
[00:10:06.560 --> 00:10:12.720]   places. We want to do like maybe two places really deeply. So do Rome, Italy, maybe go to a
[00:10:12.720 --> 00:10:17.440]   different country right around there and pick something and spend a couple of weeks over there.
[00:10:17.440 --> 00:10:20.800]   I think that's our plan. So that'd be great. So would you want to be nice?
[00:10:20.800 --> 00:10:27.360]   That would be nice. Yeah, so many the problem is there's so much, there's so many options,
[00:10:27.360 --> 00:10:32.720]   right? It's like, how could I even pick just only one more? I want to see them all. I want to go,
[00:10:32.720 --> 00:10:37.120]   you know, so many more places than just one other place, but really looking forward to it
[00:10:37.120 --> 00:10:40.960]   now that we've decided we're going to go. I mean, you know, the thing is that Rome is a
[00:10:40.960 --> 00:10:46.640]   gigantic city and it would be also nice to go to another Italian place that is not urban
[00:10:47.200 --> 00:10:53.920]   and, you know, for example, the Sicilian country so it would be nice. Northern Italy is super nice.
[00:10:53.920 --> 00:11:02.720]   Milan, Venice, etc. So yeah, but the options are, or you have so many options. I know. It's going to
[00:11:02.720 --> 00:11:07.520]   be fun hanging out with Padre. We spent the day with him once in Rome and that was super fun.
[00:11:07.520 --> 00:11:13.120]   Yeah, super fun. Yeah, he's been saying it for a number of years like, "Hey man, if you ever
[00:11:13.120 --> 00:11:19.280]   get out to Rome, like I'm your man, I got you covered." And, you know, I told him authentically,
[00:11:19.280 --> 00:11:23.440]   like, "Yes, someday we'll make it happen." And finally, just probably like a month ago, I was
[00:11:23.440 --> 00:11:27.440]   like, you know, if we're going to do it, it's got to be like soon because we don't know how much
[00:11:27.440 --> 00:11:32.640]   longer he's going to be there. And also, you know, our girl is like, my oldest is 13 now. It's a
[00:11:32.640 --> 00:11:38.400]   couple of years before she's really doesn't want to hang out with us. So it's like, we got to get
[00:11:38.400 --> 00:11:43.200]   us in now. Like, we're trying to go, you know? Does your 13 year old like fashion?
[00:11:43.200 --> 00:11:49.600]   Yeah, she's pretty fashionable. Yes. She likes to mention you should go to Milan. Oh, really?
[00:11:49.600 --> 00:11:56.480]   She'll freak out. Milan is a city of fashion. Like Palo Alto is a city of technology.
[00:11:56.480 --> 00:12:02.240]   Oh, no kidding. I mean, that makes sense. Yeah. What I passively know of Milan over the years,
[00:12:02.240 --> 00:12:07.760]   you know, but that's great advice. Cool. Yeah, I'm super excited. We got a lot to plan, but,
[00:12:08.400 --> 00:12:13.040]   it'll be a lot of fun. If you're out there, of course, we will swing by and say, hi, but I don't
[00:12:13.040 --> 00:12:17.840]   know if you would randomly be in Rome at the same time, but we'll certainly, I'll be in touch and
[00:12:17.840 --> 00:12:23.360]   let you know we're going to be out there. Cool stuff. And by the way, Google News and Reddit News.
[00:12:23.360 --> 00:12:30.960]   We do just real quick. We were talking about gastro-nomad just to get it in their gastronomad.net,
[00:12:30.960 --> 00:12:35.760]   right? That's where people can go to find out all the stuff. Yeah.
[00:12:35.760 --> 00:12:42.080]   And we'll do that then. Gutenberg parenthesis.com. There you go. See, we like to get our plugs in
[00:12:42.080 --> 00:12:48.720]   at the beginning. Gutenbergcrestice.com gastronomad.net. And that's the show. Thank you, everybody.
[00:12:48.720 --> 00:12:54.640]   Actually, we do have some news. There is a good amount of Google News in here. Do we start
[00:12:54.640 --> 00:13:01.440]   though with Reddit? Reddit is just, man, this whole saga is just crazy right now. Like, I'm a,
[00:13:01.440 --> 00:13:07.600]   man, I'm going to admit, like, I'm a little sad because, and I'm sure, you know, Leo and you,
[00:13:07.600 --> 00:13:12.480]   Jeff and others have already kind of had the opportunity to talk about this a little bit, but,
[00:13:12.480 --> 00:13:18.880]   you know, it was not very long ago that I stopped my interaction with Twitter. Like,
[00:13:18.880 --> 00:13:23.520]   I really don't do much of anything with Twitter anymore. The sour taste of my mouth,
[00:13:23.520 --> 00:13:28.320]   and the further I got away from it, the more I realized, I'm not really missing it that much,
[00:13:28.320 --> 00:13:33.120]   so I'll just keep doing this thing. Reddit, though, has been a constant for a very long time,
[00:13:33.120 --> 00:13:37.920]   and it's not a constant in my life that I'm like, I'm sharing a million different posts on a million
[00:13:37.920 --> 00:13:44.480]   different subreddits all the time. It's been more of just like something I go to, to learn and to
[00:13:44.480 --> 00:13:51.520]   get the, get a really nice take on what's happening right now and how people feel about it, which is,
[00:13:51.520 --> 00:13:57.280]   I guess, largely what social media is about, but I can't explain why it's different in my mind
[00:13:57.280 --> 00:14:02.080]   and my experience to something like a Twitter or a Facebook. Reddit has just been a really
[00:14:02.080 --> 00:14:06.720]   enjoyable thing for me. Every community, do you, because I don't use Reddit enough, does,
[00:14:06.720 --> 00:14:11.920]   what's the structure of Reddit that fascinates me that I hope is a model for the future,
[00:14:11.920 --> 00:14:18.640]   until now, is the idea that the moderators and the communities have control over the culture of
[00:14:18.640 --> 00:14:24.240]   each community independently. Do you sense that difference as you go from one subreddit to another?
[00:14:24.240 --> 00:14:30.560]   Sure. I mean, I definitely, you know, I probably follow 30 or 40 different subreddits and they all
[00:14:30.560 --> 00:14:34.400]   have their own different, you know, rules and everything. I think that's one of the things that
[00:14:34.400 --> 00:14:39.360]   I actually do like, I think you've kind of put your, put your finger on it, is to a certain degree,
[00:14:39.360 --> 00:14:45.280]   subreddits feel like bulletin board systems to me. And that harkens to a day, you know, when I
[00:14:45.280 --> 00:14:49.280]   was much younger and this like magical idea of like, oh, wait a minute, there's people over there
[00:14:49.280 --> 00:14:54.480]   talking about this thing that I also care about. I'm going to call up that BBS and connect to it
[00:14:54.480 --> 00:14:58.640]   be part of the conversation. And you know, even if there's only like 10 people there, like,
[00:14:58.640 --> 00:15:02.560]   we're 10 people that love the same thing. And so we talk about it. It brings it back to the scale
[00:15:02.560 --> 00:15:07.120]   of humanity. It's really nice. Yeah. And I kind of get a little bit of that vibe when I go into
[00:15:07.120 --> 00:15:11.840]   subreddits. Like, there's a community there that's really excited about talking about Google Pixel
[00:15:11.840 --> 00:15:16.800]   phones, or there's a community that's really excited about, Oh, this is a great one about power
[00:15:16.800 --> 00:15:22.800]   washing. Like, I subscribe to a subreddit where all it is is people sharing like really satisfying
[00:15:22.800 --> 00:15:28.400]   power washing videos. And like, that sounds ridiculous. But yet every time I see one of those
[00:15:28.400 --> 00:15:33.440]   videos pop up my feed, I stop and I watch it because it's just really satisfying. And here's a bunch
[00:15:33.440 --> 00:15:41.120]   of other TV shows. So why not? Totally. I mean, I can't do that. But I also understand, I suppose.
[00:15:41.120 --> 00:15:49.120]   Yes. So it's so sad to me to see that Reddit is undergoing kind of a similar moment to what Twitter
[00:15:49.120 --> 00:15:54.640]   kind of last year, that's what it feels like to me. I mean, and certainly it's shaken.
[00:15:54.640 --> 00:15:59.760]   The foundational kind of feeling that I've had about Reddit of being like, Oh, yeah, you know what?
[00:15:59.760 --> 00:16:06.000]   This is one of the good places. And now I'm seeing the CEO just being very, man, I don't know. It's
[00:16:06.000 --> 00:16:12.240]   just like the way he's talking about the people who have donated their time to manage these
[00:16:12.240 --> 00:16:18.560]   subreddits. It just feels very, I don't know what the word is, but he's just very angry. And
[00:16:18.560 --> 00:16:24.560]   well, this is his job. So the CEO, the CEO of Steve Huffman, he's one of the co-founders.
[00:16:24.560 --> 00:16:32.480]   And his perspective is roughly as follows. Reddit is not profitable. And it's also because of the
[00:16:32.480 --> 00:16:38.560]   structure and other things. It's an excellent source of data to train AI. So all of these
[00:16:38.560 --> 00:16:46.000]   companies are just covering up all this very well, well organized data and using it and making a
[00:16:46.000 --> 00:16:50.800]   lot of money off of it. So they're making money off of something that we're providing for free.
[00:16:50.800 --> 00:16:56.800]   And we're not profitable ourselves. So we need to make sure we charge money for people who are
[00:16:56.800 --> 00:17:02.640]   making a lot of money off of it. So that's his perspective. Here's the other perspective.
[00:17:02.640 --> 00:17:13.120]   I guess you might call it my perspective. Here's a guy who is a content site and it's also a social
[00:17:13.120 --> 00:17:22.480]   networking site. So the content is all provided to the company for free by volunteers. The social
[00:17:22.480 --> 00:17:28.880]   networking part, the moderation and the organization is all provided for free. And he's not profitable.
[00:17:28.880 --> 00:17:36.720]   Like, who's fault? Is it the Reddit is not profitable? Well, because the advertising
[00:17:36.720 --> 00:17:43.440]   model around interaction has always been crappy. Well, yes, but I mean, look at the cost advantages.
[00:17:43.440 --> 00:17:48.560]   So here another component of this is that there are all these third party apps. So
[00:17:49.280 --> 00:17:53.840]   his perspective is, Oh, these third party apps are just accessing a site for free.
[00:17:53.840 --> 00:18:02.640]   My perspective is people are also donating and voluntarily donating application programming
[00:18:02.640 --> 00:18:07.280]   expertise. Yes, but that was absolutely. Your ads. Your ads.
[00:18:07.280 --> 00:18:13.360]   Like, why couldn't Reddit make a good app? Their apps are terrible. And that's why people do it in
[00:18:13.360 --> 00:18:21.360]   third party apps. And so to me, every part of this story points to Steve Hoffman as a failure
[00:18:21.360 --> 00:18:28.960]   as a CEO, they should be highly profitable. They're running a website, right? Where moderation
[00:18:28.960 --> 00:18:34.000]   and content creation is all for free. And so it's like, how do you, you know, you got to be able to
[00:18:34.000 --> 00:18:40.080]   make that profitable, even in the wonky ad market, there's got to be wasted to it. I bet there are
[00:18:40.080 --> 00:18:43.680]   a lot of CEOs and potential CEOs in Silicon Valley who could make it profitable. I agree with that.
[00:18:43.680 --> 00:18:49.760]   That's good. Yeah. I'm sure someone could like the, yeah. And again, I'm not a big
[00:18:49.760 --> 00:18:56.320]   ready user. So I don't know, but having, I mean, and I don't think as bad as the full disclosure,
[00:18:56.320 --> 00:19:01.840]   but Reddit was bought by my old boss, Steve Newhouse in advance. I didn't get any piece of it.
[00:19:01.840 --> 00:19:09.520]   But I know from my days working for advance, which believe Steve Newhouse believes strongly
[00:19:09.520 --> 00:19:19.600]   in interaction, in forums and comments and conversation. A, moderation does bring a cost in addition,
[00:19:19.600 --> 00:19:24.800]   because you got lawyers and all kinds of stuff. B, there's never been much of an ad market around
[00:19:24.800 --> 00:19:29.920]   that because advertisers are scared of public voice. They're scared of a lack of control.
[00:19:29.920 --> 00:19:33.680]   They're convinced by media companies that you've got to be in a controlled environment
[00:19:33.680 --> 00:19:40.160]   of media content. And so that's really pretty crappy. Now, yes, ads have been on Twitter,
[00:19:40.160 --> 00:19:47.120]   but Twitter didn't make it either. Ads are on Facebook, but Facebook controls it more as a mass
[00:19:47.120 --> 00:19:52.240]   structure with more use of personal data. So yeah, there are probably ways to do it. I'm not
[00:19:52.240 --> 00:19:59.600]   sure how many of those ways you'd like. So I don't know how well to judge the failure. I think
[00:19:59.600 --> 00:20:05.200]   I think how if it's failure in this case, it's more about bedside manner. Yeah, I'd agree with that.
[00:20:05.200 --> 00:20:11.520]   It's what matter if we said, listen, folks, we all love this thing. We've got to align our interests.
[00:20:11.520 --> 00:20:16.400]   We've got to get ads on to apps so that we can share revenue. And we've got to do this and we've
[00:20:16.400 --> 00:20:20.080]   got to do that. But we've got to pull together, not unlike what's happening at this company,
[00:20:20.080 --> 00:20:28.960]   even at difficult times around ads around Twitter and start a club and start other mechanisms.
[00:20:28.960 --> 00:20:35.120]   So yes, instead he attacks the people who provide this tremendous value for free, not smart.
[00:20:35.120 --> 00:20:39.840]   Well, there's the PR aspect of it, which he's failing at, but there's also the,
[00:20:39.840 --> 00:20:45.040]   he's basically saying, okay, these big companies are making money,
[00:20:45.040 --> 00:20:52.960]   using our API for free and taking all this data. Okay, where's the proposal to have a tiered
[00:20:54.320 --> 00:21:02.480]   payment and free payment for API access? Why isn't he charging open AI, $100 million a year,
[00:21:02.480 --> 00:21:08.000]   charging an app developer nothing because that benefits the community and having maybe a couple
[00:21:08.000 --> 00:21:13.280]   of tiers for advertisers, because a lot of the advertising on Reddit is kind of like quasi
[00:21:13.280 --> 00:21:19.680]   advertorial. They look like legit submissions. Twitter's like that a little bit of with their
[00:21:19.680 --> 00:21:26.800]   advertising. Why is nobody holding his feet to the fire about this ridiculous notion that because
[00:21:26.800 --> 00:21:34.000]   big companies are using the data for free that committed users and moderators and app developers
[00:21:34.000 --> 00:21:38.400]   also have to pay the prices that they would charge Google, for example, or make yourself.
[00:21:38.400 --> 00:21:46.400]   Yeah, that doesn't make any eye. It feels like a logical fallacy of some kind.
[00:21:46.400 --> 00:21:50.960]   I totally agree because these companies are making money, the people are not making money,
[00:21:50.960 --> 00:21:55.920]   also have to pay. Doesn't make sense. That was a big part of my confusion early on in this little
[00:21:55.920 --> 00:22:03.120]   saga, little this major Reddit saga, where the API switch was looming and third party app
[00:22:03.120 --> 00:22:07.760]   developers were basically led to believe like Reddit saying, hey, look, we're not going to hold
[00:22:07.760 --> 00:22:12.880]   you out to the or put your, what is, what is the metaphor I'm looking for?
[00:22:12.880 --> 00:22:16.880]   Oh, you're not going to throw a jam in a dry. Yeah.
[00:22:16.880 --> 00:22:19.840]   Whatever it is. We're not going to throw you out. We're going to pay attention to you.
[00:22:19.840 --> 00:22:25.760]   We respect you and don't worry about it. And then when the, when the announcement comes that,
[00:22:25.760 --> 00:22:32.480]   oh, okay. So here's, here's the actual details. The details are so far outside of any sort of realm
[00:22:32.480 --> 00:22:39.520]   of like reality that no third party, like technically, yes, you're right. If a third party
[00:22:39.520 --> 00:22:43.600]   app wants to pay millions of dollars, they can continue doing the thing. So I guess you got that
[00:22:43.600 --> 00:22:47.760]   right. But no, with a third party app is going to actually do that. And so that felt very,
[00:22:47.760 --> 00:22:52.720]   very much like a fallacy, kind of like what you're saying, Mike, I was, Jason, I think, yeah,
[00:22:52.720 --> 00:22:56.320]   go ahead. You go. Well, I was just going to say that one thing that I don't understand, you know,
[00:22:56.320 --> 00:23:00.160]   when we're talking about like, Reddit needs to make money and they make money off of ads and
[00:23:00.160 --> 00:23:05.680]   how can they make more money off of ads? Why wasn't never considered or maybe it was and I missed it,
[00:23:05.680 --> 00:23:10.800]   but what why can't third party apps have the ads in them too? Like sure, continue doing it,
[00:23:10.800 --> 00:23:16.880]   but we need you to respect our ad platform and serve our ads to your users. I mean,
[00:23:16.880 --> 00:23:21.680]   that makes sense to me. I'm sure any of the third party apps probably would have been open to that
[00:23:21.680 --> 00:23:26.240]   if it meant they could continue to exist. You could also deploy an app. So the API,
[00:23:26.240 --> 00:23:30.080]   you could, you can write a code, made it a conditional use the API is you have to write it
[00:23:30.080 --> 00:23:35.760]   totally, totally. Or you could pull an apple and say, okay, you can have a third party Reddit app,
[00:23:35.760 --> 00:23:39.120]   you can sell ads on that, but we'll take one third of that. That would still be a good
[00:23:39.120 --> 00:23:43.440]   instance for app developers, right? Yes. Have an additional source of ad revenue.
[00:23:43.440 --> 00:23:48.160]   They're just, I don't, I see zero creativity about the problem of not being profitable,
[00:23:48.160 --> 00:23:53.120]   just like, okay, let's just not let's just go out there and just fundamentally understand
[00:23:53.120 --> 00:23:59.840]   that the product is the volunteer moderation and the volunteer content creation. That is
[00:23:59.840 --> 00:24:06.560]   Reddit. That's why people go to Reddit and to sort of like pick a fight with that, with those
[00:24:06.560 --> 00:24:11.600]   people, those communities is just, it's really ridiculous. It feels so much like Twitter,
[00:24:11.600 --> 00:24:16.640]   where the people who really don't quit are venal and an owner now.
[00:24:16.640 --> 00:24:23.760]   That's true. That's absolutely true. But it's that war is still happening.
[00:24:26.560 --> 00:24:32.560]   For somebody at the top running the place to fundamentally misunderstand what it is he's running,
[00:24:32.560 --> 00:24:38.240]   it feels very similar in that sense, even though it's a completely different scale.
[00:24:38.240 --> 00:24:45.280]   The other thing I think, Jason, to your point before is, and I don't know anything about this,
[00:24:45.280 --> 00:24:49.680]   but I'm just guessing that they had a sense of what they were charged for the API and then along
[00:24:49.680 --> 00:24:56.080]   comes open AI and copyright. I was just writing about this for something else.
[00:24:56.080 --> 00:25:01.120]   Copyright holders are seeing the dollar signs and the cartoon eyes going around thinking,
[00:25:01.120 --> 00:25:04.880]   "Oh, they're using my content to train their systems. They're going to make a fortune. They're
[00:25:04.880 --> 00:25:10.720]   not yet." I'm owed all this money because it's copyright. Rupert Murdoch and Barry Diller are
[00:25:10.720 --> 00:25:15.280]   screaming about this already. You owe us money. You can't use our content. Well, a couple things
[00:25:15.280 --> 00:25:23.840]   about that. One is, I think it's very use to learn from existing content. They don't record it.
[00:25:23.840 --> 00:25:27.920]   They don't replicate it. They just learn from it. I also think that what comes out of
[00:25:27.920 --> 00:25:35.680]   LLMs is transformative, so that fits the law in terms of fair use. I'm not sure there's a bag
[00:25:35.680 --> 00:25:41.760]   of money to be had there. I did an event this last week with Barry Ellsman's Investment Fund,
[00:25:41.760 --> 00:25:48.080]   and I moderated two sessions on AI. It's Shadow House, so I guess I can't quote. I always hate
[00:25:48.080 --> 00:25:51.760]   one thing I hate about Shadow House is I want to give credit to someone. I can't unless I ask
[00:25:51.760 --> 00:25:58.880]   a permission. A person I was talking to there said that he would advise, "The legal battle is
[00:25:58.880 --> 00:26:04.320]   going to go on forever, but go ahead and negotiate now because you want to just get on with your work
[00:26:04.320 --> 00:26:08.880]   and come up with some stuff and just act like you got to and do it." I think what happened with
[00:26:08.880 --> 00:26:16.800]   Reddit in part was that huge dollar amount of their API. They knew that LLMs were using them to train
[00:26:16.800 --> 00:26:22.320]   on it because it's really valuable. There's tons of content. They've got an API. It's kind of great.
[00:26:22.320 --> 00:26:28.720]   Your Twitter doesn't anymore. Facebook never had in this way. They do stand alone in the values
[00:26:28.720 --> 00:26:38.400]   of those models, but to charge the same value to Sam Altman and a volunteer who made an app that
[00:26:38.400 --> 00:26:41.920]   expands your value in the marketplace is wrong-headed.
[00:26:41.920 --> 00:26:47.200]   Yeah. Totally. Absolutely. The other thing that bothers me is that when you notice, when you run a
[00:26:47.200 --> 00:26:54.400]   company and you notice that companies are using the data for generative AI purposes
[00:26:54.400 --> 00:27:00.160]   and your response is we're going to charge everybody a ton of money just so we can get those.
[00:27:00.160 --> 00:27:06.240]   That is the first thing I would think of if I was running it would be why don't we use it for
[00:27:06.240 --> 00:27:15.280]   generative AI? Imagine a search engine based on Reddit data. It'd be killer. There's so much good
[00:27:15.280 --> 00:27:20.640]   information on Reddit. There's bad information there too, but that's the beauty of Reddit. The
[00:27:20.640 --> 00:27:26.480]   bad information gets dumped to the bottom and the good information on the whole gets raised to the
[00:27:26.480 --> 00:27:34.480]   top. You could wait the cred of the data of the information based on the community.
[00:27:34.480 --> 00:27:42.400]   So the thumbs up data would rank higher in how the generative AI worked and you'd have a really
[00:27:42.400 --> 00:27:47.920]   great, would not be like what we're seeing out there with other generative AI attempts at search
[00:27:47.920 --> 00:27:54.080]   engines where everything's kind of treated equally to a certain extent. No, you could use the
[00:27:54.080 --> 00:28:01.200]   fundamental nature of Reddit, which is the user moderation and the crowdsourcing of the value to
[00:28:01.200 --> 00:28:08.000]   up or down to weight the value of the content that's used to construct the one true answer you get
[00:28:08.000 --> 00:28:12.400]   from the from from a generative AI based search engine. It could be the greatest search engine
[00:28:12.400 --> 00:28:18.080]   ever built. I don't hear those proposals coming out of Reddit and this could be even a separate
[00:28:18.080 --> 00:28:24.320]   site that would compete directly with Google search, etc. Where's that proposal? That could be huge.
[00:28:24.880 --> 00:28:30.480]   That could be a huge business and it wouldn't presumably bother the Reddit community.
[00:28:30.480 --> 00:28:34.880]   So I don't know. I just I just I the lack of
[00:28:34.880 --> 00:28:40.400]   I'm curious. Where do you both think this is going to end up? Is there going to be peace found and
[00:28:40.400 --> 00:28:45.680]   the mods will come back and we'll be okay or is this a permanent damaged Reddit? I don't get
[00:28:45.680 --> 00:28:50.960]   I don't get the latter. I'm afraid. I just like every other search every other social network.
[00:28:51.600 --> 00:28:57.440]   It's just an certification as Leo says, where it's going to be wounded and
[00:28:57.440 --> 00:29:02.960]   remain wounded and a lesser site than it used to be. Why we can't stand centralised social.
[00:29:02.960 --> 00:29:11.440]   Right. Yeah. I agree. I agree. Unfortunately, that I'd be really surprised if suddenly the CEO
[00:29:11.440 --> 00:29:15.200]   was like, you know, I realize I was trash talking to everybody. I'm really sorry.
[00:29:16.960 --> 00:29:21.920]   And which I think is at least the beginning of what would need to happen to kind of start
[00:29:21.920 --> 00:29:26.960]   by doing the ill feelings that a lot of these moderators have. I think it's it just kind of
[00:29:26.960 --> 00:29:32.640]   permanently changes changes it. And some of those people are going to get out and new people will
[00:29:32.640 --> 00:29:36.000]   come in and they'll adhere to the new rules, whatever the new rules are, because you know,
[00:29:36.000 --> 00:29:42.560]   the CEO has definitely talked about instituting new rules to make to give moderators less influence,
[00:29:42.560 --> 00:29:49.680]   less control. And yeah, like it's just a problem. He's also trying to change the rules a bit so
[00:29:49.680 --> 00:29:56.960]   that it's easier to vote out mods that are not playing ball with the company. Right. So there
[00:29:56.960 --> 00:30:06.240]   are changes afoot where he's trying to make that happen. It's a real problem that Reddit isn't a
[00:30:06.240 --> 00:30:11.280]   public company because there's no board of directors that can fire him. Right. And well, that's what
[00:30:11.280 --> 00:30:14.560]   they're trying to get to Mike because he's trying to go to an IPO.
[00:30:14.560 --> 00:30:19.440]   Yes, I know. But this is this is going to delay it by who knows how long.
[00:30:19.440 --> 00:30:22.320]   Well, that's that's a really great question. Let me just agree with you, Mike.
[00:30:22.320 --> 00:30:31.120]   Being a public company is in the end what borked Twitter. Because because there was no
[00:30:31.120 --> 00:30:37.440]   decent stocks and night ritter and other companies, right? Because there wasn't a stock
[00:30:37.440 --> 00:30:42.800]   structure to enable a beneficent leader, which is why I think Steve Newhouse in the end,
[00:30:42.800 --> 00:30:50.400]   in the case of Reddit, to do things. Steve bought Reddit wholesale, then put it back out there so
[00:30:50.400 --> 00:30:55.440]   there was equity so that the people who were doing it could raise up. And now they're trying to get
[00:30:55.440 --> 00:31:01.600]   to an IPO to do that. But public market is no panacea. Well, but if you look at Twitter,
[00:31:01.600 --> 00:31:09.120]   for example, obviously Elon Musk made it private and now he can't be fired with his record of
[00:31:09.120 --> 00:31:14.400]   bumbling and failure and the billions of dollars, the tens of billions of dollars evaluation
[00:31:14.400 --> 00:31:21.360]   lost at least $20 billion evaluation lost. He would have been fired in a public company. I mean,
[00:31:21.360 --> 00:31:27.200]   he just the degree to which he is failing from a financial point of view, from the point of view
[00:31:28.080 --> 00:31:32.800]   of a board of directors. He would have been fired and they'd put somebody else in there.
[00:31:32.800 --> 00:31:37.680]   Of course, he did hire another CEO, but he still owns a place and makes all the decisions.
[00:31:37.680 --> 00:31:43.600]   But I, you know, I agree that it's not a panacea, but Steve Hoffman should be fired. I don't see
[00:31:43.600 --> 00:31:50.400]   how that's going to happen given that they don't have a board of directors who accountable to
[00:31:50.400 --> 00:31:59.600]   shareholders. What is the impact that we see of this on this kind of looming IPO? I mean,
[00:31:59.600 --> 00:32:08.000]   I would imagine a situation like this isn't great for the possibility of an IPO in the near term or
[00:32:08.000 --> 00:32:13.520]   or will this convince certain potential shareholders that like, oh, hey, you know,
[00:32:13.520 --> 00:32:18.640]   and someone's really running the company that has our best interest in mind. So maybe this
[00:32:18.640 --> 00:32:21.280]   elevates the IPO possibility.
[00:32:21.280 --> 00:32:30.160]   I mean, I think that one of the ways that mods are protesting is they're making
[00:32:30.160 --> 00:32:37.360]   subreddits that are in fact safe for work. They're designating them as not safe for work,
[00:32:37.360 --> 00:32:42.720]   which means advertising won't won't be displayed, which means direct is done at scale. The company
[00:32:42.720 --> 00:32:48.320]   loses a lot of advertising dollars. So they're taking a hit financially. You know, of course,
[00:32:48.320 --> 00:32:53.440]   it's not a public company. So we don't get all the details, but surely they're taking a big hit in
[00:32:53.440 --> 00:33:03.040]   advertising dollars. And so that's going to give potential investors pause. It's also a source of
[00:33:03.040 --> 00:33:08.240]   trouble and controversy. That's going to give them pause. So yes, he seems to be acting in a way that
[00:33:08.240 --> 00:33:19.440]   is he's being assertive toward the cause of revenue and all that kind of stuff. But it's a bumbling
[00:33:19.440 --> 00:33:25.520]   kind of assertion. It's a wrong headed kind of assertion. And ultimately, it's just creating
[00:33:25.520 --> 00:33:32.720]   controversy and problems for Reddit, which is not appealing to to potential investors. So I don't
[00:33:32.720 --> 00:33:38.880]   think there's going to be any serious talk of an IPO anytime in the next year, at least,
[00:33:38.880 --> 00:33:44.880]   and probably more than that. I mean, I just don't see how they're going to get to the point where,
[00:33:44.880 --> 00:33:50.800]   oh, yeah, this looks like a great money making business that is going to disore and grow and
[00:33:50.800 --> 00:33:56.640]   become this gigantic thing, which just seems to go counter to probably the driving force of this
[00:33:56.640 --> 00:34:01.600]   change to begin with. The word I was trying to look for earlier when describing Steve Hoffman and
[00:34:01.600 --> 00:34:08.720]   his actions around this was contemptuous. I feel contempt coming from him when it comes to talking
[00:34:08.720 --> 00:34:12.800]   about the moderators of this platform that have been doing all this free work for him. And I think
[00:34:12.800 --> 00:34:18.000]   that's what really poisons me about this whole situation. Like, oh, you know, kind of like with
[00:34:18.000 --> 00:34:22.960]   Elon Musk and Twitter, there were things that Elon was doing that made me not want to touch
[00:34:22.960 --> 00:34:26.880]   Twitter because it felt dirty. And now I'm like, got this contemptuous thing happening over here
[00:34:26.880 --> 00:34:32.080]   with Reddit. And I just, I don't want all my social networks that I care about to just go away, like,
[00:34:32.080 --> 00:34:37.440]   where am I going to do? You know, I guess I just don't use them as much. I actually fired up my,
[00:34:37.440 --> 00:34:43.120]   my very untouched TikTok account earlier today, because I was like, you know, there's a lot of
[00:34:43.120 --> 00:34:48.240]   stuff happening right now that I care about a lot of stuff in my life and hear it twit, and I'll
[00:34:48.240 --> 00:34:54.720]   talk about it later and everything. But like, I have no place outside of shows on this network where
[00:34:54.720 --> 00:34:59.680]   I can really kind of talk about this stuff on a passing day to day level. I used to do that on
[00:34:59.680 --> 00:35:04.000]   Twitter. I don't really anymore because I don't really want to do it in that way. And I was like,
[00:35:04.000 --> 00:35:08.720]   well, what if I use TikTok the way I use Twitter? So I'll just try that and see how that goes.
[00:35:08.720 --> 00:35:12.560]   You know, I don't know where it's going to go. But anyways, that's, that's my plan. But then
[00:35:12.560 --> 00:35:16.080]   something's going to happen to TikTok. This just seems to be the way of the world with social
[00:35:16.080 --> 00:35:22.320]   media right now. You know, my, my dream has always been to have one social place. That's why I
[00:35:22.320 --> 00:35:28.240]   loved Google Plus so much back in the first four years of Google Plus. And now I find myself once
[00:35:28.240 --> 00:35:34.480]   again spread out across all these things. I am on Twitter still. I'm on blue sky. I'm on
[00:35:34.480 --> 00:35:42.000]   sub stack notes. I'm on T two. I'm on something else. I mean, it's just it's really a
[00:35:42.000 --> 00:35:45.760]   bastard on it is a bummer. That's it on. Thank you. Yes. Thank you. Mass it on.
[00:35:45.760 --> 00:35:51.360]   It's really a bummer. And it's it's just a lot of work to go from one to the other and switch
[00:35:51.360 --> 00:35:56.480]   so much for contextual gears to engage in these conversations and they all have their own
[00:35:56.480 --> 00:36:01.440]   attacks and one great place. Yes. Yeah. Well, you know, and I guess the flip side of that, you
[00:36:01.440 --> 00:36:07.040]   know, I can, I can kind of hear, you know, I don't know how if he really would feel this way,
[00:36:07.040 --> 00:36:10.480]   but I can kind of hear Leo's voice in my ears right now being like, well, that's,
[00:36:10.480 --> 00:36:13.680]   that's good because then you're not putting all your eggs in one basket and you know,
[00:36:13.680 --> 00:36:17.920]   you're not giving one company or one entity, everything that you're doing and you spread it
[00:36:17.920 --> 00:36:22.960]   out. But I mean, it's exhausting is what it is. From my perspective, it's hard enough to just
[00:36:22.960 --> 00:36:28.720]   update one place, let alone have to, you know, just have it locked in my mind that I got to go
[00:36:28.720 --> 00:36:36.240]   at all these, all these places, one, to even check them and then two, to do content or posting or
[00:36:36.240 --> 00:36:40.720]   whatever it is, all the different syntaxes that they require. Like it's exhausting. I just don't
[00:36:40.720 --> 00:36:47.440]   have that space in my life. So I post, I post, I want what I, the morning when I go through the
[00:36:47.440 --> 00:36:55.840]   news, I will post stuff in Twitter, in blue sky and in Mastodon. Occasionally I'll link
[00:36:55.840 --> 00:37:00.400]   in if it's appropriate. Same stuff. Not because I'm trying to spam anything, but I just want to,
[00:37:00.400 --> 00:37:08.080]   I'm still trying to learn what the interaction is going to be in each place. And they're so
[00:37:08.080 --> 00:37:13.760]   unpredictable. Because it's really weird, something that I think, oh, you know, Mastodon's quiet,
[00:37:13.760 --> 00:37:18.560]   the Mastodon's the one where I get a lot of interesting conversation. And blue skies still
[00:37:18.560 --> 00:37:23.680]   pretty light. Twitter is still surprises. And I think, Mike, for your businesses, I think you have
[00:37:23.680 --> 00:37:29.440]   to be on Twitter. Sure. Yeah. It's worse than that. We have to be on Instagram. You know, my wife
[00:37:29.440 --> 00:37:35.840]   runs a Instagram there because outside of the US, there's a huge number of people who only use
[00:37:35.840 --> 00:37:44.640]   meta products. They only use Instagram WhatsApp and Facebook. And so they've never ever go to
[00:37:44.640 --> 00:37:49.840]   Twitter or any of these other things. So my wife takes one for the team. She holds her nose and
[00:37:49.840 --> 00:37:56.320]   goes on Instagram. But yeah, it's exactly what you're saying, Jeff, I do the same thing. And I'll
[00:37:56.320 --> 00:38:01.040]   often post, you know, if it's super techie, I'll only post it on Mastodon and, and, and, and
[00:38:02.080 --> 00:38:07.040]   T two or something like that. If it's, if it's super political, maybe only Twitter and blue sky.
[00:38:07.040 --> 00:38:15.120]   But sometimes I'll post the same exact content on all five. And then I'm surprised it just completely
[00:38:15.120 --> 00:38:19.600]   blows up on one of them and goes nowhere on the others. So I'm not really sure what's going there.
[00:38:19.600 --> 00:38:26.160]   I'm hoping eventually that one of these social networks will demonstrate to me that that's the
[00:38:26.160 --> 00:38:30.240]   place where I want to spend all my time and I'd be happy to cancel my accounts on all the rest.
[00:38:30.240 --> 00:38:33.280]   But so far they're all kind of, they're all kind of out there.
[00:38:33.280 --> 00:38:42.560]   And each one is unsatisfying by itself. Yeah. So for, for our comfort, blue sky, which, you know,
[00:38:42.560 --> 00:38:48.560]   hasn't been federated yet, just, just said yesterday that they put up a sandbox environment for
[00:38:48.560 --> 00:38:54.160]   federation is now ready. So I think, I think proof of the pudding there will be how federated
[00:38:54.160 --> 00:38:59.120]   it becomes and how independent people can be. That gives me some hope also the other thing I like
[00:38:59.120 --> 00:39:08.480]   about blue sky is that they don't really have customizable algorithms so much yet as customizable
[00:39:08.480 --> 00:39:14.640]   feeds. But I like the idea of being able to, for someone to come in and make money doing it,
[00:39:14.640 --> 00:39:21.440]   let's listen, read it, and give me an algorithm that recommends the kind of stuff that I would
[00:39:21.440 --> 00:39:27.440]   want and goes to that effort. I think there's opportunities for customizable federated worlds
[00:39:27.440 --> 00:39:31.120]   around both mastodon. And I hope blue sky will see. I hope they do it right.
[00:39:31.120 --> 00:39:37.840]   The frustrating thing is that blue skies using the at protocol and instead of, so they're not,
[00:39:37.840 --> 00:39:42.720]   you know, currently going to be federated along with mastodon and all the rest.
[00:39:42.720 --> 00:39:47.280]   So that would be killer. If they were, you know, if I could interact with
[00:39:47.280 --> 00:39:54.560]   twit.social and all the people on mastodon and that fetaverse, I'd probably just use blue sky.
[00:39:55.120 --> 00:39:59.360]   I think that once they get their Federation act together, it's more possible to imagine how
[00:39:59.360 --> 00:40:02.960]   that might happen. And I don't know anything. But the same count when we had rabble on,
[00:40:02.960 --> 00:40:12.960]   you know, who works in Federation at an early Twitter and so on. He, as I remember, argued that
[00:40:12.960 --> 00:40:19.040]   there was some benefit for competing protocols that they could improve each other and learn from
[00:40:19.040 --> 00:40:26.320]   each other. And so it may be too soon for a way to get behind just activity pub. Maybe there's a
[00:40:26.320 --> 00:40:30.640]   benefit to having another protocol that has some of the functionality we don't have. I don't know,
[00:40:30.640 --> 00:40:35.760]   I don't know enough to judge that. But I still have some hope here. And again, what we said before,
[00:40:35.760 --> 00:40:40.160]   you said earlier, Jason, about about the feeling you had of Reddit being like a bulletin board.
[00:40:41.440 --> 00:40:50.240]   I think we got everybody got too much greed for attention in their eyes of wanting a mass
[00:40:50.240 --> 00:40:54.240]   audience. I want Twitter, even though even though nobody has a whole Twitter, nobody has a whole
[00:40:54.240 --> 00:40:59.360]   Facebook, no two people see the same place for either place. But we get the sense the mass had
[00:40:59.360 --> 00:41:05.280]   to matter and scale had to matter. If we can get back down right size to human size and recognize
[00:41:05.280 --> 00:41:11.200]   that if you're suddenly talking to 500 people somewhere, that's amazing. That's like having
[00:41:11.200 --> 00:41:15.280]   your own auditorium. That's just great. And you can meet all kinds of interesting people and you
[00:41:15.280 --> 00:41:19.360]   can have interesting conversations. And that's wonderful. You don't need 50,000. You don't need
[00:41:19.360 --> 00:41:26.000]   100,000. You don't need 5 million. In fact, that's absurd. So to rescale our social expectations of
[00:41:26.000 --> 00:41:33.280]   the internet, I think is important is part of how we're going to make this right again. And then
[00:41:33.280 --> 00:41:41.120]   also the asset involved isn't as attractive to nihilistic narcissists like Elon Musk.
[00:41:41.120 --> 00:41:46.960]   Or to your point, Mike, I don't really know enough. But let's just say in competent executives like
[00:41:46.960 --> 00:41:57.680]   Huffman, I think the potential is to keep modest. Yeah, exactly. And one of the draws for a place
[00:41:57.680 --> 00:42:05.200]   like Twitter is JLo can go there and have 100 bazillion followers. And so you want to reward
[00:42:05.200 --> 00:42:10.720]   the people who will bring a big audience and bring a lot of fans, bring a lot of readers,
[00:42:10.720 --> 00:42:16.000]   bring a lot of viewers, whatever it is for the people who really do need those big, big audiences.
[00:42:16.000 --> 00:42:21.360]   I mean, Anderson Cooper is not going to be happy with talking to 500 people. He talks to a million
[00:42:21.360 --> 00:42:25.440]   every night or whatever his numbers are. And so you want to be able to track those people. But
[00:42:25.440 --> 00:42:30.000]   at the same time, you don't want it to be this winner takes all system. I mean, I think that's
[00:42:30.000 --> 00:42:36.320]   what brought down dig, which I think is more comparable to Reddit, for example. I mean, there
[00:42:36.320 --> 00:42:41.760]   was a user there named Mr. Babyman. I remember Mr. Babyman. And every single thing he posted was on
[00:42:41.760 --> 00:42:47.680]   the top of dig every single time. And he just determined what the content was of dig,
[00:42:47.680 --> 00:42:55.280]   almost single handedly. And nobody else, everybody wanted that kind of reach. But it was the
[00:42:55.280 --> 00:43:00.080]   whole thing was kind of weighted against you. This is kind of the one of the things that Steve
[00:43:00.080 --> 00:43:08.080]   Huffman called, you know, called called longtime mods landed gentry, because they're holding on
[00:43:08.080 --> 00:43:14.320]   to their spots for lots of time to have they have more authority over the other mods of their of
[00:43:14.320 --> 00:43:20.080]   their subreddit and so on. So this is one of the things like moderation that social networks really
[00:43:20.080 --> 00:43:25.600]   have to figure out a good system for. And you know, you don't want to win or takes all system,
[00:43:25.600 --> 00:43:32.800]   you want people who to who consistently post engaging content to extend their reach and people
[00:43:32.800 --> 00:43:37.440]   who almost never go or who are lucky lose or whatever, kind of to sing to the bottom or whatever,
[00:43:37.440 --> 00:43:42.560]   there's got to be a better way to do it. And so hopefully, hopefully some of these social
[00:43:42.560 --> 00:43:49.760]   networks will figure that out. Hopefully so. All right, that was that was
[00:43:49.760 --> 00:43:54.880]   fantastic. We've got a whole lot more coming up here. Do want to take a break though and thank
[00:43:54.880 --> 00:43:58.560]   the sponsor of this episode and then we will get into some Google news. We've got a whole Google
[00:43:58.560 --> 00:44:04.240]   block. So we might as well tackle it. I love it. I love it. We don't call this. We will talk about
[00:44:04.240 --> 00:44:10.480]   Google. We'll do that in a second. But first this episode of this week in Google is brought to you
[00:44:10.480 --> 00:44:16.000]   by Bitwarden Bitwarden is my password manager Bitwarden is awesome. It's the only open source
[00:44:16.000 --> 00:44:22.160]   cross platform password manager can be used at home, it can be used at work on the go. It's trusted
[00:44:22.160 --> 00:44:29.840]   by millions of people. Even our very own Steve Gibson has switched over. So have you switched over?
[00:44:29.840 --> 00:44:35.200]   Well, you should with Bitwarden, all of the data in your vault is end to end encrypted. And that's
[00:44:35.200 --> 00:44:39.440]   not we're not just talking about passwords. You can protect your data and privacy with Bitwarden
[00:44:39.440 --> 00:44:44.320]   by secure by adding security to your passwords. Yes, with strong randomly generated passwords
[00:44:44.320 --> 00:44:49.200]   for each account. But you can go further. You can use their username generator. You can create
[00:44:49.200 --> 00:44:55.360]   unique usernames for each account. You can even use any of the five integrated email alias services.
[00:44:55.360 --> 00:45:04.320]   It's almost like a secure like a secure password toolkit, not just a password manager. Bitwarden
[00:45:04.320 --> 00:45:09.520]   is open source. All the code is available on GitHub. Keep things open. Anyone can view it.
[00:45:09.520 --> 00:45:14.080]   This means that you don't have to trust their word. You can actually see that it's completely
[00:45:14.080 --> 00:45:19.520]   secure yourself. On top of being public to the world, Bitwarden has a professional third party
[00:45:19.520 --> 00:45:25.120]   audits. That's performed every single year. And the results are also published on their websites.
[00:45:25.120 --> 00:45:29.920]   They don't hide in anything. There's open source security that you can trust at the end of the day.
[00:45:29.920 --> 00:45:35.120]   Bitwarden also launched a new Bitwarden secrets manager. This is currently a beta.
[00:45:35.120 --> 00:45:41.200]   Right now it's an end to end encrypted solution that allows teams of developers to centrally secure,
[00:45:41.200 --> 00:45:46.240]   manage, and deploy sensitive secrets, things like API keys and machine credentials.
[00:45:46.240 --> 00:45:51.120]   Secrets manager keeps those sensitive developer secrets out of source code.
[00:45:51.120 --> 00:45:55.760]   It eliminates the risk of them being exposed to the public in the process.
[00:45:55.760 --> 00:46:01.120]   Bitwarden needs developers to test out the new secrets manager and provide feedback.
[00:46:01.120 --> 00:46:08.240]   That's why it's in beta. So you can learn more at bitwarden.com/secretsbeta. That's secrets beta one word.
[00:46:09.760 --> 00:46:14.160]   And then you can share your private data securely with your co-workers. You can do that across
[00:46:14.160 --> 00:46:20.080]   departments, the entire company even with fully customizable and adaptive plans. They've got the
[00:46:20.080 --> 00:46:26.800]   Bitwarden teams organization option. That's only $3 a month per user. We're talking really
[00:46:26.800 --> 00:46:32.480]   inexpensive here. Their enterprise organization plan is just $5 a month per user. And then if
[00:46:32.480 --> 00:46:38.000]   you're an individual user, like many of you are, you can always use the basic free account for an
[00:46:38.000 --> 00:46:43.680]   unlimited number of passwords, no limits. Upgrade any time then to a premium account.
[00:46:43.680 --> 00:46:48.400]   That's less than a buck a month. Or you can bring the whole family with their family organization
[00:46:48.400 --> 00:46:56.240]   options. That's what I have to give up to six users premium features. That's only $3.33 a month.
[00:46:56.240 --> 00:47:02.160]   Pretty awesome stuff. And here at Twit, we think Bitwarden is awesome. We're fans of password
[00:47:02.160 --> 00:47:07.120]   managers, of course. Bitwarden is the only open source cross-platform password manager
[00:47:07.120 --> 00:47:13.440]   that can be used at home, on the go, or at work. And it's also trusted by millions of individuals,
[00:47:13.440 --> 00:47:20.400]   teams and organizations worldwide. So you should check out free trial, get started with that.
[00:47:20.400 --> 00:47:27.360]   By checking out that free trial of a team's or an enterprise plan. Or you can get started for free
[00:47:27.360 --> 00:47:32.080]   across all devices as an individual user. And really just kind of check it out for yourself.
[00:47:32.080 --> 00:47:36.800]   Do that. What have you got to lose? Bitwarden.com/twit. That's Bitwarden.
[00:47:37.200 --> 00:47:42.960]   We think Bitwarden for their support of this week in Google.
[00:47:42.960 --> 00:47:49.440]   Okay, so let me scroll up here and see what kind of Googly stuff we have. Oh yeah, the Google
[00:47:49.440 --> 00:48:00.560]   domains thing. This is going to be fun going along the road of, can we trust the big technology
[00:48:00.560 --> 00:48:07.760]   companies that we've grown so close to over the years. And Google, time and time again,
[00:48:07.760 --> 00:48:11.840]   man, they just keep reminding us you can't trust us to hold on to something that you love.
[00:48:11.840 --> 00:48:17.760]   That even might be a success, but maybe not to Google's metric of success, whatever the
[00:48:17.760 --> 00:48:25.680]   heck that is. But Google domains getting the axe, according to ours, Technica, selling its
[00:48:25.680 --> 00:48:31.840]   domain hosting business to Squarespace. This is going to close or expected to close anyways in
[00:48:31.840 --> 00:48:41.520]   third quarter of 2023. Eight years since it was launched. And I mean, a lot of people, a lot of
[00:48:41.520 --> 00:48:49.600]   companies relying on this now suddenly going to go and go in the hands of Squarespace. So Google's
[00:48:49.600 --> 00:48:51.600]   getting out of it. And what do we think of Squarespace?
[00:48:52.720 --> 00:48:59.600]   I mean, I have a site on Squarespace. That's my main thing. I have a site. I like the site.
[00:48:59.600 --> 00:49:04.880]   But beyond that, I don't know. I have several and it's in the next bag. I mean,
[00:49:04.880 --> 00:49:12.240]   they're very good in certain things. In fact, Gastronome.net is a Squarespace site. And one of the reasons
[00:49:12.240 --> 00:49:18.160]   we use it is because we use their e-commerce for people to sign up for experiences. So it's all
[00:49:18.160 --> 00:49:25.440]   very integrated into Stripe and so on. And it works really well. They have some nicely designed
[00:49:25.440 --> 00:49:32.560]   templates. And they have pretty good tech support. I should say better than pretty good. They have
[00:49:32.560 --> 00:49:39.280]   good tech support. They're a little slow to evolve. I think it's fine for them to have this.
[00:49:41.200 --> 00:49:48.880]   The service, what's once again disappointing is that Google has this thing that people are
[00:49:48.880 --> 00:49:54.720]   using. They're happy with it. It's associated with workspace. People who bought into Google's stuff
[00:49:54.720 --> 00:50:03.200]   are once again being kind of shafted by Google, in this case, not closing it, essentially selling
[00:50:03.200 --> 00:50:08.720]   it off. And it's just once again, it's just so confusing about why Google does these kinds of
[00:50:08.720 --> 00:50:14.880]   things. Why sell it? Are they strapped for cash? It was profitable. So that doesn't make any sense.
[00:50:14.880 --> 00:50:22.000]   It just doesn't make any sense to keep pulling the rug out from your most passionate users who
[00:50:22.000 --> 00:50:27.600]   follow your lead. Do what you say. They roll this kind of stuff out to Big Fan Fair. Everybody
[00:50:27.600 --> 00:50:32.400]   gets excited. Users go rushing in to use the service. And then later, Google just says,
[00:50:32.400 --> 00:50:35.760]   nah, we're not going to be associated with it anymore.
[00:50:35.760 --> 00:50:39.200]   Yeah. And one of the reasons that I mean, obviously I've been a Google fanboy going back
[00:50:39.200 --> 00:50:43.440]   here is I wrote a book called what Google do. I'm on a podcast called this weekend Google.
[00:50:43.440 --> 00:50:48.480]   One of the reasons that I that I liked Google and trusted them in the past was that these were
[00:50:48.480 --> 00:50:52.960]   things that just made you feel good about Google. They were worth doing it for that purpose.
[00:50:52.960 --> 00:51:01.200]   In another world, we call it branding. It just had a world that was filled with sleazy promoters.
[00:51:05.520 --> 00:51:10.800]   URL world, the domain world. Thank you. Thank you, my soul. I couldn't come up with.
[00:51:10.800 --> 00:51:17.280]   The domain world was filled with with yikki places. Google said, okay, okay, we're going to come in.
[00:51:17.280 --> 00:51:20.160]   We're going to clean it up. We're going to do some decent, decent price, boom, boom. We're going to
[00:51:20.160 --> 00:51:25.440]   run profitably as you said, Mike. And it was great. And now just to drop it, there's just no
[00:51:25.440 --> 00:51:29.600]   trust you them for anything. You know, at some point, are they going to get rid of Gmail?
[00:51:29.600 --> 00:51:32.160]   Oh my goodness. I mean, how many times do we have these conversations?
[00:51:32.160 --> 00:51:38.320]   Photos. Right. Yeah. How terrifying would it be if they said, okay, we're closing Google photos in
[00:51:38.320 --> 00:51:43.440]   one month. And that sounds ridiculous to me. But yet at the same time, I would never be surprised.
[00:51:43.440 --> 00:51:47.600]   At this point, I just would never be surprised if they killed anything. I guess Gmail would surprise
[00:51:47.600 --> 00:51:52.960]   me because, but I mean, even then, like, you know, maybe Google decides, oh, we're not killing it,
[00:51:52.960 --> 00:51:58.240]   but we're selling it to Squarespace. You know, like, so space is Gmail. I don't know. Like, I'm not,
[00:51:58.240 --> 00:52:02.640]   I think that's there. Someone, I think Jeff, you would put an article in here,
[00:52:02.640 --> 00:52:09.360]   written by David Heinemayer Hanson. Yeah, I don't know him, but the headline grabby.
[00:52:09.360 --> 00:52:16.720]   Yeah, we can't trust Google. Yeah, can't trust Google. And I love the way he ends this article. He
[00:52:16.720 --> 00:52:20.480]   says, all I'm saying is you better have a backup plan. Be that for your collaboration,
[00:52:20.480 --> 00:52:24.720]   your email, your home security system, anything that reads made by Google implicitly has the
[00:52:24.720 --> 00:52:30.800]   subscript until we don't give an F anymore printed below. And that just feels more and more true.
[00:52:30.800 --> 00:52:37.120]   I don't know how many times really is this exact story insert new Google thing into it. And each time
[00:52:37.120 --> 00:52:43.360]   more and more, I believe more and more people who were once very passionate about Google's approach
[00:52:43.360 --> 00:52:48.080]   to these things and feeling exactly like you were talking about Jeff, like, you know, Google does
[00:52:48.080 --> 00:52:53.600]   something in a nicer way versus the competitors that kind of feel slimy and everything like that.
[00:52:53.600 --> 00:52:58.800]   Like that's great. But if we never have any sort of confidence that Google's going to stick the
[00:52:58.800 --> 00:53:03.920]   landing and keep supporting something that seems successful and good for the company and good for
[00:53:03.920 --> 00:53:09.280]   users and everything like that, why are we going to continue trusting Google? Why would we do that?
[00:53:09.280 --> 00:53:13.200]   At a certain point, we're just kind of crazy if we do that because we know it's going to go away
[00:53:13.200 --> 00:53:22.640]   eventually. They've already they've already scraped off their shoe. Millions of super passionate Google
[00:53:22.640 --> 00:53:27.840]   fanboys by closing Google Reader by closing Google+, by doing all the things that they've done over the
[00:53:27.840 --> 00:53:35.440]   years. And so there really aren't a whole lot of loyal customers left of Google. They're people
[00:53:35.440 --> 00:53:40.640]   who are locked in. And apparently that's good enough for Google as long as they can keep selling
[00:53:40.640 --> 00:53:46.080]   ads and making the money that they do and the ways that they do. But how is it possible to be
[00:53:46.080 --> 00:53:54.560]   within 10 miles of the Apple campus and not think, huh, wow, Apple's users are super
[00:53:54.560 --> 00:54:02.960]   loyal devoted to the Apple cause. And one of the reasons for that is people know for sure,
[00:54:02.960 --> 00:54:06.880]   they're not going to suddenly kill the iPhone. They're not going to suddenly say, oh, you know what,
[00:54:06.880 --> 00:54:11.040]   we we made a mistake getting into the Apple TV business. We're just going to close all that
[00:54:11.040 --> 00:54:18.080]   stuff down. Let me try this out on you. Let me try this out on you. Here, you say that.
[00:54:18.080 --> 00:54:25.600]   Just that Leo moment devil's advocate moment, or actually not, just crazy idea moment.
[00:54:25.600 --> 00:54:32.640]   Is Google Apple is a consumer company? Apple requires people to buy their stuff. Is Google
[00:54:32.640 --> 00:54:39.520]   turning into an enterprise B2B company? Is it you know, behind it's yeah, sure they make Android
[00:54:39.520 --> 00:54:44.960]   phones. But then again, they really license Android out to everybody else. Yeah, they've got G
[00:54:44.960 --> 00:54:52.800]   mail, but it's really about, you know, enterprise stuff. They have enterprise SaaS services.
[00:54:52.800 --> 00:55:00.240]   Advertising is all B2B. And now that they own the marketplace both ways, it's really about
[00:55:00.240 --> 00:55:04.960]   advertisers and media back and forth. Is it no longer a consumer company and brand?
[00:55:04.960 --> 00:55:09.040]   Well, the reason you're asking that question is because it's unknowable. It's confusing. It's a
[00:55:09.040 --> 00:55:15.040]   confusing point. If you look at a company like Microsoft, a Microsoft has clearly
[00:55:15.040 --> 00:55:21.520]   nearly completed their pivot to becoming an enterprise company. And they are so successful.
[00:55:21.520 --> 00:55:26.960]   If you look at the valuation of technology companies, of course, you would expect Apple to be at the
[00:55:26.960 --> 00:55:33.440]   very top of valuation. But if you look at Microsoft, Microsoft is number two right behind Apple.
[00:55:34.320 --> 00:55:41.200]   Microsoft is almost as valuable as a present, which is stunning to me. But they've done it by being
[00:55:41.200 --> 00:55:46.720]   pretty clear that they're about business and the enterprise. Then you have Google. Google has,
[00:55:46.720 --> 00:55:50.240]   you know, they sell a smartphone, then they don't. Now they're selling a smartphone again,
[00:55:50.240 --> 00:55:56.160]   then they buy Motorola, then they spin off Motorola. So confusing. They have the laptops,
[00:55:56.160 --> 00:56:00.400]   then they want to do laptops anymore. And then they buy nests, right? And then they get rid of
[00:56:00.400 --> 00:56:04.880]   net. They don't get rid of nests, but they sort of don't do much with it.
[00:56:04.880 --> 00:56:12.240]   If they wanted to be an enterprise company, once or for all, get rid of nests,
[00:56:12.240 --> 00:56:18.160]   stop making consumer play. I mean, they dominate education, for example,
[00:56:18.160 --> 00:56:28.560]   with Chromebooks to a very large extent. They're just so confusing. And if they really wanted to
[00:56:29.360 --> 00:56:37.280]   do the kinds of things Apple does, they would have one messaging app instead of 13 or 12 or
[00:56:37.280 --> 00:56:42.160]   nine or 15 or whatever it is they have. Nobody knows. It's unknowable what their messaging
[00:56:42.160 --> 00:56:48.560]   products are. They would have one. That would be Google messages or something like that.
[00:56:48.560 --> 00:56:52.720]   And that could be the catalyst that would bring people into all these other things. But no,
[00:56:52.720 --> 00:56:57.360]   they just they can't seem to get control of themselves. They're like, what do you think?
[00:56:57.360 --> 00:57:01.440]   Teenager. Since you will always be my top expert on Android.
[00:57:01.440 --> 00:57:09.840]   What do you think about Google and its fate? I mean, it just seems like time and time again,
[00:57:09.840 --> 00:57:15.680]   Google can't coordinate between itself to get everybody on the same page to know like,
[00:57:15.680 --> 00:57:20.080]   all that I could think of when I was when I was listening to you, Mike, and thinking about the
[00:57:20.080 --> 00:57:24.400]   question is like, I don't even know that Google could answer that question. I don't know that
[00:57:24.400 --> 00:57:30.400]   Google understands exactly which direction is going for. I think Google, to a certain degree,
[00:57:30.400 --> 00:57:35.280]   which is all of these different departments doing many different things, they want to be
[00:57:35.280 --> 00:57:41.040]   everything. And they want to be everything for as long as they're tasked to do that until suddenly
[00:57:41.040 --> 00:57:44.800]   they get recognized for the work they did over there. I'm talking about like an individual like
[00:57:44.800 --> 00:57:50.080]   product manager or something like that. And suddenly he or she gets transferred over to this
[00:57:50.080 --> 00:57:55.200]   other thing. And then that thing dies on the vine because there's no more person there to
[00:57:55.200 --> 00:58:01.760]   vie for it. As a company, it seems like a lot of their efforts are not executed with the company
[00:58:01.760 --> 00:58:06.560]   in mind. It's more like, I've got this really great idea. Okay, you do that. And they do that and
[00:58:06.560 --> 00:58:11.840]   it gets successful. But it's not like, it's not considered this big major success for Google. It's
[00:58:11.840 --> 00:58:19.120]   a major success for it. And then once the person champions that team is gone, then that it falls
[00:58:19.120 --> 00:58:24.960]   apart. And as a consumer, as a user of Google, it's just kind of exhausting at a certain point.
[00:58:24.960 --> 00:58:31.040]   It's like, there's only so many times I can put my faith into this product and then have it
[00:58:31.040 --> 00:58:35.680]   disappear on me again. And I think it's a fascinating period because, because
[00:58:35.680 --> 00:58:41.440]   right Facebook realized that everything it stood for was shrinking. So it decides to go full
[00:58:41.440 --> 00:58:47.840]   many verse and then that doesn't really work. So now it decides to go AI. Microsoft
[00:58:47.840 --> 00:58:54.960]   is kind of I think ruining its consumer products by throwing AI in appropriately.
[00:58:54.960 --> 00:59:03.760]   Google is screwing all these properties that we cared about. It's really interesting to
[00:59:03.760 --> 00:59:08.640]   figure that out. Apple, and I'm not a, as you know, I'm no Apple fanboy because I think that they
[00:59:08.640 --> 00:59:13.600]   got out of the advertising business because they failed and privacy became a bug, became a feature,
[00:59:13.600 --> 00:59:19.840]   but they have to stick close to the consumer. You know, if you look at media companies,
[00:59:19.840 --> 00:59:24.800]   media companies, except for little ones like this, aren't close to consumers. They're just selling,
[00:59:24.800 --> 00:59:28.640]   they're the ones who for whom you are a product because they're selling your eyeballs to advertisers
[00:59:28.640 --> 00:59:36.240]   always have been. There's not a lot of truly consumer, customer based companies on the internet
[00:59:36.240 --> 00:59:38.960]   out there. Now that we think about it, now we're discussing this. I haven't thought of this before.
[00:59:38.960 --> 00:59:45.360]   And then people assume Apple is, but really Apple is very successful in the enterprise as well,
[00:59:45.360 --> 00:59:50.480]   and in business markets, and they don't draw this huge distinction between those. They basically
[00:59:50.480 --> 00:59:54.080]   say, okay, well iPhone is just the best phone. That's what they would say. It does good.
[00:59:54.080 --> 00:59:57.840]   And it's the best phone if you're an enterprise user or if you're a consumer.
[00:59:57.840 --> 01:00:03.360]   And so that's that kind of idea has worked well for Apple. But yeah, you're right. They are
[01:00:03.360 --> 01:00:09.680]   small consumer companies. But many of the big companies have realized that the business market
[01:00:09.680 --> 01:00:15.120]   is the better business. And of course it is a better business. It's easier. It's a hell of a lot
[01:00:15.120 --> 01:00:20.400]   easier. It's great to have a government contract rather than trying to sell individual units at
[01:00:20.400 --> 01:00:26.880]   Best Buy because that's really problematic. But the thing about Google, I think that just to
[01:00:26.880 --> 01:00:31.360]   reiterate and kind of reframe a little bit what you were saying, Jeff, is that
[01:00:32.000 --> 01:00:43.360]   I mean, Jason, is that Google, nobody's in charge. Nobody's in charge. The individual
[01:00:43.360 --> 01:00:50.160]   departments are just doing their own thing. And again, contrasting against Apple,
[01:00:50.160 --> 01:00:57.440]   Steve Jobs created a company where he was the fascist dictator. He personally was in charge
[01:00:58.000 --> 01:01:02.800]   all the way down. And he decided what color blue the translucent,
[01:01:02.800 --> 01:01:09.680]   loosened desktop PCs would be personally. And he kind of handed that over to Tim Cook. And Tim Cook
[01:01:09.680 --> 01:01:17.200]   is a kind of a dictator where Sundar Pichai, who's both the CEO of Google and also Alphabet,
[01:01:17.200 --> 01:01:22.880]   he's just kind of, I don't know, I don't know what he does. But he just lets the kids run,
[01:01:22.880 --> 01:01:28.080]   why he lets the inmates run the asylum. And we could get the result that we get. Plus,
[01:01:28.080 --> 01:01:33.600]   the incentives at Google are all messed up. You get bonuses and incentivized for launching
[01:01:33.600 --> 01:01:40.960]   products, but you get very little benefit within the company politically or salary wise by
[01:01:40.960 --> 01:01:48.720]   really improving, constantly improving, being dedicated to the users of the product and seeing
[01:01:48.720 --> 01:01:54.240]   it evolve to be better and better and better. They don't incentivize that. So it doesn't happen.
[01:01:54.240 --> 01:01:59.760]   And then these products just sort of languish in obscurity until they're finally killed.
[01:01:59.760 --> 01:02:05.360]   And they do it year after year after year. Nobody ever says, Sundar Pichai never stops and says,
[01:02:05.360 --> 01:02:14.960]   you know, maybe there's a better way. They just keep fumbling along with this conspicuous reputation
[01:02:14.960 --> 01:02:19.680]   as a company just kills this and kills that and kills everything. And they keep doing it as if
[01:02:19.680 --> 01:02:23.280]   they're, I don't know, it feels like they're almost trolling us.
[01:02:23.280 --> 01:02:30.160]   If you think they try to do something about their bad reputation, they don't seem to even be aware
[01:02:30.160 --> 01:02:31.200]   of it somehow.
[01:02:31.200 --> 01:02:36.800]   I mean, the reader thing, I only realized this last night when I was kind of going through old,
[01:02:36.800 --> 01:02:42.320]   you know, all about Android document sheets to get ready for last night's episode. The reader
[01:02:42.320 --> 01:02:47.280]   thing, that was 20, was it 2013 somewhere around there? I mean, it was a long time ago.
[01:02:47.280 --> 01:02:48.560]   That sounds right.
[01:02:48.560 --> 01:02:53.840]   It was a decade ago. And that was one of the earlier times that I remember going,
[01:02:53.840 --> 01:02:58.960]   whoa, if readers on the chopping block, like nothing is safe. You know what I mean? Like,
[01:02:58.960 --> 01:03:02.880]   if you're getting rid of reader, there's probably not a whole lot that Google wouldn't be willing
[01:03:02.880 --> 01:03:07.120]   to get rid of. Like, that was just very surprising to me. Here we are a decade later.
[01:03:07.120 --> 01:03:11.520]   And I mean, go to killed by Google.com. You'll see, you'll see a number of names in there that
[01:03:11.520 --> 01:03:14.000]   will be scratching your head.
[01:03:14.000 --> 01:03:19.360]   Hundreds of products and services, many of which, you know, they're a little bit like Yahoo,
[01:03:19.360 --> 01:03:22.640]   where they announce its closure. You're like, wow, that sounds great. I totally would have used
[01:03:22.640 --> 01:03:28.080]   that if I'd known about it. So the most recent thing is they're killing off album archive.
[01:03:28.080 --> 01:03:34.160]   This is on the rundown. This is part of the inshirtification of Google Photos.
[01:03:34.960 --> 01:03:41.920]   The first big betrayal was that when they, when, when the Vikindotra rolled out Google Photos
[01:03:41.920 --> 01:03:46.400]   and all that stuff, it was unlimited photo storage. And so everybody said, wow, unlimited free
[01:03:46.400 --> 01:03:53.120]   photo source. That's amazing. And everybody poured, you know, gazillions of photos into Google Photos.
[01:03:53.120 --> 01:03:56.480]   And then some time went by and they said, you know what, we changed our mind. We're going to start
[01:03:56.480 --> 01:04:01.680]   charging if you're over a certain amount, a total betrayal. And I personally felt the trade,
[01:04:01.680 --> 01:04:07.760]   because I recommended to so many people, so many readers, that they use Google Photos because they
[01:04:07.760 --> 01:04:12.640]   had this unlimited free photo storage. And now they're killing off album archive. They make
[01:04:12.640 --> 01:04:17.040]   these promises. Explain album archive, Vikind, because I couldn't remember what it was.
[01:04:17.040 --> 01:04:23.360]   Yeah. So you can basically, you can basically take albums and put it into an archive status.
[01:04:23.360 --> 01:04:30.480]   And they would just sit there forever. And so, and so now they're basically saying that, you know,
[01:04:30.480 --> 01:04:34.080]   no, we're, if it's in an archive condition,
[01:04:34.080 --> 01:04:36.800]   I still don't understand that. I still don't like, hold on, slow down for me.
[01:04:36.800 --> 01:04:40.480]   Yeah. What's the difference between album archive and Google Photos?
[01:04:40.480 --> 01:04:46.080]   You know, I don't, I don't really use it that much, but I think it has to do with,
[01:04:46.080 --> 01:04:51.760]   it's a place that they put other kinds of imagery, like from Hangouts and other services.
[01:04:51.760 --> 01:04:57.760]   It could be, you know, I really don't understand that well, frankly.
[01:04:57.760 --> 01:05:03.840]   I know, I use albums a lot, but, but it's, it's a feature in there that I believe that some people
[01:05:03.840 --> 01:05:10.320]   really use. And so I think that it's, you know, I, from what I understand, you can put an album
[01:05:10.320 --> 01:05:16.960]   into, into archive status. So, and then, and then it's not deleted. It's just archived. It's sort
[01:05:16.960 --> 01:05:22.160]   of like what I'm thinking is it's photos that ended up coming from other places. So I go to
[01:05:22.160 --> 01:05:28.400]   Almarkive and it first says, this is photos from post, photos from Hangouts. So it's kind of like
[01:05:28.400 --> 01:05:35.120]   media that was from the side. Yeah, I, I honestly had never heard of this before I got that email.
[01:05:35.120 --> 01:05:40.800]   And when I go there, same as you, Jeff, I have photos from Blogger, which is, okay.
[01:05:40.800 --> 01:05:48.400]   Seal photo from like 2001 DJing. That's probably the only photo that I know of of me being a DJ
[01:05:49.200 --> 01:05:55.520]   back then. And then I have photos from Hangouts, which are just in, I mean, is exactly what it says,
[01:05:55.520 --> 01:06:00.400]   right? The number of really old Hang like photos that I obviously shared with different in different
[01:06:00.400 --> 01:06:05.920]   Hangouts chats. And that's like, I didn't even know this existed until I got that email.
[01:06:05.920 --> 01:06:11.600]   So yeah, it is from these third party things, but it's also for directly usable within Google
[01:06:11.600 --> 01:06:16.160]   photos where you can put, you can take active albums, I guess you could call it, and you can
[01:06:16.160 --> 01:06:19.440]   put it in there with the other stuff into into the archives. Anyway,
[01:06:19.440 --> 01:06:20.880]   which I never archive anything.
[01:06:20.880 --> 01:06:21.760]   You can take the photos.
[01:06:21.760 --> 01:06:30.960]   Yeah, it's a holding tank for photos that, that is separate from the like the active
[01:06:30.960 --> 01:06:34.240]   albums and also from the non-albumized photos.
[01:06:34.240 --> 01:06:38.640]   Yeah, it says, it says, it says repository for photo. If we believe see that, if it didn't come
[01:06:38.640 --> 01:06:43.520]   from chat GPT repository for photos and videos that you've shared on older Google services like
[01:06:43.520 --> 01:06:50.720]   Hangouts.Google Chat or Google+, okay. All right, well, yeah, I mean, there's some old stuff in here.
[01:06:50.720 --> 01:06:53.840]   I'm looking through it. I'm like, oh, yeah, I don't even know if I have that photo in my
[01:06:53.840 --> 01:07:00.320]   photos library. I might actually have to do some takeout work on this, which, oh my God, shoot me,
[01:07:00.320 --> 01:07:04.880]   like takeout working with Google takeout is just such a, I think you said you take it out and you
[01:07:04.880 --> 01:07:08.160]   put it somewhere and you never gonna look at it again.
[01:07:09.840 --> 01:07:15.200]   But it's a major feature in the sense that when you go into the Google Photos app,
[01:07:15.200 --> 01:07:18.800]   there are four things that it dangles in front of you.
[01:07:18.800 --> 01:07:24.000]   Favorites, utilities, archive and trash. I mean, it's like right up there at the top of the interface.
[01:07:24.000 --> 01:07:31.360]   I assume there are lots of people who said, oh, wow, look at that. I'm gonna use that for whatever
[01:07:31.360 --> 01:07:44.400]   reason. And it's just incredible. What is the benefit to Google of doing this? How many of their users
[01:07:44.400 --> 01:07:50.880]   are not really getting, who don't listen to Twitch, watch Twitch, the Twig, right? And don't
[01:07:50.880 --> 01:07:55.920]   get the verge or whatever and won't know about this. They think their photos are safe and sound
[01:07:55.920 --> 01:08:03.360]   and in June or July, whatever it is, it's going to be just unceremoniously July 19.
[01:08:03.360 --> 01:08:04.880]   Just continued.
[01:08:04.880 --> 01:08:06.080]   Discontinued.
[01:08:06.080 --> 01:08:06.880]   I guess what you want.
[01:08:06.880 --> 01:08:08.480]   You're gonna piss off some people and why?
[01:08:08.480 --> 01:08:08.880]   Yeah.
[01:08:08.880 --> 01:08:09.920]   I like piss off everybody.
[01:08:09.920 --> 01:08:17.120]   What is the benefit? I guess what comes to my mind right now is, is Google just to spread out?
[01:08:17.120 --> 01:08:21.120]   Like, do they just have their hands in too many different things? When I compare Google
[01:08:21.120 --> 01:08:25.600]   and Apple, obviously, they're very different companies. They have very different strategies,
[01:08:25.600 --> 01:08:33.680]   but when I think of Apple, the mental image I get is a very kind of honed track of devices and
[01:08:33.680 --> 01:08:38.640]   services. They all work together. They all fit together. They're in the same, they're going in
[01:08:38.640 --> 01:08:42.720]   the same direction. They're traveling on the same road together. And then when I think of Google,
[01:08:42.720 --> 01:08:45.920]   I just think of a million different things shooting into a million different directions.
[01:08:45.920 --> 01:08:50.800]   It's a sky full of fireworks with different colors shooting in all different directions.
[01:08:50.800 --> 01:08:56.240]   And that's Google's strategy. And apparently that doesn't work because they kill so many things.
[01:08:56.240 --> 01:09:02.240]   I appreciate and have appreciated that Google likes to throw spaghetti against the wall and
[01:09:02.240 --> 01:09:08.400]   see what sticks. And that's created some really interesting and fun and enjoyable products and
[01:09:08.400 --> 01:09:13.280]   services that we've used over the years. But it's also created a lot of grief. And I'm just like,
[01:09:13.280 --> 01:09:20.480]   maybe Google just needs to narrow your focus. Do less things but do them better instead of
[01:09:20.480 --> 01:09:22.560]   doing everything and failing at them all.
[01:09:22.560 --> 01:09:30.640]   Well, the thing is that it's actually just feels like Apple does only a few things.
[01:09:30.640 --> 01:09:35.680]   Apple does all the things that Google does for the most part. For example, they have incredible
[01:09:35.680 --> 01:09:41.200]   AI. But instead of just having this AI sort of out there in the wind or having 25 different AI
[01:09:41.200 --> 01:09:45.680]   products that you can use, I'm going to go use an AI product. They build AI into their
[01:09:45.680 --> 01:09:51.760]   ear into the front where you already are. Right. It did subtle little ways. They have a photos
[01:09:51.760 --> 01:09:59.200]   app. They have all those things except they're all in the service of these hardware software
[01:09:59.200 --> 01:10:04.640]   platforms with the iPhone, iPad, etc. And so there's a focus, a clarity, there's a hierarchy of
[01:10:04.640 --> 01:10:09.440]   importance and what they're ultimately trying to, what Apple's ultimately trying to do is
[01:10:09.440 --> 01:10:15.360]   thrill the user and keep them locked in. I mean, the only reason I never use Android phones anymore
[01:10:15.360 --> 01:10:21.440]   is because I love this watch so much. It only works with an iPhone. So they sort of hooked me
[01:10:21.440 --> 01:10:28.480]   with this watch. But the watch works with the phone, the apps work together. They all work with
[01:10:28.480 --> 01:10:34.960]   the iPad. That works with the MacBook Pro that I use and it all kind of works together. There's
[01:10:34.960 --> 01:10:41.840]   a intention to make me, the user, very happy with what I'm doing and I give them way too much money
[01:10:41.840 --> 01:10:46.960]   as a result. Whereas Google, they don't even think about the user, it seems like they're like,
[01:10:46.960 --> 01:10:51.040]   oh, well, we can do this. We have the technology to make this product. Let's make it. And then they
[01:10:51.040 --> 01:10:56.560]   throw this product out there and then there's a, you know, after the fact there's an attempt to
[01:10:56.560 --> 01:11:04.000]   integrate them. Yeah. Right. After the fact, exactly. Yeah. And it's just they just say it's a badly
[01:11:04.000 --> 01:11:09.280]   run company. It's they are the, I said it before in the show and I'll say it again. Sundar Pichai
[01:11:09.280 --> 01:11:13.200]   is the Steve Ballmer of Google. So is there any company you like?
[01:11:13.200 --> 01:11:20.480]   Well, I think, I think, well, I don't know. You know, I think Apple is doing well. Apple certainly
[01:11:20.480 --> 01:11:28.240]   get it doing well financially. They certainly get a lot of money from me and my family. But yeah,
[01:11:28.240 --> 01:11:34.480]   that's a there are a lot of good companies that think the frustrating thing is all of us have
[01:11:34.480 --> 01:11:41.600]   wanted so badly to love Google for so long. Yeah. Right. And I really, really, really want to
[01:11:41.600 --> 01:11:48.240]   want to be on Google side. I loved what they used to be and I love their whole attitude. And I know
[01:11:48.240 --> 01:11:56.160]   that the sort of the scrappy entrepreneurial try everything kind of attitude is a little bit
[01:11:56.160 --> 01:12:00.720]   pass these days. It's not a good way to run a company. But I would have hoped that they would
[01:12:00.720 --> 01:12:10.080]   have evolved and use their advantages to evolve into the new era and sort of notice that it's
[01:12:10.080 --> 01:12:17.120]   a good idea to have one or two messaging platforms instead of 11 or 12. And it's a good idea to have
[01:12:17.120 --> 01:12:25.600]   one or two AI chatbots and not a whole bunch of them or whatever. And I was really counting on them
[01:12:25.600 --> 01:12:31.920]   to do some amazing stuff. I was a pixel book owner. I thought, okay, this is a platform and it's
[01:12:31.920 --> 01:12:38.400]   going to keep getting better and better and better. But no. And so it's, I have to call it like it
[01:12:38.400 --> 01:12:43.360]   is. They just disappoint. They disappoint their users. That's what they're good at.
[01:12:43.360 --> 01:12:47.120]   That's what they're good at right now. It wasn't always that way, but it certainly feels that way
[01:12:47.120 --> 01:12:54.480]   and has for a while in my opinion. I find myself wondering what would Google be like if soon
[01:12:54.480 --> 01:12:59.600]   Narapachai was replaced by a different CEO of the new CEO. And I don't even know who that CEO would
[01:12:59.600 --> 01:13:05.360]   be. But if the CEO was to come in and say, all right, fresh eyes, it's Tim Cook. It's such a
[01:13:05.360 --> 01:13:14.560]   new della level of like transformative fresh look at Google. If some new CEO was to step into that
[01:13:14.560 --> 01:13:19.760]   role, soon ours out that CEO is in, what would Google do that would turn the sky?
[01:13:19.760 --> 01:13:26.080]   I think it's really interesting that I'm about to write a piece of a chapter of the next book about
[01:13:26.080 --> 01:13:31.520]   the kind of goes into that. And it occurs to me, the heading for this part that I'm going to enjoy
[01:13:31.520 --> 01:13:37.680]   writing is it's time to demote the technologists. We needed them to kind of build stuff. What
[01:13:37.680 --> 01:13:42.320]   you think about it, if you were going to go back to, I'm sorry, Gutenberg moment.
[01:13:42.320 --> 01:13:48.000]   Gutenberg was in charge because he knew how to set type at first, right? But before long,
[01:13:48.560 --> 01:13:55.200]   he was replaced by publishers and editors and others who got to the core value of what printing
[01:13:55.200 --> 01:14:00.240]   delivered. If you were going to start a Facebook today, we're going to start a service we're going
[01:14:00.240 --> 01:14:05.120]   to connect lots of people in the world. Who would you put in charge of it? Not a technologist. You
[01:14:05.120 --> 01:14:11.040]   put a charge of, I don't know, a sociologist or an anthropologist or a psychologist or something
[01:14:11.040 --> 01:14:18.320]   else for Google from a consumer perspective, who should be in charge? I know this is what I'm
[01:14:18.320 --> 01:14:23.920]   about to say is absurd, but I'll say it anyway. A librarian, maybe even a journalist, an educator.
[01:14:23.920 --> 01:14:29.120]   What's the value of a consumer perspective there? As a corporate perspective, of course,
[01:14:29.120 --> 01:14:33.200]   it's an advertising company number one. So maybe you put it at sales, maybe Philip.
[01:14:35.680 --> 01:14:42.720]   Who's the chief revenue officer of Google? Philip Schneider. No, Philip.
[01:14:42.720 --> 01:14:50.240]   It's not that I forget his name. I am frantically giving me somebody else.
[01:14:50.240 --> 01:14:59.120]   I can't find his name right now. Or Twitter, it should be a talk show host.
[01:14:59.120 --> 01:15:04.720]   I know I'm getting a absurd, but the point is that when you decide what the essence of the
[01:15:04.720 --> 01:15:09.200]   company is, that's what determines what the leadership should be. John Hoffman.
[01:15:09.200 --> 01:15:17.760]   No, somebody else is thinking about Philip. So again, I apologize for talking so much about
[01:15:17.760 --> 01:15:25.280]   Apple, but that's why Tim Cook, that's why Steve Jobs put Tim Cook as his successor,
[01:15:25.280 --> 01:15:32.400]   because Tim Cook is an expert, probably the world's leading expert at complex manufacturing
[01:15:33.440 --> 01:15:42.160]   of electronics at a massive scale. His job before he took over as CEO was organizing the manufacturing
[01:15:42.160 --> 01:15:52.560]   of tens of millions of iPhones in a short period of time, right the first time using a Taiwanese
[01:15:52.560 --> 01:15:59.680]   company based in China. And he's really good at that. And they recognize that that's really the
[01:15:59.680 --> 01:16:04.880]   core thing Apple does. That's the hardest part of what Apple does is manufacturing
[01:16:04.880 --> 01:16:15.520]   very complex electronics products at a massive scale. And I agree with you entirely and
[01:16:15.520 --> 01:16:19.600]   soon to apologize the wrong person for that. But again, I wouldn't even know what that is at Google.
[01:16:19.600 --> 01:16:27.280]   I don't know what their, I mean, maybe, I don't know. Jeff, just say one thing.
[01:16:27.280 --> 01:16:33.040]   I've been, I've been crapping all over Google a lot. But I think one example of a success story
[01:16:33.040 --> 01:16:42.320]   is Google Maps. So Google Maps is, is a, is an app that competes directly with multiple products,
[01:16:42.320 --> 01:16:49.200]   including with Apple. Apple has worked so hard to, to make Apple Maps as good as Google Maps,
[01:16:49.200 --> 01:16:55.200]   and they have been unable to do it. And you know, Google Maps isn't perfect, but it's pretty amazing.
[01:16:55.200 --> 01:16:58.800]   Yeah, actually continues to be a man. And they haven't. Yeah. And they haven't
[01:16:58.800 --> 01:17:03.040]   bailed on it. I think, you know, again, they're, they're, I can think of several ways that I'd
[01:17:03.040 --> 01:17:08.320]   like to see it improved. But I also can't think of a single other application that's anywhere
[01:17:08.320 --> 01:17:13.600]   near as useful or as high quality as Google Maps is. It always feels like a downgrade.
[01:17:13.600 --> 01:17:19.440]   Anytime I'm not using Google Maps, I'm using something else. Mash Potato in our Discord has
[01:17:19.440 --> 01:17:25.440]   your next book, Jeff. We know you already wrote what would Google do. Now it's what should Google
[01:17:25.440 --> 01:17:31.440]   do. Yeah. What would Google kill? Yeah. Oh boy. Why would Google do that? What?
[01:17:31.440 --> 01:17:40.720]   That, that's awesome. I love it. That's got to be the title. Why would Google do that?
[01:17:40.720 --> 01:17:48.000]   Oh man. What a great conversation. I love this. This shows so much fun. Thank you so much for
[01:17:48.000 --> 01:17:52.560]   diving into that. We've got more coming up. We're going to get into other facets of Google because
[01:17:52.560 --> 01:17:58.000]   that was one story from our Google block that just took us there's more and there's so much more
[01:17:58.000 --> 01:18:04.000]   coming up. Mike Elgin, of course here. It's great to do a podcast with you, sir. It's, it's been a
[01:18:04.000 --> 01:18:08.800]   very long time and I'm just happy to get the chance to talk with you and then always Jeff Jarvis. I
[01:18:08.800 --> 01:18:16.480]   just always feel so, so happy when I get to do this show. It's really great to be here with you both.
[01:18:16.480 --> 01:18:20.240]   But let's take a moment and thank the sponsor of this episode of this week in Google brought to you
[01:18:20.240 --> 01:18:26.960]   by ACI learning. We've got ACI learning all over the studio. We love ACI learning. Love having them
[01:18:26.960 --> 01:18:32.640]   on board. Thanks to ACI learning. The days of boring, archaic training methods are finally over.
[01:18:32.640 --> 01:18:40.080]   Lack of meaningful impact shows up as low engagement. That translates to sub optimal performance
[01:18:40.080 --> 01:18:44.640]   and you and your team deserve to be entertained while you train and be empowered to keep your
[01:18:44.640 --> 01:18:50.640]   organization safe and secure. It's simple. If your IT training isn't raising your team to the level
[01:18:50.640 --> 01:18:56.240]   that you aspire to be, well, you need to check out ACI learning. While the training industry's
[01:18:56.240 --> 01:19:02.560]   completion rate is barely 30%, ACI learning blows its competitors out of the water with an over 80%
[01:19:02.560 --> 01:19:10.480]   completion rate, 80%, 80%, 80%. This is the format that IT professionals want and love. In today's IT
[01:19:10.480 --> 01:19:15.760]   talent shortage, whether you operate as your own in department or you're part of a larger team,
[01:19:15.760 --> 01:19:24.320]   your skills must be at least up to date at the bare minimum. 94% of CIOs and CISOs agree
[01:19:24.320 --> 01:19:30.400]   that attracting and retaining talent is increasingly critical to their roles. Well, ACI learning helps
[01:19:30.400 --> 01:19:35.680]   you retain your team and trust them to thrive while investing in the security of your business.
[01:19:35.680 --> 01:19:42.000]   ACI learning helps keep your skills up to date with more than 7,000 hours of content available,
[01:19:42.000 --> 01:19:49.200]   new episodes added every single day. In your enterprise, it needs cohesive cutting edge training
[01:19:49.200 --> 01:19:54.320]   to keep your team compliant and ahead of the pack. So you can choose an existing course,
[01:19:54.320 --> 01:20:00.320]   let ACI learning combine modules for a tailored solution, or you can let them custom design a
[01:20:00.320 --> 01:20:06.480]   course to address your specific needs. How about that? ACI learning's private bootcamp will train
[01:20:06.480 --> 01:20:11.200]   your team alongside the most passionate and best subject matter experts certified in the latest
[01:20:11.200 --> 01:20:18.080]   version of each certification. So full access to advanced reporting is just one example via ACI
[01:20:18.080 --> 01:20:23.120]   learning's pro portal. You can actually track and manage your team's results. You can manage seats,
[01:20:23.120 --> 01:20:29.040]   of course assign and unassign team members for customized courses that are relevant to their
[01:20:29.040 --> 01:20:34.560]   specific position, access monthly progress and usage reports. There's these visual reports that
[01:20:34.560 --> 01:20:38.800]   provide immediate insight into your team's viewing patterns and progress over any period.
[01:20:38.800 --> 01:20:43.280]   In other words, you're going to know exactly how your team is doing when it comes to learning
[01:20:43.280 --> 01:20:49.920]   through ACI learning. ACI learning trains thousands of aspiring tech and cyber professionals annually,
[01:20:49.920 --> 01:20:55.520]   including providing scholarships to individuals from diverse backgrounds and those transitioning
[01:20:55.520 --> 01:21:01.520]   out of military service into civilian careers. You can join the always on tech training solution
[01:21:01.520 --> 01:21:06.880]   in a rapidly changing world of technology. ACI learning is in the studio every single day to
[01:21:06.880 --> 01:21:13.200]   record and share relevant content that impacts your business. So you can be bold and you can train
[01:21:13.200 --> 01:21:20.560]   smart. Learn more about ACI learning's premium training options across audit, IT and cybersecurity
[01:21:20.560 --> 01:21:28.960]   readiness. All you got to do is go to go.acilearning.com/twit for teams of two to a thousand. That's
[01:21:28.960 --> 01:21:35.120]   one thousand two to one thousand volume discounts start at five seats. Fill out the form when you
[01:21:35.120 --> 01:21:43.520]   go to go.acilearning.com/twit and you'll get more information on a free two week training trial
[01:21:43.520 --> 01:21:48.080]   for your team. That's ACI learning. We appreciate their support of this week in Google. It's great
[01:21:48.080 --> 01:21:54.880]   to have their support of the Twit Network as well. We wouldn't be doing what we're doing right now
[01:21:54.880 --> 01:22:02.640]   without you guys. So thank you for your support. All right. What other Google-y stuff do we have
[01:22:02.640 --> 01:22:07.440]   to put the Google back in this week in Google here? Well, we can be nice to Google for a minute.
[01:22:07.440 --> 01:22:12.080]   Okay, let's do that. I think we need to change a little bit. It would be nice for you.
[01:22:12.080 --> 01:22:16.320]   So even though, well, we're going to talk about Google getting sued, but Gannett sued Google this
[01:22:16.320 --> 01:22:20.560]   week. And editor and publisher called me for response. And the more I thought about the more
[01:22:20.560 --> 01:22:24.560]   I thought ridiculously, Gannett is charged in a lot of the various AGs along with other
[01:22:24.560 --> 01:22:30.000]   companies that Google is an antitrust advertising. And there are legitimate issues. Look at it.
[01:22:30.000 --> 01:22:37.040]   We talked about this in the show last week that where Google controls both the buy and sell side
[01:22:37.040 --> 01:22:44.880]   of advertising, then that has an impact. But as I thought about it, Gannett, I don't know where
[01:22:44.880 --> 01:22:50.560]   you guys have near you. I have a Gannett paper right near me. It's crap. It has been for years.
[01:22:50.560 --> 01:22:56.080]   Gannett is a monopolist. Gannett bought up nine news brands in New Jersey. Basically,
[01:22:56.080 --> 01:23:02.400]   everything they get their hands upon except advanced, my old employer, and cut the newsrooms and cut
[01:23:02.400 --> 01:23:08.800]   them to crap and act like a monopoly. And they're accusing Google to be a monopoly. To blame Google
[01:23:08.800 --> 01:23:14.080]   for their problems is disingenuous as hell because Gannett just didn't advance. They've been the
[01:23:14.080 --> 01:23:20.720]   one of the least innovative companies out there and least quality companies out there. And so,
[01:23:20.720 --> 01:23:26.400]   part of the problem with attacking Google, which I kind of get, we weren't attacking Google before.
[01:23:26.400 --> 01:23:31.200]   We were disappointed in Google. The problem is that as long as Google is one of the proprietors
[01:23:31.200 --> 01:23:36.000]   of the internet and people attack them, then that affects our internet and it just pisses me off.
[01:23:36.000 --> 01:23:40.560]   So full disclosure is that Google has contributed to the activities of the school. I don't get
[01:23:40.560 --> 01:23:48.640]   anything in person from Google. But Gannett, really? You're crap. Yeah, it was you.
[01:23:48.640 --> 01:23:54.160]   And there are other publishers who are kind of cheerleading on the side. Everybody wants
[01:23:54.160 --> 01:24:00.880]   something from someone. But yeah, I don't think you could imagine remedies. I mean,
[01:24:00.880 --> 01:24:05.280]   they're not after a remedy. I don't believe the amount of the lawsuit has been published.
[01:24:05.280 --> 01:24:19.120]   But imagine if, let's say, Google only had 50% share or 30% share, the status of Gannett would be
[01:24:19.120 --> 01:24:22.400]   exactly the same. They'd be the exact same price. Yeah, Google disappeared tomorrow.
[01:24:22.400 --> 01:24:24.560]   Right. They'd be just screwed up.
[01:24:24.560 --> 01:24:32.400]   Meanwhile, you also have other other protections legislation. So next week, a bill called the CJPA
[01:24:32.400 --> 01:24:37.600]   in California, the California Journalism Protection Act, which is like the JCP, which is the federal
[01:24:37.600 --> 01:24:42.320]   version, which these, as you say, Mike, these other big companies and these lobbyists keep
[01:24:42.320 --> 01:24:47.760]   trying to push through is trying to blackmail Google and Facebook to pay for the privilege of
[01:24:47.760 --> 01:24:52.880]   linking to their news. And acting as if news is so valuable to them when the truth is Facebook,
[01:24:52.880 --> 01:24:56.720]   which doesn't walk away from news, Google might walk away from news in Canada.
[01:24:56.720 --> 01:25:02.560]   It's the old protectionist, bad media industry, and I've kind of had it with them.
[01:25:02.560 --> 01:25:09.920]   I signed a letter last week to Congress about the JCP, a joining in a protest about it, because
[01:25:09.920 --> 01:25:12.960]   I've just had it with my old industry. I've just just had it.
[01:25:12.960 --> 01:25:22.000]   Yeah, it's trying to get the automobile industry to prop up the buggy whip industry.
[01:25:22.400 --> 01:25:28.960]   When that industry is kind of going to engage with companies that make buggy
[01:25:28.960 --> 01:25:36.240]   whips or not adapting to a new world in which people drive cars. And so the fact is, the only
[01:25:36.240 --> 01:25:43.600]   difference is, of course, that people find good publishing companies through Google search.
[01:25:43.600 --> 01:25:49.600]   That's the main role that they have is that they're driving, people can go in and just search for
[01:25:49.600 --> 01:25:54.160]   things and it's like, "Oh, here's a link to this article." And you're like, "Wow, I keep
[01:25:54.160 --> 01:25:59.200]   linking to the Washington Post or the Atlantic Monthly. I think I should subscribe because I'm
[01:25:59.200 --> 01:26:04.160]   always linking to these places." And so on. We know these dynamics. And we've seen this play
[01:26:04.160 --> 01:26:11.120]   out in other countries in Spain and elsewhere, where there have been these sort of misguided
[01:26:11.120 --> 01:26:18.000]   attempts to make Google pay to drive traffic to media sites. And it just seems kind of
[01:26:18.000 --> 01:26:30.880]   obviously bogus. That is not going to help media organizations evolve to meet the challenges
[01:26:30.880 --> 01:26:38.960]   that they face right now. And it's just looking for money. And I'm sure they'll get cheerleading
[01:26:38.960 --> 01:26:46.560]   from their shareholders, but it's just not anything that makes sense to me at all.
[01:26:46.560 --> 01:26:49.440]   And I suppose now-
[01:26:49.440 --> 01:26:55.680]   Did you watch these silly pixel videos or can we play video or we're going to get the problem?
[01:26:55.680 --> 01:27:05.280]   Yeah. I was watching, I did watch one of them and a little cringy, but I don't know. Do you think
[01:27:05.280 --> 01:27:09.760]   we probably could? I never know. These days, I just never know if we can play even in the
[01:27:09.760 --> 01:27:15.200]   advertising. So basically, we can probably act it out. So it's a Google phone, it's a pixel phone,
[01:27:15.200 --> 01:27:20.160]   and an iPhone talking to each other. And of course, the pixel phone is going to end up better off.
[01:27:20.160 --> 01:27:26.000]   There's like six of them and they're dorky. So in one, the iPhone runs out of battery.
[01:27:26.000 --> 01:27:32.480]   And another one, the iPhone runs out of battery. And Google phone lays down on top of it to
[01:27:32.480 --> 01:27:36.400]   charge the iPhone because it's one of those neat features. And the iPhone says,
[01:27:36.400 --> 01:27:39.200]   "What are you doing on top of me?" And says, "Well, I'm bringing you back to life."
[01:27:39.200 --> 01:27:42.480]   Oh, okay. Thanks. They're very weird.
[01:27:42.480 --> 01:27:47.920]   I mean, they're weird. They're silly. The one that I saw was the one where the iPhone runs out
[01:27:47.920 --> 01:27:57.120]   of battery. And they're each talking in their AI voice. So the iPhone has a Siri-like,
[01:27:57.120 --> 01:28:02.320]   I don't think it's actually a Siri voice talking, but it's very stilted and robotic.
[01:28:02.320 --> 01:28:06.640]   And the assistant voice and everything. And it's kind of like their puppets, right?
[01:28:06.640 --> 01:28:12.640]   They're kind of like shaking and talking to each other and everything. So it's cute on one hand.
[01:28:12.640 --> 01:28:16.000]   But I don't know. There was something about it that was like, "All right. All right. Cool."
[01:28:16.000 --> 01:28:21.200]   It's actually the one that I saw was a little bit longer than it really needed to be. It was like,
[01:28:21.200 --> 01:28:25.600]   "Seriously?" "Yes." "Cut this down to like a 30-second gag and maybe you've got something,
[01:28:25.600 --> 01:28:29.760]   but this thing's like a minute and a half. No one's going to watch this thing. So,
[01:28:30.320 --> 01:28:39.120]   I don't know. Hey, I did find it interesting though that Google is obviously firmly in the
[01:28:39.120 --> 01:28:46.640]   point fingers that Apple in public ways to prove it's good and Apple is not. And
[01:28:46.640 --> 01:28:50.640]   whether you agree with that or not, we're seeing that more and more from Google. It seems to be
[01:28:50.640 --> 01:28:57.360]   kind of their playbook. We saw it a lot with the RCS thing that continues to go on where Google
[01:28:57.360 --> 01:29:03.200]   keeps calling out Apple in different public places to say, "Hey, Apple." Almost like they're waiting
[01:29:03.200 --> 01:29:10.560]   for the throngs of people behind them to be like, "Hey, everybody. Let's pile on Apple. Everybody,
[01:29:10.560 --> 01:29:18.240]   come on. Everybody like, "Help me here." I just don't know that it's helping. I don't know that
[01:29:18.240 --> 01:29:23.200]   Apple will be swayed by the public pressure. It's like when Will Ferrell decided to go
[01:29:23.200 --> 01:29:26.960]   streaking and back to school and he thought he'd get everybody streaking down the street,
[01:29:26.960 --> 01:29:30.080]   but he was just making it by himself. That's exactly it.
[01:29:30.080 --> 01:29:41.040]   That whole campaign of Google pointing fingers at Apple about the second-class status of non-Apple,
[01:29:41.040 --> 01:29:48.720]   trying to get them to support RCS in messages, Apple messages, was so misguided. Apple has been
[01:29:48.720 --> 01:29:55.440]   for the last 10, 15 years in the perfect place to have the messaging platform.
[01:29:55.440 --> 01:30:01.680]   They could have the perfect cross-platform messaging platform. They could put it on
[01:30:01.680 --> 01:30:06.640]   into Android. They could have, but no, instead they totally fumbled that ball again and again
[01:30:06.640 --> 01:30:11.760]   with having all these different platforms. They would kill this one, but they still have a different
[01:30:11.760 --> 01:30:16.560]   version with the same name. I don't know how these work together and then they have RCS, but
[01:30:16.560 --> 01:30:22.880]   these phones have an RCS-based messaging platform, but these don't. Nobody knew what was going on.
[01:30:22.880 --> 01:30:29.600]   I said it earlier in the show, imagine if 10 years ago, Google said, "We're going to have
[01:30:29.600 --> 01:30:38.160]   one messaging platform." It supports RCS, it supports Apple users. There's a really great Apple app
[01:30:38.160 --> 01:30:45.680]   that connects directly. If you're an Apple user and you're tired of seeing people who are not
[01:30:45.680 --> 01:30:51.920]   Apple users show up in some second-class place, then you use our app instead of messages. They
[01:30:51.920 --> 01:30:57.920]   could have totally owned that market and they screwed up. It was only their failure that led
[01:30:57.920 --> 01:31:05.200]   to the situation they were complaining to Apple about about RCS. That's a perfect example of,
[01:31:05.200 --> 01:31:11.120]   reminds me of the Reddit thing, we have the CEO of Reddit blaming the mods when in fact he's failing
[01:31:11.120 --> 01:31:18.160]   to make the company profitable, to be innovative, to monetize artificial intelligence, data collection.
[01:31:18.160 --> 01:31:27.360]   I think the theme here so far is that, and the thing that Reddit and Google have in common is,
[01:31:27.360 --> 01:31:31.200]   where's the leadership? Where's the vision? You just don't have it.
[01:31:31.200 --> 01:31:35.840]   I don't know that the finger pointing is necessarily going to work.
[01:31:36.880 --> 01:31:45.840]   No, it's not. I guess the Mac versus PC thing was iconic for Apple back in the day.
[01:31:45.840 --> 01:31:57.120]   It's not like that hasn't worked before, but I don't know. I would love though. I was reminded
[01:31:57.120 --> 01:32:03.440]   of this even just a couple of days ago. My daughter was at a swim camp, and one of our
[01:32:04.560 --> 01:32:12.400]   friends mom was there to pick both of them up and saw my daughter swim race at the end of this
[01:32:12.400 --> 01:32:19.440]   four day long intensive swim camp. She recorded it with her iPhone, which I realized when she
[01:32:19.440 --> 01:32:25.200]   sent me the video via text message, and the video that I got was like the size of a stamp.
[01:32:25.200 --> 01:32:31.840]   When I blew it up, you could vaguely tell that there was a swimming pool in the image, but that
[01:32:31.840 --> 01:32:39.600]   was about the level of detail that you got. I can't believe we're still here, where how many years
[01:32:39.600 --> 01:32:45.280]   later I'm getting a video from an iPhone, and it looks less than garbage. It doesn't even look
[01:32:45.280 --> 01:32:53.600]   potato. It was blue. It was five large blue pixels. Was the entire content of the video.
[01:32:53.600 --> 01:33:00.080]   Jason, can I ask you a too soon question? Yeah, you can ask me anything.
[01:33:00.960 --> 01:33:03.680]   Are you going to stick with Android phones?
[01:33:03.680 --> 01:33:11.520]   I haven't even mentioned on this show yet that all about Android is done last night's episode
[01:33:11.520 --> 01:33:15.600]   was the last episode of the show. Am I going to stick with Android? Yeah, I'm going to stick
[01:33:15.600 --> 01:33:22.160]   with Android. I have no reason to bounce off of Android. Am I making an end to the end of life
[01:33:22.160 --> 01:33:29.760]   allegiance to Google on Android phones? No. I'm open to whatever I need to use at whatever point.
[01:33:29.760 --> 01:33:33.440]   But I'm not in a position right now where I'm like, "Okay, great."
[01:33:33.440 --> 01:33:38.240]   Android shows down. You're not saying, "Oh, I'm free at last to use an iPhone."
[01:33:38.240 --> 01:33:43.440]   No. I actually really love my Android phone. God. I know. I have continued to love my Android
[01:33:43.440 --> 01:33:48.320]   phones. Sure, there are things that annoy me about them from time to time, but there would be
[01:33:48.320 --> 01:33:54.160]   things that annoy me about iOS from time to time too. Yeah, not to mention my family,
[01:33:54.160 --> 01:34:00.960]   mostly is on Android. I guess my older daughter, she got her phone. She's 13 now.
[01:34:00.960 --> 01:34:05.600]   She gave her the ability to have a phone. I basically said, "I've got a drawer full of phones,
[01:34:05.600 --> 01:34:10.000]   babe. You can just pick one." And it's yours. And she's like, "Well, I want an iPhone."
[01:34:10.000 --> 01:34:14.640]   I was like, "Okay, well, I've got a free phone here. It's yours. If you want it,
[01:34:14.640 --> 01:34:18.560]   if you want an iPhone, you got to buy it." And she bought it. She saved up her money.
[01:34:18.560 --> 01:34:22.800]   Wow. She bought one and she hasn't. She's very happy. So I can't say we're an entirely
[01:34:22.800 --> 01:34:27.680]   Android household. She has an iPhone, but I gave her full props. That was like a
[01:34:27.680 --> 01:34:34.080]   shiv to the heart. My own daughter. I don't care. I don't take any of this personally. You
[01:34:34.080 --> 01:34:40.240]   know what I mean? It's a phone. My daughter got a Windows machine. My phone is on iPhone.
[01:34:40.240 --> 01:34:44.960]   It's just they don't talk very well to each other. And that's what really pisses me off.
[01:34:44.960 --> 01:34:52.640]   When she's texting with her friends and family, you're green, not blue on the iPhone.
[01:34:53.520 --> 01:35:00.400]   And messages, the iPhone people are blue and everybody else is green. So you're one of the
[01:35:00.400 --> 01:35:04.000]   second-class citizens in her messages.
[01:35:04.000 --> 01:35:09.760]   Well, yes. But I will say, Mike, we actually had a big conversation about this when she was
[01:35:09.760 --> 01:35:14.320]   wanting an iPhone. I remember having the conversation with her. We were driving somewhere.
[01:35:14.320 --> 01:35:17.680]   And I mentioned, are you familiar with the green bubble red bubble thing?
[01:35:17.680 --> 01:35:21.920]   Or sorry, green bubble, blue bubble thing. And she's like, "Yeah, I think I've heard a little
[01:35:21.920 --> 01:35:30.640]   bit about it." We had a talk about she's also very emotionally mature and very
[01:35:30.640 --> 01:35:36.640]   dialed into just being a kind person. He's a very kind person. And so we talked through these
[01:35:36.640 --> 01:35:45.200]   things and really I tried to imprint on her that it's silly to see someone's bubble come through
[01:35:45.200 --> 01:35:49.200]   as green and to think that they are anything less than you. And she's like, "Oh, God, why are you
[01:35:49.200 --> 01:35:54.000]   even telling me this? I know this. It's totally ridiculous." So maybe she's telling me what I wanted
[01:35:54.000 --> 01:36:01.760]   to hear. But I truly believe that if she was going to go down that road, hopefully have given her
[01:36:01.760 --> 01:36:06.320]   the tools to not suddenly be that kind of user.
[01:36:06.320 --> 01:36:07.200]   Because I think that--
[01:36:07.200 --> 01:36:12.560]   I also like that other fathers and daughters in the car have a talk about boys.
[01:36:12.560 --> 01:36:16.480]   You have a talk with your daughter about Android phones and iPhones.
[01:36:16.480 --> 01:36:20.560]   It's kind of perfect. Not the birds and the bees, but the blues and the greens.
[01:36:20.560 --> 01:36:28.800]   All of the above. It all gets in there somehow. It's part of having a kid, I suppose.
[01:36:28.800 --> 01:36:38.480]   But yeah, so that's that. All right, well, moving off from the blues and the greens.
[01:36:38.480 --> 01:36:42.480]   I love that. Dang, we have a couple of really great title ideas now.
[01:36:43.360 --> 01:36:47.520]   What else do we want to talk about here? Chromebook X, is this notable?
[01:36:47.520 --> 01:36:52.160]   So this is just that there evidently this is a report going out that they're going to
[01:36:52.160 --> 01:37:00.080]   mark high-level Chromebooks officially. So Chromebooks that can do the gaming,
[01:37:00.080 --> 01:37:03.600]   Chromebooks that can do other things. And so it's going to be--
[01:37:03.600 --> 01:37:07.520]   Brad, I wish it were a new Chromebook that we're producing no such luck.
[01:37:07.520 --> 01:37:08.400]   Yeah, I know.
[01:37:08.400 --> 01:37:11.040]   They're just going to separate out the quality here.
[01:37:11.040 --> 01:37:15.680]   Who knows? Maybe Google will have its own Chromebook X. The Pixel X--
[01:37:15.680 --> 01:37:19.120]   Don't-- Chromebook. That's cruel. That's cruel.
[01:37:19.120 --> 01:37:22.240]   Give them something to kill in a couple of years. Yeah, they do.
[01:37:22.240 --> 01:37:22.960]   Yes, exactly.
[01:37:22.960 --> 01:37:28.880]   Chromebooks. Chromebook X, well, it's probably a good thing. They're going to have a bunch of
[01:37:28.880 --> 01:37:37.120]   specs to aspire to for manufacturers. So a certain amount of RAM, a certain quality of camera,
[01:37:38.000 --> 01:37:43.280]   it's going to be optimized. They're kind of guaranteeing that it'll be good for video calls,
[01:37:43.280 --> 01:37:49.200]   Zoom calls, et cetera. And a minimum processor configurations.
[01:37:49.200 --> 01:37:57.360]   So it's a new standard that hardware manufacturers will have to get to if they want to charge the
[01:37:57.360 --> 01:38:01.440]   higher price to the Chromebook X. I think it's in general, it's a good idea.
[01:38:01.440 --> 01:38:05.200]   Right now it's more nebulous. There are high-end Chromebooks, low-end Chromebooks.
[01:38:05.920 --> 01:38:16.240]   And now there's an actual material tier that consumers can rely on to provide a certain
[01:38:16.240 --> 01:38:21.200]   degree of quality and that manufacturers can aspire to sell on the higher echelon.
[01:38:21.200 --> 01:38:23.280]   So I think it's probably a good thing.
[01:38:23.280 --> 01:38:29.200]   Micro-book, my Pixelbook is one by one, it's falling apart. The microphone doesn't work anymore.
[01:38:29.200 --> 01:38:33.520]   The touchscreen doesn't just suddenly stop working. So I'm going to have to make the decision.
[01:38:33.520 --> 01:38:38.880]   Right now it's that expensive HP, but it's going to be my luck that I'll go ahead and buy it.
[01:38:38.880 --> 01:38:43.600]   And then one month later there'll be some amazing machine Chromebook X and I won't be able to get it.
[01:38:43.600 --> 01:38:48.480]   That's how the world works. So this is the original Pixelbook 2017.
[01:38:48.480 --> 01:38:52.240]   If you're not six years out of that, do you feel like?
[01:38:52.240 --> 01:38:56.240]   It's a Pixelbook Go. Oh, the Pixelbook. So a little bit later.
[01:38:56.240 --> 01:39:01.440]   A little later. I don't think it's going to last that long with me. I'm not cruel.
[01:39:01.440 --> 01:39:06.960]   2019. The keyboard is like Stacey. But dang, so it's disintegrating after four,
[01:39:06.960 --> 01:39:13.280]   not even four years. Oh, yeah? Yeah. That's disappointing. That is disappointing.
[01:39:13.280 --> 01:39:19.680]   Yeah. That's not long enough for, not even long enough for a phone, let alone a laptop.
[01:39:19.680 --> 01:39:23.600]   No. So maybe just as well, I leave Google hardware, but...
[01:39:23.600 --> 01:39:28.960]   I mean, the original Pixelbook, I have to say, that was a fantastic machine.
[01:39:28.960 --> 01:39:32.240]   Oh, I always loved working on that computer.
[01:39:32.240 --> 01:39:41.680]   And I think my experience with that opened me up to the understanding that a higher-end
[01:39:41.680 --> 01:39:47.360]   Chromebook deserves to exist because that was a really wonderful, long-lasting,
[01:39:47.360 --> 01:39:54.960]   performance Chromebook. Yes, it's a browser computer, but still it felt premium and it was
[01:39:54.960 --> 01:40:01.120]   enjoyable to use for that reason. Sure, it's not for everybody, but if you want to buy a high
[01:40:01.120 --> 01:40:07.680]   spec, probably more expensive Chromebook X computer, you should be able to dang it.
[01:40:07.680 --> 01:40:11.440]   And so... I'll suffer the abuse of people who say you're spending that much for a Chromebook,
[01:40:11.440 --> 01:40:16.960]   a lot of browser. I've got a browser on my phone. I got to say that I don't know if
[01:40:18.320 --> 01:40:26.320]   you guys have talked about a company's siteful and its space-top device on this show or other
[01:40:26.320 --> 01:40:31.840]   shows on the Twitter network. Siteful is a... But this is a direction I'd love to see
[01:40:31.840 --> 01:40:37.600]   Google go in with Chromebook. So siteful is in its really startup that used to be called
[01:40:37.600 --> 01:40:44.320]   Multinarity. And they recently released, I don't know, 1000 units, it's kind of like a beta program
[01:40:44.320 --> 01:40:49.520]   type thing of a device called a space-top, what they call an AR laptop. So basically what this
[01:40:49.520 --> 01:40:55.680]   thing is, it's a device about the size of a laptop, but instead of a screen, it has augmented
[01:40:55.680 --> 01:41:04.320]   reality glasses that I believe are tethered. And so it's unlike Apple's AR product,
[01:41:04.320 --> 01:41:11.840]   this doesn't do all the things. It just gives you a virtual screen and a big one, like 100 inch
[01:41:11.840 --> 01:41:17.120]   screen floating in space in front of you. And then you run the apps, it has a kind of a
[01:41:17.120 --> 01:41:27.040]   customized operating system, but the operating system works like a Chromebook. So they're all
[01:41:27.040 --> 01:41:36.800]   cloud apps. It doesn't run Windows or any sort of desktop operating system. It's own
[01:41:36.800 --> 01:41:40.720]   operating system around cloud apps. So you can run Gmail, all those kinds of things.
[01:41:41.600 --> 01:41:45.840]   I would love to see Google get into this because it's a really great idea. Now the way that they've
[01:41:45.840 --> 01:41:51.920]   done the space top is very clever. It actually has a port for plugging in a physical display,
[01:41:51.920 --> 01:41:57.840]   but it doesn't come with a physical display, just the glasses. So you can use it as a regular
[01:41:57.840 --> 01:42:03.040]   device in your home office or in your workplace. And then you can pick it up and you can go to
[01:42:03.040 --> 01:42:09.120]   Starbucks and you can use the goggles and you have 100 inch screen in this tiny little box.
[01:42:09.120 --> 01:42:14.640]   What's the input device? Is there a keyboard? It's a keyboard, keyboard mouse, all that stuff.
[01:42:14.640 --> 01:42:20.240]   Yeah. So it's like the bottom, the bottom half is like a regular laptop. It has ports like a
[01:42:20.240 --> 01:42:25.440]   regular laptop for peripheral devices. It uses Bluetooth like a regular laptop. It connects a
[01:42:25.440 --> 01:42:31.680]   Wi-Fi like a regular laptop. The difference is the default mode is you put on AR goggles and you
[01:42:31.680 --> 01:42:37.920]   have this giant screen in front of you. And so this would be a great direction for Google.
[01:42:37.920 --> 01:42:42.320]   Google should have launched this product and they launched this before Apple launched the Vision
[01:42:42.320 --> 01:42:51.920]   Pro. And of course the Vision Pro has the feature of showing you your macOS applications floating in
[01:42:51.920 --> 01:42:59.760]   space. But it also does all these other things as well that are more high and more 3D kind of
[01:43:01.200 --> 01:43:08.400]   magically type stuff. But I love the idea of a cloud-based device like a Chromebook that has
[01:43:08.400 --> 01:43:15.760]   it's like a virtual laptop with a virtual screen. It's just very efficient, I think,
[01:43:15.760 --> 01:43:21.840]   in terms of processor power, in terms of the low cost you could have, in terms of the educational
[01:43:21.840 --> 01:43:26.400]   capabilities of having this virtual screen. We're entering into an era of augmented reality.
[01:43:27.200 --> 01:43:31.520]   And I would love to see Chromebook go in that direction. Wouldn't that be amazing?
[01:43:31.520 --> 01:43:41.760]   Well, how high, I think, technology like this is dependent on the screens that you're looking at
[01:43:41.760 --> 01:43:49.600]   being high-res enough that text that you're probably looking a lot at isn't going to fall apart.
[01:43:49.600 --> 01:43:55.520]   Do you happen to know? The demos seem to make it seem like it's not a big deal, but
[01:43:56.400 --> 01:44:00.400]   that it's sufficient as far as that's concerned. But I wonder how that actually looks.
[01:44:00.400 --> 01:44:08.640]   None of the AR units are as high-def as the Vision Pro that Apple announced, but they're also
[01:44:08.640 --> 01:44:17.520]   not $3,500. And so they're selling these for $2,000 each. And they're probably low,
[01:44:17.520 --> 01:44:24.560]   much lower-res than the Vision Pro. But people who have tried it in person say that it's good
[01:44:24.560 --> 01:44:27.840]   enough, and you can read text on it, and you can do all those kinds of things.
[01:44:27.840 --> 01:44:36.640]   And the hands-on reviews have been fairly positive. The biggest problem with this is this
[01:44:36.640 --> 01:44:42.560]   kind of a low-power device. It is battery-operated, but the battery life is very low, like, I don't
[01:44:42.560 --> 01:44:50.480]   know, just a few of ours. That kind of thing. But I really believe in this idea of having a virtual
[01:44:50.480 --> 01:44:57.440]   screen with an optional physical screen. And I think it's ideal for Google. But again,
[01:44:57.440 --> 01:45:02.560]   they're often the weeds on the stuff. And this was done by this tiny Israeli startup as the
[01:45:02.560 --> 01:45:05.840]   first mover. And it should have been Google, I think.
[01:45:05.840 --> 01:45:16.960]   Yeah. If only they had, you know, whatever, capitalized on their early, early to market with
[01:45:16.960 --> 01:45:23.680]   a Google Glass. And taking that somewhere. I mean, they were obviously too early.
[01:45:23.680 --> 01:45:30.560]   But they were there first, I would say. They were the major player that was there first. So that
[01:45:30.560 --> 01:45:34.720]   definitely accounts for something. And now we're starting to kind of see the fruits of that
[01:45:34.720 --> 01:45:42.720]   happen now. I think it's still kind of, though, at least in my mind, it still needs to prove
[01:45:42.720 --> 01:45:48.800]   itself. Like, even once the Apple vision pro comes out, you know, I still am not entirely
[01:45:48.800 --> 01:45:53.120]   convinced that that's how I want to compute all the time. You know what I mean? Like, I don't
[01:45:53.120 --> 01:45:57.600]   know that I want to be an advisor. But maybe that's because I haven't done it. Like, maybe it would
[01:45:57.600 --> 01:46:04.240]   be great. Certainly find out $2,000 for that early access. That's interesting.
[01:46:04.240 --> 01:46:08.880]   Yeah, it very well could be great. But the big difference is that, you know, the problem of
[01:46:08.880 --> 01:46:13.920]   Google Glass, to a certain extent, was that it wasn't, it was augmented reality, but it wasn't.
[01:46:13.920 --> 01:46:20.080]   It was a heads up display. If you move your head, the screen moves, right? Whereas with the,
[01:46:20.080 --> 01:46:25.120]   with both Apple's product and this insightful product, I've been talking about, the screen
[01:46:25.120 --> 01:46:29.760]   stays put. And you move your head, you look at different parts of the screen. That's the kind of
[01:46:29.760 --> 01:46:36.960]   AR for general computing that makes a lot of sense. And the beauty of this concept is that,
[01:46:37.520 --> 01:46:45.920]   you know, HoloLens, Microsoft HoloLens and Magic Leap spent so much time figuring out how to
[01:46:45.920 --> 01:46:54.960]   anchor virtual objects in 3D physical real space. They demonstrated characters, not only standing
[01:46:54.960 --> 01:47:00.080]   on the table, but hiding behind the table. You have to map a 3D environment. Apple's Vision Pro
[01:47:00.080 --> 01:47:06.480]   maps the 3D environment. This product dispenses with all the need for all that technology.
[01:47:06.480 --> 01:47:12.720]   And it has its anchoring point as exclusively being the laptop itself. So they have built in
[01:47:12.720 --> 01:47:18.560]   hardware that needs the screen to anchor there. And they don't have to map your 3D space. There's
[01:47:18.560 --> 01:47:23.520]   no mapping. It's just something that floats in space over the laptop. You can move it forward
[01:47:23.520 --> 01:47:28.400]   back and stuff like that. But it's all based on where the laptop physically is because they
[01:47:28.400 --> 01:47:35.120]   have some technology that tells the virtual space to sort of center itself over the laptop.
[01:47:35.120 --> 01:47:40.720]   And so, you know, I love the efficiency of that. It's a new idea. And it's not going to go anywhere
[01:47:40.720 --> 01:47:45.040]   unfortunately because it's a tiny little Israeli company. But I think, you know,
[01:47:45.040 --> 01:47:51.920]   I think Google should buy them immediately if they're not within a year of launching a product
[01:47:51.920 --> 01:47:56.880]   like that of their own based on the Chromebook operating system. So I just would love to see
[01:47:56.880 --> 01:48:02.640]   the Vision Pro have a lower cost, browser-based competitor.
[01:48:02.640 --> 01:48:07.200]   Who knows, Jeff, your next pixel book could be a pixel blast.
[01:48:07.200 --> 01:48:08.640]   No, no, I've been there.
[01:48:08.640 --> 01:48:16.320]   Fool me once. Never, never, no. Don't say never.
[01:48:16.320 --> 01:48:23.920]   Well, okay. So, I mean, only because we're talking sort of AR/VR, but there's the news that
[01:48:23.920 --> 01:48:32.640]   meta lowered the age requirement for its Quest VR headsets. So now kids age 10 to 12 will be able
[01:48:32.640 --> 01:48:39.440]   to use this, use the device because they were already. They were just using it through an account
[01:48:39.440 --> 01:48:41.680]   that their parents set up. I can speak from experience.
[01:48:41.680 --> 01:48:45.920]   As a parent, Jason, how do you feel about that? You feel that it's too young?
[01:48:45.920 --> 01:48:53.200]   I mean, if I said yes, then I'd be a total hypocrite because my youngest daughter is 10
[01:48:53.200 --> 01:49:00.240]   and she loves playing in VR. I don't let her, she doesn't get a ton of time in VR, but yeah,
[01:49:00.240 --> 01:49:06.400]   absolutely. And she started when she was 9. I mean, it's a screen. It's a screen. Yeah, totally.
[01:49:06.400 --> 01:49:13.120]   You know, but it's been really interesting to watch her interaction with VR and how naturally,
[01:49:13.120 --> 01:49:17.520]   I guess VR in a sense is supposed to come, if they're doing it right, it comes naturally
[01:49:17.520 --> 01:49:25.440]   regardless. But there's a vacation simulator and job simulator. And one of the joys of my life
[01:49:25.440 --> 01:49:32.960]   has been watching her in the living room in like job simulator in the convenience store.
[01:49:32.960 --> 01:49:40.080]   Because she's like, she's there. And so you're just, I'm watching her in the middle of my living
[01:49:40.080 --> 01:49:43.760]   room. And to her, she's like, I'm just going to go, Oh, hot dogs done.
[01:49:46.400 --> 01:49:51.360]   Okay, yes, one second, sir. You know, it's like, it's like she's playing with so, I don't know,
[01:49:51.360 --> 01:49:58.720]   I can't explain it. It's just, it's so fun to watch her go into VR. So do I think that it's too low?
[01:49:58.720 --> 01:50:03.120]   No, I don't. I mean, at the end of the day, how do the parents feel, you know, the parent,
[01:50:03.120 --> 01:50:09.360]   the age requirement does stipulate that the kids will need permission from their parents to use
[01:50:09.360 --> 01:50:15.200]   the headset. I'm not entirely sure how that's done. Does that tie into my meta account? And then I
[01:50:15.200 --> 01:50:20.960]   grant access, probably so something along those lines. But that makes sense to me,
[01:50:20.960 --> 01:50:27.840]   unless there's some sort of like health reason, you know, reason that a kid that's 11 or 10 years
[01:50:27.840 --> 01:50:32.880]   old should not use it because their eyes are developing. And I feel like I've heard mixed
[01:50:32.880 --> 01:50:38.080]   reports as far as that's concerned. I don't really know exactly what the, what the actual answer is
[01:50:38.080 --> 01:50:44.720]   there. And also it's a, it's a benefit that the platform that Meta has developed is not very
[01:50:44.720 --> 01:50:51.040]   compelling, to which I mean, is not particularly addictive yet. If they were really successful,
[01:50:51.040 --> 01:50:55.600]   that they would have worlds that you just have to live in all the time, in which case,
[01:50:55.600 --> 01:51:01.280]   very, very unhealthy for 10 year olds to be hours and hours and hours inside a world. And in fact,
[01:51:01.280 --> 01:51:06.160]   you know, social networks itself, Facebook itself, I believe the age limit is still 13.
[01:51:06.160 --> 01:51:12.880]   I'm a little creeped out by the idea of, you know, here's a company that's desperate for users. And
[01:51:12.880 --> 01:51:17.600]   so like, I know we'll go after younger kids. And I hope that's not a trend where all these things
[01:51:17.600 --> 01:51:22.960]   are for teenagers and older, they're like, well, let's go below the teenage years and we'll just
[01:51:22.960 --> 01:51:28.640]   add a million people to the roster. Yeah. Well, yeah, I don't, I don't know their reason for doing it.
[01:51:28.640 --> 01:51:33.760]   What I do know is that I'm not alone. I have friends who also have kids who are definitely in
[01:51:33.760 --> 01:51:40.560]   this age bracket, and they're using VR. So the kids are already using VR. So then it's like,
[01:51:40.560 --> 01:51:45.120]   okay, so then is meta, you know, I don't know what their intention is necessarily. I would
[01:51:45.120 --> 01:51:49.120]   agree with you if that's their intention, the hook them early, and then, you know, they're,
[01:51:49.120 --> 01:51:53.120]   they're addicted for life sort of thing. Like, I don't like that. That gives me an icky feeling.
[01:51:53.120 --> 01:51:54.080]   But again,
[01:51:54.080 --> 01:51:55.280]   Ronald McDonald model,
[01:51:55.280 --> 01:52:02.800]   you know, my kid was already doing VR. So if there's maybe a more official way,
[01:52:02.800 --> 01:52:07.280]   but I mean, at the same time, as I say this, and I think about it, like, it might just be easier
[01:52:07.280 --> 01:52:11.840]   for me to still do what I'm doing. Cause like, I don't care if she logs in under my account.
[01:52:11.840 --> 01:52:17.360]   She's not, she's not managing an account that has any sort of longevity of her data or anything.
[01:52:17.360 --> 01:52:20.800]   She's just literally putting on the headset and going, I want to play that game. And she plays
[01:52:20.800 --> 01:52:25.600]   it for half an hour. And then she's done. And that's what that seems to me way easier than creating
[01:52:25.600 --> 01:52:30.480]   an account, worrying about the data transfer and what, you know, what are they logging and what
[01:52:30.480 --> 01:52:34.960]   are they not logging and everything just plays me, you know. And it's also, she's, she's working
[01:52:34.960 --> 01:52:40.720]   in the quickie march. She's not, she's not a play acting being like a Barbie doll in some kind of
[01:52:40.720 --> 01:52:45.280]   glamour world or superficial like, you know, Hollywood like, you know, culture or whatever.
[01:52:45.280 --> 01:52:51.440]   So that's that that, you know, the content is everything. Yeah, I think. Yeah. Yeah.
[01:52:51.440 --> 01:52:57.520]   Well, there is the, what is the game rec room that's like Roblox, but in VR, I don't know,
[01:52:57.520 --> 01:53:02.800]   either of you has had a chance to play that, but that's, that's a super interesting kind of
[01:53:02.800 --> 01:53:10.640]   social thing. That's where I think being too young, you know, in air quotes becomes kind of a sticky
[01:53:10.640 --> 01:53:17.280]   situation because this is like a full on social network in the sense that, you know, I am standing
[01:53:17.280 --> 01:53:24.400]   in a room filled with 10 to 15 other kids who are on their headsets. And some of them, you know,
[01:53:24.400 --> 01:53:29.840]   are saying stuff they probably should not be saying. And you like, what are the controls around
[01:53:29.840 --> 01:53:34.240]   that? And of course you can go into rec room and you can set these controls that I as a parent can
[01:53:34.240 --> 01:53:39.120]   can set it and say, no, Mike access, no, you know, you're not going to hear anyone else,
[01:53:39.120 --> 01:53:43.520]   you're just going to be able to gesture to them and everything. But there is a whole other dynamic
[01:53:43.520 --> 01:53:49.520]   there of like, this, this perception of personal safety and protecting them from, yes, from those
[01:53:49.520 --> 01:53:54.720]   things that can be challenged. This is the, this is the issue with any avatar based thing, which of
[01:53:54.720 --> 01:54:01.520]   course, any VR, AR social thing, whether it's a conference call or a virtual world or, you know,
[01:54:01.520 --> 01:54:08.240]   virtual version of Second Life or whatever. And that's why, you know, I'd been predicting
[01:54:08.240 --> 01:54:15.440]   at computer world since 2017, based on patents, it wasn't that hard to predict that apples,
[01:54:15.440 --> 01:54:22.960]   goggles would have biometric security, either face scans or Irish scans, they won't with Irish
[01:54:22.960 --> 01:54:30.080]   scans. But it's very, very important to know who like, you know, to buy to biometrically identify
[01:54:30.080 --> 01:54:37.840]   the person, because what you don't want is a hangout place for 10, 11, 12, 13 year olds,
[01:54:37.840 --> 01:54:45.760]   where one of the teenagers is a, you know, actually 45 year old, actually not 10, 11, 12, 13. Yeah,
[01:54:45.760 --> 01:54:53.120]   totally, totally. So we have to, we have to figure out, and Apple is going to control that because
[01:54:53.120 --> 01:54:58.640]   they're a very controlling company. But I worry about a future when everyone is an avatar and you
[01:54:58.640 --> 01:55:05.040]   don't know who that is. And, you know, you have these compelling addictive worlds where people
[01:55:05.040 --> 01:55:08.560]   are not who they say they are. And I don't know, it's, it's, it's one of the things we're going to
[01:55:08.560 --> 01:55:15.120]   have to solve for sure. Yeah. And it's one thing to be playing a game and have to think about that,
[01:55:15.120 --> 01:55:20.000]   like, you know, I'm thinking of, there's a lot of kids that have a, have a PlayStation, have an
[01:55:20.000 --> 01:55:25.280]   Xbox and are connected to other, other players and can talk to them and everything like that. So
[01:55:25.280 --> 01:55:30.640]   it's a similar, similar challenge there. It's an entirely different story though, when you are
[01:55:30.640 --> 01:55:36.400]   locked in a virtual environment and you're facing those things, it feels a lot more immediate,
[01:55:36.400 --> 01:55:45.360]   it feels more personal, it has, it has the potential to have an actual kind of impact on, on you, on
[01:55:45.360 --> 01:55:48.400]   it, on it, I believe a deeper level. Because it's like,
[01:55:48.400 --> 01:55:54.000]   I mean, you're, you're, anybody, right, even even console video games, you play Call of Duty and
[01:55:54.000 --> 01:56:00.880]   Paul Therat can tell us about this. Those really, your brain is certain that those are real places.
[01:56:02.000 --> 01:56:10.320]   You remember being in a place and that place was a simulated world and VR is way stronger than that.
[01:56:10.320 --> 01:56:16.160]   So these are, these are psychologically, these are real places that have a big impact on you. So
[01:56:16.160 --> 01:56:23.840]   we're going to be really dependent on the content creators for augmented reality to provide us
[01:56:23.840 --> 01:56:30.160]   spaces that are, you know, healthy places for us, for our minds to be. Indeed, controllable, safe,
[01:56:30.160 --> 01:56:41.920]   yeah, all that. 100%. How about the EU making user replaceable batteries mandatory in 2027 when
[01:56:41.920 --> 01:56:48.320]   I read this, I had to pull out my motorway of droid. Let's see if I can pop the back off of here,
[01:56:48.320 --> 01:56:52.400]   because if you remember back in the day, you know, swapping out your battery used to be
[01:56:52.400 --> 01:56:56.880]   used to carry them with me. Yes, exactly. Did you have the droid? Jeff?
[01:56:57.600 --> 01:57:01.120]   No, I didn't have that one. Okay. I had different ones that had batteries out.
[01:57:01.120 --> 01:57:06.080]   No, my trio for God's sakes. Yeah. Well, I mean, so many phones, it used to be the case where you
[01:57:06.080 --> 01:57:12.000]   could swap out the battery. And yes, I had like two or three of these that, you know, out of necessity.
[01:57:12.000 --> 01:57:16.320]   I'm not sure why you would give a couple hours. Yeah. Why are they concentrated on this now?
[01:57:16.320 --> 01:57:22.800]   Number one, batteries last longer in a day, the last longer period. They're smaller and designed
[01:57:22.800 --> 01:57:29.040]   into smaller units in ways that make them smaller. It just seems like it's a five-year-old battle
[01:57:29.040 --> 01:57:33.360]   that they've suddenly woken up to. Yeah, that is a good question. I have no idea why they're
[01:57:33.360 --> 01:57:41.120]   suddenly gluing into it now. Other than it seems like the EU recognizes chum in the water when it
[01:57:41.120 --> 01:57:48.880]   comes to big tech and pushing through a heck of a lot of requirements and stuff. And this is just
[01:57:48.880 --> 01:57:55.200]   yet another one, which now I can't I can't speak to the specific reason for this, but I can
[01:57:55.200 --> 01:58:05.440]   speak to the general idea that the EU is almost as prone to lobbying and so on as the US government.
[01:58:05.440 --> 01:58:12.160]   So whenever there's this big push against Google or big push against whomever, it's usually the
[01:58:12.160 --> 01:58:18.480]   competitors of the target that are pushing the EU to go after that target. So in this case,
[01:58:19.360 --> 01:58:26.880]   you know, this would be a disaster for Apple, especially. They would be less willing to
[01:58:26.880 --> 01:58:33.360]   have replaceable batteries. And so it could be Google behind this, could be any number of
[01:58:33.360 --> 01:58:42.160]   companies, but it's usually lobbying. The EU is a great place for that kind of lobbying because
[01:58:42.160 --> 01:58:48.960]   they don't have a kind of computer science mindset when it comes to government action. They just think,
[01:58:48.960 --> 01:58:56.320]   well, it's the government's job in society to set all the rules that and they they diminish the
[01:58:56.320 --> 01:59:03.200]   role of norms. They diminish the role of private organizations. They diminish the role of consumer
[01:59:03.200 --> 01:59:08.320]   action and consumer choice. And they just say, well, cell phones should have batteries,
[01:59:08.320 --> 01:59:14.080]   so we're just going to create a law around that. That's how they think. It's a political culture
[01:59:14.080 --> 01:59:23.040]   that is very extreme in Europe and doesn't really exist in a lot of places to the extent that exists
[01:59:23.040 --> 01:59:28.960]   in Europe. It's unfortunate because the EU is such a huge market and they have some, you know,
[01:59:28.960 --> 01:59:33.760]   they're deciding, oh, you have to have a USBC cable and you have to have replaceable batteries,
[01:59:33.760 --> 01:59:39.840]   you have to have this. And they're designing products that are evolving quickly and they
[01:59:39.840 --> 01:59:46.000]   they're taking choice out of the hands of consumers. If I don't want a phone that doesn't have a
[01:59:46.000 --> 01:59:51.360]   replaceable battery, then I won't buy one. Right? That's, you know, my sensibility as an American
[01:59:51.360 --> 01:59:56.960]   is that that's how it should work. Right? And, but, you know, that's how they are, but they have so
[01:59:56.960 --> 02:00:04.640]   much power and so much weight and they are so unaccountable to European citizens that there we
[02:00:04.640 --> 02:00:09.840]   are. They just, they decide that they're going to, they're going to be designing consumer electronics
[02:00:09.840 --> 02:00:17.280]   products. Man, imagine what that requirement would do for a company like Apple. I mean, that is a,
[02:00:17.280 --> 02:00:23.120]   that's not just a small change. That's not even a large change. That is like a change of epic
[02:00:23.120 --> 02:00:26.800]   proportions when it comes to Apple and its hardware. That would change everything.
[02:00:26.800 --> 02:00:30.560]   Yep. Yeah. Yeah. That's interesting.
[02:00:30.560 --> 02:00:36.240]   Is there anything in here? I'll kind of leave it to the two of you to decide there's so many
[02:00:36.240 --> 02:00:40.320]   stories in here. We're never going to get to all of them. We obviously have the change log at some
[02:00:40.320 --> 02:00:44.960]   point here pretty soon. But is there anything in here that is like that you're burning to talk
[02:00:44.960 --> 02:00:51.680]   about that I haven't brought up yet? Doesn't happen to me.
[02:00:51.680 --> 02:00:57.840]   You've been doing a good job, boss. Doesn't happen to her. I like the way you subtly told
[02:00:57.840 --> 02:01:01.520]   your engineer there to queue up the Google change log music. But,
[02:01:01.520 --> 02:01:10.400]   I'm always producing, even when I'm hosting, I'm producing it like, all right. So I got five
[02:01:10.400 --> 02:01:15.200]   minutes until the Google change log. I got 20 minutes until, you know, oh, I got one. Yeah.
[02:01:15.200 --> 02:01:20.160]   I got one. Yep. Yeah. What's up? That's a quiz for your staff here. One member of the staff has
[02:01:20.160 --> 02:01:26.880]   already said that that he does not follow this rule. Line 81. Do software engineers wash their
[02:01:26.880 --> 02:01:34.080]   underwear? Oh, Guardian did a trend story where those ridiculous trend stories of people who are
[02:01:34.080 --> 02:01:40.160]   deciding not to wash their underwear for a week. And of who is the lead of the story? Of course,
[02:01:40.400 --> 02:01:47.840]   it's a software engineer. What? Wait a minute. Who doesn't wash their underpants for a week?
[02:01:47.840 --> 02:01:52.560]   Well, I know. Mike, you haven't you haven't weighed in here yet, Mike?
[02:01:52.560 --> 02:01:59.040]   Well, I can answer the question you asked people who don't wash their underwear or single people.
[02:01:59.040 --> 02:02:07.120]   This guy, this guy has a wife and kids. He doesn't wash his underwear. We'll see. We'll see how long
[02:02:07.120 --> 02:02:13.760]   that lasts. Yeah, I don't know. I don't know. There's a lot of there are a lot of trends around these
[02:02:13.760 --> 02:02:20.400]   things. There was a trend a few years ago about people not using soap. Yeah. Just rinsing off and
[02:02:20.400 --> 02:02:27.040]   all that kind of stuff. I don't know. There's also all these products out there from workout
[02:02:27.040 --> 02:02:31.440]   clothes and especially underwear that have like, I don't know, silver threads or something like that.
[02:02:31.440 --> 02:02:36.880]   They're designed to be worn over and over again. There's a whole movement of people. I'm sure
[02:02:36.880 --> 02:02:43.360]   there's a subreddit about it of people who don't wash their their their blue jeans for weeks or
[02:02:43.360 --> 02:02:48.000]   months. Yeah, that's right. I've heard that forever. Right. You don't need to wash blue jeans. They
[02:02:48.000 --> 02:02:53.600]   get better with age and whether or not washed. Never. But I don't think that a reputation for
[02:02:53.600 --> 02:02:57.120]   not washing underwear is going to help the reputation of engineers. That's all I'm saying. No, I don't
[02:02:57.120 --> 02:03:03.840]   think so. Yeah. So this is a show for geeks, which guys guys wash your your undies. Okay. Yes.
[02:03:03.840 --> 02:03:08.800]   Guys and gals. Just tell whoever you are. You're not watching. I got no women or two cents
[02:03:08.800 --> 02:03:16.800]   will do this. Let's just let's be real here. Yeah. We're probably talking mostly to the guys.
[02:03:16.800 --> 02:03:20.000]   Well, that's not the story I thought you were going to throw out there.
[02:03:20.000 --> 02:03:33.600]   What about let's see here the. Yes. There's a story about the flight of scientists from
[02:03:33.600 --> 02:03:38.480]   Twitter, which again, this is this is the ongoing and certification of social that
[02:03:38.480 --> 02:03:46.480]   that we talked about on this show on Twitter, etc. But yeah, there there there's less and a lot
[02:03:46.480 --> 02:03:53.360]   of a lot of scientists are actually going to the Fedivers. That's one contingent that is really
[02:03:53.360 --> 02:03:58.960]   doing that. But it's really unfortunate. It's going to damage Twitter in some subtle and
[02:03:58.960 --> 02:04:05.600]   already on fatal way, right? Peter Hotez is a brilliant, brilliant scientist who designs vaccines
[02:04:05.600 --> 02:04:13.440]   for people who are poor. He doesn't go through big pharma and Joe Rogan and Elon Musk and their
[02:04:13.440 --> 02:04:19.120]   boys went after Hotez and it's just shameless. It's just shameful. Yeah. It's awful. I stand with
[02:04:19.120 --> 02:04:23.600]   Peter Hotez. He's brilliant. He's one of the most helpful in the whole pandemic. When I started my
[02:04:23.600 --> 02:04:29.280]   pandemic Twitter list, Hotez was just one of the most generous with advice and with information
[02:04:29.280 --> 02:04:39.360]   and education and and schmuck, musk and schmuck Rogan. Go below. Yeah, it's really a shame. And
[02:04:39.360 --> 02:04:44.080]   one of the things that and since we're talking about what a schmuck Elon Musk is, one of the
[02:04:44.080 --> 02:04:52.240]   things that's really disappointing. I follow a subreddit called enough musk spam. I think it's called
[02:04:53.440 --> 02:05:00.240]   Musk. But it's basically just it's finding these little things that Elon Musk does related to Twitter
[02:05:00.240 --> 02:05:05.120]   and it kind of exposes them because we, you know, it's all much of what he does is kind of lost in
[02:05:05.120 --> 02:05:15.040]   the soup. But he does this thing that is just so awful where he'll comment on a blatantly racist,
[02:05:16.240 --> 02:05:27.920]   homophobic, transphobic or anti-Semitic tweet. And he won't support it so much as go, huh?
[02:05:27.920 --> 02:05:32.880]   Some of those things makes this outrageous claim about, you know, Fauci is conspiring with
[02:05:32.880 --> 02:05:40.320]   I don't know, the Martians to like, you know, sort of set up these prison camps or, you know,
[02:05:40.320 --> 02:05:45.440]   whatever it is. And he just, he's like, huh, like as if he's saying, that's interesting. That's
[02:05:45.440 --> 02:05:50.320]   an interesting or even using that emoji, you know, that emoji where they're like, yeah, you know,
[02:05:50.320 --> 02:05:55.760]   that that's the entirety of it. Not not coming out with a statement in support or against or whatever,
[02:05:55.760 --> 02:06:02.320]   but just like, hmm, we should all think about this at least. Yeah, exactly. It's like, and it's,
[02:06:02.320 --> 02:06:07.840]   I don't think and then when people get apoplectic about it, he says, well, there's, you know,
[02:06:07.840 --> 02:06:11.920]   it's free speech. I can do what I want. It's like, I didn't say, you know, I didn't, I didn't support
[02:06:11.920 --> 02:06:18.160]   it. I didn't do this to that. Why do it? He's changed Twitter's algorithm so that he gets
[02:06:18.160 --> 02:06:26.480]   all the attention that everything he tweets is the highest ranking, highest, you know,
[02:06:26.480 --> 02:06:33.200]   most algorithmically boosted stuff that's on Twitter. And then he uses it for that
[02:06:34.000 --> 02:06:42.240]   just to troll people with this non-committal highlighting of really oftentimes really ugly
[02:06:42.240 --> 02:06:47.680]   and objectionable tweets that other people that normally most of us Twitter users would never
[02:06:47.680 --> 02:06:55.920]   encounter. I just, it's just awful. And I think he, he deserves a big, a big thumbs down for that
[02:06:55.920 --> 02:07:00.080]   impulse that he has. He knows what he's doing.
[02:07:02.480 --> 02:07:08.560]   I don't even know how repulsive it is. Yeah. Yeah. Big wag of the finger going to,
[02:07:08.560 --> 02:07:12.640]   and I'm not telling you which fingers, but a big wag of a finger.
[02:07:12.640 --> 02:07:20.880]   Should we do the change log? Sure. Well, we've got things that Google has changed.
[02:07:20.880 --> 02:07:23.520]   The Google change log.
[02:07:27.280 --> 02:07:35.600]   Excellent. Thank you very much for the horns. So little grab bag of Googly things that have
[02:07:35.600 --> 02:07:42.560]   happened in the last week or so iOS Chrome. So if you have, if you have iOS, you've got the Chrome
[02:07:42.560 --> 02:07:47.680]   app, they're going to be integrating little Google Maps and calendar and translate basically
[02:07:47.680 --> 02:07:55.280]   integrating some of, some of Google's other services into Chrome on iOS. I suppose that is a big deal
[02:07:55.280 --> 02:08:01.360]   for those of you on iOS to have that. But you know what? I always see these stories and I put them
[02:08:01.360 --> 02:08:07.440]   in there just because I don't want it to always seem like the only Google that I put
[02:08:07.440 --> 02:08:13.040]   of a change log has to do with Android. So there you go. There you go, iOS. Is this a big deal?
[02:08:13.040 --> 02:08:19.680]   Only you would know because I don't use iOS, but there it is. What is Project Tailwind?
[02:08:19.680 --> 02:08:24.720]   This is an AI project. Tailwind is very interesting. We saw it. You saw it. You were there. For God's
[02:08:24.720 --> 02:08:31.760]   thanks. I'm so jealous that you were an IO. But basically, the way to think about it is that you
[02:08:31.760 --> 02:08:36.640]   have a whole folder of stuff and you can say, "Tailwind makes sense of this." Oh, that's right.
[02:08:36.640 --> 02:08:41.520]   And it will make me back. And here's what's interesting. Stephen Johnson, who's a really well-known author,
[02:08:41.520 --> 02:08:48.160]   who has written all kinds of amazing books. I got to remember what they are, is actually working on
[02:08:48.160 --> 02:08:51.440]   Tailwind. He wrote about this. I put it in the rundown a couple weeks ago. We didn't get to it.
[02:08:52.320 --> 02:09:02.560]   But he's written extra life and an enemy of all mankind and far-sighted and wonderland and how
[02:09:02.560 --> 02:09:07.120]   we got to now and future perfect. Stephen's a brilliant author. And he's been working with
[02:09:07.120 --> 02:09:12.400]   the one. It's the perspective of an author saying, "I have all this research. I have all these files.
[02:09:12.400 --> 02:09:16.880]   I have this stuff. And it's whether you're an author or a company or whoever, and being able to
[02:09:16.880 --> 02:09:22.240]   use Tailwind to help you organize it is a really interesting use of AI because it's not making
[02:09:22.240 --> 02:09:26.160]   crap up. It's trying to make sense of the crap you have."
[02:09:26.160 --> 02:09:33.280]   Okay. I can't wait to get in on it. And they haven't yet because I was saying to Stephen when he,
[02:09:33.280 --> 02:09:37.440]   but I saw that I said, "Oh, hey, Stephen. Nice guy here. You want to be in?" They haven't
[02:09:37.440 --> 02:09:43.840]   let anybody in yet because I signed up for it immediately as soon as we saw IO. But I'm really
[02:09:43.840 --> 02:09:51.040]   excited about Tailwind. Well, this is going to be a real boon for people on Twig, hosts and guests
[02:09:51.040 --> 02:09:55.920]   on Twig where you can have a rundown. And sometimes some of the stories on the rundown are very
[02:09:55.920 --> 02:10:01.520]   simple, straightforward. Some of them are incredibly complex. And this would be an opportunity to put
[02:10:01.520 --> 02:10:07.840]   in five or six articles into a folder from the rundown and just basically have Tailwind.
[02:10:07.840 --> 02:10:13.440]   Give me a summary on this and what's the consensus on this and who are the players or who would you?
[02:10:13.440 --> 02:10:18.640]   That sort of thing. It's very nice on a podcast to be able to call up information.
[02:10:19.760 --> 02:10:27.120]   And Chachie BT is worthless because of this sort of thing because its most recent content is from
[02:10:27.120 --> 02:10:33.920]   what 2020, 2021, something like that. Whereas some Project Tailwind can be news that broke
[02:10:33.920 --> 02:10:40.800]   an hour ago, you can drop into a folder and get Chachie BT answers from it or get some sort of
[02:10:40.800 --> 02:10:46.080]   high-level clarity about it, which is great when you're running your mouth on a podcast.
[02:10:46.080 --> 02:10:52.800]   So this is going to be a great feature of that. See, these are the things like that right there.
[02:10:52.800 --> 02:10:58.720]   I'm dropping a note because I'll talk about it in a little bit. But I've got ideas for a new show
[02:10:58.720 --> 02:11:04.080]   post all about Android has to do with AI. And these are things that tie right into it in my mind.
[02:11:04.080 --> 02:11:08.160]   Exactly. I'm going to put a bookmark on that. Talk about that in a little bit. But what this
[02:11:08.160 --> 02:11:12.160]   reminded me of, you mentioned Google I/O. I realized I haven't been on this show since I was a Google
[02:11:12.160 --> 02:11:19.840]   I/O. And thought that you might appreciate, at least while I was there, I got to check out
[02:11:19.840 --> 02:11:28.560]   the Project Starlight, Starlight? What is it? The booth where you sit down and you're sitting in front
[02:11:28.560 --> 02:11:34.640]   of someone on the other side. The Mondo Zoom. Yes, exactly. The three-dimensional kind of in-the-box
[02:11:34.640 --> 02:11:41.520]   Zoom conference thing. And it was awesome. I have to say, it was one of the highlights of my time
[02:11:41.520 --> 02:11:45.760]   there. Because I was really curious about it when they announced it. I think the year or two before,
[02:11:45.760 --> 02:11:53.840]   it just kind of like it checked the boxes for me. I was like, "Oh, wow, virtual, but in-person,
[02:11:53.840 --> 02:11:58.080]   like it feels like you're there." So it made a difference. Oh, yeah, it was super cool. I mean,
[02:11:58.080 --> 02:12:03.600]   it wasn't perfect. But I mean, there was a part like, I think what was weird for me was that
[02:12:03.600 --> 02:12:09.280]   there is no camera that is facing you directly, right? The cameras are all around and they're
[02:12:09.280 --> 02:12:15.200]   kind of stitching together this 3D image of you for the person on the other side. But when you're
[02:12:15.200 --> 02:12:18.400]   sitting there, I mean, you're making full eye contact with the person on the other side of the
[02:12:18.400 --> 02:12:23.920]   screen. And they are the right size. There's dimensionality to them. The way that the booth was
[02:12:23.920 --> 02:12:29.360]   set up had this kind of like the bottom of the TV screen, because obviously it is a TV. Instead
[02:12:29.360 --> 02:12:37.440]   of it looking like a TV, they put in your peripheral view this curved platform that blocked the bottom
[02:12:37.440 --> 02:12:42.640]   of the TV. But it was curved because it helped to kind of tie in with the three-dimensional view of
[02:12:42.640 --> 02:12:47.760]   the person that you're looking at, almost like they were like right on the other side of that little
[02:12:47.760 --> 02:12:54.240]   platform thing. And just the whole experience was just really compelling and really convincing to my
[02:12:54.240 --> 02:13:00.400]   eyes. At one point, he held out an apple to me and like, I really felt like I could grab that apple.
[02:13:00.400 --> 02:13:05.440]   I was like, "Whoa, you know, and then we did a fist bump and I didn't feel the fist, but I felt
[02:13:05.440 --> 02:13:10.160]   like I should." You know, it was just really cool. One of the amazing grabbing things,
[02:13:10.160 --> 02:13:19.600]   I got to ask, did you get anything free? They had a bag for press that had a couple of shirts,
[02:13:19.600 --> 02:13:26.480]   which was kind of interesting. One of the shirts was XL. It was a long sleeve white shirt. Okay,
[02:13:26.480 --> 02:13:30.800]   great. And then there was a sweatshirt that was like a, I think it was like a double or a triple XL.
[02:13:32.800 --> 02:13:36.240]   It was almost just like they grabbed shirts off the shelf. They're like, "I don't know that one and
[02:13:36.240 --> 02:13:43.680]   that one. Go!" Like neither of them. There's your Google move. Yeah, exactly. But yeah, and a water bottle.
[02:13:43.680 --> 02:13:49.120]   That sure has changed back in the day that give you a laptop and a watch and like a, you know,
[02:13:49.120 --> 02:13:56.160]   Google cardboard and a TV device, like all at once. Yes, I know. It was amazing.
[02:13:56.160 --> 02:14:03.200]   Now you had a t-shirt. Times have changed. No, they have. Anyways, so that's that.
[02:14:03.200 --> 02:14:13.680]   The killer thing about Starline, by the way, is that it's something akin to Apple's vision
[02:14:13.680 --> 02:14:19.760]   pro concept when you're doing sort of 3D FaceTime, where they map the other person's face is map,
[02:14:19.760 --> 02:14:27.360]   that becomes an avatar. But this is without classes. And in both cases, very crucial.
[02:14:27.360 --> 02:14:32.000]   You make eye contact with the person you're talking to. Yeah. So this is one of the problems with
[02:14:32.000 --> 02:14:37.760]   Zoom right now. In addition to the fact that you're looking at a wall of people, if you have 12
[02:14:37.760 --> 02:14:42.800]   people on the call, there's 12 people looking at you. Yeah. And then when you're talking to people,
[02:14:42.800 --> 02:14:47.200]   you're looking down or you're looking somewhere else besides eye contact, very important,
[02:14:47.200 --> 02:14:53.200]   psychologically for people. So these virtualizing avatar based technologies that enable you to look
[02:14:53.200 --> 02:14:59.040]   somebody in the virtual eyes is going to be much more comfortable. And this whole Zoom fatigue
[02:14:59.040 --> 02:15:04.800]   thing is going to someday be a thing of the past. Yeah, it really did help. It was almost
[02:15:04.800 --> 02:15:10.640]   uncump, like it was comfortable and familiar. Like, I don't have problems looking people directly
[02:15:10.640 --> 02:15:14.240]   in the eye when I talk to them in person. I know some people that make some feel uncomfortable to
[02:15:14.240 --> 02:15:17.440]   do that for extended period of time. I don't really have that problem.
[02:15:17.440 --> 02:15:23.040]   But when I was in there, I noticed I wanted to look away at times. And I think part of the reason
[02:15:23.040 --> 02:15:30.640]   was because it was a screen and it wasn't a true, like in-person representation, it just felt so
[02:15:30.640 --> 02:15:35.600]   different from what I'm used to when I look at a screen. That's something like what I think
[02:15:35.600 --> 02:15:43.200]   God who was hired to do this job to talk to all these strangers and engage them and show them apples
[02:15:43.200 --> 02:15:47.040]   and things. That's somebody who does not have social anxiety.
[02:15:47.040 --> 02:15:51.040]   Yeah, that's right. No kidding.
[02:15:51.040 --> 02:15:55.920]   What was his name? I actually talked with the founder of the project.
[02:15:55.920 --> 02:16:04.800]   Started with a J. I'm suddenly blanking on his name. But anyways, yeah, it'll come to me later.
[02:16:04.800 --> 02:16:12.240]   But well, apologies guy who created it. But yeah, it was a cool experience. I'm so happy that.
[02:16:12.240 --> 02:16:20.400]   And they were able to fit me in. By no means a priority booking. And they only had a limited
[02:16:20.400 --> 02:16:25.520]   number of entries. And they were all filled. And then I just pester to enough. And they were like,
[02:16:25.520 --> 02:16:29.120]   you know what, I think we've got five minutes. Let's get you in there. So cool. It was pretty cool.
[02:16:29.120 --> 02:16:36.800]   Continuing on with the change law, Google Wallet getting new features, becoming more and more usable,
[02:16:36.800 --> 02:16:44.960]   health insurance cards, photo, car. Let's see here. I'm looking through this. Oh, the ID. So in certain
[02:16:44.960 --> 02:16:49.760]   areas, I feel like this is kind of old information. Is this? I don't know that I put this in.
[02:16:49.760 --> 02:16:54.480]   Yeah, I do. They talked about some time ago. Yeah, digital car keys. I'm trying to see.
[02:16:54.480 --> 02:16:59.760]   I didn't put this Fox News link. Another another. Yeah, it's Fox. That's my fault. I put that in there.
[02:16:59.760 --> 02:17:04.320]   It's another rebranding too. Oh, is that? Wait a minute, they're rebranding it?
[02:17:04.960 --> 02:17:08.560]   Well, what was I guess? I guess it already is rebranded. Google Play. Never mind. I just
[02:17:08.560 --> 02:17:14.080]   is my fault. It's a Fox News. I should have known better. It's okay. I was like, maybe I missed the
[02:17:14.080 --> 02:17:21.200]   news. Google. Oh, I see. Oh, well, wait a minute. Google paid a Google Wallet. See, this is the
[02:17:21.200 --> 02:17:25.040]   problem. They've changed the damn name of this thing so many times. I don't even know what new
[02:17:25.040 --> 02:17:32.640]   news is. Has it always been Google Wallet? I don't know. But it was at some point. So it is again.
[02:17:33.520 --> 02:17:40.240]   There we go. So confusing. Oh, I mean, I don't know if this is a change log worthy or if this is
[02:17:40.240 --> 02:17:45.680]   even where it went. But Pixel tablet reviews have that the embargo lifted a couple of days ago.
[02:17:45.680 --> 02:17:52.720]   And I just thought it sounds like the majority of people are kind of like mixed bag with this thing.
[02:17:52.720 --> 02:17:58.400]   Well, really, the Guardian gave it a rave. Some excellent reviews as far as it being a pretty
[02:17:58.400 --> 02:18:05.360]   solid tablet device. I think some of the criticism comes in the fact that Google is see appears to
[02:18:05.360 --> 02:18:10.800]   be marketing this as yes, a tablet, but also a smart home controls device. And I think some people
[02:18:10.800 --> 02:18:16.080]   who are reviewing this device see it as a smart home, a replacement for their current smart home
[02:18:16.080 --> 02:18:22.800]   controls device or their smart display, like a Nest Hub display. And they're not the same. Like,
[02:18:22.800 --> 02:18:28.240]   they do some of the same things, but it's not a apples to apples comparison as far as what they
[02:18:28.240 --> 02:18:33.280]   can do and how they do it. And so I think they're let down by the fact that, hey, this should be a
[02:18:33.280 --> 02:18:40.720]   better smart hub than it is if this is how Google is positioning it. So that seems to be what people
[02:18:40.720 --> 02:18:46.400]   are disappointed about if they are. But I mean, I had some hands on time with it at Google I/O.
[02:18:46.400 --> 02:18:51.760]   It's a nice feel it like I don't have it in my hands now. I didn't buy one, but the device feels
[02:18:51.760 --> 02:18:58.640]   really nice. Like it's got a nice kind of soft touch to it. It's very curvy. So it's comfortable
[02:18:58.640 --> 02:19:05.520]   to hold the way it snaps into the magnet base is super satisfying. It just like snaps right into
[02:19:05.520 --> 02:19:10.480]   place that magnet catches it and the pogo pins attached. So it's interesting.
[02:19:10.480 --> 02:19:16.560]   It feels to me like it's like a smart display that you can just pick it up and use it as a tablet.
[02:19:16.560 --> 02:19:22.720]   Right. And that's kind of a nice idea. It's also got a really good price. It's like 500 bucks.
[02:19:22.720 --> 02:19:28.000]   500 bucks with the base, which I think is really important. I think if I had heard 500 and then
[02:19:28.000 --> 02:19:34.720]   the base is only $129 be like no way, but it's included. Thankfully, that's kind of part of the kit.
[02:19:34.720 --> 02:19:43.520]   So yeah, yeah. Built in Chromecast. Yeah, I think maybe the confusion or the dissatisfaction is like,
[02:19:44.000 --> 02:19:50.640]   what is this meant to do first? Is it a tablet first? Is it a smart display first? And depending on how
[02:19:50.640 --> 02:19:56.000]   you buy into it, that you could either be happy or disappointed based on how you enter into that.
[02:19:56.000 --> 02:20:00.880]   Because if you're entering into it as a smart display replacement, you might be disappointed
[02:20:00.880 --> 02:20:07.920]   by what you get. And then we've got the Pixel Fold shipping date. Apparently,
[02:20:07.920 --> 02:20:13.120]   slip in a little bit. I don't know that this is this a official word from Google that these
[02:20:13.120 --> 02:20:20.960]   things are slipping. June 27th was the same day that Verizon provided not starting until June 20th.
[02:20:20.960 --> 02:20:26.880]   So oh, okay. So then does that mean that it's shipping out? Oh, no, I see. That's what it was
[02:20:26.880 --> 02:20:33.280]   originally supposed to be. And now it's slipped to June 28th through July 7th.
[02:20:33.280 --> 02:20:37.440]   Yeah. So the thing about the Pixel Fold is very expensive, but it comes with a free watch.
[02:20:37.440 --> 02:20:40.880]   You get a free Pixel. That's true. Watch with it. So that's kind of cool.
[02:20:40.880 --> 02:20:45.120]   Are you like, are you? Well, I guess you're iOS now. So you're probably not going to get the
[02:20:45.120 --> 02:20:54.320]   Pixel Fold. A trader. Yes. I love smart watches. But yeah, that's an okay feature. I personally
[02:20:54.320 --> 02:21:00.400]   am not crazy about the environmental impact of these folding screen phones.
[02:21:00.400 --> 02:21:05.200]   About time will tell. We'll see how it goes. And we'll see when the EO bans them.
[02:21:05.200 --> 02:21:10.480]   Ooh, okay. So I'm intrigued now. I don't know that I've heard about this explained.
[02:21:10.480 --> 02:21:16.800]   Like what about the environmental impact of the foldable? So different types of phone form factors
[02:21:16.800 --> 02:21:22.000]   that have come out that have been multiple screens where like there'll be a folding phone with a
[02:21:22.000 --> 02:21:26.240]   screen on the outside. So if you have a big flexible screen, then you have another screen.
[02:21:26.240 --> 02:21:33.840]   These screens by themselves and also the electronics that support them contain all kinds of toxic
[02:21:33.840 --> 02:21:41.040]   metals, all the things that make smartphones an environmental problem. But far more of them.
[02:21:41.040 --> 02:21:47.680]   And what we don't know is how long do they last? We don't know, for example, do these folding
[02:21:47.680 --> 02:21:54.880]   screen phones last for five, six years? They're always being folded and bent and stuff like that.
[02:21:54.880 --> 02:22:00.400]   Or do they have like half the shelf life of a standard phone? We don't know. My guess is that
[02:22:00.400 --> 02:22:06.560]   they have a much shorter life. They're much more likely to be damaged to wear out all that kind of
[02:22:06.560 --> 02:22:11.760]   stuff. And there's a lot more screen real estate. And in some cases, there's yet another screen.
[02:22:11.760 --> 02:22:18.320]   There's a giant screen and a smaller screen. And all of this adds up to the idea that
[02:22:18.320 --> 02:22:24.720]   smartphones are already problematic. But these folding screen phones and extra screen phones
[02:22:25.440 --> 02:22:33.840]   are twice as bad for the environment. Or even worse than that, because they may not last nearly as
[02:22:33.840 --> 02:22:40.000]   long. They might not be as repurposable. And they have a lot more of the toxic metals inside of them
[02:22:40.000 --> 02:22:44.000]   that all smartphones have. So I don't know, time will tell.
[02:22:44.000 --> 02:22:45.760]   Yeah. Well, I mean,
[02:22:45.760 --> 02:22:53.440]   the original Z Fold was introduced February 2019, but that didn't release until September of 2019.
[02:22:53.440 --> 02:22:57.360]   So we're coming up on four years, at least for the Z Fold.
[02:22:57.360 --> 02:23:02.320]   As far as that's concerned. So I'm...
[02:23:02.320 --> 02:23:06.960]   How many of those are out there? You know what I mean? How many do they sell? It's not like
[02:23:06.960 --> 02:23:12.880]   a major Android phone or an iPhone where there's like 100 million units are sold.
[02:23:12.880 --> 02:23:19.360]   And then the scale of it can be a problem. I don't know. We'll see. It's something I worry about.
[02:23:19.360 --> 02:23:20.720]   Interesting.
[02:23:22.000 --> 02:23:27.040]   That is super interesting. I hadn't heard that. Let's see here. Google Maps immersive view.
[02:23:27.040 --> 02:23:34.560]   This is rolling out in some new cities, including 500 landmarks. This was shown off at Google I/O
[02:23:34.560 --> 02:23:43.520]   as a way to get a kind of like a virtual tour of your route in certain supported areas, which looked,
[02:23:43.520 --> 02:23:48.400]   I don't know, looked kind of cool. Like, I'm going over there. What is my route actually?
[02:23:48.400 --> 02:23:53.200]   Like, what is the experience of going through this route and you take like a little virtual tour
[02:23:53.200 --> 02:24:01.360]   through the navigation? So that's rolling out to a few more cities. What cities is that coming to?
[02:24:01.360 --> 02:24:04.480]   I didn't open it up. Amsterdam, Dublin, Florence, Venice.
[02:24:04.480 --> 02:24:10.960]   Already in New York City, San Francisco, London, Tokyo, Los Angeles. So, you know,
[02:24:10.960 --> 02:24:16.880]   they're focusing on, oh, and plans to support 15 cities in total. That's Berlin, Las Vegas,
[02:24:16.880 --> 02:24:24.000]   Miami, Paris, Seattle, San Jose. So they're expanding this, but that's neat. I will look forward to
[02:24:24.000 --> 02:24:29.920]   using that. We were talking about maps as being one of those apps and services that is usually
[02:24:29.920 --> 02:24:34.080]   just, you know, Google knocking it out of the park and doing really cool, innovative things.
[02:24:34.080 --> 02:24:41.920]   It's one of my absolute all-time favorite apps for Android. So, I'm always curious to see what
[02:24:41.920 --> 02:24:53.200]   they do there. And then finally, trying on clothes with Google's AI. It's a new shopping feature. So,
[02:24:53.200 --> 02:24:58.880]   that I'm assuming you can... I don't know what to say. I'm trying to bring this out. I couldn't
[02:24:58.880 --> 02:25:03.920]   get it. I couldn't understand it. Basically, how it works is that this is a, I believe that they're
[02:25:03.920 --> 02:25:09.440]   going to roll this out to retailers. So Nordstrom, other retailers will have it. And basically,
[02:25:09.440 --> 02:25:17.360]   what you do is you pick from a menu of body types. So, you basically find, have all these, you know,
[02:25:17.360 --> 02:25:22.960]   dozens and dozens of models that have, you know, short, tall, big, small, all that kind of stuff.
[02:25:22.960 --> 02:25:29.200]   And you pick the body that most closely resembles yours. And then it's a platform for the retailers
[02:25:29.200 --> 02:25:35.840]   to essentially capture the image of the actual clothing inventory that they have in their inventory.
[02:25:35.840 --> 02:25:43.760]   And then the technology takes that and makes the fabric hang on the body. It clings in the way
[02:25:43.760 --> 02:25:49.520]   clothes would. It moves and folds and wrinkles and all the stuff that the way clothes actually do,
[02:25:49.520 --> 02:25:54.880]   rather than being this paper, all kind of thing that just kind of holds a two-dimensional image
[02:25:54.880 --> 02:26:01.040]   of the clothes in front of the body. So, it sounds like they're doing all the right things
[02:26:01.040 --> 02:26:05.440]   to reach the kind of Nirvana we've been talking about for many, many years of being able to
[02:26:05.440 --> 02:26:10.640]   virtually try and close in a compelling way. And so, they have, they're rolling out with a number
[02:26:10.640 --> 02:26:15.040]   of partners that are going to be doing this. And this could actually be a really interesting
[02:26:15.040 --> 02:26:21.280]   application of technology that helps people shop online. And it'll be a real boon for online
[02:26:21.280 --> 02:26:26.720]   sales of clothes, I think. No kidding. Interesting. At some point, we'll be wearing
[02:26:26.720 --> 02:26:32.640]   wearing our glasses, looking at a virtual mirror, looking at ourselves, standing in front of the
[02:26:32.640 --> 02:26:38.160]   mirror, actually wearing the clothes, going, "Okay, yeah, order." And then we'll receive it.
[02:26:38.160 --> 02:26:44.400]   Like, you know, that's going to happen at some point. And this is kind of how we get there.
[02:26:44.400 --> 02:26:49.920]   I would imagine. That's really cool. And surprising that it hasn't happened before. But here we are
[02:26:49.920 --> 02:26:56.960]   in the future, living in the future. And that is the Google change log. Google change log is always
[02:26:56.960 --> 02:27:04.400]   about the future. How about we take a break, thank the sponsor, then come back and do our picks
[02:27:04.400 --> 02:27:11.760]   for the week. And then we round things out. But before we get there, this episode of This Week in
[02:27:11.760 --> 02:27:19.760]   Google is brought to you by ZipRecruiter. Did you know it can now take up to 11 weeks? That's on average
[02:27:19.760 --> 02:27:24.400]   to hire for an open position. That's a long time. That's almost two and a half months.
[02:27:25.040 --> 02:27:31.120]   So if you're hiring for a growing business, you probably do not have the kind of time that we're
[02:27:31.120 --> 02:27:37.120]   talking about here to just wait for the right person. You need that person fast or those people
[02:27:37.120 --> 02:27:42.480]   fast. Well, if you're listening today, I've got some advice for you. Stop waiting. You don't have
[02:27:42.480 --> 02:27:48.720]   to wait anymore. Start using ZipRecruiter because ZipRecruiter can help you find qualified candidates
[02:27:48.720 --> 02:27:54.160]   for all of your roles. And they do it fast. And right now, you can try it for free. All you have
[02:27:54.160 --> 02:28:03.120]   to do is go to ziprecruiter.com/twig. And what can I say? It's effective. We've used ZipRecruiter
[02:28:03.120 --> 02:28:08.720]   here at Twit a number of times to fill the roles that we have. And it just keeps on working and it
[02:28:08.720 --> 02:28:13.680]   works fast. How is ZipRecruiter so efficient in helping you hire? What's it going to do for you?
[02:28:13.680 --> 02:28:19.360]   Well, ZipRecruiter uses powerful matching technology to quickly find and send you the most qualified
[02:28:19.360 --> 02:28:25.040]   people for your roles. You can check out the people that ZipRecruiter sends you. And if you really like
[02:28:25.040 --> 02:28:32.880]   one or two, you can personally invite them to apply with one click. That may make them apply
[02:28:32.880 --> 02:28:40.080]   even sooner, right? Even faster. Plus, here's how quickly ZipRecruiter can help you hire four out of
[02:28:40.080 --> 02:28:45.120]   five employers who post on ZipRecruiter. Get a quality candidate within the first day. I know
[02:28:45.120 --> 02:28:51.120]   that's happened here. I know that I've heard Lisa talk about that. So, if you're in that position
[02:28:51.120 --> 02:28:58.080]   as well, you know the value of getting the right hire fast. That's why you need ZipRecruiter. Speed up
[02:28:58.080 --> 02:29:04.240]   your hiring process with ZipRecruiter. See why 3.8 million businesses have come to ZipRecruiter
[02:29:04.240 --> 02:29:12.160]   for their hiring needs. Just go to this exclusive web address to try ZipRecruiter for free. That's
[02:29:12.160 --> 02:29:23.600]   ziprecruiter.com/twig. There's one more time ziprecruiter.com/twig and check it out for yourself. ZipRecruiter is the smartest
[02:29:23.600 --> 02:29:33.600]   way to hire. We thank them for their continued support of this week in Google. All right. Well,
[02:29:33.600 --> 02:29:40.640]   we are at the picks and tips and tricks and all those things section of this week in Google. Mike,
[02:29:40.640 --> 02:29:46.160]   why don't we start with you? What you got? Fantastic. I have a very, very simple one that
[02:29:46.160 --> 02:29:53.680]   ties into the first story we're talked about, which is Reddit. A lot of mods on Reddit are
[02:29:53.680 --> 02:30:01.040]   protesting by various means. One of them is they're duplicating the sub-Reddit on other platforms.
[02:30:01.040 --> 02:30:07.680]   And this is happening at a fairly large scale. And so, somebody has created a website called
[02:30:07.680 --> 02:30:16.400]   sub.rehab. Now, this is a place that tells you where your favorite sub-readers have gone.
[02:30:16.400 --> 02:30:22.800]   So, they may be Discord servers or some other kind of site, but it takes you through all of the
[02:30:22.800 --> 02:30:31.040]   sub-readers that have moved somewhere in, I guess, alphabetical order. And you can find the
[02:30:31.040 --> 02:30:39.760]   ones that you like, you know, are anti-work, are Apple, etc. And in some cases, these sub-readers
[02:30:39.760 --> 02:30:45.680]   have gone to multiple places. And in many cases, they're duplicating kind of the look and feel of
[02:30:45.680 --> 02:30:53.200]   the sub-readed. So, they're trying to retain, in some cases, as much of the functionality of Reddit
[02:30:53.200 --> 02:30:58.880]   on these other platforms as they had on Reddit itself. So, this is a great place. If you're a
[02:31:00.000 --> 02:31:05.600]   Reddit fan, this is a great place to go and find out where else, besides Reddit, you can find your
[02:31:05.600 --> 02:31:14.800]   favorite sub-readers. And so, these are the same content being ported over or like, is it?
[02:31:14.800 --> 02:31:20.080]   Yes. It's an alternate location for new discussions to happen that are outside of Reddit, around the
[02:31:20.080 --> 02:31:24.080]   same time. Exactly. And I think there's been a lot of porting as well. But in either case,
[02:31:24.880 --> 02:31:32.080]   you may find your favorite sub-Reddit is closed or unsafe for work or affected in some way,
[02:31:32.080 --> 02:31:38.800]   but you might be able to find it via this site and engage with it and continue to use it as you
[02:31:38.800 --> 02:31:46.640]   did before, but not on Reddit. That's super cool. And yeah, I'm looking through some of these sub-readers
[02:31:46.640 --> 02:31:53.760]   alternatives anyways and seeing a lot of activity in them. So, yeah, that's pretty impressive.
[02:31:54.320 --> 02:31:58.560]   Cool. Many of them Discord. So, that's cool. There you go. Yeah, Discord's it. That's another thing.
[02:31:58.560 --> 02:32:04.160]   I mean, I realize we have a Discord. Yeah, we have the Club Twit Discord here and I use that.
[02:32:04.160 --> 02:32:09.440]   But I have heard many people say, "Oh, we'll just find it on Discord now." And that's like a whole
[02:32:09.440 --> 02:32:16.160]   realm, like a whole world that I have not ventured down. Where do you even begin on that? Discord.
[02:32:16.160 --> 02:32:22.240]   But I'm not sure how to deal with Discord. Yeah. Do you search and do you use the Discord search
[02:32:22.240 --> 02:32:27.280]   to find the Discord that you, you know, communities that you want to join? Or are you
[02:32:27.280 --> 02:32:32.240]   Patreon-ing, you know, someone? And as a result, you get access to the Discord around that topic and
[02:32:32.240 --> 02:32:38.240]   it just, yeah. Anyways, the whole. I also get confused. It's like Slack where I have like
[02:32:38.240 --> 02:32:42.480]   six or eight different slacks I'm a part of. Yeah. And the switch between them drives me nuts.
[02:32:42.480 --> 02:32:50.080]   Yeah, totally. Discord is definitely that way. I'm on a handful of Discord channels and yeah.
[02:32:51.040 --> 02:32:56.240]   There's always unread badges on every one of them that is read all across the board. I'm just like,
[02:32:56.240 --> 02:33:02.320]   it almost seems like work for me to like wipe them out. So I've given up on that. There's just
[02:33:02.320 --> 02:33:09.200]   so much activity happening between those six that I belong to. So sub rehab. Love it. Thank you,
[02:33:09.200 --> 02:33:14.240]   Mike. That's awesome. Well, what about you, Jeff? What you got? This is kind of fun.
[02:33:14.240 --> 02:33:20.400]   logolalenge.com is a guy named Bill Gardner. I guess does an annual report on logo trends.
[02:33:20.400 --> 02:33:24.480]   This is a visual. Sorry for you folks who are on audio, but you can go to a lecture.
[02:33:24.480 --> 02:33:30.960]   Measure. And so some he comes up with logos that look like wildflowers. It's just design trends.
[02:33:30.960 --> 02:33:40.880]   Well, they're going to be called blow blend. Another one is spirals. This doesn't work so well
[02:33:40.880 --> 02:33:46.880]   for audio, I realize. Wire forms, baldcaps. What was the name fills, which is just names filling a
[02:33:46.880 --> 02:33:52.080]   space in different ways. And so the guy goes through, he's obviously a logo designer and
[02:33:52.080 --> 02:33:57.040]   consultant, but he goes through all kinds of logos in a year. And it is fun to see
[02:33:57.040 --> 02:34:03.280]   the trends that exist. So simple. Yeah, a little nice little carousel.
[02:34:03.280 --> 02:34:09.680]   Swap through them and it quickly flashes through the different examples of each type
[02:34:09.680 --> 02:34:18.560]   to give you a sense of what falls into that category. Yeah, there you go. And oh, and it dates back.
[02:34:18.560 --> 02:34:23.920]   So you if you want to see that, you go to 2009, check out the trend reporter even 2000.
[02:34:23.920 --> 02:34:29.280]   I think it goes as far back as 2003 boy, those logos, those are data. Actually,
[02:34:29.280 --> 02:34:38.400]   it's a Tivo in there. It is dated. That was probably a cutting edge logo back in 2003 was the Tivo logo.
[02:34:39.200 --> 02:34:44.400]   The little TV with the eyes and the arms and everything. Cool stuff.
[02:34:44.400 --> 02:34:53.120]   Logo trend report. So my pick, I think I just wanted to make mention of the fact that last night's
[02:34:53.120 --> 02:35:01.120]   episode of all about Android was the last episode of all about Android, which was definitely bittersweet.
[02:35:01.120 --> 02:35:08.480]   But we had a wonderful, wonderful episode. We actually for a number of years now on the show,
[02:35:08.480 --> 02:35:16.160]   this recurring theme of a Hall of Fame for Android kept coming up and we had joked around time and
[02:35:16.160 --> 02:35:21.920]   time again about someday in the future. We're going to do an episode that is the Android Hall of Fame.
[02:35:21.920 --> 02:35:26.080]   We're going to do it right and blah, blah, blah. Well, it only took ending the show for us to finally
[02:35:26.080 --> 02:35:33.600]   do that. It's a very long, long episode. But I had a ton of devices out on the table and we
[02:35:33.600 --> 02:35:38.320]   compiled a list of some of the devices that we thought would deserve to be in the Android Hall
[02:35:38.320 --> 02:35:45.600]   of Fame. We debated all of them and anointed our Hall of Fame winners as far as that's concerned.
[02:35:45.600 --> 02:35:52.880]   Then said farewell to the show and got a little teary, got a little emotional primarily because
[02:35:53.680 --> 02:36:00.160]   we've been doing that show for 13 years. I can speak for myself, it's a show that's
[02:36:00.160 --> 02:36:06.080]   been near and dear to my heart for that entire time. It's been a total fun hang session with
[02:36:06.080 --> 02:36:11.120]   some really great friends, all of us talking about something that we care passionately enough
[02:36:11.120 --> 02:36:18.320]   about to talk about it for 13 years, week after week, every Tuesday night. It's worth watching.
[02:36:18.320 --> 02:36:24.640]   If you haven't checked all about Android in a while, I think we did the show justice with our
[02:36:24.640 --> 02:36:30.240]   episode last night. I'm really proud of the way it turned out because I think it was just a really
[02:36:30.240 --> 02:36:36.080]   fun look back at Android. Not necessarily the show as much, although we had a little bit of that at
[02:36:36.080 --> 02:36:42.240]   the end. But I don't know. Worth saying goodbye to a show that's been on this network almost as
[02:36:42.240 --> 02:36:48.880]   long as I've been here. Jason, it was really, really well done and touching the relationships
[02:36:48.880 --> 02:36:55.040]   you built with it. Over this time, the credibility you built with it, watching all these trends for
[02:36:55.040 --> 02:37:00.960]   the years, it really expresses it. It was lovely to watch and you didn't cry through the whole
[02:37:00.960 --> 02:37:09.600]   things so far as I could tell. I started to at the very end. When did her share of crime,
[02:37:09.600 --> 02:37:14.480]   which I loved to see she wears her heart on her sleeve and she definitely did that last night.
[02:37:14.480 --> 02:37:19.440]   And I had one moment where, yes, I was going and I had to kind of like reel myself back because I
[02:37:19.440 --> 02:37:24.640]   didn't want to do the ugly cry and I knew there was about to happen. And also, I could kind of faintly
[02:37:24.640 --> 02:37:30.880]   hear Leo's voice over my shoulder, even though he was at Disneyland going, "He's not a huge fan of
[02:37:30.880 --> 02:37:36.000]   the big send-off for a show." I'm really glad they let you do it because it was a really well done
[02:37:36.000 --> 02:37:40.320]   send-off. And all the way to now, say, "Clear." I just did it. Make clear to everybody.
[02:37:40.320 --> 02:37:46.000]   Well, yeah, just screw it. What are you going to do? Totally. Yeah, totally. The show's done.
[02:37:46.000 --> 02:37:50.640]   What are we going to do? But you're staying here. It's important to make clear to everybody.
[02:37:50.640 --> 02:37:56.000]   Yes. Very, very important. Thank you. It's the end of the show. I got nervous and I was looking
[02:37:56.000 --> 02:38:01.040]   around and saying, "What's going on? What's going on? Oh my God." No, it's just all about
[02:38:01.040 --> 02:38:05.600]   Android. All about Android, the numbers had been lagging. Actually, I think this is an interesting
[02:38:05.600 --> 02:38:11.760]   topic for this show is, I think, just in general, smartphone as an innovation smartphone, as a thing
[02:38:11.760 --> 02:38:17.280]   to be passionate about. Oh, you're not interested. 10 years ago, when I was looking through past
[02:38:17.280 --> 02:38:22.720]   episodes and my favorite years and everything like that, 2013 was actually a really great year.
[02:38:22.720 --> 02:38:28.560]   There was tons of innovation happening in phones. Google was firing on all cylinders with Android.
[02:38:28.560 --> 02:38:32.640]   There was a lot to get excited about because there was a lot that we hadn't already seen.
[02:38:32.640 --> 02:38:36.720]   And there was plenty of innovation still to be had. And I'm not saying that it's completely
[02:38:36.720 --> 02:38:41.360]   tapped out when it comes to smartphones. But I am saying that it's pretty ubiquitous at this point.
[02:38:41.360 --> 02:38:46.480]   Everybody has a smartphone. Everybody has a side. There's not a whole lot that companies are doing
[02:38:46.480 --> 02:38:52.400]   now with smartphones that are very surprising, save for maybe the foldables and other things.
[02:38:52.400 --> 02:38:58.400]   Some of it feels kind of gimmicky. We've got to innovate. So let's do this thing. I don't know.
[02:38:58.400 --> 02:39:06.000]   You know, I don't know. I just feel like the passion around smartphones has kind of dissipated a little
[02:39:06.000 --> 02:39:10.640]   bit. There are other things that people are getting that excited about in different directions.
[02:39:10.640 --> 02:39:14.720]   And I don't know that it's necessarily smartphones the way it used to be. And I think that showed in
[02:39:14.720 --> 02:39:21.360]   our numbers over the last handful of years. So not a whole lot you can do about it. I'm convinced
[02:39:21.360 --> 02:39:28.240]   that we were creating a strong of a show there at the end of its run than we ever have.
[02:39:28.800 --> 02:39:34.560]   You know what I mean? I know we had very smart people. We had as much fun, if not more fun,
[02:39:34.560 --> 02:39:40.400]   than we've had. And that's always been a really big marker. That show is we're together to hang
[02:39:40.400 --> 02:39:45.360]   out and be friends and make jokes and also talk about this thing that we all kind of unite on,
[02:39:45.360 --> 02:39:49.360]   which is the Android platform. And I think we did that till the very last episode.
[02:39:49.360 --> 02:39:58.000]   Yeah. And in fact, it was the number one clear, best Android podcast that ever was. And that's
[02:39:58.000 --> 02:40:03.040]   all you can do. And so congratulations on just a fantastically great show.
[02:40:03.040 --> 02:40:05.600]   Thank you, Jason. So very well done.
[02:40:05.600 --> 02:40:07.840]   Thank you. I really do appreciate that.
[02:40:07.840 --> 02:40:16.400]   Just to reiterate, I'm not going anywhere. I'm here at Twit. My plan now, because,
[02:40:16.400 --> 02:40:21.920]   you know, Lisa, they didn't want to kill the show, but it just seemed like it was time.
[02:40:21.920 --> 02:40:26.480]   And they also wanted to kind of like challenge me like, okay, well, what do you do if you're not
[02:40:26.480 --> 02:40:30.720]   doing all about Android anymore? What do you want to do? And I meet like, without even thinking,
[02:40:30.720 --> 02:40:34.960]   I knew exactly what I wanted to do. It was like, I want to do an AI show. I want to do a show that's
[02:40:34.960 --> 02:40:41.040]   focused on AI. I don't know how that's going to materialize. I know the thing that I'm not as
[02:40:41.040 --> 02:40:47.520]   interested in is like, like a panel discussion show about the news and events happening in the
[02:40:47.520 --> 02:40:52.640]   world of AI. Sam, all been doing that. We don't care. Totally. Like, I think we cover that on the
[02:40:52.640 --> 02:40:59.680]   network. What I talked about earlier, and I made mention of this just a little bit ago was in
[02:40:59.680 --> 02:41:05.680]   tailwind when you were talking like about kind of using that technology for producing shows.
[02:41:05.680 --> 02:41:12.160]   That's the kind of stuff that really intrigues me. How can we as people as just everyday people,
[02:41:12.160 --> 02:41:16.640]   not people who know how to, you know, the open source community know how to hack together these
[02:41:16.640 --> 02:41:22.800]   AI generating systems or whatever. Maybe some of that, of course. But how can we use what is available
[02:41:22.800 --> 02:41:28.880]   to us in the world of AI to improve our life or to make this part of our job easier or to
[02:41:28.880 --> 02:41:34.560]   create images? You know, I'm a horrible graphic designer, but I can create things if I know the
[02:41:34.560 --> 02:41:39.680]   right words and the right prompts to do it. Like it's opening these doors that I don't think we
[02:41:39.680 --> 02:41:47.360]   have to be scared necessarily about the potential of AI to take over our jobs and ruin the world
[02:41:47.360 --> 02:41:51.760]   and everything like that. I think we're going to be okay. How can we use these things to do some
[02:41:51.760 --> 02:41:57.680]   really cool things in our lives to, I don't know, to find more satisfaction in what we do and how
[02:41:57.680 --> 02:42:01.840]   we do and all these things. So that's what excites me. And that's what I think I'm going to kind of
[02:42:01.840 --> 02:42:07.040]   focus my efforts on. And I hope to find some small way to help you on that. I think it's a great idea.
[02:42:07.040 --> 02:42:10.560]   I know. I know. I would love to do that. And I will definitely be in touch with you, Jeff,
[02:42:10.560 --> 02:42:16.400]   because I know you've mentioned wanting to kind of be involved in something around AI with Twitch.
[02:42:16.400 --> 02:42:22.560]   And the opportunity is here now. It wasn't before. I don't know that Leo and Lisa were
[02:42:22.560 --> 02:42:28.960]   as willing to start a new show about AI prior. But with all about Android, no longer, now I have
[02:42:28.960 --> 02:42:34.960]   the time and the ability to focus on starting something like that up. So I will be in touch.
[02:42:34.960 --> 02:42:40.320]   Absolutely. We'll see if anyone has any ideas of what you would love to see out of an AI show,
[02:42:40.320 --> 02:42:46.080]   I would love to hear from you, Jason at Twitch.tv. Let me know, because I'm all ears. I'm in
[02:42:46.080 --> 02:42:51.120]   development stage right now. And I'm starting from the beginning, which is a little intimidating,
[02:42:51.120 --> 02:42:55.680]   because there's a lot I don't know about AI. But I think that's the fun is to do a show where I
[02:42:55.680 --> 02:43:01.600]   learn about it with you, you know, and we can learn about it together. So anyways, that's my
[02:43:01.600 --> 02:43:07.360]   good work, sir. Thank you. And thanks for all the support all around. I've just had so much
[02:43:07.360 --> 02:43:11.920]   support from people today. So it's been really wonderful to hear that. But we have reached the
[02:43:11.920 --> 02:43:18.320]   end of this show and it's not going anywhere. This is this week in Google, such a fun show. And I'm so
[02:43:18.320 --> 02:43:24.640]   always so honored to be able to fill in for Leo when he's gone and talk with you guys about Google
[02:43:24.640 --> 02:43:29.360]   and to sit on the panel with you, Mike Elgin after a very, very long time. It's been just absolutely
[02:43:29.360 --> 02:43:35.840]   wonderful. Thank you for being here today with us. Thank you. And can I do a couple of quick plugs?
[02:43:35.840 --> 02:43:39.520]   Please do. This is your opportunity to do that. Yes, absolutely. I was going to ask.
[02:43:39.520 --> 02:43:47.760]   Okay. So as you mentioned earlier, we do gastronomic experiences. These are exquisite food and wine
[02:43:47.760 --> 02:43:55.600]   and gastronomic adventures, of which you cannot even describe. They're really fantastic. They're
[02:43:55.600 --> 02:44:01.760]   all sold out this year for the rest of the year, except for we have a room for Mexico City. So I
[02:44:01.760 --> 02:44:08.640]   would like to invite everybody to that Mexico City, which is happening November 13th to the 18th,
[02:44:08.640 --> 02:44:14.480]   just one week. And then we have a brand new one we've never done before in January in El Salvador.
[02:44:14.480 --> 02:44:20.880]   El Salvador is an amazing, beautiful, delicious, tropical country. And that experience is happening
[02:44:20.880 --> 02:44:26.240]   January 20th through the 26th. It's going to be relaxing. There's going to be a lot of beach time.
[02:44:26.240 --> 02:44:32.800]   There's going to be a lot of tropical rainforest exploration. There's going to be a lot of eating
[02:44:32.800 --> 02:44:37.360]   and drinking and having fun. So I invite everybody to join us on that. The other quick thing I wanted
[02:44:37.360 --> 02:44:43.840]   to mention simply because we've been talking a lot about both AI, the future of AI, and also
[02:44:43.840 --> 02:44:50.960]   how advanced technologies affect children. Anyone who's listened to the show before knows that my
[02:44:50.960 --> 02:44:56.000]   son Kevin has a company called Chatterbox. It's a smart speaker that kids put together
[02:44:56.000 --> 02:45:02.640]   themselves. Then they teach it what to say. And in the process, they learn what AI is and how it
[02:45:02.640 --> 02:45:09.200]   works. And he's been preaching the gospel of preparing kids for the future of AI for many years,
[02:45:09.200 --> 02:45:18.960]   long before Chatterbitt or any of this stuff. But now that the AI world has crashed into mainstream
[02:45:18.960 --> 02:45:26.320]   culture, people should know that Chatterbox now supports Chatterbitt in a child friendly way.
[02:45:26.320 --> 02:45:34.800]   And also the image version of that via stable diffusion. So kids, as you know, stable diffusion
[02:45:34.800 --> 02:45:44.000]   is done all with text prompts. With Chatterbox, children can create a scale and then generate
[02:45:44.000 --> 02:45:50.400]   images with voice. So they tap the button on the top and they give the prompt and they get back
[02:45:50.400 --> 02:45:56.080]   the pictures. And again, the purpose is not to create pictures. The purpose is for them to
[02:45:56.080 --> 02:46:02.080]   prepare to live in the future that they'll actually live in, which is a future where AI is utterly
[02:46:02.080 --> 02:46:07.760]   ubiquitous. And so I'd anybody who's an educator in the school system or a parent,
[02:46:07.760 --> 02:46:11.680]   I would I would encourage you to go to hello Chatterbox.com and check this out because
[02:46:11.680 --> 02:46:18.640]   this is really, this is how we prepare kids for the future of AI, not by banning it, not by
[02:46:18.640 --> 02:46:26.320]   pretending it doesn't exist, but by getting kids hands on AI, the hardware, the software,
[02:46:26.320 --> 02:46:30.880]   all of it, and letting them know what it is. So they're ready for the future.
[02:46:30.880 --> 02:46:36.800]   That's super cool. I love it. I love the Chatterbox and watching the evolution of Chatterbox over
[02:46:36.800 --> 02:46:42.880]   the years has been really, really awesome to see. You guys have a really great thing going. So
[02:46:42.880 --> 02:46:48.240]   thank you, Mike. Fantastic stuff and really great to have you here. And I hope we get to do this
[02:46:48.240 --> 02:46:54.800]   again soon. Thank you for inviting me. Absolutely. Any time. And thank you, Mr. Jeff Jarvis over
[02:46:54.800 --> 02:47:00.560]   here on my left, at least here in the studio anyways. What do you want to leave people with?
[02:47:00.560 --> 02:47:03.520]   I mean, you got your book, right? Where can people find your book?
[02:47:03.520 --> 02:47:04.800]   What are the details?
[02:47:04.800 --> 02:47:05.360]   The Deet's.
[02:47:05.360 --> 02:47:08.320]   Brenthesis.com. It's out on the 29th and you can order it now.
[02:47:08.320 --> 02:47:09.280]   That's so exciting.
[02:47:09.280 --> 02:47:12.400]   Somebody, friend of mine ordered it from Barnes and Noble. They said they were sold out,
[02:47:12.400 --> 02:47:17.280]   which is ridiculous. It hasn't arrived yet. So Black Wells is a great place to do what Amazon
[02:47:17.280 --> 02:47:21.280]   has full price now, but they'll do their lower price when they decide that.
[02:47:21.280 --> 02:47:27.280]   Boom is very directly has a discount as well. So I'd be grateful to hear what you think of it,
[02:47:27.280 --> 02:47:28.080]   folks.
[02:47:28.080 --> 02:47:33.760]   Right on. You know, you're going to get a lot of readers of that book who are watching and listening
[02:47:33.760 --> 02:47:40.480]   to this very show as well. So that's like days away. I don't know what it's like to write a book,
[02:47:40.480 --> 02:47:45.200]   but I can only imagine that this part, like there's so much anticipation,
[02:47:45.200 --> 02:47:48.720]   it's going to feel really nice to get on the other side of the release and be like,
[02:47:48.720 --> 02:47:50.400]   it's out.
[02:47:52.720 --> 02:47:58.800]   So it's such a build up to that moment. So so much to be proud of and really cool stuff.
[02:47:58.800 --> 02:48:01.040]   Thank you again, Jeff. Always appreciate it.
[02:48:01.040 --> 02:48:06.400]   As for me, like I said earlier, I'm not really doing Twitter much, but if you want to find me
[02:48:06.400 --> 02:48:10.960]   there, I'm at Jason Howl. Master Don a little bit with social slash at Jason Howl.
[02:48:10.960 --> 02:48:15.680]   Try in the TikTok thing. I don't really know how I'm going to use TikTok, but I figured like,
[02:48:15.680 --> 02:48:20.560]   I'll just say a few things into it every, you know, every day and see what, see what happens.
[02:48:20.560 --> 02:48:24.960]   Where's my mind at? Where's my heart at? And I'll just kind of share it and see what happens.
[02:48:24.960 --> 02:48:31.120]   I don't know. Instead of instead of pulling up a desktop, you know, browser and going to Twitter
[02:48:31.120 --> 02:48:36.080]   and thinking for 20 minutes, like the perfectly phrased thing that I'm going to send out to
[02:48:36.080 --> 02:48:41.200]   everybody, I'm just going to pick up my phone to record a thing and see what that does for me. So
[02:48:41.200 --> 02:48:48.080]   that is that Jason Howl, I think is my my handle over there. If you want to see what that's all about,
[02:48:48.080 --> 02:48:52.480]   still not even certain it's a great idea, but I'm going to try it anyways, because why the heck not?
[02:48:52.480 --> 02:49:00.000]   As for this show, you can go to twit.tv/twig, twig. There you will find all the details you need
[02:49:00.000 --> 02:49:05.680]   to know as far as subscribing for this show. By the way, subscribing is the most important thing
[02:49:05.680 --> 02:49:12.240]   for us. If you are, you know, a fan of the show, you got to you got to subscribe. So twit.tv/twig,
[02:49:12.240 --> 02:49:17.280]   you'll find all the details to do that. If not that, then we hope that you'll join the club
[02:49:17.280 --> 02:49:25.120]   because that would support us directly. That's twit.tv/clubtwit. You go there, you pay $7 a month.
[02:49:25.120 --> 02:49:29.760]   You have the option to pay more if you like. We only say that because some people have actually
[02:49:29.760 --> 02:49:34.960]   asked for that feature. And so we added that feature. But if you do that, you get every single
[02:49:34.960 --> 02:49:40.400]   episode of every single show we do with no ads included. So all the ads are moved. You get access
[02:49:40.400 --> 02:49:45.680]   to bonus content that you don't get outside of the club, not only pre and post show content,
[02:49:45.680 --> 02:49:50.960]   put into a feed so you don't have to catch us live in order to get that stuff. But you also get
[02:49:50.960 --> 02:49:56.160]   extra shows like hands on windows, hands on Mac, home theater, gigs, the untitled Linux show.
[02:49:56.160 --> 02:50:02.800]   I mean, that Stacey's book club, when that happens, all sorts of extra stuff that Ant
[02:50:02.800 --> 02:50:08.400]   Pruitt has cooking. And then you get access to our Discord, which is always a ton of fun.
[02:50:08.400 --> 02:50:14.240]   And you find a lot of like-minded technology enthusiasts just like you hanging out in the
[02:50:14.240 --> 02:50:20.560]   Discord. So twit.tv/plubtwit. Big thanks to Leo for letting me fill in for him while he's gone.
[02:50:20.560 --> 02:50:24.400]   Next week, I'm sure he'll have tons of stories to share with you from Disneyland.
[02:50:24.400 --> 02:50:29.600]   But until then, thank you so much for watching. We'll see you next time on This Week in Google.
[02:50:29.600 --> 02:50:30.160]   Bye everybody.
[02:50:30.160 --> 02:50:36.880]   It's midweek and you really want to know even more about the world of technology.
[02:50:36.880 --> 02:50:41.280]   So you should check out Tech News Weekly, the show where we talk to and about the people making
[02:50:41.280 --> 02:50:45.920]   and breaking the tech news. It's the biggest news we talk with the people writing the stories that
[02:50:45.920 --> 02:50:50.080]   you're probably reading. We also talk between ourselves about the stories that are getting us
[02:50:50.080 --> 02:50:55.040]   even more excited about Tech News this week. So if you're excited, well, then join us. Head to
[02:50:55.040 --> 02:51:03.120]   twit.tv/tnw to subscribe.
[02:51:03.120 --> 02:51:08.560]   [Music]

