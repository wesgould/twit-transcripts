;FFMETADATA1
title=Sinkhole Ahead!
artist=TWiT
album_artist=TWiT
album=This Week in Google
track=415
genre=Podcast
comment=http://twit.tv/twig
copyright=These netcasts are released under a Creative Commons License - Attribution-NonCommercial-NoDerivatives 4.0 International. TWiT and TWiT Logo are registered trademarks of Leo Laporte.
publisher=TWiT
date=2017
encoder=Lavf59.27.100

[00:00:00.000 --> 00:00:05.840]   It's time for Twig this week in Google. We got a great panel for you. Stacey has the week off, but Aaron Nukem is here.
[00:00:05.840 --> 00:00:12.480]   We've got Mike Elgin and Jeff Jarvis visiting us from Australia. It's early in the morning there.
[00:00:12.480 --> 00:00:16.800]   We're going to talk about the latest news from Google. Actually, we've got Facebook's earnings.
[00:00:16.800 --> 00:00:23.040]   They came in just during the show. You won't believe your ears. It's all coming up next on Twig.
[00:00:23.040 --> 00:00:31.520]   NetCasts you love from people you trust.
[00:00:31.520 --> 00:00:43.040]   This is Twig. Bandwidth for this week in Google is provided by cashfly, C-A-C-H-E-F-L-Y.com.
[00:00:47.360 --> 00:00:55.440]   This is Twig. This week in Google, Episode 415, recorded Wednesday, July 26, 2017. Cincole ahead.
[00:00:55.440 --> 00:01:02.240]   This week in Google is brought to you by Rocket Mortgage from Quick and Loans. Home plays a big
[00:01:02.240 --> 00:01:07.040]   role in your life. That's why Quick and Loans created Rocket Mortgage. It lets you apply simply
[00:01:07.040 --> 00:01:11.120]   and understand the entire mortgage process fully so you could be confident you're getting the
[00:01:11.120 --> 00:01:18.160]   right mortgage for you. Get started at rocketmortgage.com/twig and buy LegalZoom.
[00:01:18.160 --> 00:01:22.960]   Prepare for your family's future within a state plan from LegalZoom. Visit LegalZoom.com and
[00:01:22.960 --> 00:01:30.160]   enter Twig at checkout for special savings. And buy Casper, an online retailer of premium mattresses
[00:01:30.160 --> 00:01:34.960]   for a fraction of the price because everyone deserves a great night's sleep. Get $50 off
[00:01:34.960 --> 00:01:40.880]   any mattress purchased by visiting Casper.com/twig and entering the promo code TWIG.
[00:01:40.880 --> 00:01:48.400]   It's time for Twig this week in Google to show we'd cover the latest news from Google,
[00:01:48.400 --> 00:01:54.480]   Facebook, media, whatever we want to talk about. Jeff Jarvis is here. He's all the way. It's early
[00:01:54.480 --> 00:02:00.000]   in the morning. He's all the way from Australia and Sydney. Wake up, Jeff, wake up, wake up.
[00:02:00.000 --> 00:02:04.720]   He's at the, where are you? The University of Technology, Sydney.
[00:02:04.720 --> 00:02:08.960]   Nice. My friend Peter Fray's office. I'm over here for the whole week.
[00:02:08.960 --> 00:02:12.960]   Yeah, I mean, yeah, I mean, yeah. But, um, so you're all so unfortunately, that means you're
[00:02:12.960 --> 00:02:18.400]   probably about an Australian time by now. Yes. Yeah. Which means it's really early in the morning.
[00:02:18.400 --> 00:02:24.960]   Otherwise it'd be evening. That's just right. It's just hard. Yeah, it's so hard. It's tomorrow.
[00:02:24.960 --> 00:02:29.920]   I'm telling you Thursday's bad. You don't want to stay in Wednesday. It's every day
[00:02:29.920 --> 00:02:37.200]   has been getting worse and worse. Are you kidding? Great. Great to have you at Jeff Jarvis, also joining
[00:02:37.200 --> 00:02:45.280]   us back after his stunning, stunning show on Sunday, Mount Gailgen from Gastronomad.net.
[00:02:45.280 --> 00:02:49.680]   He is, we're so glad we have you in the country for a little while. I'm glad to be in the country.
[00:02:49.680 --> 00:02:53.760]   Isn't your grandchild? Enjoy the country very much. Yeah. And it was a stunning show. I think I was
[00:02:53.760 --> 00:02:57.920]   stunned the entire time. It was actually a lot of fun. Yeah, that was a lot of fun. And yeah, it's,
[00:02:57.920 --> 00:03:04.480]   it's, you know, it's, I was in France in Southern Europe and just like right here,
[00:03:04.480 --> 00:03:08.960]   Sonoma County. The climate is almost. It is actually, isn't it? Yeah. It's just like Sonoma,
[00:03:08.960 --> 00:03:13.280]   but with castles and stuff. And French people history and culture. Yeah. We're going there in
[00:03:13.280 --> 00:03:18.400]   two months. Yeah. And actually, if you're going to, if you're interested in going somewhere,
[00:03:18.400 --> 00:03:24.080]   Mike and Amira, his wife are doing an amazing event in Barcelona coming up September 12th.
[00:03:25.200 --> 00:03:29.520]   So I believe that's right. If you go to Gastronomad.net, you can get the exact, if that's not it. I'm
[00:03:29.520 --> 00:03:33.680]   pretty sure that's it. Spend a week with them cooking, baking bread, the best baker in Spain.
[00:03:33.680 --> 00:03:37.440]   That's right. We, I stand behind that statement. That's awesome. Yes. Yes.
[00:03:37.440 --> 00:03:42.400]   What is, is Spanish bread any different than the, well, French bread, say, or Italian bread?
[00:03:42.400 --> 00:03:48.400]   It has lots of regional varieties, many of which are not generally available. But there's also a,
[00:03:49.440 --> 00:03:55.840]   pardon the pun, pan European bread culture. And so this baker parts of both. So it's,
[00:03:55.840 --> 00:04:00.400]   it's kind of French, kind of Spanish, really good bread. Yeah. And you're a good, I don't know
[00:04:00.400 --> 00:04:04.320]   people know, but Mike's an amazing baker. He really inspired me to do more baking. Thank you.
[00:04:04.320 --> 00:04:09.760]   And I'm obsessed with bread. I'm very, you know, I follow you on the Google plus bread community.
[00:04:09.760 --> 00:04:15.840]   Yes. Yes. The art of bread. It's a wonderful, if you really, if you don't mind the carbs,
[00:04:16.560 --> 00:04:21.120]   highly recommend the art of bread. Hey, look who else is here. Aaron Nukem is here. Hello, Aaron.
[00:04:21.120 --> 00:04:26.640]   Great to see you. Yeah. Yeah. It's been back. I don't know how long it's been boy. It seems like
[00:04:26.640 --> 00:04:32.720]   forever. Well, where are you working these days? Yeah. So I'm at New Relic, which is part of the
[00:04:32.720 --> 00:04:37.280]   reason I haven't been able to join as often as I'd like to. We use New Relic.
[00:04:37.280 --> 00:04:42.400]   Yeah. It's great software. If anybody needs application monitoring software, you should
[00:04:42.400 --> 00:04:46.000]   really check it out or even infrastructure monitoring, which is what I joined to help them.
[00:04:46.960 --> 00:04:52.080]   Develop is their infrastructure monitoring platform. So yeah, it's just busy as I'll get out here,
[00:04:52.080 --> 00:04:56.560]   as my dad would say. And so they don't give me much time, but I try to get on
[00:04:56.560 --> 00:05:03.920]   channels as often as I can on Floss Weekly twice in a row the past couple of weeks. So go back out
[00:05:03.920 --> 00:05:08.960]   and take a look at Floss Weekly if you missed those episodes. Yeah. We use New Relic to monitor
[00:05:08.960 --> 00:05:16.480]   the Twitter TV website. Yeah. From day one of your websites, applications, your hosts. So it
[00:05:16.480 --> 00:05:21.440]   makes it really easy. The thing that I love about it is you can really dive in if you're a data nerd.
[00:05:21.440 --> 00:05:24.080]   In fact, the people behind me, I don't know if you can see them walking back and forth. Those
[00:05:24.080 --> 00:05:29.040]   are our data scientists. I love data. So they're constantly digging in and trying to find insights
[00:05:29.040 --> 00:05:31.760]   and all the data we collect. So it's pretty cool. It's amazing. Yeah.
[00:05:33.120 --> 00:05:39.520]   So good news for you, Jeff. The Chromebook rumors are starting the rumor mill starting to pound.
[00:05:39.520 --> 00:05:51.600]   Chromebook Eve, which we've been seeing in the OS commits, Chrome OS commits since last October
[00:05:51.600 --> 00:05:59.520]   seems to be getting closer and closer. This would be if it is what people think it is,
[00:05:59.520 --> 00:06:05.040]   a replacement for this Google Pixel, which we're all desperate to get. The Pixel is kind of run
[00:06:05.040 --> 00:06:11.200]   through its end of life at this point. I lugged mine here so I can do the show and I love it dearly.
[00:06:11.200 --> 00:06:15.280]   But it's yeah, I'm waiting for the next one. It would be running the current seventh-generation
[00:06:15.280 --> 00:06:19.440]   KB Lake processor from Intel. That's one of the things Google did with its Pixel. It ran
[00:06:19.440 --> 00:06:26.320]   i5 processors and i3 processors. And then there's another thing that's kind of interesting that
[00:06:27.760 --> 00:06:32.000]   is actually a larger story, which is that Google may be eliminating the,
[00:06:32.000 --> 00:06:38.480]   I don't want to say it out loud, okay, Google features from the Chromebook, you know, where you
[00:06:38.480 --> 00:06:43.840]   invoke Google Assistant. Actually, it's not Google Assistant, it is. It's Google something.
[00:06:43.840 --> 00:06:48.320]   Something voice search or whatever it is. Seems like it's assistant. See, this is the confusion.
[00:06:48.320 --> 00:06:54.480]   It's the problem. And so I think they're heading toward hopefully a thing that when you talk to
[00:06:54.480 --> 00:06:58.720]   any Google thing, you know you're talking to the assistant. And that would be very nice.
[00:06:58.720 --> 00:07:04.480]   That's essentially what Apple does with Siri. There's only one A word at Amazon, even though
[00:07:04.480 --> 00:07:08.640]   that's widely distributed. And so when you get to Google, it's always been, it was like, is it
[00:07:08.640 --> 00:07:12.640]   Google now? Is it this? Is it that? And they really need to centralize it. I think it's a good thing.
[00:07:12.640 --> 00:07:18.880]   It's mostly branding. So the other rumor is, at least according to code in the OS repository,
[00:07:18.880 --> 00:07:26.400]   there will be a dedicated assistant key, which I like. I mean, I have it on Bixby, but who wants
[00:07:26.400 --> 00:07:33.120]   to talk to Bixby? Nobody Samsung. Is it a key word? No, a key, a physical like button that you'd
[00:07:33.120 --> 00:07:40.480]   press to say and now and then start talking. So I like that. Because I think a lot of times,
[00:07:40.480 --> 00:07:46.800]   you feel kind of dopey saying, okay, goog, and then talking. So I like to use also, can you also
[00:07:46.800 --> 00:07:53.520]   say, okay, you know who? This is what I'm reading from an article in Laptop Magazine. But I think
[00:07:53.520 --> 00:08:00.560]   that they may be quoting Chrome unboxed, which is a Chromebook, Chrome OS blog. They say that it's
[00:08:00.560 --> 00:08:06.880]   that the code in the repository suggests Google plans to deprecate, okay, Google functionality.
[00:08:06.880 --> 00:08:13.120]   Now I'm not sure if that's in only Chrome OS. I mean, that's what they know. But I wonder if
[00:08:13.120 --> 00:08:16.720]   Google might even be doing them more global way. I don't know. I don't know.
[00:08:16.720 --> 00:08:20.800]   And I suspect they will. What they really should do, what I'd really love to see Google do, and they
[00:08:20.800 --> 00:08:26.640]   probably won't do it, but they should have another hardware product, which would be earbuds,
[00:08:26.640 --> 00:08:30.640]   the hearables. I know you're a big fan of Apple's earbuds. A big fan of them. But what the way
[00:08:30.640 --> 00:08:36.160]   Google should work is that should automatically connect to whichever device is nearby that it
[00:08:36.160 --> 00:08:40.640]   already has permissions to connect. And then when you talk to this, when you talk to the Google
[00:08:40.640 --> 00:08:47.760]   Assistant, you can just do that. You can just talk. It'll be like the A word from Amazon, the Echo.
[00:08:47.760 --> 00:08:54.320]   And that would be killer because we're moving to a world where we just talk, be like Star Trek,
[00:08:54.320 --> 00:09:02.000]   and our virtual assistant talks back. And other companies, namely Amazon and Apple,
[00:09:02.000 --> 00:09:06.880]   are starting to take over that space, even though Google had the best assistant first.
[00:09:06.880 --> 00:09:10.720]   And I'd love to see them get back into it with more hardware like the home,
[00:09:10.720 --> 00:09:18.880]   but also like these earpods that Apple AirPods are wonderful. The way they were double tap them to
[00:09:18.880 --> 00:09:25.760]   get Siri to listen. Yes. And that is hit or miss, I think. It is. It's problematic. It also
[00:09:25.760 --> 00:09:32.240]   hurts your ear. I'd like to have it be keyword triggered. I think that would be perfectly fine.
[00:09:32.240 --> 00:09:37.760]   Or maybe have a user setting that you could do one or the other. Either way, we're going to the
[00:09:37.760 --> 00:09:42.800]   world where we just talk and something whispers in our ear. Let's get there. Let's hurry up and get
[00:09:42.800 --> 00:09:48.560]   there. There is a Wacun voice capability that is in the Chromebook Eve repository.
[00:09:48.560 --> 00:09:56.800]   But I think key mapping. I decided to read the original article by Gabriel Branger in
[00:09:56.800 --> 00:10:06.880]   Chromebook Chrome Unboxed. So this will be the first time a Google Assistant is on a Chrome OS
[00:10:06.880 --> 00:10:12.720]   device. And again, distinguishing it from Google Search, voice search. He says we've been tracking
[00:10:12.720 --> 00:10:17.760]   the new Chromebook Eve for some time now. And the longer we do, the more intriguing it becomes.
[00:10:17.760 --> 00:10:23.520]   So he's mentioning this. And here's the snippet, special keyboard mapping for Eve project. The
[00:10:23.520 --> 00:10:30.240]   keyboard has an extra assistant key. The commit looks to add key mapping for some
[00:10:30.240 --> 00:10:36.160]   combination of the eight key and another key yet to be discovered. The Wacun voice
[00:10:36.160 --> 00:10:39.760]   capability has been added to Chromebook Eve. So it does, I guess, still Wacun voice.
[00:10:39.760 --> 00:10:47.600]   But that's why I'm puzzled because the article I was reading in laptop magazines said they were
[00:10:47.600 --> 00:10:54.400]   in a deprecate. I guess they're deprecating. Okay. You know, okay, you know who but they could do.
[00:10:54.400 --> 00:11:00.240]   Yeah, I agree with you. You have to have a trigger of some kind, whether it's a button or a voice.
[00:11:00.240 --> 00:11:04.000]   But I love it. I'd love the Moto X where you could say whatever you want. And I thought that
[00:11:04.000 --> 00:11:07.360]   was much better. It's more secure, obviously, because people don't necessarily know your pass
[00:11:07.360 --> 00:11:11.120]   phrase. The problem with the Moto X, excuse me, is that you'd have to take it out of your, I mean,
[00:11:11.120 --> 00:11:14.640]   this is the first world problems. You have to take it out of your pocket. What would be ideal would
[00:11:14.640 --> 00:11:20.320]   be to have a Chromebook closed in your backpack or sitting in the seat next to you in the car.
[00:11:20.320 --> 00:11:24.080]   Powering those earbuds. Yeah, that would be great. Yeah, I would like that.
[00:11:24.080 --> 00:11:27.280]   Okay. I mean, they do have the technologies almost there, right? Yeah.
[00:11:27.280 --> 00:11:31.680]   I mean, I know when I'm sitting at home and I've got my phone out and I've got Google Home in the
[00:11:31.680 --> 00:11:37.440]   same room and I say the trigger word and ask it a question, they both hear me. Yes. And it'll say
[00:11:37.440 --> 00:11:42.320]   answering on another device. It always seems to answer when you're on the phone, it'll wake up
[00:11:42.320 --> 00:11:46.400]   the phone, but it always seems to answer on the home, right? It's like I had a built-in preference
[00:11:46.400 --> 00:11:52.400]   in the software. Yeah. On the Amazon Echo, because it has those beamforming array mics,
[00:11:52.400 --> 00:11:57.760]   it knows what you're closest to. So I almost always wake up multiple echoes when I say it,
[00:11:57.760 --> 00:12:03.280]   because I have a booming voice. But the one that answers me is always the one that nears me.
[00:12:03.280 --> 00:12:06.000]   That's how it should be. Mike, there's one other thing you need, though,
[00:12:06.960 --> 00:12:12.560]   for that laptop and your backpack, you need a cellular connectivity on it.
[00:12:12.560 --> 00:12:17.920]   Oh, yeah. You definitely need that. I missed that so much from the first pixel. I would kill
[00:12:17.920 --> 00:12:27.280]   for that the same with my pixel C. By the way, Mike is, oh, no, you're not, I keep making that
[00:12:27.280 --> 00:12:31.920]   mistake. You're using an iPad. It looks like you're using a pixel C, but it's not. That's right.
[00:12:31.920 --> 00:12:36.480]   He is using a tablet like you do, Jeff. Yeah. And I have the SIM card in there,
[00:12:36.480 --> 00:12:42.560]   so I have data and it's unlimited data plans. So I'm like, that's heaven. You got to have that.
[00:12:42.560 --> 00:12:47.200]   If you're going to be a Nomad, does it work overseas? I have to get a SIM card,
[00:12:47.200 --> 00:12:49.120]   like the local card. But then it does. But then it does.
[00:12:49.120 --> 00:12:54.960]   Yeah. I think that's a special case, because I think the reason they stop putting it in
[00:12:54.960 --> 00:12:59.200]   is because everybody already is paying for data on their phone. And nowadays,
[00:12:59.200 --> 00:13:01.520]   almost everybody has the ability to hotspot from their phone.
[00:13:01.520 --> 00:13:07.680]   And so, now, that's what, no, and that's, that's a matter of the business model.
[00:13:07.680 --> 00:13:10.640]   What you should be able to do is connect all your SIMs in one account,
[00:13:10.640 --> 00:13:15.200]   right? And just have it take them the same pool. If you can do that among family members,
[00:13:15.200 --> 00:13:19.200]   why can't you do that among devices? Exactly. And actually, AT&T, if you buy the new
[00:13:19.200 --> 00:13:24.320]   Android 2 watch, you can, you have a choice of having its own phone number and its own SIM,
[00:13:24.320 --> 00:13:32.720]   or using an app on your phone to use data from the, from, I'm not sure how it works, but I gather
[00:13:32.720 --> 00:13:37.520]   that it's a handoff, a handoff. Well, Google's project, Fi, you can, you get your main account,
[00:13:37.520 --> 00:13:41.760]   and then you can get up to 10, I think, additional SIM cards. I keep meaning to do that. That would
[00:13:41.760 --> 00:13:46.080]   be on the Fi account. It's on the same, the problem is it's not cheap anymore. When they first came
[00:13:46.080 --> 00:13:50.160]   out, they're like, Oh my gosh, look at these prices. But now there's all these unlimited
[00:13:50.160 --> 00:13:53.920]   things and deals have gotten much better. And now Google Fi is kind of on the pricey side.
[00:13:54.400 --> 00:13:59.360]   You know, you keep using a lot of data, you're going to pay for all that data. It's, it's in a
[00:13:59.360 --> 00:14:05.520]   way, it's kind of a boy. It's Mike isn't the best thing abroad. I love it. Yes. And I,
[00:14:05.520 --> 00:14:13.760]   you do, but when I go abroad, yeah, where so can I shop on the Fi store? Where would I do that?
[00:14:13.760 --> 00:14:21.360]   Oh, manage plan maybe or because I've got a fairly a five devices, which I didn't know about.
[00:14:22.560 --> 00:14:29.040]   Wait a minute, that can't be right. Are people buying SIM cards on my account? Five devices.
[00:14:29.040 --> 00:14:35.760]   Your monthly costs 70 bucks. Oh, oh, these are, okay, these are old devices.
[00:14:35.760 --> 00:14:41.760]   Okay, so here's where you do it. I get it. So I should probably get rid of these inactive devices.
[00:14:41.760 --> 00:14:47.040]   These are old Nexus six, the old pixel. You could employ a full time person just getting rid of
[00:14:47.040 --> 00:14:52.080]   your inactive devices. I have so much that I should just be a separate person just for Amazon.
[00:14:52.080 --> 00:14:56.640]   So add a data only sim using any compatible device or try to data coverage. And that's the
[00:14:56.640 --> 00:15:01.600]   same 10 bucks a month. Yeah, 10 bucks a gigabyte, I should say. Right. And then they, what do they
[00:15:01.600 --> 00:15:06.560]   charge you to get a sim? Oh, nothing's free. That's right. And you free sim. They'll send you several
[00:15:06.560 --> 00:15:12.080]   free sims. They want you to use data, you know, and you think about it. And the best thing about
[00:15:12.080 --> 00:15:17.520]   Google Fi is the clarity in the pricing model. So if I'm going to be in the US for three months,
[00:15:17.520 --> 00:15:21.280]   I just pause service for three months and they charge me nothing during those months.
[00:15:21.280 --> 00:15:25.440]   And then when I'm going to go abroad again, I just reactivate it. Half an hour later,
[00:15:25.440 --> 00:15:30.720]   I'm on the network in the foreign country. And it works really great. The only problem is that I
[00:15:30.720 --> 00:15:35.760]   use way too much data for this plan. I, you know, I think you're going to run up a bill of like 100
[00:15:35.760 --> 00:15:43.200]   bucks in a couple of hours recently. And yeah, I signed up for Google Fi recently. And I'm,
[00:15:43.200 --> 00:15:48.560]   I work on the ferry now back and forth to work in the morning, the afternoon. It works.
[00:15:48.560 --> 00:15:54.160]   Like even when you're in the bay in the middle, it's spotty, but I can get a connection. That's
[00:15:54.160 --> 00:15:57.760]   the reason I got five was because it will jump around from, from tower to tower, right?
[00:15:57.760 --> 00:16:04.160]   Yeah. And so I was trying to sprint a and a T mobile and Wi-Fi. So it'll find the best,
[00:16:04.160 --> 00:16:08.000]   if it could find anything. Yeah. So I figured I'd try it out. Unfortunately,
[00:16:08.000 --> 00:16:13.680]   I'm using about seven gig a month. So I think I'm going to go back to T mobile's one plan.
[00:16:13.680 --> 00:16:17.920]   They're unlimited plan because I just asked the cut off. I can't. That's the cut off because
[00:16:17.920 --> 00:16:23.440]   you have to pay 20 bucks for voice and text and then 10 bucks per gigabyte. So you're paying $90
[00:16:23.440 --> 00:16:27.920]   now, whereas you go to a T mobile 70 or $80 plan. Exactly. You're right at that. You're right at
[00:16:27.920 --> 00:16:33.520]   that. If Google can somehow take Google Fi and make it unlimited, that would be,
[00:16:33.520 --> 00:16:36.480]   forget about it. There would be no other. It'd be killer.
[00:16:36.480 --> 00:16:44.160]   By the way, there is a Google Fi referral challenge. So we can all fight over which
[00:16:44.160 --> 00:16:51.680]   Fi code. Who's Google Fi code? I think all four of us use Fi. That's interesting.
[00:16:51.680 --> 00:16:58.400]   Of course, it is this week in Google. So I guess the reason I bring this up is because
[00:16:58.400 --> 00:17:04.080]   Jeff is desperate for a new pixel. Yes. And it sounds like this Eve will be the Chromebook to get
[00:17:04.080 --> 00:17:08.320]   if whenever it comes out. It's got to be fairly close.
[00:17:09.760 --> 00:17:17.760]   Yeah, because the Samsung Pro and the ACESC 302 are good, but they're only four gigs of
[00:17:17.760 --> 00:17:23.600]   onboard memory. You want an 8 gig machine? You want an i5 processor?
[00:17:23.600 --> 00:17:29.920]   Yeah. Yeah. Touch screen, good screen. This screen will be three, two.
[00:17:30.720 --> 00:17:40.160]   According, this is all stuff gleaned from the Chrome OS repository. There's something
[00:17:40.160 --> 00:17:42.640]   in it's called double click. I don't know what that is.
[00:17:42.640 --> 00:17:50.320]   This is from Laptop Magazine. Third more perplexing, remember the Chrome unboxed uncovered
[00:17:50.320 --> 00:17:54.160]   is it can respond to a double tap similar to the Chromebook pixel.
[00:17:56.240 --> 00:18:00.320]   On the external, when it's closed, you can don't tap on the case.
[00:18:00.320 --> 00:18:02.320]   Oh, right. That way except that LED.
[00:18:02.320 --> 00:18:05.040]   Yeah. Yeah, could do other things.
[00:18:05.040 --> 00:18:09.680]   It's unclear what this will do, but Eve apparently doesn't have a light bar like the Pixel C does.
[00:18:09.680 --> 00:18:13.680]   Commits refer to some LEDs, but we don't know what they'll do. So that's interesting.
[00:18:13.680 --> 00:18:19.360]   That's interesting. So this is the code repository for Chrome OS.
[00:18:19.360 --> 00:18:23.680]   And as new devices come out, they start to add code to specific to those devices.
[00:18:23.680 --> 00:18:26.800]   And that's what since it's open source, that's what these guys are looking at.
[00:18:26.800 --> 00:18:31.680]   Other rumors fingerprint reader like that. Well,
[00:18:31.680 --> 00:18:35.040]   2400 by 1600 touch screen display. That's good.
[00:18:35.040 --> 00:18:39.200]   That's three by two, which the current one is.
[00:18:39.200 --> 00:18:41.200]   Yep. Is that right? Yeah, three by two.
[00:18:41.200 --> 00:18:44.560]   So it sounds like a good, it sounds like something to wait for.
[00:18:44.560 --> 00:18:48.160]   Jeff, if I'm going to be a betting man, what do you guys think?
[00:18:48.160 --> 00:18:52.080]   The current rumor, we're back in the rumor sphere again, but the current rumor is the
[00:18:52.080 --> 00:18:56.240]   Pixel will be an X, because it will be announced in October after Apple's event.
[00:18:56.240 --> 00:19:00.240]   Not before. So that's only a few months off.
[00:19:00.240 --> 00:19:05.280]   That would be a logical time to announce the one or two new phones and a new Chromebook.
[00:19:05.280 --> 00:19:09.520]   It's a little late for back to school though. If you wanted to get back to school, you'd want to do it now.
[00:19:09.520 --> 00:19:16.080]   But I'm not sure the schools, that's not a device for schools.
[00:19:16.080 --> 00:19:17.920]   It's too high end. It's too high end.
[00:19:17.920 --> 00:19:22.160]   The rest of the Chrome OS, the cheap OS.
[00:19:22.160 --> 00:19:23.440]   Yeah, that's a whole benefit.
[00:19:23.440 --> 00:19:26.240]   I bought Michael Zenering. It's going to be a freshman in high school.
[00:19:26.240 --> 00:19:29.120]   I bought him the Samsung Chromebook Plus, which I really like.
[00:19:29.120 --> 00:19:33.600]   That's a really nice lightweight, powerful, but easy to use machine.
[00:19:33.600 --> 00:19:35.680]   Right. Okay.
[00:19:35.680 --> 00:19:40.640]   Let's take a break. We're going to come back. We're going to talk about a lot of new things
[00:19:40.640 --> 00:19:44.400]   from Google was busy this week. SOS in Maps and Search.
[00:19:47.440 --> 00:19:51.200]   This international space station. You can now tour it in Street View.
[00:19:51.200 --> 00:19:55.840]   And a lot more, I think.
[00:19:55.840 --> 00:19:57.040]   And much, much more.
[00:19:57.040 --> 00:20:00.880]   Much, much more, which I haven't found yet, but I will find before this ad is over.
[00:20:00.880 --> 00:20:04.080]   I showed today, brought to you by Rocket Mortgage.
[00:20:04.080 --> 00:20:10.000]   If you're buying a house, unless you're, you know, you got some money and you're writing a check,
[00:20:10.000 --> 00:20:14.480]   chances are good, or bringing a briefcase full of cash, you're going to get a mortgage.
[00:20:14.480 --> 00:20:19.600]   You're going to get a home loan. Everybody does. But not all home loans are created equal.
[00:20:19.600 --> 00:20:23.040]   And certainly not all mortgage lenders are created equal. I want to encourage you to go to
[00:20:23.040 --> 00:20:27.760]   quick and loans, the best mortgage lender in the business. That's why year after year,
[00:20:27.760 --> 00:20:33.760]   they win those great JD Power Customer Satisfaction Awards. And they like geeks because they've created
[00:20:33.760 --> 00:20:40.160]   a brand new service, a completely online mortgage approval process called Rocket Mortgage.
[00:20:40.800 --> 00:20:46.080]   It's awesome. It's, first of all, you could do it all on your phone. You could do it.
[00:20:46.080 --> 00:20:49.040]   It's so fast you could do it at an open house and get approval before you leave.
[00:20:49.040 --> 00:20:56.000]   But you may say, but Leo, don't we have to fax them documents or hand carry our
[00:20:56.000 --> 00:21:01.680]   banker's box full of check stubs and pay statements and bank statements? Don't we have to?
[00:21:01.680 --> 00:21:07.600]   No, you don't because Rocket Mortgage from Quick and Loans is paired with all of the big
[00:21:07.600 --> 00:21:12.320]   financial institutions so they can just automatically send them to quick and loans,
[00:21:12.320 --> 00:21:16.240]   give them all the information they need. Just, you know, all you have to do is say,
[00:21:16.240 --> 00:21:23.120]   yes, do that, do that, do that. And then within minutes, they will chop the numbers
[00:21:23.120 --> 00:21:27.920]   and based on your income, your assets and your credit, they can give you exactly the home loan
[00:21:27.920 --> 00:21:32.560]   that's right for you. You can choose the right in term, of course, it's flexible, but it's
[00:21:32.560 --> 00:21:38.000]   transparent. You'll know how it's working. You'll know what's going on and you can be confident
[00:21:38.000 --> 00:21:44.240]   you're getting the best loan for you. Rocket Mortgage is here to lift the burden of getting a
[00:21:44.240 --> 00:21:50.000]   home loan. Apply simply, understand fully mortgage confidently. Go to rocketmortgage.com/twig,
[00:21:50.000 --> 00:21:55.920]   rocketmortgage.com/twig, equal housing, lender licensed to all 50 states and MLS consumer access
[00:21:55.920 --> 00:22:01.840]   dot org number 3030. And of course, if you go to rocketmortgage.com/twig, they'll know you heard
[00:22:01.840 --> 00:22:06.480]   it here, which is good for us. Rocket Mortgage from Quick and Loans, we thank them so much
[00:22:06.480 --> 00:22:14.640]   for the support of this week in Google. What was the YouTube boycott? I didn't, it says your YouTube
[00:22:14.640 --> 00:22:18.800]   ad boycott had minimal impact. Well, I didn't even know it was happening. So maybe that's why.
[00:22:22.400 --> 00:22:27.120]   So let's see here. This is YouTube boycott as minimal impact. This is a, oh, okay, this is part
[00:22:27.120 --> 00:22:33.520]   of the report on Google's quarterly results. Of course, a very big quarter.
[00:22:33.520 --> 00:22:43.600]   Net income was down 28%, but they still made $3.5 billion. The reason it was down is because
[00:22:43.600 --> 00:22:49.680]   they paid a two or I guess they took, I don't think they've paid it because they're appealing it,
[00:22:49.680 --> 00:22:55.600]   but they took a loss of $2.7 billion for the antitrust fund they got from the EC.
[00:22:55.600 --> 00:23:00.160]   That's nice. If you make so much money that you could pay a $2.7 billion fine and still make
[00:23:00.160 --> 00:23:05.520]   $3.5 billion. They just write it off. The funny thing is that the amount that
[00:23:05.520 --> 00:23:10.320]   Europe fined, that was a record fine, obviously, just keeps, it doubles every 18th month. It's like
[00:23:10.320 --> 00:23:16.320]   the European Moore's Law. That's not good. That's not good. So the next one will be in 18 months
[00:23:16.320 --> 00:23:20.720]   and it'll be, is that built into the law that it keeps going up or that's just the way it works?
[00:23:20.720 --> 00:23:26.000]   No, I just think that they keep noticing how deep Google's pockets are.
[00:23:26.000 --> 00:23:29.520]   That's really, it's more. Well, we got money. They got plenty left over.
[00:23:29.520 --> 00:23:38.800]   Search and display advertising revenue grew by 20% to $18.4 billion, $18.4 billion in revenue,
[00:23:38.800 --> 00:23:43.280]   $3.5 billion in profit. It's good work if you can get it, Leo.
[00:23:44.480 --> 00:23:49.120]   I didn't know this, but there was a YouTube brand safety boycott earlier this year.
[00:23:49.120 --> 00:23:52.960]   What was that? Apparently. That was major advertisers.
[00:23:52.960 --> 00:24:01.600]   That was Guardian, BBC, Havas, and others pulled back their ads from YouTube because of being
[00:24:01.600 --> 00:24:07.040]   next to bad stuff. And the financials had no impact. Google responded quickly and Google
[00:24:07.040 --> 00:24:09.920]   needed to because otherwise others could have left if they weren't responsive. So it did have
[00:24:09.920 --> 00:24:13.440]   an impact on their actions. It just didn't have an impact on their bottom line.
[00:24:14.400 --> 00:24:19.040]   Cost per click, this might be a cause for concern, cost per click down 26%
[00:24:19.040 --> 00:24:29.200]   on Google properties, 11% on display network member sites. But paid clicks increased by 61%.
[00:24:29.200 --> 00:24:33.520]   That's why their overall revenue went up even though the cost went down. Maybe that's part of the
[00:24:33.520 --> 00:24:39.920]   deal as the cost goes down, but they continue to grow the market. A 9% increase in paid clicks
[00:24:39.920 --> 00:24:46.080]   on Google display. Google paid out $3 billion to network members. That's up 15% year over year.
[00:24:46.080 --> 00:24:50.240]   So I guess you'd say the ad. Jeff, I'll defer to you on this, but I guess you say the ad market
[00:24:50.240 --> 00:24:56.320]   is healthy. It is. But one has to wonder whether the ad market starts to collapse at some point.
[00:24:56.320 --> 00:25:03.120]   Is there a point at which they're just a kick any bigger be there's so many other ways that
[00:25:03.120 --> 00:25:09.760]   people buy things. You know, we see this on the podcast revenues because there's
[00:25:09.760 --> 00:25:16.640]   so many more podcasts now, even though the pie is growing, the slices are getting smaller because
[00:25:16.640 --> 00:25:22.320]   there's so many different podcast companies. It's roughly an equal. I think we're down, we're
[00:25:22.320 --> 00:25:27.920]   probably down maybe 10% this year. It's the first year we'd be down ever. But I think that's because
[00:25:27.920 --> 00:25:33.200]   there's just so much competition. And I think it's probably the same thing in Google's sphere.
[00:25:33.200 --> 00:25:37.600]   And there are a huge number of podcasts that are just too small to make a penny.
[00:25:38.160 --> 00:25:44.960]   Less right. Yeah. And so they know that I hope. But that also has the sort of invisible effect of
[00:25:44.960 --> 00:25:51.280]   just kind of subtly draining away people's time, you know, away from. They're listening to them,
[00:25:51.280 --> 00:25:56.080]   right? Yeah, yeah, yeah. And that's true. They have small audiences. Everybody has a limited
[00:25:56.080 --> 00:25:59.920]   amount of time that they can pay attention to stuff like this. Yeah. And even those
[00:25:59.920 --> 00:26:04.080]   isn't related to podcasts related to advertising in general, but programmatic advertising in these
[00:26:04.080 --> 00:26:10.160]   marketplaces, these trading floors. They depress prices as well, right? It's tiniest competition.
[00:26:10.160 --> 00:26:14.880]   Yeah. And that depresses prices considerably. It commodifies media. So that has an impact on
[00:26:14.880 --> 00:26:18.880]   media as a whole. Now, podcasts should stand out from that because you can't just place any
[00:26:18.880 --> 00:26:24.800]   old generic ad anywhere. Oh, by the way, there's moves to do that in podcast too with insertion.
[00:26:24.800 --> 00:26:30.160]   Oh, I'm not. We will never do that because I don't believe. Well, I can't say we'll never do it,
[00:26:30.160 --> 00:26:34.720]   but which I would prefer not to do it. I don't believe in that. I think that you're exactly
[00:26:34.720 --> 00:26:39.360]   right, Jeff. That's what differentiates our advertising from just run of the mill media. But
[00:26:39.360 --> 00:26:44.320]   there's lots of pressure from advertisers. I also think it's an opportunity. The way that
[00:26:44.320 --> 00:26:51.040]   you do ads on this network is kind of a it's a it's a respite. So as the outside world where the
[00:26:51.040 --> 00:26:57.280]   advertisements get more and more intrusive, you know, automatically running video, all this noise
[00:26:57.280 --> 00:27:04.320]   and just irritating ads in your face all the time, it's nice to go to the Twit Network and
[00:27:04.320 --> 00:27:08.320]   hear ads that the way you do them. But we're just kind of conversational. Exactly.
[00:27:08.320 --> 00:27:08.880]   Yeah, exactly.
[00:27:08.880 --> 00:27:15.840]   But advertising that works. Well, I want to make it all about us. But I do think that there's a
[00:27:15.840 --> 00:27:21.600]   now that podcasting is having a renaissance, which always makes me laugh because we've been
[00:27:21.600 --> 00:27:26.800]   here 12 years, but now that there's a renaissance of podcasting and the media world, particularly
[00:27:26.800 --> 00:27:31.520]   New York is sitting up and taking notice because there's a lot of podcasts coming out of media in
[00:27:31.520 --> 00:27:37.600]   New York. There's a lot of pressure. There's more money in it, but there's also a lot of pressure to
[00:27:37.600 --> 00:27:42.880]   kind of conform to other media. People want it to be to work the same way it works in radio and TV.
[00:27:42.880 --> 00:27:46.720]   So there's up fronts now. They're looking at insertion. They're looking at
[00:27:46.720 --> 00:27:52.720]   terms from the IAB, the interactive advertising bureau that are less favorable to
[00:27:52.720 --> 00:27:58.560]   podcasters, more favorable to advertisers. So we knew this was coming. I kind of like the day. I
[00:27:58.560 --> 00:28:03.760]   always liked the days when podcasting was kind of the little lesser known cousin of mainstream media.
[00:28:03.760 --> 00:28:07.840]   Nobody really knew what about us. It's not like that anymore. Everybody knows about podcasts now.
[00:28:07.840 --> 00:28:14.240]   So it's changing. Half the podcast were yours. Those were the days when I was the only podcaster.
[00:28:14.240 --> 00:28:20.800]   I had a monopoly on a tiny tiny. I'd rather be a big fish in a little pond. I admit it.
[00:28:22.240 --> 00:28:31.120]   Shrink that pond down. Draying the swamp or something. Let's see. So good news for, I would say overall,
[00:28:31.120 --> 00:28:36.640]   for Google, less money per click. They have this very similar, isn't it? Less money per clip,
[00:28:36.640 --> 00:28:41.120]   click, but the pond is growing bigger. So that makes up for it.
[00:28:41.120 --> 00:28:46.560]   Clicks on its ads, according to alphabets, surged 52%. Wow, more clicks.
[00:28:47.600 --> 00:28:53.680]   Wow. What does that mean? I mean, advertisers are getting savvier about making ads that work.
[00:28:53.680 --> 00:29:02.240]   I think it might have something to do with better targeting. Everybody hates ad targeting.
[00:29:02.240 --> 00:29:07.760]   Right, Aaron, everybody says, "Oh, don't track me, bro." But at the same time, I would far
[00:29:07.760 --> 00:29:11.280]   perfursus he adds for products and interest and then adds for stuff I have no interest in and
[00:29:11.280 --> 00:29:18.960]   why waste my time. Yeah, that's exactly right. And so fewer clicks, or if you earn less for each
[00:29:18.960 --> 00:29:25.200]   click, but you're more productive in presenting what people want, that's okay.
[00:29:25.200 --> 00:29:34.800]   So you're trading the high dollar amount for the volume in that case, and people are happier.
[00:29:36.000 --> 00:29:42.240]   The other thing that's happening is the distribution of advertising is becoming sort of going
[00:29:42.240 --> 00:29:46.000]   underground and becoming more subtle. And what I mean by that is that the rise in experiential
[00:29:46.000 --> 00:29:51.120]   marketing means that marketers and advertisers are not actually creating content. What they're
[00:29:51.120 --> 00:29:56.080]   doing is they're creating Instagrammable experiences, and then consumers are
[00:29:56.080 --> 00:30:00.240]   Instagramming them, and they're creating the content and they're distributing the content on
[00:30:00.240 --> 00:30:04.880]   social. And that's kind of like this weird new world where like, how do you measure it? How do you
[00:30:04.880 --> 00:30:10.000]   control it? And so you don't know how much of those sort of ad budgets are being drained off
[00:30:10.000 --> 00:30:13.040]   from advertising, which you can measure, you can measure clicks and all that stuff,
[00:30:13.040 --> 00:30:20.880]   into this experiential marketing universe, which again, with augmented reality is just going to be
[00:30:20.880 --> 00:30:28.240]   a huge form of marketing. Great article today in Buzzfeed by Alex Cantrowitz, who's talking about
[00:30:28.240 --> 00:30:35.600]   how money is going away from buying ads, and instead it's going to promoting
[00:30:35.600 --> 00:30:40.320]   favorable news coverage. And this is exactly what you're talking about. Fascinating. Fascinating.
[00:30:40.320 --> 00:30:45.840]   And that's good marketing, right? Promote a positive review of your product. That's better than an ad.
[00:30:45.840 --> 00:30:49.760]   Oh, yeah, much better. But once again, the content creators are the users.
[00:30:49.760 --> 00:30:53.280]   Are they making any money on that? Why didn't didn't match more good clicks?
[00:30:54.880 --> 00:31:02.240]   Let's see. So yeah, that's interesting. So here's an example. Mashable wrote a positive
[00:31:02.240 --> 00:31:08.960]   review of an app called Blind. What Blind did is buy on Facebook,
[00:31:08.960 --> 00:31:15.280]   see suggested post links, not to an ad in effect, but to the Mashable review.
[00:31:15.280 --> 00:31:20.400]   And of course, Mashable doesn't get any of that money. It all goes to Facebook. But
[00:31:21.040 --> 00:31:25.440]   if you click on the article, Leo, you would go to the to the Mashable review and they get
[00:31:25.440 --> 00:31:31.120]   more traffic. It says the post drove more than 11,000 visits to the app download page, which was,
[00:31:31.120 --> 00:31:36.160]   I guess, linked Mashable, which sells advertising to companies like Blind didn't see a dime.
[00:31:36.160 --> 00:31:44.240]   Not that way. In other words, Blind didn't buy an ad on Mashable. But it's benefits Mashable.
[00:31:44.240 --> 00:31:49.920]   And this is instead of buying an ad, instead of buying a normal ad on Facebook. So I think this
[00:31:49.920 --> 00:31:55.200]   is beneficial to everybody. Facebook still gets the same amount of money. Blind gets better promotion
[00:31:55.200 --> 00:31:59.680]   and Mashable, which wouldn't have gotten any money from an ad, gets some traffic.
[00:31:59.680 --> 00:32:05.760]   Here's the dark side. The dark side is that the people who work at Mashable, young kids out of
[00:32:05.760 --> 00:32:11.760]   college writing these articles are now now the massive incentive to write positive reviews so
[00:32:11.760 --> 00:32:16.080]   that they will get traffic. Now, now in order to get traffic, it's not about clickbait. It's about
[00:32:16.080 --> 00:32:20.880]   sucking up to Microsoft sucking up to other companies so that they link to you and you can go to your
[00:32:20.880 --> 00:32:24.880]   editor and say, "Oh, look at all the traffic I'm generating with my articles." And it's back to
[00:32:24.880 --> 00:32:30.160]   paper post. Yeah. Yeah. Yeah. Yeah. Paper post. And as this BuzzFeed article points out, advertisers
[00:32:30.160 --> 00:32:35.760]   are going to send Facebook wins because advertisers send money to Facebook instead of to Mashable.
[00:32:35.760 --> 00:32:42.640]   Facebook wins anyway. Yes. That Casper did this. Now, I guess it would affect us as well, right?
[00:32:43.200 --> 00:32:49.120]   Casper repurposed a BBC story as a Facebook ad promoting its product. A local plumbing company
[00:32:49.120 --> 00:32:53.200]   in Texas used a Dallas Morning News article about a water main break to promote its service.
[00:32:53.200 --> 00:32:59.840]   Facebook itself recently promoted an ad-age article to hype its video offering. So, here's
[00:32:59.840 --> 00:33:04.720]   a sponsored post, Facebook Business, which links to ad-age. Facebook has a message for marketers
[00:33:04.720 --> 00:33:10.400]   ahead of Cairns. All digital is not the same. And this is one of those things like for a while,
[00:33:10.400 --> 00:33:18.320]   it was it was, you know, every time there's a new type of controversial ad format, everybody tries it.
[00:33:18.320 --> 00:33:25.760]   Native advertising like came and didn't quite go again, but it's like it became a thing everybody
[00:33:25.760 --> 00:33:31.360]   was trying to see if it was a good fit. I hope this experiment fails for everybody because this is,
[00:33:31.360 --> 00:33:34.960]   this is- I don't think it will. I think native failed because it felt skeasy. It felt like it
[00:33:34.960 --> 00:33:41.680]   was a trick, right? But this is clearly an ad and it's linking to a legitimate article. Well,
[00:33:41.680 --> 00:33:45.360]   that's going to be the question I agree that maybe this article will become over time.
[00:33:45.360 --> 00:33:51.200]   This will sub-born the best intentions of these publications, but at least for now,
[00:33:51.200 --> 00:33:57.760]   publishes- Here's the danger, Lael. Right. So, we have a Casper ad here. If somebody else writes,
[00:33:58.320 --> 00:34:05.760]   if Jason Caliconis writes a glowing Casper review, just knowing he's going to screw you,
[00:34:05.760 --> 00:34:11.280]   do they stop advertising with you? No. Well, yeah, they might- So what could happen is-
[00:34:11.280 --> 00:34:16.560]   Casper could buy an ad on Facebook pushing the Calicanis' article, but that's not Calicanis' fault.
[00:34:16.560 --> 00:34:20.720]   And it's a different kind of- I'm making a Jason joke is all- I know.
[00:34:20.720 --> 00:34:25.040]   I'm saying this. Does this change advertising such that they stop-
[00:34:25.040 --> 00:34:25.600]   Oh.
[00:34:25.600 --> 00:34:29.440]   So what you're- So again, they said they do this. Right. And this might
[00:34:29.440 --> 00:34:35.680]   incent a whole new demand media style business where people write positive articles. But see,
[00:34:35.680 --> 00:34:39.120]   I don't think that that's it. Because again, that's going to look skeasy because it's going to be
[00:34:39.120 --> 00:34:44.400]   people- You've got to push to a legitimate source of this positive review where it's just-
[00:34:44.400 --> 00:34:49.360]   But left in the dust is the legitimate article that was critical.
[00:34:49.360 --> 00:34:50.640]   Well, that's true. It's a good- Well, that's true.
[00:34:50.640 --> 00:34:55.920]   Fuse the favorability. It also skews the algorithms because Facebook says, "Oh, everybody's linking
[00:34:55.920 --> 00:35:02.960]   to this article." What did you do? So when you were running Windows Magazine, if you had a positive
[00:35:02.960 --> 00:35:09.040]   review of a product, did the product come to you and say, "Can we put that- a link to that on our
[00:35:09.040 --> 00:35:12.560]   web page?" Well, when I started Windows Magazine, there was no web.
[00:35:12.560 --> 00:35:15.600]   Or- Or-
[00:35:15.600 --> 00:35:16.640]   It happened-
[00:35:16.640 --> 00:35:20.160]   Newspaper ads. Yeah. No. If people- I mean, it's free speech issue.
[00:35:20.160 --> 00:35:24.880]   Windows Magazine gives it five stars. You can't- Or Cisco and Ebert say two thumbs up.
[00:35:24.880 --> 00:35:28.960]   You can't stop that. Right. Exactly. And we wouldn't try. And they would even put that stuff in ads
[00:35:28.960 --> 00:35:34.000]   that appeared in Windows Magazine. And that was fine. At least you got some revenue.
[00:35:34.000 --> 00:35:39.760]   But we get asked that all the time, "Can we use- So let's say we do a segment. Now I realize
[00:35:39.760 --> 00:35:43.680]   what's going on. This, this, we'll do a segment on a product. And that company will then say,
[00:35:43.680 --> 00:35:47.120]   "Can we embed that on our web page?" And would usually- In fact, we always say no.
[00:35:47.120 --> 00:35:49.760]   Yeah. Well, what you should do- But I don't think we can really stop it.
[00:35:49.760 --> 00:35:52.880]   Here's what you should do. Turn this thing around to your own advantage.
[00:35:52.880 --> 00:35:59.840]   So you have- Let's say you have several ads on your shows. You could go to one of those
[00:35:59.840 --> 00:36:05.440]   advertisers and say, "Look, here's how much you spent on the ad. Take that money, instead,
[00:36:05.440 --> 00:36:10.640]   we'll do the ad for free if you take that money and advertise links to the show."
[00:36:11.280 --> 00:36:15.760]   In other words, you could turn as payment for some of your advertisers into promotions.
[00:36:15.760 --> 00:36:19.760]   I'd rather have cash. Yeah. Cash is nice. Give me cash.
[00:36:19.760 --> 00:36:23.680]   Give me wrong. Cash is good. Well, I think this is the kind of thing will happen, in fact.
[00:36:23.680 --> 00:36:27.600]   Who knows? Maybe Mashable did say something like that. We don't know.
[00:36:27.600 --> 00:36:35.040]   Because traffic is valuable. So it's good for everybody, at least now. Mashable got traffic.
[00:36:35.040 --> 00:36:38.960]   Traffic is less valuable. It's less valuable than the dollar.
[00:36:38.960 --> 00:36:43.680]   And Facebook gets a new kind of- So we were talking just a few minutes ago about how Google
[00:36:43.680 --> 00:36:48.480]   and Facebook have to find new ways to get new pieces of the pie they advertise in. This is a new
[00:36:48.480 --> 00:36:51.440]   kind of advertising. Chatham, what do you think? What do you think? What do you think?
[00:36:51.440 --> 00:36:56.000]   The consumers- I think these are ads. These are better than regular ads.
[00:36:56.000 --> 00:36:59.920]   Because they point to it in hopes of trusted third-party that's recommending the product.
[00:36:59.920 --> 00:37:04.320]   Sources sent to us trusted not Sally's- Yeah. It has to be trusted.
[00:37:04.320 --> 00:37:10.400]   Yeah. There have been studies that indicate that socially shared content is more trustworthy than
[00:37:10.400 --> 00:37:14.800]   advertising. But that's usually socially shared from a friend of yours.
[00:37:14.800 --> 00:37:20.560]   Exactly. So sharing a Mashable article or advertising with a link to Mashable article wouldn't
[00:37:20.560 --> 00:37:27.040]   count it that level. But see, this changes the algorithms. If enough people click on that ad,
[00:37:27.040 --> 00:37:31.280]   Facebook sees that people are going to the article, Google sees that articles get
[00:37:31.280 --> 00:37:34.720]   lots of traffic. People share it more because it comes up in their algorithms.
[00:37:34.720 --> 00:37:40.480]   And it's like they're trying to create a sort of virality. You heard it here first. We warned you
[00:37:40.480 --> 00:37:45.120]   first. You're going to see more of these ads. I think it's a better question.
[00:37:45.120 --> 00:37:55.040]   One more question. If so, I saw a sponsor post for the Cardio, the EKG that we've talked about in
[00:37:55.040 --> 00:37:59.360]   the show. It's a sponsor post. They bought it. But I like the product. So I shared the
[00:37:59.360 --> 00:38:03.200]   response. Oh, wow. This thing works. Do they pay for that?
[00:38:03.200 --> 00:38:11.200]   No. You gave them free. I gave them free advertising. In fact, I think probably people
[00:38:11.200 --> 00:38:16.480]   create native content. That's one of the side benefits. The potential to get more
[00:38:16.480 --> 00:38:19.840]   traffic by having that be shared. To me, the most important thing is
[00:38:19.840 --> 00:38:25.440]   advertising is good. And the good advertising is good. Bad advertising is bad. We're all sick of
[00:38:25.440 --> 00:38:31.520]   the really junky, garbage-y advertising. But we really, really want advertising. This is why
[00:38:31.520 --> 00:38:38.320]   I know I think that you've praised Medium's move to paid. Yeah. At first, I was suspect. And I know
[00:38:38.320 --> 00:38:44.480]   Jeff, I think probably still is. But it worked for me because Barrett-Tunday became hidden behind a
[00:38:44.480 --> 00:38:48.000]   paywall. It was five bucks a month. And I bought it because I wanted to see his article. Five bucks
[00:38:48.000 --> 00:38:54.160]   a month is a lot of money for a lot of people. Essentially, it's creating a... You basically,
[00:38:54.160 --> 00:38:58.240]   it would be great if all medium content was available to everyone with an internet connection
[00:38:58.240 --> 00:39:02.640]   globally. Unfortunately, $5 can be like somebody's weekly salary in lots of parts of the world.
[00:39:02.640 --> 00:39:07.200]   And they're just... They just can't afford to read Medium. And that further advantages people who
[00:39:07.200 --> 00:39:14.160]   are already advantaged. And so if you just make content, advertisers reported, those of us who
[00:39:14.160 --> 00:39:18.960]   buy the products are subsidizing it so that the whole world can see that content. I think that's
[00:39:18.960 --> 00:39:25.200]   better. Advertising is good. Yeah. You've said that before. Yes. It's democratizing.
[00:39:25.200 --> 00:39:30.880]   And I actually, as somebody who's always worked in ad supported free media, I agree.
[00:39:30.880 --> 00:39:36.400]   Yeah. It's a bad thing on the one hand thing. Nobody likes ads, right? So it's a bad thing in
[00:39:36.400 --> 00:39:42.960]   that respect. But let's remember what it buys us. It buys us a world, a beautiful world,
[00:39:43.520 --> 00:39:49.680]   in which it's a redistribution of wealth that is voluntary. I mean, it's beautiful.
[00:39:49.680 --> 00:39:55.440]   It does not touch the issue. In this age of fake news to redline journalism and make it the
[00:39:55.440 --> 00:39:59.520]   product only for the elite is only for the past. That would be bad. That would be bad. Yeah.
[00:39:59.520 --> 00:40:03.280]   That's a very good point. Yeah. Because if you're a cheap scale like me, you're going to end up
[00:40:03.280 --> 00:40:07.840]   going to another source anyway. Right. So that's what happens when I hit... Mr. Cheapskate.
[00:40:07.840 --> 00:40:11.760]   Do you pay for any news? Do you pay for the New York Times or the Washington Post or anything?
[00:40:11.760 --> 00:40:17.280]   I do not. I do not. And if I see a story there and I hit a paywall, I'll just go to another source.
[00:40:17.280 --> 00:40:19.920]   I do that with financial times.
[00:40:19.920 --> 00:40:28.480]   Yeah. I just say, well, I guess I can't read that. Yeah. It's terrible. That's it. Really.
[00:40:28.480 --> 00:40:32.400]   I think what you're arguing for is true is that this does need to be free and open.
[00:40:32.400 --> 00:40:38.240]   And that's the best way to get the good stories out there. Because what happens is,
[00:40:38.240 --> 00:40:43.440]   what if I'm not me? What if I'm someone who maybe doesn't know the difference when they take a look
[00:40:43.440 --> 00:40:48.880]   at a story and I hit the Wall Street Journal and I can't get through and I end up going to the fake
[00:40:48.880 --> 00:40:52.640]   news. Right? It's a similar headline, but it has a totally different... The fake news will always be
[00:40:52.640 --> 00:40:56.560]   free. Because it has an agenda. Exactly. Exactly. The other thing is that when
[00:40:56.560 --> 00:40:59.920]  ... That's really interesting. When organizations depend on advertising,
[00:40:59.920 --> 00:41:03.920]   they are vulnerable to boycotts and things like that. I mean, look at what's happened with Fox News
[00:41:03.920 --> 00:41:09.280]   and a couple of shows on Fox News where there was some objectionable activity by one or two of the
[00:41:09.280 --> 00:41:13.680]   hosts and everybody went after their advertisers and they went on vacation and spent more time
[00:41:13.680 --> 00:41:19.600]   with their family and all this kind of stuff. The public can put pressure on semi-fake news,
[00:41:19.600 --> 00:41:24.480]   semi-real news type news organizations to squeeze their advertisers. So if all this is true,
[00:41:24.480 --> 00:41:29.840]   we want to keep ads supported free media. One of the charges then would be to make advertising
[00:41:29.840 --> 00:41:35.760]   more palatable. Both more... And that's why I like this idea of sharing an article because it's
[00:41:35.760 --> 00:41:41.600]   more palatable, it's more effective. Yeah. It's... But theoretically, nobody likes the idea like you
[00:41:41.600 --> 00:41:45.760]   said a minute ago, but nobody likes the idea of targeting. But if targeting really worked,
[00:41:45.760 --> 00:41:49.680]   it wouldn't feel like advertising. It'd be like, "Oh, we know what you want. This is exactly what...
[00:41:49.680 --> 00:41:53.760]   Looking for a car? You know, let's talk about it." I mean, I spend a lot of time searching for things
[00:41:53.760 --> 00:41:58.160]   that I want. I'd love it for just come to me and say, "Look, this is..." Well, that's kind of what...
[00:41:58.160 --> 00:42:03.760]   So we don't need to track you and find out what your interests are. One of the reasons a very
[00:42:03.760 --> 00:42:09.680]   niche network like this works is because it's very thin slice of the populace. But we know,
[00:42:09.680 --> 00:42:16.160]   but if you want to talk to geeks, we're a great way to do it. And in fact, every time we've diverged,
[00:42:16.160 --> 00:42:21.440]   it's really... I should have known this, but every time we've diverged from hardcore geekdom,
[00:42:21.440 --> 00:42:26.560]   those shows don't make it. They don't get the audience and they don't get the ads.
[00:42:27.360 --> 00:42:32.080]   So the shows that do the best here are the hardest core geek shows.
[00:42:32.080 --> 00:42:37.440]   And the stuff you advertise is not... Again, don't want to make it all about a twit,
[00:42:37.440 --> 00:42:39.680]   but like a stuff... Well, Rocket Mortgage is interesting. There's an example,
[00:42:39.680 --> 00:42:42.240]   because that's a mainstream business. Well, no, no, but mortgage lenders.
[00:42:42.240 --> 00:42:44.480]   No, but it's... But they want to get geeks.
[00:42:44.480 --> 00:42:50.160]   What geeks do is not just interested in geeks. They're open to alternative new ways to do things.
[00:42:50.160 --> 00:42:52.800]   Right. Even if it's a bed and things like that. That's a good point too.
[00:42:52.800 --> 00:42:57.440]   Right. It's a... Taspur, Harry's Dollar Shaper. That's a very good point.
[00:42:57.440 --> 00:43:01.520]   Yeah. Geeks are open-minded about new innovations by definition.
[00:43:01.520 --> 00:43:03.920]   Yeah. Okay. Well, it's an interesting world we live in.
[00:43:03.920 --> 00:43:07.680]   So, breaking news, the Facebook results are out.
[00:43:07.680 --> 00:43:11.200]   Oh, let's go check them out. How bad/good is it?
[00:43:11.200 --> 00:43:14.400]   Oh, it's tremendous again.
[00:43:14.400 --> 00:43:16.080]   I guess they made money. I'm guessing.
[00:43:16.080 --> 00:43:17.920]   So... Oh, yeah.
[00:43:17.920 --> 00:43:21.120]   Before we get into... Two billion users.
[00:43:22.480 --> 00:43:25.440]   We're seeing... This is a live blog from us from MarketWatts.
[00:43:25.440 --> 00:43:26.800]   Two billion too many, if you ask me.
[00:43:26.800 --> 00:43:29.280]   We knew that it was going to hit two billion.
[00:43:29.280 --> 00:43:37.280]   The biggest quarter ever for hires, they're growing.
[00:43:37.280 --> 00:43:42.240]   I'm going backwards. So, this is backwards in time.
[00:43:42.240 --> 00:43:51.520]   Expenses are going to grow for the year. Oh, this is a story up 40 to 50% compared to
[00:43:52.080 --> 00:43:53.360]   big growth in expenses.
[00:43:53.360 --> 00:43:55.840]   This is a Wall Street Journal has a story up there.
[00:43:55.840 --> 00:43:56.560]   This is a story that does grow.
[00:43:56.560 --> 00:43:58.320]   I pay for the Wall Street Journal. So, let's...
[00:43:58.320 --> 00:44:01.360]   Let's get what you paid.
[00:44:01.360 --> 00:44:02.400]   No, pay well for you.
[00:44:02.400 --> 00:44:03.440]   No, pay well for me.
[00:44:03.440 --> 00:44:06.800]   Facebook profit jumps 71%.
[00:44:06.800 --> 00:44:09.120]   God, it's terrible.
[00:44:09.120 --> 00:44:11.040]   71%.
[00:44:11.040 --> 00:44:16.720]   Oh, man. And me without any tech stocks.
[00:44:16.720 --> 00:44:19.040]   Holy...
[00:44:20.480 --> 00:44:21.520]   Geez, Louise.
[00:44:21.520 --> 00:44:23.200]   Profit rose.
[00:44:23.200 --> 00:44:24.080]   Leo, it's like...
[00:44:24.080 --> 00:44:27.840]   Are you like the Donald Trump of the tech world that if you close down
[00:44:27.840 --> 00:44:31.680]   Twitch and took all of your money and just put it in tech stocks,
[00:44:31.680 --> 00:44:33.920]   which you can't get now, would you make more money than you do from Twitch?
[00:44:33.920 --> 00:44:34.480]   Yeah, probably.
[00:44:34.480 --> 00:44:35.920]   Oh, absolutely.
[00:44:35.920 --> 00:44:36.960]   If you put...
[00:44:36.960 --> 00:44:38.800]   The right tech stock.
[00:44:38.800 --> 00:44:39.120]   Right.
[00:44:39.120 --> 00:44:41.040]   I know. It's so funny now because
[00:44:41.040 --> 00:44:46.160]   I have a lot of friends who are angel investors
[00:44:46.160 --> 00:44:48.720]   and got into it for whatever reason.
[00:44:48.720 --> 00:44:50.960]   They're younger than I am, maybe in their 30s.
[00:44:50.960 --> 00:44:54.000]   And many of these people are...
[00:44:54.000 --> 00:44:57.760]   You know, are huge successes because they invested in
[00:44:57.760 --> 00:44:59.360]   Uber and Twitter.
[00:44:59.360 --> 00:45:01.360]   But as I see and companies like that,
[00:45:01.360 --> 00:45:04.320]   as I see those companies start to fail and falter,
[00:45:04.320 --> 00:45:08.400]   these people don't look like the geniuses that they were four years ago, right?
[00:45:08.400 --> 00:45:10.080]   I got in at the beginning on Uber.
[00:45:10.080 --> 00:45:11.680]   I still haven't made any money.
[00:45:11.680 --> 00:45:13.440]   I got in at the beginning at Twitter.
[00:45:13.440 --> 00:45:14.640]   Oh, that stock's good.
[00:45:14.640 --> 00:45:15.280]   Yeah.
[00:45:15.280 --> 00:45:16.160]   Are you happy now?
[00:45:16.720 --> 00:45:19.920]   So, you know, I bought Yahoo when it was...
[00:45:19.920 --> 00:45:20.240]   Right.
[00:45:20.240 --> 00:45:20.720]   Right.
[00:45:20.720 --> 00:45:21.600]   Twenty dollars.
[00:45:21.600 --> 00:45:22.880]   It's like...
[00:45:22.880 --> 00:45:23.600]   But all into my space.
[00:45:23.600 --> 00:45:26.400]   I do have a friend and it's actually kind of a tragic story
[00:45:26.400 --> 00:45:31.520]   who worked at Waze, which was a database company that was purchased by Yahoo.
[00:45:31.520 --> 00:45:34.640]   And in the purchase he got a lot of Yahoo stock.
[00:45:34.640 --> 00:45:37.840]   Was it Yahoo or AOL?
[00:45:37.840 --> 00:45:39.840]   I know it was AOL, even worse.
[00:45:39.840 --> 00:45:43.760]   He got a lot of AOL stock and did not diversify.
[00:45:43.760 --> 00:45:46.400]   Probably should have.
[00:45:46.400 --> 00:45:47.040]   Probably should have.
[00:45:47.040 --> 00:45:49.840]   So, he was living high on the hog for a while.
[00:45:49.840 --> 00:45:52.400]   But now not so much.
[00:45:52.400 --> 00:45:54.800]   Wow.
[00:45:54.800 --> 00:45:55.520]   Yeah.
[00:45:55.520 --> 00:45:58.640]   So, that's why, yes, maybe I would if I invested in the right stocks,
[00:45:58.640 --> 00:46:00.960]   but I think I'll just stick with what I'm doing right now.
[00:46:00.960 --> 00:46:05.840]   I like the small slow growth of Twit as opposed to the potential.
[00:46:05.840 --> 00:46:09.840]   Seventy one percent earnings per share of a buck 32.
[00:46:09.840 --> 00:46:11.920]   That's up from 78 cents.
[00:46:11.920 --> 00:46:15.840]   Analysts thought, okay, they thought they'd do a dollar 12.
[00:46:15.840 --> 00:46:17.200]   They did a dollar 32.
[00:46:17.200 --> 00:46:22.800]   You know, it really bothers me when that Facebook is so successful.
[00:46:22.800 --> 00:46:24.400]   I think they are too powerful.
[00:46:24.400 --> 00:46:28.240]   They can just pick the president with a secret tweet to their algorithm
[00:46:28.240 --> 00:46:29.280]   and nobody could know.
[00:46:29.280 --> 00:46:31.440]   I mean, it's unbelievable.
[00:46:31.440 --> 00:46:33.600]   They'd have to forget the Russian much power.
[00:46:33.600 --> 00:46:35.120]   Forget the Russian Facebook.
[00:46:35.120 --> 00:46:36.960]   Wait too much.
[00:46:36.960 --> 00:46:44.240]   That profit was 2.3 billion a year ago, 3.9 billion one year later.
[00:46:44.240 --> 00:46:48.320]   Quarterly revenue up 45% to 9.3 billion.
[00:46:48.320 --> 00:46:51.920]   That's more than the analyst consensus as well.
[00:46:51.920 --> 00:46:54.080]   That means the stock will go through the roof tomorrow morning.
[00:46:54.080 --> 00:46:54.400]   Yeah.
[00:46:54.400 --> 00:46:59.040]   Yeah, they're up 4% in after hours right now.
[00:46:59.040 --> 00:46:59.360]   Yeah.
[00:46:59.360 --> 00:47:01.600]   90.
[00:47:01.600 --> 00:47:02.160]   Wait a minute.
[00:47:02.160 --> 00:47:02.640]   First.
[00:47:02.640 --> 00:47:03.920]   Oh, this is, here's a good one.
[00:47:03.920 --> 00:47:09.840]   If you include Facebook and Google, they soaked up between the two of them.
[00:47:09.840 --> 00:47:13.520]   99% of the online ad industries growth last year.
[00:47:13.520 --> 00:47:18.000]   Almost all the growth in the ad industry last year went to two companies,
[00:47:18.000 --> 00:47:18.960]   Facebook and Google.
[00:47:18.960 --> 00:47:23.200]   They are to advertising what Apple and Samsung are to phone profits.
[00:47:23.200 --> 00:47:28.640]   Now, Facebook warns the number of ads in its news feed is maxed out.
[00:47:28.640 --> 00:47:28.880]   Yeah.
[00:47:28.880 --> 00:47:31.440]   Just added WhatsApp ads.
[00:47:31.440 --> 00:47:32.480]   Yeah.
[00:47:32.480 --> 00:47:33.920]   Oh, they're going to be ads in WhatsApp.
[00:47:33.920 --> 00:47:35.280]   No, messenger ads.
[00:47:35.280 --> 00:47:35.600]   Yeah.
[00:47:35.600 --> 00:47:36.960]   So, they're smart.
[00:47:36.960 --> 00:47:38.240]   I think they're smart and they're doing what we do,
[00:47:38.240 --> 00:47:39.920]   which is to keep units down.
[00:47:39.920 --> 00:47:42.800]   Instagram, it's one every 10 posts on Facebook.
[00:47:42.800 --> 00:47:46.400]   It really, those side ads, I don't even see them and doubt anybody does.
[00:47:46.400 --> 00:47:50.960]   And they're not that important, but the periodic ads in the stream, that's effective.
[00:47:50.960 --> 00:47:52.000]   That's what Instagram's doing.
[00:47:52.000 --> 00:47:53.360]   They're getting better at the relevance there.
[00:47:53.360 --> 00:47:57.360]   I find the ads, you know, one out of 10 is irritating an off target.
[00:47:57.360 --> 00:48:02.080]   And when I do try to tell them it's off target, the choices of telling them just aren't quite,
[00:48:02.080 --> 00:48:03.360]   like I already bought a car, stop.
[00:48:03.360 --> 00:48:09.600]   Add revenue up 53% this quarter.
[00:48:09.600 --> 00:48:10.960]   53%.
[00:48:12.000 --> 00:48:12.960]   That's too many percent.
[00:48:12.960 --> 00:48:14.000]   They're doing something right.
[00:48:14.000 --> 00:48:14.560]   Yeah.
[00:48:14.560 --> 00:48:18.080]   Well, they're getting more powerful, but Google's getting more power.
[00:48:18.080 --> 00:48:20.000]   Everybody, these companies are...
[00:48:20.000 --> 00:48:23.120]   They're doing some things right.
[00:48:23.120 --> 00:48:26.080]   They're screwing up a lot less than they used to, but the biggest
[00:48:26.080 --> 00:48:28.560]   secret to their success is they have monopoly on everybody.
[00:48:28.560 --> 00:48:30.640]   Everybody's on Facebook because everybody's on Facebook.
[00:48:30.640 --> 00:48:34.640]   And that's because in the game of musical chairs over time,
[00:48:34.640 --> 00:48:40.640]   where technology trends match social trends, they happen to be the major social network when
[00:48:40.640 --> 00:48:46.480]   everybody got on social networking before Facebook, you know, is just geeks like us who are on
[00:48:46.480 --> 00:48:48.640]   CompuServe and all these other places.
[00:48:48.640 --> 00:48:53.440]   And they will always have the mother of all network effects.
[00:48:53.440 --> 00:48:57.840]   And now you are going to understand why it's in Facebook's interest to get publishers to
[00:48:57.840 --> 00:49:03.120]   put content there, why they're spending so much money now on live content, our video content.
[00:49:03.120 --> 00:49:03.520]   Yeah.
[00:49:03.520 --> 00:49:05.120]   That's beyond that, Leo.
[00:49:05.120 --> 00:49:06.080]   50% more this year.
[00:49:07.520 --> 00:49:11.120]   The next thing I think you're going to see...
[00:49:11.120 --> 00:49:13.680]   What we said earlier is you've got to steal revenue from somebody else.
[00:49:13.680 --> 00:49:15.680]   The place everybody wants to steal revenue from his television.
[00:49:15.680 --> 00:49:18.080]   So it's not just live.
[00:49:18.080 --> 00:49:21.600]   Look what Facebook does because Facebook TV is going to be coming up very soon.
[00:49:21.600 --> 00:49:21.920]   Yep.
[00:49:21.920 --> 00:49:22.240]   Three...
[00:49:22.240 --> 00:49:23.120]   They're going to spend...
[00:49:23.120 --> 00:49:24.400]   YouTube is changing itself.
[00:49:24.400 --> 00:49:29.520]   They're willing to spend $3 million in episode on episodic content for Facebook.
[00:49:29.520 --> 00:49:32.640]   That's significant money.
[00:49:35.200 --> 00:49:37.840]   I don't know if that's not Game of Thrones money, but it's getting close.
[00:49:37.840 --> 00:49:46.480]   What if there were a 10-minute weekly show of interest equivalents to Game of Thrones
[00:49:46.480 --> 00:49:48.080]   on Facebook?
[00:49:48.080 --> 00:49:48.960]   Well, everybody would...
[00:49:48.960 --> 00:49:50.560]   It would just be the...
[00:49:50.560 --> 00:49:51.280]   They should do that.
[00:49:51.280 --> 00:49:51.760]   That's smart.
[00:49:51.760 --> 00:49:52.720]   Let me tell you that.
[00:49:52.720 --> 00:49:58.080]   It's like, imagine they did a Game of Thrones house of cards type level TV show.
[00:49:58.080 --> 00:50:01.680]   They have 2 billion monthly active users.
[00:50:01.680 --> 00:50:05.120]   They're massively larger than Showtime or Netflix or...
[00:50:05.120 --> 00:50:06.800]   They'd make the money back in ads if they put it.
[00:50:06.800 --> 00:50:07.200]   Yeah.
[00:50:07.200 --> 00:50:08.160]   It's just...
[00:50:08.160 --> 00:50:09.120]   It's terrifying.
[00:50:09.120 --> 00:50:11.760]   They can basically write their own ticket and do whatever they want.
[00:50:11.760 --> 00:50:16.800]   So House of Cards had 13 episodes in season one, and it was $100 million.
[00:50:16.800 --> 00:50:21.040]   So that's like $8 million in episodes, something like that.
[00:50:21.040 --> 00:50:23.200]   So it's still...
[00:50:23.200 --> 00:50:26.880]   But it's an hour-long high production value show.
[00:50:26.880 --> 00:50:29.120]   Three million is not that far off.
[00:50:29.120 --> 00:50:29.440]   Yeah.
[00:50:30.400 --> 00:50:36.000]   Mike, this is why you want to like Facebook, is because Zuckerberg likes things to be free.
[00:50:36.000 --> 00:50:40.800]   I'm told that though they're now putting up a subscription of
[00:50:40.800 --> 00:50:44.560]   funnels for publishers, because publishers have been whining about it and complaining about it.
[00:50:44.560 --> 00:50:46.560]   Even News Corp is working with them on this potentially.
[00:50:46.560 --> 00:50:51.120]   But what I'm told is that Zuckerberg himself just...
[00:50:51.120 --> 00:50:54.080]   It grates him of anything paid.
[00:50:54.080 --> 00:50:55.120]   He wants it free.
[00:50:55.840 --> 00:51:00.400]   And so with TV they do... I'll bet you they won't have premium TV.
[00:51:00.400 --> 00:51:03.760]   I'll bet you they'll have a free ad supported TV.
[00:51:03.760 --> 00:51:05.040]   They need more...
[00:51:05.040 --> 00:51:07.440]   They're running out of ad real estate.
[00:51:07.440 --> 00:51:08.800]   They need somewhere to put ads.
[00:51:08.800 --> 00:51:09.200]   Yeah.
[00:51:09.200 --> 00:51:10.160]   That's what... I mean...
[00:51:10.160 --> 00:51:11.440]   That's why they put ads in this show.
[00:51:11.440 --> 00:51:12.880]   Google has the rest of the web.
[00:51:12.880 --> 00:51:13.680]   Yeah.
[00:51:13.680 --> 00:51:16.480]   But Facebook's got every Facebook with a lock in on it.
[00:51:16.480 --> 00:51:17.760]   Facebook has Facebook.
[00:51:17.760 --> 00:51:19.600]   They don't need to do more ads actually.
[00:51:19.600 --> 00:51:21.200]   They just need to raise prices.
[00:51:21.200 --> 00:51:26.560]   Well, good news. The cost of ads on Facebook rose as much as 39% this quarter.
[00:51:26.560 --> 00:51:28.480]   It's a scarcity.
[00:51:28.480 --> 00:51:32.880]   57% increase in the cost of some ads.
[00:51:32.880 --> 00:51:38.640]   So these are two different marketing technology companies, Ken Shue and Merkel.
[00:51:38.640 --> 00:51:40.000]   So Ken Shue reported 39%.
[00:51:40.000 --> 00:51:41.920]   Merkel reported 57%.
[00:51:41.920 --> 00:51:46.160]   That'll just keep going up.
[00:51:46.160 --> 00:51:46.480]   Wow.
[00:51:47.440 --> 00:51:53.360]   Facebook stock price up, as you said, 4% Aaron and I bet you that's just the case.
[00:51:53.360 --> 00:51:56.480]   But they said it headed down first because there was confusion over you.
[00:51:56.480 --> 00:51:58.880]   They switched to gap standards.
[00:51:58.880 --> 00:51:59.920]   And so there was some confusion.
[00:51:59.920 --> 00:52:01.280]   Oh, got to know that.
[00:52:01.280 --> 00:52:02.480]   I guess the market got smarter.
[00:52:02.480 --> 00:52:02.960]   It went up.
[00:52:02.960 --> 00:52:03.200]   Yeah.
[00:52:03.200 --> 00:52:04.960]   The market got smarter.
[00:52:04.960 --> 00:52:06.800]   The wisdom of crowds.
[00:52:06.800 --> 00:52:10.240]   What is Facebook stock symbol F?
[00:52:10.240 --> 00:52:13.600]   It's the F stock, the F word.
[00:52:13.600 --> 00:52:16.320]   No, F is forward.
[00:52:16.320 --> 00:52:16.720]   Sorry.
[00:52:16.720 --> 00:52:20.320]   Should be Zuck.
[00:52:20.320 --> 00:52:25.120]   I thought it was FBOOK, but I might be wrong.
[00:52:25.120 --> 00:52:29.040]   It's FB on the NASDAQ.
[00:52:29.040 --> 00:52:32.880]   Let's see the current.
[00:52:32.880 --> 00:52:34.400]   Let's see the after hours search.
[00:52:34.400 --> 00:52:34.720]   Whoa.
[00:52:34.720 --> 00:52:36.400]   Whoa.
[00:52:36.400 --> 00:52:37.360]   After hours trading.
[00:52:37.360 --> 00:52:38.000]   Whoa.
[00:52:38.000 --> 00:52:39.440]   Launching into the stratosphere.
[00:52:39.440 --> 00:52:44.000]   So the blue line is right up to closing of stock.
[00:52:44.000 --> 00:52:47.200]   And then the gray line is right after the announcement.
[00:52:47.200 --> 00:52:48.960]   So you see it went up and then there's that.
[00:52:48.960 --> 00:52:51.200]   That's when they got off Facebook to listen to the announcement.
[00:52:51.200 --> 00:52:52.240]   And then drop.
[00:52:52.240 --> 00:52:53.680]   Well, that's probably what Jeff was saying,
[00:52:53.680 --> 00:52:56.000]   which misunderstanding what the revenues meant.
[00:52:56.000 --> 00:53:00.080]   And they're currently, so they closed at 165.
[00:53:00.080 --> 00:53:01.440]   They're currently at 172.
[00:53:01.440 --> 00:53:06.480]   Price to earnings is pretty high, 41.
[00:53:06.480 --> 00:53:09.280]   All right.
[00:53:09.280 --> 00:53:10.880]   I'm no stock analyst.
[00:53:12.240 --> 00:53:15.280]   So can we talk about another metric besides money?
[00:53:15.280 --> 00:53:15.600]   Yeah.
[00:53:15.600 --> 00:53:17.360]   So Ethereum?
[00:53:17.360 --> 00:53:20.320]   No, no, no, no, please no.
[00:53:20.320 --> 00:53:22.400]   Customer satisfaction.
[00:53:22.400 --> 00:53:26.480]   The American customer satisfaction index released in 2007.
[00:53:26.480 --> 00:53:27.440]   Yeah, you knew this was coming.
[00:53:27.440 --> 00:53:31.600]   And Google+ is the most satisfying social network.
[00:53:31.600 --> 00:53:33.600]   That is the weirdest story I've ever heard.
[00:53:33.600 --> 00:53:36.400]   How did that even happen?
[00:53:36.400 --> 00:53:38.480]   I'll tell you, they don't have ads for starters.
[00:53:38.480 --> 00:53:41.280]   The most loved social network in America.
[00:53:41.280 --> 00:53:42.400]   I'll tell you how it happens.
[00:53:42.400 --> 00:53:45.040]   Everybody hates the other social networks more than they used to.
[00:53:45.040 --> 00:53:48.320]   Yeah, but is this a poll or is this measuring actual,
[00:53:48.320 --> 00:53:49.520]   yeah, it's a survey.
[00:53:49.520 --> 00:53:50.880]   So that's what happens.
[00:53:50.880 --> 00:53:52.160]   Same thing happens with PBS.
[00:53:52.160 --> 00:53:53.760]   Everybody says they watch PBS,
[00:53:53.760 --> 00:53:55.200]   but really they're watching the Bachelor.
[00:53:55.200 --> 00:53:57.520]   Well, this isn't about popularity.
[00:53:57.520 --> 00:54:00.320]   This doesn't say tell how many people are on Google+.
[00:54:00.320 --> 00:54:02.960]   It says the people who are on Google+, like it better,
[00:54:02.960 --> 00:54:05.840]   than the people who are on Facebook or whatever.
[00:54:05.840 --> 00:54:07.760]   Well, it's a survey of 5,000 consumers
[00:54:07.760 --> 00:54:08.960]   responded over email.
[00:54:10.640 --> 00:54:14.320]   And they were asked, what do you use?
[00:54:14.320 --> 00:54:15.280]   What do you like?
[00:54:15.280 --> 00:54:17.120]   What were they asked?
[00:54:17.120 --> 00:54:22.240]   And so the ranking, just so you know,
[00:54:22.240 --> 00:54:24.240]   that it's based on zero to 100 points,
[00:54:24.240 --> 00:54:27.360]   Google+ number one at 81 points, Pinterest number two.
[00:54:27.360 --> 00:54:28.800]   What's interesting about both of those
[00:54:28.800 --> 00:54:30.400]   are both of those social networks.
[00:54:30.400 --> 00:54:31.920]   They're little analysis on Google+,
[00:54:31.920 --> 00:54:33.200]   but they just want ads.
[00:54:33.200 --> 00:54:35.920]   Well, what they have in common is they're areas where,
[00:54:35.920 --> 00:54:42.320]   so think of the clash of argumentation on social networks like Twitter.
[00:54:42.320 --> 00:54:47.200]   Twitter invites people with diverging views to come together and argue with each other violently.
[00:54:47.200 --> 00:54:49.520]   And everybody's sick of that.
[00:54:49.520 --> 00:54:51.920]   And so I think they're taking it out on those other social networks.
[00:54:51.920 --> 00:54:54.080]   Google+ and Pinterest are all about people's interests.
[00:54:54.080 --> 00:54:56.160]   And like-minded people, you can,
[00:54:56.160 --> 00:54:58.800]   what you do on Google+ and Pinterest, and also Reddit,
[00:54:58.800 --> 00:55:00.640]   which is not on this list for some reason,
[00:55:00.640 --> 00:55:05.760]   is you find your tribes, you find your communities of people who generally like the same things
[00:55:05.760 --> 00:55:09.200]   you like and who agree with you more or less about various things.
[00:55:09.200 --> 00:55:11.200]   And you interact with those people.
[00:55:11.200 --> 00:55:16.320]   It doesn't throw together opposites so that they argue and bicker and all that kind of stuff.
[00:55:16.320 --> 00:55:19.280]   And then if you look at the bottom, it's linked in Facebook, YouTube.
[00:55:19.280 --> 00:55:22.400]   Those are places where people are clashing and arguing and disagreeing.
[00:55:22.400 --> 00:55:23.440]   Not linking so much.
[00:55:23.440 --> 00:55:25.040]   Wikipedia was number three, which is-
[00:55:25.040 --> 00:55:26.160]   That's not a social network.
[00:55:26.160 --> 00:55:26.800]   Come on.
[00:55:26.800 --> 00:55:28.080]   It's like, why is it even on there?
[00:55:28.080 --> 00:55:29.440]   Okay, I think you're on to something, Mike.
[00:55:29.440 --> 00:55:33.040]   Because last week we talked about Kevin Rus' column in the New York Times,
[00:55:33.040 --> 00:55:39.200]   which he went into 100 secret groups on Facebook and said, maybe this is the future of civility.
[00:55:39.200 --> 00:55:40.560]   But you're exactly what you're saying.
[00:55:40.560 --> 00:55:41.200]   People are finding it.
[00:55:41.200 --> 00:55:43.760]   Now that we're going to get the echo chamber argument back again,
[00:55:43.760 --> 00:55:46.160]   but it never goes away.
[00:55:46.160 --> 00:55:51.520]   But yeah, you get to find people who share your interest and there's no reason to argue with them.
[00:55:51.520 --> 00:55:52.800]   Yeah, absolutely.
[00:55:52.800 --> 00:55:54.240]   And I think this is-
[00:55:54.240 --> 00:55:59.600]   The news and discourse has been poisoned by weaponized information,
[00:55:59.600 --> 00:56:05.520]   by fake news, by propaganda, by all these crazy people screaming at each other and trying to
[00:56:05.520 --> 00:56:10.400]   distance the public from other members of the public.
[00:56:10.400 --> 00:56:13.200]   It's very divisive and everybody's kind of sickened by it.
[00:56:13.200 --> 00:56:16.880]   And if you go to some of these other places where you can just pursue your interests and
[00:56:16.880 --> 00:56:19.840]   talk to people who are rational, it's a beautiful- it's better.
[00:56:19.840 --> 00:56:23.840]   And so the fact is that Google+ isn't as good as it used to be when it ranked lower.
[00:56:23.840 --> 00:56:26.560]   Google+ has gotten worse.
[00:56:26.560 --> 00:56:28.720]   Several other social networks have gotten worse.
[00:56:28.720 --> 00:56:31.520]   And several social networks have stayed as bad as they've always been.
[00:56:31.520 --> 00:56:35.280]   But more or less, the places where people are bickering and arguing and where there's
[00:56:35.280 --> 00:56:38.640]   trolls and harassment, they're ranking the social networks.
[00:56:38.640 --> 00:56:40.800]   Their satisfaction of the users is lower.
[00:56:40.800 --> 00:56:43.760]   And I think it's not because of the qualities of the social networks.
[00:56:43.760 --> 00:56:46.560]   It's because of the decline in civil discourse.
[00:56:46.560 --> 00:56:55.360]   Here is an article which is probably a little stingy to Facebook right now after their big
[00:56:55.360 --> 00:57:00.880]   announcement. Facebook worker Living in Garage says to Zuckerberg,
[00:57:00.880 --> 00:57:04.400]   "You don't need to travel across the US to learn about people's hopes and challenges.
[00:57:04.400 --> 00:57:07.360]   Talk to your cafeteria workers."
[00:57:07.360 --> 00:57:11.360]   This guy works at the Facebook cafeteria apparently struggling to make ends meet.
[00:57:11.360 --> 00:57:17.760]   There's a little wealth inequality right there in Lotusland.
[00:57:17.760 --> 00:57:22.000]   And their house, by the way, and this is a true story, is smaller than the giant vault
[00:57:22.000 --> 00:57:26.480]   the junk built underground where he keeps all the googemic duck gold coins and his big treasure
[00:57:26.480 --> 00:57:28.960]   chests of money. Does he really have a vault? No, he must.
[00:57:28.960 --> 00:57:31.680]   Come on. Wouldn't you have a giant, richy, rich vault?
[00:57:31.680 --> 00:57:34.880]   I'd have one of those safe rooms that you go into.
[00:57:34.880 --> 00:57:40.720]   I would have the swimming pool full of gold coins that have little dollar signs on it and just swim in it.
[00:57:40.720 --> 00:57:43.280]   I've in it. That's just me.
[00:57:43.280 --> 00:57:46.800]   It's not a bad job.
[00:57:47.920 --> 00:57:55.200]   They both work there. Victor and Nicole. Nicole makes 1985 an hour. He makes 1785 an hour.
[00:57:55.200 --> 00:57:59.840]   The problem is that they live in Silicon Valley. That's actually a good pay.
[00:57:59.840 --> 00:58:03.760]   They live in Silicon Valley and you can't live on that.
[00:58:03.760 --> 00:58:08.880]   Yeah. There are places in the Bay Area that are so out of whack. I think in Marin, it is that if
[00:58:08.880 --> 00:58:12.160]   you're below $100,000 a year, you're in the poverty.
[00:58:13.040 --> 00:58:19.440]   They have lived there their whole lives. In fact, when they were growing up, his father was able to
[00:58:19.440 --> 00:58:23.920]   buy a small house there from his earnings as a landscaper. When they first got married,
[00:58:23.920 --> 00:58:28.160]   they were earning 12 bucks an hour as Chipotle managers. They had their own apartment.
[00:58:28.160 --> 00:58:33.440]   But then Facebook moves into Menlo Park and they have to live in a garage because that's the
[00:58:33.440 --> 00:58:39.680]   best they can get. Facebook is planning to build new apartments, including low-income units,
[00:58:39.680 --> 00:58:45.440]   but they can't build enough. It'd be interesting to see companies like Amazon and Facebook.
[00:58:45.440 --> 00:58:51.280]   I think they're moving in this direction. Create basically company cities.
[00:58:51.280 --> 00:58:56.880]   Isn't that what Fox Man does? It's creepy. All muscle to the company is stored.
[00:58:56.880 --> 00:59:00.400]   Exactly. You have to buy. That's also breaking news.
[00:59:00.400 --> 00:59:03.680]   What's that? They're going to build a US plant. They're going to build an American plant for 10
[00:59:03.680 --> 00:59:10.240]   million bucks. Apple, Donald Trump tweeted that Apple had, Tim Cook had promised him that he was
[00:59:10.240 --> 00:59:17.600]   going to build three big, beautiful plants in the US. At least one of those was real. Maybe they're
[00:59:17.600 --> 00:59:26.640]   more coming. I just love how the president is taking credit for Apple's and they've moved stuff
[00:59:26.640 --> 00:59:33.440]   to the US before. He thinks that if you bluster, then everything moves. I did it all. I have to say
[00:59:34.080 --> 00:59:41.680]   this news is timely. It's right after the tweet. Apple's immediate reaction was no comment.
[00:59:41.680 --> 00:59:49.200]   Apple did, you remember, famously try to do an assembly, the Mac Pro in Texas that failed.
[00:59:49.200 --> 00:59:55.520]   They also failed. Remember their factory where they're going to build sapphire
[00:59:55.520 --> 01:00:01.280]   glass? They got sued by the company. Are they sued to come or something like that?
[01:00:01.280 --> 01:00:04.400]   They built the whole factory and then they ended up closing and stuff like that.
[01:00:04.400 --> 01:00:10.160]   But is that a statement on the quality of American workers or the cost of American workers?
[01:00:10.160 --> 01:00:17.600]   It's supervisors. The US cannot produce enough factory supervisors with the education and training
[01:00:17.600 --> 01:00:22.560]   and engineering training. We're maxed out on engineers. We need to import more engineers,
[01:00:22.560 --> 01:00:28.640]   more programmers. That's the kind of thing. You can get lots and lots of workers if you pay them
[01:00:28.640 --> 01:00:36.640]   enough. That's what China has that the US doesn't have. It's just legions of trained managerial
[01:00:36.640 --> 01:00:46.480]   level engineering talent. This is Foxconn, not Apple, but Foxconn makes the iPhones. Foxconn wants
[01:00:46.480 --> 01:00:53.840]   to build a factory in Wisconsin. They did the same in Brazil because Brazil had high tariffs
[01:00:53.840 --> 01:00:58.080]   and the only way to make a reasonably priced iPhone in Brazil was to manufacture it there.
[01:00:58.080 --> 01:01:03.840]   Apple is going to do the same in India. India also has very restrictive rules about what companies
[01:01:03.840 --> 01:01:10.000]   can sell in non-Indian companies can sell in India. But there's not that kind of pressure in the US
[01:01:10.000 --> 01:01:18.560]   yet. They're going to build a $10 billion manufacturing plant with 13,000 jobs. It's all about jobs.
[01:01:18.560 --> 01:01:23.360]   It's 13,000 jobs a lot for a factory that size. What makes it possible to manufacture in the US
[01:01:23.360 --> 01:01:28.880]   is robotics. Remember that Foxconn replaced 13,000 workers with robots in China.
[01:01:28.880 --> 01:01:36.080]   Not so long ago. They're thinking long-term. Even if you hire 13,000 employees, it's like
[01:01:36.080 --> 01:01:42.320]   Uber drivers. They're training Uber self-driving car technology. That's what they're a placeholder
[01:01:42.320 --> 01:01:48.240]   until the self-driving cars hit. Same thing with any factory you build in 2017-2018. You're
[01:01:48.240 --> 01:01:53.600]   essentially building a factory that will sooner rather than later be mostly robotic.
[01:01:53.600 --> 01:01:59.280]   Actually, I correct myself. Foxconn replaced 60,000 workers with robots in China.
[01:01:59.280 --> 01:02:04.960]   60,000. All right, let's take a little break. We'll have more. Mike Elgin is here,
[01:02:04.960 --> 01:02:10.080]   digital Nomad. Mike Elgin, the world traveler. You can find more about him and what he and
[01:02:10.080 --> 01:02:15.520]   Namera are doing at gastronomad.net. Their next event is in Barcelona in September. You're going
[01:02:15.520 --> 01:02:19.760]   to do Fes Morocco after that. We got a bunch lined up. Leo, we're going to do Italy. We're going to
[01:02:19.760 --> 01:02:24.800]   do France. We're going to put me down for Italy. You got it. Seriously. We're in Italy, you think?
[01:02:24.800 --> 01:02:29.360]   Prosecco Hills. That's what we're doing. You're going to love Italy. You're going to love Italy.
[01:02:29.360 --> 01:02:36.960]   I don't care when I'm there. Well, I know where. Aaron Nukem is also here. He's at New Relic
[01:02:36.960 --> 01:02:41.680]   these days. You can find him on the Twitter @AaronNukem. He's, of course, the founder and runs the
[01:02:41.680 --> 01:02:48.560]   Benetia Maker Space. It's going right there. Doing well? Yeah. In fact, we just opened up
[01:02:48.560 --> 01:02:54.880]   another 1,200 square feet for classroom space and dedicated electronics work areas that can be
[01:02:54.880 --> 01:02:59.360]   hopefully a little cleaner because they were in our other shop with all the woodworking and
[01:02:59.360 --> 01:03:04.240]   metalworking. See, that's where the future of manufacturing in the United States is going to
[01:03:04.240 --> 01:03:09.520]   happen is people learning these skills in hacker spaces. I think that's awesome. That's fantastic.
[01:03:10.320 --> 01:03:14.640]   Yeah. What you're really doing there is, I think, a little bit towards what Mike was saying is that
[01:03:14.640 --> 01:03:21.680]   you're teaching people how to be innovators, not just workers on an assembly line, but you're
[01:03:21.680 --> 01:03:28.640]   teaching them to think critically and to come up with new ideas. I think that's, again, the knowledge,
[01:03:28.640 --> 01:03:34.480]   getting the knowledge and the confidence to be able to do that is where the future lies.
[01:03:34.480 --> 01:03:40.000]   Well, and it's fun. It's a great hobby. Aaron is a regular on many of our shows. In fact,
[01:03:40.000 --> 01:03:44.080]   we've got to get you back. We had you scheduled for the new screensavers you couldn't do, but
[01:03:44.080 --> 01:03:48.960]   let's get you back in soon. I will very much go to get you on and talk about your latest
[01:03:48.960 --> 01:03:56.000]   making projects. Also, all the way from Australia, where the sun is just coming up on Thursday morning,
[01:03:56.640 --> 01:04:03.840]   Jeff Jarvis. He is, of course, a blogger at buzzmachine.com and Twitter is at Jeff Jarvis.
[01:04:03.840 --> 01:04:09.920]   Our show today brought to you by LegalZoom. Summertime is here, the time for family vacations,
[01:04:09.920 --> 01:04:17.520]   sunscreen, barbecues, but, and I know nobody wants to think about it. It might be a good thing this
[01:04:17.520 --> 01:04:24.080]   summer to prepare for your family's future with an estate plan from LegalZoom. You see, it's
[01:04:24.080 --> 01:04:30.560]   National Make a Will Month next month. Perfect time. Make sure you're prepared for the future.
[01:04:30.560 --> 01:04:35.200]   We did this. Actually, Lisa did this. It was great. You get a great kit, all the forms you need.
[01:04:35.200 --> 01:04:41.280]   Then, if you need legal advice, LegalZoom is not a law firm, but they have put together a
[01:04:41.280 --> 01:04:46.400]   really nice network of independent attorneys. Now, in all 50 states, they finally got to those
[01:04:46.400 --> 01:04:52.400]   last few states. You can go to an attorney in your state and ask questions, work with them,
[01:04:53.040 --> 01:04:58.400]   to get the right estate plan and not at a huge hourly fee, but at a pre-negotiated flat rate.
[01:04:58.400 --> 01:05:03.600]   So, if you're doing a will, or they do living trusts, you bet. You can get the advice you need
[01:05:03.600 --> 01:05:09.440]   to address the needs of your family. During National Make a Will Month in August, LegalZoom is
[01:05:09.440 --> 01:05:13.680]   pulling a bunch of helpful resources together all in one place to make it a little easier to
[01:05:13.680 --> 01:05:17.760]   ensure your family and your assets are protected. But don't wait until August gets started right now
[01:05:19.040 --> 01:05:25.360]   at LegalZoom.com. Not just your estate plan. Plan your business. Start your business. You know
[01:05:25.360 --> 01:05:31.120]   what a good estate plan is? Start a business. I'll tell you what, I put my kids through college.
[01:05:31.120 --> 01:05:38.240]   Where did I start that? LLC, LegalZoom.com. If you have a family or own anything you care about,
[01:05:38.240 --> 01:05:43.680]   now's the time. In the meantime, see what else LegalZoom.com has to offer and save more by entering
[01:05:43.680 --> 01:05:51.360]   Twig at checkout. LegalZoom.com. We did the trademarks there too. LegalZoom.com. Use the
[01:05:51.360 --> 01:06:00.960]   offer code TWIG. Thank LegalZoom for their support. In more than one way, artificial intelligence.
[01:06:00.960 --> 01:06:07.360]   There's a little cat fight going on now. I love this. Elon Musk said the AI ought to be regulated.
[01:06:07.360 --> 01:06:13.360]   Last week we talked a little bit about Rodney Brooks, who is the creator of iRobot and has
[01:06:13.360 --> 01:06:20.400]   a professor of robotics at MIT. Might know a little bit about AI. He says, "All the people want to
[01:06:20.400 --> 01:06:25.920]   regulate AI. Don't work in AI." He said, "What does Elon want to regulate? You know how to regulate?
[01:06:25.920 --> 01:06:32.000]   Self-driving Tesla's." That's what you ought to regulate. Now Mark Zuckerberg weighs in and he
[01:06:32.000 --> 01:06:39.600]   says, "Elon's views on artificial intelligence are pretty irresponsible."
[01:06:40.960 --> 01:06:43.920]   Why is Mark weighing in on this? Does he have something up his sleeve?
[01:06:43.920 --> 01:06:50.640]   Oh yeah. They're working on AI. They want AI replacing their algorithms in the future so that
[01:06:50.640 --> 01:06:55.440]   AI can just figure out what you see, what you don't see, figure out the advertising.
[01:06:55.440 --> 01:07:01.360]   AI's can be huge in the world of social networking and he's counting on it to be competitive.
[01:07:01.360 --> 01:07:10.400]   Also, by the way, Facebook has amazing face recognition. That's based on AI machine learning.
[01:07:11.120 --> 01:07:15.280]   It's incredible. It's better than the FBI's. They can recognize your face even if your back is
[01:07:15.280 --> 01:07:21.760]   turned. It's amazing. That's your head. Zuckerberg says, "I kind of agree. This is like what you've
[01:07:21.760 --> 01:07:26.000]   talked about in the past, Jeff, with the techno panic that he could have been taking this out of
[01:07:26.000 --> 01:07:30.880]   the Jeff Jarvis playbook. People are arguing for slowing down the process of building AI.
[01:07:30.880 --> 01:07:36.400]   I find that really questionable," says Zuckerberg. "I have a hard time wrapping my head around it."
[01:07:37.120 --> 01:07:41.840]   As an example, he says, "One of the top causes of death for people, car accidents. If you can
[01:07:41.840 --> 01:07:48.080]   eliminate that with self-driving cars, that's going to be a dramatic improvement in people's lives."
[01:07:48.080 --> 01:07:52.720]   Any technology can be misused. That's what Zuck says.
[01:07:52.720 --> 01:07:57.440]   That's what Zuck says. Does it mean you should control it? Yeah. The irony here is it's techno
[01:07:57.440 --> 01:08:05.200]   panic from the most technological person. Probably we have. Elon Musk. Meanwhile, Elon says,
[01:08:06.320 --> 01:08:09.440]   "Mark Zuckerberg's knowledge of AI's future is limited."
[01:08:09.440 --> 01:08:14.800]   They're really kind of in a little pissing match.
[01:08:14.800 --> 01:08:22.800]   Yeah. Of course, Elon's never been shy. Like Steve Jobs and others saying somebody's stupid if he
[01:08:22.800 --> 01:08:29.760]   thinks they're not as bright as he is. In unrelated news, Elon Musk's news feed is empty, and his
[01:08:29.760 --> 01:08:36.000]   posts are not going to any of his friends. I wonder if Musk has a Facebook page.
[01:08:36.800 --> 01:08:39.680]   That's the thing. He's got it. Everybody has to.
[01:08:39.680 --> 01:08:44.960]   But isn't that... With him going to the governors and saying they should start legislating and
[01:08:44.960 --> 01:08:48.560]   all this kind of stuff, is that what you're kind of like calling fire in the theater? I mean,
[01:08:48.560 --> 01:08:56.400]   I agree with those. Mark included that have said, "That is irresponsible. Why would you say that? This
[01:08:56.400 --> 01:09:03.280]   is something that's in its infancy, and it's something we can definitely control. It's okay to
[01:09:03.280 --> 01:09:07.360]   raise a concern, but don't go to governors and say start legislating this now."
[01:09:07.360 --> 01:09:14.160]   Because those are the people who will first of all can and don't have and truly don't understand
[01:09:14.160 --> 01:09:18.960]   it. We'll listen to somebody like Elon Musk and say, "Uh-oh, we better do something right now."
[01:09:18.960 --> 01:09:24.640]   Brooks's point was, Rodney Brooks said MIT's point was, "Well, what are you going to regulate?
[01:09:24.640 --> 01:09:29.280]   Either something exists or doesn't exist, and since it doesn't exist at this point,
[01:09:29.280 --> 01:09:34.320]   he also says, "Anybody who does AI knows it's not that smart. It's a long way to go."
[01:09:34.320 --> 01:09:41.120]   Elon's response to Mark Zuckerberg's crack, "I've talked to Mark about this. I love this.
[01:09:41.120 --> 01:09:46.000]   I need a voice for this. His understanding of the subject is limited."
[01:09:46.000 --> 01:09:55.280]   Wow! What a snotty tweet. All right, well, there's nothing to say here except...
[01:09:56.240 --> 01:10:05.920]   Meow. I think we are in agreement that it is like crying fire in a crowded theater.
[01:10:05.920 --> 01:10:11.120]   They don't know what it reminds me of. I think it was Warner Brothers. I think it wasn't many,
[01:10:11.120 --> 01:10:15.920]   many years ago when this is a great anecdote. I forget which book had it, where the Google
[01:10:15.920 --> 01:10:20.400]   Guys, the founders were Warner Brothers, and Warner Brothers basically said, "Don't ruin advertising.
[01:10:20.400 --> 01:10:25.760]   You're messing this up." Yeah. Well, too late. They ruined it.
[01:10:26.240 --> 01:10:33.040]   I went to an event in Washington last week where the Americans of the room were trying to
[01:10:33.040 --> 01:10:36.880]   basically convince the Europeans to stop trying to regulate speech.
[01:10:36.880 --> 01:10:42.400]   Good luck. Well, Google has responded to, remember we talked about the Canadian court
[01:10:42.400 --> 01:10:51.680]   that said Google had to strip a libelous post... Postings that the Canadian court considered
[01:10:51.680 --> 01:10:57.360]   libelous had to strip those postings not just in Canada, but from the entire Google search worldwide.
[01:10:57.360 --> 01:11:05.760]   Google has gone to the 9th District Court in California to get that overturned. They asked
[01:11:05.760 --> 01:11:12.880]   the judge... They told the justices that the Canadian case's outcome runs counter to America's
[01:11:12.880 --> 01:11:20.320]   First Amendment. And so, Google's asking the US judges to reject the findings of the Canadian court.
[01:11:20.320 --> 01:11:25.600]   I'm not clear what the outcome would be. Isn't there an international court that adjudicates
[01:11:25.600 --> 01:11:29.760]   this kind of stuff? Yeah, but he didn't go to that. He went to judge in the US who, let's say,
[01:11:29.760 --> 01:11:34.720]   the US judge agrees and sides with Google, then what? Then what? Because basically,
[01:11:34.720 --> 01:11:42.080]   you're talking about Canadian law and they can take action against Google's activities in Canada.
[01:11:42.080 --> 01:11:46.960]   That's their leverage. That's their only leverage. But this is the world where we are now.
[01:11:46.960 --> 01:11:53.920]   This is where Google is going to pit nations against each other in a Japanese monster movie
[01:11:53.920 --> 01:12:01.200]   fight in Tokyo Bay here and stand back and watch. But that's... Does the nation have the same
[01:12:01.200 --> 01:12:08.080]   authority that it had in a truly international world? It does not have what we're seeing the rise of
[01:12:08.080 --> 01:12:12.880]   nationalism. It does within the nation. What Canada is not allowed to do, and it shouldn't be allowed
[01:12:12.880 --> 01:12:19.440]   to do, in my opinion, is overrule the First Amendment in the United States. You can drive
[01:12:19.440 --> 01:12:26.000]   to the Google campus from here in an hour and a half. If I'm going to Google to get information
[01:12:26.000 --> 01:12:30.000]   about what is actually on the internet, not a censored version of that, but what's actually
[01:12:30.000 --> 01:12:36.240]   on the internet, which, again, isn't entirely true, but what right does a foreign government have
[01:12:36.240 --> 01:12:41.120]   to step in between me and Google in a country that has the First Amendment? I say they have zero
[01:12:41.120 --> 01:12:46.640]   right to do that. It's also cowardly on the part of the Canadian judges doing this,
[01:12:46.640 --> 01:12:50.880]   and the Canadian government people who support this. Because if they want to be censors,
[01:12:50.880 --> 01:12:57.280]   they can build a great firewall of Canadian, and they can censor the internet, just like China does.
[01:12:57.280 --> 01:13:02.640]   Stand up and take your loans. If you're a censor, you're a censor. You don't have Google do your
[01:13:02.640 --> 01:13:07.360]   early work. Exactly. Exactly. And so it's like, no, and it's, again, the slippery slow
[01:13:07.360 --> 01:13:11.440]   argument is obvious. China is going to decide that nobody in the world can talk about Tiananmen
[01:13:11.440 --> 01:13:15.040]   Square, and Russia is going to decide, et cetera, forget about it. It's terrible.
[01:13:15.040 --> 01:13:19.040]   So Mike, what's going to happen, I think, is the doctor in the Google and Facebook want,
[01:13:19.040 --> 01:13:23.920]   I think, here is we will, whether we like it or not, we will follow local laws locally.
[01:13:23.920 --> 01:13:28.880]   And so I think what they're trying to get is the United States court to say,
[01:13:28.880 --> 01:13:35.920]   they think about the First Amendment, though, is it's about government sense. Here's the weird
[01:13:35.920 --> 01:13:41.680]   thing about it. It's about American government. US government. Yes. And so,
[01:13:41.680 --> 01:13:47.440]   but if they can say, listen, we got two countries with two different rulings,
[01:13:47.440 --> 01:13:55.200]   we're just going to follow each country onto itself. Right. And if Canada wants to punish
[01:13:55.200 --> 01:14:00.800]   Google financially with fines or whatever, then that's the course it has to take. If Google actually
[01:14:01.760 --> 01:14:06.400]   agrees with this ruling and actually performs that censorship, I'm moving to Bing. That is
[01:14:06.400 --> 01:14:11.360]   outrageous. They cannot do that. If the money is so important to them that they would do that,
[01:14:11.360 --> 01:14:14.400]   then I'm willing to use a search engine that does that.
[01:14:14.400 --> 01:14:21.280]   There's also a French case, a right to be forgotten case in France that was appealing to a
[01:14:21.280 --> 01:14:26.480]   European court. Of course, they've lost before, but I think that's what it was. It could be wrong.
[01:14:26.480 --> 01:14:31.680]   Yeah. And I mentioned Bing. That's the other bizarre thing about this ruling. It doesn't
[01:14:31.680 --> 01:14:36.320]   apply to Bing or other search engines, only one company, even though these links exist on the
[01:14:36.320 --> 01:14:48.480]   other search engines. I'm sure. Speaking of laws overturning national laws overturning
[01:14:48.480 --> 01:14:54.480]   laws of other lands, how about a national law that overturns the laws of mathematics?
[01:14:55.200 --> 01:15:01.520]   I like it. The Prime Minister of Australia, Malcolm Turnbull says, let me find the exact quote,
[01:15:01.520 --> 01:15:08.000]   because it's pretty funny. He was challenged on whether it was possible to crack down an encryption
[01:15:08.000 --> 01:15:15.920]   because, well, the encryption is governed by the laws of mathematics. And you can't really stop
[01:15:15.920 --> 01:15:21.600]   that from working. You can try. So Turnbull said, well, the laws of Australia prevail in
[01:15:21.600 --> 01:15:25.680]   Australia. I can assure you of that. The laws of mathematics are very commendable.
[01:15:25.680 --> 01:15:30.960]   But the only law that applies in Australia is the law of Australia.
[01:15:30.960 --> 01:15:34.400]   I think they should start with overturning the laws of physics, because those are more dangerous
[01:15:34.400 --> 01:15:38.640]   than the laws of mathematics. Australia is one of the five eyes. And of course,
[01:15:38.640 --> 01:15:43.920]   and I'm sure this will happen in the USA. England's done in Australia's proposing something similar
[01:15:43.920 --> 01:15:50.480]   to the English Snippers Charter, which would force companies to hand over the clear text
[01:15:50.480 --> 01:15:56.240]   contents of encrypted messages on their services. The problem is, of course,
[01:15:56.240 --> 01:16:02.720]   if they don't have the clear text, they can't do that. So the only way to adhere to that law
[01:16:02.720 --> 01:16:11.600]   would be to break the encryption, to put a backdoor in. So we'll see. Or to disallow encryption.
[01:16:11.600 --> 01:16:17.120]   Or to disallow it, to say there's no encryption, or we're going to hold the keys. And if we're
[01:16:17.120 --> 01:16:22.240]   asked, we'll give them the information, or we'll give the government a backdoor,
[01:16:22.240 --> 01:16:26.240]   all three of which have been proposed by various governments. What a surprise.
[01:16:26.240 --> 01:16:32.800]   I'm sorry, Prime Minister, but you can't overturn the law of mathematics. It's just,
[01:16:32.800 --> 01:16:36.640]   it's not that kind of law. You should overturn Moore's law. Maybe that would help.
[01:16:38.000 --> 01:16:44.400]   Not just that kind of law. I'm quite enjoying the, well, not enjoying, but watching with interest,
[01:16:44.400 --> 01:16:50.160]   since I don't have a dog in the cryptocurrency hunt, the various dramas that are going on in
[01:16:50.160 --> 01:16:58.000]   Bitcoin, the potential forking of Bitcoin. And last week, you might have noted that the biggest
[01:16:58.000 --> 01:17:09.200]   heist in the history of cryptocurrencies occurred in $31 million worth of ether. That's the,
[01:17:09.200 --> 01:17:15.680]   the currency of the Ethereum network, we're stolen the matter of minutes.
[01:17:15.680 --> 01:17:22.480]   In fact, it could have been a lot worse, but fortunately somebody caught them and analyzed
[01:17:22.480 --> 01:17:27.600]   the attack. They couldn't reverse the effects that occurred, but they protected the rest of the
[01:17:27.600 --> 01:17:33.840]   wallets. They actually hacked them before the bad guy did. And so they hacked all the remaining
[01:17:33.840 --> 01:17:40.240]   at risk Ethereum wallets, drained their accounts, preventing the attacker from reaching the remaining
[01:17:40.240 --> 01:17:48.240]   $150 million. Unbelievable. And that, and then today's story that the SEC has decided that
[01:17:48.960 --> 01:17:59.840]   ICOs are a, "regulatable." It's not exactly the same as regulating Bitcoin, but it's a kind of a
[01:17:59.840 --> 01:18:06.400]   step down that road. Securities and Exchange Commission yesterday ruled that some of the coins
[01:18:06.400 --> 01:18:13.760]   for sale in the initial coin offerings are actually securities and therefore subject to regulation.
[01:18:14.320 --> 01:18:25.360]   So ICO is a really, it's like an IPO, but for individuals and small companies, right? In an ICO,
[01:18:25.360 --> 01:18:29.760]   which can last anywhere from a few hours to a few weeks, a company will invite people to buy
[01:18:29.760 --> 01:18:35.520]   digital tokens, kind of like on Kickstarter or Indiegogo to fund a project, but you do get,
[01:18:35.520 --> 01:18:41.680]   you get some stake then, I guess, in the company, but it involves blockchain software like Ethereum,
[01:18:41.680 --> 01:18:47.280]   like Bitcoin. Otherwise, the ledger can be tampered with so that you need some way of making sure
[01:18:47.280 --> 01:18:52.800]   that everybody agrees about what happened and it can't be modified. To take part in ICO,
[01:18:52.800 --> 01:18:59.680]   you send Bitcoin to a website run by the company and then you get these digital tokens. The tokens,
[01:18:59.680 --> 01:19:06.080]   this is what the SEC wants to regulate, these tokens, because it looks a lot like stock, right?
[01:19:06.080 --> 01:19:14.240]   The tokens give the holder a right to participate in a pre-specified blockchain activity,
[01:19:14.240 --> 01:19:19.200]   it depends on what the company wants to do. The company might say, you have to have a token to
[01:19:19.200 --> 01:19:25.200]   join an automated investment project to get access to certain services or, I mean, it could even be
[01:19:25.200 --> 01:19:33.280]   to vote as a shareholder, but the tokens can also be bought and sold. I have a token, I gave
[01:19:34.800 --> 01:19:42.560]   the Mike Elgin digital nomad currency, I gave you some Bitcoin, you gave me some tokens,
[01:19:42.560 --> 01:19:49.360]   I could sell that to Aaron. That is a lot like securities and the SEC said,
[01:19:49.360 --> 01:19:57.360]   these are indeed securities. This was actually a part of an investigation to a
[01:19:57.360 --> 01:20:04.080]   journaling company called The Dow or Decentralized Autonomous Organization that raised 150 million
[01:20:04.080 --> 01:20:10.720]   in ICOs last year. It feels pyramid-y, doesn't it? Yeah, and I think it probably should be regulated,
[01:20:10.720 --> 01:20:17.040]   but it did cost a little money to Ethereum holders, the price of Ethereum went down 10%.
[01:20:17.040 --> 01:20:20.560]   Yesterday on that news.
[01:20:23.600 --> 01:20:30.080]   Plus it also sounds like a mineral you hear in the movie Avatar or something. ICO? Ethereum.
[01:20:30.080 --> 01:20:34.320]   I know it does, I like Ethereum. Unobtanium.
[01:20:34.320 --> 01:20:41.680]   This is not the first time digital currencies, crypto currencies have been stolen. They're not
[01:20:41.680 --> 01:20:51.040]   that secure. Although they seem like they would be, but they're not. It'd be secureable.
[01:20:51.040 --> 01:20:54.640]   And it's a lot less interesting than a bank robbery with an Abani and Clyde with the
[01:20:54.640 --> 01:20:59.520]   new Tommy Guns. It's also a lot more lucrative. 13 million could have been
[01:20:59.520 --> 01:21:04.480]   $31 million. It could have been $180 million. I don't know where you spend this.
[01:21:04.480 --> 01:21:11.440]   Do you read the Silk Road book? No, Nick Bilton's book, I got to read it because Nick's coming on
[01:21:11.440 --> 01:21:16.080]   triangulation pretty soon. It's very good. I heard it was very good.
[01:21:16.080 --> 01:21:24.960]   Couldn't put it down. Google has added SOS alerts.
[01:21:24.960 --> 01:21:31.360]   Kind of like Facebook safety check, but they've added them to search and to maps.
[01:21:31.360 --> 01:21:36.560]   The weird thing is that humans are putting these together. It's not algorithmically
[01:21:36.560 --> 01:21:41.920]   determinant, which is like, wait a minute, what business is Google? I mean, I imagine they
[01:21:41.920 --> 01:21:46.480]   may have a long term. I think when you're talking about natural disasters, you probably don't want
[01:21:46.480 --> 01:21:51.600]   to trust it to a machine. But then why is Google doing it? I mean, isn't it? It's trusting the
[01:21:51.600 --> 01:21:56.720]   things about Google. I guess it's valuable information for their. The reason is it has all
[01:21:56.720 --> 01:22:04.480]   these mechanisms to be able to distribute through maps, through phones, through browsers, through,
[01:22:04.480 --> 01:22:11.680]   I think that they make sense as a great way. When disaster strikes is Facebook really the
[01:22:11.680 --> 01:22:15.840]   first place you're going to turn? That safety check is cool. I mean, there's been some problems
[01:22:15.840 --> 01:22:21.920]   with it. There's always the issue of if you're in an infected area, where there's been a tornado
[01:22:21.920 --> 01:22:28.000]   or tsunami, and you don't use Facebook or you don't check in and people might think they didn't
[01:22:28.000 --> 01:22:33.760]   make it. It's not universal enough. This isn't really like this. This collates information you
[01:22:33.760 --> 01:22:39.600]   might need to know from governments and other authoritative organizations. So that's why they
[01:22:39.600 --> 01:22:48.240]   want a human. It's a curation effort. In fairness, Google's past efforts at providing information in
[01:22:48.240 --> 01:22:55.120]   certain disasters or whatever has been amazing, providing maps and all kinds of things. Do you
[01:22:55.120 --> 01:23:01.200]   remember the flu map that they did and things like that? Yeah. They're good on data. And they
[01:23:01.200 --> 01:23:08.000]   will aggregate data from first responders, trusted media outlets, government agencies.
[01:23:08.000 --> 01:23:14.880]   And if you think about it, the best place for that is on the Google app,
[01:23:14.880 --> 01:23:20.000]   with the cards. Oh, I wonder if you'll be in Google now. They mention they say,
[01:23:20.000 --> 01:23:24.080]   if you're near a major crisis, you have to be in the vicinity of it and you search
[01:23:24.080 --> 01:23:28.400]   for related words or phrases on Google, you may see a banner indicating there's an ongoing crisis
[01:23:28.400 --> 01:23:34.720]   followed by emergency information and resources such as useful translations or phone numbers.
[01:23:34.720 --> 01:23:40.960]   So let's say you're in Thailand and there's a tsunami, but you speak English, you search for,
[01:23:40.960 --> 01:23:45.840]   what do I do in a tsunami? You could get some useful information there. If you install the
[01:23:45.840 --> 01:23:50.320]   latest version of the Google app and your location, oh, you're right. And your location is turned on,
[01:23:50.320 --> 01:23:55.040]   you may also receive a notification on your mobile devices home screen. That's a good place for it.
[01:23:55.040 --> 01:24:01.120]   And I would love for Google to get more aggressive about putting that screen in our faces better.
[01:24:02.080 --> 01:24:07.040]   At least on Google's lock screen. Yeah, absolutely. Why not? Make it optional,
[01:24:07.040 --> 01:24:11.440]   of course, but you have to go find it. And it doesn't quite work for that type.
[01:24:11.440 --> 01:24:15.040]   I also like this. They're going to do it on maps. So if we are looking at a map and we,
[01:24:15.040 --> 01:24:19.600]   you know, and there's tornadoes in tornado alley, we will see, even if we're not there, if we're
[01:24:19.600 --> 01:24:25.440]   in California, we'll see some sort of indication that there's something going on and there's an
[01:24:25.440 --> 01:24:29.680]   alert and you can click it and find out more. I think that's a really useful map information.
[01:24:29.680 --> 01:24:35.040]   I like that. I mean, well, they do it. I mean, they do it already with amber alerts, right?
[01:24:35.040 --> 01:24:39.920]   I mean, I know that's built into the phone functionality. I subscribe to those. And that is in your face.
[01:24:39.920 --> 01:24:44.480]   Excuse me. It really does get your attention when there's an amber alert.
[01:24:44.480 --> 01:24:50.800]   Right. No, I agree with you. I'm just going to zoom out here, see if there's anything going on
[01:24:50.800 --> 01:24:54.960]   in the world. I mean, a lot of the Facebook things, you know, they've been touching go with
[01:24:55.520 --> 01:24:59.680]   with their service. It's mostly about reassuring loved ones that you're okay in a disaster.
[01:24:59.680 --> 01:25:02.640]   World has disappeared. Yeah. No, that's it. Oh, my God.
[01:25:02.640 --> 01:25:09.840]   Tiny blue dot right there. Oh, my God. Okay. Never mind. Yeah. And, you know, but it's like,
[01:25:09.840 --> 01:25:13.520]   you know, if there's a disaster in Australia and Jeff doesn't check in and, you know, everybody's
[01:25:13.520 --> 01:25:20.240]   like, well, he had a good run. He was he had a good life. The only thing I was good bandwidth.
[01:25:20.240 --> 01:25:26.880]   Is there it? By the way, this is drive drives me crazy. See that there. This guy, I'm not going to
[01:25:26.880 --> 01:25:33.040]   highlight it because it'll show his name. Yeah. In Joplin, Missouri has shared his location.
[01:25:33.040 --> 01:25:40.400]   What do you care? Yeah. What did we do about? Can I just can I get rid of that?
[01:25:40.400 --> 01:25:44.160]   Yeah, it's a good question because people do that with me. See, here's somebody in England.
[01:25:44.160 --> 01:25:47.040]   I get it all the time. I'm like, I don't first of all, I don't need to know.
[01:25:47.040 --> 01:25:50.240]   No, you don't want to see them on the map. If I were in your family, I might care,
[01:25:50.240 --> 01:25:55.600]   but I don't want to see these guys. Same thing on ways when ways to hold somebody is driving.
[01:25:55.600 --> 01:26:01.120]   How can I possibly use that information? Right. Trying to be a social network.
[01:26:01.120 --> 01:26:07.040]   It's it's an attempt to be so stupid social. Yeah. Well, Google should at least give you controls.
[01:26:07.040 --> 01:26:12.000]   Like if they aren't in your contact list, for instance, I don't they shouldn't be able to add
[01:26:12.000 --> 01:26:18.160]   their face to my map. Worst thing about ways though is when it says, it makes you confirm that
[01:26:18.160 --> 01:26:22.160]   you're not driving. It's like, what are you, my mother? Oh, yeah. Well, I don't know if I
[01:26:22.160 --> 01:26:26.800]   does do that for local laws and stuff. That's that's that's why they have to do that. I mean,
[01:26:26.800 --> 01:26:30.320]   yeah, they have to Google Maps doesn't when you get in turn by turn direction. That's
[01:26:30.320 --> 01:26:35.360]   in company. Yeah. Ways will now be part of Android Auto. It's coming soon to
[01:26:37.280 --> 01:26:41.280]   Auto. What is it? Apple's thing car, Apple car. I can't remember.
[01:26:41.280 --> 01:26:48.800]   That did you ever get a car with Android Auto? Jeff, you know you. So here's the deal. So, but
[01:26:48.800 --> 01:26:54.480]   yeah, so I actually read a post about this because I tortured all my friends, including on Twig
[01:26:54.480 --> 01:27:00.320]   about this car. I bought a Mazda CX5, which I absolutely adore. Love this thing. And I gave up
[01:27:00.320 --> 01:27:03.680]   on getting Android Auto. I said to hell with it. And then after I got it, they announced that
[01:27:03.680 --> 01:27:07.200]   they're going to port Android Auto onto it. We don't have a date yet, but they've announced that.
[01:27:07.200 --> 01:27:13.520]   So I will get Android Auto in the car. Yay. Nice. We're looking at a place about it,
[01:27:13.520 --> 01:27:18.000]   and I won't use it and I'll send it back. But you know, I'll get it. Here's Roberto Baldwin
[01:27:18.000 --> 01:27:25.280]   showing how it works on us. This is a Chevy Cruz. Chevy's one of the cars that has Android Auto.
[01:27:25.280 --> 01:27:29.600]   I think we're looking at a bolt. Lisa wants to buy a car at the end of the year.
[01:27:30.400 --> 01:27:38.160]   Her lease runs out on her old car. And I was thrilled to see that at least a couple of the cars,
[01:27:38.160 --> 01:27:41.680]   she wants an electric car. She's looking at have Android Auto. That'll be fantastic.
[01:27:41.680 --> 01:27:47.600]   CarPlay, Apple's CarPlay. Yeah. Also, by the way, there are instructions for the Mazda,
[01:27:47.600 --> 01:27:54.000]   I could sideload Android Auto into the car. Oh, good. Somebody, somebody came up with something
[01:27:54.000 --> 01:27:59.840]   for that, but I don't think I will. I love brick my car. I love ways. And I think having
[01:27:59.840 --> 01:28:04.960]   ways on your dashboard, you could have, you know, it's Google Maps before, I guess apps have to
[01:28:04.960 --> 01:28:10.240]   kind of prove themselves. But there is one thing that worries me a little bit. And Roberto is pointing
[01:28:10.240 --> 01:28:17.600]   this out right now. If you look at the dashboard, he's got that ways screen where you can report
[01:28:17.600 --> 01:28:22.560]   hazards ahead. I don't think that that's an example of ways, you know, ways should say,
[01:28:22.560 --> 01:28:27.200]   you can't do this right now. You're driving. Well, yeah, I mean, I,
[01:28:27.200 --> 01:28:32.240]   I, plus, plus it's the stupidest, stupidest alerts, you know, car to the side. You got to
[01:28:32.240 --> 01:28:37.600]   get it was fine. My favorite is pothole ahead. No s. Well, if there's a big pothole,
[01:28:37.600 --> 01:28:43.520]   potholes everywhere. When you have a whole ahead, I'd want to know. Yeah. Then you get these
[01:28:43.520 --> 01:28:47.760]   jerks is probably somebody's kid. You're in a rainy day. They'll say every two miles, they'll
[01:28:47.760 --> 01:28:54.880]   say it's rain ahead, rain ahead, rain ahead. You can't turn that off. Yeah, I do. I have the
[01:28:54.880 --> 01:28:59.360]   thing where you wave your hand over your phone and then you can say it. But this is on screen.
[01:28:59.360 --> 01:29:03.200]   I don't think they have that feature and not Android Auto. So yeah, I don't know.
[01:29:03.200 --> 01:29:09.040]   That always kind of made me I've tried to indoor Android Auto a little bit running it on the phone
[01:29:09.040 --> 01:29:13.200]   because you can do that now too. If you don't have the option of putting it in the car,
[01:29:13.200 --> 01:29:20.240]   and it's okay. It's all right. I don't know. I find it just as easy to keep the phone running
[01:29:20.240 --> 01:29:25.280]   the way it is and use it or not use it. Sorry. It's a little bigger though on the screen, right?
[01:29:25.280 --> 01:29:29.600]   It's bigger icons a little bit easier to manipulate. They blow things up a little bit
[01:29:29.600 --> 01:29:34.640]   ease a little bit on your phone, make it easier to read. But they also disable some things that
[01:29:34.640 --> 01:29:40.320]   you can't do everything. Right. So yeah, which is here. Yeah.
[01:29:40.320 --> 01:29:48.080]   I'd rather have a my mouse use Android Auto in one car. Just it. Yeah, I got to say it did.
[01:29:48.080 --> 01:29:52.720]   And for all the desire for me to get it, it irritated me and how much it
[01:29:52.720 --> 01:29:56.880]   and my mic is your point, how much it was a babysitter. Yeah, you can't take that with you.
[01:29:56.880 --> 01:30:00.240]   Can't take it with you. Jeff.
[01:30:00.240 --> 01:30:04.240]   Or what's that commercial down? You're not taking that with you.
[01:30:04.240 --> 01:30:07.040]   Andrea, I'm taking that. Alicia.
[01:30:07.040 --> 01:30:16.080]   What's it like outside? Let's see. Android users are going to get the latest emoji soon.
[01:30:16.080 --> 01:30:21.040]   We're going to do on Saturday our friend who's on the Unicode Committee, the emoji committee
[01:30:21.040 --> 01:30:26.000]   at the Unicorn Consortium is going to stop by. They're talking about new emojis already.
[01:30:26.000 --> 01:30:30.800]   They do it all the time. But notice something about these new Android emojis.
[01:30:30.800 --> 01:30:35.440]   They're not blobbed. They're circles. Highly controversial.
[01:30:35.440 --> 01:30:37.920]   Are you going to miss the blob?
[01:30:37.920 --> 01:30:43.840]   Well, I mean, I think people liked them because it was a differentiator.
[01:30:43.840 --> 01:30:48.400]   And now they're joining the herd. But you could actually get your own emoji, Leo.
[01:30:48.400 --> 01:30:55.920]   You know people on the committee, right? So, well, Tonya, Tonya Hall got a milkshake emoji.
[01:30:55.920 --> 01:30:59.760]   She talked to Jeremy and said, there needs to be a milkshake emoji.
[01:30:59.760 --> 01:31:02.800]   It's a good point. And he said, you're right. Now they don't call it. Okay.
[01:31:02.800 --> 01:31:05.520]   Just so you know, they don't call it milkshake. They call it glass was straw.
[01:31:05.520 --> 01:31:09.920]   You can decide what's inside. I say it's a milkshake.
[01:31:09.920 --> 01:31:12.400]   Well, what would the perfect Leo emoji be?
[01:31:13.360 --> 01:31:16.480]   Hmm. What would it be? Well, he already got the middle finger. Let's see.
[01:31:16.480 --> 01:31:23.840]   Why listen to my show? I don't know. I don't know what it would be.
[01:31:23.840 --> 01:31:29.120]   To have you guys, your guys are all Twitter verified. You got the blue check, right?
[01:31:29.120 --> 01:31:35.680]   Now you can meet other people with blue checks. It's a dating app for verified Twitter users
[01:31:35.680 --> 01:31:38.080]   called blue. Wow, that's a terrible idea.
[01:31:42.080 --> 01:31:46.000]   You can't. It's free to join if you're verified. It's rolling out San Francisco,
[01:31:46.000 --> 01:31:50.800]   Los Angeles, New York, London, and Tokyo. It's only going to go live once it has a thousand
[01:31:50.800 --> 01:31:55.840]   local members in your neighborhood. Only 150,000 people have the blue checkmark in Twitter.
[01:31:55.840 --> 01:32:00.720]   And most of them come from the world of journalism and media.
[01:32:00.720 --> 01:32:04.000]   Exactly. That's the, I mean, that you really want to meet us.
[01:32:04.000 --> 01:32:07.520]   No, you don't. You don't.
[01:32:10.880 --> 01:32:16.400]   Actually, actual celebrities, TechCrunch points out like Justin Bieber and Taylor Swift probably
[01:32:16.400 --> 01:32:25.120]   don't need to date using their Twitter verified status. But it's, you know, hey, it's an interesting
[01:32:25.120 --> 01:32:32.560]   idea. So it's from the same folks who brought you love flutter, which is another Twitter.
[01:32:32.560 --> 01:32:37.120]   Twitter dating app. I don't even want to know what that is.
[01:32:38.000 --> 01:32:43.760]   I want to sign up for blue. I love flutter, but I, but I'm not on the market and I just,
[01:32:43.760 --> 01:32:48.480]   I just want to see what it, you know, like, could you even meet anybody that way?
[01:32:48.480 --> 01:32:53.680]   But I know if I signed up for it, it wouldn't go over well in my house.
[01:32:53.680 --> 01:33:01.520]   Date, date verified Twitter users. Twitter verified? Get blue free.
[01:33:02.560 --> 01:33:10.160]   Lisa is not verified. She can't get verified. Even though she's the CEO of a major media
[01:33:10.160 --> 01:33:14.320]   company behind the camera instead of in front of it. Yeah, it bugs the hell out of her.
[01:33:14.320 --> 01:33:23.280]   Well, you know, yeah, it's, I think, I mean, ostensibly the reason they have verified users is
[01:33:23.280 --> 01:33:29.840]   because people imitate your name. And I petition them actually. I was, I was unverified for a
[01:33:29.840 --> 01:33:34.080]   long, long time. There is a form now. Yeah, there is. And even the first time I filled it out,
[01:33:34.080 --> 01:33:39.360]   they ignored it. And then, and then I sent them the list of the other Mike Elkins using my profile
[01:33:39.360 --> 01:33:43.120]   picture and there was dozens of them. Right. I'm like, look at this. This is why you have verified.
[01:33:43.120 --> 01:33:46.880]   I ain't gonna be verified. Then they verify me. Oh, that work. Yeah. I think that they,
[01:33:46.880 --> 01:33:52.480]   I was a real Twitter basher for a long time. And I always suspected that they withheld the
[01:33:52.480 --> 01:33:57.520]   verification for that reason. Exactly. And, and then eventually I just demonstrated they're just
[01:33:57.520 --> 01:34:00.880]   all these people using my name and profile picture. And so, yeah.
[01:34:00.880 --> 01:34:05.600]   So this is, you can now date celebrities discreetly.
[01:34:05.600 --> 01:34:14.080]   You've got a blue, a blue check. And journalists, mostly journalists. The safest dating community
[01:34:14.080 --> 01:34:19.760]   ever. Do you know what's going on in the tech community these days? Twitter, BlueTick,
[01:34:19.760 --> 01:34:25.680]   you're in. This is so silly. You know, I'm sure this isn't really about dating. This is about mining
[01:34:26.640 --> 01:34:32.800]   something. This is about, this is about creating an exclusive club and using it a different way.
[01:34:32.800 --> 01:34:37.040]   That's what I think. That's what I think. This is about changing the gene pool. Yeah.
[01:34:37.040 --> 01:34:44.080]   For the worse, what if, what if the world were populated only by the sentence of BlueTick holders?
[01:34:44.080 --> 01:34:51.200]   Be like gatica, but you'd have to have a be verified on Twitter instead of the.
[01:34:51.200 --> 01:34:55.360]   Twitter says it's taking action against 10 times the numbers of accounts it did.
[01:34:56.080 --> 01:35:02.720]   Just a year ago, the abusive accounts and it's working. Do we sense that it's working? Any of us?
[01:35:02.720 --> 01:35:07.040]   You know, I was listening to an interview with
[01:35:07.040 --> 01:35:13.680]   what's his name, the guy that you were talking about a couple of weeks ago,
[01:35:13.680 --> 01:35:19.200]   Camille Nandjani, right? The guy in Silicon Valley, right? Oh, right, right. Yeah. And his new
[01:35:19.200 --> 01:35:24.160]   movie, The Big Sick. Yeah. And he said, he was talking about Twitter. He said, this is on fresh air.
[01:35:24.160 --> 01:35:29.760]   He said, I don't read my @ replies and I turn. He says, I highly recommend everybody turn on
[01:35:29.760 --> 01:35:34.640]   the quality filter. The problem that probably works. He doesn't see anything. Right. But the
[01:35:34.640 --> 01:35:38.640]   problem with that is he doesn't see it. See, from I can't do it, but for him, I guess he doesn't
[01:35:38.640 --> 01:35:44.320]   care if somebody's saying bad things about him. But I kind of like to know. Yeah. Yeah.
[01:35:44.320 --> 01:35:48.800]   Dinesh in the Silicon Valley. Yeah. Yeah. And and you're going to go see that movie tonight,
[01:35:48.800 --> 01:35:52.800]   by the way. Oh, we see that, Jeff. You were, we were singing its praises. The Big Sick. Which
[01:35:52.800 --> 01:35:56.800]   one? The Big Sick. I liked it a lot. I liked it a lot. And of course, there was kind of a PC
[01:35:56.800 --> 01:36:03.680]   response and that South Asian women aren't presented as well because they're the foils in
[01:36:03.680 --> 01:36:11.520]   the comedy plot. Kind of inevitable. But but I think it's really good. I like to sort of their
[01:36:11.520 --> 01:36:19.440]   story. Yeah. Emily V. Yeah, it is. It is. No, it's charming and fun and it was great.
[01:36:19.440 --> 01:36:25.040]   Charlie Warz. Go ahead. Go ahead. Don Kirk. Who? Don Kirk. Are you going to go see Don Kirk?
[01:36:25.040 --> 01:36:30.640]   I saw Don Kirk. And? Oh, you did. Oh, already. What do you think? Okay, Leo. No spoilers.
[01:36:30.640 --> 01:36:39.040]   Well, I don't want to say how it ends. Yeah, it's very good. I like Christopher Nolan. He likes
[01:36:39.040 --> 01:36:43.600]   to play with time. So there's it's a jumps around in time a little bit, which I think might confuse
[01:36:43.600 --> 01:36:47.920]   people who aren't familiar with inception in his other movies. But I thought it was really good.
[01:36:47.920 --> 01:36:54.160]   Yeah, it's very well done. It's you know, it's a very important story of World War two, but a very
[01:36:54.160 --> 01:37:01.040]   small slice of World War two's history. And I thought it was very well done. Yeah, the Germans win,
[01:37:01.040 --> 01:37:08.960]   but only briefly. I saw Wonder Woman for the first time last night. Oh, really? Oh, he's a
[01:37:08.960 --> 01:37:13.040]   hunter wood. It was fantastic in it. Clear under woods. Yeah. Princess Brighterwood. Yeah, she's
[01:37:13.040 --> 01:37:20.080]   Jenny. She's fantastic. Yeah, Jenny from the hood. Yeah. I love where we really that we veered all
[01:37:20.080 --> 01:37:26.240]   over the place with that one. I love Claire underwood. Yeah. Twitter says that it's getting better,
[01:37:26.240 --> 01:37:32.800]   but Charlie Wartzel writing in Buzzfeed news says it's not it's not getting any better. Yeah,
[01:37:32.800 --> 01:37:39.120]   there's just as much rude stuff as ever. There actually it actually might have gotten better
[01:37:40.320 --> 01:37:46.080]   in terms of their tools and worse because of the election. So I I've noticed that a lot of the
[01:37:46.080 --> 01:37:53.120]   vitriol and stupidity is all around the new president. There's a lot of that. And I don't know
[01:37:53.120 --> 01:37:57.840]   if you saw a series of articles that basically talked about how people are trying to get into the
[01:37:57.840 --> 01:38:03.680]   first first suppliers. Yes, because they figured the the president will see it. I started that. Have
[01:38:03.680 --> 01:38:07.680]   you been blocked yet? I have been blocked by the president. Yeah. And so I'm so proud of it. Yeah,
[01:38:07.680 --> 01:38:09.840]   I should get another Twitter badge. I got blocked by
[01:38:09.840 --> 01:38:17.520]   junior, but I'm still trying to get up to Donald Trump senior. I haven't blocked yet. Yeah.
[01:38:17.520 --> 01:38:23.200]   You've locked because he's the one he follows me. Yeah. Perseverance. That's the key, Jeff. But
[01:38:23.200 --> 01:38:28.160]   but anyway, I wrote this article for medium some time ago saying if you get in if you reply
[01:38:28.160 --> 01:38:35.040]   within the first three seconds, then the president won't see it, but his his fans will see it and
[01:38:35.040 --> 01:38:40.720]   you can it's a way to reach it to go across the bubbles and then recode picked it up and they
[01:38:40.720 --> 01:38:46.480]   publish my medium post and then BuzzFeed did a thing referencing the recode article and lots and
[01:38:46.480 --> 01:38:50.800]   lots of people are doing it now. It's like the new thing. And but here's another interesting.
[01:38:50.800 --> 01:38:55.920]   BuzzFeed says it really unless you're a celebrity or a journalist, you're not going to get any
[01:38:55.920 --> 01:39:01.120]   satisfaction if you report somebody on Twitter. Absolutely. That's the problem that this is the
[01:39:01.120 --> 01:39:04.560]   problem with with with Twitter. They're bragging about how their system is better, but they still
[01:39:04.560 --> 01:39:09.520]   don't let people delete replies. They have to be a little bit before they reply. This is the key
[01:39:09.520 --> 01:39:13.200]   and they want to maintain control so you can bag and plead and they'll basically like you just
[01:39:13.200 --> 01:39:19.520]   said, Leo, they will listen to you or not listen to you based on who you are. It's it's really a
[01:39:19.520 --> 01:39:25.200]   it's really a kind of a bad system. Yeah, that's some really bad example. The associate repressed
[01:39:25.200 --> 01:39:30.960]   just put out a tweet that the Twitter is not going crazy over. The AP has deleted a tweet
[01:39:30.960 --> 01:39:36.160]   about a draft being born because it included a photo of the wrong giraffe. A new tweet is upcoming.
[01:39:36.160 --> 01:39:41.840]   Fake news. Fake news. People are loving that. They don't want to. But how can you tell one
[01:39:41.840 --> 01:39:46.640]   giraffe from another? They all know. I'm not going to stick my neck. I shouldn't say that. It's racist.
[01:39:46.640 --> 01:39:51.360]   Oh, all giraffes look the same. But but but I do have a prepared statement about this whole
[01:39:51.360 --> 01:39:56.640]   area where people say fake news. Fake news providers do not issue retractions. They don't
[01:39:56.640 --> 01:40:02.560]   issue apologies. They don't do corrections. They deliberately say fake things and then they spread
[01:40:02.560 --> 01:40:10.400]   it more. And that's the difference. So you can't criticize CNN, for example, as fake news when they
[01:40:10.400 --> 01:40:15.280]   fire the people who did it, issue an apology, all that stuff. That's not what fake news
[01:40:15.280 --> 01:40:22.480]   organizations do. So somebody's issuing a correction or attraction. That is not if you want to read a
[01:40:22.480 --> 01:40:27.680]   really depressing article. Read Charlie Wartzell's article in BuzzFeed News about Twitter.
[01:40:27.680 --> 01:40:32.880]   And there's plenty of examples not for the queasy, not for the week of
[01:40:32.880 --> 01:40:38.080]   so what should they do? What should you know, I we've we've discussed this over the years and I
[01:40:38.080 --> 01:40:42.240]   you know, I've always said that I love the open Twitter and the open Twitter enables
[01:40:42.240 --> 01:40:48.720]   people to start revolutions. But is Twitter responsible?
[01:40:50.320 --> 01:40:56.320]   If Google and Facebook are each starting to account for quality more, which they say they're starting
[01:40:56.320 --> 01:41:00.080]   to do and I see it happening, Twitter does not at all should Twitter.
[01:41:00.080 --> 01:41:08.000]   I'm not sure what the I'm not sure exactly what the question is, but they make themselves
[01:41:08.000 --> 01:41:12.880]   responsible because of the way that they do reporting. That's on the fake news side. And in
[01:41:12.880 --> 01:41:16.640]   making the content better, they're doing that through algorithms, which is another bad thing.
[01:41:17.280 --> 01:41:23.120]   So what we they make it so impossible, right? So with the problem is their default is always
[01:41:23.120 --> 01:41:27.440]   to not take it down because they're Twitter. Right. And pretty much Facebook's default is that
[01:41:27.440 --> 01:41:32.240]   too, but Facebook can then stop promoting it. So at least that helps. But should Twitter have
[01:41:32.240 --> 01:41:43.760]   a should Twitter enact a more a policy that enables people who complain to get stuff taken down or is
[01:41:43.760 --> 01:41:51.040]   that counter to the internet and Twitter ethos? They need to set up mechanisms so that it's self
[01:41:51.040 --> 01:41:58.640]   policing in a way to the greatest extent possible. If they are the ones that
[01:41:58.640 --> 01:42:03.440]   get aimed, it'll get gamed. Yeah, absolutely. Right. Right. And then
[01:42:03.440 --> 01:42:07.040]   have the car means will come in and complain about you, Mike, I'll get in your doomed. Yeah.
[01:42:07.040 --> 01:42:13.120]   Yeah. I mean, it's it's it's problematic because they basically have policies that, you know,
[01:42:13.120 --> 01:42:18.240]   if you're threatening somebody, you get booted or whatever, certain they added racism, some other
[01:42:18.240 --> 01:42:22.800]   things, but like what is racism? I reported a whole bunch of people for racism on Twitter and
[01:42:22.800 --> 01:42:27.840]   nothing happens. And you know, it's different ideas around the world about what what that
[01:42:27.840 --> 01:42:36.880]   means. But you should be able to craft your own sort of social space on on all these places and
[01:42:36.880 --> 01:42:42.320]   have the replies be under the control of the person who did the post that people are replying to.
[01:42:42.320 --> 01:42:46.000]   And again, I'm, you know, broken record on this issue, but that's really the key thing. That's
[01:42:46.000 --> 01:42:49.600]   Facebook lets you do it. Google plus let you do it. Almost everybody lets you do it. But Twitter
[01:42:49.600 --> 01:42:54.400]   doesn't let you do it. Twitter themselves at the corporate level want to maintain personal
[01:42:54.400 --> 01:42:59.200]   control over who gets booted, who you see, who you don't see and all that kind of stuff through
[01:42:59.200 --> 01:43:02.320]   both algorithms and also the reporting system. Just to clear somebody in the chat room, some
[01:43:02.320 --> 01:43:06.240]   idiot in the chat room said this Twitter harassment thing boils down to this. These journalists and
[01:43:06.240 --> 01:43:10.400]   celebs are used to saying something and having it be gospel. They hate being talked back to,
[01:43:10.400 --> 01:43:15.280]   especially by the unwashed masses. But that's not what we're talking about. We're not saying
[01:43:15.280 --> 01:43:25.760]   we want to have criticism band or disagreement band and vile threats against your person should
[01:43:25.760 --> 01:43:30.560]   be the person should be banned. It's not it's not so we want to recapture civility.
[01:43:30.560 --> 01:43:35.760]   It doesn't even have to be civil. I don't care if somebody's on civil. But if they but
[01:43:35.760 --> 01:43:39.280]   look at this Charlie Wartzel article and see if you think I'm not showing it now.
[01:43:39.280 --> 01:43:46.480]   See if you think those tweets, I'm not going to show them on the air, are somehow valid criticism.
[01:43:46.480 --> 01:43:50.960]   If somebody says, I have this, I have this gun and I'm coming to your house and as a picture of
[01:43:50.960 --> 01:43:56.480]   him with the gun, that's valid criticism. Hell no. Well, that's a threatening tweet and the guy's
[01:43:56.480 --> 01:44:02.560]   account should be taken down. But again, these these threats are as soon as they
[01:44:03.760 --> 01:44:09.360]   ban successfully ban explicit threats, then they figure out there's always testing the limits.
[01:44:09.360 --> 01:44:13.120]   So it's like they learn where the edges are. I mean, that's fine. If they stay within the edges,
[01:44:13.120 --> 01:44:18.080]   that's fine. Right. You should be you know, you should be nice. Is that different from I'm going
[01:44:18.080 --> 01:44:24.160]   to knife you? I mean, is it? I mean, it's like it's a fine line. So here's part of what I think
[01:44:24.160 --> 01:44:30.320]   is happening in society. There are these pictures somebody last week tweeted a montage of photos of
[01:44:30.320 --> 01:44:34.560]   those of those various people in various parts of the country who did things like
[01:44:34.560 --> 01:44:40.480]   scream horrible racist things at kids birthday parties and parks. Somebody, God bless, on the
[01:44:40.480 --> 01:44:45.840]   internet, videos them and shames them online. And the next thing you see is them crying their
[01:44:45.840 --> 01:44:52.880]   eyes out in court. And I realized it's as if they got transported from a land of fear and hate
[01:44:52.880 --> 01:44:59.280]   back to civilization. But but the question is, do you have to go that far overboard to reclaim
[01:44:59.280 --> 01:45:08.160]   your civility, to reclaim decency, to reclaim your sense of humanity? Or do we intervene before that?
[01:45:08.160 --> 01:45:15.440]   By the way, Twitter's quarterly results come out tomorrow. We'll find out if any of this affects
[01:45:15.440 --> 01:45:21.440]   the bottom line. One of the only thing stock market cares about is how many people use Twitter.
[01:45:21.440 --> 01:45:26.640]   This is the reason why there's no incentive for Twitter to do anything about this.
[01:45:26.640 --> 01:45:30.560]   Because as long as they show growth and there's more people on it, they don't care what those
[01:45:30.560 --> 01:45:35.840]   people are saying on it or how they're acting on it. Twitter said last quarter they had three
[01:45:35.840 --> 01:45:41.040]   to 28 million users just as a benchmark. You can see how that if it's up or down, that's how
[01:45:41.040 --> 01:45:49.680]   Twitter's stock will be. It's currently Twitter's stock is up 41% since it's low in April.
[01:45:49.680 --> 01:45:54.960]   So there people people believe in Twitter. Not sure why. I think because of the president,
[01:45:54.960 --> 01:46:00.320]   frankly, I think he didn't have Donald. I don't know if there'd be anything exciting about Twitter
[01:46:00.320 --> 01:46:04.800]   these days. Twitter is the most important thing. He's done more for Twitter than probably anything
[01:46:04.800 --> 01:46:11.440]   in the last few years. Well, the funny thing is that it's really not him. It's the media that
[01:46:11.440 --> 01:46:17.120]   has made his Twitter account the center of attention. But when he makes as he did this morning,
[01:46:17.120 --> 01:46:22.640]   announces on Twitter and nowhere else that they're going to ban transgender
[01:46:23.760 --> 01:46:29.200]   people from the military, that's how he makes his executive order. That makes Twitter extremely
[01:46:29.200 --> 01:46:34.480]   important. But it doesn't matter what the media says. No, it's only the media that's making it
[01:46:34.480 --> 01:46:39.360]   into the phenomenon that it is. Let me give you an example. Former President Barack Obama
[01:46:39.360 --> 01:46:45.040]   has massively more followers than the president does, even the combined potus and
[01:46:45.040 --> 01:46:51.920]   and real Donald Trump accounts. And his average tweet gets far more engagement, far more sharing,
[01:46:51.920 --> 01:46:57.360]   far more likes, all that stuff. And you never even nobody ever even talks about it because
[01:46:57.360 --> 01:47:01.360]   it's all just bland. He's not the president of the United States. But when he even when he was,
[01:47:01.360 --> 01:47:04.320]   it's all bland. Like, you know, it's nothing. Oh, I see what you're saying.
[01:47:04.320 --> 01:47:10.000]   And so the media doesn't talk about his tweets, they ignore his tweets. But the media is the thing
[01:47:10.000 --> 01:47:17.440]   that amplifies twin Trump's tweets. I never saw Obama's speech to the Boy Scouts or George W's
[01:47:17.440 --> 01:47:23.920]   or George A. W's because it was bland, pablam, you know, be good citizens go out there.
[01:47:23.920 --> 01:47:26.320]   So but that's where Trump is really excellent.
[01:47:26.320 --> 01:47:32.400]   Entertaining. Well, he's so here's here's how I look at it. I look at it.
[01:47:32.400 --> 01:47:38.880]   He's Trump talks about how he hates the media. He loves the media. The media is his instrument.
[01:47:38.880 --> 01:47:44.080]   And Twitter is how he plays the media. Yeah. I mean, this is this is his this is his leaver.
[01:47:44.080 --> 01:47:49.200]   No, he's a master of it. But it's not just Twitter. I got to tell you, he's a master of
[01:47:49.200 --> 01:47:54.720]   media manipulation in general. He in every way uses his speeches and rallies and also Twitter
[01:47:54.720 --> 01:48:00.480]   mostly to get the media to to cover him incessantly. Right. And but again, it's not he's not having
[01:48:00.480 --> 01:48:05.280]   the impact on Twitter. He's having the impact through Twitter on the media. Okay.
[01:48:05.280 --> 01:48:09.680]   So you don't think he's a benefit to Twitter and that stock price? I don't think he should be.
[01:48:10.320 --> 01:48:15.040]   I do think he is absolutely. I mean, he gets every media outlet to talk about Twitter for starters.
[01:48:15.040 --> 01:48:19.280]   I mean, that's really right. What what what that's all I'm saying phenomenon is. Yeah,
[01:48:19.280 --> 01:48:22.800]   if it weren't for Donald Trump, I don't know if Twitter's stock price would be up 41% since
[01:48:22.800 --> 01:48:28.080]   April. I doubt it would be. I'm I don't doubt that at all. That you're absolutely right about that.
[01:48:28.080 --> 01:48:35.680]   Google study says that I was surprised that this number was so low. Ransomware victims have paid
[01:48:35.680 --> 01:48:39.760]   out more than $25 million since last year. I would have thought it'd been a lot higher.
[01:48:39.760 --> 01:48:48.240]   Yeah. But yeah, actually over two years. For reality. Yeah. Maybe that's it. Maybe that's it.
[01:48:48.240 --> 01:48:56.560]   Maybe ransomware is over hyped. And well, a lot some ransomware asks for small amounts. Some
[01:48:56.560 --> 01:49:01.440]   ransomware, the mechanism that they use to threaten is broken. So even if you try to pay,
[01:49:01.440 --> 01:49:06.560]   that doesn't work. Right. And then a lot of people just don't pay it for one reason or another. So.
[01:49:06.560 --> 01:49:09.600]   So on Windows weekly earlier today,
[01:49:09.600 --> 01:49:20.240]   Paul Therat pick of the week, Kaspersky antivirus, the free version, Kaspersky is the is the Russian
[01:49:20.240 --> 01:49:24.160]   antivirus company was a very it still is a very good antivirus. I don't have anything wrong with
[01:49:24.160 --> 01:49:29.040]   the antivirus. But there's some question about Eugene Kaspersky in the company itself. In fact,
[01:49:29.040 --> 01:49:35.120]   there seemed to be a smoking gun and emails uncovered by I think Bloomberg Business Week
[01:49:35.120 --> 01:49:41.520]   that showed the Kaspersky, the company worked for the FSB, the Russian security firm that
[01:49:41.520 --> 01:49:46.720]   had written software for the federal for Russian government. So I'm just curious what you guys
[01:49:46.720 --> 01:49:53.520]   think. Aaron, would you would you install free software from Kaspersky? No, not this point.
[01:49:55.040 --> 01:49:59.600]   Well, I mean, we can set aside the dubious value of an antivirus these days.
[01:49:59.600 --> 01:50:05.520]   But let's say, yeah, I get I get asked that question all the time with with all the latest
[01:50:05.520 --> 01:50:09.440]   news about these things is, Oh, which antivirus thing should I install a VAP?
[01:50:09.440 --> 01:50:15.200]   Should I say no, no, just keep windows up to date and and run that if you're running Windows
[01:50:15.200 --> 01:50:19.840]   or use a Chromebook. That's right. He's a Chromebook or run Linux. How about that?
[01:50:21.840 --> 01:50:25.200]   I don't know. I mean, I don't want to cast aspersions on the guy if he's innocent.
[01:50:25.200 --> 01:50:30.160]   I'm not met Kaspersky. Everybody loved me. This is by the way, why he gets very smart.
[01:50:30.160 --> 01:50:35.040]   This is why he gets a lot of free pass from a lot of media. Everybody's met him. I met him,
[01:50:35.040 --> 01:50:37.840]   but a lot of people met him, Paul's met him, and they love the guy.
[01:50:37.840 --> 01:50:44.960]   Real charmer. I find charming people to be more suspicious myself. Yes, yes.
[01:50:47.920 --> 01:50:53.200]   Oh, I'm a Russian spy for sure. I'm one of those Frank Underwood.
[01:50:53.200 --> 01:50:54.880]   Frank Underwood. You're a sleeper.
[01:50:54.880 --> 01:50:56.720]   Well, you are. Frank Underwood. Very charming.
[01:50:56.720 --> 01:51:01.600]   You're like, you're like in the Americas. All right. I apologize, Eugene. I,
[01:51:01.600 --> 01:51:05.520]   Well, what do you think, Jeff, you know him? Is he a Russian spy?
[01:51:05.520 --> 01:51:09.840]   I might trust him personally, but I can't trust anything out of that country.
[01:51:09.840 --> 01:51:16.560]   No. And Congress, by the way, has said nobody's to install Kaspersky products on any computer used.
[01:51:17.200 --> 01:51:20.560]   I think in the US government, I would think.
[01:51:20.560 --> 01:51:24.160]   And if you can't trust Congress' software recommendations, what can you trust?
[01:51:24.160 --> 01:51:30.240]   Well, they also remember they said, was the Commerce Department said,
[01:51:30.240 --> 01:51:38.880]   the NOAA, Huawei or CTE phones. Let's see. This is from July 5th. Congress casts a suspicious
[01:51:38.880 --> 01:51:47.120]   eye on Russia's Kaspersky lab. Best thing, Kaspersions. Best by loads Kaspersky software on its computers.
[01:51:47.120 --> 01:51:53.760]   The Federal Bureau of Prisons uses Kaspersky. So do many state and local governments.
[01:51:53.760 --> 01:52:02.160]   NPR points out Kaspersky lab is also among our financial supporters. But the House and Senate
[01:52:02.160 --> 01:52:07.360]   Armed Services Committee have approved legislation that would bar the US military from owning or
[01:52:07.360 --> 01:52:12.720]   using any products made by Kaspersky. I don't know what the status of that law is at this point.
[01:52:12.720 --> 01:52:17.120]   Kaspersky lab is used by hundreds of thousands,
[01:52:17.120 --> 01:52:22.400]   if not millions of Americans said Marco Rubio, to each of our witnesses,
[01:52:22.400 --> 01:52:27.440]   the six intelligence agency chiefs speaking to the Senate Intelligence Committee,
[01:52:27.440 --> 01:52:31.520]   to each of our witnesses, I would ask, would any of you be comfortable with a Kaspersky lab
[01:52:31.520 --> 01:52:37.280]   software on your computer? Dan Coates, Director of National Intelligence, a resounding know for me,
[01:52:37.280 --> 01:52:43.600]   Mike Rogers, NSA Director. No, CIA Director, Mike Pompeo. No,
[01:52:43.600 --> 01:52:50.880]   Senator FBI acting FBI Director Andrew McCabe. No, sir. Defence intelligence agency director,
[01:52:50.880 --> 01:52:58.400]   Lieutenant General Vincent Stewart, no, Senator. And to get it unanimous, national geo spatial
[01:52:58.400 --> 01:53:03.680]   intelligence agency director. I'm glad we have one of those. Yes. Robert Cardillo, no, sir.
[01:53:04.880 --> 01:53:09.200]   So I mean, if it was open source, maybe, you know, because then you could take a look at it, right?
[01:53:09.200 --> 01:53:13.920]   But that's that's why we need open source software for this kind of stuff. You can take a look at
[01:53:13.920 --> 01:53:18.400]   the code and make sure it's okay. And this was before Kaspersky was offering a free copy to every
[01:53:18.400 --> 01:53:24.560]   American. I don't know, you know, it could go both ways. It could be he wants to, you know,
[01:53:24.560 --> 01:53:28.480]   make nice and say, look, I'm a nice guy. Yeah, it could be, hey,
[01:53:29.600 --> 01:53:34.560]   is free software, please take two. I don't know. Could be we don't know.
[01:53:34.560 --> 01:53:39.200]   I think if there is any nefarious relationship with the Russian government,
[01:53:39.200 --> 01:53:46.160]   how that would most likely play out is that they would have special access to information
[01:53:46.160 --> 01:53:51.200]   from that company. I don't think it's going to be malware on everybody's devices turning on the
[01:53:51.200 --> 01:53:56.480]   camera and beaming it back to Moscow. I really don't see that happening. But I do.
[01:53:56.480 --> 01:54:02.880]   What if though, what if it had a Trojan built into it that could be activated in a case of
[01:54:02.880 --> 01:54:08.320]   invasion? When the invasion happens red, red, dawn type of scenario. I'm ready.
[01:54:08.320 --> 01:54:13.680]   Yeah, it's your bunker. I got my bunker. You have an alternative. Get a gun.
[01:54:13.680 --> 01:54:17.360]   No, she says you'll shoot your your eye out. She won't.
[01:54:17.360 --> 01:54:23.680]   She has a gun, but I'm not allowed to get one. She likes that. That was a power. Yeah, maybe
[01:54:23.680 --> 01:54:30.560]   that's it. Maybe that's it. All right, let's take a break and get your tips and picks.
[01:54:30.560 --> 01:54:37.440]   Boys and boys. Stacy, Stacy, where is Stacy? She told us last week. Do you remember, Jeff?
[01:54:37.440 --> 01:54:42.640]   She's I think she's at an event. I feel like in Seattle, but I could be wrong.
[01:54:42.640 --> 01:54:47.680]   We're shipping you. Nobody knows. Or maybe it's just, oh, yeah, she said she was going
[01:54:47.680 --> 01:54:50.240]   somewhere. I think, yeah, but it was just vacation. Yeah, yeah, yeah, it was vacation.
[01:54:50.240 --> 01:54:52.480]   Yeah. Okay. For your wearer. How dare she.
[01:54:52.480 --> 01:54:54.720]   Good. Nobody can find Stacy. They don't know where she is.
[01:54:54.720 --> 01:54:59.120]   No, where in the world is Stacy. You're getting both of them.
[01:54:59.120 --> 01:55:04.800]   I know. I know where Jeff Jarvis is. He's in Australia. And again, thanks to what is it? The
[01:55:04.800 --> 01:55:10.720]   Sydney technical university technology, Sydney, university technology, Sydney,
[01:55:10.720 --> 01:55:16.960]   butts, butts for letting us use the studio and this and a great big thanks to Jeff Jarvis for
[01:55:16.960 --> 01:55:22.000]   getting up early in the morning to be on this show. That's the best dream we've ever had it.
[01:55:22.000 --> 01:55:24.000]   That's a very high quality, I must say.
[01:55:24.000 --> 01:55:29.360]   Has the sound thing been fixed? We're getting a little echo back.
[01:55:29.360 --> 01:55:32.800]   I don't know. I think it's not you. It's the software has nothing to do with it.
[01:55:32.800 --> 01:55:42.320]   What's, what's university of technical stuff? Also with this, Mike Elgin. Highly recommend
[01:55:42.320 --> 01:55:47.280]   you visit Mike's site and find out about the digital nomadic life.
[01:55:47.280 --> 01:55:53.280]   Gastronomad.net. Actually, yes, it's Gastronomad.net. So you can sign up for the Gastronomad event
[01:55:53.280 --> 01:55:59.120]   coming up in September. You still have room? We still do. We have interested party circling,
[01:55:59.120 --> 01:56:02.800]   but anybody wants to grab it? There's one spot for a couple left.
[01:56:02.800 --> 01:56:07.520]   Mike Elgin's Skype, somebody says, "It's so good. It looks like you're there in the studio. Isn't
[01:56:07.520 --> 01:56:15.520]   that amazing? What quality?" It's amazing. Yeah, technology. And also with Aaron Nukem,
[01:56:15.520 --> 01:56:19.600]   and you can follow his work on the Twitter. Yeah, we have your Twitter handle on here. That's
[01:56:19.600 --> 01:56:24.960]   what you wanted, right? Yeah, Twitter's file. I'm Aaron Nukem everywhere. So Facebook, Twitter,
[01:56:24.960 --> 01:56:33.280]   Google+, just type in Aaron Nukem. You'll find me. A-R-O-N-N-E-W-C-O-M-B. The B is silent. Or is it?
[01:56:33.280 --> 01:56:39.440]   It is silent. Okay. It's sort of there. Sometimes spelled with an E.
[01:56:41.840 --> 01:56:48.080]   The Komb. Our show today brought to you by my fine mattress. A good night. See, Jeff,
[01:56:48.080 --> 01:56:54.240]   you need this. A good night's sleep on a Casper mattress, Casper's an online retailer. A premium
[01:56:54.240 --> 01:57:00.560]   mattress is designed and made in the US of A. They're revolutionizing the mattress industry
[01:57:00.560 --> 01:57:04.800]   by cutting out the middleman. No more do you have to deal with resellers or spend that
[01:57:04.800 --> 01:57:09.360]   money on the mark up there. You don't have to worry about a showroom. And they pass the savings
[01:57:09.360 --> 01:57:14.400]   right on to you. Now, wait. You may say, "Wait, Leo. Wait a minute. Hold on there. I can't try
[01:57:14.400 --> 01:57:20.480]   before I buy." Well, sort of you can. Because when you go to Casper.com/Twig and you buy a
[01:57:20.480 --> 01:57:26.880]   wonderful Casper mattress, and trust me, you will love it. Here's mine arriving in a very
[01:57:26.880 --> 01:57:34.640]   compact box. I already have my jammies on. I really like this mattress. You have 100 nights
[01:57:34.640 --> 01:57:38.960]   to sleep on it. And if at any time in the first 100 nights, you say, "Yeah, it's okay, but it's not
[01:57:38.960 --> 01:57:44.400]   great." Or, "I want a different one." Or whatever. You just call them the come. They take it away,
[01:57:44.400 --> 01:57:48.080]   and they refund you every penny. So really, you do get to try before you buy it. Well,
[01:57:48.080 --> 01:57:52.640]   you have to buy it, but you get to try. And if you don't like it, you're money 100% refund.
[01:57:52.640 --> 01:57:57.840]   And it is awesome. I really like Casper's back in the rundown just to be able to watch this.
[01:57:57.840 --> 01:58:05.440]   This is native advertising the way it's meant to be. For those of you not watching our video,
[01:58:05.440 --> 01:58:11.680]   there's now a slow motion video of me falling into my Casper. Pretty soon, Aussie, the late Aussie,
[01:58:11.680 --> 01:58:17.520]   the dog show up. Do you actually wear pajamas? Actually, I do. I don't wear those though.
[01:58:17.520 --> 01:58:26.080]   Those are just for media. I usually just wear underwear. I don't have professional pajamas like
[01:58:26.080 --> 01:58:31.920]   you. But Casper, I don't know if they sell pajamas. They certainly sell mattresses.
[01:58:31.920 --> 01:58:35.440]   They are a wonderful kind of mattress. It's a combination of
[01:58:35.440 --> 01:58:42.160]   memory, supportive memory phones. I don't know how they do it. Just the right sync. So your
[01:58:42.160 --> 01:58:48.160]   your knobby bits are supported. They sync in. But then just the right amount of firmness is trying
[01:58:48.160 --> 01:58:53.600]   to picture with the knobby. Whatever your knobby bits, mine are my hips. Because I sip on my side,
[01:58:53.600 --> 01:58:57.760]   and I want them to sync in. But I don't want to, I'll get a sore back if the mattress is too soft.
[01:58:57.760 --> 01:59:02.000]   So it's weird, but it's perfect. It's just right. Both supportive and
[01:59:02.000 --> 01:59:06.000]   soft. I don't know how to describe it. And it's by the way, highly breathable.
[01:59:06.000 --> 01:59:11.440]   Some mattresses, you have to air them out for like a week when you get this one.
[01:59:11.440 --> 01:59:17.200]   Used it right away. There was no odor. It's wonderful. It's great for these hot summer nights.
[01:59:17.200 --> 01:59:23.040]   It's really cool. Long lasting comfort and support. And you could buy it online and completely
[01:59:23.040 --> 01:59:28.400]   risk free. And I have to add also, there's a lot of emphasis on sleeping, but I like to work in bed.
[01:59:28.400 --> 01:59:33.760]   I do too. And you know what I bought? I highly recommend it. The Casper is flexible. It doesn't
[01:59:33.760 --> 01:59:39.840]   have springs. So you can get one of those motors underneath it that raises the head up or the feet
[01:59:39.840 --> 01:59:44.800]   up. And that works. Yeah, it works great. It works better with the Casper than what would
[01:59:44.800 --> 01:59:48.880]   any other mattress because it's flexible. It wouldn't work with regular mattress.
[01:59:48.880 --> 01:59:54.160]   Right. No, it couldn't. You're breaking. So the Casper is perfect. And then you can type.
[01:59:54.160 --> 02:00:01.520]   That's cool. I love it. I do. I work in bed now. Free shipping and returns to the US and Canada.
[02:00:01.520 --> 02:00:06.800]   And now the UK. Good news for those of you listening in the UK. People complain because they say,
[02:00:06.800 --> 02:00:12.400]   I want one. Go to the Casper mattress site today and you'll save an additional $50 when you use
[02:00:12.400 --> 02:00:18.960]   the offer code twig. It's Casper. C-A-S-P-E-R dot com slash twig. The offer code is twig.
[02:00:18.960 --> 02:00:25.600]   T-W-I-G terms and conditions apply. Casper dot com slash twig. Save $50 on your brand new
[02:00:25.600 --> 02:00:31.600]   Casper. They don't call it Casper the friendly mattress, but they should.
[02:00:31.600 --> 02:00:39.280]   All right, Mike, you're our visiting celebrity. What? You got a couple of things here.
[02:00:39.280 --> 02:00:43.840]   I know it's just two different. You are. It's basically there's a company called Hunter and they have a
[02:00:43.840 --> 02:00:53.840]   new thing called Tech Lookup. This is an alternative search engine. And this is a techlookup.hunter.io.
[02:00:53.840 --> 02:00:59.520]   And what this does is it's a really fascinating thing. It's great for web developers, but probably
[02:00:59.520 --> 02:01:04.880]   for any curious geek. What it does is it enables you to search websites by technology. They have
[02:01:04.880 --> 02:01:11.760]   115 technologies. And these are not just technologies, but branded plugins. For example, if they use
[02:01:11.760 --> 02:01:17.680]   Amazon EC2 or Amazon S3 or technology. They can tell what they're using. Exactly. Or if it's
[02:01:17.680 --> 02:01:23.200]   blogger, if they have Twitter plugins, if they have Google charts in there, if they're using Pearl,
[02:01:23.200 --> 02:01:29.920]   a PHP, Python, Ruby, if they have widgets from Facebook or Outbrain, if they use New Relic.
[02:01:30.640 --> 02:01:35.760]   You can give it a try, but basically you search for the technology and then you download it into a
[02:01:35.760 --> 02:01:41.920]   basically a spreadsheet and you have all the companies and all the websites and URLs that
[02:01:41.920 --> 02:01:47.840]   are using these technologies. 100. You'll be glad to know Aaron, 121,000 websites use New Relic.
[02:01:47.840 --> 02:01:52.720]   That's more than that. Yeah, I just look at that up too. That's the ones. And we're in them. So
[02:01:52.720 --> 02:01:57.760]   you can't say what is Twitter. I wish we could say what technologies is Twitter.tv using.
[02:01:58.320 --> 02:02:01.200]   But it doesn't work that way. But you say no one of the technologies
[02:02:01.200 --> 02:02:08.480]   that show up on the list and it'll be a long list. But so this is something that's interesting
[02:02:08.480 --> 02:02:13.520]   to certain types of geeks. If you're not one of those types of geeks, this company has their
[02:02:13.520 --> 02:02:19.440]   older product is fantastic. And I use it all the time. It's basically an email finder. The best
[02:02:19.440 --> 02:02:26.640]   implementation of it is a Chrome browser plugin. And you can get this one at hunter.io.
[02:02:27.360 --> 02:02:31.840]   It's a Chrome plugin and then you go to a website and it gives you a button. So if you're at a website,
[02:02:31.840 --> 02:02:35.360]   you click the button, it'll show you all the email addresses associated with that domain.
[02:02:35.360 --> 02:02:40.880]   Yeah. And it gives you it ranks them a quarter's dream. Oh, yeah. And you can
[02:02:40.880 --> 02:02:46.080]   and it'll rank them according to how many references they find on the internet for those email
[02:02:46.080 --> 02:02:51.040]   addresses. So you can find the CEO's address and the customer service very quickly with a single
[02:02:51.040 --> 02:02:57.040]   buy. I do like that. That's that's hunter.io. That's right. And that's free. And I've been using
[02:02:57.040 --> 02:03:01.600]   it for a long time. I use it to contact sources. Well, that's a great idea. Would be sources.
[02:03:01.600 --> 02:03:07.200]   Yeah. And it works great. And I love that plugin one click and you just see a long list of all
[02:03:07.200 --> 02:03:13.360]   the email addresses. So I could enter twit.tv and then find all the associated email addresses.
[02:03:13.360 --> 02:03:19.040]   Oh, they are. And they're all blurred out. You notice that the 20 sources is this one. This
[02:03:19.040 --> 02:03:23.280]   one's 20. Where are they getting those from? They're references online. They're finding these
[02:03:23.280 --> 02:03:27.680]   internet. They're saying, oh, yeah, they're, we found 13 examples of that particular one
[02:03:27.680 --> 02:03:34.400]   we're looking at. Tickets at twit.tv. There's all the names of the hosts. Once you create the free
[02:03:34.400 --> 02:03:39.440]   account, then it'll unblur them. I guess. Yeah, they're blurred. And I'm only seeing a handful of
[02:03:39.440 --> 02:03:44.560]   them. They're 78 total. Well, I'll vouch for this. These are all real. Yeah. Yeah. Wow.
[02:03:46.000 --> 02:03:52.640]   That is very useful. I can see. Yeah, they can see how you do that. Jeff Jarvis, a number for us.
[02:03:52.640 --> 02:04:00.320]   So yeah, I like this one. Remember 11 years ago, I think we on the show. Hello, is the show been on?
[02:04:00.320 --> 02:04:04.400]   Oh, probably that long. I don't know. Let's see. Well, this is episode 14.
[02:04:04.400 --> 02:04:12.880]   If we all gasped. Yeah. Yeah. We gasped when when Google bought YouTube for 1.65.
[02:04:12.880 --> 02:04:18.400]   No, we weren't doing this show and that happened. No, we weren't. Okay. But I would. I didn't gasp,
[02:04:18.400 --> 02:04:21.920]   but I don't think we were doing this show. Everybody gas. We all got. Now,
[02:04:21.920 --> 02:04:29.360]   CNBC, a tech analyst in Victor Anthony, sat on CNBC that he estimates that if YouTube were
[02:04:29.360 --> 02:04:35.040]   stock on its own, it would be worth 75 billion. Yeah. And I would say, Google definitely got its
[02:04:35.040 --> 02:04:43.280]   money's worth. They did follow. Yeah. It's worth five Twitters or it's a 45 X on the investment.
[02:04:43.280 --> 02:04:49.760]   Right. It was all stock. Sweet. So our first episode was August 1st, 2009.
[02:04:49.760 --> 02:04:54.560]   Oh, okay. I thought so. I just thought I had this memory of us saying,
[02:04:54.560 --> 02:04:59.600]   1.65 billion members just said it's somewhere else. Yeah. It's called false memory syndrome.
[02:04:59.600 --> 02:05:04.400]   We all did it. It is. It is. So let's see. August 1st is coming up. You know, this
[02:05:05.120 --> 02:05:12.720]   this actually really is the last episode of our eighth year. Next episode will be the
[02:05:12.720 --> 02:05:17.200]   beginning of our ninth year. Nice. Wow. It's right. That doesn't seem possible.
[02:05:17.200 --> 02:05:21.680]   It's sick of me yet. This is so happy birthday. This is really our eighth anniversary.
[02:05:21.680 --> 02:05:26.640]   We should get our ninth birthday. Paper hats and confetti. Wow. I'm glad you asked that, Jeff.
[02:05:26.640 --> 02:05:31.360]   I mean, August 1st is just a few days away. Who would have thought? Who would have thunk it?
[02:05:31.360 --> 02:05:35.600]   What were we talking about? FCC investigates. We're thinking about doing a show about Google.
[02:05:35.600 --> 02:05:39.600]   Yeah. Why not? Sure. What the heck? Yeah. We were.
[02:05:39.600 --> 02:05:44.880]   FCC investigates Apple and ATT over Google voice app block.
[02:05:44.880 --> 02:05:51.760]   Why free works and using canned responses in Gmail and just had a curiosity. I just wondering
[02:05:51.760 --> 02:05:55.920]   how long the show was now. Now Google 54 minutes.
[02:05:58.880 --> 02:06:03.360]   That was a must of been a long time. The days my friends. But you know what we still have?
[02:06:03.360 --> 02:06:08.160]   We've never gotten nine years gotten rid of that horrible theme song.
[02:06:08.160 --> 02:06:13.120]   Yeah. It's the worst. This week in Google is provided. The only reason is still there is I
[02:06:13.120 --> 02:06:18.320]   never hear it. Right. If we had a band, if we had a studio band playing it,
[02:06:18.320 --> 02:06:26.640]   I would know what it is. You throw tomatoes at first. 2009. Lots of people like it. It wouldn't be
[02:06:26.640 --> 02:06:31.200]   a band playing it. It would be traveling minstrels. This show was brought to you by.
[02:06:31.200 --> 02:06:34.080]   You know why I picked it? You know why I picked it? A, because I could get it.
[02:06:34.080 --> 02:06:41.680]   I paid the royalty for it. But B, because I was going to be you, me and Gina,
[02:06:41.680 --> 02:06:47.520]   to panic, right, Jeff? And I thought, well, I wanted a fugue because it was going to be like a
[02:06:47.520 --> 02:06:53.360]   counterpoint, a contrapuntal arrangement between you and then I would say something and then
[02:06:53.360 --> 02:06:57.920]   Gina and we would interweave like that. And so I tried to find something that was a fugue.
[02:06:57.920 --> 02:06:59.600]   Can you say contrapuntal on this one?
[02:06:59.600 --> 02:07:06.080]   Edit that out. Yeah. That's we're going to get an adult tag.
[02:07:06.080 --> 02:07:09.440]   Unnecessary censorship.
[02:07:09.440 --> 02:07:13.520]   Did you do your not? You did do your number. That was a YouTube purchase point.
[02:07:13.520 --> 02:07:16.560]   Right. And what it would be worth 75. I have more. But yeah.
[02:07:16.560 --> 02:07:18.160]   That's a good one. That's a good one.
[02:07:18.960 --> 02:07:25.040]   It's also interesting that the parental control app on Google has a number that causes a problem.
[02:07:25.040 --> 02:07:26.720]   What number? 13.
[02:07:26.720 --> 02:07:30.000]   What? Because what was it here?
[02:07:30.000 --> 02:07:31.840]   Oh, where was the age you have to be?
[02:07:31.840 --> 02:07:38.640]   That's the copper age of the age of consent under the child on my particular privacy act.
[02:07:38.640 --> 02:07:44.880]   Kids on Google Plus. There's so many kids under the age of 13. And I post some picture of food,
[02:07:44.880 --> 02:07:48.960]   beautiful food, and people like that looks amazing. That looks delicious. And then somebody's like,
[02:07:48.960 --> 02:07:52.000]   "Yuck, that's gross." And I like to put the thing in a second nine-year-old.
[02:07:52.000 --> 02:07:55.600]   If you sign up for a family link that's Google's new parental controls,
[02:07:55.600 --> 02:08:01.440]   I didn't even know they had this. At the age of 13, a child can choose to graduate.
[02:08:01.440 --> 02:08:05.040]   In other words, the parent doesn't decide. The kid decides.
[02:08:05.040 --> 02:08:05.520]   That's weird.
[02:08:05.520 --> 02:08:09.040]   That's the age of majority in Google Land.
[02:08:11.840 --> 02:08:15.360]   That's weird. The minute you're a teenager, buy by restrictions.
[02:08:15.360 --> 02:08:20.480]   I don't know if that's so bad. I don't think that's so bad. What do you think?
[02:08:20.480 --> 02:08:26.560]   Well, if it over rules the parents, the parents are still in charge
[02:08:26.560 --> 02:08:30.960]   until 18. But I think Google doesn't want anything to do with it.
[02:08:30.960 --> 02:08:35.200]   That's an interesting choice.
[02:08:35.200 --> 02:08:38.400]   Yeah, it seems young.
[02:08:39.200 --> 02:08:42.320]   It's for Android phones only. Don't go looking for it on the internet.
[02:08:42.320 --> 02:08:49.440]   Well, certainly, I think parents should assert some control over kids until they're 18.
[02:08:49.440 --> 02:08:51.040]   Yeah, good luck with that.
[02:08:51.040 --> 02:08:52.880]   Good luck with that.
[02:08:52.880 --> 02:08:54.400]   I'll try it. That's work.
[02:08:54.400 --> 02:09:01.120]   I use the parental controls built into the router I use,
[02:09:01.120 --> 02:09:08.880]   one of our sponsors, Euro. And Michael's 14. And they're filters on all his devices.
[02:09:09.520 --> 02:09:12.880]   But you know, kids could get around it because he has a phone.
[02:09:12.880 --> 02:09:14.800]   He if he really wants to, he can get around it.
[02:09:14.800 --> 02:09:16.480]   Yeah.
[02:09:16.480 --> 02:09:17.840]   Aaron Nukem, what do you got for us?
[02:09:17.840 --> 02:09:24.880]   Well, this is something that's not new, new. It was new to me last night when I was doing
[02:09:24.880 --> 02:09:29.200]   some research. I don't know, Leo, do you have you tried out any of the eight bit dough controllers?
[02:09:29.200 --> 02:09:33.440]   No, I have a switch and I love my switch.
[02:09:33.440 --> 02:09:36.160]   I do too. I love my switch as well.
[02:09:36.160 --> 02:09:39.280]   But I use the stock controls. What is eight bit dough?
[02:09:39.280 --> 02:09:43.920]   So eight bit dough has been making these controllers for years that are very popular among
[02:09:43.920 --> 02:09:48.880]   folks like me that like to build their own arcade controllers, for example, or do emulation
[02:09:48.880 --> 02:09:54.080]   because they make these controllers that look kind of like, in some cases, exactly like the old
[02:09:54.080 --> 02:09:58.160]   controllers. They're Bluetooth controllers and they work with just about anything.
[02:09:58.160 --> 02:10:02.480]   Android, Windows, Mac, Linux, Raspberry Pi, they'll work with anything.
[02:10:03.760 --> 02:10:07.120]   And they're fairly inexpensive. They look good. They're fairly inexpensive. They usually come
[02:10:07.120 --> 02:10:12.560]   with a case. They're well built. So anyway, they're pretty popular, especially in the emulation crowd.
[02:10:12.560 --> 02:10:18.160]   And they released at E3, they released a new controller and they said, this one's going to come
[02:10:18.160 --> 02:10:24.400]   with the right version of the Bluetooth so that it will work with Nintendo Switch.
[02:10:24.400 --> 02:10:28.720]   Everybody really was excited about that. And at the time, I was like, okay, this is all just
[02:10:28.720 --> 02:10:32.800]   software though. Why don't they make this available for all their other controllers? Because they're
[02:10:32.800 --> 02:10:35.840]   not changing the hardware, right? They're just doing something in software. And lo and behold,
[02:10:35.840 --> 02:10:42.080]   that's exactly what they did. So if you have one of these 8-bit dough controllers,
[02:10:42.080 --> 02:10:46.320]   if you've bought one and you want to use it with your Nintendo Switch, you can. All you have to do
[02:10:46.320 --> 02:10:53.280]   now is upgrade your firmware to version 4.0. And almost all of their controllers are now
[02:10:53.280 --> 02:10:59.680]   compatible with Nintendo Switch. So if you don't necessarily have to go out and get the game
[02:10:59.680 --> 02:11:03.280]   controller that you can buy specifically for Nintendo Switch, you can use one of these 8-bit
[02:11:03.280 --> 02:11:08.160]   dough controllers. I've got the one that looks like the old NES controller, except they've added a
[02:11:08.160 --> 02:11:13.680]   couple buttons and some shoulder buttons so you can actually use it with the Switch more effectively.
[02:11:13.680 --> 02:11:18.000]   But yeah, good news for people that have these controllers and they're fun because they're retro,
[02:11:18.000 --> 02:11:25.280]   somebody in the chat room saying, how's the D-Pen on these? They feel good? Do you have?
[02:11:25.280 --> 02:11:32.080]   They feel great. They don't feel good. No, no, not at all. I mean, they're not the highest end quality,
[02:11:32.080 --> 02:11:39.200]   but they're pretty nice. The buttons are solid. They're responsive. The analog sticks are pretty
[02:11:39.200 --> 02:11:43.680]   good. So yeah, I mean, I would highly recommend them. They've been doing some really cool stuff.
[02:11:43.680 --> 02:11:49.680]   They come in a fantastic box. They've done really good. I mean, it seems weird to say that, but the
[02:11:49.680 --> 02:11:59.120]   packaging is actually really nice. I mean, 42 bucks for the NES 30. That's not cheap for
[02:11:59.120 --> 02:12:03.120]   something like that. So they should be good. Those should be good switches and all that.
[02:12:03.120 --> 02:12:07.920]   Yeah, you can see there, they even come with a little keychain, which is interesting.
[02:12:07.920 --> 02:12:14.640]   The wrong controller. They're trying. Yeah, yeah, they're trying. But I would highly recommend
[02:12:14.640 --> 02:12:20.000]   them. And especially now that you can get support to make them work with the Nintendo Switch.
[02:12:20.000 --> 02:12:23.200]   Be great. That's awesome.
[02:12:23.200 --> 02:12:30.560]   Friends, we've come to the end of another fine, a thrilling gripping edition of this week in
[02:12:30.560 --> 02:12:36.640]   Google. Three episodes, one. It was. How so? Well, it's just longer than we used to be.
[02:12:36.640 --> 02:12:42.000]   Oh my God, it's 407. Yeah, that's really nice. We're going to miss miss Mary.
[02:12:42.000 --> 02:12:47.360]   All right, go get your ferry. Thank you, Aaron. Nook them. See you soon. Take care.
[02:12:47.360 --> 02:12:54.720]   Run to the ferry. Run. I will. Okay. We'll see you. And Jeff, the good news is it's brunch time.
[02:12:54.720 --> 02:13:01.200]   Have a great day. He's got a machine.com. Thank you for being here. I really appreciate it, Jeff.
[02:13:01.200 --> 02:13:04.400]   Always a pleasure. Thank you. Mike, thank you. Thank you. Thank you.
[02:13:04.400 --> 02:13:07.360]   The crew for trying to fix the technology problems.
[02:13:07.360 --> 02:13:13.120]   It wasn't bad. You know, you said you said you can. Does it sound okay now? Oh, it sounds better.
[02:13:13.120 --> 02:13:17.760]   We're just being picky. There's a little bit of echo, a little bit of there still is. We try to
[02:13:17.760 --> 02:13:23.360]   chase with that. It's not bad. Yes. It's not bad. And thanks. Of course to Mike Elgin. Always a pleasure
[02:13:23.360 --> 02:13:27.760]   to have you on. Love the show. Come back soon. How long are you in the States? Not long.
[02:13:27.760 --> 02:13:32.000]   I think it's another month or so. Oh, okay. Because you got to get back to got to get back to Barcelona.
[02:13:32.000 --> 02:13:36.560]   Yeah. Yep. Thank you for being here. You should everybody. Gastronomad.net. If you haven't yet
[02:13:36.560 --> 02:13:41.120]   signed up and put me down for Italy, I'm not kidding. I really want to do that. You've got a
[02:13:41.120 --> 02:13:46.560]   spot reserve, two sponsors. Prosecco. Yes. We're coming to Prosecco. It'll be like cheese. It'll be like
[02:13:46.560 --> 02:13:52.960]   a cheese. I do like cheese. Mike, we're going to make this just the first two. Actually, have you
[02:13:52.960 --> 02:13:57.920]   announced a date for fans? No, no. If FES is, it doesn't have a date yet. So the only one with a
[02:13:57.920 --> 02:14:01.440]   solid date is Barcelona. Why don't they announce Italy? Can I see you? Can I see you? Can I see you?
[02:14:01.440 --> 02:14:06.080]   Mrs. Jarvis, join us. That would be awesome. Well, yeah. Mike, you know what I'd love to see is,
[02:14:06.080 --> 02:14:09.760]   why don't you put up even before you have dates, put up what you're planning, so we can kind of plan
[02:14:09.760 --> 02:14:14.400]   on that. They do have the FES. Absolutely. They talk about FES. Yeah. Absolutely. We've got all the
[02:14:14.400 --> 02:14:20.640]   people lined up for Italy, but not the dates. Oh, nice. Yeah. Great. Roughly spring next year.
[02:14:20.640 --> 02:14:28.240]   Roughly. Okay. I think we have a Japan trip, Japan trip planned in March. Oh, really? Nice. I
[02:14:28.240 --> 02:14:34.720]   wanted to see the Cherry Blossom Festival Ace. But then, but if so, if it doesn't coincide with
[02:14:34.720 --> 02:14:39.360]   that, well, definitely, I'd love to do Italy. Fantastic. Yeah. Thanks, everybody, for joining
[02:14:39.360 --> 02:14:45.760]   us. We do this week in Google, round about 130 Pacific, 430 Eastern, 2030 UTC on Wednesdays,
[02:14:45.760 --> 02:14:50.400]   right after Windows Weekly. I hope you come by and watch live. If you do, visit us in the
[02:14:50.400 --> 02:14:57.200]   chatroom at irc.twit.tv/afe. On the other hand, your schedule does not permit. Don't worry. It's
[02:14:57.200 --> 02:15:01.680]   okay. We get on-demand audio and video available at our website for all our shows,
[02:15:01.680 --> 02:15:08.320]   Twit.tv. This case, it'll be Twit.tv/twig. You can even go back to episode one from nine years
[02:15:08.320 --> 02:15:14.320]   ago, eight years ago. Wow. Wow. It was only audio, I think, back then. I don't think we were doing
[02:15:14.320 --> 02:15:18.480]   video. Yeah. It was audio. I think we did about episode three. We did video. We pretty quickly went
[02:15:18.480 --> 02:15:22.960]   to video. Very quickly. It was right about the transformation. Let's see what else.
[02:15:24.640 --> 02:15:30.000]   On-demand versions of the website or subscribe. You should use your favorite podcast application
[02:15:30.000 --> 02:15:35.280]   and subscribe that way you won't miss an episode. And we will see you next time on this week in
[02:15:35.280 --> 02:15:40.560]   Google. Bye-bye.
[02:15:40.560 --> 02:15:46.960]   [Music]

