
[00:00:00.000 --> 00:00:02.480]   It's time for Twit this week in Tech.
[00:00:02.480 --> 00:00:03.840]   Got a great panel for you.
[00:00:03.840 --> 00:00:08.280]   Samable, Samid, Georgia Dow, and my old buddy Patrick Norton.
[00:00:08.280 --> 00:00:12.000]   We'll talk about NOBUS, why the NSA says,
[00:00:12.000 --> 00:00:14.600]   "Nobody but us is all that matters.
[00:00:14.600 --> 00:00:19.040]   A face recognition company that will end privacy as we know it,
[00:00:19.040 --> 00:00:22.080]   and why sims swapping attacks are so common."
[00:00:22.080 --> 00:00:25.080]   It's all coming up next on Twit.
[00:00:25.080 --> 00:00:29.120]   This week, "Attack" comes to you from the Twit last past studios.
[00:00:29.120 --> 00:00:32.080]   You're focused on security, but are your employees?
[00:00:32.080 --> 00:00:36.560]   LastPass can ensure they are by making access and authentication seamless.
[00:00:36.560 --> 00:00:39.920]   Visit laspass.com/twit to learn more.
[00:00:39.920 --> 00:00:46.120]   Podcasts you love from people you trust.
[00:00:46.120 --> 00:00:48.920]   This is Twit.
[00:00:48.920 --> 00:00:57.000]   This is Twit.
[00:00:57.000 --> 00:01:03.280]   This week in Tech, Episode 754, recorded Sunday, January 19, 2020.
[00:01:03.280 --> 00:01:04.840]   A dream of wiki.
[00:01:04.840 --> 00:01:08.640]   This week in Tech is brought to you by CapTera.
[00:01:08.640 --> 00:01:12.320]   Find the right tools to make an informed software decision for your business.
[00:01:12.320 --> 00:01:16.840]   Visit CapTera's free website at capterra.com/twit.
[00:01:16.840 --> 00:01:20.480]   And by ExpressVPN.
[00:01:20.480 --> 00:01:23.360]   Protect your online privacy with one click.
[00:01:23.360 --> 00:01:24.640]   It's that easy.
[00:01:24.640 --> 00:01:30.440]   For three extra months free with a one-year package, go to expressvpn.com/twit.
[00:01:30.440 --> 00:01:32.440]   And by World Wide Technology.
[00:01:32.440 --> 00:01:37.040]   World Wide Technology's Advanced Technology Center is like no other testing and research lab
[00:01:37.040 --> 00:01:39.440]   with more than half a billion dollars of equipment,
[00:01:39.440 --> 00:01:42.360]   including solutions from key partners like NVIDIA.
[00:01:42.360 --> 00:01:45.320]   And it's virtual so you can access it 24/7.
[00:01:45.320 --> 00:01:51.000]   To learn more and get insights into all that it offers, go to www.t.com/twit.
[00:01:51.000 --> 00:01:54.040]   And by ITProTV.
[00:01:54.040 --> 00:01:58.200]   ITProTV provides IT training that's effective and entertaining,
[00:01:58.200 --> 00:02:01.160]   with access to virtual labs and practice tests.
[00:02:01.160 --> 00:02:07.360]   Visit itpro.tv/twit for an additional 30% off for the lifetime of your active subscription.
[00:02:07.360 --> 00:02:10.160]   Use code TWIT30 at checkout.
[00:02:10.160 --> 00:02:20.960]   It's time for TWIT the show.
[00:02:20.960 --> 00:02:22.960]   Oh my God, who's that?
[00:02:23.360 --> 00:02:29.040]   If you're watching the video, apparently some Mexican wrestler who is a 49ers fan
[00:02:29.040 --> 00:02:30.960]   is snacking at the snuck in the studio.
[00:02:30.960 --> 00:02:35.400]   Apparently, there is a hand egg game later in the day.
[00:02:35.400 --> 00:02:41.320]   So I am dressed in the accoutrement of the hand egg phonetic.
[00:02:41.320 --> 00:02:45.240]   It's time for the show where we talk about the latest tech news.
[00:02:45.240 --> 00:02:49.920]   Joining me, Mr. Patrick Naughton, a host of this week at Computer Hardware.
[00:02:49.920 --> 00:02:52.440]   My long time. Look how good he looks.
[00:02:52.440 --> 00:02:54.440]   Are you using some sort of...
[00:02:54.440 --> 00:02:55.440]   He's so...
[00:02:55.440 --> 00:02:57.200]   Is it like a filter?
[00:02:57.200 --> 00:02:59.200]   You're keeping your hair cut.
[00:02:59.200 --> 00:03:05.800]   It is the glow of being on camera with Poyo De Oro, the Lucha Dore of Petaluma.
[00:03:05.800 --> 00:03:08.480]   Did you just call me a golden chicken?
[00:03:08.480 --> 00:03:09.440]   I just got...
[00:03:09.440 --> 00:03:10.640]   Well, yes.
[00:03:10.640 --> 00:03:13.160]   What else is that or the golden egg?
[00:03:13.160 --> 00:03:14.080]   Or the golden...
[00:03:14.080 --> 00:03:15.600]   I'm wearing four-o-sneakers.
[00:03:15.600 --> 00:03:16.440]   Or the golden...
[00:03:16.440 --> 00:03:17.440]   Or the golden...
[00:03:17.440 --> 00:03:18.440]   The golden...
[00:03:18.440 --> 00:03:19.280]   I mean...
[00:03:19.280 --> 00:03:20.040]   The golden...
[00:03:20.040 --> 00:03:20.840]   I don't know.
[00:03:20.840 --> 00:03:22.160]   The golden child.
[00:03:22.160 --> 00:03:27.480]   Patrick Norton, A-V-X-L.com.
[00:03:27.480 --> 00:03:29.040]   Great to see you.
[00:03:29.040 --> 00:03:30.040]   Welcome to the show.
[00:03:30.040 --> 00:03:31.040]   Did you get a CES?
[00:03:31.040 --> 00:03:32.040]   I think you did.
[00:03:32.040 --> 00:03:33.040]   I did.
[00:03:33.040 --> 00:03:34.040]   I went to CES.
[00:03:34.040 --> 00:03:36.600]   I actually saw something cool.
[00:03:36.600 --> 00:03:38.040]   You texted me.
[00:03:38.040 --> 00:03:40.200]   I was...
[00:03:40.200 --> 00:03:43.400]   I said, "You're here?
[00:03:43.400 --> 00:03:44.400]   What are you doing here?"
[00:03:44.400 --> 00:03:45.400]   Everything okay?
[00:03:45.400 --> 00:03:47.000]   I said, "Four of my sins.
[00:03:47.000 --> 00:03:49.800]   I am back after eight years."
[00:03:49.800 --> 00:03:50.800]   But I had a good time.
[00:03:50.800 --> 00:03:52.280]   I'm going to talk about that a little bit.
[00:03:52.280 --> 00:03:53.680]   Hang in there.
[00:03:53.680 --> 00:03:55.280]   Also with me, Sam Abel-Samet.
[00:03:55.280 --> 00:03:57.440]   He is my car guy.
[00:03:57.440 --> 00:03:58.680]   I like to have a car guy.
[00:03:58.680 --> 00:03:59.680]   I like that.
[00:03:59.680 --> 00:04:02.000]   Principal analyst at Navigant Research.
[00:04:02.000 --> 00:04:04.560]   He's also the host of the Wheel-Baring's podcast.
[00:04:04.560 --> 00:04:08.960]   He joins the radio show every Sunday to talk about automobiles.
[00:04:08.960 --> 00:04:12.480]   He's in Detroit where it does not look like that.
[00:04:12.480 --> 00:04:15.240]   No, not this time of year.
[00:04:15.240 --> 00:04:16.800]   That's a super-time shot.
[00:04:16.800 --> 00:04:17.800]   I'm great, Sam.
[00:04:17.800 --> 00:04:18.800]   Welcome.
[00:04:18.800 --> 00:04:19.800]   It's good to have you.
[00:04:19.800 --> 00:04:24.280]   We're from beautiful Toronto where the sun is shining, the birds are singing, and the
[00:04:24.280 --> 00:04:27.600]   temperature has fallen to a sub-arctic.
[00:04:27.600 --> 00:04:29.200]   How cold is it, Georgia Dow?
[00:04:29.200 --> 00:04:30.800]   Well, I'm in Montreal.
[00:04:30.800 --> 00:04:31.800]   It's pretty cold.
[00:04:31.800 --> 00:04:32.800]   What am I saying, Toronto?
[00:04:32.800 --> 00:04:33.800]   You're in Montreal?
[00:04:33.800 --> 00:04:35.400]   It's a good Canadian place.
[00:04:35.400 --> 00:04:36.400]   That's fine.
[00:04:36.400 --> 00:04:37.400]   They're all the same.
[00:04:37.400 --> 00:04:39.200]   It's all around the area.
[00:04:39.200 --> 00:04:40.200]   No, they are not.
[00:04:40.200 --> 00:04:41.200]   Thank you.
[00:04:41.200 --> 00:04:42.200]   They are not.
[00:04:42.200 --> 00:04:43.200]   Thank you.
[00:04:43.200 --> 00:04:44.200]   Thank you.
[00:04:44.200 --> 00:04:45.200]   John.
[00:04:45.200 --> 00:04:46.200]   Actually, Canada is very diverse, isn't it?
[00:04:46.200 --> 00:04:47.200]   It's very diverse.
[00:04:47.200 --> 00:04:49.080]   We have the French connection here.
[00:04:49.080 --> 00:04:51.560]   So that makes it a little different.
[00:04:51.560 --> 00:05:00.120]   Lisa and I have decided that we are going to take the via cross-Canada train, maybe
[00:05:00.120 --> 00:05:02.200]   not next year, but the year after.
[00:05:02.200 --> 00:05:05.240]   I think we have to end up in Montreal.
[00:05:05.240 --> 00:05:06.240]   You really do.
[00:05:06.240 --> 00:05:07.240]   We'll take you out.
[00:05:07.240 --> 00:05:09.200]   There's some beautiful places to go in Montreal.
[00:05:09.200 --> 00:05:12.240]   It'll be you and Renee and it'll be so much fun.
[00:05:12.240 --> 00:05:13.240]   Oh, yeah.
[00:05:13.240 --> 00:05:14.720]   Anyway, great to have all three of you.
[00:05:14.720 --> 00:05:16.760]   Georgia did not go to CES.
[00:05:16.760 --> 00:05:18.280]   I did not go to CES.
[00:05:18.280 --> 00:05:19.280]   I was here.
[00:05:19.280 --> 00:05:20.280]   I was here.
[00:05:20.280 --> 00:05:24.280]   I got to see all of the most interesting things through the internet, but that was it.
[00:05:24.280 --> 00:05:25.520]   Well, that's my sense of it.
[00:05:25.520 --> 00:05:29.400]   Patrick, correct me if I'm wrong, but it's kind of like the difference between going to
[00:05:29.400 --> 00:05:33.360]   a football game in person, which you do for the atmosphere, but it's very difficult to
[00:05:33.360 --> 00:05:36.880]   tell what's going on in the field and watching on TV where you see all the details.
[00:05:36.880 --> 00:05:39.680]   Honestly, CES is best covered from afar.
[00:05:39.680 --> 00:05:45.240]   Yeah, I tell you to see the momentum of CES.
[00:05:45.240 --> 00:05:46.240]   Baby.
[00:05:46.240 --> 00:05:47.240]   There's something fun about it.
[00:05:47.240 --> 00:05:51.800]   There's something fun about sitting in the stands and trying to make out what those 22
[00:05:51.800 --> 00:05:54.240]   men are doing down there on the field.
[00:05:54.240 --> 00:05:55.520]   Is there a football amongst them?
[00:05:55.520 --> 00:05:57.520]   I don't know.
[00:05:57.520 --> 00:06:00.920]   Patrick, do you go every year now?
[00:06:00.920 --> 00:06:05.240]   This was my 22nd or 23rd.
[00:06:05.240 --> 00:06:07.720]   It depends on what you're doing.
[00:06:07.720 --> 00:06:13.040]   I actually have, it depends on if you're...
[00:06:13.040 --> 00:06:18.880]   One, it seems to be a lot less coverage where teams, either huge media teams, are sending
[00:06:18.880 --> 00:06:24.560]   to do 123 stories in the first two or three days.
[00:06:24.560 --> 00:06:30.560]   It's becoming less important to hard tech, more important to general news, but it's interesting
[00:06:30.560 --> 00:06:35.160]   because it's still in so many ways like homecoming because so many people in the various injuries
[00:06:35.160 --> 00:06:41.640]   that show up are there or people you know whether they are writers or make video or whatever
[00:06:41.640 --> 00:06:43.280]   else they do.
[00:06:43.280 --> 00:06:47.800]   I saw two or three things that I wouldn't have seen if I hadn't been at CES.
[00:06:47.800 --> 00:06:50.680]   In terms of television, there was like nothing new.
[00:06:50.680 --> 00:06:55.680]   In terms of audio, there was actually the least number of audio vendors I've ever seen,
[00:06:55.680 --> 00:06:59.040]   which I think means audio is finally given up completely on CES.
[00:06:59.040 --> 00:07:02.080]   It wasn't too bad last year this year, it was nothing.
[00:07:02.080 --> 00:07:05.080]   The Delta keynote still fascinates me.
[00:07:05.080 --> 00:07:11.080]   Delta Airlines, the first time a major air carrier had presented at CES.
[00:07:11.080 --> 00:07:15.480]   I didn't see the keynote, but I did see they had exoskeletons where you could lift luggage
[00:07:15.480 --> 00:07:19.720]   and they had a sign board that was different depending on who was looking at it.
[00:07:19.720 --> 00:07:23.440]   What do they do at the keynote that baffled you?
[00:07:23.440 --> 00:07:26.240]   Oh, I just...
[00:07:26.240 --> 00:07:30.400]   If I don't have to be at press days, I don't go anymore because sitting in two hours...
[00:07:30.400 --> 00:07:33.920]   I've sat in two hours to go see something and found out they actually didn't reveal a new
[00:07:33.920 --> 00:07:37.000]   product and if I don't have to do that, I don't.
[00:07:37.000 --> 00:07:41.640]   Actually, the thing that saw me that blew me away was Mojo Vision's prototype.
[00:07:41.640 --> 00:07:47.600]   I actually got the hands-on demo with the contact lens with the embedded display.
[00:07:47.600 --> 00:07:49.840]   Did they put it in your eye?
[00:07:49.840 --> 00:07:53.760]   No, they are not to that point yet, but actually they literally had...
[00:07:53.760 --> 00:07:56.400]   So you could view the demo.
[00:07:56.400 --> 00:08:02.720]   It was basically like a contact lens on a stick and that allows you to see the interface.
[00:08:02.720 --> 00:08:05.600]   Why would you want a contact lens on a stick?
[00:08:05.600 --> 00:08:11.760]   So there's a display embedded in the contact lens.
[00:08:11.760 --> 00:08:12.760]   The idea is...
[00:08:12.760 --> 00:08:18.120]   Oh, you mean like a Roku built into the contact lens?
[00:08:18.120 --> 00:08:20.720]   It's something more basic information.
[00:08:20.720 --> 00:08:26.040]   Imagine you're sitting there, they had an interface demo where you could actually interact
[00:08:26.040 --> 00:08:31.120]   with the interface where you would sort of look out to the...
[00:08:31.120 --> 00:08:37.320]   You'd look up to the edge of your vision and that would activate a very simple, very subtle
[00:08:37.320 --> 00:08:42.480]   drop-down menu where you could sort of pause audio or check the weather or get a discrete
[00:08:42.480 --> 00:08:43.480]   piece of information.
[00:08:43.480 --> 00:08:45.640]   It's a science of that contact lens.
[00:08:45.640 --> 00:08:47.840]   It's got to cover your whole eyeball.
[00:08:47.840 --> 00:08:49.200]   Well, it's in the early days.
[00:08:49.200 --> 00:08:50.200]   Yeah, it is.
[00:08:50.200 --> 00:08:51.200]   It's early days.
[00:08:51.200 --> 00:08:55.800]   But what's fascinating about this, right, is part of what they're motivated about is
[00:08:55.800 --> 00:09:01.240]   this embedded display on this is incredibly tiny, doesn't disrupt your vision.
[00:09:01.240 --> 00:09:07.480]   And they did an amazing demo where you were seeing it doing edge detection and it gave
[00:09:07.480 --> 00:09:11.920]   you the equivalent of a form of night vision that could be dropped to a bottom two, an
[00:09:11.920 --> 00:09:12.920]   eyeball.
[00:09:12.920 --> 00:09:13.920]   And that for...
[00:09:13.920 --> 00:09:17.320]   And there are people inside of the company that are motivated because of relationships
[00:09:17.320 --> 00:09:19.000]   they have in their personal lives.
[00:09:19.000 --> 00:09:22.720]   And it was fascinating because they were showing sort of medical uses for it that will
[00:09:22.720 --> 00:09:28.680]   help them and they've got a partnership with the FDA to help move this through testing.
[00:09:28.680 --> 00:09:32.560]   And it was really fascinating because looking up in the corner and pulling this very simple
[00:09:32.560 --> 00:09:35.520]   menu down, they're not trying to close the line.
[00:09:35.520 --> 00:09:39.680]   The gesture is where your eyeball is?
[00:09:39.680 --> 00:09:45.680]   Their goal, the demo I had was using an HTC Vive, right, as they kind of work out the
[00:09:45.680 --> 00:09:46.000]   inner-
[00:09:46.000 --> 00:09:47.000]   Okay, that's fair.
[00:09:47.000 --> 00:09:48.000]   Which is actually really well done.
[00:09:48.000 --> 00:09:50.400]   You're wearing a visor, but it would look the same as that.
[00:09:50.400 --> 00:09:53.320]   But the difference in the Vive is there's a camera looking at your eyeball.
[00:09:53.320 --> 00:09:56.800]   There wouldn't be with a contact lens.
[00:09:56.800 --> 00:09:59.880]   But what they're saying, essentially what my understanding is there is a display that
[00:09:59.880 --> 00:10:03.440]   faces your eyeball and a camera that faces out.
[00:10:03.440 --> 00:10:08.520]   And what they will do is they will be able to track or they're basically saying they
[00:10:08.520 --> 00:10:11.680]   will be able to track which direction your pupil is looking.
[00:10:11.680 --> 00:10:12.680]   That makes sense.
[00:10:12.680 --> 00:10:13.680]   And that is...
[00:10:13.680 --> 00:10:14.680]   You will interact with this.
[00:10:14.680 --> 00:10:15.920]   Now is the camera on the contact lens?
[00:10:15.920 --> 00:10:19.480]   Are you wearing some unusual headgear?
[00:10:19.480 --> 00:10:23.520]   The whole idea, their goal, win this ship, and it's a few years out at this point, is
[00:10:23.520 --> 00:10:27.120]   to actually have all of this including the battery power.
[00:10:27.120 --> 00:10:32.160]   This incredibly tiny lithium polymer batteries will all be in the contact lens that goes
[00:10:32.160 --> 00:10:33.160]   over your eyeball.
[00:10:33.160 --> 00:10:36.920]   To me, this is exactly what augmented reality should be.
[00:10:36.920 --> 00:10:41.560]   But it does sound like it's a little bit of science fiction because the batteries in
[00:10:41.560 --> 00:10:45.320]   that thing, I mean, there's a camera in that thing, it sounds like we don't...
[00:10:45.320 --> 00:10:47.560]   We're not quite there yet.
[00:10:47.560 --> 00:10:49.440]   That's exactly the kind of thing that we described in that book.
[00:10:49.440 --> 00:10:52.280]   It's a little demon, you know, in some years ago.
[00:10:52.280 --> 00:10:55.760]   Yeah, it's like Daniel Suarez's demon.
[00:10:55.760 --> 00:10:56.760]   Daniel Suarez.
[00:10:56.760 --> 00:10:57.760]   Yeah.
[00:10:57.760 --> 00:10:59.600]   In that case, you were able to always...
[00:10:59.600 --> 00:11:04.600]   Maybe I can't remember if Damon had spectacles or a contact, but you could look at anybody.
[00:11:04.600 --> 00:11:05.600]   It was contact.
[00:11:05.600 --> 00:11:10.920]   And get exactly what that image shows, which is a little pop-up over the person with their
[00:11:10.920 --> 00:11:13.400]   reputation information about them.
[00:11:13.400 --> 00:11:17.520]   So is that kind of what they were showing is an overlay on the real world that has information?
[00:11:17.520 --> 00:11:18.520]   I love that.
[00:11:18.520 --> 00:11:21.520]   That to me, I would buy that in a heartbeat.
[00:11:21.520 --> 00:11:27.440]   Yeah, their goal is for this to be something for you to opt in to get the information so
[00:11:27.440 --> 00:11:28.880]   that they're not constantly...
[00:11:28.880 --> 00:11:33.480]   I always think of that line in Ready Player One, you know, where he's like, "We've discovered
[00:11:33.480 --> 00:11:38.080]   we can cover 87% of the human vision without causing what is it, seizures, right?
[00:11:38.080 --> 00:11:39.080]   They don't want to do that.
[00:11:39.080 --> 00:11:43.320]   They want this to be out of the way and not disrupting your vision until you go to look
[00:11:43.320 --> 00:11:44.320]   for information."
[00:11:44.320 --> 00:11:46.080]   And it's like, "Okay, who is that person?
[00:11:46.080 --> 00:11:49.400]   All right, I look up into the right and then you drops down.
[00:11:49.400 --> 00:11:50.400]   I get my information.
[00:11:50.400 --> 00:11:51.400]   I look straight forward.
[00:11:51.400 --> 00:11:53.280]   The menu recedes."
[00:11:53.280 --> 00:11:56.080]   But it was...
[00:11:56.080 --> 00:12:01.840]   I hate to use the word graceful for whatever it's face, but the UI was astonishingly graceful
[00:12:01.840 --> 00:12:02.840]   for...
[00:12:02.840 --> 00:12:05.920]   I used it and I wasn't like, "Oh God, what were they thinking?"
[00:12:05.920 --> 00:12:09.680]   So this actually brings up one of the stories we wanted to talk about today.
[00:12:09.680 --> 00:12:17.200]   The "Ajmier Hill's Peace in Today's New York Times" about a startup that is collecting
[00:12:17.200 --> 00:12:22.080]   face recognition information from everywhere.
[00:12:22.080 --> 00:12:23.440]   It's called Clear View.
[00:12:23.440 --> 00:12:28.820]   They're scraping images from Facebook, from Instagram.
[00:12:28.820 --> 00:12:35.440]   And they're not completely forthcoming about what they're doing and how they're doing it,
[00:12:35.440 --> 00:12:36.440]   but headline is the secret of...
[00:12:36.440 --> 00:12:37.440]   Well, the secret of...
[00:12:37.440 --> 00:12:38.440]   Well, the secret of...
[00:12:38.440 --> 00:12:39.440]   Yeah, right.
[00:12:39.440 --> 00:12:40.440]   Right.
[00:12:40.440 --> 00:12:41.440]   Yeah.
[00:12:41.440 --> 00:12:45.280]   The secret of company that might end privacy as we know it, law enforcement is using their
[00:12:45.280 --> 00:12:47.720]   massive database.
[00:12:47.720 --> 00:12:51.360]   The problem is, you're not opting into it.
[00:12:51.360 --> 00:12:59.680]   If you've got images up on the internet, you're probably in the Clear View database.
[00:12:59.680 --> 00:13:06.560]   They claim to have scraped from Facebook, YouTube, Venmo, Venmo, where you put your profile picture
[00:13:06.560 --> 00:13:07.560]   on it.
[00:13:07.560 --> 00:13:16.000]   There are millions of other websites, a database of three billion images.
[00:13:16.000 --> 00:13:21.520]   Federal law enforcement says, "We don't really know how it works or who's behind it, but
[00:13:21.520 --> 00:13:23.200]   we sure love it.
[00:13:23.200 --> 00:13:25.040]   We sure like to use it.
[00:13:25.040 --> 00:13:28.960]   Imagine adding that capability to those contact lenses.
[00:13:28.960 --> 00:13:31.960]   You'd know as you walk down the street, "Oh, that guy's a convicted felon.
[00:13:31.960 --> 00:13:34.120]   Oh, that guy's got an outstanding warrant.
[00:13:34.120 --> 00:13:36.600]   Oh, that guy's just a scary looking."
[00:13:36.600 --> 00:13:47.320]   I mean, I don't normally like stories that are designed to scare you, but this does scare
[00:13:47.320 --> 00:13:50.800]   me a little bit.
[00:13:50.800 --> 00:13:51.800]   So it's Peter Thiel.
[00:13:51.800 --> 00:13:52.800]   I didn't realize that.
[00:13:52.800 --> 00:13:56.240]   Yeah, he's backing it.
[00:13:56.240 --> 00:14:01.720]   He did Palantir, which was another kind of company working in the shadows, also widely
[00:14:01.720 --> 00:14:06.040]   used by law enforcement gathering information for a variety of sources, not face recognition,
[00:14:06.040 --> 00:14:11.920]   database information, and then selling it to law enforcement.
[00:14:11.920 --> 00:14:17.480]   In fact, if you have read your Tolkien, you know what a Palantir is.
[00:14:17.480 --> 00:14:22.840]   Isn't it one of those things the wizards used to see like a crystal ball anywhere in the
[00:14:22.840 --> 00:14:24.680]   world, all the Palantirs are connected?
[00:14:24.680 --> 00:14:26.560]   It's a little creepy.
[00:14:26.560 --> 00:14:27.560]   I guess.
[00:14:27.560 --> 00:14:28.560]   Hey.
[00:14:28.560 --> 00:14:31.480]   Did you see a non-on Netflix?
[00:14:31.480 --> 00:14:32.480]   Not yet.
[00:14:32.480 --> 00:14:33.480]   Is it good?
[00:14:33.480 --> 00:14:42.800]   Well, it's good because the idea of this is Clive Owen plays detective and as he's walking,
[00:14:42.800 --> 00:14:46.120]   he gets information on everyone he sees as he's walking.
[00:14:46.120 --> 00:14:47.120]   Exactly.
[00:14:47.120 --> 00:14:48.120]   Well, yeah.
[00:14:48.120 --> 00:14:53.040]   And then there's somebody who actually has anonymity and the whole-
[00:14:53.040 --> 00:14:55.800]   That's the most dangerous person of all.
[00:14:55.800 --> 00:14:56.800]   Right?
[00:14:56.800 --> 00:14:57.800]   Yes.
[00:14:57.800 --> 00:15:02.800]   In a land where everybody's face is in the database, who are the suspects?
[00:15:02.800 --> 00:15:04.320]   People who aren't.
[00:15:04.320 --> 00:15:06.320]   And that's precisely the problem.
[00:15:06.320 --> 00:15:10.120]   Yeah, but if you aren't, you don't actually exist in their world.
[00:15:10.120 --> 00:15:11.640]   That's where it gets really squirrely.
[00:15:11.640 --> 00:15:17.760]   In a future where technology has ran privacy obsolete, a detective investigates a serial
[00:15:17.760 --> 00:15:22.400]   assassin who has been deleted from all visual records.
[00:15:22.400 --> 00:15:24.720]   I'm guessing that's a man at Safread.
[00:15:24.720 --> 00:15:25.720]   Maybe not.
[00:15:25.720 --> 00:15:26.720]   I recognize her face.
[00:15:26.720 --> 00:15:32.040]   It'll be the future where you get plastic surgery so that no one knows who you are instead
[00:15:32.040 --> 00:15:35.160]   of, so you can Instagram more often.
[00:15:35.160 --> 00:15:40.440]   You know, a lot of Neil Stevenson's latest sci-fi book, The Fall, All the Teenagers
[00:15:40.440 --> 00:15:45.280]   are wearing devices that project images of their face for anonymity.
[00:15:45.280 --> 00:15:46.280]   Right.
[00:15:46.280 --> 00:15:47.760]   I can imagine a woman.
[00:15:47.760 --> 00:15:51.960]   I'll just use short mode like a little bit of submarine in a way playing for radar to
[00:15:51.960 --> 00:15:54.680]   scan your skull to go by or something else.
[00:15:54.680 --> 00:15:56.680]   It's still in the red.
[00:15:56.680 --> 00:15:57.680]   Yeah.
[00:15:57.680 --> 00:15:58.680]   Gotta get tech medium plating.
[00:15:58.680 --> 00:16:01.760]   This is actually, Sandy, you brought this up today on The Tech Guy.
[00:16:01.760 --> 00:16:04.600]   This is a category of technology.
[00:16:04.600 --> 00:16:10.120]   This is a contact lenses that have both great benefits and great risks.
[00:16:10.120 --> 00:16:13.280]   You were talking about Elon Musk's Starlink.
[00:16:13.280 --> 00:16:16.480]   And we both, or no, it wasn't you, it was Chris Markhart, our photo guy.
[00:16:16.480 --> 00:16:21.320]   We both agree that we want global gigabit internet, no matter where you go anywhere
[00:16:21.320 --> 00:16:24.760]   in the world from these low earth orbit satellites.
[00:16:24.760 --> 00:16:25.760]   But when there are--
[00:16:25.760 --> 00:16:31.360]   If you got 40,000 of these things orbiting around casting, reflecting the sun everywhere,
[00:16:31.360 --> 00:16:34.720]   you're not going to be able to see the sky anymore.
[00:16:34.720 --> 00:16:35.800]   Right.
[00:16:35.800 --> 00:16:38.760]   So on the one hand, it's a great idea.
[00:16:38.760 --> 00:16:42.480]   Can you imagine?
[00:16:42.480 --> 00:16:46.320]   They will-- everyone will be able to crack you everywhere.
[00:16:46.320 --> 00:16:49.040]   It's just so profoundly creepy to me.
[00:16:49.040 --> 00:16:50.040]   I'm going to--
[00:16:50.040 --> 00:16:53.960]   Well, those are actually something that's coming with autonomous vehicles too.
[00:16:53.960 --> 00:16:59.280]   When we do start to deploy autonomous vehicles in significant numbers, it's not going to
[00:16:59.280 --> 00:17:01.600]   be vehicles that we sell to consumers.
[00:17:01.600 --> 00:17:06.120]   It's going to be-- it's going to be Robotaxi services, autonomous mobility services.
[00:17:06.120 --> 00:17:10.520]   So every one of these things is going to have sensors in there that's going to monitor who's
[00:17:10.520 --> 00:17:15.560]   getting in the vehicle, what their state is when they're in the vehicle, if somebody
[00:17:15.560 --> 00:17:21.920]   gets sick or has a heart attack or something, if they leave anything behind, whoever's operating
[00:17:21.920 --> 00:17:27.760]   these fleets is going to want to know who's in there so that they can do billing and everything.
[00:17:27.760 --> 00:17:36.680]   And if you're in these things, already today, if you carry a phone, you're being tracked
[00:17:36.680 --> 00:17:37.680]   anyway.
[00:17:37.680 --> 00:17:42.880]   But it's going to just keep accelerating as we move into these new kinds of services where
[00:17:42.880 --> 00:17:47.840]   the systems depend on knowing who you are and where you're going.
[00:17:47.840 --> 00:17:49.840]   It's like the Amazon Ghost Store.
[00:17:49.840 --> 00:17:53.200]   Yeah, they don't have to pay for anything, the cameras know.
[00:17:53.200 --> 00:17:58.360]   It's already that anonymity is almost impossible to keep.
[00:17:58.360 --> 00:18:02.960]   If you travel across borders, if you're going to end up using a credit card, if you're using
[00:18:02.960 --> 00:18:07.840]   a cell phone, anonymity is almost-- this is going to be one day where anonymity itself
[00:18:07.840 --> 00:18:11.200]   will be illegal, that you will have to make sure that you're kind of tracked wherever you
[00:18:11.200 --> 00:18:12.200]   are.
[00:18:12.200 --> 00:18:13.200]   And it's like the gateway drug.
[00:18:13.200 --> 00:18:17.000]   We're already way overly addicted to our phones.
[00:18:17.000 --> 00:18:19.400]   The ability to unplug is really difficult.
[00:18:19.400 --> 00:18:24.200]   Georgia, besides being senior editor at iMore, you are a psychotherapist.
[00:18:24.200 --> 00:18:27.120]   Is there-- I don't know why I'm telling you that.
[00:18:27.120 --> 00:18:29.880]   I think you know that.
[00:18:29.880 --> 00:18:31.640]   For those who don't.
[00:18:31.640 --> 00:18:38.880]   But I would imagine there's also a deep psychological risk to this.
[00:18:38.880 --> 00:18:43.200]   People want to be known, but maybe that's alluded too much.
[00:18:43.200 --> 00:18:48.280]   It's kind of funny because the latest trend that I've seen in my work is people saying
[00:18:48.280 --> 00:18:53.280]   that young teens saying I'm actually on my phone too much, I don't want to use it as
[00:18:53.280 --> 00:18:54.480]   much.
[00:18:54.480 --> 00:18:56.840]   I'm trying to unplug.
[00:18:56.840 --> 00:19:01.080]   And this is the largest growth population, which was the strongest for addiction.
[00:19:01.080 --> 00:19:03.440]   That's actually being the first people that are saying, "You know what?
[00:19:03.440 --> 00:19:04.440]   This is too much.
[00:19:04.440 --> 00:19:05.440]   I don't want to use it."
[00:19:05.440 --> 00:19:10.280]   And it's the first week that I had three people say, "I try not to use my phone anymore,"
[00:19:10.280 --> 00:19:15.120]   which was really pretty powerful because of how addictive its nature is.
[00:19:15.120 --> 00:19:17.400]   And they're not attached to social media.
[00:19:17.400 --> 00:19:19.600]   They're trying not to use Instagram.
[00:19:19.600 --> 00:19:21.440]   One is because of its psychological effects.
[00:19:21.440 --> 00:19:26.800]   And the other is because their Facebook is now looked at as creepy by the newest generation,
[00:19:26.800 --> 00:19:28.080]   not as something that's cool.
[00:19:28.080 --> 00:19:29.920]   It's something that your grandmother does.
[00:19:29.920 --> 00:19:30.920]   That encourages me.
[00:19:30.920 --> 00:19:32.760]   Not that there's anything wrong with that.
[00:19:32.760 --> 00:19:33.760]   Grandma?
[00:19:33.760 --> 00:19:34.920]   Yes, there is.
[00:19:34.920 --> 00:19:40.320]   No, that encourages me because of course part of the debate that's going on is should
[00:19:40.320 --> 00:19:46.920]   government be regulating these giant companies, especially Facebook, to protect us from ourselves.
[00:19:46.920 --> 00:19:48.240]   It's encouraging.
[00:19:48.240 --> 00:19:51.520]   I think that's a terrible solution, but if it's the only solution, then it's the only
[00:19:51.520 --> 00:19:52.520]   solution.
[00:19:52.520 --> 00:19:58.600]   But it's encouraging that maybe we don't need that if people are self-correcting.
[00:19:58.600 --> 00:20:00.960]   If they're going to be saying, "You know what?
[00:20:00.960 --> 00:20:01.960]   I could tell this is bad for me.
[00:20:01.960 --> 00:20:03.760]   I'm going to use it less."
[00:20:03.760 --> 00:20:06.400]   That would be a very encouraging thing to me.
[00:20:06.400 --> 00:20:09.480]   I still think that they probably will need to have regulations.
[00:20:09.480 --> 00:20:11.240]   They have too much power.
[00:20:11.240 --> 00:20:12.240]   They have too much power.
[00:20:12.240 --> 00:20:16.760]   There's no way that a company with that much power will not be able to be evil with it.
[00:20:16.760 --> 00:20:19.520]   It's just it corrupts.
[00:20:19.520 --> 00:20:23.680]   Once you taste power and how much money they can make and how much they can control what
[00:20:23.680 --> 00:20:29.080]   people do and say, which if you have information to everyone, really, there's more information
[00:20:29.080 --> 00:20:30.240]   about me on my phone.
[00:20:30.240 --> 00:20:35.080]   I'd rather if I had to choose between my husband being subpoenaed or my phone, I'll take my
[00:20:35.080 --> 00:20:36.080]   husband.
[00:20:36.080 --> 00:20:37.400]   He knows a lot less about you.
[00:20:37.400 --> 00:20:38.400]   He does.
[00:20:38.400 --> 00:20:41.080]   I bet he doesn't even notice when you get your hair color changed.
[00:20:41.080 --> 00:20:42.080]   No.
[00:20:42.080 --> 00:20:43.080]   He wouldn't notice.
[00:20:43.080 --> 00:20:44.080]   Did you get a haircut?
[00:20:44.080 --> 00:20:45.080]   No.
[00:20:45.080 --> 00:20:46.080]   He wouldn't know.
[00:20:46.080 --> 00:20:47.080]   He wouldn't know.
[00:20:47.080 --> 00:20:52.080]   I would say that that's because he cares about inside of me.
[00:20:52.080 --> 00:20:53.080]   The deep tune.
[00:20:53.080 --> 00:20:54.080]   Oh, is that it?
[00:20:54.080 --> 00:20:58.080]   I think that's my excuse to my wife every time she comes back from a haircut.
[00:20:58.080 --> 00:20:59.080]   He cares about it.
[00:20:59.080 --> 00:21:00.080]   Did you just always...
[00:21:00.080 --> 00:21:01.080]   Yeah.
[00:21:01.080 --> 00:21:02.080]   That's for dinner.
[00:21:02.080 --> 00:21:03.080]   That's really...
[00:21:03.080 --> 00:21:04.080]   Okay.
[00:21:04.080 --> 00:21:08.200]   We have a theme on this show, which is Double Edge Sword.
[00:21:08.200 --> 00:21:13.840]   Because like Starlink, like face recognition, you could see positives and negatives.
[00:21:13.840 --> 00:21:15.280]   We're going to take a break.
[00:21:15.280 --> 00:21:20.880]   When we come back, I think we got to talk about the United States Attorney General,
[00:21:20.880 --> 00:21:30.280]   William Barr, and the latest battle with Apple over a terrorist's iPhone and what it all
[00:21:30.280 --> 00:21:31.280]   means.
[00:21:31.280 --> 00:21:36.880]   I think that you said something interesting, Georgia, when you said maybe what will happen
[00:21:36.880 --> 00:21:42.200]   is we'll get to a world where it's illegal not to be in the database.
[00:21:42.200 --> 00:21:45.560]   I think we may get to a world where it's illegal to use encryption.
[00:21:45.560 --> 00:21:51.840]   That's the only way you can't force people to unlock phones.
[00:21:51.840 --> 00:21:56.040]   But you can say it would be illegal to have a crypto device.
[00:21:56.040 --> 00:21:57.280]   And I wonder if that's where we're headed.
[00:21:57.280 --> 00:21:59.240]   We're going to talk about that in just a second.
[00:21:59.240 --> 00:22:00.240]   imore.com.
[00:22:00.240 --> 00:22:02.200]   Georgia Dow, great to have you.
[00:22:02.200 --> 00:22:04.120]   Haven't seen you in ages.
[00:22:04.120 --> 00:22:07.640]   Still doing the 3D VR thing.
[00:22:07.640 --> 00:22:08.640]   I am.
[00:22:08.640 --> 00:22:09.640]   Yeah.
[00:22:09.640 --> 00:22:11.640]   Don't go on to some 2D games as well.
[00:22:11.640 --> 00:22:12.640]   What?
[00:22:12.640 --> 00:22:13.640]   Yeah.
[00:22:13.640 --> 00:22:14.640]   Yeah.
[00:22:14.640 --> 00:22:15.640]   My kids are now.
[00:22:15.640 --> 00:22:19.000]   My husband and my kids are playing Castlevania Symphony of the Night.
[00:22:19.000 --> 00:22:21.480]   Like really old school 1997.
[00:22:21.480 --> 00:22:22.480]   See?
[00:22:22.480 --> 00:22:23.480]   Gaming.
[00:22:23.480 --> 00:22:24.480]   I'm not sure why you're being a game.
[00:22:24.480 --> 00:22:25.480]   It's all coming back.
[00:22:25.480 --> 00:22:26.480]   It's all coming back.
[00:22:26.480 --> 00:22:29.560]   Yeah, but I still love, I still, there's nothing like a zombie apocalypse.
[00:22:29.560 --> 00:22:34.120]   How many VR rooms do you have now?
[00:22:34.120 --> 00:22:35.120]   Four.
[00:22:35.120 --> 00:22:39.200]   You say that as if there's something to be ashamed of.
[00:22:39.200 --> 00:22:40.200]   That's something you've probably brought.
[00:22:40.200 --> 00:22:46.480]   Well, it's a little bit much, but you know, I, we have, there's four of us in the family.
[00:22:46.480 --> 00:22:49.280]   And if we all want to play a game together, we can.
[00:22:49.280 --> 00:22:50.280]   Sure.
[00:22:50.280 --> 00:22:51.280]   And I like tech.
[00:22:51.280 --> 00:22:52.280]   So there we go.
[00:22:52.280 --> 00:22:53.280]   Nice.
[00:22:53.280 --> 00:22:57.600]   Also with the Sam Eble Samad, how many cars do you have?
[00:22:57.600 --> 00:22:59.600]   I own only two.
[00:22:59.600 --> 00:23:00.600]   Wow.
[00:23:00.600 --> 00:23:03.560]   But you know, currently there's two more in the driveway, two additional ones in the
[00:23:03.560 --> 00:23:04.560]   driveway.
[00:23:04.560 --> 00:23:05.560]   Your neighbors must be confused.
[00:23:05.560 --> 00:23:08.320]   I get to drive other people's cars.
[00:23:08.320 --> 00:23:12.920]   Patrick Norton, who is currently rolling coal down the down the streets.
[00:23:12.920 --> 00:23:14.240]   No, I never roll coal.
[00:23:14.240 --> 00:23:15.240]   Good.
[00:23:15.240 --> 00:23:19.040]   I have a hundred foot pounds of torque, but I do not roll coal.
[00:23:19.040 --> 00:23:21.360]   You by the way, taught me what rolling coal means.
[00:23:21.360 --> 00:23:22.360]   So thank you.
[00:23:22.360 --> 00:23:26.240]   That was an odd conversation.
[00:23:26.240 --> 00:23:32.080]   I show today brought to you by Kaptera the way to find the right business software for
[00:23:32.080 --> 00:23:34.360]   you and your business.
[00:23:34.360 --> 00:23:40.800]   New year, bigger goals, time to get the big things done in your business better and faster.
[00:23:40.800 --> 00:23:45.840]   That means no more Windows seven, no more Windows XP, no more internet explorer.
[00:23:45.840 --> 00:23:47.440]   It's time to get some modern stuff.
[00:23:47.440 --> 00:23:50.640]   And where do you go to find out what's new, what's out there?
[00:23:50.640 --> 00:23:53.000]   Kaptera, the free website.
[00:23:53.000 --> 00:23:56.120]   Millions of people use every month to find software for their business.
[00:23:56.120 --> 00:24:00.040]   Kaptera simplifies the search in just a few easy steps.
[00:24:00.040 --> 00:24:01.920]   First of all, you say, well, here's what I need.
[00:24:01.920 --> 00:24:07.960]   And by the way, 700 categories, thousands of different programs, pretty much anything
[00:24:07.960 --> 00:24:15.080]   you might do in business from yoga studio management to CRM to video management and more.
[00:24:15.080 --> 00:24:17.200]   You go in there, you say, this is what I'm looking for.
[00:24:17.200 --> 00:24:22.240]   You can narrow it down with your smart search tool and the filters check the boxes for the
[00:24:22.240 --> 00:24:23.560]   features you need.
[00:24:23.560 --> 00:24:27.400]   What's nice is they're customized depending on the category you're looking at.
[00:24:27.400 --> 00:24:29.400]   This is music school software.
[00:24:29.400 --> 00:24:30.400]   What?
[00:24:30.400 --> 00:24:32.080]   So there's quite a bit of it.
[00:24:32.080 --> 00:24:34.160]   You can say, well, I want a free tier.
[00:24:34.160 --> 00:24:37.640]   I want to be able to schedule.
[00:24:37.640 --> 00:24:40.880]   I want to be able to manage students, whatever features you need.
[00:24:40.880 --> 00:24:44.680]   And you see how it's great that this selection is appropriate to the category that you're
[00:24:44.680 --> 00:24:45.680]   in.
[00:24:45.680 --> 00:24:50.160]   Narrow it to a short list, compare them side by side, which makes it very easy to see
[00:24:50.160 --> 00:24:51.160]   what does what.
[00:24:51.160 --> 00:24:53.760]   But then this is when the best part happens.
[00:24:53.760 --> 00:24:59.160]   When you're at Kaptera.com/twit, you'll see over a million reviews from actual software
[00:24:59.160 --> 00:25:06.160]   users, Kaptera, Vetsum, to make sure that everything there is valid, a valid user.
[00:25:06.160 --> 00:25:10.480]   And that is the kind of information you need to find exactly the right software for you.
[00:25:10.480 --> 00:25:12.000]   This is what makes Kaptera so great.
[00:25:12.000 --> 00:25:14.760]   Did I mention it's free?
[00:25:14.760 --> 00:25:15.760]   It's free.
[00:25:15.760 --> 00:25:17.440]   Kaptera can help your business thrive.
[00:25:17.440 --> 00:25:21.760]   But making the software buying process as easy and effective as possible.
[00:25:21.760 --> 00:25:24.040]   You shouldn't be using Windows 7 at work anymore.
[00:25:24.040 --> 00:25:26.600]   It's time to get something a little more modern.
[00:25:26.600 --> 00:25:28.920]   Go to kaptera.com/twit.
[00:25:28.920 --> 00:25:30.600]   There's lots of other stuff there too, by the way.
[00:25:30.600 --> 00:25:34.680]   It's the leading free online resource for business software, helpful articles, free
[00:25:34.680 --> 00:25:37.640]   guidebooks, step by step, ebooks, a whole lot more.
[00:25:37.640 --> 00:25:39.280]   Kaptera.com/twit.
[00:25:39.280 --> 00:25:44.920]   We're looking for a new CRM program when Kaptera really helped us find exactly the program
[00:25:44.920 --> 00:25:46.280]   that's right for us.
[00:25:46.280 --> 00:25:51.840]   Kaptera.com/twit, making the form software decision for your business.
[00:25:51.840 --> 00:25:55.560]   C-A-P-T-E-W-R-A, Kaptera.com/twit.
[00:25:55.560 --> 00:25:59.680]   Kaptera's software selection, simplified.
[00:25:59.680 --> 00:26:03.440]   Say that again, you don't roll cold, but you have how many hundred thousand pounds
[00:26:03.440 --> 00:26:04.440]   of torque?
[00:26:04.440 --> 00:26:07.920]   I think around 800 foot pounds.
[00:26:07.920 --> 00:26:09.280]   Is that a lot, Sam?
[00:26:09.280 --> 00:26:15.840]   I want a higher Sam to translate for me when I talk to Patrick from now on.
[00:26:15.840 --> 00:26:18.640]   It is an adequate amount.
[00:26:18.640 --> 00:26:21.560]   You can never have too much torque.
[00:26:21.560 --> 00:26:24.880]   That has long been my philosophy that there's no such thing as too much torque.
[00:26:24.880 --> 00:26:25.880]   Wow.
[00:26:25.880 --> 00:26:30.400]   I don't think I've driven a car where I even knew how much torque I had.
[00:26:30.400 --> 00:26:34.040]   You probably had close to that in your model.
[00:26:34.040 --> 00:26:38.360]   My Tesla did have 800 foot pounds of torque.
[00:26:38.360 --> 00:26:40.640]   And you had it from 0 RPM through maximum RPM.
[00:26:40.640 --> 00:26:43.200]   Yes, I did have a torque curve.
[00:26:43.200 --> 00:26:47.680]   No, I didn't notice that because when I started, the front wheels kept going up.
[00:26:47.680 --> 00:26:49.440]   I thought.
[00:26:49.440 --> 00:26:54.840]   So, this is a complicated story.
[00:26:54.840 --> 00:26:58.040]   It's been getting the headlines this week.
[00:26:58.040 --> 00:27:06.640]   You may remember in last year in San Bernad, Pensacola, Florida, a Saudi military officer
[00:27:06.640 --> 00:27:13.280]   who was training at the Pensacola Naval Air Station, killed three service members, wounded
[00:27:13.280 --> 00:27:19.400]   eight, and then was shot himself after shooting one of his iPhones.
[00:27:19.400 --> 00:27:25.840]   Clearly, he understood that that iPhone might contain some imported information.
[00:27:25.840 --> 00:27:32.200]   The FBI apparently, and this is one thing that's really frosted Apple, did go to Apple
[00:27:32.200 --> 00:27:33.200]   right away.
[00:27:33.200 --> 00:27:39.240]   And Apple helped giving him access to his iCloud account to a lot of information about
[00:27:39.240 --> 00:27:41.000]   the person.
[00:27:41.000 --> 00:27:45.400]   They helped as much as they could, but they're one thing that Apple cannot do.
[00:27:45.400 --> 00:27:49.720]   And that's why this is a little different than the San Bernadino case from a few years back.
[00:27:49.720 --> 00:27:54.480]   In fact, this is the law fair blog, Nicholas Weaver writing, Pensacola isn't San Bernadino
[00:27:54.480 --> 00:28:00.120]   because in San Bernadino was an older iPhone, they could have given the information to the
[00:28:00.120 --> 00:28:03.000]   FBI or they could have done something to modify it.
[00:28:03.000 --> 00:28:05.960]   This time, Apple has no access to that information.
[00:28:05.960 --> 00:28:12.360]   They've been very careful to make sure that the device is encrypted in a way that even
[00:28:12.360 --> 00:28:16.600]   Apple can't see it.
[00:28:16.600 --> 00:28:21.680]   In the San Bernadino case, the FBI eventually dropped their request because they figured
[00:28:21.680 --> 00:28:27.080]   out, "Oh, there's an Israeli company that sells software that will crack this," and
[00:28:27.080 --> 00:28:29.720]   they were able to get into it.
[00:28:29.720 --> 00:28:33.360]   They may be able to do the same with the Pensacola case, apparently, "Graky."
[00:28:33.360 --> 00:28:36.640]   "Graky" and "celebrated" are the two big companies that do this.
[00:28:36.640 --> 00:28:40.520]   "Graky" does have something that will get into it even an iPhone 11.
[00:28:40.520 --> 00:28:44.000]   He talks about it because they know that if they talked about it, Apple would fix it as
[00:28:44.000 --> 00:28:49.960]   soon as they could.
[00:28:49.960 --> 00:28:50.960]   What do you think?
[00:28:50.960 --> 00:28:52.400]   Let me ask you, Patrick.
[00:28:52.400 --> 00:28:57.480]   What do you think Attorney General Barr really wants?
[00:28:57.480 --> 00:29:04.840]   Well, he wants them to magically unlock everything and hear from all the information immediately.
[00:29:04.840 --> 00:29:12.280]   The same thing that the Attorney General or the FBI wanted in previous cases.
[00:29:12.280 --> 00:29:16.200]   Law enforcement wants, for the most part, full access immediately.
[00:29:16.200 --> 00:29:17.200]   They want a magic.
[00:29:17.200 --> 00:29:21.640]   I mean, this is the same thing.
[00:29:21.640 --> 00:29:25.480]   Well, my former, your current Senator.
[00:29:25.480 --> 00:29:27.560]   Dine Feinstein, yeah.
[00:29:27.560 --> 00:29:29.040]   Wait a minute.
[00:29:29.040 --> 00:29:34.040]   You want to just tell me anymore or did you just become a citizen of your own land?
[00:29:34.040 --> 00:29:38.640]   Well, we'll discuss domicile on another exciting podcast.
[00:29:38.640 --> 00:29:42.280]   Have you departed our fair, golden state?
[00:29:42.280 --> 00:29:50.040]   Are you one of many people who have just said goodbye to a 14% tax rate and an 8% sales tax?
[00:29:50.040 --> 00:29:51.440]   Are you one of those people?
[00:29:51.440 --> 00:29:52.440]   Yes.
[00:29:52.440 --> 00:29:56.040]   I did not feel the large enough rats, so I sold my house.
[00:29:56.040 --> 00:29:57.240]   Congratulations.
[00:29:57.240 --> 00:29:59.440]   We are exploring and searching for a new location.
[00:29:59.440 --> 00:30:04.720]   But the thing, I mean, fine signs, like this is, I love security.
[00:30:04.720 --> 00:30:05.720]   I love it.
[00:30:05.720 --> 00:30:06.720]   It's been so good for business in the state.
[00:30:06.720 --> 00:30:15.280]   Now, if you just put a little key that only, this is a security argument from forever.
[00:30:15.280 --> 00:30:19.200]   There's one side that's like, everything should have a backdoor because we need to have access
[00:30:19.200 --> 00:30:20.200]   to everything.
[00:30:20.200 --> 00:30:25.920]   And the other side's like, if there's a backdoor, eventually everyone will have access to it.
[00:30:25.920 --> 00:30:29.440]   Look, I am a big First Amendment person.
[00:30:29.440 --> 00:30:36.120]   The problem is, is if all speech is protected, barring the stuff that's been settled about
[00:30:36.120 --> 00:30:41.920]   yelling fire in a crowded movie house, then the Illinois Nazis get to march up in March,
[00:30:41.920 --> 00:30:48.520]   which is why the ACLU fought for their right to be villainous scumbags in public, which
[00:30:48.520 --> 00:30:49.920]   I think is great.
[00:30:49.920 --> 00:30:53.720]   I love it when you identify the Nazis and you can go hunt them down and exterminate them.
[00:30:53.720 --> 00:30:54.720]   That's personal opinion.
[00:30:54.720 --> 00:30:56.720]   We're not advocating incidentally.
[00:30:56.720 --> 00:30:57.720]   Yeah.
[00:30:57.720 --> 00:30:58.720]   Yeah.
[00:30:58.720 --> 00:31:05.520]   You know, as far as I could, sir, you could punch them in the nose, but let's not hunt
[00:31:05.520 --> 00:31:06.520]   them down.
[00:31:06.520 --> 00:31:08.480]   Yeah, Warren Ellis is telling you it's okay to punch a Nazi in the face.
[00:31:08.480 --> 00:31:09.720]   It's probably okay.
[00:31:09.720 --> 00:31:10.720]   I digress.
[00:31:10.720 --> 00:31:15.600]   But the challenge here, right, is people who are responsible for security and safety,
[00:31:15.600 --> 00:31:21.080]   want access and people who, there are people who also believe, you know, to the whole,
[00:31:21.080 --> 00:31:25.080]   this is, this is an argument goes back a long time, people who would give up a little
[00:31:25.080 --> 00:31:27.400]   liberty for safety, deserve neither, right?
[00:31:27.400 --> 00:31:29.400]   In the words of Santa Franklin.
[00:31:29.400 --> 00:31:31.680]   This is though that same double edged sword.
[00:31:31.680 --> 00:31:34.040]   We do want protection from terrorism.
[00:31:34.040 --> 00:31:37.520]   We do want law enforcement to be able to do their job.
[00:31:37.520 --> 00:31:42.760]   But at the, the real question is, can you give law enforcement or anybody access to
[00:31:42.760 --> 00:31:46.800]   this data without giving bad guys access to this data?
[00:31:46.800 --> 00:31:50.080]   Here's what further complicates it from my point of view.
[00:31:50.080 --> 00:31:56.920]   AG bar must indeed know, according to Forbes, the FBI already knows how to unlock an iPhone
[00:31:56.920 --> 00:31:59.160]   11 Pro Max.
[00:31:59.160 --> 00:32:04.920]   They already know using technology from gray, what is it?
[00:32:04.920 --> 00:32:07.120]   Gray cell, gray key.
[00:32:07.120 --> 00:32:15.480]   So gray key, if gray key can unlock an iPhone 11 Pro Max, then it means the FBI can unlock
[00:32:15.480 --> 00:32:17.200]   the shooters phone.
[00:32:17.200 --> 00:32:21.800]   And now I'm starting to think that that's really not AG bar's agenda.
[00:32:21.800 --> 00:32:29.400]   No, it's about making companies like Apple look bad, you know, to make them appear to
[00:32:29.400 --> 00:32:32.360]   be on the wrong side of this issue.
[00:32:32.360 --> 00:32:39.520]   And then hopefully get Congress to act and do, you know, to introduce some kind of legislation
[00:32:39.520 --> 00:32:44.640]   to do what you talked about, you know, which is to make encryption illegal or, you know,
[00:32:44.640 --> 00:32:49.880]   enforce them to put back doors into it, which, you know, on this one, you know, I humbly
[00:32:49.880 --> 00:32:55.280]   have to disagree with, with Steve Gibson, you know, I don't think that you can safely
[00:32:55.280 --> 00:32:56.280]   do it.
[00:32:56.280 --> 00:33:00.920]   I don't think that there is a safe way to, you know, create that kind of escrow system
[00:33:00.920 --> 00:33:05.000]   for this key and not have it abused by somebody.
[00:33:05.000 --> 00:33:06.000]   Georgia?
[00:33:06.000 --> 00:33:07.960]   Yeah, no, I absolutely agree.
[00:33:07.960 --> 00:33:12.240]   There's only one reason for them to go public and that's to put pressure on Apple to try
[00:33:12.240 --> 00:33:17.480]   to create as much bad press for them so that the Court of Public Opinion is against them
[00:33:17.480 --> 00:33:19.120]   and wants this.
[00:33:19.120 --> 00:33:23.440]   And then they will push it through Congress as quickly as possible.
[00:33:23.440 --> 00:33:27.400]   And they really, they just want to make sure that Apple is going to get as much bad press.
[00:33:27.400 --> 00:33:31.160]   So every time this happens, they push them even though you know that they can, they probably
[00:33:31.160 --> 00:33:33.160]   even have it opened already.
[00:33:33.160 --> 00:33:34.920]   Who knows, right?
[00:33:34.920 --> 00:33:39.600]   Here's what Nicholas Weaver writes in the law fair blog.
[00:33:39.600 --> 00:33:43.160]   The FBI's request for Apple's help is puzzling.
[00:33:43.160 --> 00:33:47.680]   If the government takes Apple to court, as it did in the San Bernardino case, the judiciary
[00:33:47.680 --> 00:33:53.480]   can't compel Apple to provide any meaningful assistance because there is no more meaningful
[00:33:53.480 --> 00:33:55.960]   assistance Apple can provide.
[00:33:55.960 --> 00:33:58.800]   San Bernardino was about Apple not wanting to assist the FBI.
[00:33:58.800 --> 00:34:03.560]   This is about Apple being incapable of assisting the FBI.
[00:34:03.560 --> 00:34:07.080]   So even if the case winds up in court, real help from Apple is not going to come out of
[00:34:07.080 --> 00:34:08.480]   a judicial battle.
[00:34:08.480 --> 00:34:11.360]   The meaningful fight, this is exactly what you said Georgia.
[00:34:11.360 --> 00:34:16.760]   The meaningful fight is in the court of public opinion.
[00:34:16.760 --> 00:34:20.080]   And if he was, you can tell that if they were going to go through this and be really
[00:34:20.080 --> 00:34:23.040]   honest about it, they would have stated that you know what Apple's helped us as much as
[00:34:23.040 --> 00:34:24.040]   we could.
[00:34:24.040 --> 00:34:27.320]   We wish that they would create a backdoor so that we could, you know, not have to go
[00:34:27.320 --> 00:34:30.640]   through this or it would be faster, but they don't state any of those things.
[00:34:30.640 --> 00:34:35.080]   They try to put Apple in as dark of a light as possible in hopes that people get really
[00:34:35.080 --> 00:34:36.080]   angry.
[00:34:36.080 --> 00:34:42.400]   You know, that we can say that we do have a kind of hair trigger society right now that,
[00:34:42.400 --> 00:34:46.400]   you know, the zeitgeist of the moment kind of goes through all social media with people
[00:34:46.400 --> 00:34:49.040]   being exceptionally angry and it's fast.
[00:34:49.040 --> 00:34:51.840]   Yeah, we live in an era of outrage.
[00:34:51.840 --> 00:34:52.840]   Yeah.
[00:34:52.840 --> 00:34:56.000]   And you're on that much.
[00:34:56.000 --> 00:34:57.000]   Patrick, go ahead.
[00:34:57.000 --> 00:35:04.480]   You know, the problem is that, you know, as bad as terrorism is, you know, and I'd say
[00:35:04.480 --> 00:35:06.480]   it's a bad thing.
[00:35:06.480 --> 00:35:08.480]   No doubt about it.
[00:35:08.480 --> 00:35:13.680]   And the grand scheme of all the issues we have, it's not actually that big of an issue.
[00:35:13.680 --> 00:35:18.160]   It doesn't affect that many people, you know, compared to so many other things.
[00:35:18.160 --> 00:35:22.160]   You know, if you look at, you know, how many people in this country are going with how
[00:35:22.160 --> 00:35:27.320]   proper health care or, or, you know, not, you know, not being able to afford food and
[00:35:27.320 --> 00:35:33.200]   shelter, you know, you know, terrorism is not really that big a deal.
[00:35:33.200 --> 00:35:35.200]   I'm going to go one step.
[00:35:35.200 --> 00:35:36.200]   Generate contracts.
[00:35:36.200 --> 00:35:41.360]   I'm going to go one step farther than you because I think really what's really, no,
[00:35:41.360 --> 00:35:46.800]   I don't want to be a conspiracy theory guy, but I feel like Attorney General Barr is emboldened
[00:35:46.800 --> 00:35:49.480]   by the current situation in the United States.
[00:35:49.480 --> 00:35:55.240]   He feels like he has an opportunity, perhaps a brief window of opportunity to do what I
[00:35:55.240 --> 00:36:00.920]   think some, not all by far, not all, but some in law enforcement want, which is to create
[00:36:00.920 --> 00:36:02.880]   a surveillance state.
[00:36:02.880 --> 00:36:10.520]   But some in law enforcement would like to do is have a perfect view, a panopticon, a perfect
[00:36:10.520 --> 00:36:14.440]   view of everything that happens in the country.
[00:36:14.440 --> 00:36:18.960]   And I don't think it's solely to protect us for terrorism or, you know, they'll often
[00:36:18.960 --> 00:36:23.840]   use things like terrorism or child abuse or child pornography because those things really
[00:36:23.840 --> 00:36:25.880]   get people outraged and upset.
[00:36:25.880 --> 00:36:27.920]   I don't think it has really much to do with that.
[00:36:27.920 --> 00:36:33.200]   I think it has a lot more to do with just controlling the populace and really knowing
[00:36:33.200 --> 00:36:37.880]   what's going on so you can suppress dissent, so you can do all the kinds of things true
[00:36:37.880 --> 00:36:40.640]   authoritarian regimes do.
[00:36:40.640 --> 00:36:42.800]   I honestly think that that's what's going on.
[00:36:42.800 --> 00:36:49.320]   I think Barr is in some ways represents the worst of law enforcement, the people who want
[00:36:49.320 --> 00:36:51.400]   total information.
[00:36:51.400 --> 00:36:57.840]   I'm probably the last person to defend Barr, but I think he may genuinely just want
[00:36:57.840 --> 00:37:03.440]   the magic button on any given crime or any given situation and that he's not intentionally
[00:37:03.440 --> 00:37:05.560]   planning to create a surveillance state.
[00:37:05.560 --> 00:37:10.240]   I mean, you know, if that's a side effect as long as his side is in control, he'll be
[00:37:10.240 --> 00:37:12.160]   really happy about it.
[00:37:12.160 --> 00:37:15.160]   You know, and there's a lot of people who do a lot of things.
[00:37:15.160 --> 00:37:20.280]   You don't think he wants a Chinese style surveillance apparatus in the United States?
[00:37:20.280 --> 00:37:22.080]   You know, I don't know the mayor.
[00:37:22.080 --> 00:37:24.080]   There are others in the administration who do.
[00:37:24.080 --> 00:37:25.080]   Yeah, absolutely.
[00:37:25.080 --> 00:37:26.080]   No.
[00:37:26.080 --> 00:37:29.600]   I'll be honest with you, there's others in every administration who just want perfect
[00:37:29.600 --> 00:37:32.000]   clarity on all the issues at all time.
[00:37:32.000 --> 00:37:37.560]   I mean, it's unfortunately is not something it is restricted to the Republican side of
[00:37:37.560 --> 00:37:38.560]   the fence.
[00:37:38.560 --> 00:37:40.960]   There are lots of Democrats who, you know, are fairly.
[00:37:40.960 --> 00:37:43.000]   Ryan Feinstein, you brought her up.
[00:37:43.000 --> 00:37:44.000]   Yeah.
[00:37:44.000 --> 00:37:45.000]   Yeah.
[00:37:45.000 --> 00:37:50.440]   No, it's, it's, you know, either way it's creepy and unnecessary and fundamentally un-American
[00:37:50.440 --> 00:37:51.440]   and kind of evil.
[00:37:51.440 --> 00:37:55.160]   That's kind of the, that's the point is it is, it is anti, it's unconstitutional.
[00:37:55.160 --> 00:37:59.680]   It's anti-American, but you can see why people will say, but we'd be safer.
[00:37:59.680 --> 00:38:04.000]   And I think that's some of the argument in China, but, but we've received order this
[00:38:04.000 --> 00:38:05.000]   way.
[00:38:05.000 --> 00:38:07.000]   Would you rather have an orderly country?
[00:38:07.000 --> 00:38:08.000]   Yeah.
[00:38:08.000 --> 00:38:11.320]   I don't think anyone really thinks to themselves that they're going to use this for ill.
[00:38:11.320 --> 00:38:15.560]   They think that if I had full knowledge, you can see the same thing with like parenting.
[00:38:15.560 --> 00:38:19.600]   If I knew everything that my child was doing at every moment, I could stop that thing.
[00:38:19.600 --> 00:38:20.600]   It would be really depressed.
[00:38:20.600 --> 00:38:21.600]   Right.
[00:38:21.600 --> 00:38:23.320]   No, that's a really good point though.
[00:38:23.320 --> 00:38:24.920]   Actually, that's a great analogy.
[00:38:24.920 --> 00:38:28.880]   As a mom, you would like to know exactly where your kid is at all times, everything they're
[00:38:28.880 --> 00:38:29.880]   talking about.
[00:38:29.880 --> 00:38:30.880]   But that's not good for the kid.
[00:38:30.880 --> 00:38:35.440]   That would be helpful and you could stop things and you could protect them.
[00:38:35.440 --> 00:38:39.720]   But in the end, what you're doing is you're disempowering them and not allowing them to
[00:38:39.720 --> 00:38:43.880]   be able to think for themselves and to be able to make their own choices, even if they're
[00:38:43.880 --> 00:38:46.480]   the wrong choice to learn from those decisions.
[00:38:46.480 --> 00:38:49.760]   So I don't think that a lot of times I don't think that's out of malice.
[00:38:49.760 --> 00:38:54.000]   I think that we're all a little bit narcissistic and you believe that if I used it, I would
[00:38:54.000 --> 00:38:55.360]   use it for good.
[00:38:55.360 --> 00:38:56.880]   Like, you know, Galadriel with the ring.
[00:38:56.880 --> 00:38:58.160]   Like I would totally take the ring.
[00:38:58.160 --> 00:38:59.800]   Like I would be a good dark queen.
[00:38:59.800 --> 00:39:00.800]   Yes.
[00:39:00.800 --> 00:39:01.800]   You know, all the things.
[00:39:01.800 --> 00:39:05.320]   Everybody thinks they could use the ring of power safely.
[00:39:05.320 --> 00:39:10.720]   100% and I, but the thing is, is that power corrupts and once you know everything, it
[00:39:10.720 --> 00:39:12.400]   becomes really dangerous.
[00:39:12.400 --> 00:39:18.000]   And that's why we need to make sure that the constitution is protected because you will
[00:39:18.000 --> 00:39:22.800]   out of good thing that you can use something that later becomes really bad and you cannot
[00:39:22.800 --> 00:39:25.280]   put the genie back inside of the bottle.
[00:39:25.280 --> 00:39:29.320]   I should point out that I'm not making up this total information awareness.
[00:39:29.320 --> 00:39:37.960]   This was the acronym in 2003 shortly after 9/11, our law enforcement in this country actively
[00:39:37.960 --> 00:39:40.880]   sought this kind of information.
[00:39:40.880 --> 00:39:45.680]   And the whole point was total information awareness of transnational threats requires
[00:39:45.680 --> 00:39:49.560]   keeping track of individuals and understanding how they fit into models, knowing everything
[00:39:49.560 --> 00:39:51.040]   that's going on.
[00:39:51.040 --> 00:39:55.880]   And yes, we'll use the ring of power wisely.
[00:39:55.880 --> 00:39:57.880]   That's a great analogy.
[00:39:57.880 --> 00:39:58.880]   And it's bad for the kid, right?
[00:39:58.880 --> 00:40:02.120]   You know, even though you keep them safe for that way.
[00:40:02.120 --> 00:40:03.120]   100%
[00:40:03.120 --> 00:40:07.680]   Even if a current administration did use it wisely, there, you know, as we've said, you
[00:40:07.680 --> 00:40:11.920]   know, in the past, you know, about tech companies, about companies like Apple, you know, even
[00:40:11.920 --> 00:40:16.800]   if they're doing the right thing with privacy today, there's no guarantee that, you know,
[00:40:16.800 --> 00:40:22.400]   five years from now that, you know, that you're going to have people in power that, you know,
[00:40:22.400 --> 00:40:26.600]   once you have that ability, that they will use it wisely.
[00:40:26.600 --> 00:40:28.960]   You know, you can't create that.
[00:40:28.960 --> 00:40:33.400]   You can't create that environment in the first place because otherwise someone will eventually
[00:40:33.400 --> 00:40:34.400]   abuse it.
[00:40:34.400 --> 00:40:35.400]   They do.
[00:40:35.400 --> 00:40:36.400]   We're so short sighted.
[00:40:36.400 --> 00:40:38.800]   Like, we really only think about our here and now.
[00:40:38.800 --> 00:40:43.880]   Like, if people really understood the cost that you would pay later, that, you know, even
[00:40:43.880 --> 00:40:48.240]   though your government may be a really honorable government, maybe these same rules could be
[00:40:48.240 --> 00:40:53.920]   used for ill by another government that may not be as honorable or have as much integrity.
[00:40:53.920 --> 00:40:55.880]   And we often sell ourselves off.
[00:40:55.880 --> 00:40:58.920]   Like we sell for short term game, we sell off our future.
[00:40:58.920 --> 00:41:03.440]   Like no one would be smoking if, you know, they say that you lose seven seconds of your
[00:41:03.440 --> 00:41:04.440]   life.
[00:41:04.440 --> 00:41:07.880]   If we all froze for seven seconds every time you took a puff of the cigarette, no one
[00:41:07.880 --> 00:41:08.880]   would be smoking.
[00:41:08.880 --> 00:41:12.120]   But since you pay that off later, we think, eh, doesn't really matter.
[00:41:12.120 --> 00:41:14.720]   Aren't we as humans masters of denial?
[00:41:14.720 --> 00:41:15.720]   Oh, yes.
[00:41:15.720 --> 00:41:18.080]   We are own best liars.
[00:41:18.080 --> 00:41:22.520]   So, again, it's a double edged sword.
[00:41:22.520 --> 00:41:28.960]   And you know, I could totally understand how the citizens of China or Singapore or Dubai
[00:41:28.960 --> 00:41:35.200]   say, well, we like having an orderly, we don't like graffiti and homelessness and crime.
[00:41:35.200 --> 00:41:36.880]   We like having an orderly society.
[00:41:36.880 --> 00:41:40.760]   And if we have to give up a little privacy to get that, that doesn't seem like too high
[00:41:40.760 --> 00:41:41.760]   a price to pay.
[00:41:41.760 --> 00:41:47.640]   But then we end up in a black mirror kind of state, right?
[00:41:47.640 --> 00:41:50.280]   Like I've seen mine or I don't want to live that way.
[00:41:50.280 --> 00:41:51.280]   Yeah.
[00:41:51.280 --> 00:41:52.280]   I don't know.
[00:41:52.280 --> 00:41:59.000]   Again, this is that technology has brought into relief so many issues like this where
[00:41:59.000 --> 00:42:03.720]   it's difficult to know exactly what's the right thing to do.
[00:42:03.720 --> 00:42:07.200]   You know, and because of these capabilities, we couldn't have these capabilities.
[00:42:07.200 --> 00:42:12.840]   If we didn't have vast databases, huge computational power, we wouldn't be able to use this information.
[00:42:12.840 --> 00:42:18.120]   You can't have total information awareness without massive technology, modern technology.
[00:42:18.120 --> 00:42:25.600]   I just learned a great new acronym, NOBUS, N-O-B-U-S.
[00:42:25.600 --> 00:42:28.000]   And it's a doctrine at the NSA.
[00:42:28.000 --> 00:42:30.080]   I didn't know about it.
[00:42:30.080 --> 00:42:31.800]   Nobody but us can use it.
[00:42:31.800 --> 00:42:35.920]   And Michael Hayden, who was a former director of the NSA, apparently was talking about it.
[00:42:35.920 --> 00:42:42.560]   The notion that there are exploits that would take, he used the analogy, four acres of supercomputer
[00:42:42.560 --> 00:42:46.680]   power to take advantage of.
[00:42:46.680 --> 00:42:50.600]   So we don't have to publicize those exploits or tell the companies about them or get them
[00:42:50.600 --> 00:42:56.640]   fixed because NOBUS, nobody but us can take advantage of them.
[00:42:56.640 --> 00:42:57.640]   Yet.
[00:42:57.640 --> 00:42:58.640]   Yet.
[00:42:58.640 --> 00:42:59.640]   Yet.
[00:42:59.640 --> 00:43:10.880]   The NSA did recently release kind of a shocking release of information about a Windows exploit
[00:43:10.880 --> 00:43:18.960]   that they at least had the good courtesy to wait until Microsoft had fixed it.
[00:43:18.960 --> 00:43:23.800]   It was called Eternal Blue.
[00:43:23.800 --> 00:43:34.720]   It was a flaw in the Windows Crypto API, crypto32.dll that validates elliptical curve cryptography.
[00:43:34.720 --> 00:43:40.360]   And the NSA actually did something kind of almost unheard of this past week.
[00:43:40.360 --> 00:43:42.640]   They had discovered this.
[00:43:42.640 --> 00:43:44.360]   They did get Microsoft to fix it.
[00:43:44.360 --> 00:43:50.640]   Actually, before they did that, they told the military stop using Windows for crypto.
[00:43:50.640 --> 00:43:55.080]   Here's the threat to you and me because of this flaw, it's possible to spoof a certificate
[00:43:55.080 --> 00:43:56.680]   on Microsoft Windows.
[00:43:56.680 --> 00:44:01.800]   Apparently, Windows 10, Windows Server 2016 and Windows Server 2019 were vulnerable, were
[00:44:01.800 --> 00:44:02.800]   vulnerable.
[00:44:02.800 --> 00:44:03.800]   They've been patched.
[00:44:03.800 --> 00:44:06.280]   They were patched last Tuesday.
[00:44:06.280 --> 00:44:12.240]   If you spoof those crypto certs, you could, for instance, offer somebody a file that looks
[00:44:12.240 --> 00:44:19.600]   like a Microsoft office and is signed by a Microsoft certificate, but instead is malware.
[00:44:19.600 --> 00:44:28.000]   So it also impacts HTTPS, signed files and emails, signed executable code, kind of a
[00:44:28.000 --> 00:44:29.760]   serious flaw.
[00:44:29.760 --> 00:44:33.040]   This was not a no bus.
[00:44:33.040 --> 00:44:34.680]   The NSA did alert Microsoft.
[00:44:34.680 --> 00:44:36.040]   It has been fixed.
[00:44:36.040 --> 00:44:43.480]   Nevertheless, there are other exploits that the NSA keeps to itself.
[00:44:43.480 --> 00:44:45.680]   I love it.
[00:44:45.680 --> 00:44:46.680]   No bus.
[00:44:46.680 --> 00:44:48.520]   Nobody but us.
[00:44:48.520 --> 00:44:53.460]   By the way, if you're running Windows 10, you might want to make sure that you got Patch
[00:44:53.460 --> 00:44:54.460]   Tuesday's patch.
[00:44:54.460 --> 00:45:02.120]   As long as we're talking about flaws, this is when Steve was also talking about on Tuesday
[00:45:02.120 --> 00:45:08.840]   that affects virtually all cable modems and can't be patched by you.
[00:45:08.840 --> 00:45:09.840]   Can't be fixed by you.
[00:45:09.840 --> 00:45:17.520]   Patrick, did you read about this cable haunt?
[00:45:17.520 --> 00:45:21.920]   It's a little haunt.com if you're curious.
[00:45:21.920 --> 00:45:23.680]   My modem is impacted.
[00:45:23.680 --> 00:45:26.000]   Almost all the modems in the world are impacted.
[00:45:26.000 --> 00:45:34.240]   Any modem that has a Broadcom chip in it, and it's not an unusual flaw.
[00:45:34.240 --> 00:45:41.080]   Very often, companies like Broadcom and Intel will write example code for how to take advantage
[00:45:41.080 --> 00:45:43.800]   of certain features in their hardware.
[00:45:43.800 --> 00:45:49.040]   It is not at all unusual for this example code to then be taken up wholesale by companies,
[00:45:49.040 --> 00:45:53.720]   put into their modems without any vetting, without any error checking.
[00:45:53.720 --> 00:45:54.720]   It was Broadcom.
[00:45:54.720 --> 00:46:00.760]   Of course, never intended it to be used, but it was widely used.
[00:46:00.760 --> 00:46:05.480]   It's like a lot of cheap web cameras, not the inexpensive Internet of Things stuff where
[00:46:05.480 --> 00:46:08.120]   they slap a little rabbit on the...
[00:46:08.120 --> 00:46:09.120]   Thanks, Qualcomm.
[00:46:09.120 --> 00:46:12.040]   I'll just use that.
[00:46:12.040 --> 00:46:16.560]   Google haunt is a critical vulnerability found in cable modem manufacturers.
[00:46:16.560 --> 00:46:18.040]   There are 200...
[00:46:18.040 --> 00:46:24.240]   The researchers found 200 million cable modems in Europe alone that are vulnerable, virtually
[00:46:24.240 --> 00:46:25.240]   all of them.
[00:46:25.240 --> 00:46:28.120]   Both cable modems I use are vulnerable.
[00:46:28.120 --> 00:46:32.280]   My Motorola, ARIS, and my Netgear CM1000.
[00:46:32.280 --> 00:46:35.480]   It's because many of these modems have spectrum analyzers.
[00:46:35.480 --> 00:46:39.080]   You go to the modem's IP address, colon 8080.
[00:46:39.080 --> 00:46:44.120]   They're open on port 8080.
[00:46:44.120 --> 00:46:49.200]   With a buffer overflow, you can take control of the modem.
[00:46:49.200 --> 00:46:50.480]   There's a proof of concept.
[00:46:50.480 --> 00:46:52.640]   There's a test script at cable haunt.com.
[00:46:52.640 --> 00:46:58.760]   If kids, if you want to get to work right now and start building that malware, hasn't
[00:46:58.760 --> 00:47:01.920]   been found in the public, but here's the real problem.
[00:47:01.920 --> 00:47:03.560]   Your cable company has to fix it.
[00:47:03.560 --> 00:47:06.040]   You can't.
[00:47:06.040 --> 00:47:09.880]   Unfortunately, in the process of fixing this, even if you bought the cable modem, which
[00:47:09.880 --> 00:47:14.600]   I did, you can't fix it, even though it's my modem.
[00:47:14.600 --> 00:47:16.400]   Even though it's my Android phone.
[00:47:16.400 --> 00:47:20.960]   Even though it's my modem, Comcast is the only one that could flash the firmware.
[00:47:20.960 --> 00:47:24.720]   They don't like to do it because it takes you off the internet for a period of time.
[00:47:24.720 --> 00:47:26.120]   All this is happening.
[00:47:26.120 --> 00:47:29.560]   Well, they also have to patch it, fix it.
[00:47:29.560 --> 00:47:32.200]   They got to do a lot of work.
[00:47:32.200 --> 00:47:33.200]   They're probably going to get a million.
[00:47:33.200 --> 00:47:36.880]   If you're Comcast and you have tens of millions of subscribers, you're probably going to get
[00:47:36.880 --> 00:47:38.360]   a few hundred thousand calls.
[00:47:38.360 --> 00:47:39.480]   My internet's out.
[00:47:39.480 --> 00:47:43.120]   What's going on?
[00:47:43.120 --> 00:47:49.000]   Once control is achieved by attacker, it can be used to change the default DNS server.
[00:47:49.000 --> 00:47:51.520]   Conduct man in the middle attacks remotely.
[00:47:51.520 --> 00:47:53.680]   Hot swap code.
[00:47:53.680 --> 00:47:56.080]   Just the whole firmware you could change.
[00:47:56.080 --> 00:47:57.720]   Upload flash and upgrade firmware silent.
[00:47:57.720 --> 00:48:01.920]   The disable ISP firmware upgrades change every config file and settings.
[00:48:01.920 --> 00:48:08.720]   Set SNMPOID values, change all associated MAC addresses, change serial numbers, and put
[00:48:08.720 --> 00:48:10.360]   you in a botnet.
[00:48:10.360 --> 00:48:12.600]   It is a nasty flaw.
[00:48:12.600 --> 00:48:14.440]   You're almost certainly affected.
[00:48:14.440 --> 00:48:23.360]   If you go to cablehot.com, they have a list of cable modems that are vulnerable.
[00:48:23.360 --> 00:48:24.360]   It's a pretty good list.
[00:48:24.360 --> 00:48:28.760]   Well, they also say they don't really have any examples of it being found in the wild,
[00:48:28.760 --> 00:48:34.760]   but they also point out that anybody who's sophisticated could probably cover their tracks
[00:48:34.760 --> 00:48:38.120]   in the process of using this exploit, which is always really charming.
[00:48:38.120 --> 00:48:39.120]   Exactly.
[00:48:39.120 --> 00:48:41.280]   Now, the only good news is they have to do this.
[00:48:41.280 --> 00:48:43.720]   They have to do it from within your network.
[00:48:43.720 --> 00:48:48.320]   What they do is they have to compromise a system in your internal network, which then
[00:48:48.320 --> 00:48:49.840]   can write to the modem.
[00:48:49.840 --> 00:48:51.360]   They can't do it from the outside world end.
[00:48:51.360 --> 00:48:54.120]   They have to do it from the inside world.
[00:48:54.120 --> 00:48:59.520]   Once again, patch and do the best you can to protect yourself on all your devices.
[00:48:59.520 --> 00:49:05.800]   If you've got an IoT device, good luck.
[00:49:05.800 --> 00:49:08.240]   Since this exploit now, the code is out there.
[00:49:08.240 --> 00:49:10.720]   I don't know what's going to happen.
[00:49:10.720 --> 00:49:14.680]   Just thought I'd mention that.
[00:49:14.680 --> 00:49:18.240]   Let's take a little break so you can absorb this in rough run to fix you.
[00:49:18.240 --> 00:49:19.600]   Steve says, and I tried this.
[00:49:19.600 --> 00:49:21.000]   I couldn't get it to work.
[00:49:21.000 --> 00:49:26.440]   If you can, first of all, check to see you need to know what your router, but your cable
[00:49:26.440 --> 00:49:28.320]   modem's IP address is.
[00:49:28.320 --> 00:49:33.960]   In my case, for my CM1000, it was 192.168.100.1.
[00:49:33.960 --> 00:49:37.480]   If you go to that address colon 8080, your spectrum analyzer pops up.
[00:49:37.480 --> 00:49:40.280]   If that's the case, then you have it.
[00:49:40.280 --> 00:49:42.400]   That means you're vulnerable.
[00:49:42.400 --> 00:49:47.360]   He says you could set up a firewall rule that blocks outbound.
[00:49:47.360 --> 00:49:49.760]   This is what I was having a hard time doing.
[00:49:49.760 --> 00:49:53.840]   On traffic on port 8080, I can't figure out how to do that.
[00:49:53.840 --> 00:49:54.840]   Maybe I don't know.
[00:49:54.840 --> 00:49:57.800]   I can block inbound, but outbound is a little harder.
[00:49:57.800 --> 00:49:58.800]   If you can do that, maybe that's a good idea.
[00:49:58.800 --> 00:50:00.800]   I just got a 404 on mine.
[00:50:00.800 --> 00:50:02.800]   Well, but that may not be your...
[00:50:02.800 --> 00:50:04.000]   This is the problem.
[00:50:04.000 --> 00:50:05.640]   It may not be 192.168.101.
[00:50:05.640 --> 00:50:06.640]   Might be a different port.
[00:50:06.640 --> 00:50:07.640]   It might be a different port at 100.1.
[00:50:07.640 --> 00:50:10.800]   The port's usually 8080, but you have to know what your cable modem is.
[00:50:10.800 --> 00:50:12.200]   Well, mine is 100.1.
[00:50:12.200 --> 00:50:14.880]   So if you go there, you get the cable modem login.
[00:50:14.880 --> 00:50:15.880]   Yeah.
[00:50:15.880 --> 00:50:16.880]   Okay.
[00:50:16.880 --> 00:50:17.880]   So maybe you're all right.
[00:50:17.880 --> 00:50:19.760]   It's 8080 and it gave you a 404.
[00:50:19.760 --> 00:50:20.760]   You looked at it.
[00:50:20.760 --> 00:50:21.760]   Yay.
[00:50:21.760 --> 00:50:24.520]   Or maybe your cable company's already patched it.
[00:50:24.520 --> 00:50:25.520]   I don't know.
[00:50:25.520 --> 00:50:29.200]   It doesn't seem like Comcast would be too quick on anything like that.
[00:50:29.200 --> 00:50:32.280]   I usually take their time.
[00:50:32.280 --> 00:50:34.400]   We have a plan to fix it in 2025.
[00:50:34.400 --> 00:50:37.440]   After they launch a peacock.
[00:50:37.440 --> 00:50:38.440]   Yeah.
[00:50:38.440 --> 00:50:40.800]   We got a launch peacock first.
[00:50:40.800 --> 00:50:41.800]   Let's take a little break.
[00:50:41.800 --> 00:50:44.960]   I'm going to talk about protecting yourself online and then we'll have more.
[00:50:44.960 --> 00:50:47.720]   There's some other fun stuff to talk about too.
[00:50:47.720 --> 00:50:50.680]   Good news, not just bad news.
[00:50:50.680 --> 00:50:53.520]   Amazon wants you to pay with a wave.
[00:50:53.520 --> 00:50:55.680]   What could possibly go wrong?
[00:50:55.680 --> 00:50:57.680]   I showed it.
[00:50:57.680 --> 00:51:02.120]   I brought you by this by the Express VPN.
[00:51:02.120 --> 00:51:05.960]   This is the VPN I use and I recommend.
[00:51:05.960 --> 00:51:08.560]   It is awesome because it's fast.
[00:51:08.560 --> 00:51:12.160]   They have VPN servers all over the world, more than 100 countries.
[00:51:12.160 --> 00:51:15.120]   Plus they use a trusted server technology.
[00:51:15.120 --> 00:51:17.680]   They figured this out and it's been audited by a third party.
[00:51:17.680 --> 00:51:22.360]   That not only do they not do any logging, they couldn't even if they wanted to.
[00:51:22.360 --> 00:51:27.280]   They're trusted server which spins up when you get on their server and open the VPN and
[00:51:27.280 --> 00:51:32.560]   then spins down afterwards is sandbox so that it can't write to disk in any way.
[00:51:32.560 --> 00:51:35.720]   Which means there's no way they can keep track of anything you're doing.
[00:51:35.720 --> 00:51:37.800]   Your privacy is 100% protected.
[00:51:37.800 --> 00:51:39.760]   Be more secure.
[00:51:39.760 --> 00:51:44.360]   Protect yourself against bad guys that they open Wi-Fi access point from snoops that your
[00:51:44.360 --> 00:51:51.280]   internet service provider and besides protecting your privacy and security online, you can
[00:51:51.280 --> 00:51:56.360]   also use it to take your TV watching to the next level.
[00:51:56.360 --> 00:52:00.120]   Because Express VPN has servers all over the world.
[00:52:00.120 --> 00:52:06.160]   You can go to Netflix, go to Express VPN, turn on your VPN, pick where you want.
[00:52:06.160 --> 00:52:09.560]   Let's say you want to watch Star Trek.
[00:52:09.560 --> 00:52:11.560]   You can watch it on Netflix in the UK.
[00:52:11.560 --> 00:52:13.160]   So all you got to do is tell Express VPN.
[00:52:13.160 --> 00:52:19.080]   I'm in London right now and boom, you're watching Doctor Who in Star Trek on UK Netflix.
[00:52:19.080 --> 00:52:23.280]   Go to Japan, watch anime on Japanese Netflix.
[00:52:23.280 --> 00:52:26.240]   Express VPN hides your IP address.
[00:52:26.240 --> 00:52:29.840]   Let's you control where you want sites to think you're coming from.
[00:52:29.840 --> 00:52:35.040]   It's so fast they just do such a good job that you can stream HD no problem at all while
[00:52:35.040 --> 00:52:36.040]   you're on the VPN.
[00:52:36.040 --> 00:52:39.160]   And I know that because when I first tried this, I want to say this is working.
[00:52:39.160 --> 00:52:40.640]   I was watching Netflix in Japan.
[00:52:40.640 --> 00:52:43.520]   I forgot to turn it off for three days.
[00:52:43.520 --> 00:52:48.600]   And even though I was running through VPN on my iPad for the longest time, that's how fast
[00:52:48.600 --> 00:52:49.600]   it is.
[00:52:49.600 --> 00:52:52.080]   I didn't even notice I was using no buffering, no lag.
[00:52:52.080 --> 00:52:53.400]   It works everywhere.
[00:52:53.400 --> 00:52:59.360]   Mac, Windows, Linux, iPhone, Android, even on media consoles on smart TVs.
[00:52:59.360 --> 00:53:02.520]   You can watch what you want on the go or on the big screen wherever you are.
[00:53:02.520 --> 00:53:04.320]   I love Express VPN.
[00:53:04.320 --> 00:53:06.240]   I love you guys.
[00:53:06.240 --> 00:53:08.120]   Right now ExpressVPN.com/twit.
[00:53:08.120 --> 00:53:12.000]   You can get an extra three months for free when you sign up for a year.
[00:53:12.000 --> 00:53:14.000]   ExpressVPN.com/twit.
[00:53:14.000 --> 00:53:19.920]   About seven bucks a month when you get that extra three months.
[00:53:19.920 --> 00:53:22.800]   That's a very good deal for the best VPN in the market.
[00:53:22.800 --> 00:53:24.640]   ExpressVPN.com/twit.
[00:53:24.640 --> 00:53:26.040]   Thanks for supporting us.
[00:53:26.040 --> 00:53:27.040]   ExpressVPN.
[00:53:27.040 --> 00:53:29.040]   Apple's doing some good things.
[00:53:29.040 --> 00:53:36.680]   I just read a story in DigiDay, which caters to the advertising community.
[00:53:36.680 --> 00:53:42.440]   Apple's new privacy features have further rattled the location-based ad market.
[00:53:42.440 --> 00:53:43.920]   This is one for the good guys.
[00:53:43.920 --> 00:53:45.760]   You know that pop up you get an iOS 13.
[00:53:45.760 --> 00:53:52.720]   You get it on Android now too, when it says, "Hey, Google has just checked your location
[00:53:52.720 --> 00:53:55.560]   four times in the last 24 hours."
[00:53:55.560 --> 00:53:57.000]   You know that pop up?
[00:53:57.000 --> 00:54:03.360]   It says, "Do you want to allow that or maybe only when the app's open or maybe not at all?"
[00:54:03.360 --> 00:54:08.280]   So that's been going on since iOS 13 was released in September.
[00:54:08.280 --> 00:54:18.080]   AdTech sources are saying it has been a big hit to the amount of data they can gather.
[00:54:18.080 --> 00:54:23.760]   DigiDay, "Benoit Grouchko," who has a great name, by the way, "Benoit Grouchko."
[00:54:23.760 --> 00:54:26.480]   He runs the AdTech Business Team-O.
[00:54:26.480 --> 00:54:29.680]   They do software for apps to collect that location data.
[00:54:29.680 --> 00:54:33.080]   He says, "Three years ago, opt-in rates, almost 100 percent.
[00:54:33.080 --> 00:54:36.120]   Almost everybody left location on.
[00:54:36.120 --> 00:54:42.440]   Ever since iOS 13, the opt-in rate now is often below 50 percent."
[00:54:42.440 --> 00:54:46.960]   People when they're given the choice, saying, "You know what?
[00:54:46.960 --> 00:54:47.960]   No."
[00:54:47.960 --> 00:54:53.480]   Seven in 10 iOS 13 location signals analyzed by location sciences.
[00:54:53.480 --> 00:54:59.160]   In the six weeks after iOS 13 came out, 80 percent of those users stopped all background
[00:54:59.160 --> 00:55:02.160]   tracking across their devices.
[00:55:02.160 --> 00:55:12.080]   So if you're in the business of selling based on location, PublicC agency Starcom said,
[00:55:12.080 --> 00:55:16.960]   "This impacts the ability to tie users that research online and purchase in store or driving
[00:55:16.960 --> 00:55:19.040]   and measure foot-fulk for clients."
[00:55:19.040 --> 00:55:21.240]   This is some Google offers, by the way.
[00:55:21.240 --> 00:55:26.320]   Google monitors credit card purchases and then says to an advertiser, "Hey, this guy
[00:55:26.320 --> 00:55:31.160]   saw your ad on Tuesday and went to the store and bought your product on Wednesday.
[00:55:31.160 --> 00:55:33.360]   Your ad's working.
[00:55:33.360 --> 00:55:36.000]   Not as easy.
[00:55:36.000 --> 00:55:38.920]   Not as easy.
[00:55:38.920 --> 00:55:40.240]   Time to celebrate Georgia.
[00:55:40.240 --> 00:55:43.040]   You're an iPhone user.
[00:55:43.040 --> 00:55:44.040]   I am.
[00:55:44.040 --> 00:55:45.040]   I love it.
[00:55:45.040 --> 00:55:46.040]   I love it.
[00:55:46.040 --> 00:55:47.040]   I love the ability.
[00:55:47.040 --> 00:55:48.040]   I love the ability.
[00:55:48.040 --> 00:55:49.040]   I'll always opt out.
[00:55:49.040 --> 00:55:52.760]   I'm actually shocked that there's 50 percent of people that say that they're still allowed.
[00:55:52.760 --> 00:55:53.760]   What are you doing?
[00:55:53.760 --> 00:55:54.760]   Stop it.
[00:55:54.760 --> 00:55:55.760]   It's creepy.
[00:55:55.760 --> 00:56:00.040]   Would you want someone walking around tracking you if you could see them snooping into your
[00:56:00.040 --> 00:56:02.520]   bathroom, looking at what you're doing, what you're surfing around?
[00:56:02.520 --> 00:56:03.720]   You'd say, "Stop doing that.
[00:56:03.720 --> 00:56:05.120]   You'd close your blinds."
[00:56:05.120 --> 00:56:06.120]   There's a few of us.
[00:56:06.120 --> 00:56:07.680]   Maybe you'd be like, "Yeah, into that."
[00:56:07.680 --> 00:56:10.440]   Most people would say, "No, stop following me around."
[00:56:10.440 --> 00:56:11.440]   Stop it.
[00:56:11.440 --> 00:56:13.800]   Actually, you know what I'm weird, Georgia?
[00:56:13.800 --> 00:56:14.800]   Are you?
[00:56:14.800 --> 00:56:16.000]   I always say, "I always allow."
[00:56:16.000 --> 00:56:22.040]   In fact, it pisses me off because Apple doesn't usually give "always allow" as an option.
[00:56:22.040 --> 00:56:24.320]   There's really, most of the time I see two options.
[00:56:24.320 --> 00:56:27.200]   Allow when app is in use, don't allow.
[00:56:27.200 --> 00:56:31.080]   You have to go into the settings to turn on "always allow" and I do because I want them
[00:56:31.080 --> 00:56:32.080]   to know.
[00:56:32.080 --> 00:56:34.680]   What do you want them to know?
[00:56:34.680 --> 00:56:35.680]   Everything.
[00:56:35.680 --> 00:56:36.680]   Everything.
[00:56:36.680 --> 00:56:37.680]   I like it.
[00:56:37.680 --> 00:56:38.680]   Patrick knows.
[00:56:38.680 --> 00:56:39.680]   I feel like they care.
[00:56:39.680 --> 00:56:43.160]   Do you think that you get better targeted ads?
[00:56:43.160 --> 00:56:44.160]   Yes.
[00:56:44.160 --> 00:56:45.760]   What's wrong with that?
[00:56:45.760 --> 00:56:47.680]   I think I get better ads.
[00:56:47.680 --> 00:56:51.080]   I walk by the Levi store and it says, "Hey, here's a coupon.
[00:56:51.080 --> 00:56:54.640]   You can go in my Google Maps.
[00:56:54.640 --> 00:56:57.040]   I love that feature where I can look at my timeline."
[00:56:57.040 --> 00:57:01.160]   If you all have places I've been, why wouldn't I want that?
[00:57:01.160 --> 00:57:02.160]   What do they...
[00:57:02.160 --> 00:57:04.480]   Do you think they're following me around?
[00:57:04.480 --> 00:57:05.480]   Is it like somebody...
[00:57:05.480 --> 00:57:07.120]   It is like following you around.
[00:57:07.120 --> 00:57:08.120]   It's not.
[00:57:08.120 --> 00:57:12.040]   The best part of this conversation is like two minutes ago.
[00:57:12.040 --> 00:57:16.480]   It was like, "I don't want law enforcement to be able to track us everywhere."
[00:57:16.480 --> 00:57:20.960]   The reality is through third-party marketing tools, if they can identify your phone, which
[00:57:20.960 --> 00:57:26.680]   is not that hard to do, the level of mapping and tracking they can do now without using
[00:57:26.680 --> 00:57:31.080]   any official tools is terrifying.
[00:57:31.080 --> 00:57:32.080]   You're saying...
[00:57:32.080 --> 00:57:33.920]   See, I don't worry about Google.
[00:57:33.920 --> 00:57:36.640]   You're saying, but you should realize that Google might be given that information to
[00:57:36.640 --> 00:57:38.480]   the cops.
[00:57:38.480 --> 00:57:43.840]   It's actually turned out a lot of apps sell the tracking information to third-party services,
[00:57:43.840 --> 00:57:49.200]   which are then people can walk up with a credit card number and get information that you would
[00:57:49.200 --> 00:57:55.760]   freak out if it was made available directly from Google or from Apple.
[00:57:55.760 --> 00:58:03.000]   Or, for example, the car's track is utterly terrifying at this point.
[00:58:03.000 --> 00:58:07.160]   I may never buy a new car again based on the amount of information that's being pulled
[00:58:07.160 --> 00:58:08.160]   out of the...
[00:58:08.160 --> 00:58:09.160]   Oh, man.
[00:58:09.160 --> 00:58:10.160]   I drove a Tesla.
[00:58:10.160 --> 00:58:12.680]   I would call Tesla and say, "You know, I've got this.
[00:58:12.680 --> 00:58:13.680]   This happened.
[00:58:13.680 --> 00:58:17.440]   I had it in forward and your car went backward."
[00:58:17.440 --> 00:58:18.520]   They say, "Well, no, wait a minute.
[00:58:18.520 --> 00:58:20.320]   What time did that happen?"
[00:58:20.320 --> 00:58:21.800]   This afternoon, and look, "No, no.
[00:58:21.800 --> 00:58:22.800]   You were going...
[00:58:22.800 --> 00:58:23.880]   You had it in forward.
[00:58:23.880 --> 00:58:25.080]   I could see the log."
[00:58:25.080 --> 00:58:28.600]   The sensor registered it as forward, not...
[00:58:28.600 --> 00:58:31.200]   That's what I should have said.
[00:58:31.200 --> 00:58:32.600]   It's your sensors fault.
[00:58:32.600 --> 00:58:37.120]   Patrick, would it depend on the amount of torque, though?
[00:58:37.120 --> 00:58:44.520]   Well, if it accidentally goes into reverse and you bump into it with your...
[00:58:44.520 --> 00:58:47.080]   I'm going to pick on Prius because it's here.
[00:58:47.080 --> 00:58:51.080]   I don't mind if Elon knows, and I don't mind if Google knows.
[00:58:51.080 --> 00:58:56.760]   Google's not handing my information over to law enforcement in unprecedented geofence.
[00:58:56.760 --> 00:58:57.760]   But it's almost...
[00:58:57.760 --> 00:59:00.520]   But it's almost other apps.
[00:59:00.520 --> 00:59:01.520]   They're not...
[00:59:01.520 --> 00:59:02.520]   What?
[00:59:02.520 --> 00:59:09.400]   You know, I've got Android 10 on Pixel 3 now.
[00:59:09.400 --> 00:59:13.560]   They added the same thing in there so that now in all the apps you can go in and set your
[00:59:13.560 --> 00:59:20.080]   location preferences by app to always allow when in use or never allow.
[00:59:20.080 --> 00:59:23.560]   I was shocked after upgrading to 10.
[00:59:23.560 --> 00:59:28.840]   Some of these apps that were coming up and asking for location permission that...
[00:59:28.840 --> 00:59:32.960]   I mean, games and stuff that had no business knowing where I was.
[00:59:32.960 --> 00:59:37.040]   I don't mind Google Maps having my location.
[00:59:37.040 --> 00:59:40.440]   That's why I used to work.
[00:59:40.440 --> 00:59:45.760]   Things like Lyft or Uber, clearly they need to know where I am when I'm using them.
[00:59:45.760 --> 00:59:50.240]   But there's no reason for a ride-hailing app to know where I am when I'm not using the
[00:59:50.240 --> 00:59:51.240]   app.
[00:59:51.240 --> 00:59:54.440]   Any time that I'm not using the app, it's off.
[00:59:54.440 --> 00:59:59.200]   I think the only app I have set to always allow is Google Maps because, like, you Leo,
[00:59:59.200 --> 01:00:01.200]   I do like the timeline.
[01:00:01.200 --> 01:00:02.200]   I find it useful.
[01:00:02.200 --> 01:00:06.600]   Plus, I want to help law enforcement when there's a robbery.
[01:00:06.600 --> 01:00:09.320]   They wanted everybody who was in 500 feet of the robbery.
[01:00:09.320 --> 01:00:10.320]   But it's...
[01:00:10.320 --> 01:00:11.320]   But it's not really.
[01:00:11.320 --> 01:00:13.320]   The gold jacket and the gold heart hat.
[01:00:13.320 --> 01:00:14.320]   Is that the location?
[01:00:14.320 --> 01:00:15.320]   Look at your cameras.
[01:00:15.320 --> 01:00:16.320]   You can't miss me.
[01:00:16.320 --> 01:00:21.000]   I think it's the best transparency, though.
[01:00:21.000 --> 01:00:25.240]   It's that you don't really know what they're going to be doing with it and who they're going
[01:00:25.240 --> 01:00:29.000]   to be selling it to and what they're going to be using it for.
[01:00:29.000 --> 01:00:33.160]   There are no regulations to make sure that they're really being honest and it's legible.
[01:00:33.160 --> 01:00:34.920]   No one reads the privacy.
[01:00:34.920 --> 01:00:37.920]   Like, I have every once in a while, it's terrifying and that I always don't...
[01:00:37.920 --> 01:00:41.320]   If I really want the app, I won't read it because then I will say no.
[01:00:41.320 --> 01:00:42.320]   But no one reads it.
[01:00:42.320 --> 01:00:43.320]   It's illegible.
[01:00:43.320 --> 01:00:45.480]   So, it's a big problem.
[01:00:45.480 --> 01:00:46.640]   Actually, I'll be honest.
[01:00:46.640 --> 01:00:52.160]   I almost always select only when using app because that seems reasonable to me.
[01:00:52.160 --> 01:00:55.480]   And if it's an app that shouldn't have location information, if it's Fortnite or something,
[01:00:55.480 --> 01:00:57.240]   then they say no.
[01:00:57.240 --> 01:01:01.960]   Remember the flashlight app that some nefarious company bought and then it was basically...
[01:01:01.960 --> 01:01:05.880]   It went from being like, "You can turn on the light for your camera when you're not actually
[01:01:05.880 --> 01:01:07.320]   using your camera."
[01:01:07.320 --> 01:01:10.160]   And then they did an update and it was looking for information.
[01:01:10.160 --> 01:01:15.320]   It was basically accessing all possible information on your phone, your photos, your contact information,
[01:01:15.320 --> 01:01:16.320]   everything.
[01:01:16.320 --> 01:01:21.960]   It was kind of fascinating to watch because the millions of downloads...
[01:01:21.960 --> 01:01:24.680]   This was before they integrated this stuff into the operating system.
[01:01:24.680 --> 01:01:28.240]   People kept downloading it and installing it and presumably saying, "Okay."
[01:01:28.240 --> 01:01:29.760]   That's how badly they wanted a flashlight app.
[01:01:29.760 --> 01:01:34.000]   But there's an article that New York Times did back in the middle of December, 12 million
[01:01:34.000 --> 01:01:43.680]   phones, one data set at zero privacy, where somebody turned over a data set which was
[01:01:43.680 --> 01:01:49.600]   50 billion pings from the phones of more than 12 million Americans as they moved through
[01:01:49.600 --> 01:01:55.440]   several major cities, including Washington, New York, San Francisco and Los Angeles.
[01:01:55.440 --> 01:02:03.960]   And basically because apps that would track you and then report the information, it also
[01:02:03.960 --> 01:02:10.960]   meant that these unregulated third party app data collection centers could allow any way
[01:02:10.960 --> 01:02:16.720]   with that information to track the location of people who probably shouldn't be tracked
[01:02:16.720 --> 01:02:24.480]   or don't want to be tracked, whether they are celebrities or exes or abuse.
[01:02:24.480 --> 01:02:32.400]   It's kind of amazing how much information is out there and just it's...
[01:02:32.400 --> 01:02:36.520]   The William Gibson line, it's my favorite, the street finds its own uses for things.
[01:02:36.520 --> 01:02:39.840]   The street's going to find its own use for this information and it might be creepy as
[01:02:39.840 --> 01:02:40.840]   hell.
[01:02:40.840 --> 01:02:43.680]   That's actually a really important point.
[01:02:43.680 --> 01:02:47.960]   Is that you can invent a technology and have an idea about how it's going to be used.
[01:02:47.960 --> 01:02:50.320]   Law enforcement can have an idea.
[01:02:50.320 --> 01:02:55.400]   But you know, well, with Kiesz Groh will only use the ring of power if for good, not
[01:02:55.400 --> 01:02:56.400]   evil.
[01:02:56.400 --> 01:03:00.400]   But the street finds its own uses is a really good thing to keep in mind.
[01:03:00.400 --> 01:03:01.800]   I like that, Patrick.
[01:03:01.800 --> 01:03:02.800]   Yeah.
[01:03:02.800 --> 01:03:04.440]   Thank William Gibson.
[01:03:04.440 --> 01:03:05.440]   Yeah.
[01:03:05.440 --> 01:03:08.000]   It just, that's the nature of technology.
[01:03:08.000 --> 01:03:11.480]   It flows like water.
[01:03:11.480 --> 01:03:13.200]   I should have brought this up, Georgia.
[01:03:13.200 --> 01:03:16.360]   I'm curious what you thought, think about this, it was an article in The New York Times
[01:03:16.360 --> 01:03:18.240]   panicking about your kids' phones.
[01:03:18.240 --> 01:03:20.200]   New research says don't.
[01:03:20.200 --> 01:03:25.040]   A growing number of academics are challenging assumptions about the negative effects of
[01:03:25.040 --> 01:03:27.720]   social media and smartphone on children.
[01:03:27.720 --> 01:03:30.080]   See that kid's even from Canada.
[01:03:30.080 --> 01:03:34.040]   Actually, he's nice from Newport Beach.
[01:03:34.040 --> 01:03:37.440]   But this is research that was published on Friday.
[01:03:37.440 --> 01:03:41.840]   Forty studies, it was one of those survey of surveys to psychology professors, looked
[01:03:41.840 --> 01:03:47.760]   at the studies, links between social media and depression and anxiety among adolescents.
[01:03:47.760 --> 01:03:54.680]   They say based on our meta-study, that's a small and inconsistent link.
[01:03:54.680 --> 01:03:59.200]   There doesn't seem to be a strong evidence.
[01:03:59.200 --> 01:04:03.520]   They didn't really take a look at a lot of different variables though, just from in my
[01:04:03.520 --> 01:04:12.080]   office and I see probably 20 families a week, every single week, and the amount of kids
[01:04:12.080 --> 01:04:16.120]   that are negatively affected by social media is vast.
[01:04:16.120 --> 01:04:21.600]   Again, it's not a big data study, but this is all I see and this is kids that are talking
[01:04:21.600 --> 01:04:24.800]   to me and they have no reason to lie because I'm not going to be telling their parents
[01:04:24.800 --> 01:04:26.960]   what they say.
[01:04:26.960 --> 01:04:30.600]   There's none of them that say that they wish they were on the phone more or that social
[01:04:30.600 --> 01:04:35.520]   media does good or that how many kids are now bullied on social media or feel like they're
[01:04:35.520 --> 01:04:39.600]   not good enough because of what they see or they're trying to become someone that they
[01:04:39.600 --> 01:04:50.800]   aren't because of that, the amount of cutting anorexia, wanting a plastic surgery for my
[01:04:50.800 --> 01:04:55.840]   actual clients is really strongly linked to the media of which they are consuming.
[01:04:55.840 --> 01:04:58.320]   These are naturally mimics.
[01:04:58.320 --> 01:04:59.400]   They model behavior.
[01:04:59.400 --> 01:05:02.160]   We are programmed to model what we see.
[01:05:02.160 --> 01:05:07.040]   There's a part of our brain that have mirror neurons and that means that they fire with
[01:05:07.040 --> 01:05:10.720]   what we see and then like kids, they don't care what you say.
[01:05:10.720 --> 01:05:14.960]   Like a lot of this advertising, it's all about like say this, they care about what they see
[01:05:14.960 --> 01:05:19.000]   and what they consume and so if you're they care about someone on social media, they want
[01:05:19.000 --> 01:05:22.920]   to become like them and they don't really understand that most of it is filters, it's
[01:05:22.920 --> 01:05:27.960]   expensive, lighting, it's professional makeup artists and having all of these different
[01:05:27.960 --> 01:05:33.840]   things that are at their whim and they believe the lies and then they're feeling of depression
[01:05:33.840 --> 01:05:36.680]   and that they're not good enough and that they should be doing more and their world
[01:05:36.680 --> 01:05:41.320]   becomes about all of this supernatural fluff that really is crap.
[01:05:41.320 --> 01:05:46.000]   You are not who you, what you consume, you're not your title, you're not your car, you drive,
[01:05:46.000 --> 01:05:47.760]   though torque is awesome.
[01:05:47.760 --> 01:05:52.240]   You're not how many VR systems that you have in your house, you really are your personal
[01:05:52.240 --> 01:05:57.440]   characteristics and the levels of care to that of building yourself as your character
[01:05:57.440 --> 01:06:03.240]   instead of what other people will see has been changing and that's been changing really
[01:06:03.240 --> 01:06:08.600]   quickly and rapidly because of the effects of social media.
[01:06:08.600 --> 01:06:15.480]   So I again don't see my world does not reflect to that and so I looked at that article with
[01:06:15.480 --> 01:06:20.000]   a little bit of like, yeah, I'm not so sure about that that wasn't pushed or propelled
[01:06:20.000 --> 01:06:25.840]   by lobbyists like Facebook and I don't want to throw out that this might be fake media
[01:06:25.840 --> 01:06:32.520]   but I'm just consuming out with a grain of salt because there's a whole bunch of this,
[01:06:32.520 --> 01:06:38.320]   again, Facebook and Instagram and everything else wants you to not limit how much your
[01:06:38.320 --> 01:06:41.960]   kids get access to it but I would say limit it.
[01:06:41.960 --> 01:06:46.240]   They do say the authors of these studies say they have not taken any funding from the tech
[01:06:46.240 --> 01:06:50.800]   industry, they say we've been outspoken critics of the industry and issues other than mental
[01:06:50.800 --> 01:06:54.200]   health, privacy and lack of transparency.
[01:06:54.200 --> 01:06:58.400]   Ms. Ogdars added that she was not surprising that people had a hard time accepting her
[01:06:58.400 --> 01:07:02.800]   findings, her own mother questioned her research after one of her grandson stopped talking
[01:07:02.800 --> 01:07:07.120]   to her during the long drive she used to enjoy but children turning out their elders when
[01:07:07.120 --> 01:07:10.080]   they become teenagers is hardly a new trend.
[01:07:10.080 --> 01:07:15.680]   Some said also, yeah, there might be an effect but it's not, don't compare it to other factors
[01:07:15.680 --> 01:07:18.240]   like lack of sleep or diet.
[01:07:18.240 --> 01:07:22.960]   There are things kids can do that really can severely impact them much more dramatically
[01:07:22.960 --> 01:07:24.600]   than the smart.
[01:07:24.600 --> 01:07:31.720]   So if Facebook has some of the brightest minds on the planet working to make the Pavlovian
[01:07:31.720 --> 01:07:37.360]   response to Facebook be as addictive as possible so you spend more time on Facebook so you're
[01:07:37.360 --> 01:07:41.080]   up until 4 a.m. and not sleeping.
[01:07:41.080 --> 01:07:43.000]   That's, you know what I mean?
[01:07:43.000 --> 01:07:48.000]   I woke up at 4 o'clock this morning as I do every night.
[01:07:48.000 --> 01:07:50.480]   I don't know why but that's something about that hour.
[01:07:50.480 --> 01:07:51.840]   It's funny that you should say that.
[01:07:51.840 --> 01:07:52.840]   And you know what I did?
[01:07:52.840 --> 01:07:54.120]   I set up a wiki.
[01:07:54.120 --> 01:07:57.000]   Then I went back to bed.
[01:07:57.000 --> 01:08:00.120]   I don't need Facebook.
[01:08:00.120 --> 01:08:01.520]   I think they have a pill for that.
[01:08:01.520 --> 01:08:02.520]   I don't know.
[01:08:02.520 --> 01:08:03.520]   There's a pill for everything.
[01:08:03.520 --> 01:08:07.680]   Or I am setting up a wiki pill that was being developed by a large made or pharmaceutical
[01:08:07.680 --> 01:08:08.680]   for.
[01:08:08.680 --> 01:08:13.640]   You find yourself waking up and doing unnecessary web creation in the weeks of all hours before
[01:08:13.640 --> 01:08:14.640]   it was an implement.
[01:08:14.640 --> 01:08:15.640]   I woke up and I thought.
[01:08:15.640 --> 01:08:16.840]   But you know what I don't have?
[01:08:16.840 --> 01:08:21.720]   I don't have a wiki.
[01:08:21.720 --> 01:08:28.160]   You might have a problem however.
[01:08:28.160 --> 01:08:30.600]   I even have a domain for it and everything anyway.
[01:08:30.600 --> 01:08:33.560]   Well at least you know.
[01:08:33.560 --> 01:08:34.960]   Use your time efficiently.
[01:08:34.960 --> 01:08:35.960]   Officially.
[01:08:35.960 --> 01:08:38.040]   Someday I'll be glad I have that wiki.
[01:08:38.040 --> 01:08:39.040]   Use some good news.
[01:08:39.040 --> 01:08:43.360]   Actually before we do that I'll give you some good news from Google in just a second.
[01:08:43.360 --> 01:08:48.640]   But first speaking of tracking you we don't track you obviously.
[01:08:48.640 --> 01:08:50.000]   And there's a big move afoot.
[01:08:50.000 --> 01:08:52.640]   I've talked about this so much I don't want to bore you.
[01:08:52.640 --> 01:08:54.680]   But ad tech is coming to podcasting.
[01:08:54.680 --> 01:08:59.760]   There are lots of podcasts that well Spotify for instance has already even announced that
[01:08:59.760 --> 01:09:03.280]   they're going to do more and more exclusive podcasts.
[01:09:03.280 --> 01:09:05.640]   You have to listen on the Spotify app.
[01:09:05.640 --> 01:09:07.480]   Spotify already knows everything they need to know about you.
[01:09:07.480 --> 01:09:11.880]   You've got your credit card number and they plan on monitoring your podcast listening
[01:09:11.880 --> 01:09:13.200]   through that app.
[01:09:13.200 --> 01:09:14.200]   We do not do that.
[01:09:14.200 --> 01:09:16.560]   We will not do that I promise you.
[01:09:16.560 --> 01:09:22.240]   But in its place we do have a voluntary thing we do once a year.
[01:09:22.240 --> 01:09:27.040]   We'd love to ask you to participate in our Twit Annual Audience Survey.
[01:09:27.040 --> 01:09:29.960]   Just takes a few minutes.
[01:09:29.960 --> 01:09:33.880]   I already am getting email from people who are taking it saying but you don't cover my
[01:09:33.880 --> 01:09:35.280]   unusual use case.
[01:09:35.280 --> 01:09:37.280]   Okay that's fine.
[01:09:37.280 --> 01:09:42.040]   It's not possible to design a survey that fits everybody's unusual use case.
[01:09:42.040 --> 01:09:47.120]   The questions we ask on there are questions that we can use both to improve the product
[01:09:47.120 --> 01:09:48.800]   and to help us sell.
[01:09:48.800 --> 01:09:52.680]   Advertisers often want to know for instance how many women listen versus how many men.
[01:09:52.680 --> 01:09:54.720]   So we appreciate this.
[01:09:54.720 --> 01:09:56.120]   It's completely voluntary.
[01:09:56.120 --> 01:09:57.520]   We do not track you.
[01:09:57.520 --> 01:09:59.120]   We will never track you.
[01:09:59.120 --> 01:10:01.040]   That's not how we work here.
[01:10:01.040 --> 01:10:05.360]   But in order to help us sell the show we do ask you once a year to take this survey.
[01:10:05.360 --> 01:10:08.720]   Twit.to that's our URL shortener.
[01:10:08.720 --> 01:10:13.600]   Twit.to/survey20 because it's 2020.
[01:10:13.600 --> 01:10:14.600]   Let us know what you think.
[01:10:14.600 --> 01:10:16.120]   There's no sign up form.
[01:10:16.120 --> 01:10:19.800]   We're not going to use this information about you personally only in aggregate.
[01:10:19.800 --> 01:10:23.880]   It just helps us make Twit better, helps us keep Twit on the air.
[01:10:23.880 --> 01:10:25.480]   And so thank you in advance.
[01:10:25.480 --> 01:10:26.480]   I know many of you do this.
[01:10:26.480 --> 01:10:31.000]   We usually give about 20 or 30,000 people taking the survey and that's enough for us
[01:10:31.000 --> 01:10:34.360]   to use it to make it statistically valuable.
[01:10:34.360 --> 01:10:35.360]   So thank you.
[01:10:35.360 --> 01:10:36.360]   I appreciate you doing that.
[01:10:36.360 --> 01:10:43.680]   Twit.to/survey20 if you wouldn't do that.
[01:10:43.680 --> 01:10:46.920]   Our show today brought to you by Worldwide Technology.
[01:10:46.920 --> 01:10:51.320]   We are I think we're going March 5th I think is the plan to go to St. Louis to visit their
[01:10:51.320 --> 01:10:54.680]   amazing advanced technology center.
[01:10:54.680 --> 01:11:00.600]   Patrick, you I know we worked with Jim Latterback back in the day at the Ziff Davis Labs in Foster
[01:11:00.600 --> 01:11:02.160]   City.
[01:11:02.160 --> 01:11:08.200]   Those days of big magazines having giant testing labs so they could see you know test 300 printers
[01:11:08.200 --> 01:11:10.080]   or 800 network cards.
[01:11:10.080 --> 01:11:11.880]   Those days are long gone.
[01:11:11.880 --> 01:11:14.640]   Do you think is that ZD Labs still exist even Patrick?
[01:11:14.640 --> 01:11:15.640]   Do you know?
[01:11:15.640 --> 01:11:16.640]   I have no idea.
[01:11:16.640 --> 01:11:18.120]   Can't imagine it does.
[01:11:18.120 --> 01:11:19.880]   I mean who owns it?
[01:11:19.880 --> 01:11:24.520]   I I I I I all I can say is what I really miss was one of the great missed opportunities
[01:11:24.520 --> 01:11:28.200]   was when I got a phone call from somebody said do you know anybody who wants the fair
[01:11:28.200 --> 01:11:29.200]   day cage.
[01:11:29.200 --> 01:11:32.960]   Did you buy it?
[01:11:32.960 --> 01:11:38.440]   I it was it was 12 by 12 by 12 or 10 minutes left.
[01:11:38.440 --> 01:11:44.080]   It was a giant it was it was a giant massive incredibly expensive copper fair day cage
[01:11:44.080 --> 01:11:48.800]   and I it would moving it would have cost you know more than I made in a month at that
[01:11:48.800 --> 01:11:49.800]   point much less.
[01:11:49.800 --> 01:11:53.680]   But then if you wake up at four in the morning you can't set up a wiki.
[01:11:53.680 --> 01:11:57.760]   Unless you have ethernet.
[01:11:57.760 --> 01:12:04.160]   Bingo worldwide technology is taking the place of these old you know centers about 10 years
[01:12:04.160 --> 01:12:05.160]   ago.
[01:12:05.160 --> 01:12:09.160]   I think they realize there was going to be a need in enterprise tech for a place to trial
[01:12:09.160 --> 01:12:10.480]   technology to test it out.
[01:12:10.480 --> 01:12:13.600]   They started building the Advanced Technology Center.
[01:12:13.600 --> 01:12:19.480]   It has grown like crazy in the last 10 years and now has more than half a billion dollars
[01:12:19.480 --> 01:12:20.480]   in equipment.
[01:12:20.480 --> 01:12:24.440]   I bet you they have a fair day cage from hundreds of OEMs.
[01:12:24.440 --> 01:12:32.240]   Deep partners ranging from high tech heavyweights like Cisco, VMware, AI disruptors like Nvidia.
[01:12:32.240 --> 01:12:34.840]   Absolutely they've got it all in there.
[01:12:34.840 --> 01:12:40.280]   This is what the engineers at WWT used to spin up proofs of concept to test the system
[01:12:40.280 --> 01:12:45.080]   before they set it up on your premises to pilot programs.
[01:12:45.080 --> 01:12:51.280]   It's a great way for engineers at WWT and their customers to confidently select the best
[01:12:51.280 --> 01:12:52.280]   solution.
[01:12:52.280 --> 01:12:55.840]   But here's the best part about this amazing lab.
[01:12:55.840 --> 01:12:58.040]   You can use it too.
[01:12:58.040 --> 01:13:02.720]   On demand and schedulable labs or workshops like for instance in video's deep learning
[01:13:02.720 --> 01:13:07.440]   workshop available to you 24/7 anywhere in the world.
[01:13:07.440 --> 01:13:09.480]   You don't even have to go to St. Louis to use it.
[01:13:09.480 --> 01:13:10.880]   It's online.
[01:13:10.880 --> 01:13:15.120]   There are hundreds of labs representing the newest advances in architectural solutions
[01:13:15.120 --> 01:13:21.520]   to accelerate customers on artificial intelligence and machine learning and a whole lot more.
[01:13:21.520 --> 01:13:24.240]   You can learn about products before you launch.
[01:13:24.240 --> 01:13:29.520]   This lab is a service they call it is a dedicated lab space within the ATC where you could perform
[01:13:29.520 --> 01:13:35.760]   your own programmatic testing using this amazing technology ecosystem built by WWT.
[01:13:35.760 --> 01:13:42.440]   Customers of WWT stay with WWT for years and years and years because it's the best way
[01:13:42.440 --> 01:13:45.760]   to get help setting up enterprise technology.
[01:13:45.760 --> 01:13:49.760]   This ATC is just one example and these virtual labs is brilliant.
[01:13:49.760 --> 01:13:52.320]   WWT's engineers themselves work in these labs.
[01:13:52.320 --> 01:13:55.360]   They're there everyday beta testing new solutions.
[01:13:55.360 --> 01:14:00.440]   Some of them based on the best greatest and latest in video technologies for AI.
[01:14:00.440 --> 01:14:05.680]   Building reference architectures, custom integrations, help their customers see results faster
[01:14:05.680 --> 01:14:10.000]   to help you know ahead of time if it's going to work with a lot less investment.
[01:14:10.000 --> 01:14:16.880]   This new lab is a service platform encompassing the entire ATC ecosystem is now available
[01:14:16.880 --> 01:14:21.520]   creating a multiplier effective knowledge and speed and agility anytime anywhere around
[01:14:21.520 --> 01:14:24.080]   the world for a WWT customers.
[01:14:24.080 --> 01:14:29.560]   Not just labs to get access to studies, case studies to articles to hands-on labs to other
[01:14:29.560 --> 01:14:31.120]   tools that make the difference.
[01:14:31.120 --> 01:14:35.080]   Today is complicated and fast paced enterprise world.
[01:14:35.080 --> 01:14:39.720]   To learn more about the ATC, to get insights into their newest features, to actually use
[01:14:39.720 --> 01:14:43.160]   it, go to www.com/twit.
[01:14:43.160 --> 01:14:48.640]   Worldwide technology simplifies the complex.
[01:14:48.640 --> 01:14:50.600]   www.com/twit.
[01:14:50.600 --> 01:14:54.600]   WWT delivering business and technology outcomes around the world.
[01:14:54.600 --> 01:14:56.160]   Take advantage of this.
[01:14:56.160 --> 01:14:58.400]   Such a great thing to have.
[01:14:58.400 --> 01:15:04.920]   Google is doing something I think unprecedented and boy, color me cynical because I'm immediately
[01:15:04.920 --> 01:15:08.280]   saying, well, okay, well, what are they planning?
[01:15:08.280 --> 01:15:14.000]   They've said they are going to drop support for tracking cookies for third party cookies
[01:15:14.000 --> 01:15:16.520]   by 2022.
[01:15:16.520 --> 01:15:20.960]   Third party cookies, of course, are the thing that we tell everybody.
[01:15:20.960 --> 01:15:22.160]   Most browsers accept Chrome.
[01:15:22.160 --> 01:15:23.720]   You can turn that off.
[01:15:23.720 --> 01:15:27.320]   That's the basically tracking cookies.
[01:15:27.320 --> 01:15:31.480]   Instead of using those companies have now turned to other solutions like fingerprinting
[01:15:31.480 --> 01:15:34.360]   and all sorts of things.
[01:15:34.360 --> 01:15:41.360]   Google said that they are going to deprecate third party cookies.
[01:15:41.360 --> 01:15:44.160]   They didn't say what they're going to offer instead.
[01:15:44.160 --> 01:15:51.280]   They say third party cookies and cross-site tracking are problems starting next month.
[01:15:51.280 --> 01:15:55.640]   They're going to limit insecure cross-site tracking.
[01:15:55.640 --> 01:15:59.720]   Cookies that don't include the same site label as first party only and require, they're going
[01:15:59.720 --> 01:16:04.440]   to block those and they're going to require cookies labeled for third party used to be
[01:16:04.440 --> 01:16:09.040]   accessed only over secure HTTP.
[01:16:09.040 --> 01:16:12.080]   That makes them more secure and they're going to slowly phase it out over time.
[01:16:12.080 --> 01:16:16.280]   Apple and Firefox both let you block tracking cookies.
[01:16:16.280 --> 01:16:18.880]   So does Brave, our sponsor.
[01:16:18.880 --> 01:16:22.960]   Microsoft says we're going to have some cookie blocking in their new version of Edge that's
[01:16:22.960 --> 01:16:26.120]   based on Chromium.
[01:16:26.120 --> 01:16:30.880]   Is this a good thing or is it just an announcement that Google is going to find something worse?
[01:16:30.880 --> 01:16:33.200]   I'm puzzled by it.
[01:16:33.200 --> 01:16:34.560]   I think it's a good thing.
[01:16:34.560 --> 01:16:38.880]   In fact, privacy advocates like Benadida say I retract my criticism.
[01:16:38.880 --> 01:16:40.040]   Kudos to Google.
[01:16:40.040 --> 01:16:44.200]   This is a big deal.
[01:16:44.200 --> 01:16:45.440]   Any thoughts anybody?
[01:16:45.440 --> 01:16:47.440]   Sam?
[01:16:47.440 --> 01:16:52.680]   It's hard not to be skeptical or cynical about this.
[01:16:52.680 --> 01:16:54.760]   This is their businesses ads.
[01:16:54.760 --> 01:17:03.240]   It seems like if Google is going to eliminate third party cookies, they almost certainly
[01:17:03.240 --> 01:17:06.920]   have something that they think is at least a good or better.
[01:17:06.920 --> 01:17:10.480]   Maybe something that they only they have access to.
[01:17:10.480 --> 01:17:15.080]   That would be the perfect thing to do is to stop something that everybody can use and
[01:17:15.080 --> 01:17:18.320]   only Google can use something even better.
[01:17:18.320 --> 01:17:22.660]   It seems like they've probably figured out some way to do some sort of signals and
[01:17:22.660 --> 01:17:32.720]   intelligence through Chrome and through Android that gives them at least as good information.
[01:17:32.720 --> 01:17:38.000]   Maybe they've just determined that with all the other stuff going on, with cutting back
[01:17:38.000 --> 01:17:45.160]   on location awareness and things like that, maybe they've decided that all this targeting
[01:17:45.160 --> 01:17:49.560]   and micro-targeting just isn't as valuable as it used to be.
[01:17:49.560 --> 01:17:53.660]   They don't say that they're not targeting people anymore.
[01:17:53.660 --> 01:17:55.580]   They're still doing it.
[01:17:55.580 --> 01:17:56.820]   This is only so good.
[01:17:56.820 --> 01:17:58.340]   They're still doing it.
[01:17:58.340 --> 01:18:03.780]   I'm still going to be using DuckDuckGo, which is only so great of an experience at times.
[01:18:03.780 --> 01:18:06.100]   You might try Start Page.
[01:18:06.100 --> 01:18:07.540]   Do you know about Start Page?
[01:18:07.540 --> 01:18:08.540]   No.
[01:18:08.540 --> 01:18:11.700]   I'm a little worried because they got acquired by an advertising company.
[01:18:11.700 --> 01:18:16.860]   The idea, so maybe it's all I've moved, but the idea of Start Page is they use the
[01:18:16.860 --> 01:18:18.460]   Google index.
[01:18:18.460 --> 01:18:22.320]   Google still is the gold standard for search.
[01:18:22.320 --> 01:18:24.580]   What they do is they anonymize it.
[01:18:24.580 --> 01:18:29.240]   Furthermore, when you do a search startpage.com, you'll get the same results you get from Google,
[01:18:29.240 --> 01:18:31.680]   but as if you were in a Cognito mode.
[01:18:31.680 --> 01:18:35.400]   Then there is a button next to it to visit this site anonymously.
[01:18:35.400 --> 01:18:42.960]   Then they route you through an anonymizer, a little bit like a VPN, but not.
[01:18:42.960 --> 01:18:45.680]   Your IP address isn't visible to that site.
[01:18:45.680 --> 01:18:49.740]   It lets you visit a site completely anonymously, which I think is really interesting.
[01:18:49.740 --> 01:18:50.740]   Start Page.
[01:18:50.740 --> 01:18:55.700]   I think that's what Apple tries to do in iOS as well, right?
[01:18:55.700 --> 01:18:59.660]   You know Verizon, this is a related story.
[01:18:59.660 --> 01:19:04.740]   Verizon, whom I wouldn't normally assume is the number one company in privacy, has also
[01:19:04.740 --> 01:19:08.580]   announced they're doing a private search engine.
[01:19:08.580 --> 01:19:09.580]   Yeah, right.
[01:19:09.580 --> 01:19:11.940]   What do they mean by private?
[01:19:11.940 --> 01:19:13.820]   What do you mean by private?
[01:19:13.820 --> 01:19:15.940]   That means that only they will have access to it.
[01:19:15.940 --> 01:19:17.640]   They won't share it with anybody else.
[01:19:17.640 --> 01:19:18.640]   Right.
[01:19:18.640 --> 01:19:19.640]   Right.
[01:19:19.640 --> 01:19:20.640]   They can sell it.
[01:19:20.640 --> 01:19:22.400]   You know, they have the information.
[01:19:22.400 --> 01:19:23.400]   I don't know.
[01:19:23.400 --> 01:19:27.320]   I mean, they already have the information about all the customers.
[01:19:27.320 --> 01:19:28.960]   It launched Tuesday.
[01:19:28.960 --> 01:19:31.840]   They say, "We will not store records of what you search.
[01:19:31.840 --> 01:19:37.360]   We will not create profiles of your usage or share your search data with advertisers."
[01:19:37.360 --> 01:19:41.000]   They also say it gives unbiased, unfiltered results.
[01:19:41.000 --> 01:19:45.880]   Just like Start Page, that means it's not Google because you're logged into Google when
[01:19:45.880 --> 01:19:50.800]   you're using Google, tailors its results to you.
[01:19:50.800 --> 01:19:55.500]   So that's why when I search for me, I get such great results because it's tailoring it
[01:19:55.500 --> 01:19:57.300]   to me, right?
[01:19:57.300 --> 01:20:01.420]   Verizon says everyone seems the same result for the same search terms.
[01:20:01.420 --> 01:20:08.340]   And once searches results can self-destruct after a set period of time.
[01:20:08.340 --> 01:20:10.540]   Why would Verizon do this?
[01:20:10.540 --> 01:20:13.560]   It seems odd to me.
[01:20:13.560 --> 01:20:16.960]   In hopes that then people don't regulate, I don't know.
[01:20:16.960 --> 01:20:19.600]   Give me something I can search for.
[01:20:19.600 --> 01:20:21.600]   By the way, okay.
[01:20:21.600 --> 01:20:22.880]   Immediately I have one problem.
[01:20:22.880 --> 01:20:26.640]   As soon as I click in the search private and encrypted search, I get a list of things
[01:20:26.640 --> 01:20:28.240]   people are searching for right now.
[01:20:28.240 --> 01:20:31.200]   Tells me, is that a completely private?
[01:20:31.200 --> 01:20:32.920]   They're not telling you who's searching for.
[01:20:32.920 --> 01:20:33.920]   Well, okay.
[01:20:33.920 --> 01:20:34.920]   Yeah.
[01:20:34.920 --> 01:20:35.920]   I guess so.
[01:20:35.920 --> 01:20:37.920]   What should I search for that we would know if it was a good search?
[01:20:37.920 --> 01:20:43.740]   Sam, if I searched for Chevy Corvette, would you know what a good search is?
[01:20:43.740 --> 01:20:45.820]   What would you know a good search?
[01:20:45.820 --> 01:20:46.820]   Yeah.
[01:20:46.820 --> 01:20:49.860]   How about when can I buy a mid-engine Corvette?
[01:20:49.860 --> 01:20:50.860]   When?
[01:20:50.860 --> 01:20:56.100]   Oh boy, can I buy a mid-engine Corvette?
[01:20:56.100 --> 01:20:58.600]   Okay.
[01:20:58.600 --> 01:21:04.100]   And then it says you can already buy a mid-engine Corvette for $120,000.
[01:21:04.100 --> 01:21:05.100]   Okay.
[01:21:05.100 --> 01:21:08.360]   And then here's the reveal date, here's the reveal date.
[01:21:08.360 --> 01:21:12.460]   It doesn't have, as you notice, the Google knowledge box on the right.
[01:21:12.460 --> 01:21:13.460]   It's just got search results.
[01:21:13.460 --> 01:21:18.360]   Let me just search because I, it does, by the way, have images, video.
[01:21:18.360 --> 01:21:22.640]   It lets you, it has that anytime button which lets you search by date.
[01:21:22.640 --> 01:21:25.300]   And they have safe, safe search as well.
[01:21:25.300 --> 01:21:28.020]   Let me just search for Leo Laport.
[01:21:28.020 --> 01:21:32.580]   Oh, actually, well, yeah.
[01:21:32.580 --> 01:21:37.340]   And by the way, the auto-complete seems to be as scary as Google.
[01:21:37.340 --> 01:21:38.340]   Okay.
[01:21:38.340 --> 01:21:44.380]   If I typed is, yeah, I mean, and no, there's a knowledge box from Wikipedia and other people.
[01:21:44.380 --> 01:21:48.020]   This looks, look, Patrick, people, when people search for Leo Laport, they also search for
[01:21:48.020 --> 01:21:49.020]   Patrick Norton.
[01:21:49.020 --> 01:21:50.180]   Look at that.
[01:21:50.180 --> 01:21:52.260]   I'm not arguing that.
[01:21:52.260 --> 01:21:53.260]   No.
[01:21:53.260 --> 01:21:54.260]   Yeah.
[01:21:54.260 --> 01:22:00.060]   I just, you know, Verizon, what in 2016 was it 1.3 million?
[01:22:00.060 --> 01:22:02.860]   What did you find to the FCC for super cookies?
[01:22:02.860 --> 01:22:05.700]   Do you think this is a response to that?
[01:22:05.700 --> 01:22:06.700]   I don't know.
[01:22:06.700 --> 01:22:07.700]   Or it's weird.
[01:22:07.700 --> 01:22:09.980]   I mean, they own Yahoo.
[01:22:09.980 --> 01:22:17.900]   It's, I, I, I, I covet unlimited data access to Verizon's network.
[01:22:17.900 --> 01:22:22.060]   I do not covet dealing with Verizon itself.
[01:22:22.060 --> 01:22:27.420]   You know, it's, I'm trying to figure out why they are doing this.
[01:22:27.420 --> 01:22:31.500]   Verizon said one search will generate revenue from the service by matching ads to search
[01:22:31.500 --> 01:22:32.500]   terms.
[01:22:32.500 --> 01:22:36.700]   Remember when you do a Google search, you make money for Google.
[01:22:36.700 --> 01:22:37.700]   Believe it or not.
[01:22:37.700 --> 01:22:42.380]   That's why Google paid Apple $12 billion last year to be the default search in Safari
[01:22:42.380 --> 01:22:44.660]   on an iPhone because it's that valuable.
[01:22:44.660 --> 01:22:51.020]   Mozilla makes money on Firefox because of the Google, Google pays them hundreds of millions
[01:22:51.020 --> 01:22:54.060]   of dollars every year because of referrals.
[01:22:54.060 --> 01:22:59.460]   So when you, so maybe this is Verizon saying, we don't want to give Google that money.
[01:22:59.460 --> 01:23:03.860]   We want to keep it to ourselves.
[01:23:03.860 --> 01:23:05.660]   I don't know.
[01:23:05.660 --> 01:23:07.100]   It's one of those weird ones.
[01:23:07.100 --> 01:23:12.420]   Google's blocking third party cookies for Verizon starting a search engine.
[01:23:12.420 --> 01:23:13.820]   Cats are lying down with dogs.
[01:23:13.820 --> 01:23:14.980]   The world's about to end.
[01:23:14.980 --> 01:23:17.980]   That's all I can say.
[01:23:17.980 --> 01:23:26.260]   By the way, good news, we misreported this story and I stand corrected now by Cameron
[01:23:26.260 --> 01:23:28.340]   Faulkner on the verge.
[01:23:28.340 --> 01:23:34.060]   We had on Tuesday talked on Mac break weekly and I was today about the EU ruling saying
[01:23:34.060 --> 01:23:39.660]   there has to be chargers all have to be uniform for smartphones.
[01:23:39.660 --> 01:23:43.740]   And we took the tax that many did that this meant that the EU was asking Apple to get rid
[01:23:43.740 --> 01:23:45.140]   of the lightning cable.
[01:23:45.140 --> 01:23:49.100]   It wasn't about that end of the plug.
[01:23:49.100 --> 01:23:52.460]   It was actually about the charger brick.
[01:23:52.460 --> 01:23:58.460]   They've been trying to convince tech companies since 2009 for 10 years to adapt a single wall
[01:23:58.460 --> 01:24:06.340]   charger instead of proprietary chargers because there are so many wall chargers, 51,000 metric
[01:24:06.340 --> 01:24:12.420]   tons of e-waste per year because there's so many different proprietary charging methods.
[01:24:12.420 --> 01:24:17.260]   They would like to cut now by the way, it might not matter technologies moving more towards
[01:24:17.260 --> 01:24:19.620]   Type C and power delivery.
[01:24:19.620 --> 01:24:23.940]   And I suspect that all wall chargers there will be a uniform in any way whether they
[01:24:23.940 --> 01:24:29.500]   make this law or not.
[01:24:29.500 --> 01:24:35.900]   Even with USB C though, there's still some outliers like OnePlus which has they have their own
[01:24:35.900 --> 01:24:36.900]   fast charging.
[01:24:36.900 --> 01:24:40.900]   They have their own proprietary fast charging system.
[01:24:40.900 --> 01:24:43.900]   It's like four or five different fast charging systems.
[01:24:43.900 --> 01:24:47.260]   I mean, there's four different competing fast charging systems.
[01:24:47.260 --> 01:24:49.620]   But at least you can get it.
[01:24:49.620 --> 01:24:54.580]   You may take eight times as long but any USB charger if it's high enough wattage should
[01:24:54.580 --> 01:24:57.420]   be able to charge your phone.
[01:24:57.420 --> 01:24:59.500]   What was it saying that article?
[01:24:59.500 --> 01:25:04.060]   When they initiated these efforts, there were 23 distinct charger connectors.
[01:25:04.060 --> 01:25:10.860]   In 2009, this is from European Commission Vice President Maro Cepovic who said in two
[01:25:10.860 --> 01:25:15.420]   years 2009 when they started this, there were 30 proprietary charging methods.
[01:25:15.420 --> 01:25:17.660]   Now they're apparently just three.
[01:25:17.660 --> 01:25:22.780]   However, discarded useless chargers are filling up the e-waste.
[01:25:22.780 --> 01:25:25.220]   So I think they're filling up my house.
[01:25:25.220 --> 01:25:26.220]   Yeah.
[01:25:26.220 --> 01:25:28.140]   I read an article.
[01:25:28.140 --> 01:25:30.100]   Where did I read this?
[01:25:30.100 --> 01:25:35.860]   Every house has a wire drawer or a box of old chargers, right?
[01:25:35.860 --> 01:25:39.300]   That you think, well someday I'll be able to use these.
[01:25:39.300 --> 01:25:41.060]   But you have no idea what they'll go to.
[01:25:41.060 --> 01:25:42.060]   I have that box.
[01:25:42.060 --> 01:25:43.060]   What they use for it.
[01:25:43.060 --> 01:25:45.060]   You must have like a few boxes.
[01:25:45.060 --> 01:25:46.060]   I do.
[01:25:46.060 --> 01:25:48.940]   Yeah, I've got a couple of those sitting about 10 feet away from me right now.
[01:25:48.940 --> 01:25:49.940]   Exactly.
[01:25:49.940 --> 01:25:51.540]   Just in case, you never know.
[01:25:51.540 --> 01:25:58.180]   You put it away and I'm like, is this for my scuba diving, you know, like, you know,
[01:25:58.180 --> 01:25:59.700]   flashlight or this?
[01:25:59.700 --> 01:26:00.700]   I don't remember.
[01:26:00.700 --> 01:26:02.020]   So I just keep them.
[01:26:02.020 --> 01:26:03.260]   This is the Wall Street Journal.
[01:26:03.260 --> 01:26:04.260]   Admit it.
[01:26:04.260 --> 01:26:09.140]   You have a box of cords you'll never, ever use again.
[01:26:09.140 --> 01:26:16.580]   Well, I cleaned out the garage and got rid of, I eat like a E-waste recycled about 150 pounds
[01:26:16.580 --> 01:26:17.580]   of various.
[01:26:17.580 --> 01:26:23.100]   That's when you move through that stress, that's like that stress of like, but what if
[01:26:23.100 --> 01:26:28.860]   I need to charge my scuba diving flashlight and now I'm not going to know like it's,
[01:26:28.860 --> 01:26:30.660]   I threw out the cord that I need for that.
[01:26:30.660 --> 01:26:31.660]   That's stress of me.
[01:26:31.660 --> 01:26:32.660]   That in key.
[01:26:32.660 --> 01:26:33.660]   I agree.
[01:26:33.660 --> 01:26:34.660]   I have a box of keys.
[01:26:34.660 --> 01:26:35.740]   Well, that's what happens.
[01:26:35.740 --> 01:26:40.660]   Like when my wife and I moved three years ago, the kids were out of the house and, you know,
[01:26:40.660 --> 01:26:46.460]   we went through a major purge and we got rid of so much stuff, including a whole bunch
[01:26:46.460 --> 01:26:54.660]   of, you know, I went through all the electronic stuff and, you know, either donated it or took
[01:26:54.660 --> 01:26:59.060]   it to some E-waste place and got rid of a lot of stuff.
[01:26:59.060 --> 01:27:04.540]   I still have too much, but we definitely reduced by a lot.
[01:27:04.540 --> 01:27:07.060]   I love Catherine Binley for this article.
[01:27:07.060 --> 01:27:09.180]   This is just, and look at that box.
[01:27:09.180 --> 01:27:16.260]   That is, that is almost literally my box, except I have four or five of them.
[01:27:16.260 --> 01:27:19.820]   And here at the station, at the studio, we've got bins.
[01:27:19.820 --> 01:27:23.420]   We've got binders full of boxes.
[01:27:23.420 --> 01:27:25.060]   This is her lead.
[01:27:25.060 --> 01:27:26.060]   Good job, Catherine.
[01:27:26.060 --> 01:27:30.540]   There's a box that moved with Sarah Lovelace and her husband from San Diego to Charleston,
[01:27:30.540 --> 01:27:35.620]   from Dallas, from Dallas to Richland, the box never unpacked, went into a closet of
[01:27:35.620 --> 01:27:40.060]   the garage each time, contents 20 to 30 electronics cords.
[01:27:40.060 --> 01:27:44.860]   The box was always just a part of our life, says Ms Lovelace 38.
[01:27:44.860 --> 01:27:46.460]   It wasn't useful to us.
[01:27:46.460 --> 01:27:50.220]   We weren't doing anything with it, except for moving with it.
[01:27:50.220 --> 01:27:58.820]   We, we, there's a great Wall Street Journal pinpoint graphic featuring.
[01:27:58.820 --> 01:28:01.300]   Man, I all my life.
[01:28:01.300 --> 01:28:07.540]   I've wanted to have a picture of me from the Wall Street Journal and this style of graphic.
[01:28:07.540 --> 01:28:09.340]   This cord beat me to it.
[01:28:09.340 --> 01:28:13.340]   Never let me somebody in the audience that knows how to do those and make one for you.
[01:28:13.340 --> 01:28:14.380]   Oh, man, I love that.
[01:28:14.380 --> 01:28:15.380]   Never let me go.
[01:28:15.380 --> 01:28:17.180]   It says, it's the caption.
[01:28:17.180 --> 01:28:24.020]   I just thought, wow, the Wall Street Journal really knows me, but apparently I'm.
[01:28:24.020 --> 01:28:26.020]   You're one of many.
[01:28:26.020 --> 01:28:29.140]   So good for the, you've tried, I think this is part of what they're trying to get rid
[01:28:29.140 --> 01:28:30.140]   of.
[01:28:30.140 --> 01:28:33.660]   Look, you can see that's a micro USB cable right there.
[01:28:33.660 --> 01:28:37.580]   There's a, there's a mini headphone jack right there.
[01:28:37.580 --> 01:28:39.420]   There's a, this is what I have a lot of.
[01:28:39.420 --> 01:28:43.180]   These are the, and part of this is the industry that never labels those bricks.
[01:28:43.180 --> 01:28:44.580]   Yeah, they barrel.
[01:28:44.580 --> 01:28:45.740]   They never labeled the bricks.
[01:28:45.740 --> 01:28:49.140]   So you have no idea what that goes to someday.
[01:28:49.140 --> 01:28:50.140]   I'll have this.
[01:28:50.140 --> 01:28:54.700]   The best bet is to, if you can, if you can read that really tiny fine print that's silk
[01:28:54.700 --> 01:29:00.980]   screened on the, the wall wart with what the wattage is and the voltage, you know, and
[01:29:00.980 --> 01:29:03.180]   then, you know, hopefully you can find some devices.
[01:29:03.180 --> 01:29:05.740]   Yeah, but then you need the polarity, then you need.
[01:29:05.740 --> 01:29:08.340]   They also have a little polarity diagram on there.
[01:29:08.340 --> 01:29:09.340]   Yeah.
[01:29:09.340 --> 01:29:11.220]   And then you need to know this.
[01:29:11.220 --> 01:29:13.740]   This is my life right there.
[01:29:13.740 --> 01:29:20.500]   I have, I have two, two or three old cable modems sitting around somewhere and several
[01:29:20.500 --> 01:29:30.020]   old routers that, you know, have been retired, including an old Lynxis 54G somewhere.
[01:29:30.020 --> 01:29:35.020]   The someday it'll be a collector's item.
[01:29:35.020 --> 01:29:41.260]   I just feel like I know that I'm going to, at some point find, for instance, I, and that's
[01:29:41.260 --> 01:29:43.180]   the other side of this equation.
[01:29:43.180 --> 01:29:47.020]   I have a hard drive that needs a power adapter for the life of me.
[01:29:47.020 --> 01:29:52.060]   It's not in that box.
[01:29:52.060 --> 01:29:53.060]   George is there.
[01:29:53.060 --> 01:29:54.060]   You need a video.
[01:29:54.060 --> 01:29:59.180]   You need an anxiety video and daddy-videos.com for getting rid of the boxes.
[01:29:59.180 --> 01:30:02.380]   You could be a Marie condo of tech.
[01:30:02.380 --> 01:30:06.300]   No, you see, I wouldn't be good at it because that's why I have a box of all of the cords
[01:30:06.300 --> 01:30:11.620]   and I have a box of, of all of the keys that, because you never know when you need to open
[01:30:11.620 --> 01:30:15.100]   that one thing, you have to go to this box and go through whatever, hundred keys that
[01:30:15.100 --> 01:30:20.460]   you keep because you never know that you're going to need to charge that little tiny
[01:30:20.460 --> 01:30:23.300]   QBB8 sphero at some point.
[01:30:23.300 --> 01:30:24.300]   What does it use?
[01:30:24.300 --> 01:30:25.300]   Where did you find it?
[01:30:25.300 --> 01:30:26.780]   Where did you place it?
[01:30:26.780 --> 01:30:30.500]   I would like for it all to be in Universal so I can just keep a few of them and throw
[01:30:30.500 --> 01:30:31.620]   everything else away.
[01:30:31.620 --> 01:30:35.660]   So EU helped me out in a few years.
[01:30:35.660 --> 01:30:39.660]   I'm laughing right now because it reminds me, I had a novice talk, the little sort of
[01:30:39.660 --> 01:30:41.900]   wifi connected space bunny.
[01:30:41.900 --> 01:30:49.380]   And I purging the garage, I got rid of them.
[01:30:49.380 --> 01:30:54.340]   What was so funny is Jim Lauterbeck, my old boss tech TV before I started working full
[01:30:54.340 --> 01:30:59.340]   time on the screen savers, he and I each had a couple of them and there's been, in the
[01:30:59.340 --> 01:31:03.900]   last few months, there's been an open source project to put a drop in board that makes
[01:31:03.900 --> 01:31:08.620]   them sort of like wifi enabled and usable again in the 21st century and I was like, "Oh,
[01:31:08.620 --> 01:31:13.260]   if I'd only held on to it for another three weeks."
[01:31:13.260 --> 01:31:22.540]   I remember you and Robert on whatever was the Rev 3 predecessor of TechThing or TechZilla.
[01:31:22.540 --> 01:31:26.940]   You always had that thing on the table there between you.
[01:31:26.940 --> 01:31:35.300]   It was the weird, that was probably like DLTV, but it was such a bizarre thing and it became
[01:31:35.300 --> 01:31:39.740]   at one point we had one running for months in the background and it was just occasionally
[01:31:39.740 --> 01:31:46.020]   chirped things and its ears wouldn't move and it was simultaneously the dumbest and
[01:31:46.020 --> 01:31:47.500]   the best thing ever.
[01:31:47.500 --> 01:31:53.700]   It was like somebody's crazy ass art project that actually scaled and shipped.
[01:31:53.700 --> 01:31:57.780]   It would do text messages, it would read it, it would do email and it would just sit there
[01:31:57.780 --> 01:32:03.860]   blathering in the background and it was strangely soothing just to have it sitting back there.
[01:32:03.860 --> 01:32:07.140]   And then its ears would go back like an angry cat, you'd always be wondering what was going
[01:32:07.140 --> 01:32:09.220]   to happen next.
[01:32:09.220 --> 01:32:10.220]   I had a weird-
[01:32:10.220 --> 01:32:14.700]   It's what the internet of things should be, not early secured routers and weird thermal
[01:32:14.700 --> 01:32:15.700]   devices.
[01:32:15.700 --> 01:32:20.700]   I had a weird DLTV experience a couple of days ago, believe it or not.
[01:32:20.700 --> 01:32:27.740]   On my Plex, I ripped a bunch of Dick Cavitt show, DVDs.
[01:32:27.740 --> 01:32:32.500]   For some reason the Plex identified them all as DLTV.
[01:32:32.500 --> 01:32:36.540]   I got nothing for it.
[01:32:36.540 --> 01:32:42.460]   And I can't, you know it's fine, I know what they are but it's like what?
[01:32:42.460 --> 01:32:48.060]   But it was even a weird coincidence like oh yeah, I know that guy.
[01:32:48.060 --> 01:32:49.860]   I love Patrick, he's no Dick Cavitt.
[01:32:49.860 --> 01:32:53.660]   But I would have.
[01:32:53.660 --> 01:32:55.340]   It was a very strange thing.
[01:32:55.340 --> 01:32:57.220]   So there was a good article in the Atlantic.
[01:32:57.220 --> 01:33:01.620]   This must be the kind of thing that reporters write at the beginning of a new year as they
[01:33:01.620 --> 01:33:04.380]   talk about boxes of cables and stuff.
[01:33:04.380 --> 01:33:06.340]   This is from Robinson Meyer.
[01:33:06.340 --> 01:33:10.940]   What the death of iTunes says about our digital habits.
[01:33:10.940 --> 01:33:16.340]   We started the 2010s with our electronic, obsessed with our electronic hygiene and it
[01:33:16.340 --> 01:33:21.140]   ended up a nation of digital hoarders.
[01:33:21.140 --> 01:33:27.140]   And actually it was early in the decade when Gmail arrived, this all began.
[01:33:27.140 --> 01:33:30.800]   Gmail said stop deleting email.
[01:33:30.800 --> 01:33:32.060]   Stop cleaning up your email.
[01:33:32.060 --> 01:33:33.060]   Have unlimited space.
[01:33:33.060 --> 01:33:34.500]   Just put everything in there.
[01:33:34.500 --> 01:33:35.500]   Leave it all.
[01:33:35.500 --> 01:33:36.500]   Don't delete anything.
[01:33:36.500 --> 01:33:42.420]   Just use our great search and you'll find the file you need.
[01:33:42.420 --> 01:33:48.780]   It was in counter, I bet you Georgia, are you still an inbox zero person?
[01:33:48.780 --> 01:33:54.460]   Yeah, my inbox is pretty great right now.
[01:33:54.460 --> 01:33:59.580]   But I have to say, but I think I'm questioning this.
[01:33:59.580 --> 01:34:03.000]   We started out with being, I think we're hoarders by nature.
[01:34:03.000 --> 01:34:06.520]   Anyway, I think that we were obsessed with it because we had to.
[01:34:06.520 --> 01:34:12.480]   But you remember that whole thing about inbox zero where the whole idea is every day you
[01:34:12.480 --> 01:34:16.280]   would religiously go through every damn email you had received and handle it in some way.
[01:34:16.280 --> 01:34:19.280]   Delete it, archive it, assign it, respond to it.
[01:34:19.280 --> 01:34:21.440]   And at the end of the day, you'd sigh a great sigh of relief.
[01:34:21.440 --> 01:34:23.240]   I, and you'd tweet it too.
[01:34:23.240 --> 01:34:25.320]   I am inbox zero.
[01:34:25.320 --> 01:34:30.480]   And then it got so onerous that people started declaring email bankruptcy.
[01:34:30.480 --> 01:34:31.480]   Remember that?
[01:34:31.480 --> 01:34:33.120]   Where you'd say, I just know, wait, I get to you.
[01:34:33.120 --> 01:34:35.560]   So in order to get to inbox zero, I'm just going to delete everything.
[01:34:35.560 --> 01:34:36.960]   I'm not going to even look at it.
[01:34:36.960 --> 01:34:40.680]   And I'm going to announce to the world, I have declared email bankruptcy.
[01:34:40.680 --> 01:34:44.520]   If I haven't responded to you, I'm not going to send me another email.
[01:34:44.520 --> 01:34:49.280]   Now it's just like, I talked to somebody in the radio show today with 93,000 emails
[01:34:49.280 --> 01:34:51.520]   in this inbox.
[01:34:51.520 --> 01:34:53.960]   I'm looking at my Gmail inbox right now.
[01:34:53.960 --> 01:34:54.960]   58,000.
[01:34:54.960 --> 01:35:00.120]   But there's only like five or six that are unread.
[01:35:00.120 --> 01:35:05.960]   And actually the thing that has been the best thing for helping me manage my inbox.
[01:35:05.960 --> 01:35:10.200]   You know, because I don't, you know, delete most of the stuff.
[01:35:10.200 --> 01:35:12.400]   Most of it just stays in there.
[01:35:12.400 --> 01:35:14.840]   But it's almost all been dealt with.
[01:35:14.840 --> 01:35:18.480]   But my smartphone helps me to triage that stuff.
[01:35:18.480 --> 01:35:23.920]   You know, on Android, you know, I can delete a message directly from the notification.
[01:35:23.920 --> 01:35:25.320]   So I can glance at my phone.
[01:35:25.320 --> 01:35:28.920]   Okay, read the read the subject line, who it's from.
[01:35:28.920 --> 01:35:30.120]   Delete, delete, delete.
[01:35:30.120 --> 01:35:34.120]   And I triage a lot of stuff right from there without ever even looking at it.
[01:35:34.120 --> 01:35:38.200]   You know, and then, you know, I come back when I've got the time, you know, if I've got
[01:35:38.200 --> 01:35:42.160]   a few minutes here or there, I'll go through to a quick read if I need to respond.
[01:35:42.160 --> 01:35:43.160]   So I'll respond.
[01:35:43.160 --> 01:35:45.680]   Otherwise, you know, just leave it, leave it in there.
[01:35:45.680 --> 01:35:49.320]   I don't, you know, I don't have to mess with it.
[01:35:49.320 --> 01:35:50.880]   You're just a weirdo.
[01:35:50.880 --> 01:35:51.880]   Yeah.
[01:35:51.880 --> 01:35:56.680]   I got the point now where I don't even look at my email for days in a stretch.
[01:35:56.680 --> 01:35:59.880]   Well, I mean, in my job, I can't, I can't afford it.
[01:35:59.880 --> 01:36:00.880]   You have to do it.
[01:36:00.880 --> 01:36:02.920]   I do have to respond, you know, to stuff.
[01:36:02.920 --> 01:36:07.720]   But you know, I get a lot of stuff that comes in, you know, that's just, you know, meaning
[01:36:07.720 --> 01:36:09.240]   like, you know, ads.
[01:36:09.240 --> 01:36:10.240]   All right.
[01:36:10.240 --> 01:36:11.240]   How about this?
[01:36:11.240 --> 01:36:12.240]   Motion's for stuff.
[01:36:12.240 --> 01:36:13.240]   Maybe your email.
[01:36:13.240 --> 01:36:14.240]   All right.
[01:36:14.240 --> 01:36:15.240]   How about this?
[01:36:15.240 --> 01:36:19.940]   Robison also says that around 2014, iTunes got so ridiculous that people stopped using
[01:36:19.940 --> 01:36:24.040]   it to manage their iPhones and they just started, you know, syncing.
[01:36:24.040 --> 01:36:28.500]   And it was about that time that people stopped organizing their iPhones, you know, where you
[01:36:28.500 --> 01:36:34.340]   have the front page and then folders and stuff and just put whenever they just stopped
[01:36:34.340 --> 01:36:40.020]   or the iPhone became seven, eight, nine pages of apps in no possible order.
[01:36:40.020 --> 01:36:43.220]   And they just use the search to launch the app.
[01:36:43.220 --> 01:36:44.220]   Is that Georgia?
[01:36:44.220 --> 01:36:45.860]   Do you have an organized iPhone?
[01:36:45.860 --> 01:36:47.740]   I really don't know.
[01:36:47.740 --> 01:36:48.740]   No, I don't.
[01:36:48.740 --> 01:36:49.740]   I can't be bothered.
[01:36:49.740 --> 01:36:52.700]   I, whenever my niece comes over, she organizes it for me.
[01:36:52.700 --> 01:36:54.940]   So I do have folders because I can't find anything.
[01:36:54.940 --> 01:36:57.740]   So I searched for them anyways, because I didn't organize them in the first place.
[01:36:57.740 --> 01:36:58.740]   Right.
[01:36:58.740 --> 01:37:00.140]   Whether it's in a folder or not, doesn't matter.
[01:37:00.140 --> 01:37:01.140]   Right.
[01:37:01.140 --> 01:37:02.140]   No, I don't really care.
[01:37:02.140 --> 01:37:03.140]   Yeah.
[01:37:03.140 --> 01:37:04.540]   It's just a.
[01:37:04.540 --> 01:37:05.980]   So we've become a nation of hoarders.
[01:37:05.980 --> 01:37:10.300]   He said part of the problem is the, in the last 10 years, the cost of a gigabyte of hard
[01:37:10.300 --> 01:37:14.100]   drive space has dropped from 10 cents to one cent.
[01:37:14.100 --> 01:37:18.940]   I just bought a 16 terabyte hard drive for under 400 bucks.
[01:37:18.940 --> 01:37:22.260]   16 terabytes.
[01:37:22.260 --> 01:37:27.740]   That's like the library of Congress for my hard drive.
[01:37:27.740 --> 01:37:28.740]   And then it was so much fun.
[01:37:28.740 --> 01:37:31.780]   I bought a couple more.
[01:37:31.780 --> 01:37:34.380]   My nast now has 30 terabytes of storage.
[01:37:34.380 --> 01:37:35.380]   I don't know.
[01:37:35.380 --> 01:37:40.140]   I don't ever have to throw anything out ever again.
[01:37:40.140 --> 01:37:46.700]   So is that, is that what's happened is that we have, we've become a, we've finally relaxed
[01:37:46.700 --> 01:37:48.420]   into our hoarder.
[01:37:48.420 --> 01:37:49.420]   Yeah.
[01:37:49.420 --> 01:37:51.380]   I think we were all in our orders anyways.
[01:37:51.380 --> 01:37:52.380]   We just couldn't.
[01:37:52.380 --> 01:37:56.380]   We had this crazy notion in the digital world, at least we could keep order.
[01:37:56.380 --> 01:38:00.260]   And then we could, we couldn't afford to not.
[01:38:00.260 --> 01:38:02.180]   So we were forced into it.
[01:38:02.180 --> 01:38:04.620]   And now our true nature has just.
[01:38:04.620 --> 01:38:06.020]   What's more emerged?
[01:38:06.020 --> 01:38:07.020]   Yes.
[01:38:07.020 --> 01:38:08.020]   Patrick.
[01:38:08.020 --> 01:38:10.140]   I don't know.
[01:38:10.140 --> 01:38:14.340]   My problem is I think he makes a much of valid points in this, especially, you know,
[01:38:14.340 --> 01:38:17.220]   Gmail getting people used to be like, Oh, just search for it.
[01:38:17.220 --> 01:38:21.260]   Eventually you'll come up with the right set of vectors to get the thing you want.
[01:38:21.260 --> 01:38:24.660]   You don't have to, you know, don't just leave everything where we can search it.
[01:38:24.660 --> 01:38:25.980]   It'll be fine.
[01:38:25.980 --> 01:38:30.620]   But you know, part of the reason iTunes died is because iTunes was always a tremendously
[01:38:30.620 --> 01:38:31.620]   difficult product.
[01:38:31.620 --> 01:38:32.620]   It was awful.
[01:38:32.620 --> 01:38:33.620]   Yeah.
[01:38:33.620 --> 01:38:36.900]   He calls it all sorts of names in this article.
[01:38:36.900 --> 01:38:41.620]   And, and, you know, and I remember like, you know, I remember, like I recently moved back
[01:38:41.620 --> 01:38:43.620]   to iOS after a while on Android.
[01:38:43.620 --> 01:38:48.380]   And I remember being like, Oh, they deleted the part of iTunes that would allow me to
[01:38:48.380 --> 01:38:51.900]   range all the icons on my page because of course they wanted to get rid of iTunes.
[01:38:51.900 --> 01:38:58.700]   And now I have to sit there and drag things and just being like, this is so irritating.
[01:38:58.700 --> 01:38:59.700]   But it is what it is.
[01:38:59.700 --> 01:39:05.260]   He says because of that, each of us quote has become a wanderer in a sea of content.
[01:39:05.260 --> 01:39:10.900]   Each of us adopted the tacit, but still shameful assumption that we are just treading water,
[01:39:10.900 --> 01:39:15.220]   but the clock is always running and the work will never end.
[01:39:15.220 --> 01:39:20.140]   Oh my God, that's depressing.
[01:39:20.140 --> 01:39:21.140]   But so true.
[01:39:21.140 --> 01:39:22.140]   But so true.
[01:39:22.140 --> 01:39:28.420]   He, the final sentence, he's talking about a famous review of a Paul Clay painting about
[01:39:28.420 --> 01:39:31.300]   an angel by a German critic Walter Benjamin.
[01:39:31.300 --> 01:39:32.380]   This is back in 1940.
[01:39:32.380 --> 01:39:36.700]   The angel looked quote as though he's about to move away from something he's fixatively
[01:39:36.700 --> 01:39:38.700]   contemplating his eyes are staring.
[01:39:38.700 --> 01:39:39.700]   His mouth is open.
[01:39:39.700 --> 01:39:40.780]   His wings are spread.
[01:39:40.780 --> 01:39:46.540]   The angel would like to stay and wake in the dead, make whole what has been smashed, but
[01:39:46.540 --> 01:39:48.340]   a storm is blowing from paradise.
[01:39:48.340 --> 01:39:50.900]   It has got caught in his wings with such violence.
[01:39:50.900 --> 01:39:52.620]   The angel can no longer close them.
[01:39:52.620 --> 01:39:57.660]   The storm irresistibly propels him into the future to which his back is turned while the
[01:39:57.660 --> 01:40:03.220]   pile of debris before him grows skyward.
[01:40:03.220 --> 01:40:10.460]   It is now clear, writes Robison that 80 years later, the angel is looking at his iPhone.
[01:40:10.460 --> 01:40:20.660]   But you know, watching the chat room as you talk, everybody for years, for at least a
[01:40:20.660 --> 01:40:25.220]   decade or more is complained about how awful and bloated iTunes was.
[01:40:25.220 --> 01:40:29.100]   But think back to 2001 when it first came out.
[01:40:29.100 --> 01:40:31.540]   It actually was really good at first.
[01:40:31.540 --> 01:40:36.380]   When it was just a music organization app, it was actually, it was the best thing out
[01:40:36.380 --> 01:40:37.380]   there.
[01:40:37.380 --> 01:40:38.380]   It was fantastic.
[01:40:38.380 --> 01:40:40.380]   It was the best thing that happened.
[01:40:40.380 --> 01:40:42.380]   It was the best thing that happened.
[01:40:42.380 --> 01:40:43.380]   It was the best thing that happened.
[01:40:43.380 --> 01:40:44.380]   It was the best thing that happened.
[01:40:44.380 --> 01:40:45.380]   It was the best thing that happened.
[01:40:45.380 --> 01:40:46.380]   It was the best thing that happened.
[01:40:46.380 --> 01:40:47.380]   It was the best thing that happened.
[01:40:47.380 --> 01:40:48.380]   It was the best thing that happened.
[01:40:48.380 --> 01:40:49.380]   It was the best thing that happened.
[01:40:49.380 --> 01:40:50.380]   It was the best thing that happened.
[01:40:50.380 --> 01:40:51.380]   It was the best thing that happened.
[01:40:51.380 --> 01:40:52.380]   It was the best thing that happened.
[01:40:52.380 --> 01:40:53.380]   It was the best thing that happened.
[01:40:53.380 --> 01:40:54.380]   It was the best thing that happened.
[01:40:54.380 --> 01:40:55.380]   It was the best thing that happened.
[01:40:55.380 --> 01:40:56.380]   It was the best thing that happened.
[01:40:56.380 --> 01:40:57.380]   It was the best thing that happened.
[01:40:57.380 --> 01:40:58.380]   It was the best thing that happened.
[01:40:58.380 --> 01:40:59.380]   It was the best thing that happened.
[01:40:59.380 --> 01:41:00.380]   It was the best thing that happened.
[01:41:00.380 --> 01:41:01.380]   It was the best thing that happened.
[01:41:01.380 --> 01:41:02.380]   It was the best thing that happened.
[01:41:02.380 --> 01:41:03.380]   It was the best thing that happened.
[01:41:03.380 --> 01:41:04.380]   It was the best thing that happened.
[01:41:04.380 --> 01:41:05.380]   It was the best thing that happened.
[01:41:05.380 --> 01:41:06.380]   It was the best thing that happened.
[01:41:06.380 --> 01:41:07.380]   It was the best thing that happened.
[01:41:07.380 --> 01:41:08.380]   It was the best thing that happened.
[01:41:08.380 --> 01:41:09.380]   It was the best thing that happened.
[01:41:09.380 --> 01:41:10.380]   It was the best thing that happened.
[01:41:10.380 --> 01:41:11.380]   It was the best thing that happened.
[01:41:11.380 --> 01:41:12.380]   It was the best thing that happened.
[01:41:12.380 --> 01:41:13.380]   It was the best thing that happened.
[01:41:13.380 --> 01:41:14.380]   It was the best thing that happened.
[01:41:14.380 --> 01:41:15.380]   It was the best thing that happened.
[01:41:15.380 --> 01:41:16.380]   It was the best thing that happened.
[01:41:16.380 --> 01:41:17.380]   It was the best thing that happened.
[01:41:17.380 --> 01:41:18.380]   It was the best thing that happened.
[01:41:18.380 --> 01:41:19.380]   It was the best thing that happened.
[01:41:19.380 --> 01:41:20.380]   It was the best thing that happened.
[01:41:20.380 --> 01:41:21.380]   It was the best thing that happened.
[01:41:21.380 --> 01:41:22.380]   It was the best thing that happened.
[01:41:22.380 --> 01:41:23.380]   It was the best thing that happened.
[01:41:23.380 --> 01:41:24.380]   It was the best thing that happened.
[01:41:24.380 --> 01:41:25.380]   It was the best thing that happened.
[01:41:25.380 --> 01:41:26.380]   It was the best thing that happened.
[01:41:26.380 --> 01:41:27.380]   It was the best thing that happened.
[01:41:27.380 --> 01:41:28.380]   It was the best thing that happened.
[01:41:28.380 --> 01:41:29.380]   It was the best thing that happened.
[01:41:29.380 --> 01:41:30.380]   It was the best thing that happened.
[01:41:30.380 --> 01:41:31.380]   It was the best thing that happened.
[01:41:31.380 --> 01:41:32.380]   It was the best thing that happened.
[01:41:32.380 --> 01:41:33.380]   It was the best thing that happened.
[01:41:33.380 --> 01:41:34.380]   It was the best thing that happened.
[01:41:34.380 --> 01:41:35.380]   It was the best thing that happened.
[01:41:35.380 --> 01:41:36.380]   It was the best thing that happened.
[01:41:36.380 --> 01:41:37.380]   It was the best thing that happened.
[01:41:37.380 --> 01:41:38.380]   It was the best thing that happened.
[01:41:38.380 --> 01:41:39.380]   It was the best thing that happened.
[01:41:39.380 --> 01:41:40.380]   It was the best thing that happened.
[01:41:40.380 --> 01:41:41.380]   It was the best thing that happened.
[01:41:41.380 --> 01:41:42.380]   It was the best thing that happened.
[01:41:42.380 --> 01:41:43.380]   It was the best thing that happened.
[01:41:43.380 --> 01:41:44.380]   It was the best thing that happened.
[01:41:44.380 --> 01:41:45.380]   It was the best thing that happened.
[01:41:45.380 --> 01:41:46.380]   It was the best thing that happened.
[01:41:46.380 --> 01:41:52.500]   In my engineering days, working on electronic control systems and cars, we had a term for
[01:41:52.500 --> 01:41:53.500]   this.
[01:41:53.500 --> 01:41:54.500]   We called it creeping featureitis.
[01:41:54.500 --> 01:41:55.500]   Yes.
[01:41:55.500 --> 01:41:57.380]   That's the same term, right?
[01:41:57.380 --> 01:41:58.380]   Yes.
[01:41:58.380 --> 01:42:00.380]   It still is applicable today.
[01:42:00.380 --> 01:42:01.380]   A little bit, Patrick.
[01:42:01.380 --> 01:42:07.780]   We tech journalists are to blame because we invented a PC magazine and invented the grid with
[01:42:07.780 --> 01:42:08.780]   the features.
[01:42:08.780 --> 01:42:09.780]   Right?
[01:42:09.780 --> 01:42:14.780]   Then people would say Norton utilities has all these and then semantic this is.
[01:42:14.780 --> 01:42:17.580]   They're with all the check boxes and you want the one with the most check boxes.
[01:42:17.580 --> 01:42:18.580]   Right?
[01:42:18.580 --> 01:42:19.580]   There was this huge pressure.
[01:42:19.580 --> 01:42:24.500]   On some level, I get the whole check box feature problem.
[01:42:24.500 --> 01:42:29.380]   But admittedly, there was a lot of shovelware on a lot of different machines that had nothing
[01:42:29.380 --> 01:42:34.900]   to do with anybody's check boxes and was a pure like, this comes with 711 apps.
[01:42:34.900 --> 01:42:37.300]   More is always better.
[01:42:37.300 --> 01:42:39.260]   More is always better.
[01:42:39.260 --> 01:42:43.140]   Which brings us back to the double-edged sword in human nature.
[01:42:43.140 --> 01:42:45.140]   We like bigger numbers.
[01:42:45.140 --> 01:42:53.380]   I mean, why else with AMD be releasing a 64 core thread ripper?
[01:42:53.380 --> 01:42:54.740]   There is a use.
[01:42:54.740 --> 01:42:59.420]   There are people who saw that announcement and went, yes, because it's going to significantly
[01:42:59.420 --> 01:43:02.860]   reduce the amount of time it takes them to do something.
[01:43:02.860 --> 01:43:07.340]   Have you surpassed on this week in computer hardware, which is the great show you guys
[01:43:07.340 --> 01:43:09.340]   do on our network?
[01:43:09.340 --> 01:43:10.940]   Have you come around the A?
[01:43:10.940 --> 01:43:14.380]   I see people going from Intel back to the AMD way.
[01:43:14.380 --> 01:43:17.380]   Have you come around to AMD?
[01:43:17.380 --> 01:43:23.100]   I've been running an AMD Ryzen desktop since they were released.
[01:43:23.100 --> 01:43:31.780]   Moving from my end current Intel processor to an AMD Ryzen dropped my...
[01:43:31.780 --> 01:43:35.580]   Basically, it was just such a massive reduction in the time of the computer render files.
[01:43:35.580 --> 01:43:37.740]   It was a no-brainer decision.
[01:43:37.740 --> 01:43:41.940]   One issue is for reasons nobody can quite figure out.
[01:43:41.940 --> 01:43:47.620]   The USB ports on the motherboard with that Ryzen processor do something really peculiar
[01:43:47.620 --> 01:43:53.500]   to my video capture device and made the video look washed out.
[01:43:53.500 --> 01:43:59.860]   In terms of editing, video, computing, gaming, everything else, it was a staggering amount
[01:43:59.860 --> 01:44:04.940]   of performance for the money compared to an Intel part.
[01:44:04.940 --> 01:44:08.260]   That gap is widening, isn't it?
[01:44:08.260 --> 01:44:10.260]   What's going to be interesting is the big...
[01:44:10.260 --> 01:44:11.260]   Last year was crazy.
[01:44:11.260 --> 01:44:16.540]   There was so much PC and especially PC gaming news at CES last year.
[01:44:16.540 --> 01:44:23.140]   This year, NVIDIA didn't present Intel presented, but they didn't have any presence on the
[01:44:23.140 --> 01:44:25.140]   show floor.
[01:44:25.140 --> 01:44:27.540]   AMD though announced that they were...
[01:44:27.540 --> 01:44:33.340]   They rise in 4,000 processors and they are essentially gunning for the Intel's laptop
[01:44:33.340 --> 01:44:34.940]   market, which is a big deal.
[01:44:34.940 --> 01:44:39.940]   I am really curious to see what the performance on those processors look like and which of
[01:44:39.940 --> 01:44:43.020]   the manufacturers will adopt them.
[01:44:43.020 --> 01:44:44.780]   When does that series come out?
[01:44:44.780 --> 01:44:45.780]   When it was the time for...
[01:44:45.780 --> 01:44:49.380]   Not soon enough for all of this week in computer hardware.
[01:44:49.380 --> 01:44:50.380]   Very interesting.
[01:44:50.380 --> 01:44:51.900]   Well, you know, I'll be watching.
[01:44:51.900 --> 01:44:55.660]   I'll be learning about the hardware.
[01:44:55.660 --> 01:44:58.220]   I'm coming to you from a Ryzen 5 as well.
[01:44:58.220 --> 01:45:00.460]   I thought you were a Ryzen guy.
[01:45:00.460 --> 01:45:01.860]   You just looked like it.
[01:45:01.860 --> 01:45:04.740]   That was a long time AMD guy going...
[01:45:04.740 --> 01:45:10.740]   The very first PC I ever bought when I was still in college in the mid 1980s was an AMD
[01:45:10.740 --> 01:45:12.940]   286 12 megahertz.
[01:45:12.940 --> 01:45:14.540]   Screaming 12 megahertz.
[01:45:14.540 --> 01:45:19.980]   Well, Patrick and I really were AMD fans back in the day on tech TV on the new screensavers
[01:45:19.980 --> 01:45:22.780]   because they were sticking it to Intel.
[01:45:22.780 --> 01:45:27.100]   It was a good thing because that competition was what convinced Intel that perhaps the
[01:45:27.100 --> 01:45:31.540]   titanium was not the direction in which to go.
[01:45:31.540 --> 01:45:32.540]   Not 164.
[01:45:32.540 --> 01:45:33.540]   Yeah.
[01:45:33.540 --> 01:45:37.740]   They actually ended up finding a little skunk works project they had going in Israel and
[01:45:37.740 --> 01:45:44.060]   that was the genesis of what is the current Intel line of processors.
[01:45:44.060 --> 01:45:48.540]   It was thanks to AMD that those prices stayed low and the power went up and now AMD is doing
[01:45:48.540 --> 01:45:52.780]   it again, which is great because they went through a kind of a fallow period.
[01:45:52.780 --> 01:45:54.180]   In a few lead years.
[01:45:54.180 --> 01:45:56.700]   There's the term.
[01:45:56.700 --> 01:46:03.740]   The other Wall Street Journal story, Anna Maria Andreatus, cash, plastic or hand.
[01:46:03.740 --> 01:46:08.300]   Amazon envisions paying with a wave.
[01:46:08.300 --> 01:46:14.940]   They want to put checkout terminals in brick and mortar stores that allow shoppers to link
[01:46:14.940 --> 01:46:19.860]   their card information to their hands.
[01:46:19.860 --> 01:46:25.020]   Not just a palm reader, but I guess these cameras are fast enough and accurate enough
[01:46:25.020 --> 01:46:29.260]   that a wave would be enough.
[01:46:29.260 --> 01:46:35.740]   Amazon's discussed the project with JP Morgan Chase and company Wells Fargo, Synchrony Financial,
[01:46:35.740 --> 01:46:41.260]   enabling consumer credit card accounts to work with hand terminals.
[01:46:41.260 --> 01:46:43.460]   It's interesting.
[01:46:43.460 --> 01:46:50.940]   They have a patent for a non-contact biometric identification system.
[01:46:50.940 --> 01:46:54.980]   The only problem I have with this is the same problem we talked about with face recognition
[01:46:54.980 --> 01:46:59.060]   and fingerprint is you can't change your hand.
[01:46:59.060 --> 01:47:04.260]   You can change your credit card number easily and if it gets compromised, no problem.
[01:47:04.260 --> 01:47:06.980]   You can't change your hand, your palm print.
[01:47:06.980 --> 01:47:07.980]   What do you do?
[01:47:07.980 --> 01:47:12.140]   Now you're going to be searching through all your social media if you had any really great
[01:47:12.140 --> 01:47:18.540]   quality pictures of your palm that someone else can't attack up and be able to suddenly
[01:47:18.540 --> 01:47:22.260]   be buying Teslas on your dime.
[01:47:22.260 --> 01:47:26.340]   Apparently it's pretty easy to just buy it when your phone is sitting in your pocket
[01:47:26.340 --> 01:47:28.660]   and not be able to get a refund.
[01:47:28.660 --> 01:47:29.660]   Oh really?
[01:47:29.660 --> 01:47:30.660]   Is that true?
[01:47:30.660 --> 01:47:38.700]   Yeah, apparently people have been accidentally buying the full self-driving option.
[01:47:38.700 --> 01:47:39.860]   Apparently the way the app is.
[01:47:39.860 --> 01:47:43.300]   Maybe they woke up before in the morning and instead of the bill starting installing a
[01:47:43.300 --> 01:47:45.700]   wiki they bought full self-driving.
[01:47:45.700 --> 01:47:46.700]   Yeah.
[01:47:46.700 --> 01:47:47.700]   I've done that.
[01:47:47.700 --> 01:47:48.700]   Who hasn't?
[01:47:48.700 --> 01:47:55.420]   Let's see.
[01:47:55.420 --> 01:47:56.420]   Sim swapping.
[01:47:56.420 --> 01:47:57.580]   Did you see this CDNAD article?
[01:47:57.580 --> 01:48:06.540]   Now I've seen some people poo poo this but this was a Princeton study in which they bought
[01:48:06.540 --> 01:48:17.020]   prepaid mobile cards services testing five major US providers to see if they could trick
[01:48:17.020 --> 01:48:23.580]   the humans at the call center into changing a user's phone number to another sim without
[01:48:23.580 --> 01:48:25.580]   providing proper credentials.
[01:48:25.580 --> 01:48:29.580]   According to the team AT&T, T-Mobile, track phone, US mobile and Verizon, I don't know
[01:48:29.580 --> 01:48:34.060]   where Sprint is in this but everybody but Sprint were found to be using vulnerable procedures
[01:48:34.060 --> 01:48:36.140]   with their customer support centers.
[01:48:36.140 --> 01:48:43.860]   For instance, and here's the flow, you call up the CSR, you say I'm a victim and I need
[01:48:43.860 --> 01:48:46.580]   a sim swap on my account.
[01:48:46.580 --> 01:48:48.060]   They say okay what's your PIN number?
[01:48:48.060 --> 01:48:49.060]   You give them a PIN number.
[01:48:49.060 --> 01:48:50.060]   One, two, three, four.
[01:48:50.060 --> 01:48:51.780]   They say no that's not your PIN number.
[01:48:51.780 --> 01:48:52.780]   Oh crud.
[01:48:52.780 --> 01:48:54.060]   Did I write that down wrong?
[01:48:54.060 --> 01:48:56.140]   I'm sorry I must have screwed up.
[01:48:56.140 --> 01:49:01.420]   Okay, no problem says the customer service representative.
[01:49:01.420 --> 01:49:05.020]   Can you tell me two numbers you've dialed on your phone recently?
[01:49:05.020 --> 01:49:07.700]   This is literally how they do that.
[01:49:07.700 --> 01:49:13.540]   You can provide those numbers perhaps because you tricked somebody into dying numbers.
[01:49:13.540 --> 01:49:18.420]   In some cases they even ask you can you tell me two inbound calls you received?
[01:49:18.420 --> 01:49:21.340]   That's really easy.
[01:49:21.340 --> 01:49:27.140]   And then they say oh that is you or billing information, a lot of stuff that isn't really
[01:49:27.140 --> 01:49:32.100]   that secure and then they say oh that is you yeah we'll swap that sim for you which
[01:49:32.100 --> 01:49:38.020]   is why you don't ever want to use an SMS for two-factor authentication.
[01:49:38.020 --> 01:49:41.380]   When providing incorrect answers to personal questions like date of birth or billing zip
[01:49:41.380 --> 01:49:46.060]   code research assistants would explain oh I've been careless at sign up.
[01:49:46.060 --> 01:49:49.380]   I can't recall the information.
[01:49:49.380 --> 01:49:53.380]   These call center operators are required based on their procedures to move to another
[01:49:53.380 --> 01:49:54.380]   mechanism.
[01:49:54.380 --> 01:50:05.900]   In some cases they would ask, you'd say what's a date of your last bill and if you get it
[01:50:05.900 --> 01:50:11.940]   a little wrong and say no no it's you're getting warm, warmer, no colder.
[01:50:11.940 --> 01:50:15.660]   They're helpful, they're helpful, they want to help you.
[01:50:15.660 --> 01:50:19.700]   The problem is they also help the bad guy.
[01:50:19.700 --> 01:50:26.220]   So this was not surprising to me but just a little word of warning.
[01:50:26.220 --> 01:50:27.700]   It's pretty easy to do.
[01:50:27.700 --> 01:50:31.300]   Because they don't want to be yelled at.
[01:50:31.300 --> 01:50:33.060]   They're service, that's right.
[01:50:33.060 --> 01:50:35.380]   They're customer service representatives.
[01:50:35.380 --> 01:50:38.340]   They're trying to serve you.
[01:50:38.340 --> 01:50:39.340]   Right?
[01:50:39.340 --> 01:50:45.020]   No, I remember the first time somebody asked me for a pin number for my account.
[01:50:45.020 --> 01:50:50.500]   I was like never had one because I'd been at the company since before they'd implemented
[01:50:50.500 --> 01:50:53.020]   them on the same account and changed my plan.
[01:50:53.020 --> 01:51:02.820]   It led to a long and it just takes time but social engineering people have a funny habit
[01:51:02.820 --> 01:51:04.220]   of finding a way to make this happen.
[01:51:04.220 --> 01:51:10.380]   Patrick Norton is here, AVExcel.com.
[01:51:10.380 --> 01:51:14.140]   That's a fabulous podcast you do with, is that with Robert as well?
[01:51:14.140 --> 01:51:15.140]   Robert Herron?
[01:51:15.140 --> 01:51:16.140]   Yes sir.
[01:51:16.140 --> 01:51:17.140]   That is with Robert Herron.
[01:51:17.140 --> 01:51:19.540]   All about audio, visual excellence.
[01:51:19.540 --> 01:51:20.540]   We have fun.
[01:51:20.540 --> 01:51:24.700]   I liked those AK micro LED displays I saw at CES.
[01:51:24.700 --> 01:51:27.540]   Did you not think those were really beautiful and cool?
[01:51:27.540 --> 01:51:33.940]   Yeah, but I have no AK content and there's more than enough resolution.
[01:51:33.940 --> 01:51:40.300]   Our eyeballs evolved for contrast, not resolution.
[01:51:40.300 --> 01:51:46.580]   My goal at this point, it was funny, I finally got to watch that episode of Game of Thrones,
[01:51:46.580 --> 01:51:48.380]   which I would have called the Long Night.
[01:51:48.380 --> 01:51:50.020]   The Dark episode, yeah.
[01:51:50.020 --> 01:51:51.020]   Yeah.
[01:51:51.020 --> 01:51:54.260]   I finally got to see it on an HDR television and I was like, "Okay, I was right.
[01:51:54.260 --> 01:51:56.020]   They really shot this with HDR in mind.
[01:51:56.020 --> 01:51:57.020]   Yes.
[01:51:57.020 --> 01:52:02.020]   Now I want an HDR television that has, I want to essentially analogy OLED television at this
[01:52:02.020 --> 01:52:03.020]   point.
[01:52:03.020 --> 01:52:04.020]   Yes, you do.
[01:52:04.020 --> 01:52:05.020]   I will vouch for it.
[01:52:05.020 --> 01:52:06.020]   On the television sides of things.
[01:52:06.020 --> 01:52:10.500]   By the way, the only problem with that, I did the same thing on my HDR LGO LED.
[01:52:10.500 --> 01:52:16.020]   The only problem with that is the way Comcast compressed it before delivering it.
[01:52:16.020 --> 01:52:17.020]   Didn't matter.
[01:52:17.020 --> 01:52:18.020]   It's not Comcast, it's HBO.
[01:52:18.020 --> 01:52:20.180]   Somebody's compressed in the hell out of that.
[01:52:20.180 --> 01:52:22.860]   I want the DVD of the Blu-ray now because I...
[01:52:22.860 --> 01:52:23.860]   Yeah.
[01:52:23.860 --> 01:52:29.020]   My notes for the next episode of AV Excel was talking about how frustrating it is that
[01:52:29.020 --> 01:52:32.020]   I've having used multiple different...
[01:52:32.020 --> 01:52:39.260]   I've seen across multiple different internet systems, it's HBO.
[01:52:39.260 --> 01:52:40.260]   That's a shame.
[01:52:40.260 --> 01:52:42.660]   They just compressed the crap out of everything.
[01:52:42.660 --> 01:52:44.660]   Well, it's their prerogative, I guess.
[01:52:44.660 --> 01:52:48.260]   It is, but if you're going to do that, then the directors and the producers of these programs
[01:52:48.260 --> 01:52:51.060]   need to take to know that it's not going to work.
[01:52:51.060 --> 01:52:52.620]   You're not going to see anything.
[01:52:52.620 --> 01:52:53.620]   But they do that for...
[01:52:53.620 --> 01:52:55.660]   But it's something, they do that for all their content.
[01:52:55.660 --> 01:52:58.220]   It was just especially brutal on that particular episode.
[01:52:58.220 --> 01:52:59.220]   It was.
[01:52:59.220 --> 01:53:01.220]   Especially the night it shipped.
[01:53:01.220 --> 01:53:05.420]   Yeah, well, because we were all watching live, right?
[01:53:05.420 --> 01:53:12.860]   The wall, Samsung had a TV that was 290-some inches.
[01:53:12.860 --> 01:53:15.420]   I want a wall of my house.
[01:53:15.420 --> 01:53:16.820]   This is why I need 8K.
[01:53:16.820 --> 01:53:19.900]   And this is why micro LED is a solution because they're little tiles you put together.
[01:53:19.900 --> 01:53:23.780]   I want a whole wall that's a TV because then you're there, you're immersed.
[01:53:23.780 --> 01:53:26.700]   You are sitting with Archie Bunker in his living room.
[01:53:26.700 --> 01:53:33.980]   But I had a perfectly wonderful experience with a 100-inch projection screen in my old
[01:53:33.980 --> 01:53:34.980]   house.
[01:53:34.980 --> 01:53:37.020]   120 would have been a nice jump for 4K.
[01:53:37.020 --> 01:53:40.500]   But 8K resolution is...
[01:53:40.500 --> 01:53:42.900]   When there's 8K content, call me.
[01:53:42.900 --> 01:53:44.620]   Until then, which I think on this point, there's probably...
[01:53:44.620 --> 01:53:45.620]   You can't buy the TV either.
[01:53:45.620 --> 01:53:49.340]   I mean, unless you have a million dollars lying around.
[01:53:49.340 --> 01:53:54.700]   I told Lisa, I said, "That's our TV in five years when there's content and we have a room
[01:53:54.700 --> 01:53:59.860]   that's...we want to fill the whole wall."
[01:53:59.860 --> 01:54:02.300]   You can sit there with your Florida ceiling experience.
[01:54:02.300 --> 01:54:07.060]   I will have the hover chair that the segway people...
[01:54:07.060 --> 01:54:08.060]   They crashed at...
[01:54:08.060 --> 01:54:09.060]   What did you say?
[01:54:09.060 --> 01:54:10.060]   Did you see the crash?
[01:54:10.060 --> 01:54:12.060]   The knob fell off.
[01:54:12.060 --> 01:54:15.060]   No, but the white...
[01:54:15.060 --> 01:54:16.060]   The wallie experience.
[01:54:16.060 --> 01:54:17.060]   The wallie experience.
[01:54:17.060 --> 01:54:18.060]   The wallie experience.
[01:54:18.060 --> 01:54:19.060]   Yeah.
[01:54:19.060 --> 01:54:21.180]   She's like, "They built the chair from Wallie and I'm all I can think of is like this.
[01:54:21.180 --> 01:54:24.340]   It comes with a sesquicentennial cupcake and a cup."
[01:54:24.340 --> 01:54:25.340]   I hope so.
[01:54:25.340 --> 01:54:26.340]   Sesquicentennial cupcake.
[01:54:26.340 --> 01:54:31.860]   And it's going to have the giant wall TV and I'm just...I can just...
[01:54:31.860 --> 01:54:32.860]   Yeah.
[01:54:32.860 --> 01:54:33.860]   I can't wait.
[01:54:33.860 --> 01:54:36.060]   Forget your VR rooms.
[01:54:36.060 --> 01:54:37.060]   I got to have...
[01:54:37.060 --> 01:54:38.500]   No, I would be all in for both.
[01:54:38.500 --> 01:54:39.500]   Yep.
[01:54:39.500 --> 01:54:41.260]   Then I could play VR in the chair.
[01:54:41.260 --> 01:54:42.260]   Yeah.
[01:54:42.260 --> 01:54:43.260]   You see?
[01:54:43.260 --> 01:54:44.260]   Yeah.
[01:54:44.260 --> 01:54:45.260]   Yeah.
[01:54:45.260 --> 01:54:46.260]   Now we're cooking.
[01:54:46.260 --> 01:54:47.260]   That's...
[01:54:47.260 --> 01:54:48.260]   You never have to worry about tripping over any of it.
[01:54:48.260 --> 01:54:53.260]   I always want to say that sweet jerk brown, but it's actually Georgia Dow.
[01:54:53.260 --> 01:54:55.100]   So sweet Georgia Brown.
[01:54:55.100 --> 01:55:00.540]   She's senior editor at iMore, but don't forget anxiety-videos.com.
[01:55:00.540 --> 01:55:08.380]   That's where she and her partner create the best videos on parenting, on sleep, on anxiety,
[01:55:08.380 --> 01:55:09.740]   stuff that just really use...
[01:55:09.740 --> 01:55:11.380]   I have the whole set and I'm thrilled.
[01:55:11.380 --> 01:55:13.500]   Thank you for sending that to me.
[01:55:13.500 --> 01:55:14.500]   Really neat stuff.
[01:55:14.500 --> 01:55:15.500]   Anxiety-videos.com.
[01:55:15.500 --> 01:55:18.740]   And of course, Sam Abble-Samit.
[01:55:18.740 --> 01:55:20.540]   He is my car guy.
[01:55:20.540 --> 01:55:24.780]   My principal, I know it's a navigate research and he's sitting on a...
[01:55:24.780 --> 01:55:28.140]   Is that Lake Michigan you're sitting in front of?
[01:55:28.140 --> 01:55:29.140]   Grand Travers Bay.
[01:55:29.140 --> 01:55:30.140]   Grand Travers Bay.
[01:55:30.140 --> 01:55:31.140]   And Travers Bay.
[01:55:31.140 --> 01:55:32.140]   That's beautiful.
[01:55:32.140 --> 01:55:33.540]   That's where Cape Patello lives.
[01:55:33.540 --> 01:55:34.540]   Yep.
[01:55:34.540 --> 01:55:37.900]   She moved there, yeah, with Ray.
[01:55:37.900 --> 01:55:42.540]   Our show today brought to you by ITProTV.
[01:55:42.540 --> 01:55:43.540]   And IT would...
[01:55:43.540 --> 01:55:49.540]   If you're looking for a gig, if you're listening to the shows here on Twitch, we know you
[01:55:49.540 --> 01:55:50.820]   love tech, right?
[01:55:50.820 --> 01:55:53.780]   Would it be nice to take your passion, the thing you love the most and make a living
[01:55:53.780 --> 01:55:54.780]   doing that?
[01:55:54.780 --> 01:55:56.080]   And what a good living.
[01:55:56.080 --> 01:56:00.940]   There are millions of IT jobs lying open, just waiting for the right people to come along.
[01:56:00.940 --> 01:56:05.580]   Best way to get that job, get the cert you need from ITProTV.
[01:56:05.580 --> 01:56:12.500]   It's a fun and easy way to learn ITProTV's entertainers, blend education and entertainment
[01:56:12.500 --> 01:56:14.300]   to make IT learning fun.
[01:56:14.300 --> 01:56:17.900]   You can watch live, chat live or on demand.
[01:56:17.900 --> 01:56:24.420]   And every area, CompTIA, Microsoft, Cisco, Security, Linux, Apple, AWS, they have all
[01:56:24.420 --> 01:56:25.420]   the certs.
[01:56:25.420 --> 01:56:29.060]   In fact, they're the official video training partner for CompTIA.
[01:56:29.060 --> 01:56:34.740]   So a great cert to get into IT is one of the CompTIA certs, like A+ or Network+ or
[01:56:34.740 --> 01:56:40.460]   Security+ they have 12 on-demand courses to get you those CompTIA certs.
[01:56:40.460 --> 01:56:43.460]   You can take the tests before you take the test.
[01:56:43.460 --> 01:56:47.820]   They have practice tests, hands-on learning with their virtual labs.
[01:56:47.820 --> 01:56:53.460]   All you need is an HTML5 browser and you've got access to Windows Server and desktop clients.
[01:56:53.460 --> 01:56:56.900]   So you can test out your skills to learn new techniques.
[01:56:56.900 --> 01:57:01.780]   By the way, not just Windows, also Mac OS, everything you need to know, they've got.
[01:57:01.780 --> 01:57:02.860]   I am such a fan.
[01:57:02.860 --> 01:57:09.700]   The ISC squared certs, the EC Council certif, I want to, I got to take the time to get the
[01:57:09.700 --> 01:57:12.580]   CEH, the Certified Ethical Hackers cert.
[01:57:12.580 --> 01:57:16.260]   I just would be nice to put a frame on the wall.
[01:57:16.260 --> 01:57:21.780]   Explore all those IT career paths available to you like entry level systems administration,
[01:57:21.780 --> 01:57:25.700]   desktop support, cloud technology, and let's not forget security.
[01:57:25.700 --> 01:57:29.380]   There's a huge demand for IT security professionals out there.
[01:57:29.380 --> 01:57:32.340]   And the best way to learn right now, ITProTV.
[01:57:32.340 --> 01:57:35.580]   They even have one-on-one coaching services.
[01:57:35.580 --> 01:57:40.500]   If you want a little hands-on support, that's available to premium members as well.
[01:57:40.500 --> 01:57:42.460]   Become part of the ITProTV family.
[01:57:42.460 --> 01:57:44.380]   The standard membership is very affordable.
[01:57:44.380 --> 01:57:46.500]   It costs a lot less than a technical school.
[01:57:46.500 --> 01:57:49.420]   Less than the materials you'd buy at a bookstore.
[01:57:49.420 --> 01:57:50.660]   And that's the video only plan.
[01:57:50.660 --> 01:57:54.340]   Then there's a premium membership that includes the videos, all the on-demand videos, all
[01:57:54.340 --> 01:57:59.820]   the live video, plus the labs, the practice tests, the one-on-one learning coach.
[01:57:59.820 --> 01:58:00.820]   ITProTV.
[01:58:00.820 --> 01:58:01.820]   It's time.
[01:58:01.820 --> 01:58:02.820]   It's time.
[01:58:02.820 --> 01:58:06.460]   And if you're already in IT, what a great way to keep your chops up learning new skills,
[01:58:06.460 --> 01:58:09.020]   get a better job or a raise.
[01:58:09.020 --> 01:58:15.900]   ITProTV.tv/twit, use the code TWIT30, and you'll get 30% off, and not just for a little
[01:58:15.900 --> 01:58:18.820]   while, but for as long as you use it, as long as you're active.
[01:58:18.820 --> 01:58:22.380]   TWIT30, 30% off ITProTV.
[01:58:22.380 --> 01:58:27.260]   Build or expand your IT career and enjoy the journey.
[01:58:27.260 --> 01:58:28.260]   Great folks.
[01:58:28.260 --> 01:58:29.260]   I love them.
[01:58:29.260 --> 01:58:30.260]   ITProTV.
[01:58:30.260 --> 01:58:37.780]   ITProTV/twit to find out more.
[01:58:37.780 --> 01:58:42.900]   I'm a little worried about Section 230.
[01:58:42.900 --> 01:58:45.020]   Are you worried about Section 230?
[01:58:45.020 --> 01:58:49.660]   Now Joe Biden is going after it.
[01:58:49.660 --> 01:58:53.180]   Joe did an interview with the New York Times editorial board.
[01:58:53.180 --> 01:58:56.700]   There's a very long, detailed transcript.
[01:58:56.700 --> 01:59:05.380]   In much of it, I was impressed by his command of the issues and his thoughtful, you know,
[01:59:05.380 --> 01:59:07.380]   suggestions and policies.
[01:59:07.380 --> 01:59:12.340]   But then as you get down towards the bottom, they start talking to me, boy, the bottom
[01:59:12.340 --> 01:59:13.340]   is a long way down.
[01:59:13.340 --> 01:59:18.180]   Let me just, I need to scroll fast.
[01:59:18.180 --> 01:59:26.580]   They start talking about Facebook, Cambridge Analytica, and the problems that Facebook potentially
[01:59:26.580 --> 01:59:33.660]   is creating by allowing candidates to lie in political ads on Facebook.
[01:59:33.660 --> 01:59:37.780]   Charlie Wartzel, in October, your campaign said a letter to Facebook, running an ad that
[01:59:37.780 --> 01:59:42.460]   falsely claimed you blackmailed Ukrainian officials to not investigate your son.
[01:59:42.460 --> 01:59:45.820]   I'm curious, did that experience dealing with Facebook and their power?
[01:59:45.820 --> 01:59:48.940]   Did that change the way you see the power of tech platforms right now?
[01:59:48.940 --> 01:59:52.580]   He says, Biden, I've never been a fan of Facebook, as you probably know.
[01:59:52.580 --> 01:59:55.060]   I've never been a big Zuckerberg fan.
[01:59:55.060 --> 01:59:58.020]   I think he's a real problem.
[01:59:58.020 --> 01:59:59.500]   He knows better.
[01:59:59.500 --> 02:00:03.620]   From my perspective, I'm of the view that not only should we be worrying about the concentration
[02:00:03.620 --> 02:00:08.900]   of power, we should worry about the lack of privacy and, and this is where it starts to
[02:00:08.900 --> 02:00:13.740]   get a little problematic for me, them being exempt.
[02:00:13.740 --> 02:00:15.100]   The New York Times is an exempt.
[02:00:15.100 --> 02:00:18.700]   You can't write something, you know, to be false and an exempt from being sued, but he
[02:00:18.700 --> 02:00:19.700]   can.
[02:00:19.700 --> 02:00:20.700]   Mark Zuckerberg can.
[02:00:20.700 --> 02:00:22.260]   But he didn't write it.
[02:00:22.260 --> 02:00:23.260]   He didn't write it.
[02:00:23.260 --> 02:00:25.420]   And that's not what 230 is all about, 230.
[02:00:25.420 --> 02:00:30.620]   And the last sentence says, the discourse would be improved if we take, if we all take a moment
[02:00:30.620 --> 02:00:32.980]   to actually read the text of CDA 230.
[02:00:32.980 --> 02:00:36.020]   Well, maybe we should start with Joe Biden reading the text.
[02:00:36.020 --> 02:00:37.580]   Yeah, this really worries me.
[02:00:37.580 --> 02:00:39.220]   He clearly doesn't understand it.
[02:00:39.220 --> 02:00:44.700]   He says he's effectively saying that whatever appears on Facebook is the responsibility of
[02:00:44.700 --> 02:00:51.940]   Mark Zuckerberg and Facebook, they're a publisher and section 230 of the Communications Decency
[02:00:51.940 --> 02:00:57.100]   Act says online platforms aren't held liable for things their users post on them.
[02:00:57.100 --> 02:01:02.040]   Any more than the phone company is held liable for the conversation you have on the phone.
[02:01:02.040 --> 02:01:06.740]   That is really important to protecting the internet.
[02:01:06.740 --> 02:01:12.420]   If, if for instance, I'm responsible for anything anybody says on our forums or in our chat
[02:01:12.420 --> 02:01:19.180]   room or in a twit.social mastodon, I'm going to take them all down because I can't, I can't
[02:01:19.180 --> 02:01:20.780]   be held responsible for it.
[02:01:20.780 --> 02:01:21.780]   I'm not.
[02:01:21.780 --> 02:01:26.300]   People can, it's an open forum and it's impossible to monitor that.
[02:01:26.300 --> 02:01:30.700]   Imagine now multiply that times one and a half billion users.
[02:01:30.700 --> 02:01:37.900]   It's, it's, what he's saying is Charlie responds, it's a pretty foundational law of the modern
[02:01:37.900 --> 02:01:39.300]   internet.
[02:01:39.300 --> 02:01:40.300]   That's right.
[02:01:40.300 --> 02:01:43.940]   Says Biden exactly right and it should be revoked.
[02:01:43.940 --> 02:01:46.100]   It should be revoked because it's not merely an internet company.
[02:01:46.100 --> 02:01:47.740]   It's propagating falsehoods.
[02:01:47.740 --> 02:01:49.740]   They know to be false.
[02:01:49.740 --> 02:01:53.620]   And we should be sending standards like the Europeans do with privacy.
[02:01:53.620 --> 02:02:00.780]   Oh boy, I, I hope somebody may be a little bit hipper, a little bit younger, maybe somebody
[02:02:00.780 --> 02:02:05.700]   who's read the section 230.
[02:02:05.700 --> 02:02:08.140]   He was, he was in the Senate when that was passed.
[02:02:08.140 --> 02:02:09.140]   Yeah.
[02:02:09.140 --> 02:02:10.140]   Yeah.
[02:02:10.140 --> 02:02:11.140]   But I understand his eye.
[02:02:11.140 --> 02:02:12.140]   I read the bills.
[02:02:12.140 --> 02:02:13.140]   They vote on.
[02:02:13.140 --> 02:02:14.140]   I know.
[02:02:14.140 --> 02:02:15.140]   I understand his ire.
[02:02:15.140 --> 02:02:18.980]   But honestly, this is, this is much more complex than that.
[02:02:18.980 --> 02:02:21.820]   He compares, you know, he talks about the Luddites.
[02:02:21.820 --> 02:02:23.060]   He does say something interesting.
[02:02:23.060 --> 02:02:26.580]   I mean, he says, you know, tech, tech, things happen.
[02:02:26.580 --> 02:02:31.740]   Technology comes along, create, you know, every industrial revolution, every major technological
[02:02:31.740 --> 02:02:37.020]   breakthrough, every single one, he says there's an arrogance.
[02:02:37.020 --> 02:02:40.540]   He says, we're in the fourth technological revolution.
[02:02:40.540 --> 02:02:42.100]   The hardest speech I've ever had to make.
[02:02:42.100 --> 02:02:46.100]   I've asked to speak at the World Economic Forum.
[02:02:46.100 --> 02:02:48.940]   And he says, every other revolution we've had technologically, it's taken so long.
[02:02:48.940 --> 02:02:52.500]   And somewhere between six years, at this I don't agree, disagree with, between six years
[02:02:52.500 --> 02:02:57.980]   in a generation for government to come in and level the playing field again.
[02:02:57.980 --> 02:03:01.220]   Remember the Luddites smashing the machinery in the Midlands?
[02:03:01.220 --> 02:03:03.300]   That was their answer when the culture was changing.
[02:03:03.300 --> 02:03:06.460]   Same thing with television, same thing before that with radio.
[02:03:06.460 --> 02:03:09.380]   Same thing, but this is gigantic and it's a responsibility of government to make sure
[02:03:09.380 --> 02:03:10.380]   it's not abused.
[02:03:10.380 --> 02:03:16.100]   I don't disagree with that, but it starts by reading CDA 230 and understanding why it's
[02:03:16.100 --> 02:03:17.100]   so important.
[02:03:17.100 --> 02:03:18.100]   Right.
[02:03:18.100 --> 02:03:23.580]   And, you know, I think that the answer, you know, not that there necessarily is an answer,
[02:03:23.580 --> 02:03:27.460]   but to the degree there is one is not repealing 230.
[02:03:27.460 --> 02:03:30.620]   But you know, I mean, what is the real issue here?
[02:03:30.620 --> 02:03:37.700]   The issue is that it's trying to manage this content, trying to moderate this content,
[02:03:37.700 --> 02:03:44.260]   cannot possibly scale up to something the size of Facebook or YouTube or any of these
[02:03:44.260 --> 02:03:45.900]   other major platforms.
[02:03:45.900 --> 02:03:49.140]   You know, the problem is these platforms have simply gotten too big.
[02:03:49.140 --> 02:03:55.220]   We've allowed them to grow out of control and there's no way that we can manage that.
[02:03:55.220 --> 02:03:59.540]   And you know, I think we need to start moving away from these enormous platforms and start
[02:03:59.540 --> 02:04:02.660]   getting back to smaller, more constrained platforms.
[02:04:02.660 --> 02:04:04.220]   That's why we have a Twitter community.
[02:04:04.220 --> 02:04:06.620]   Yeah, that's why we do it and Twitter social.
[02:04:06.620 --> 02:04:13.620]   On the other side, though, you know, if you're being paid to put up advertising that you
[02:04:13.620 --> 02:04:18.100]   know has libelous statements on that, shouldn't you then be able to be prosecuted for libel
[02:04:18.100 --> 02:04:21.900]   since you are putting that up and you've been paid for it, which would be different than
[02:04:21.900 --> 02:04:27.500]   having a chatroom or having just Mary that posted this, whatever article that Mary wanted
[02:04:27.500 --> 02:04:29.340]   to post.
[02:04:29.340 --> 02:04:37.900]   Historically, we have not, for instance, regulated that in broadcast because what you
[02:04:37.900 --> 02:04:43.060]   don't want to do is put the broadcasters or the FCC in the position of determining what
[02:04:43.060 --> 02:04:48.660]   is truth and what is false because then there is, you know, there's issues.
[02:04:48.660 --> 02:04:53.580]   It's not always the case that you could say, well, that's a lie.
[02:04:53.580 --> 02:04:58.020]   And so what you don't want is government to say, okay, it's up to you, Mark Zuckerberg
[02:04:58.020 --> 02:05:01.220]   to prevent lies on your platform.
[02:05:01.220 --> 02:05:04.820]   That actually gives him an immense amount of power.
[02:05:04.820 --> 02:05:06.780]   And so we don't regulate that in the United States.
[02:05:06.780 --> 02:05:11.260]   I don't know what they do in Canada, but in the US, we don't regulate that in broadcast.
[02:05:11.260 --> 02:05:16.860]   You see, the only thing is that my thought is that if, you know, citizens united and
[02:05:16.860 --> 02:05:21.180]   companies are people, if you can, you know, someone else, if you put up a lie about me
[02:05:21.180 --> 02:05:25.500]   and I could sue you personally for libel because you wrote something that I could prove under
[02:05:25.500 --> 02:05:30.140]   a court of law was a lie and the court said so, then you should be able to do that the
[02:05:30.140 --> 02:05:34.580]   same way with a company, which may make companies more careful about what they place up and
[02:05:34.580 --> 02:05:36.180]   not just go to the biggest dollar.
[02:05:36.180 --> 02:05:38.660]   But you see that's the right there in the court of law.
[02:05:38.660 --> 02:05:40.140]   That's going to be a problem.
[02:05:40.140 --> 02:05:45.340]   Because if you try each one of these, those trials will end in a year or two by which time
[02:05:45.340 --> 02:05:51.460]   25,000 ads have appeared in the meantime and the election's over.
[02:05:51.460 --> 02:05:53.020]   So that's too slow a means.
[02:05:53.020 --> 02:05:54.460]   I just don't know if there's any effect.
[02:05:54.460 --> 02:05:58.820]   And it's also not a guarantee that you're going to get, you know, an accurate outcome
[02:05:58.820 --> 02:05:59.820]   either.
[02:05:59.820 --> 02:06:04.420]   I mean, look at, you know, the recent libel case against Elon Musk for calling that.
[02:06:04.420 --> 02:06:05.660]   Yeah, the head of, right.
[02:06:05.660 --> 02:06:06.660]   He don't.
[02:06:06.660 --> 02:06:07.660]   Yeah.
[02:06:07.660 --> 02:06:08.660]   He got away with that.
[02:06:08.660 --> 02:06:09.660]   Yeah.
[02:06:09.660 --> 02:06:11.580]   I don't know.
[02:06:11.580 --> 02:06:14.700]   This is the, and in the other direction, this is a Washington Post article.
[02:06:14.700 --> 02:06:20.780]   There was a, the Congress took testimony in Boulder, Colorado this week from small companies
[02:06:20.780 --> 02:06:26.700]   complaining about Apple, Amazon, Facebook and Google, Sonos, which is suing Google saying
[02:06:26.700 --> 02:06:34.380]   you stole our technology, testified that, you know, there's abuse in the marketplace.
[02:06:34.380 --> 02:06:43.620]   Kyle said, Oh man, Apple, Apple put, find my iPhone into the iPhone, largely mimicking
[02:06:43.620 --> 02:06:45.560]   what we do.
[02:06:45.560 --> 02:06:52.220]   And then in their app store said, Oh, you can't collect any information that location data.
[02:06:52.220 --> 02:06:53.660]   That's anti competitive.
[02:06:53.660 --> 02:06:54.660]   Mm.
[02:06:54.660 --> 02:07:00.260]   What see this happened in Europe too, where you get smaller companies going after Google,
[02:07:00.260 --> 02:07:08.300]   for instance, and using the regulators to in effect tilt the market in their direction.
[02:07:08.300 --> 02:07:11.460]   So I, I worry that it can go both ways.
[02:07:11.460 --> 02:07:13.100]   It's as difficult, isn't it?
[02:07:13.100 --> 02:07:14.220]   This is that double edged sword.
[02:07:14.220 --> 02:07:18.380]   I knew this would be the theme for today.
[02:07:18.380 --> 02:07:24.260]   We are going to see there the, the Supreme Court has agreed to take the Apple store case.
[02:07:24.260 --> 02:07:26.900]   So that will be very interesting.
[02:07:26.900 --> 02:07:27.900]   You know what?
[02:07:27.900 --> 02:07:29.980]   I've kept you here long enough.
[02:07:29.980 --> 02:07:35.220]   I think it's time to on that note to say thank you.
[02:07:35.220 --> 02:07:37.420]   Patrick is in an unknown location.
[02:07:37.420 --> 02:07:39.380]   Tom, it's all like city.
[02:07:39.380 --> 02:07:40.380]   Really?
[02:07:40.380 --> 02:07:41.380]   Is that where you're going to move?
[02:07:41.380 --> 02:07:42.380]   Are you moving there?
[02:07:42.380 --> 02:07:43.380]   Are you just visiting?
[02:07:43.380 --> 02:07:46.740]   We are traveling through here on our way to Rapid City.
[02:07:46.740 --> 02:07:50.660]   And then we are swinging back around where we could end up in St. Louis.
[02:07:50.660 --> 02:07:53.020]   So you don't have a destination.
[02:07:53.020 --> 02:07:55.820]   We are, we are exploring and figuring out where we move next.
[02:07:55.820 --> 02:07:57.860]   They're a family on the move.
[02:07:57.860 --> 02:07:59.660]   Are you all stuck in an RV?
[02:07:59.660 --> 02:08:00.660]   What's going on?
[02:08:00.660 --> 02:08:05.540]   Well, we were stuck in an air stream and now we are stuck in a somewhat larger and somewhat
[02:08:05.540 --> 02:08:10.420]   warmer creeks eye, which is outdoors RV for season.
[02:08:10.420 --> 02:08:12.980]   What happened to the air streamer?
[02:08:12.980 --> 02:08:19.100]   It turns out when you take, you know, two adults, a seven year old, a 12 year old and
[02:08:19.100 --> 02:08:26.580]   a husky, suddenly an air stream, you know, 76 air stream sovereign seems so much smaller
[02:08:26.580 --> 02:08:27.580]   than it did.
[02:08:27.580 --> 02:08:29.340]   But it's so cute, isn't it?
[02:08:29.340 --> 02:08:34.340]   You know, it is aesthetically, it is a design icon.
[02:08:34.340 --> 02:08:36.380]   It is a magnificently constructed beast.
[02:08:36.380 --> 02:08:42.340]   It is too damn small for my relationship with my wife and my children and the dog to survive
[02:08:42.340 --> 02:08:44.580]   all of us in there in cold weather.
[02:08:44.580 --> 02:08:46.860]   I had no idea you were doing this, Patrick.
[02:08:46.860 --> 02:08:51.140]   How long has this hejira been going on?
[02:08:51.140 --> 02:08:54.020]   You know, let's just say a couple months and leave it at that.
[02:08:54.020 --> 02:08:55.020]   Holy cow.
[02:08:55.020 --> 02:08:56.020]   Yeah.
[02:08:56.020 --> 02:08:57.020]   Patrick.
[02:08:57.020 --> 02:08:58.020]   Patrick.
[02:08:58.020 --> 02:08:59.020]   Leo.
[02:08:59.020 --> 02:09:00.020]   Patrick.
[02:09:00.020 --> 02:09:01.020]   He's Leo.
[02:09:01.020 --> 02:09:06.700]   Yeah, I always thought you carried your life in your backpack, but this is ridiculous.
[02:09:06.700 --> 02:09:12.060]   Well, I do feel like a, you know, a snail with a rather large shell right now.
[02:09:12.060 --> 02:09:13.060]   Yeah.
[02:09:13.060 --> 02:09:14.060]   No kidding.
[02:09:14.060 --> 02:09:15.060]   Well, it's great.
[02:09:15.060 --> 02:09:16.300]   It's, are you in it now?
[02:09:16.300 --> 02:09:17.860]   Is that it right now that you're in?
[02:09:17.860 --> 02:09:18.860]   Yeah.
[02:09:18.860 --> 02:09:19.860]   Nice.
[02:09:19.860 --> 02:09:20.860]   Yeah.
[02:09:20.860 --> 02:09:22.140]   I'm in the slide out in the corner at the table.
[02:09:22.140 --> 02:09:28.940]   Hence the magnificent look we, we found the guy who designed all the Motel 6's in 1985,
[02:09:28.940 --> 02:09:31.300]   which apparently is how they design RV interiors.
[02:09:31.300 --> 02:09:34.300]   Where did you put the kids, the Husky and Sarah?
[02:09:34.300 --> 02:09:38.060]   Sarah is actually sitting across the table from the children are hitting their bunks right
[02:09:38.060 --> 02:09:39.060]   now.
[02:09:39.060 --> 02:09:40.060]   Oh, Sarah, or the dog.
[02:09:40.060 --> 02:09:41.060]   They're so quiet.
[02:09:41.060 --> 02:09:42.060]   They're so nice.
[02:09:42.060 --> 02:09:43.060]   Your kids are so good.
[02:09:43.060 --> 02:09:44.060]   Oh, don't worry.
[02:09:44.060 --> 02:09:45.060]   That'll change.
[02:09:45.060 --> 02:09:47.060]   Well, Patrick, I love you, man.
[02:09:47.060 --> 02:09:48.060]   I miss you.
[02:09:48.060 --> 02:09:49.060]   They did great.
[02:09:49.060 --> 02:09:54.700]   I hope you find a home somewhere out there.
[02:09:54.700 --> 02:09:57.020]   But it sounds like a really great, actually kind of a fun experience.
[02:09:57.020 --> 02:10:01.900]   I imagine by the time the kids have to go to school or something, you're going to, I
[02:10:01.900 --> 02:10:03.660]   don't know what, I don't know what you're doing.
[02:10:03.660 --> 02:10:04.660]   We have home school.
[02:10:04.660 --> 02:10:07.380]   Oh, well, Sarah's a very smart person.
[02:10:07.380 --> 02:10:08.380]   Yes, she is.
[02:10:08.380 --> 02:10:11.820]   And you could teach the kids how to solder.
[02:10:11.820 --> 02:10:17.140]   We were, actually referred to the name of our school is the, the North Island school
[02:10:17.140 --> 02:10:19.460]   poetry and power tools.
[02:10:19.460 --> 02:10:20.460]   Exactly right.
[02:10:20.460 --> 02:10:21.460]   Thank you.
[02:10:21.460 --> 02:10:23.420]   The kids need to be able to write an essay.
[02:10:23.420 --> 02:10:24.580]   They got to be able to do math.
[02:10:24.580 --> 02:10:29.420]   They have to understand history and it would be nice if they could operate wrenches and
[02:10:29.420 --> 02:10:30.580]   various and sundry other things.
[02:10:30.580 --> 02:10:32.260]   Again, a better education than I did.
[02:10:32.260 --> 02:10:33.260]   That's awesome.
[02:10:33.260 --> 02:10:35.820]   AV Excel.com for Patrick's podcast.
[02:10:35.820 --> 02:10:42.420]   And of course, every week with Sebastian Peake on this week in computer hardware.
[02:10:42.420 --> 02:10:43.420]   Thank you, Patrick.
[02:10:43.420 --> 02:10:44.420]   Great to see you.
[02:10:44.420 --> 02:10:45.420]   Thank you.
[02:10:45.420 --> 02:10:46.420]   Thanks for having me.
[02:10:46.420 --> 02:10:51.580]   He's my car guy and he's also apparently navigate researchers car guy.
[02:10:51.580 --> 02:10:54.020]   He's put some more and what's there.
[02:10:54.020 --> 02:10:59.060]   Also a great podcast, Wheel bearings at wheel bearings dot media.
[02:10:59.060 --> 02:11:03.780]   And I hope you're enjoying the beautiful warm weather in Detroit right now.
[02:11:03.780 --> 02:11:10.260]   Yeah, I would if we actually had some, but had to really bundle up to take Daisy for
[02:11:10.260 --> 02:11:11.260]   a walk today.
[02:11:11.260 --> 02:11:12.900]   Oh man.
[02:11:12.900 --> 02:11:13.900]   Great to see you.
[02:11:13.900 --> 02:11:16.580]   See you next week on the Tech Eye Show.
[02:11:16.580 --> 02:11:17.580]   Yep.
[02:11:17.580 --> 02:11:21.860]   And I'm actually heading out to San Francisco tomorrow for something fun.
[02:11:21.860 --> 02:11:29.180]   No, Cruz, Cruz Automation, the company, the GM owns his developing their autonomous driving
[02:11:29.180 --> 02:11:31.420]   system is having an event on Tuesday.
[02:11:31.420 --> 02:11:33.220]   To self driving something else.
[02:11:33.220 --> 02:11:35.340]   Yeah, maybe just go for a ride in something.
[02:11:35.340 --> 02:11:38.740]   Thank you also for your great assistance at CES.
[02:11:38.740 --> 02:11:43.700]   We really saw some fun things with you, including my next vehicle, I think.
[02:11:43.700 --> 02:11:44.700]   They must stay maki.
[02:11:44.700 --> 02:11:47.020]   That was a lot of fun to get that tour.
[02:11:47.020 --> 02:11:49.780]   That was fun doing that with you and really cool.
[02:11:49.780 --> 02:11:50.780]   Yeah.
[02:11:50.780 --> 02:11:52.100]   Thank you, Georgia Dow.
[02:11:52.100 --> 02:11:53.100]   I miss you.
[02:11:53.100 --> 02:11:59.220]   I hope everything's going well in Montreal now that you've relocated.
[02:11:59.220 --> 02:12:08.300]   Senior editor at iMore, owner of four, account on four VR rooms soon to have a wall size TV.
[02:12:08.300 --> 02:12:09.860]   Anxiety-videos.com.
[02:12:09.860 --> 02:12:11.380]   Anything else you want to mention?
[02:12:11.380 --> 02:12:13.620]   No, that's about it.
[02:12:13.620 --> 02:12:14.620]   Come back soon.
[02:12:14.620 --> 02:12:16.820]   Great to see you.
[02:12:16.820 --> 02:12:19.420]   I have a football game to watch.
[02:12:19.420 --> 02:12:22.020]   So I'm putting on my hard hat.
[02:12:22.020 --> 02:12:24.020]   If you didn't watch the video today, you missed.
[02:12:24.020 --> 02:12:31.340]   I look like a, I don't know, a padded gold LeMay construction worker, I think is.
[02:12:31.340 --> 02:12:34.980]   At the beginning of the video, you looked like you were a wrestler.
[02:12:34.980 --> 02:12:37.940]   I can, you know, I could do both.
[02:12:37.940 --> 02:12:42.260]   That would be a very strange combination, but it's possible.
[02:12:42.260 --> 02:12:47.500]   You do this show every Sunday afternoon, around 2.30 Pacific, 5.30 Eastern.
[02:12:47.500 --> 02:12:49.180]   That's 2.230 UTC.
[02:12:49.180 --> 02:12:51.180]   Oh, that is a weird combination.
[02:12:51.180 --> 02:12:52.980]   You're the newest member of the village people.
[02:12:52.980 --> 02:12:55.100]   I don't know what the hell that is.
[02:12:55.100 --> 02:12:59.260]   It looks like something out of a Stephen King nightmare.
[02:12:59.260 --> 02:13:03.180]   If you want to watch live, or listen live, twitter.tv/live, you can also join us in
[02:13:03.180 --> 02:13:04.180]   the studio like Pete did.
[02:13:04.180 --> 02:13:06.500]   All you have to do is email tickets to twitter.tv.
[02:13:06.500 --> 02:13:09.460]   We'll put a seat out for you.
[02:13:09.460 --> 02:13:14.740]   And of course, on demand versions of all of our shows available at our website, twit.tv
[02:13:14.740 --> 02:13:20.380]   or YouTube, or best thing to do, subscribe.
[02:13:20.380 --> 02:13:24.820]   In your favorite podcast application, that way you'll get the show the minute it's available.
[02:13:24.820 --> 02:13:28.020]   And plenty of time for your Monday morning commute.
[02:13:28.020 --> 02:13:29.020]   Thanks everybody.
[02:13:29.020 --> 02:13:30.020]   It's been great.
[02:13:30.020 --> 02:13:31.020]   We'll see you next time.
[02:13:31.020 --> 02:13:33.540]   Another twit is in the can.
[02:13:33.540 --> 02:13:40.540]   You scared me?
[02:13:41.540 --> 02:13:47.540]   You scared me.
[02:13:47.540 --> 02:13:54.540]   I'm tired.

