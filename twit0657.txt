
[00:00:00.000 --> 00:00:15.000]   It's time for Twit this week in Tech. Ben Johnson is here from WBUR and crew it from Tech Republic. Dan Patterson from CBS Interactive. We're gonna have a dad gum great show South by Southwest. We'll talk about Reddit.
[00:00:15.000 --> 00:00:28.000]   YL Amazon's Echo is laughing at me. Oh, it's laughing at you too. And the big Mario Day celebrations on Google Maps. It's all coming up next. On to it.
[00:00:28.000 --> 00:00:36.000]   Netcast you love. From people you trust.
[00:00:38.000 --> 00:00:47.000]   This is Twit. Bandwidth for this week in Tech is provided by CashFly at CACHEFLY.com.
[00:00:47.000 --> 00:01:01.000]   This is Twit. This week in Tech, episode 657 recorded Sunday, March 11th, 2018. Dad gum cell phone.
[00:01:02.000 --> 00:01:12.000]   This week in Tech is brought to you by FreshBooks, the easy to use cloud accounting software for small business owners. Try it free for 30 days at freshbooks.com/twit.
[00:01:12.000 --> 00:01:19.000]   And by 23andMe, a personal genetic service helping people understand their DNA.
[00:01:20.000 --> 00:01:38.000]   Buy your 23andMe kit today. Go to 23andMe.com/twit. And by the Ring Video Doorbell. Stop crying before it happens and help make your neighborhood safer. With Ring, go to Ring.com/twit and get up to $150 off a Ring of Security kit.
[00:01:39.000 --> 00:01:53.000]   And by WordPress, reach more customers when you build your business website on WordPress.com. Plan start at just $4 a month. Get 15% off any new plan purchase at WordPress.com/twit.
[00:01:56.000 --> 00:02:09.000]   It's time for Twit this week in Tech to show where we talk about the greatest news with the latest, greatest tech journalist, Dan Patterson is here. Great to have Dan on always senior writer at Tech Republic.
[00:02:09.000 --> 00:02:16.000]   And really ZDNet and CNet. I mean, he's all over CBS Interactive. Thank you for being here, Dan.
[00:02:16.000 --> 00:02:21.000]   Wonderful to be with you from Cold Brooklyn, New York.
[00:02:22.000 --> 00:02:31.000]   You got some snow this week, right? Yeah, yeah, we just got Ben. I think you're in Boston. We just got back from Boston and it looks like they got pounded by the nor Easter last week.
[00:02:31.000 --> 00:02:37.000]   I spend Johnson also joining us for WBUR. And you still do code breakers, right?
[00:02:37.000 --> 00:02:41.000]   Don't do code breaker, but I do a new show about Reddit called Endless Thread.
[00:02:41.000 --> 00:02:46.000]   That's you? Yeah, that's me. Nice. Yeah, yes, sir.
[00:02:47.000 --> 00:02:59.000]   Right. Well, there you go. The Brock Johnson, Ben Brock Johnson, Endless Thread is an NPR broadcast, well, WBUR and PR broadcast and Reddit is working with you on this, right?
[00:02:59.000 --> 00:03:10.000]   Yeah, there was a business agreement. We do all the editorial on our side, but they sort of give us some advice on how to get into the deep, you know, the deep threads as it were.
[00:03:11.000 --> 00:03:21.000]   We played, we tried to do a Reddit show for a while. I think Reddit is ripe for that. So I think, you know, I felt like, gosh, there's so much great content on Reddit.
[00:03:21.000 --> 00:03:34.000]   A lot of real people doing amazing stuff too, helping each other, but also like, you know, I mean, that whole, I mean, this year, Apple had to put out a press release basically because of Reddit, right? Right.
[00:03:35.000 --> 00:03:53.000]   All the time news breaks in red. In fact, increasingly, Reddit's become part of my regular beat check. You know, I go to Tech meme and I go to Reddit and a nozzle and, and I think Hacker News and those every single day and Reddit often is the best source of material for me.
[00:03:54.000 --> 00:04:03.000]   Before we go on down this line, let me say hello to Ant Pruitt, who is also with us from Tech Republic. Always a thrill to have the drone master on with us.
[00:04:03.000 --> 00:04:12.000]   You're too kind. He's definitely having me. I'm thinking that hashtag dominate shirt you're wearing is a little Clemson thing, right?
[00:04:12.000 --> 00:04:22.000]   Oh, no, that's just my daily mantra. I rise and dominate everything. It is an orange though. I mean, that is correct. Yeah.
[00:04:23.000 --> 00:04:30.000]   I'm just saying it looks like is there a paw print on the back there? I don't know. Not this time. Yeah.
[00:04:30.000 --> 00:04:40.000]   It's great to have all three of you here. We just got back yesterday. We were in Austin for South by Southwest Interactive started on Friday. It goes through Monday.
[00:04:40.000 --> 00:04:52.000]   I wish I could have spent more time there. I would have loved to. But we were there for a panel I did on Friday from the Capital One House with the Stacey Hagen-Botham and a couple of people.
[00:04:52.000 --> 00:05:00.000]   I'm a security expert on real world security for real people as opposed to all the sensational stuff you read. It was a lot of fun.
[00:05:00.000 --> 00:05:09.000]   And by the way, we did make a special out of that panel discussion. It was a really good panel discussion with Stacey Hagen-Botham, Bowwoods from We Are.
[00:05:09.000 --> 00:05:19.000]   I am the cavalry, which is a great site. And you can see that on our Twit Live specials feed. It's on YouTube, but also on our website, Twit.tv.
[00:05:20.000 --> 00:05:29.000]   It's a 328 practical security in a dangerous world. It was a really great conversation. I encourage you to download that. Add that to your feeds.
[00:05:29.000 --> 00:05:37.000]   None of you are at South by though. Is South by no longer the show for geeks? Or you just didn't get the airfare?
[00:05:37.000 --> 00:05:45.000]   I think we sent some tech republic people. We had a panel, but it was just not a...
[00:05:46.000 --> 00:05:55.000]   I think you said during the show open, it's a wonderful event, but it is not the place tech news or tech products happen anymore.
[00:05:55.000 --> 00:06:03.000]   So the value is a great value to attend, but the value to report breaking stuff is less than it used to be.
[00:06:03.000 --> 00:06:07.000]   And if you're a reporter, it's just pitch, pitch, pitch, pitch, pitch.
[00:06:07.000 --> 00:06:12.000]   Well, it became, I think, a marketing show, really. Even marketers don't go.
[00:06:15.000 --> 00:06:20.000]   The onion had a good... Let me see if I can find the onion headline from South by Southwest.
[00:06:20.000 --> 00:06:25.000]   It was funny. It's already squirreled.
[00:06:25.000 --> 00:06:29.000]   Very hashtag brands. Very hashtag brands.
[00:06:29.000 --> 00:06:35.000]   Something like South by Southwest is still real, says Junior Marketing.
[00:06:35.000 --> 00:06:43.000]   I mean, you know, it really... At the same time, Austin is such a great location.
[00:06:44.000 --> 00:06:51.000]   We were talking about the last app that got launched there. Of course, South by is where Twitter made its bones in 2006.
[00:06:51.000 --> 00:06:53.000]   Can you believe that 12 years ago?
[00:06:53.000 --> 00:06:58.000]   Wow. That's where... Four Square launched a couple of years later.
[00:06:58.000 --> 00:07:00.000]   What else?
[00:07:00.000 --> 00:07:05.000]   Four Square was '09. It was like bonkers, but a lot of fun.
[00:07:05.000 --> 00:07:10.000]   And then Ben was reminding me that Meerkat launched there a couple of years ago.
[00:07:11.000 --> 00:07:16.000]   So what are you going down, Ben, tomorrow?
[00:07:16.000 --> 00:07:23.000]   Yeah, I'm going down tomorrow and I'm just doing a Q&A. I'm actually doing an AMA for Reddit House.
[00:07:23.000 --> 00:07:29.000]   So I'm basically there to participate in the Reddit event that's happening on Tuesday
[00:07:29.000 --> 00:07:32.000]   and I'm going to talk to Steve Hoffman, the co-founder.
[00:07:32.000 --> 00:07:36.000]   So just going down there for a day or so in and out.
[00:07:36.000 --> 00:07:38.000]   But there's still stuff that happens there.
[00:07:39.000 --> 00:07:43.000]   Again, like you said, there's not as much product launches, but I think it's a good place.
[00:07:43.000 --> 00:07:47.000]   Obviously, you could throw a taco and hit a futurist, right?
[00:07:47.000 --> 00:07:50.000]   A lot of that going on.
[00:07:50.000 --> 00:07:54.000]   And some of that's better than other parts, but I think there's some good folks down there.
[00:07:54.000 --> 00:07:57.000]   There's great folks down there.
[00:07:57.000 --> 00:08:01.000]   Here's the "Onions" review.
[00:08:01.000 --> 00:08:05.000]   South by Southwest, as cool and as real as it gets, report "It's Marketing Associate".
[00:08:08.000 --> 00:08:11.000]   This is 2013, but it's true today. Let me tell you.
[00:08:11.000 --> 00:08:16.000]   We have the great Aaron Carson for CNET does offbeat or interesting tech.
[00:08:16.000 --> 00:08:19.000]   And she's doing great stuff down there.
[00:08:19.000 --> 00:08:22.000]   Team Maddox for Tech Republic is doing great B2B down there.
[00:08:22.000 --> 00:08:30.000]   It's just the there isn't the like sexy flashy anymore, but there is if you were interested in finding the stuff under the radar,
[00:08:30.000 --> 00:08:32.000]   there is still cool stuff there.
[00:08:32.000 --> 00:08:35.000]   Well, there was one thing that was a very hard ticket to get.
[00:08:36.000 --> 00:08:45.000]   I know somebody who did HBO took over two acres of land just outside of Austin to recreate Westworld.
[00:08:45.000 --> 00:08:50.000]   And we have a friend who went and visited.
[00:08:50.000 --> 00:08:52.000]   You had to apply for a ticket.
[00:08:52.000 --> 00:08:54.000]   Tickets were gone in two minutes.
[00:08:54.000 --> 00:08:56.000]   It's 20 minutes outside of Austin.
[00:08:56.000 --> 00:08:58.000]   You get on a bus.
[00:08:58.000 --> 00:09:00.000]   They give you a cowboy hat, white hat or black hat.
[00:09:00.000 --> 00:09:02.000]   You sign up.
[00:09:03.000 --> 00:09:07.000]   When you get there, there's a letter waiting for you with your name handwritten on it.
[00:09:07.000 --> 00:09:13.000]   There's a old railroad car with cowboys in it.
[00:09:13.000 --> 00:09:17.000]   There's a there's a speakeasy with ladies of the evening there.
[00:09:17.000 --> 00:09:21.000]   They've really recreated Westworld.
[00:09:21.000 --> 00:09:24.000]   And of course, it's all a promo for the next season of Westworld, which is coming.
[00:09:24.000 --> 00:09:27.000]   Although it's not Westworld this year.
[00:09:27.000 --> 00:09:30.000]   It's still gonna be called Westworld, but it's all it's the samurai world.
[00:09:30.000 --> 00:09:37.000]   And apparently there were some samurai sitting around in the bars at Westworld.
[00:09:37.000 --> 00:09:38.000]   This was the ticket to get.
[00:09:38.000 --> 00:09:40.000]   And so few people got it.
[00:09:40.000 --> 00:09:45.000]   You know, you'd had to really be connected to get in there, I guess, or just fast on the draw.
[00:09:45.000 --> 00:09:48.000]   But it looks like you're so scared to do that.
[00:09:48.000 --> 00:09:49.000]   Why?
[00:09:49.000 --> 00:09:49.000]   Why?
[00:09:49.000 --> 00:09:51.000]   You'd be afraid of getting sucked into Westworld?
[00:09:51.000 --> 00:09:56.000]   No, it's like I kind of like checked the bullets to make sure they're real and guns.
[00:09:56.000 --> 00:09:58.000]   Those robots who knows.
[00:09:58.000 --> 00:10:00.000]   You know what I mean?
[00:10:00.000 --> 00:10:01.000]   I'd be scared.
[00:10:01.000 --> 00:10:04.000]   It's actually it's really, really true.
[00:10:04.000 --> 00:10:06.000]   But that is really what it's become.
[00:10:06.000 --> 00:10:10.000]   We tried to get into here's some pictures.
[00:10:10.000 --> 00:10:11.000]   Let me see if ATX.
[00:10:11.000 --> 00:10:12.000]   Oh, no, he emailed them to him.
[00:10:12.000 --> 00:10:15.000]   ATX food guy was my friend who got in, John Kula.
[00:10:15.000 --> 00:10:16.000]   Nice.
[00:10:16.000 --> 00:10:18.000]   Yeah, I'm very jealous.
[00:10:18.000 --> 00:10:20.000]   He takes pictures of barbecue.
[00:10:20.000 --> 00:10:23.000]   Apparently didn't want to intermingle it with pictures of cowboys.
[00:10:23.000 --> 00:10:26.000]   So it's just smart man.
[00:10:26.000 --> 00:10:30.000]   It's all algorithmic.
[00:10:30.000 --> 00:10:33.000]   But what was I going to say?
[00:10:33.000 --> 00:10:36.000]   Oh, as for Reddit, you said Steve Hoffman, but not Alexis O'Haney.
[00:10:36.000 --> 00:10:39.000]   He's retired, hasn't he, from Reddit, the other founder?
[00:10:39.000 --> 00:10:41.000]   Yeah, he's sort of stepped away.
[00:10:41.000 --> 00:10:45.000]   I think he's going to be more involved and say that again.
[00:10:45.000 --> 00:10:47.000]   I think he's a VC now, isn't he?
[00:10:47.000 --> 00:10:48.000]   Yeah, yeah.
[00:10:48.000 --> 00:10:50.000]   So he's moving more into the VC world.
[00:10:50.000 --> 00:10:52.000]   At least that's what I read in the newspapers.
[00:10:52.000 --> 00:10:56.000]   And he's married to Serena Williams, so he's probably busy as well.
[00:10:56.000 --> 00:10:58.000]   He's Mr. Serena Williams now.
[00:10:58.000 --> 00:11:00.000]   Yeah, isn't that wild?
[00:11:00.000 --> 00:11:01.000]   Yeah, it's awesome.
[00:11:01.000 --> 00:11:02.000]   Salute.
[00:11:02.000 --> 00:11:04.000]   We have no kidding.
[00:11:04.000 --> 00:11:07.000]   Now that I'd be scared.
[00:11:07.000 --> 00:11:11.000]   She looks like she could kick your butt, frankly.
[00:11:11.000 --> 00:11:13.000]   In fact, she didn't look like it.
[00:11:13.000 --> 00:11:14.000]   She can kick you.
[00:11:14.000 --> 00:11:15.000]   She can.
[00:11:15.000 --> 00:11:18.000]   She can kick your butt, so he's going to be a good boy.
[00:11:18.000 --> 00:11:20.000]   Yeah, we've had both of them on triangulation.
[00:11:20.000 --> 00:11:25.000]   I remember he told me Steve Huffman wrote the original Reddit in LISP, and that kind of blew
[00:11:25.000 --> 00:11:26.000]   me away.
[00:11:26.000 --> 00:11:27.000]   I doubt it's still in LISP.
[00:11:27.000 --> 00:11:28.000]   Condi Nast is taking it away.
[00:11:28.000 --> 00:11:29.000]   I don't think so.
[00:11:29.000 --> 00:11:33.000]   You're doing a show about Reddit, which is really cool, Brock.
[00:11:33.000 --> 00:11:34.000]   I kind of gel a band.
[00:11:34.000 --> 00:11:40.000]   I'm kind of jealous because we tried to do a show about Reddit, but they felt like there
[00:11:40.000 --> 00:11:41.000]   was so much great content there.
[00:11:41.000 --> 00:11:43.000]   We just couldn't find a voice for it.
[00:11:43.000 --> 00:11:44.000]   Yeah.
[00:11:44.000 --> 00:11:46.000]   We couldn't figure out where to go with it.
[00:11:46.000 --> 00:11:50.000]   I think we just kind of -- we just was like a best of Reddit.
[00:11:50.000 --> 00:11:52.000]   But you're doing more than you're digging deep, right?
[00:11:52.000 --> 00:11:54.000]   I was just sitting by the phone and you could have called me.
[00:11:54.000 --> 00:11:55.000]   I know.
[00:11:55.000 --> 00:11:56.000]   Well, this was a few years ago.
[00:11:56.000 --> 00:11:57.000]   Yeah.
[00:11:57.000 --> 00:11:58.000]   No, it's a lot of fun.
[00:11:58.000 --> 00:12:04.000]   And it's really interesting to try to find stories and talk to people who really put stuff
[00:12:04.000 --> 00:12:05.000]   out there.
[00:12:05.000 --> 00:12:10.280]   I think sometimes it's a little complicated because one of the things that lets people
[00:12:10.280 --> 00:12:15.000]   share really openly on the platform is the anonymity.
[00:12:15.000 --> 00:12:21.000]   We've run into some of that, but we've also talked to people -- we had an episode a couple
[00:12:21.000 --> 00:12:31.000]   of weeks back where we talked to this guy who used a subreddit to recover from opiates,
[00:12:31.000 --> 00:12:33.000]   the opiates recovery subreddit.
[00:12:33.000 --> 00:12:34.000]   Wow.
[00:12:34.000 --> 00:12:38.000]   He was an aeronautics, I think, six or seven years, something like that.
[00:12:38.000 --> 00:12:44.000]   And he used Reddit to help himself get clean and to stay clean and stay sober.
[00:12:44.000 --> 00:12:48.000]   And so, there's some really interesting stories that you find.
[00:12:48.000 --> 00:12:52.640]   We did a story this week about this really weird -- someone was finding post-it notes in
[00:12:52.640 --> 00:12:53.640]   their house.
[00:12:53.640 --> 00:12:56.000]   It's a sort of famous Reddit story now or infamous.
[00:12:56.000 --> 00:12:59.000]   Someone was finding post-it notes in their house with weird messages.
[00:12:59.000 --> 00:13:03.000]   And they thought it was their landlord like creeping in their house.
[00:13:03.000 --> 00:13:09.000]   But another commenter said, "I think you have carbon dioxide poisoning or -- sorry, carbon
[00:13:09.000 --> 00:13:10.000]   monoxide poisoning."
[00:13:10.000 --> 00:13:11.000]   What?
[00:13:11.000 --> 00:13:13.000]   And it turned out they did supposedly.
[00:13:13.000 --> 00:13:15.000]   Because they were stoned on carbon monoxide.
[00:13:15.000 --> 00:13:19.000]   They thought they were seeing post-it notes, but they weren't.
[00:13:19.000 --> 00:13:22.000]   No, they were writing themselves post-it notes.
[00:13:22.000 --> 00:13:23.000]   Oh, my God.
[00:13:23.000 --> 00:13:24.000]   Yeah.
[00:13:24.000 --> 00:13:27.000]   Is that a symptom of carbon monoxide poisoning?
[00:13:27.000 --> 00:13:31.000]   You blackout, you do things, and then don't remember what you did.
[00:13:31.000 --> 00:13:36.000]   Yeah, you can become forgetful, you can hallucinate all sorts of things.
[00:13:36.000 --> 00:13:39.000]   So they saved this guy's life.
[00:13:39.000 --> 00:13:46.000]   Supposedly, it's interesting, the original commenter that this was happening to -- they
[00:13:46.000 --> 00:13:48.500]   sent us some messages, but they didn't want to talk to us.
[00:13:48.500 --> 00:13:51.240]   This is, again, the sort of anonymity thing.
[00:13:51.240 --> 00:13:56.240]   But we talked to an expert, and they set a bunch of things in the comments that we reported
[00:13:56.240 --> 00:13:57.240]   on.
[00:13:57.240 --> 00:13:58.240]   Wow.
[00:13:58.240 --> 00:14:01.880]   And we talked to the commenter who identified it as carbon dioxide poisoning.
[00:14:01.880 --> 00:14:04.400]   And this had happened to him.
[00:14:04.400 --> 00:14:05.960]   He lives on a boat in Seattle.
[00:14:05.960 --> 00:14:11.080]   This guy is an engineer who works for a company that makes parts for Boeing.
[00:14:11.080 --> 00:14:16.120]   And he almost killed himself and his wife and their dog on their boat by mistake one
[00:14:16.120 --> 00:14:18.520]   night leaving the stove on.
[00:14:18.520 --> 00:14:22.480]   And so he learned about carbon monoxide poisoning, which is why he left this comment.
[00:14:22.480 --> 00:14:24.960]   So these weird sort of connections in the comment sections.
[00:14:24.960 --> 00:14:28.960]   Well, now I'm worried because I keep hearing Alexa laughing.
[00:14:28.960 --> 00:14:34.960]   And I think maybe I have -- maybe I have carbon monoxide poisoning.
[00:14:34.960 --> 00:14:40.880]   Amazon says they know now why Amazon's echo was laughing.
[00:14:40.880 --> 00:14:45.080]   Although I thought what was most interesting about this story was not this.
[00:14:45.080 --> 00:14:50.320]   I mean, it's pretty obvious if you understand how computers work that the Amazon echo is
[00:14:50.320 --> 00:14:54.440]   not actually laughing at you.
[00:14:54.440 --> 00:14:59.040]   But people were reporting, "It sounds like a child's laughing somewhere else in my house.
[00:14:59.040 --> 00:15:00.520]   It just happens spontaneously."
[00:15:00.520 --> 00:15:04.160]   If you want to hear what it sounds like, I do have this from the New York Times article.
[00:15:04.160 --> 00:15:07.880]   This is Tal Goldfuss's Twitter feed.
[00:15:07.880 --> 00:15:08.880]   He was smart.
[00:15:08.880 --> 00:15:09.880]   He was clever.
[00:15:09.880 --> 00:15:10.880]   He heard the laugh.
[00:15:10.880 --> 00:15:16.080]   And he remembered that you could ask Echo to repeat the last sound you heard.
[00:15:16.080 --> 00:15:17.080]   So he's going to do that.
[00:15:17.080 --> 00:15:19.440]   I mean, let's get that video going here.
[00:15:19.440 --> 00:15:23.040]   Let's go play the last sound.
[00:15:23.040 --> 00:15:25.440]   Whoa.
[00:15:25.440 --> 00:15:28.240]   Just slightly creepy.
[00:15:28.240 --> 00:15:29.840]   It's a little creepy.
[00:15:29.840 --> 00:15:39.440]   But as it turns out, Amazon --
[00:15:39.440 --> 00:15:41.080]   Alexa played the last sound.
[00:15:41.080 --> 00:15:42.080]   Okay.
[00:15:42.080 --> 00:15:43.080]   Now mine's playing.
[00:15:43.080 --> 00:15:44.080]   Stop.
[00:15:44.080 --> 00:15:45.080]   Stop.
[00:15:45.080 --> 00:15:46.080]   Okay.
[00:15:46.080 --> 00:15:48.240]   I think I'm a carbon monoxide boy.
[00:15:48.240 --> 00:15:52.680]   Apparently Amazon added the capability to respond to echo laugh.
[00:15:52.680 --> 00:15:57.160]   I'm going to call it echo instead of the A word to not trigger people's stuff.
[00:15:57.160 --> 00:15:58.240]   Echo laugh.
[00:15:58.240 --> 00:15:59.520]   And that's such a short phrase.
[00:15:59.520 --> 00:16:03.680]   It was accidentally getting triggered easily.
[00:16:03.680 --> 00:16:08.560]   So now they've changed it to echo can you laugh?
[00:16:08.560 --> 00:16:10.600]   And it's actually terrible if you ask it.
[00:16:10.600 --> 00:16:12.840]   It goes, "Can I laugh?
[00:16:12.840 --> 00:16:14.240]   T-he.
[00:16:14.240 --> 00:16:16.040]   I prefer the creepy laugh."
[00:16:16.040 --> 00:16:20.600]   But what I find interesting, what I'd actually like to ask you guys about is this kind of -- all
[00:16:20.600 --> 00:16:25.800]   of a sudden there was this technopanic all over the Internet this week thinking that
[00:16:25.800 --> 00:16:28.400]   something creepy was going on with the echo.
[00:16:28.400 --> 00:16:34.880]   Like, somehow this is -- Jeff Bezos listening to you.
[00:16:34.880 --> 00:16:38.160]   This is a weird reaction to something that's just kind of obvious, right?
[00:16:38.160 --> 00:16:39.160]   Or no.
[00:16:39.160 --> 00:16:44.120]   Never mind the fact that you have a lot more creepy surveillance going on in your pocket
[00:16:44.120 --> 00:16:45.120]   as you walk around.
[00:16:45.120 --> 00:16:46.880]   Oh, thank you, Aunt Pruitt.
[00:16:46.880 --> 00:16:47.880]   Exactly.
[00:16:47.880 --> 00:16:48.880]   You're carrying the phone around.
[00:16:48.880 --> 00:16:49.880]   It's got a microphone.
[00:16:49.880 --> 00:16:50.880]   Who knows what it's listening to.
[00:16:50.880 --> 00:16:55.080]   In fact, if you really wanted to spy on somebody, you wouldn't make the echo laugh every once
[00:16:55.080 --> 00:16:56.080]   in a while.
[00:16:56.080 --> 00:16:57.080]   Right.
[00:16:57.080 --> 00:17:02.600]   I got to ask, what is the point of having that future built in?
[00:17:02.600 --> 00:17:06.360]   Is it just a little Easter egg Amazon thought people would enjoy?
[00:17:06.360 --> 00:17:09.680]   To make us answer Pemorphy's artificial intelligence.
[00:17:09.680 --> 00:17:10.680]   Maybe that's it.
[00:17:10.680 --> 00:17:12.920]   And in fact, it worked, right?
[00:17:12.920 --> 00:17:15.320]   Because people started assuming all sorts of stuff.
[00:17:15.320 --> 00:17:18.960]   And I think that we can see this as a signal in the noise.
[00:17:18.960 --> 00:17:22.600]   There is technopanic and some of it is hyperbolic and unnecessary.
[00:17:22.600 --> 00:17:30.160]   And some of it is a symptom of mainstream adoption of not just technology, but technology
[00:17:30.160 --> 00:17:32.880]   that happens and iterates very rapidly.
[00:17:32.880 --> 00:17:38.800]   And with things that we call AI, although it's not really artificial intelligence or
[00:17:38.800 --> 00:17:45.240]   machine learning, but consumer tools like Echo and all of our other listening things,
[00:17:45.240 --> 00:17:48.960]   I think that we were sold on the promise of these great devices and we can use them for
[00:17:48.960 --> 00:17:49.960]   great things.
[00:17:49.960 --> 00:17:53.760]   And there is also the after the fact, oh crap.
[00:17:53.760 --> 00:17:59.560]   And I think that a lot of people are not as tech savvy as we think that our peers are.
[00:17:59.560 --> 00:18:05.920]   And when we have this rapid iteration of gadgets and things that do improve our lives, there
[00:18:05.920 --> 00:18:07.720]   is blowback to that.
[00:18:07.720 --> 00:18:08.720]   Yeah.
[00:18:08.720 --> 00:18:12.720]   Somebody in the chat room says RF guys says the silly laugh feature distracts you from
[00:18:12.720 --> 00:18:15.480]   the real monitoring that's going on.
[00:18:15.480 --> 00:18:18.880]   That's what I was going to say because of the percents.
[00:18:18.880 --> 00:18:19.880]   Pay no attention.
[00:18:19.880 --> 00:18:20.880]   Yeah.
[00:18:20.880 --> 00:18:23.760]   It's to make us do so much to market.
[00:18:23.760 --> 00:18:24.760]   Yeah.
[00:18:24.760 --> 00:18:25.760]   No, keep going.
[00:18:25.760 --> 00:18:26.760]   Yeah.
[00:18:26.760 --> 00:18:27.760]   Yeah.
[00:18:27.760 --> 00:18:31.400]   Amazon is, you know, the real stuff that's happening is happening on the Echo too.
[00:18:31.400 --> 00:18:36.240]   Like Amazon is figuring out how to market you things all the time and try to get you
[00:18:36.240 --> 00:18:37.240]   to buy stuff.
[00:18:37.240 --> 00:18:40.080]   And that's the thing that's actually scary is that everybody has these things in their
[00:18:40.080 --> 00:18:41.080]   houses.
[00:18:41.080 --> 00:18:44.160]   And to me at least, everybody has these things in their houses and they're sort of like,
[00:18:44.160 --> 00:18:45.680]   oh, it's this cute little thing.
[00:18:45.680 --> 00:18:46.680]   I have in my house.
[00:18:46.680 --> 00:18:47.680]   It's kind of fun.
[00:18:47.680 --> 00:18:50.960]   It's not just the music on it, but really it's just trying to figure out how to separate
[00:18:50.960 --> 00:18:56.960]   you from your money, which is also interesting when you think about the fact that Amazon,
[00:18:56.960 --> 00:19:03.360]   you know, this Wall Street Journal report about the potential hybrid checking account
[00:19:03.360 --> 00:19:08.560]   thing, which is another interesting part of this.
[00:19:08.560 --> 00:19:13.600]   But I think the creepy laugh, I mean, that's just like, yeah, people shouldn't make a big
[00:19:13.600 --> 00:19:14.600]   deal about that.
[00:19:14.600 --> 00:19:18.680]   They should make a big deal about thinking about what this thing is actually doing in
[00:19:18.680 --> 00:19:24.000]   their house and what its main purpose is if they want to really get creeped out.
[00:19:24.000 --> 00:19:26.240]   Yeah, exactly right.
[00:19:26.240 --> 00:19:31.320]   If you actually really think about Jeff Bezos, who is clearly brilliant and is close, I mean,
[00:19:31.320 --> 00:19:35.720]   I don't know if he's an evil genius, but he's, if we have an evil genius, he's it.
[00:19:35.720 --> 00:19:38.720]   He's the richest man in the world now.
[00:19:38.720 --> 00:19:45.480]   And yeah, this is this is really interesting to watch as he puts Amazon's tentral tentacles
[00:19:45.480 --> 00:19:52.760]   into and tendrils into different areas like Amazon go, the store that has no clerks buying
[00:19:52.760 --> 00:19:58.880]   whole foods, buying the nest, sorry, ring video doorbell, one of our sponsors.
[00:19:58.880 --> 00:20:02.560]   And then you mentioned this checking account thing, which, you know, on any one of these
[00:20:02.560 --> 00:20:05.400]   on the face of it sounds like, well, that's just reasonable.
[00:20:05.400 --> 00:20:08.120]   The checking account, he's doing this with JP Morgan Chase.
[00:20:08.120 --> 00:20:12.880]   By the way, they have another partnership with JP Morgan for the Amazon health service for
[00:20:12.880 --> 00:20:19.280]   its employees ostensibly, but they want to do a checking account like product that Amazon
[00:20:19.280 --> 00:20:20.720]   could offer customers.
[00:20:20.720 --> 00:20:25.000]   It's they say for young people who don't yet have a checking account.
[00:20:25.000 --> 00:20:29.320]   I really wondered is what I bet here's what I thinks going on.
[00:20:29.320 --> 00:20:33.320]   I think Jeff, Jeff Bezos saying, okay, clearly checking accounts are over.
[00:20:33.320 --> 00:20:35.400]   Who writes checks?
[00:20:35.400 --> 00:20:38.560]   So what's going to replace it and how can we be in the middle of it?
[00:20:38.560 --> 00:20:43.160]   Because it's clear that Amazon's goal and I'm stealing this from Ben Thompson as a trajectory
[00:20:43.160 --> 00:20:49.520]   is to take a cut of all economic transactions that happen in the United States period.
[00:20:49.520 --> 00:20:50.520]   Yes.
[00:20:50.520 --> 00:20:52.680]   Every single one.
[00:20:52.680 --> 00:20:58.360]   Is that more of a look like the folks at what's that company stripe stripe does this?
[00:20:58.360 --> 00:20:59.360]   Yeah.
[00:20:59.360 --> 00:21:02.480]   Well, and every credit card company does in a way, right?
[00:21:02.480 --> 00:21:06.640]   But maybe the future of financial transactions isn't stripe.
[00:21:06.640 --> 00:21:08.480]   It's not Visa or MasterCard.
[00:21:08.480 --> 00:21:12.480]   Maybe it's more like Empesa in Africa where people don't have checking accounts.
[00:21:12.480 --> 00:21:18.280]   They don't have bank accounts, but all the financial transactions are handed on smartphones
[00:21:18.280 --> 00:21:26.120]   kind of like a Venmo or Stripe stripes cash.me and that becomes the bank.
[00:21:26.120 --> 00:21:32.360]   By the way, Empesa's made a lot of money as the middleman in the vast majority of economic
[00:21:32.360 --> 00:21:34.520]   transactions in many countries in Africa.
[00:21:34.520 --> 00:21:36.640]   I'm sure Amazon's thinking that, right?
[00:21:36.640 --> 00:21:39.240]   I mean, who wants a checking account nowadays?
[00:21:39.240 --> 00:21:40.640]   Yeah, absolutely.
[00:21:40.640 --> 00:21:47.720]   And this is one front in a multi-front battle for like Ben said, to separate you from your
[00:21:47.720 --> 00:21:48.720]   money.
[00:21:48.720 --> 00:21:54.960]   But we can see everyone getting in on games that take percentages of transactions.
[00:21:54.960 --> 00:21:57.000]   And Apple, of course, is doing this.
[00:21:57.000 --> 00:21:58.800]   Everyone is doing this.
[00:21:58.800 --> 00:22:04.600]   Stripe is one vertical, but we see this war happening all around.
[00:22:04.600 --> 00:22:05.960]   This is not a war for your money.
[00:22:05.960 --> 00:22:09.240]   This is a war for your mind share.
[00:22:09.240 --> 00:22:12.240]   And a small bit of every transaction.
[00:22:12.240 --> 00:22:13.240]   That's exactly right.
[00:22:13.240 --> 00:22:14.840]   We don't want your entire mind.
[00:22:14.840 --> 00:22:17.840]   We just want like two and a half percent on every thought.
[00:22:17.840 --> 00:22:18.840]   It's interesting.
[00:22:18.840 --> 00:22:22.760]   Walmart, according to the Wall Street Journal, attempted this about a decade ago and they
[00:22:22.760 --> 00:22:24.440]   got a lot of criticism.
[00:22:24.440 --> 00:22:28.920]   The Journal says from a range of companies and lawmakers.
[00:22:28.920 --> 00:22:34.160]   But you know, that's actually, let me make.
[00:22:34.160 --> 00:22:40.640]   So last fall, Amazon asked for pitches from several banks for a hybrid checking account.
[00:22:40.640 --> 00:22:41.960]   It's weighing pitches.
[00:22:41.960 --> 00:22:43.480]   So it's not necessarily a done deal.
[00:22:43.480 --> 00:22:48.880]   They're thinking about doing it with JP Morgan or Capital One, which was our sponsor at South
[00:22:48.880 --> 00:22:50.440]   by one of our sponsors.
[00:22:50.440 --> 00:22:54.480]   So it's not clear who's going to get this Capital One's a credit card company.
[00:22:54.480 --> 00:22:58.480]   JP Morgan has a variety of different things for JP.
[00:22:58.480 --> 00:23:03.200]   Amazon's partner is JP Morgan as well for the Amazon credit card.
[00:23:03.200 --> 00:23:04.200]   Oh, really?
[00:23:04.200 --> 00:23:05.200]   Oh, interesting.
[00:23:05.200 --> 00:23:06.200]   Okay.
[00:23:06.200 --> 00:23:07.200]   You know that.
[00:23:07.200 --> 00:23:16.320]   And also, I think something that's interesting here is Amazon gets to avoid some charges, right?
[00:23:16.320 --> 00:23:17.800]   In theory at least.
[00:23:17.800 --> 00:23:24.000]   If you have a checking account with Amazon/JP Morgan instead of Amazon, every time you want
[00:23:24.000 --> 00:23:28.280]   to move money from your regular checking account to Amazon to buy stuff, which you can also
[00:23:28.280 --> 00:23:33.560]   do, by the way, you can sort of bank cash in Amazon and then pay with, I think, Amazon
[00:23:33.560 --> 00:23:34.560]   cash.
[00:23:34.560 --> 00:23:35.560]   I forget what it's called.
[00:23:35.560 --> 00:23:39.280]   It's called like REAP or reload or something like that.
[00:23:39.280 --> 00:23:45.800]   Then Amazon doesn't have to pay the financial transaction fee for Amazon is also lower, I
[00:23:45.800 --> 00:23:46.800]   think.
[00:23:46.800 --> 00:23:50.240]   It's because you pay several percent on credit card transactions.
[00:23:50.240 --> 00:23:53.360]   So Amazon would love to just eliminate that.
[00:23:53.360 --> 00:23:58.160]   And this gives the company vision into transactions that are occurring not on Amazon.
[00:23:58.160 --> 00:23:59.160]   Oh.
[00:23:59.160 --> 00:24:00.160]   Right?
[00:24:00.160 --> 00:24:08.440]   This is one, I don't, this is one business that Capital One has been in for a long time.
[00:24:08.440 --> 00:24:11.680]   You know, they are a credit card company, but what they really do is see how and where
[00:24:11.680 --> 00:24:13.520]   consumer spending occurs.
[00:24:13.520 --> 00:24:20.040]   Wall Street Journal says Capital One is the number one user of Amazon's web services.
[00:24:20.040 --> 00:24:23.720]   They definitely got REAP.
[00:24:23.720 --> 00:24:24.720]   Very interesting.
[00:24:24.720 --> 00:24:25.720]   It's one of the-
[00:24:25.720 --> 00:24:29.080]   Well, that's like fast-fry people.
[00:24:29.080 --> 00:24:32.880]   I'm sorry, Ben, you're a little disadvantaged because Ben's hat got a lot of latency, I think,
[00:24:32.880 --> 00:24:33.880]   going on.
[00:24:33.880 --> 00:24:34.880]   So that's all right.
[00:24:34.880 --> 00:24:36.880]   Just when you start talking, keep talking and we'll shut up.
[00:24:36.880 --> 00:24:37.880]   Go ahead.
[00:24:37.880 --> 00:24:38.880]   Go ahead, Ben.
[00:24:38.880 --> 00:24:40.520]   Well, I was just, sorry about that.
[00:24:40.520 --> 00:24:46.560]   I was just going to say, I was just going to say that this is, again, not to get technophobic
[00:24:46.560 --> 00:24:51.200]   at all because none of us are clearly, except when we should be.
[00:24:51.200 --> 00:24:57.080]   But I think one of the interesting things about this is if you think about how typically
[00:24:57.080 --> 00:25:05.520]   you would interact with an older school financial company, at least in theory, they're pretty
[00:25:05.520 --> 00:25:12.280]   motivated to help you save or to help you do the things that you need to do as a financial,
[00:25:12.280 --> 00:25:13.880]   as an adult.
[00:25:13.880 --> 00:25:19.320]   And I think one thing that you have to think about here, again, this is all theoretical,
[00:25:19.320 --> 00:25:23.640]   but if you had a checking account with Amazon, you have to think about the possibility that
[00:25:23.640 --> 00:25:31.440]   Amazon starts to learn how you act right after you get paid, for instance.
[00:25:31.440 --> 00:25:34.160]   What do you buy right after you get it?
[00:25:34.160 --> 00:25:35.160]   Hugely fine.
[00:25:35.160 --> 00:25:36.160]   Yeah.
[00:25:36.160 --> 00:25:37.160]   What kind of bills are you paying?
[00:25:37.160 --> 00:25:38.800]   Are you getting toilet paper?
[00:25:38.800 --> 00:25:42.360]   And they talk about catering to the unbanked.
[00:25:42.360 --> 00:25:47.720]   So obviously, this means young people, but also potentially it means lower income households.
[00:25:47.720 --> 00:25:52.680]   And so I think there is a potential scary thing there where you think about Amazon basically
[00:25:52.680 --> 00:25:57.400]   really owning all of your financial behavior, at least understanding it in a way that allows
[00:25:57.400 --> 00:25:59.800]   them to then market things to you more effectively.
[00:25:59.800 --> 00:26:01.280]   How scary is that, though?
[00:26:01.280 --> 00:26:03.360]   I mean, I don't think that's that scary.
[00:26:03.360 --> 00:26:08.520]   Maybe your ads would be better targeted, but maybe there's a synergy of having Amazon be
[00:26:08.520 --> 00:26:11.240]   both my retailer and my banker.
[00:26:11.240 --> 00:26:13.360]   I mean, maybe there's advantages to that.
[00:26:13.360 --> 00:26:16.640]   You know, maybe banking costs less.
[00:26:16.640 --> 00:26:20.600]   I think there could be maybe the goods cost less because you're eliminating the two and
[00:26:20.600 --> 00:26:24.000]   a half percent markup that the bank charges for credit card charges.
[00:26:24.000 --> 00:26:25.000]   Yeah.
[00:26:25.000 --> 00:26:26.160]   There could be valuable.
[00:26:26.160 --> 00:26:31.480]   If, I mean, what I'm thinking about is this is, it seems to me that we do need to reinvent
[00:26:31.480 --> 00:26:35.760]   the financial system because the whole idea of a bank is kind of based on the notion that
[00:26:35.760 --> 00:26:41.840]   you would go there with actual money and they would hold it for you and then you could
[00:26:41.840 --> 00:26:42.880]   go and take it out.
[00:26:42.880 --> 00:26:49.080]   It's a safe deposit box, and you can go and take it out and then eventually checks came
[00:26:49.080 --> 00:26:50.080]   along.
[00:26:50.080 --> 00:26:55.160]   And so instead of taking money and using it, you could write an IOU in effect that the
[00:26:55.160 --> 00:26:58.960]   bank would make good on and that system grew.
[00:26:58.960 --> 00:27:04.160]   When credit cards came along that were basically completely separate from the bank, you transfer
[00:27:04.160 --> 00:27:09.520]   bits of money out of the bank into the credit card as you paid the credit card and then
[00:27:09.520 --> 00:27:11.200]   transfer stuff from the credit card.
[00:27:11.200 --> 00:27:16.640]   This is a kind of a crazy system that grew like Topsy over a century or two that doesn't
[00:27:16.640 --> 00:27:22.240]   really make any sense in the modern age where you don't have stuff piles of cash to bring
[00:27:22.240 --> 00:27:23.440]   to the bank.
[00:27:23.440 --> 00:27:26.600]   All you have is bits.
[00:27:26.600 --> 00:27:29.880]   Is it safe to count out Walmart in this stuff?
[00:27:29.880 --> 00:27:30.880]   I don't think so.
[00:27:30.880 --> 00:27:34.280]   I think it was pretty bad going powerful.
[00:27:34.280 --> 00:27:35.280]   Everybody shops there.
[00:27:35.280 --> 00:27:39.360]   I don't care how much money you don't make or how much money you do make.
[00:27:39.360 --> 00:27:45.080]   You shop at Walmart for whatever reason and they're always trying to figure out a way
[00:27:45.080 --> 00:27:46.680]   to keep you coming back.
[00:27:46.680 --> 00:27:53.240]   And then you mentioned this stuff about the Walmart pay and their little checking ideas
[00:27:53.240 --> 00:27:54.240]   and whatnot.
[00:27:54.240 --> 00:27:56.080]   And I wouldn't count them out.
[00:27:56.080 --> 00:28:00.120]   We really thought when Apple created Apple Pay that the next step was for Apple was to
[00:28:00.120 --> 00:28:05.080]   create a bank that I think a lot of us thought, "Oh, that's Apple's long-term goal."
[00:28:05.080 --> 00:28:09.560]   I think they didn't maybe for regulatory reasons, not because they didn't think about this.
[00:28:09.560 --> 00:28:13.760]   I'm sure the minute if Walmart hadn't already been thinking about it, as soon as they saw
[00:28:13.760 --> 00:28:17.720]   this headline in the Wall Street Journal, they said, "Oh, yeah, we got to do that because
[00:28:17.720 --> 00:28:23.040]   anything Amazon does, Walmart's got to compete against."
[00:28:23.040 --> 00:28:24.040]   Yeah.
[00:28:24.040 --> 00:28:25.400]   Walmart's been in this game for a long time.
[00:28:25.400 --> 00:28:29.640]   In fact, their employees used to be able to exchange your paycheck for goods and services
[00:28:29.640 --> 00:28:30.640]   of Walmart.
[00:28:30.640 --> 00:28:31.640]   Yeah.
[00:28:31.640 --> 00:28:32.640]   Yeah.
[00:28:32.640 --> 00:28:33.640]   Oh, my soul to the company's soul.
[00:28:33.640 --> 00:28:34.640]   Yeah, exactly.
[00:28:34.640 --> 00:28:41.480]   So, I mean, if we were to start from scratch and rethink this banking system, I don't think
[00:28:41.480 --> 00:28:43.200]   we would design it this way.
[00:28:43.200 --> 00:28:45.560]   This is more something we've inherited.
[00:28:45.560 --> 00:28:46.920]   We would do something completely different.
[00:28:46.920 --> 00:28:48.720]   And maybe blockchain has a role in here.
[00:28:48.720 --> 00:28:50.440]   Do you think blockchain has a role?
[00:28:50.440 --> 00:28:52.360]   A distributed ledger system?
[00:28:52.360 --> 00:28:53.360]   Yeah.
[00:28:53.360 --> 00:28:58.080]   It will have to be a different type of blockchain, or it will have to be an optimized or a faster
[00:28:58.080 --> 00:29:00.080]   moving blockchain.
[00:29:00.080 --> 00:29:04.720]   The blockchains that we have now are simply they can't process transactions at high scale
[00:29:04.720 --> 00:29:09.440]   fast enough, but the blockchain is a technological solution.
[00:29:09.440 --> 00:29:14.280]   Oh, your microphone just switched off from whatever it was to something else.
[00:29:14.280 --> 00:29:16.120]   That was weird.
[00:29:16.120 --> 00:29:17.120]   Here's...
[00:29:17.120 --> 00:29:18.120]   Okay.
[00:29:18.120 --> 00:29:23.880]   And this conversation needs free people to understand what blockchain is and why blockchain
[00:29:23.880 --> 00:29:24.880]   is a solution.
[00:29:24.880 --> 00:29:27.440]   Blockchain is a ledger, a distributed ledger, right?
[00:29:27.440 --> 00:29:28.440]   So what is a bank doing?
[00:29:28.440 --> 00:29:29.440]   Really?
[00:29:29.440 --> 00:29:30.440]   Bank is just a ledger, right?
[00:29:30.440 --> 00:29:31.440]   You bring them the money.
[00:29:31.440 --> 00:29:34.980]   Now they say you have this much money on account, and you can then have them pay that money
[00:29:34.980 --> 00:29:36.360]   on account to somebody else.
[00:29:36.360 --> 00:29:39.400]   If you overdraw it, you pay out more money than you have.
[00:29:39.400 --> 00:29:41.720]   They come to you and say, give us some more money.
[00:29:41.720 --> 00:29:44.440]   It's a ledger system, but it's centralized.
[00:29:44.440 --> 00:29:50.280]   But if this ledger system were decentralized using a blockchain like system that is more
[00:29:50.280 --> 00:29:51.720]   reliable, you're right.
[00:29:51.720 --> 00:29:53.080]   There's big problems with Bitcoin.
[00:29:53.080 --> 00:29:56.600]   I mean, the transaction speed and the transaction cost is at a...
[00:29:56.600 --> 00:29:58.760]   You know, it takes forever and it's at a control.
[00:29:58.760 --> 00:29:59.920]   I just got...
[00:29:59.920 --> 00:30:00.920]   I do...
[00:30:00.920 --> 00:30:01.920]   I use...
[00:30:01.920 --> 00:30:06.360]   This is kind of completely out of left view, but I use a service called Keybase to distribute
[00:30:06.360 --> 00:30:20.080]   the contract, I mean, distribute my PGP keys.
[00:30:20.080 --> 00:30:24.080]   They have just announced that they are being funded by Stellar, which is a new cryptocurrency.
[00:30:24.080 --> 00:30:25.080]   Stellar is lumens.
[00:30:25.080 --> 00:30:26.080]   And they believe...
[00:30:26.080 --> 00:30:29.080]   I mean, is this somebody else I need to be pissed off about?
[00:30:29.080 --> 00:30:32.080]   I mean, is this somebody else I need to be pissed off about?
[00:30:32.080 --> 00:30:36.640]   No, you can...
[00:30:36.640 --> 00:30:37.800]   Stellar is really...
[00:30:37.800 --> 00:30:42.080]   I never heard of them until I got this email from Keybase.
[00:30:42.080 --> 00:30:49.920]   But Stellar is essentially a blockchain system that's designed to avoid the problems Bitcoin
[00:30:49.920 --> 00:30:56.560]   has by reducing the cost of transactions, making transactions take seconds instead of
[00:30:56.560 --> 00:31:02.040]   what is almost days now, allowing micro payments, which is a big thing that we've
[00:31:02.040 --> 00:31:07.080]   all wanted for a long time and could save journalism.
[00:31:07.080 --> 00:31:08.280]   I had never heard of this.
[00:31:08.280 --> 00:31:09.560]   I don't know anything about it.
[00:31:09.560 --> 00:31:10.920]   I haven't done that much research.
[00:31:10.920 --> 00:31:13.520]   I've just read up on it.
[00:31:13.520 --> 00:31:15.360]   But this is very interesting.
[00:31:15.360 --> 00:31:16.880]   I do trust the guys at Keybase.
[00:31:16.880 --> 00:31:19.800]   They're very smart and they're well motivated.
[00:31:19.800 --> 00:31:22.160]   It's an open source project.
[00:31:22.160 --> 00:31:27.960]   And they say that Stellar can fulfill Bitcoin's original goal of fast, cheap, worldwide payments
[00:31:27.960 --> 00:31:31.120]   without a centralized bank.
[00:31:31.120 --> 00:31:32.960]   You have to get rid of those transaction fees.
[00:31:32.960 --> 00:31:38.640]   That's the thing that's killing all blockchains right now, are transaction fees and the relative
[00:31:38.640 --> 00:31:41.040]   slow speed.
[00:31:41.040 --> 00:31:45.760]   Oftentimes a transaction fee can cost as much if not more than the item or good that you
[00:31:45.760 --> 00:31:46.760]   are purchasing.
[00:31:46.760 --> 00:31:49.040]   For Bitcoin, it's over $20 for many transactions.
[00:31:49.040 --> 00:31:53.120]   Yeah, I think on Ethereum, it's even higher than that.
[00:31:53.120 --> 00:31:54.120]   So this is what...
[00:31:54.120 --> 00:31:56.760]   Now again, I'm being uncritical.
[00:31:56.760 --> 00:32:01.080]   And mostly because I know that Keybase guys, and I trust the Keybase guys, they say that
[00:32:01.080 --> 00:32:07.840]   Lumens, the currency of Stellar transaction feezers, is basically zero, a tiny fraction
[00:32:07.840 --> 00:32:12.320]   of a penny, and will scale to far more transactions in Bitcoin.
[00:32:12.320 --> 00:32:17.880]   It is fast, the average ledger time on Stellar is 4.74 seconds, and they're planning to make
[00:32:17.880 --> 00:32:21.640]   it even faster.
[00:32:21.640 --> 00:32:25.400]   And this is a really...
[00:32:25.400 --> 00:32:26.560]   Maybe they're just altruistic.
[00:32:26.560 --> 00:32:28.280]   I mean, Keybase is a free service.
[00:32:28.280 --> 00:32:29.920]   It's been free for a couple of years.
[00:32:29.920 --> 00:32:32.240]   I use it all the time.
[00:32:32.240 --> 00:32:37.280]   It's a good question to ask, and let's put it that way.
[00:32:37.280 --> 00:32:39.280]   Here's really an interesting point.
[00:32:39.280 --> 00:32:45.080]   Bitcoin now consumes as much electricity as Portugal, about a 500th of all electricity
[00:32:45.080 --> 00:32:46.880]   in the world.
[00:32:46.880 --> 00:32:47.880]   Wow.
[00:32:47.880 --> 00:32:53.600]   This is from both mining and transactions because Bitcoin requires proof of work for
[00:32:53.600 --> 00:32:54.600]   transactions.
[00:32:54.600 --> 00:33:00.360]   Proof of work, that proof of work takes electricity, takes computation.
[00:33:00.360 --> 00:33:01.840]   And this is what's really scary.
[00:33:01.840 --> 00:33:07.160]   The Bitcoin use of power has climbed 400% in the last year.
[00:33:07.160 --> 00:33:12.040]   At this rate, Bitcoin will soon use more electricity in the entire US.
[00:33:12.040 --> 00:33:14.160]   So is the price of consumer GPUs?
[00:33:14.160 --> 00:33:15.160]   Yeah.
[00:33:15.160 --> 00:33:19.040]   Yeah, and you can't buy a GPU anymore.
[00:33:19.040 --> 00:33:21.800]   Not happy about that.
[00:33:21.800 --> 00:33:26.640]   So Stellar Protocol, now here's one more reason to think about Stellar.
[00:33:26.640 --> 00:33:32.440]   The Stellar Protocol is behind Moxie Marlin Spike, the guy who created Signal's new mobile
[00:33:32.440 --> 00:33:33.440]   coin.
[00:33:33.440 --> 00:33:38.440]   Kick is switching from Ethereum to Stellar.
[00:33:38.440 --> 00:33:40.520]   So I'm very intrigued by this.
[00:33:40.520 --> 00:33:42.080]   I trust Moxie.
[00:33:42.080 --> 00:33:43.920]   I trust the Keybase folks.
[00:33:43.920 --> 00:33:47.640]   I think this is very interesting.
[00:33:47.640 --> 00:33:53.440]   So I don't know, go to keybase.io's blog and you can read up on Stellar.
[00:33:53.440 --> 00:33:54.440]   It's brand new to me.
[00:33:54.440 --> 00:33:56.200]   I thought it was very interesting.
[00:33:56.200 --> 00:33:58.760]   And I think this is the reason I bring it up.
[00:33:58.760 --> 00:34:06.720]   I think this might be the antidote to Amazon or Apple or Walmart saying, no, we want to
[00:34:06.720 --> 00:34:14.040]   own all the transactions because blockchain transactions are fundamentally anonymous, right?
[00:34:14.040 --> 00:34:16.040]   So you preserve your privacy.
[00:34:16.040 --> 00:34:20.640]   If it's done well, they're decentralized and they're fast and they're effective.
[00:34:20.640 --> 00:34:23.000]   Maybe we don't need a centralized banking system.
[00:34:23.000 --> 00:34:25.960]   Maybe we don't need Amazon.
[00:34:25.960 --> 00:34:31.160]   This really reminds me of, do you remember a year or two after the launch of the App Store
[00:34:31.160 --> 00:34:37.640]   and we had conversations about Wald Gardens and the web going from open distribution stuff
[00:34:37.640 --> 00:34:44.160]   like XML and other in RSS to app-based models and Wald Garden Worlds?
[00:34:44.160 --> 00:34:49.840]   Which feels like that era for financial transactions or for FinTech?
[00:34:49.840 --> 00:34:50.840]   Yes.
[00:34:50.840 --> 00:34:55.240]   And it all comes down to, I think, just rethinking how this works.
[00:34:55.240 --> 00:35:02.560]   There's a lot of overhead and slop in this system because it's just evolved from 100
[00:35:02.560 --> 00:35:04.680]   years ago that doesn't need to be there.
[00:35:04.680 --> 00:35:08.280]   It could be much, I think, it could be much more efficient, faster.
[00:35:08.280 --> 00:35:12.240]   And I think it's really important to think of solutions that do, if privacy is an issue
[00:35:12.240 --> 00:35:13.240]   for you.
[00:35:13.240 --> 00:35:19.280]   You know, cash was private, but nobody does cash anymore.
[00:35:19.280 --> 00:35:23.840]   And by the way, we've seen some evidence that it's possible perhaps to break through the
[00:35:23.840 --> 00:35:26.520]   anonymity of Bitcoin as well.
[00:35:26.520 --> 00:35:30.400]   I think that was a recent story about hackers.
[00:35:30.400 --> 00:35:35.960]   If that's the case, that's really going to be interesting.
[00:35:35.960 --> 00:35:44.000]   So I think a solution that is anonymous that preserves your privacy, that is efficient,
[00:35:44.000 --> 00:35:46.840]   that would be very interesting.
[00:35:46.840 --> 00:35:52.840]   I think I'm just going to keep burying gold in the backyard.
[00:35:52.840 --> 00:35:55.240]   Good luck finding somebody will take it.
[00:35:55.240 --> 00:35:56.240]   Seriously.
[00:35:56.240 --> 00:35:57.240]   Or just invest in Nvidia.
[00:35:57.240 --> 00:36:03.240]   Seriously, if you had a bunch of gold, let's say you have a thousand gold coins worth
[00:36:03.240 --> 00:36:05.040]   a lot of money.
[00:36:05.040 --> 00:36:06.040]   Yeah.
[00:36:06.040 --> 00:36:07.720]   Where do you do with them?
[00:36:07.720 --> 00:36:10.720]   Take it to the guys.
[00:36:10.720 --> 00:36:14.960]   As wounds and trade it for the wounds and then that gets it to the guys.
[00:36:14.960 --> 00:36:21.440]   The other thing and then it's not exactly a frictionless currency anymore.
[00:36:21.440 --> 00:36:26.000]   I mean, there are people buy gold, but I don't know if that's a good way to do it.
[00:36:26.000 --> 00:36:29.320]   Yeah, I was going to say to pawn shop, but then they would just try to cheat me.
[00:36:29.320 --> 00:36:30.320]   Yeah.
[00:36:30.320 --> 00:36:34.040]   I don't think gold is as liquid as you think it is.
[00:36:34.040 --> 00:36:38.480]   I wonder, 10 years from now we're going to look back on this and I wonder if either
[00:36:38.480 --> 00:36:44.080]   we'll be dealing with a chaos that's been created by multiple cryptocurrencies, ICOs,
[00:36:44.080 --> 00:36:48.640]   rampant fraud, all of which is kind of what it looks like today or if some of this, some
[00:36:48.640 --> 00:36:50.580]   sense will be made out of all of this.
[00:36:50.580 --> 00:36:55.360]   This is the problem is that government is just out of the picture, right?
[00:36:55.360 --> 00:36:58.320]   Normally you would expect government to get involved.
[00:36:58.320 --> 00:36:59.720]   Nobody trusts the government.
[00:36:59.720 --> 00:37:03.240]   The government doesn't seem to want to do anything about these kinds of things and frankly
[00:37:03.240 --> 00:37:05.160]   they're not sophisticated enough.
[00:37:05.160 --> 00:37:10.400]   They are stuck in the 19th century with the current financial system is.
[00:37:10.400 --> 00:37:15.320]   Although the government is, there's some interesting things happening.
[00:37:15.320 --> 00:37:20.440]   I think even at a governmental level, I mean, I went to an MIT blockchain conference, I
[00:37:20.440 --> 00:37:27.560]   think last year now, last summer maybe it was and the federal reserve, the head of the
[00:37:27.560 --> 00:37:34.280]   Boston Federal Reserve was there talking about how cryptocurrencies could kind of change,
[00:37:34.280 --> 00:37:41.840]   make the process of paying, buying a house easier and I'm not an expert in this.
[00:37:41.840 --> 00:37:48.280]   But I do think that there are some people like in the government who are slowly becoming
[00:37:48.280 --> 00:37:53.200]   hit to this and I think interested enough that we might see some real solutions.
[00:37:53.200 --> 00:37:56.320]   I don't know, maybe that'll be 100 years from now.
[00:37:56.320 --> 00:38:00.200]   I feel like real estate is huge for blockchain.
[00:38:00.200 --> 00:38:01.200]   Real estate.
[00:38:01.200 --> 00:38:05.200]   What's really going to matter is if I can buy snacks, I need crypto snacks, not crypto
[00:38:05.200 --> 00:38:06.200]   cats.
[00:38:06.200 --> 00:38:09.520]   No, if I can't buy a hot dog with it, what good is it?
[00:38:09.520 --> 00:38:10.520]   I need it.
[00:38:10.520 --> 00:38:12.080]   I'm joking but kind of not.
[00:38:12.080 --> 00:38:14.040]   We need crypto snacks.
[00:38:14.040 --> 00:38:17.640]   Well, again, this thing that's stellar is kind of interesting because it does have such
[00:38:17.640 --> 00:38:24.000]   low transaction fees, it conceivably could be used for micro payments or certainly $5
[00:38:24.000 --> 00:38:25.000]   hot dogs.
[00:38:25.000 --> 00:38:27.920]   Hot dog cost in Brooklyn now.
[00:38:27.920 --> 00:38:28.920]   Maybe $5.
[00:38:28.920 --> 00:38:29.920]   Yeah.
[00:38:29.920 --> 00:38:30.920]   $7.
[00:38:30.920 --> 00:38:31.920]   That include relish.
[00:38:31.920 --> 00:38:33.720]   That's an extra $4.50.
[00:38:33.720 --> 00:38:39.080]   But the bidet don't be composted.
[00:38:39.080 --> 00:38:43.640]   So but I guess what I was about to say is if it's not government, then the next place
[00:38:43.640 --> 00:38:49.000]   people will look is corporations, right?
[00:38:49.000 --> 00:38:51.360]   What is the alternative?
[00:38:51.360 --> 00:38:55.920]   Can you covered anonymous?
[00:38:55.920 --> 00:39:01.240]   Wall Street occupy Wall Street protests for a long time.
[00:39:01.240 --> 00:39:05.520]   If you say, well, I don't want it to be government, I don't want it to be banks.
[00:39:05.520 --> 00:39:07.040]   Well, then I don't want to be Amazon.
[00:39:07.040 --> 00:39:08.040]   Well, then who?
[00:39:08.040 --> 00:39:12.680]   Well, I think Ben brings Ben covers similar stuff in cyber.
[00:39:12.680 --> 00:39:16.160]   And I think that what we'll see is kind of a bifurcation of worlds.
[00:39:16.160 --> 00:39:23.360]   You will see corporate entities like Amazon, Walmart, Apple, and all of our other favorite
[00:39:23.360 --> 00:39:24.960]   big tech companies in on the game.
[00:39:24.960 --> 00:39:29.480]   And then you'll see the crypto community, the Reddit communities and those who don't
[00:39:29.480 --> 00:39:37.560]   want to have their transactions in that world might gravitate towards cryptocurrency might.
[00:39:37.560 --> 00:39:42.280]   I'm still pretty bearish on cryptocurrency, but the blockchain represents so much more
[00:39:42.280 --> 00:39:43.440]   potential.
[00:39:43.440 --> 00:39:44.640]   It feels like there's something there.
[00:39:44.640 --> 00:39:47.600]   It's clear Bitcoin at this point is a failure.
[00:39:47.600 --> 00:39:50.960]   I know people are going to flame me for that.
[00:39:50.960 --> 00:39:52.600]   But I'm bullish on Dogecoin.
[00:39:52.600 --> 00:39:54.480]   I'm going on Dogecoin.
[00:39:54.480 --> 00:39:58.520]   We're all in on Dogecoin here too, Ben.
[00:39:58.520 --> 00:39:59.520]   Yeah, Dogecoin.
[00:39:59.520 --> 00:40:00.520]   Go Dogecoin.
[00:40:00.520 --> 00:40:03.640]   I think how much Dogecoin does Father Robert have?
[00:40:03.640 --> 00:40:04.960]   I think it's a lot.
[00:40:04.960 --> 00:40:05.960]   Millions.
[00:40:05.960 --> 00:40:06.960]   Yeah.
[00:40:06.960 --> 00:40:07.960]   Yeah.
[00:40:07.960 --> 00:40:08.960]   Three million Dogecoin.
[00:40:08.960 --> 00:40:10.400]   Yes, three million Dogecoin.
[00:40:10.400 --> 00:40:12.960]   So we're all betting on Dogecoin.
[00:40:12.960 --> 00:40:13.960]   Yeah.
[00:40:13.960 --> 00:40:18.120]   It's it's it's an interesting future.
[00:40:18.120 --> 00:40:22.440]   I would I think we need to learn more about finance and what this is what's happening
[00:40:22.440 --> 00:40:27.640]   here because there's clearly some convergence of forces here and maybe maybe it'll be the
[00:40:27.640 --> 00:40:29.600]   Bank of China for all we know.
[00:40:29.600 --> 00:40:32.920]   I don't know what's going to maybe maybe let's take a break.
[00:40:32.920 --> 00:40:33.920]   We're going to talk some more.
[00:40:33.920 --> 00:40:34.920]   We've got Ben Johnson here.
[00:40:34.920 --> 00:40:35.920]   He's from WBUR.
[00:40:35.920 --> 00:40:38.280]   He's a senior producer there.
[00:40:38.280 --> 00:40:42.400]   Ben does some that this new show on Reddit, which is awesome.
[00:40:42.400 --> 00:40:43.400]   What's that call again?
[00:40:43.400 --> 00:40:48.320]   Thread thread bear endless endless thread and this thread thread bear might have been
[00:40:48.320 --> 00:40:49.320]   good too.
[00:40:49.320 --> 00:40:50.320]   Thread bear.
[00:40:50.320 --> 00:40:55.000]   Think about that's the that's the adult Reddit threads.
[00:40:55.000 --> 00:40:57.720]   That's that's our budget and there's a representation.
[00:40:57.720 --> 00:41:01.920]   Well, also I've had for the great aunt Pruitt here.
[00:41:01.920 --> 00:41:05.160]   He is a great photographer writer at Tech Republic.
[00:41:05.160 --> 00:41:07.760]   I bet you have a podcast or two, don't you?
[00:41:07.760 --> 00:41:13.440]   Well, I did at one point in time and now I just guest appear someday everyone will have
[00:41:13.440 --> 00:41:14.440]   a podcast.
[00:41:14.440 --> 00:41:16.320]   Well, we love having you on it.
[00:41:16.320 --> 00:41:21.200]   It's great to have you and Dan Patterson, who is also at CBS Interactive Senior Writer
[00:41:21.200 --> 00:41:23.320]   at Tech Republic in ZDNet.
[00:41:23.320 --> 00:41:26.640]   He also contributes to CNET and great to have all three of you here.
[00:41:26.640 --> 00:41:28.480]   Thank you for for joining us today.
[00:41:28.480 --> 00:41:33.280]   Our show brought to you by FreshBooks, a great solution for anybody.
[00:41:33.280 --> 00:41:38.600]   This is this is an interesting step forward in making money make sense.
[00:41:38.600 --> 00:41:43.840]   If you're a small business or a freelancer, you know, come the end of the month, you've
[00:41:43.840 --> 00:41:46.880]   got to do that chore called sending out the invoices.
[00:41:46.880 --> 00:41:48.640]   We've all done it and it's a pain.
[00:41:48.640 --> 00:41:53.000]   You fire up Excel, you fire up Word, you get the invoice, you print it out, you put it
[00:41:53.000 --> 00:41:57.840]   in an envelope, you stamp it, you mail it and you hope you pray that you will get paid.
[00:41:57.840 --> 00:42:01.120]   In some cases in 30, 60, 90 days.
[00:42:01.120 --> 00:42:03.480]   I got a better way.
[00:42:03.480 --> 00:42:07.480]   In fact, the way I used for a long time, I was suffering through all this.
[00:42:07.480 --> 00:42:12.600]   When I used to go up to Canada to do call for help in the Toronto and I was complaining
[00:42:12.600 --> 00:42:15.640]   to Amber MacArthur, my co-host, she said, "Oh, there's a new company in Toronto.
[00:42:15.640 --> 00:42:16.640]   Just started up.
[00:42:16.640 --> 00:42:17.640]   This was 2004."
[00:42:17.640 --> 00:42:21.760]   Called FreshBooks, they'll make it easy and they did.
[00:42:21.760 --> 00:42:23.040]   They made it easy to invoice.
[00:42:23.040 --> 00:42:25.200]   I didn't have to worry about currencies.
[00:42:25.200 --> 00:42:29.880]   I could get my expenses in there just using the app on the smartphone to take a picture
[00:42:29.880 --> 00:42:32.360]   of receipts, put them in the invoice.
[00:42:32.360 --> 00:42:34.960]   I'd send them out and something interesting happened.
[00:42:34.960 --> 00:42:38.040]   I got paid a lot faster.
[00:42:38.040 --> 00:42:39.680]   That was a mind-blower.
[00:42:39.680 --> 00:42:43.680]   People paid me a lot faster because I was using FreshBooks now because FreshBooks lets
[00:42:43.680 --> 00:42:46.640]   you accept credit cards online and you don't have to do anything extra, by the way.
[00:42:46.640 --> 00:42:47.960]   They'll handle that.
[00:42:47.960 --> 00:42:52.560]   You'll get paid on an average of twice as fast because it turns out your clients want
[00:42:52.560 --> 00:42:53.560]   to pay you.
[00:42:53.560 --> 00:42:55.280]   Just make it easy for them.
[00:42:55.280 --> 00:42:57.160]   So you don't have to chase clients for payments anymore.
[00:42:57.160 --> 00:42:59.640]   You don't have to wait in line at the bank with a stack of checks.
[00:42:59.640 --> 00:43:02.680]   You can accept credit card payments directly from your invoice.
[00:43:02.680 --> 00:43:05.400]   You always know exactly what's going on with your money.
[00:43:05.400 --> 00:43:10.720]   In fact, really, FreshBooks, don't tell anybody, is essentially a full accounting system that
[00:43:10.720 --> 00:43:13.920]   starts with the invoices and the expenses.
[00:43:13.920 --> 00:43:15.680]   Based on that, they know what your receivables are.
[00:43:15.680 --> 00:43:18.360]   They know what your payables are.
[00:43:18.360 --> 00:43:21.000]   They basically know what your profit is.
[00:43:21.000 --> 00:43:22.440]   If you're a freelancer, I never knew.
[00:43:22.440 --> 00:43:23.440]   Am I making money?
[00:43:23.440 --> 00:43:24.440]   I don't even know.
[00:43:24.440 --> 00:43:25.600]   I won't know until tax time.
[00:43:25.600 --> 00:43:28.960]   Now you know every step of the way because that's great FreshBooks dashboard tells you
[00:43:28.960 --> 00:43:30.240]   exactly what's going on.
[00:43:30.240 --> 00:43:33.520]   You see what invoices have been sent, which have been viewed, which have been paid, which
[00:43:33.520 --> 00:43:36.880]   are overdue, outstanding invoice totals.
[00:43:36.880 --> 00:43:38.040]   They have lots of other features.
[00:43:38.040 --> 00:43:42.240]   In fact, because it's a web app that's constantly being improved with new features, they added
[00:43:42.240 --> 00:43:47.160]   proposals with rich text content and images, customizable sections so you can now send
[00:43:47.160 --> 00:43:51.760]   off proposals to new clients that make it easy for you to grow your business.
[00:43:51.760 --> 00:43:53.520]   You can bill by time.
[00:43:53.520 --> 00:43:58.000]   Of course, hours, there's a big button on the FreshBooks website or you can use their
[00:43:58.000 --> 00:44:01.400]   apps to time how much time you spent on a client.
[00:44:01.400 --> 00:44:03.760]   You can even break it down by project.
[00:44:03.760 --> 00:44:04.760]   It's multilingual.
[00:44:04.760 --> 00:44:08.480]   They just added Spanish and Dutch, which is fantastic.
[00:44:08.480 --> 00:44:11.240]   Take a picture of receipt, upload it.
[00:44:11.240 --> 00:44:13.640]   Payment schedules could be set up from the FreshBooks iOS app.
[00:44:13.640 --> 00:44:16.200]   You could see attachments on existing proposals.
[00:44:16.200 --> 00:44:17.200]   Push notifications.
[00:44:17.200 --> 00:44:18.440]   I'm just going through the list of new features.
[00:44:18.440 --> 00:44:20.440]   Additional push notifications on iOS.
[00:44:20.440 --> 00:44:23.560]   You're notified when a client hasn't viewed an invoice.
[00:44:23.560 --> 00:44:27.880]   If they haven't looked at it yet or an estimate or a proposal in seven days, you can get
[00:44:27.880 --> 00:44:31.720]   notified when a client makes a comment or when an invoice goes overdue or when the
[00:44:31.720 --> 00:44:33.800]   client pays you.
[00:44:33.800 --> 00:44:35.640]   That's the best notification of all.
[00:44:35.640 --> 00:44:40.560]   Set yourself up for a stress-free tax season from payment reminders to late fees, automate
[00:44:40.560 --> 00:44:43.360]   as much or as little as you want and get back to doing what you love.
[00:44:43.360 --> 00:44:44.720]   That's why I love FreshBooks.
[00:44:44.720 --> 00:44:49.480]   Get FreshBooks free for 30 days right now, freshbooks.com/twit.
[00:44:49.480 --> 00:44:51.520]   Please when they ask, how did you hear about us?
[00:44:51.520 --> 00:44:55.560]   If you would, just write this week in tech, that would be nice.
[00:44:55.560 --> 00:45:04.040]   We got into a really good subject.
[00:45:04.040 --> 00:45:11.360]   I feel like we should, we need to dig deeper on this, reinventing the financial system
[00:45:11.360 --> 00:45:14.200]   and whether blockchain can make a difference there.
[00:45:14.200 --> 00:45:18.320]   I feel like there's definitely something going on.
[00:45:18.320 --> 00:45:22.920]   I like the, now I'm kind of digging the idea that maybe we don't want to let Google or
[00:45:22.920 --> 00:45:27.760]   Facebook or Amazon or Walmart, any big company have all that information.
[00:45:27.760 --> 00:45:34.040]   Maybe we want to be a little bit more private.
[00:45:34.040 --> 00:45:39.040]   The thing is, when I look at somebody like Google and just how much data they're scraping
[00:45:39.040 --> 00:45:45.480]   off of me in general, it's creepy, but yet at the same time it's been to my benefit for
[00:45:45.480 --> 00:45:47.960]   day-to-day life, day-to-day work kind of thing.
[00:45:47.960 --> 00:45:53.600]   I think Google's missed a, I used to think that with Google now, for instance, but now
[00:45:53.600 --> 00:45:56.160]   it's dying.
[00:45:56.160 --> 00:45:58.040]   What the hell?
[00:45:58.040 --> 00:46:01.120]   This is Google's, look Google, you're...
[00:46:01.120 --> 00:46:02.520]   As Google's in mode though, right?
[00:46:02.520 --> 00:46:06.640]   Well give you stuff, but you got to give us stuff back.
[00:46:06.640 --> 00:46:09.000]   Yeah, they're plussing it.
[00:46:09.000 --> 00:46:16.360]   I just, it kind of baffles me, but weirdly enough, according to TechCrunch, Android beats
[00:46:16.360 --> 00:46:18.960]   iOS in smartphone loyalty.
[00:46:18.960 --> 00:46:28.640]   Actually they're quoting a study from Consumer Intelligence Research Partners, or CIRP.
[00:46:28.640 --> 00:46:36.640]   If it's really a strange, wouldn't have expected this graph here, Android has 91% brand loyalty
[00:46:36.640 --> 00:46:38.840]   compared with 86% for iOS.
[00:46:38.840 --> 00:46:42.720]   So if there is a switch going on, it's from iOS to Android.
[00:46:42.720 --> 00:46:44.560]   You would have thought that.
[00:46:44.560 --> 00:46:49.440]   Is it more of a switch from iOS to Samsung?
[00:46:49.440 --> 00:46:50.440]   Yeah.
[00:46:50.440 --> 00:46:57.080]   Because that thing is just so strong in Android community and it's strong in just the regular
[00:46:57.080 --> 00:46:59.400]   person's world of technology.
[00:46:59.400 --> 00:47:04.360]   This is a switch though, I mean a few years ago it was easily iPhone, but that shifted
[00:47:04.360 --> 00:47:08.600]   in 2014 and it's been, Android's been going up ever since.
[00:47:08.600 --> 00:47:12.360]   I'm loyal to my Pixel phone, speaking of giving Google more data.
[00:47:12.360 --> 00:47:14.920]   The S9 is beautiful.
[00:47:14.920 --> 00:47:16.400]   Do you have the S9 yet?
[00:47:16.400 --> 00:47:19.720]   Yeah, I have a reviewer.
[00:47:19.720 --> 00:47:22.920]   I would say the only, I understand what Samsung is doing.
[00:47:22.920 --> 00:47:24.760]   I think Ant is on to something.
[00:47:24.760 --> 00:47:29.920]   It is that Samsung has created some premium, they have created iPhone analogs in the Android
[00:47:29.920 --> 00:47:31.400]   market.
[00:47:31.400 --> 00:47:38.120]   I think that is, it makes sense for Samsung to pursue their own, you know, big speed in
[00:47:38.120 --> 00:47:42.360]   their own operating system that kind of floats on top of Android.
[00:47:42.360 --> 00:47:48.800]   But it's really, they have put in the hard work into creating something where you really
[00:47:48.800 --> 00:47:51.320]   can switch and have the very similar experience.
[00:47:51.320 --> 00:47:55.960]   And perhaps that, although it existed in the market, perhaps the consumer top of mind
[00:47:55.960 --> 00:48:04.160]   awareness of premium phone, premium Android phones was not like it is now.
[00:48:04.160 --> 00:48:06.640]   And in business, we see Nox.
[00:48:06.640 --> 00:48:11.280]   I mean, I would only trust in a Samsung phone going overseas.
[00:48:11.280 --> 00:48:17.280]   I wouldn't use any other Google for, or Android phone, but Nox has come a long way and it
[00:48:17.280 --> 00:48:19.120]   is really secure.
[00:48:19.120 --> 00:48:24.800]   And I think those two things, a premium consumer experience and a secure business experience
[00:48:24.800 --> 00:48:28.440]   are the things that iOS offers.
[00:48:28.440 --> 00:48:32.480]   And perhaps Amazon is, or Samsung is offering that.
[00:48:32.480 --> 00:48:38.320]   Do you, I want to play a game, you guys at home can play it too.
[00:48:38.320 --> 00:48:39.880]   I wonder if people have ever done this.
[00:48:39.880 --> 00:48:43.960]   Can you look at somebody and say iOS or Android?
[00:48:43.960 --> 00:48:48.240]   Because I'm going to say Dan's Android, Ants Android, Ben's iOS.
[00:48:48.240 --> 00:48:49.800]   Am I right?
[00:48:49.800 --> 00:48:52.600]   No, I'm going to pick some, just like you, man.
[00:48:52.600 --> 00:48:55.600]   I'm going to pick some just like you.
[00:48:55.600 --> 00:48:56.680]   Come on.
[00:48:56.680 --> 00:48:59.840]   You guys are probably not good examples because Ben, you probably have an iPhone line around
[00:48:59.840 --> 00:49:00.840]   as well somewhere, right?
[00:49:00.840 --> 00:49:01.840]   Oh, no.
[00:49:01.840 --> 00:49:02.840]   No, I was wrong.
[00:49:02.840 --> 00:49:03.840]   Android to the core.
[00:49:03.840 --> 00:49:07.120]   I'm not an Ant, are you Android or iOS?
[00:49:07.120 --> 00:49:09.520]   I'm Android, Android the way.
[00:49:09.520 --> 00:49:11.600]   And Dan, you're Android?
[00:49:11.600 --> 00:49:12.600]   I'm both.
[00:49:12.600 --> 00:49:14.480]   I'm primary iOS.
[00:49:14.480 --> 00:49:19.160]   And that's, you know, I was in Kiv last year and as much as I love Android, I always
[00:49:19.160 --> 00:49:21.000]   have an Android device around.
[00:49:21.000 --> 00:49:23.680]   I will not trust an Android device overseas.
[00:49:23.680 --> 00:49:27.920]   I will use a Nox device in Samsung, but I won't use an iOS device.
[00:49:27.920 --> 00:49:28.920]   That's interesting.
[00:49:28.920 --> 00:49:33.080]   If I'm going someplace where there are active...
[00:49:33.080 --> 00:49:35.480]   You want use Android and Android device when you're...
[00:49:35.480 --> 00:49:36.720]   In Android devices, I'm sorry.
[00:49:36.720 --> 00:49:41.800]   I'll only use iOS and even that, I'll wipe and get rid of immediately after going some
[00:49:41.800 --> 00:49:42.800]   place.
[00:49:42.800 --> 00:49:44.360]   Really, you think you're getting hacked?
[00:49:44.360 --> 00:49:45.360]   Yeah.
[00:49:45.360 --> 00:49:46.360]   Oh, I know.
[00:49:46.360 --> 00:49:47.360]   I know.
[00:49:47.360 --> 00:49:49.120]   I mean, we don't have enough time to discuss this, but I wrote about this.
[00:49:49.120 --> 00:49:53.920]   Look, this is not a plug, but if you want to read the experience, this is on.
[00:49:53.920 --> 00:49:57.720]   I think one is pinned to the top of my Twitter, but yes, we had...
[00:49:57.720 --> 00:49:59.560]   Look, we were traveling with diplomats last year.
[00:49:59.560 --> 00:50:02.640]   We were traveling with the head of the former head of the NSA.
[00:50:02.640 --> 00:50:03.920]   I'm a slob.
[00:50:03.920 --> 00:50:07.880]   Nobody cares about me, but the people we were traveling and working with the Global Cyber
[00:50:07.880 --> 00:50:10.440]   Security Summit were not slobs.
[00:50:10.440 --> 00:50:11.440]   And there are...
[00:50:11.440 --> 00:50:14.400]   Look, Ukraine is a kinetic region.
[00:50:14.400 --> 00:50:18.960]   There are actual kinetic attacks happening there, and there are cyber attacks happening
[00:50:18.960 --> 00:50:20.440]   every single day.
[00:50:20.440 --> 00:50:22.800]   As we know, they shut down the power grid.
[00:50:22.800 --> 00:50:23.800]   Absolutely.
[00:50:23.800 --> 00:50:27.600]   We were under attack from various threat actors.
[00:50:27.600 --> 00:50:33.360]   You wrote in your piece from last year that you basically, as soon as you turned off airplane
[00:50:33.360 --> 00:50:35.880]   mode as the plane landed, you got hacked.
[00:50:35.880 --> 00:50:39.320]   Yeah, there are stingrays at ByStropyl Airport.
[00:50:39.320 --> 00:50:50.600]   Look, the biggest hotel in Kyiv is connected to a cyber facility at a Russian cyber facility
[00:50:50.600 --> 00:50:53.200]   that the Ukrainians don't really like there.
[00:50:53.200 --> 00:50:54.200]   Look, there's...
[00:50:54.200 --> 00:50:55.360]   Again, I'm a slob.
[00:50:55.360 --> 00:50:58.520]   I am a low-value target.
[00:50:58.520 --> 00:50:59.520]   But when you...
[00:50:59.520 --> 00:51:02.000]   High-value target, it doesn't matter.
[00:51:02.000 --> 00:51:06.840]   Second, I went on stage.
[00:51:06.840 --> 00:51:07.920]   Fishing attacks.
[00:51:07.920 --> 00:51:09.080]   You're getting attacked right now.
[00:51:09.080 --> 00:51:13.040]   I think you're getting D-dossed by the Ukrainians who don't want to.
[00:51:13.040 --> 00:51:15.040]   Don't want to.
[00:51:15.040 --> 00:51:17.640]   That stuff is so scary.
[00:51:17.640 --> 00:51:22.080]   So you get off the plane and you say, "I ignored the tell-tale warning sign of a stingray."
[00:51:22.080 --> 00:51:25.960]   Those are devices that simulate cell network but aren't.
[00:51:25.960 --> 00:51:32.760]   So your phone joined a hacker network, including, you say, the device's MAC address, maybe even
[00:51:32.760 --> 00:51:35.520]   some encryption keys.
[00:51:35.520 --> 00:51:38.440]   So why were they doing that to you?
[00:51:38.440 --> 00:51:39.960]   What were they trying to get?
[00:51:39.960 --> 00:51:42.720]   Again, nobody knows who I am.
[00:51:42.720 --> 00:51:43.720]   So the...
[00:51:43.720 --> 00:51:45.360]   They just do it to everybody.
[00:51:45.360 --> 00:51:51.480]   Yes, it is to draw a circle around you and to find out who is this person, who is this
[00:51:51.480 --> 00:51:57.000]   agent, this person, and what purpose are they serving here?
[00:51:57.000 --> 00:52:02.000]   Now the purpose we served in Kiev was a part of the Global Cybersecurity Summit that had
[00:52:02.000 --> 00:52:06.240]   diplomats and other people who actually are valuable targets.
[00:52:06.240 --> 00:52:09.400]   So they can look at me and they looked at all of my social media accounts.
[00:52:09.400 --> 00:52:12.320]   I got phishing attacks that were brilliantly...
[00:52:12.320 --> 00:52:16.680]   I mean, anybody who knows Burpsuite or any of the other tools that create phishing attacks,
[00:52:16.680 --> 00:52:19.160]   it's almost trivial to create some of these.
[00:52:19.160 --> 00:52:23.240]   And I'm sure that they found, ah, this guy's a schmuck, he's from the States, no big deal.
[00:52:23.240 --> 00:52:27.480]   And what the other people we were with were had challenges.
[00:52:27.480 --> 00:52:30.480]   But I got to point out, Dan, that wouldn't have mattered if you'd been an iPhone or an
[00:52:30.480 --> 00:52:31.480]   Android phone.
[00:52:31.480 --> 00:52:33.200]   That would have made any difference, would it?
[00:52:33.200 --> 00:52:36.600]   It wouldn't, especially with a stingray, would not have made a difference.
[00:52:36.600 --> 00:52:37.600]   So that doesn't matter.
[00:52:37.600 --> 00:52:42.400]   So why do you feel safer with an iPhone in an environment like that?
[00:52:42.400 --> 00:52:52.680]   Because the Android... look, I love Android, but you have a consistent state with iOS.
[00:52:52.680 --> 00:52:56.200]   And to burn a zero day on me is ridiculous.
[00:52:56.200 --> 00:52:58.280]   It's way too expensive.
[00:52:58.280 --> 00:53:03.040]   But there are dozens of different Android devices, different flavors of Android in the
[00:53:03.040 --> 00:53:04.200]   marketplace.
[00:53:04.200 --> 00:53:06.800]   It's just easier to find a crack in the...
[00:53:06.800 --> 00:53:07.800]   Leaks.
[00:53:07.800 --> 00:53:08.800]   Leaks.
[00:53:08.800 --> 00:53:09.800]   Leaks.
[00:53:09.800 --> 00:53:10.800]   Yeah.
[00:53:10.800 --> 00:53:12.800]   It's pretty safe.
[00:53:12.800 --> 00:53:19.520]   Knox is the secure enclave within Samsung's Android devices where you can have a secure
[00:53:19.520 --> 00:53:22.120]   folder that's locked with biometrics.
[00:53:22.120 --> 00:53:28.080]   You can have your business data separate from your personal data so that it has a security
[00:53:28.080 --> 00:53:32.360]   model, which in fact, I think the Department of Defense has approved for DOD use.
[00:53:32.360 --> 00:53:35.560]   So it must be fairly good.
[00:53:35.560 --> 00:53:38.240]   So Brian X Chen, love him.
[00:53:38.240 --> 00:53:42.000]   He's been on the show many times, was on a couple of weeks ago, did his review of the
[00:53:42.000 --> 00:53:45.920]   S9 and he used the horrific...
[00:53:45.920 --> 00:53:53.600]   He calls it the uncanny valley and AR emoji for his review.
[00:53:53.600 --> 00:53:56.440]   And he says...
[00:53:56.440 --> 00:54:00.160]   He says Bitmoji does a better job.
[00:54:00.160 --> 00:54:07.520]   Snap does a better job than these weird uncanny, creepy emoji.
[00:54:07.520 --> 00:54:09.440]   But he nevertheless decided to use them.
[00:54:09.440 --> 00:54:13.280]   So he says, "Should I buy this phone for the AR emoji?"
[00:54:13.280 --> 00:54:14.360]   No.
[00:54:14.360 --> 00:54:19.520]   He does like the new placement, as you can see, of the fingerprint reader.
[00:54:19.520 --> 00:54:20.720]   It's finally where it should be.
[00:54:20.720 --> 00:54:23.880]   Instead of to the side of the camera, it's below the camera.
[00:54:23.880 --> 00:54:26.320]   You're much less likely to smudge the...
[00:54:26.320 --> 00:54:30.720]   My S8 and Galaxy Note 8 actually have a warning when you use the camera.
[00:54:30.720 --> 00:54:35.080]   You might want to clean your lens because it's so easy to accidentally give a "shh-whats"
[00:54:35.080 --> 00:54:36.080]   on it.
[00:54:36.080 --> 00:54:42.520]   It's a fantastic device if you're looking for a premium Android experience.
[00:54:42.520 --> 00:54:44.400]   I'm not a fan of Bixby, though.
[00:54:44.400 --> 00:54:45.400]   You said...
[00:54:45.400 --> 00:54:46.880]   You actually said something that really scares me.
[00:54:46.880 --> 00:54:49.800]   Bixby is a beginning of an OS.
[00:54:49.800 --> 00:54:51.440]   I think that this is...
[00:54:51.440 --> 00:54:58.000]   Look, this is not an endorsement of Samsung or Bixby Bixby is really not so super.
[00:54:58.000 --> 00:55:03.480]   And Samsung's operating system is by far the most annoying part of the device.
[00:55:03.480 --> 00:55:09.160]   But I understand why Samsung looks at themselves and says, "Hey, we're the biggest player in
[00:55:09.160 --> 00:55:10.360]   the block.
[00:55:10.360 --> 00:55:13.640]   Why would we not create a competitive cloud platform?
[00:55:13.640 --> 00:55:14.800]   It makes no sense."
[00:55:14.800 --> 00:55:20.480]   Yeah, and of course, in the interim, it's a problem because you have two calendars, two
[00:55:20.480 --> 00:55:25.480]   clocks, two assistants, two music players, two photo galleries.
[00:55:25.480 --> 00:55:27.040]   You have Samsung's and Google's.
[00:55:27.040 --> 00:55:28.040]   You have to have groups to get in.
[00:55:28.040 --> 00:55:29.040]   So I can't get into this.
[00:55:29.040 --> 00:55:31.040]   I don't know what my password is.
[00:55:31.040 --> 00:55:33.400]   That's the Ukrainian hackers.
[00:55:33.400 --> 00:55:37.080]   Don't pay no attention to that.
[00:55:37.080 --> 00:55:41.960]   But that's something Google requires of people who are going to use Android and want full
[00:55:41.960 --> 00:55:42.960]   Google services.
[00:55:42.960 --> 00:55:45.920]   They have to put all the Google apps on there, right?
[00:55:45.920 --> 00:55:47.400]   Yeah.
[00:55:47.400 --> 00:55:48.160]   So when is that?
[00:55:48.160 --> 00:55:54.520]   So at some point, if Samsung wants to really own this phone and eliminate this pain point
[00:55:54.520 --> 00:55:58.360]   for consumers, they're going to have to say goodbye to Google.
[00:55:58.360 --> 00:56:02.960]   I think that's why they built these competitive services.
[00:56:02.960 --> 00:56:03.960]   Yeah.
[00:56:03.960 --> 00:56:05.440]   Otherwise, there's no point.
[00:56:05.440 --> 00:56:06.440]   Just do what Google's doing.
[00:56:06.440 --> 00:56:10.400]   It's been the right on the wall for the last couple of years with Samsung.
[00:56:10.400 --> 00:56:11.400]   Yeah.
[00:56:11.400 --> 00:56:15.320]   Well, they tried Tizen, which they use in their watch apps.
[00:56:15.320 --> 00:56:17.240]   It's very primitive, terrible.
[00:56:17.240 --> 00:56:20.440]   Do you think that's imminent, though?
[00:56:20.440 --> 00:56:27.680]   There'll be a Samsung OS, and will that be terrible news for Google?
[00:56:27.680 --> 00:56:28.680]   Yeah.
[00:56:28.680 --> 00:56:29.680]   This is just a hunch.
[00:56:29.680 --> 00:56:33.040]   I don't know, but I would imagine a company the size of Samsung.
[00:56:33.040 --> 00:56:35.840]   You have executives and you have decision makers.
[00:56:35.840 --> 00:56:38.720]   And you also have many, many moving parts.
[00:56:38.720 --> 00:56:43.600]   And it's easy for one part of Samsung to say, we need cloud services.
[00:56:43.600 --> 00:56:45.600]   We need our own cloud services.
[00:56:45.600 --> 00:56:50.520]   It's ridiculous for us not to play in this contemporary business tech.
[00:56:50.520 --> 00:56:52.520]   We need cloud services.
[00:56:52.520 --> 00:56:54.000]   And so let's build them.
[00:56:54.000 --> 00:56:57.440]   And there's probably other components of Samsung that say, ah, let's just make something
[00:56:57.440 --> 00:56:58.440]   with awesome hardware.
[00:56:58.440 --> 00:57:04.200]   Well, remember they had a music service called Milk, which they killed because it couldn't
[00:57:04.200 --> 00:57:07.080]   compete against all the other music services.
[00:57:07.080 --> 00:57:11.000]   From a consumer's point of view, I think don't you want a variety of companies to compete
[00:57:11.000 --> 00:57:12.160]   on any given platform?
[00:57:12.160 --> 00:57:19.480]   You don't want to be all in Google's backyard and all are all in Samsungs.
[00:57:19.480 --> 00:57:22.560]   And yet at the same time, you don't want two clocks every time.
[00:57:22.560 --> 00:57:26.800]   Brian points out when you set an alarm on your brand new S9, it's going to, before you
[00:57:26.800 --> 00:57:29.240]   could set an alarm, it's because they, which clock do you want to use?
[00:57:29.240 --> 00:57:30.240]   Clock or clock?
[00:57:30.240 --> 00:57:31.240]   Oh gosh.
[00:57:31.240 --> 00:57:33.840]   That's not a good user experience.
[00:57:33.840 --> 00:57:35.440]   That's not good.
[00:57:35.440 --> 00:57:39.640]   Here's Brian's, here's Brian's animated emoji for Bixby.
[00:57:39.640 --> 00:57:42.520]   He's crying many, many, many tears.
[00:57:42.520 --> 00:57:44.840]   Now I'm starting to like these emojis by the way.
[00:57:44.840 --> 00:57:46.080]   He does love the camera.
[00:57:46.080 --> 00:57:47.080]   Do you love the camera, Dan?
[00:57:47.080 --> 00:57:49.800]   Have you been enjoying the pictures you're getting with that thing?
[00:57:49.800 --> 00:57:54.160]   The super slow mo is, I got to tell you, man, that is a really cool feature.
[00:57:54.160 --> 00:57:56.360]   960 frames a second.
[00:57:56.360 --> 00:57:59.360]   Yeah, I'd love to come around with that.
[00:57:59.360 --> 00:58:00.360]   Yeah.
[00:58:00.360 --> 00:58:04.360]   Are you going to get an S9 and or what are you, you're using the pixel now or what do
[00:58:04.360 --> 00:58:05.360]   you use?
[00:58:05.360 --> 00:58:06.360]   I'm all pixel.
[00:58:06.360 --> 00:58:07.360]   Yeah.
[00:58:07.360 --> 00:58:08.360]   I'm all pixel.
[00:58:08.360 --> 00:58:09.360]   I'm a former Nexus fan.
[00:58:09.360 --> 00:58:10.360]   Me too.
[00:58:10.360 --> 00:58:11.880]   And I never really gotten away from it.
[00:58:11.880 --> 00:58:13.280]   I would love to see Samsung.
[00:58:13.280 --> 00:58:14.280]   I know they'll never do this.
[00:58:14.280 --> 00:58:17.440]   Samsung do a Google experience version of the S9.
[00:58:17.440 --> 00:58:18.440]   It's just plain Google.
[00:58:18.440 --> 00:58:21.360]   I would switch from iOS for that.
[00:58:21.360 --> 00:58:23.680]   Yeah, maybe, right?
[00:58:23.680 --> 00:58:27.400]   Because a plain Android is probably competitive with iOS.
[00:58:27.400 --> 00:58:35.080]   It's certainly as secure because Google does monthly updates on the pixel phone.
[00:58:35.080 --> 00:58:38.640]   Most of the reviews I've seen of the camera on the S9 say it has its good points, it's
[00:58:38.640 --> 00:58:44.720]   competitive with iPhone 10 and with the pixel 2, but that ultimately, and I think Brian said
[00:58:44.720 --> 00:58:49.240]   this too, the Pixel 2 is probably the better camera of the two.
[00:58:49.240 --> 00:58:54.400]   He did do a nice heart for the camera.
[00:58:54.400 --> 00:58:56.000]   The Pixel 2 camera is great.
[00:58:56.000 --> 00:58:57.400]   I love the camera on the Pixel.
[00:58:57.400 --> 00:58:58.640]   I'm blown away by it.
[00:58:58.640 --> 00:58:59.640]   Yeah.
[00:58:59.640 --> 00:59:00.640]   It's tough to beat.
[00:59:00.640 --> 00:59:01.640]   Yeah.
[00:59:01.640 --> 00:59:04.600]   I'm a fan of it, but it's also a tool.
[00:59:04.600 --> 00:59:08.040]   I use it for work for time to time.
[00:59:08.040 --> 00:59:10.080]   It's that good.
[00:59:10.080 --> 00:59:11.680]   So is the S9...
[00:59:11.680 --> 00:59:15.000]   I mean, most people say the S9 is great, but not...
[00:59:15.000 --> 00:59:19.560]   But only an incremental improvement over the S8 or the Note 8 is the S9 going to be a big
[00:59:19.560 --> 00:59:21.360]   seller or is it...
[00:59:21.360 --> 00:59:24.360]   One of the trends we've seen is that people are not buying new phones as rapidly.
[00:59:24.360 --> 00:59:27.880]   In fact, the Times had an article saying people are buying re-furbed phones.
[00:59:27.880 --> 00:59:31.680]   The pricing is so bad on phones today.
[00:59:31.680 --> 00:59:34.080]   And unless you wait, which is...
[00:59:34.080 --> 00:59:40.400]   I remember when the original Pixel came out, I advised people to wait about three months
[00:59:40.400 --> 00:59:42.600]   and the pricing will be somewhat better.
[00:59:42.600 --> 00:59:43.600]   And it was.
[00:59:43.600 --> 00:59:44.920]   Just wait it out.
[00:59:44.920 --> 00:59:50.640]   Don't go out and buy them on launch day and spend $1,000 for a phone.
[00:59:50.640 --> 00:59:51.640]   That's just too much.
[00:59:51.640 --> 00:59:56.800]   And yes, the iPhone X is a beautiful phone and has great technology inside of it.
[00:59:56.800 --> 01:00:00.840]   I mean, $1,000 for a dad gun cell phone is just too much.
[01:00:00.840 --> 01:00:05.320]   Well, now if I get a dad gum cell phone, I might spend a kind of money on it.
[01:00:05.320 --> 01:00:09.480]   That would be a great name for a Chinese cell phone manufacturer.
[01:00:09.480 --> 01:00:10.480]   Dad gum.
[01:00:10.480 --> 01:00:11.480]   Dad gum.
[01:00:11.480 --> 01:00:14.360]   Oh, I have the dad gum 800.
[01:00:14.360 --> 01:00:16.240]   Boy, that's good.
[01:00:16.240 --> 01:00:18.640]   Maybe Ant should make a phone called Antphone.
[01:00:18.640 --> 01:00:21.840]   It's small, but powerful.
[01:00:21.840 --> 01:00:22.840]   It's tiny.
[01:00:22.840 --> 01:00:23.840]   It's tiny.
[01:00:23.840 --> 01:00:24.840]   This is...
[01:00:24.840 --> 01:00:25.840]   I should give...
[01:00:25.840 --> 01:00:26.840]   Let me correct myself.
[01:00:26.840 --> 01:00:27.840]   It wasn't the New York Times.
[01:00:27.840 --> 01:00:28.840]   It was a Wall Street Journal.
[01:00:28.840 --> 01:00:33.160]   Again, your love of your old smartphone is a problem for Apple and Samsung.
[01:00:33.160 --> 01:00:37.680]   Because of these high-priced phones, people are holding on to devices longer, new smartphone
[01:00:37.680 --> 01:00:42.360]   shipments plunged to historic lows at the end of 2017.
[01:00:42.360 --> 01:00:45.760]   Another trend is people are buying refurbished phones.
[01:00:45.760 --> 01:00:49.600]   It's the fastest growing segment of the global smartphone industry.
[01:00:49.600 --> 01:00:56.000]   One and every 10 devices sold now is a refurbused phone, which are perfectly good.
[01:00:56.000 --> 01:01:00.040]   And partly that's because we're not seeing big strides in the new models, right?
[01:01:00.040 --> 01:01:03.640]   Like the S9, they're kind of incremental improvements over the previous models.
[01:01:03.640 --> 01:01:05.640]   Nothing to get you all excited about.
[01:01:05.640 --> 01:01:11.800]   When I saw the S9 announcement at Mobile World Congress, I wasn't there, but I remember
[01:01:11.800 --> 01:01:14.400]   saying it was Jason Heiner's feed.
[01:01:14.400 --> 01:01:18.520]   And I saw the phone and I was thinking, "Huh, that looks just like any other phone."
[01:01:18.520 --> 01:01:20.320]   It looks exactly like an S8.
[01:01:20.320 --> 01:01:21.320]   Actually...
[01:01:21.320 --> 01:01:23.960]   You know, what's the point?
[01:01:23.960 --> 01:01:29.520]   It's almost like we're sort of losing the innovative skill as far as making something that's
[01:01:29.520 --> 01:01:32.440]   going to at least catch my eyes.
[01:01:32.440 --> 01:01:34.440]   Let alone...
[01:01:34.440 --> 01:01:38.960]   I mean, facing the limitations of what the hardware can actually do for people day to
[01:01:38.960 --> 01:01:39.960]   day.
[01:01:39.960 --> 01:01:41.560]   You can have great cameras.
[01:01:41.560 --> 01:01:46.520]   You can put in some type of assistance that'll talk to you and give you your navigation
[01:01:46.520 --> 01:01:47.760]   and things like that.
[01:01:47.760 --> 01:01:53.560]   But after that, then what?
[01:01:53.560 --> 01:01:54.920]   A good question.
[01:01:54.920 --> 01:01:56.680]   Let's take a break.
[01:01:56.680 --> 01:01:58.760]   Ant Pruitt from Tech Republic is here.
[01:01:58.760 --> 01:02:00.760]   Great to have you, Ant.
[01:02:00.760 --> 01:02:03.360]   Also Ben Patterson from CBS Interactive as well.
[01:02:03.360 --> 01:02:06.600]   He's a senior writer at Tech Republic and from WBUR.
[01:02:06.600 --> 01:02:14.920]   Boston University Radio, one of the great NPR stations in America, grew up listening
[01:02:14.920 --> 01:02:15.920]   to BUUR.
[01:02:15.920 --> 01:02:17.880]   He's a senior producer there.
[01:02:17.880 --> 01:02:18.880]   Are you doing...
[01:02:18.880 --> 01:02:19.960]   What shows are you doing these days?
[01:02:19.960 --> 01:02:22.880]   You said you're not doing the crypto...
[01:02:22.880 --> 01:02:24.120]   Talk to a co-breaker.
[01:02:24.120 --> 01:02:25.120]   Co-breakers.
[01:02:25.120 --> 01:02:29.240]   But I make Endless Thread, the podcast about Reddit.
[01:02:29.240 --> 01:02:31.800]   And then I'm also on their show Here and Now, which is a national...
[01:02:31.800 --> 01:02:33.160]   Oh, I love Here and Now.
[01:02:33.160 --> 01:02:34.160]   NPR show.
[01:02:34.160 --> 01:02:36.680]   Yeah, I go on there with Jeremy Hobson and Robin Young.
[01:02:36.680 --> 01:02:40.400]   We talk tech every week or so, every week or two.
[01:02:40.400 --> 01:02:41.400]   It's great.
[01:02:41.400 --> 01:02:42.400]   Maybe we'll come back.
[01:02:42.400 --> 01:02:45.240]   We'll talk about the rise of the Daily News show.
[01:02:45.240 --> 01:02:47.200]   Everybody's got one now, all of a sudden.
[01:02:47.200 --> 01:02:48.200]   It's the big thing.
[01:02:48.200 --> 01:02:49.200]   Of course, we canceled...
[01:02:49.200 --> 01:02:50.280]   I get those numbers.
[01:02:50.280 --> 01:02:52.280]   We canceled ours.
[01:02:52.280 --> 01:02:55.640]   Well, I'll tell you why when we come back.
[01:02:55.640 --> 01:03:03.600]   First a word from our sponsor, 23andMe, a personal genetic service that helps you understand
[01:03:03.600 --> 01:03:12.360]   what your particular 23 pairs of chromosomes say about your ancestry, about your traits,
[01:03:12.360 --> 01:03:13.960]   about your health.
[01:03:13.960 --> 01:03:16.320]   It is really, really fun.
[01:03:16.320 --> 01:03:21.200]   They just got a very big news.
[01:03:21.200 --> 01:03:27.840]   The FDA has approved their BRCA tests, which is huge.
[01:03:27.840 --> 01:03:33.280]   They're going to be able to sell a test that tells people whether they're carrying genetic
[01:03:33.280 --> 01:03:37.360]   mutations that put them at a higher risk for breast cancer and ovarian cancer.
[01:03:37.360 --> 01:03:42.080]   This is the first time the FDA has allowed a company to market a cancer risk text directly
[01:03:42.080 --> 01:03:43.080]   to the public.
[01:03:43.080 --> 01:03:49.880]   It shows really how much trust there is in 23andMe and the genetic testing that they
[01:03:49.880 --> 01:03:50.880]   do.
[01:03:50.880 --> 01:03:52.360]   It is fantastic.
[01:03:52.360 --> 01:03:59.200]   Now, if you go to 23andMe.com, you can get their health and ancestry kit or their ancestry
[01:03:59.200 --> 01:04:02.960]   service by itself that tell you so much about you.
[01:04:02.960 --> 01:04:05.480]   It's fun and informative.
[01:04:05.480 --> 01:04:09.320]   In fact, I did it years ago when they first started.
[01:04:09.320 --> 01:04:12.480]   I like this by the way, is that I keep getting more information.
[01:04:12.480 --> 01:04:16.240]   There are new reports all the time coming through on my 23andMe report.
[01:04:16.240 --> 01:04:17.320]   You just said it's simple to do.
[01:04:17.320 --> 01:04:18.560]   No blood test.
[01:04:18.560 --> 01:04:19.560]   No blood drawn.
[01:04:19.560 --> 01:04:20.560]   No doctor.
[01:04:20.560 --> 01:04:21.560]   You just spit.
[01:04:21.560 --> 01:04:22.560]   No blood.
[01:04:22.560 --> 01:04:23.560]   It has enough DNA in it.
[01:04:23.560 --> 01:04:25.280]   They can do all the analysis they need.
[01:04:25.280 --> 01:04:27.960]   You spit in the little vial, send it back in the prepaid envelope.
[01:04:27.960 --> 01:04:33.960]   You'll get a 75 plus online reports within six days and it's fantastic.
[01:04:33.960 --> 01:04:35.720]   You're going to learn more about your ancestry.
[01:04:35.720 --> 01:04:41.440]   In fact, they have this new, I should blog into it, this new ancestry wheel and the,
[01:04:41.440 --> 01:04:45.640]   and the ancestor, this is really interactive stuff that's really cool.
[01:04:45.640 --> 01:04:48.040]   Let me blog into my 23andMe.
[01:04:48.040 --> 01:04:50.600]   I could show you.
[01:04:50.600 --> 01:04:58.720]   They have the health and wellness reports that tell you about traits like coffee, weight,
[01:04:58.720 --> 01:05:00.360]   ear wax.
[01:05:00.360 --> 01:05:06.120]   But some of them are really serious that are really valuable so you can change your lifestyle
[01:05:06.120 --> 01:05:09.200]   to benefit.
[01:05:09.200 --> 01:05:14.360]   Depending on, if you've got sensitivities to certain things, and once they get these
[01:05:14.360 --> 01:05:18.760]   BRCA tests, I think that's going to be, boy, is that going to be a revolution?
[01:05:18.760 --> 01:05:24.920]   It's not clear yet whether that's a separate test or not, but I, I just love 23andMe.
[01:05:24.920 --> 01:05:28.200]   Oh, and look, my sister does too.
[01:05:28.200 --> 01:05:32.080]   I sent her and my mom 23andMe for Christmas.
[01:05:32.080 --> 01:05:33.080]   Now she's joined up.
[01:05:33.080 --> 01:05:36.040]   We're joined up in the 23andMe.
[01:05:36.040 --> 01:05:38.200]   You could see all sorts of interesting stuff.
[01:05:38.200 --> 01:05:40.000]   Let's look at the ancestry report.
[01:05:40.000 --> 01:05:41.000]   This is a lot of fun.
[01:05:41.000 --> 01:05:44.600]   You could see where your, your people came from.
[01:05:44.600 --> 01:05:48.560]   Not only a few hundred years ago, but thousands of years ago.
[01:05:48.560 --> 01:05:53.120]   So I am 39.1% British and Irish.
[01:05:53.120 --> 01:05:55.080]   I have a little Neanderthal.
[01:05:55.080 --> 01:05:57.400]   Okay, I'm going to admit it.
[01:05:57.400 --> 01:05:58.720]   There's, there's a little Neanderthal.
[01:05:58.720 --> 01:06:01.160]   I think I'm 4% Neanderthal.
[01:06:01.160 --> 01:06:07.960]   265 Neanderthal variants, 4% of my overall DNA.
[01:06:07.960 --> 01:06:12.120]   Seventh place among family and friends.
[01:06:12.120 --> 01:06:14.160]   So there's some with more and some with less.
[01:06:14.160 --> 01:06:16.040]   My sister's a little less nean.
[01:06:16.040 --> 01:06:17.840]   She's going to never let, live this down.
[01:06:17.840 --> 01:06:20.840]   She's a little less Neanderthal than I am.
[01:06:20.840 --> 01:06:22.840]   God darn it Eva.
[01:06:22.840 --> 01:06:23.840]   23andMe.
[01:06:23.840 --> 01:06:25.840]   It's so much fun.
[01:06:25.840 --> 01:06:27.840]   I want to encourage you to check it out.
[01:06:27.840 --> 01:06:29.840]   The Ancestry reports, the health and wellness reports.
[01:06:29.840 --> 01:06:35.840]   There's even a DNA relative fighter tool that'll help you connect with new relatives.
[01:06:35.840 --> 01:06:39.840]   Buy your 23andMe kit today, spit in that vial and get those great reports.
[01:06:39.840 --> 01:06:41.840]   23andMe.com/twit.
[01:06:41.840 --> 01:06:44.840]   To start learning more about who you are.
[01:06:44.840 --> 01:06:47.840]   And by the way, a great gift for kids.
[01:06:47.840 --> 01:06:49.840]   They're having a St. Patrick's Day sale right now.
[01:06:49.840 --> 01:06:51.840]   You'll save some green on 23andMe.
[01:06:51.840 --> 01:06:52.840]   I like that.
[01:06:52.840 --> 01:06:58.840]   They have kits for, if you, if you, if you, if you get one for your kids, what's cool about
[01:06:58.840 --> 01:07:04.640]   this, it's a great way for them to learn about the genetics, which is going to be a big part
[01:07:04.640 --> 01:07:05.840]   of their world, isn't it?
[01:07:05.840 --> 01:07:06.840]   Going forward.
[01:07:06.840 --> 01:07:09.840]   23andMe.com/twit.
[01:07:09.840 --> 01:07:10.840]   Thank them.
[01:07:10.840 --> 01:07:12.840]   We thank them so much for their support.
[01:07:12.840 --> 01:07:15.840]   This week in tech.
[01:07:15.840 --> 01:07:17.840]   Having fun?
[01:07:17.840 --> 01:07:19.840]   Dan Patterson from Tech Republic.
[01:07:19.840 --> 01:07:21.840]   Aunt Pruitt from Tech Republic.
[01:07:21.840 --> 01:07:23.840]   That was a coincidence.
[01:07:23.840 --> 01:07:25.840]   We didn't plan it that way.
[01:07:25.840 --> 01:07:26.840]   Just is.
[01:07:26.840 --> 01:07:29.840]   There's so many, everybody we know works for CBS Interactive in one form or fashion.
[01:07:29.840 --> 01:07:32.840]   Except for you, Ben Udon, Ben Brock Johnson.
[01:07:32.840 --> 01:07:33.840]   Senior producer.
[01:07:33.840 --> 01:07:34.840]   Yes, sir.
[01:07:34.840 --> 01:07:35.840]   WBUR.
[01:07:35.840 --> 01:07:38.840]   He's the Brock Johnson.
[01:07:38.840 --> 01:07:40.840]   Let's see.
[01:07:40.840 --> 01:07:41.840]   Should we talk about Apple?
[01:07:41.840 --> 01:07:43.840]   We haven't talked much about Apple.
[01:07:43.840 --> 01:07:50.400]   They have now signed yet another content superstar to produce a new series for whatever the hell
[01:07:50.400 --> 01:07:52.440]   they're planning.
[01:07:52.440 --> 01:07:55.080]   Apple says we're going to spend a billion dollars for original content.
[01:07:55.080 --> 01:07:57.320]   They hired M. Night Shyamalan.
[01:07:57.320 --> 01:08:00.640]   He's going to do a 10 episode psychological thriller.
[01:08:00.640 --> 01:08:04.800]   Shyamalan, of course, the director and creator Sixth Sense sign.
[01:08:04.800 --> 01:08:08.000]   So many great kind of movies with twists in them.
[01:08:08.000 --> 01:08:10.960]   He did a show called Wayward Pines.
[01:08:10.960 --> 01:08:12.520]   This will be a 30 minute series.
[01:08:12.520 --> 01:08:14.560]   He'll be executive producer.
[01:08:14.560 --> 01:08:20.120]   They hired, they contracted with Steven Spielberg to reboot his amazing stories.
[01:08:20.120 --> 01:08:25.080]   They're making a half hour comedy series about a morning show with Kristen Wiig, Jennifer
[01:08:25.080 --> 01:08:27.840]   Aniston and Reese Witherspoon.
[01:08:27.840 --> 01:08:33.720]   There's a show produced by Camille Nangani and Emily V. Gordon, who did the Big Sick,
[01:08:33.720 --> 01:08:36.680]   called Little America, an anthology series about immigrants.
[01:08:36.680 --> 01:08:38.240]   This is pretty cool.
[01:08:38.240 --> 01:08:40.320]   They're putting a lot of money into this.
[01:08:40.320 --> 01:08:44.160]   And yet, no word about how they plan to do it.
[01:08:44.160 --> 01:08:47.680]   Is this going to be, do you have to subscribe to Apple Music to see M. Night Shyamalan's TV
[01:08:47.680 --> 01:08:48.680]   series?
[01:08:48.680 --> 01:08:49.680]   I don't know.
[01:08:49.680 --> 01:08:50.680]   Right.
[01:08:50.680 --> 01:08:51.680]   That's the question.
[01:08:51.680 --> 01:08:53.480]   We're going to have access to this stuff.
[01:08:53.480 --> 01:08:55.680]   Is it solely on Apple TV?
[01:08:55.680 --> 01:09:00.400]   Because I haven't heard much good talk about Apple TV devices.
[01:09:00.400 --> 01:09:04.480]   It seems like a lot of money to spend to get people to buy a device that nobody really
[01:09:04.480 --> 01:09:08.520]   wants because it's twice as much as a Roku, at least.
[01:09:08.520 --> 01:09:14.680]   And really has only one advantage over the Roku, Apple's, iTunes, TV and movie.
[01:09:14.680 --> 01:09:17.000]   So Apple's got money to burn though.
[01:09:17.000 --> 01:09:19.240]   Yeah, they got the money.
[01:09:19.240 --> 01:09:24.120]   You know, it seems like I could imagine almost a scenario where they're like, we'll figure
[01:09:24.120 --> 01:09:25.720]   it out later.
[01:09:25.720 --> 01:09:27.840]   It's what it feels like.
[01:09:27.840 --> 01:09:29.720]   This is just another business right off.
[01:09:29.720 --> 01:09:30.720]   We got this.
[01:09:30.720 --> 01:09:31.720]   Yeah.
[01:09:31.720 --> 01:09:38.440]   And yet, you got to think that people like Shyamalan and Kristen Wiig and Jennifer Aniston
[01:09:38.440 --> 01:09:42.400]   they want some sort of, they're not going to just come there because they're going to
[01:09:42.400 --> 01:09:43.480]   get a check.
[01:09:43.480 --> 01:09:46.800]   They want to know where these are going to appear, who's going to be able to see them.
[01:09:46.800 --> 01:09:53.160]   I can't imagine really people of this caliber saying, oh, yeah, it's okay if it's only on
[01:09:53.160 --> 01:09:54.240]   an Apple TV.
[01:09:54.240 --> 01:09:58.000]   That's just not, that's not going to get the big names.
[01:09:58.000 --> 01:09:59.000]   Yeah.
[01:09:59.000 --> 01:10:03.840]   Apple music doing, by the way, like as an Android user, I admit, I don't pay a lot of
[01:10:03.840 --> 01:10:08.840]   attention to how Apple music is doing in comparison to Spotify and some of the other
[01:10:08.840 --> 01:10:09.840]   services.
[01:10:09.840 --> 01:10:15.560]   But I remember when Apple music launched, it was like, oh, 14 million automatic installs
[01:10:15.560 --> 01:10:16.680]   or whatever it was.
[01:10:16.680 --> 01:10:21.080]   And then I didn't get the sense that a lot of people opted into it.
[01:10:21.080 --> 01:10:26.560]   So I feel like understanding whether or not Apple music is a success is a potential way
[01:10:26.560 --> 01:10:31.400]   to look at how Apple might be successful in making this kind of content, right?
[01:10:31.400 --> 01:10:38.320]   According to the Wall Street Journal, once again, Apple is on track to actually overtake
[01:10:38.320 --> 01:10:40.320]   Spotify in paid users.
[01:10:40.320 --> 01:10:46.240]   It's not even close to Spotify's total users because they have, I don't know, tens of millions,
[01:10:46.240 --> 01:10:52.520]   I think 70 million subscribers if you include the free tier.
[01:10:52.520 --> 01:10:54.480]   But Apple's quickly catching up.
[01:10:54.480 --> 01:10:59.880]   Apple said they told the Wall Street Journal, they have 36 million paid global users.
[01:10:59.880 --> 01:11:08.320]   That's a growth in just a few months, I think, but something like 5% growth in one month.
[01:11:08.320 --> 01:11:11.680]   And Spotify growing 2% of months in paid users.
[01:11:11.680 --> 01:11:17.040]   So those lines will cross at some point in the near future.
[01:11:17.040 --> 01:11:18.040]   Yeah.
[01:11:18.040 --> 01:11:20.200]   So Apple's growing.
[01:11:20.200 --> 01:11:23.960]   My theory, I don't have anybody telling me anything.
[01:11:23.960 --> 01:11:24.960]   It's just a theory.
[01:11:24.960 --> 01:11:31.280]   I remember that Amazon video was gone from the Apple TV for quite a while.
[01:11:31.280 --> 01:11:33.040]   And it reappeared around the holidays.
[01:11:33.040 --> 01:11:36.360]   And my theory is that this was a reciprocal arrangement.
[01:11:36.360 --> 01:11:41.600]   So that just like you can have Apple music on an Android device that they will make a
[01:11:41.600 --> 01:11:47.400]   deal with or have made a deal with Amazon so that it'll show up on the fire.
[01:11:47.400 --> 01:11:49.560]   Apple music will show up on the fire.
[01:11:49.560 --> 01:11:53.760]   Know that Apple TV or whatever this channel is.
[01:11:53.760 --> 01:11:54.760]   Yeah.
[01:11:54.760 --> 01:11:55.760]   And programming.
[01:11:55.760 --> 01:12:01.200]   But then what's the incentive for Apple just to make a successful business creating programming?
[01:12:01.200 --> 01:12:03.440]   It's just another arm.
[01:12:03.440 --> 01:12:04.440]   Yeah.
[01:12:04.440 --> 01:12:06.440]   It doesn't seem strategic for them.
[01:12:06.440 --> 01:12:12.760]   It seems like that's why we all assume that's going to be an Apple TV exclusive because
[01:12:12.760 --> 01:12:16.160]   what's the strategic goal here?
[01:12:16.160 --> 01:12:21.040]   Why would I mean, honestly, really, do you think Apple wants to be another Netflix?
[01:12:21.040 --> 01:12:22.040]   That's their goal?
[01:12:22.040 --> 01:12:25.800]   It might be them clinging to the coolness factor.
[01:12:25.800 --> 01:12:29.000]   Like I feel like it might be them just saying like we need to be involved.
[01:12:29.000 --> 01:12:35.640]   Like part of our brand is being the brand of artists and creators and people who do creative
[01:12:35.640 --> 01:12:36.640]   things.
[01:12:36.640 --> 01:12:37.640]   Yeah.
[01:12:37.640 --> 01:12:41.400]   I wonder if that's part of it for them like wanting to stay cool.
[01:12:41.400 --> 01:12:42.400]   If you will.
[01:12:42.400 --> 01:12:47.360]   And we're not going to seed all of this other ground just like in payments, right?
[01:12:47.360 --> 01:12:50.600]   Like every other industry, we have to have a competitive foothold.
[01:12:50.600 --> 01:12:55.080]   Even if we don't have dominant market share, we have to have a competitive foothold in
[01:12:55.080 --> 01:12:56.360]   other markets.
[01:12:56.360 --> 01:12:58.840]   And that includes audio content.
[01:12:58.840 --> 01:13:00.760]   It includes video content.
[01:13:00.760 --> 01:13:07.480]   And I think that Apple's not going to let like Ben said, there's a sexy hip factor and
[01:13:07.480 --> 01:13:12.880]   Apple's not going to let that go away just because we don't feel like doing video.
[01:13:12.880 --> 01:13:17.320]   Apple is sexy according to the annual brand intimacy service service.
[01:13:17.320 --> 01:13:22.680]   Always has been always been sexy.
[01:13:22.680 --> 01:13:29.800]   It's a survey is designed to determine which brands generate the strongest emotional bonds
[01:13:29.800 --> 01:13:30.800]   with consumers.
[01:13:30.800 --> 01:13:34.080]   6,000 consumers across the USA, Mexico and the UAE.
[01:13:34.080 --> 01:13:36.640]   I don't know why they picked the UAE.
[01:13:36.640 --> 01:13:40.600]   Apple number one on the list again.
[01:13:40.600 --> 01:13:45.840]   And both among normal people and young people among millennials, Disney just falls off the
[01:13:45.840 --> 01:13:46.840]   chart.
[01:13:46.840 --> 01:13:47.840]   Interesting.
[01:13:47.840 --> 01:13:52.920]   Amazon goes up and YouTube is number three.
[01:13:52.920 --> 01:14:00.040]   So among millennials, it's Apple Amazon YouTube PlayStation, Starbucks, Nintendo, Google,
[01:14:00.040 --> 01:14:02.440]   Netflix, Coca-Cola and Walmart.
[01:14:02.440 --> 01:14:07.280]   And I guess if you look at that, that kind of confirms what you're saying, Dan, that
[01:14:07.280 --> 01:14:14.600]   if you want to be a brand that people love that they identify with, look at Netflix's
[01:14:14.600 --> 01:14:15.600]   on this list.
[01:14:15.600 --> 01:14:18.680]   YouTube is on this list, create content that they love.
[01:14:18.680 --> 01:14:25.280]   And I'm going to look at that list and say, I'm sorry, go ahead, bro.
[01:14:25.280 --> 01:14:29.360]   No, I was saying I would have swapped number two and number three.
[01:14:29.360 --> 01:14:31.240]   You would have swapped Amazon and YouTube.
[01:14:31.240 --> 01:14:33.320]   Well, they're in there.
[01:14:33.320 --> 01:14:36.720]   I mean, the fact that YouTube's there at all is kind of is kind of knocking people on
[01:14:36.720 --> 01:14:43.960]   their on their behinds because nobody thought that YouTube would even be a player in there.
[01:14:43.960 --> 01:14:47.680]   But managing partner, MBLM, which does the studies is we were surprised and pleased to
[01:14:47.680 --> 01:14:52.080]   see YouTube as an addition to the top three most intimate brand, Intimate.
[01:14:52.080 --> 01:14:54.560]   Why is Victoria's secret not on here?
[01:14:54.560 --> 01:14:57.400]   Intimate brands from millennials this year.
[01:14:57.400 --> 01:15:02.280]   We believe its rise is due to our culture's continued need for escape and the brand's
[01:15:02.280 --> 01:15:06.560]   immediate diverse content personalities and growing offerings and movies and live TV.
[01:15:06.560 --> 01:15:10.040]   I mean, this data point alone confirms, Dan, what you were saying.
[01:15:10.040 --> 01:15:16.840]   I mean, that the sexy factor, the way to make your brand popular with young people is content.
[01:15:16.840 --> 01:15:18.040]   I guess you could argue that.
[01:15:18.040 --> 01:15:19.720]   Play stations on there because of content.
[01:15:19.720 --> 01:15:23.920]   Yeah, if you look at that list with the exception of perhaps, although maybe we could argue with
[01:15:23.920 --> 01:15:28.560]   the exception of perhaps Starbucks and Coca Cola, all of those companies are competitors
[01:15:28.560 --> 01:15:30.120]   of Apple in one way or another.
[01:15:30.120 --> 01:15:31.120]   Yeah.
[01:15:31.120 --> 01:15:32.120]   Very good.
[01:15:32.120 --> 01:15:33.720]   So why would they compete with them in video?
[01:15:33.720 --> 01:15:44.840]   In fact, if I were Apple, I'd create an addictive beverage called an apple juice or just cool.
[01:15:44.840 --> 01:15:45.840]   Cool.
[01:15:45.840 --> 01:15:46.840]   Cool.
[01:15:46.840 --> 01:15:47.840]   Cool.
[01:15:47.840 --> 01:15:48.840]   Let's go.
[01:15:48.840 --> 01:15:53.840]   And then they'd really have all of these guys.
[01:15:53.840 --> 01:15:59.240]   No, I think YouTube is on there because Logan Paul is so loved by so many.
[01:15:59.240 --> 01:16:00.240]   Yeah.
[01:16:00.240 --> 01:16:01.240]   Yeah.
[01:16:01.240 --> 01:16:02.240]   The millennials love Logan Paul.
[01:16:02.240 --> 01:16:03.240]   Yeah.
[01:16:03.240 --> 01:16:04.640]   For all we know, they actually do.
[01:16:04.640 --> 01:16:09.640]   I don't, you know, somebody loves Logan Paul even after, you know, he's been kind of
[01:16:09.640 --> 01:16:15.480]   booted now, but even after he came back after the suicide video, his subscriptions went
[01:16:15.480 --> 01:16:16.480]   up.
[01:16:16.480 --> 01:16:17.480]   Yeah.
[01:16:17.480 --> 01:16:19.160]   It's fascinating.
[01:16:19.160 --> 01:16:24.120]   I watch my son who's 23.
[01:16:24.120 --> 01:16:28.160]   And the more extreme and he watches nothing but YouTube, he doesn't watch TV very much.
[01:16:28.160 --> 01:16:29.160]   More extreme.
[01:16:29.160 --> 01:16:30.160]   The video is on YouTube.
[01:16:30.160 --> 01:16:32.160]   The more likely he is to watch it.
[01:16:32.160 --> 01:16:34.200]   My son is similar.
[01:16:34.200 --> 01:16:39.840]   My younger son, he's similar in that where it's all YouTube all day long.
[01:16:39.840 --> 01:16:45.480]   And he's got a few people that he's just, just, how old you to and subscribe to him.
[01:16:45.480 --> 01:16:46.880]   I don't know how old he is.
[01:16:46.880 --> 01:16:48.880]   He's in the sixth grade.
[01:16:48.880 --> 01:16:50.720]   He's about 12.
[01:16:50.720 --> 01:16:51.720]   Okay.
[01:16:51.720 --> 01:16:53.520]   I'll tell you how old your son is.
[01:16:53.520 --> 01:16:54.520]   Yeah, he's 12.
[01:16:54.520 --> 01:16:56.080]   He's in the sixth grade.
[01:16:56.080 --> 01:16:59.120]   He's not old enough to work legally.
[01:16:59.120 --> 01:17:01.160]   Otherwise you'd be putting him to work, wouldn't you?
[01:17:01.160 --> 01:17:02.000]   Exactly.
[01:17:02.000 --> 01:17:03.000]   Do you know that?
[01:17:03.000 --> 01:17:09.480]   No, I think that that's for sure true about people under 18 is YouTube is everything, right?
[01:17:09.480 --> 01:17:13.400]   But there, but, you know, and we've talked about this before, there, there, as a result,
[01:17:13.400 --> 01:17:18.200]   there's this drive to make stuff more extreme because that's really what you get with YouTube.
[01:17:18.200 --> 01:17:22.880]   Henry started watching fail videos, which always made me cringe.
[01:17:22.880 --> 01:17:25.600]   It's people crashing into walls and stuff.
[01:17:25.600 --> 01:17:29.320]   Just, oh, it just makes me cringe.
[01:17:29.320 --> 01:17:32.640]   But then if you watch enough of that, then you need to up the ante.
[01:17:32.640 --> 01:17:37.440]   And you got to watch some kid who set mattresses on fire and, you know, just.
[01:17:37.440 --> 01:17:42.920]   Do you guys track Ben, especially because you follow Reddit, the YouTube kids and Elsa
[01:17:42.920 --> 01:17:44.920]   gate controversy?
[01:17:44.920 --> 01:17:49.680]   Oh, no, I don't know anything about Elsa gate.
[01:17:49.680 --> 01:17:50.680]   What is Elsa gate?
[01:17:50.680 --> 01:17:54.600]   Oh, first of all, don't, don't Google this with kids in the room.
[01:17:54.600 --> 01:17:58.040]   Ben can probably provide a lot of the meat here.
[01:17:58.040 --> 01:18:04.120]   But this was, this is, these are videos that use popular Disney and Warner Brothers characters
[01:18:04.120 --> 01:18:06.760]   like Elsa, Spider-Man, Batman.
[01:18:06.760 --> 01:18:10.960]   Oh, yeah, we've talked, these are the creepy, the creepy YouTube kid video creepy.
[01:18:10.960 --> 01:18:16.120]   But they were, I mean, these are top 100 YouTube channels that were racking up millions and
[01:18:16.120 --> 01:18:18.280]   millions of views.
[01:18:18.280 --> 01:18:19.880]   There was a subreddit called Asigate.
[01:18:19.880 --> 01:18:23.680]   I was not up on the, on the jargon.
[01:18:23.680 --> 01:18:25.440]   It's really disturbing stuff.
[01:18:25.440 --> 01:18:26.440]   It's creepy.
[01:18:26.440 --> 01:18:28.440]   YouTube has taken action, haven't they?
[01:18:28.440 --> 01:18:31.640]   They've removed the algorithmic stuff.
[01:18:31.640 --> 01:18:37.800]   They've, although, you know, again, after the shooting in Parkland, of course, the conspiracy
[01:18:37.800 --> 01:18:44.360]   theories about Parkland were the ones that YouTube promoted to the top until humans intervene.
[01:18:44.360 --> 01:18:47.120]   The algorithm doesn't do a very good job of picking up algorithms.
[01:18:47.120 --> 01:18:48.120]   Cramp.
[01:18:48.120 --> 01:18:51.680]   We need to fix our recommendation and engines.
[01:18:51.680 --> 01:18:52.680]   That's for sure.
[01:18:52.680 --> 01:18:55.480]   That seems to be more and more true all of the time.
[01:18:55.480 --> 01:19:00.280]   The recommendation engines on large platforms are not great.
[01:19:00.280 --> 01:19:01.280]   Yeah.
[01:19:01.280 --> 01:19:06.600]   Aren't these the same companies hiring the best and brightest minds in artificial intelligence
[01:19:06.600 --> 01:19:09.000]   and they can't fix their recommendation engines?
[01:19:09.000 --> 01:19:13.200]   Well, it does kind of make you wonder if all of the things we're worried about with AI
[01:19:13.200 --> 01:19:17.080]   are really nothing to worry about because computers actually are much dumber than we
[01:19:17.080 --> 01:19:23.560]   really never Netflix, the Netflix prize, which was all about, I think they were offering
[01:19:23.560 --> 01:19:30.200]   a million dollars for improving the Netflix recommendation engine.
[01:19:30.200 --> 01:19:37.360]   This was years ago and it was kind of a flop.
[01:19:37.360 --> 01:19:44.760]   They brought in, this was what, 2006, all they asked was that the company's recommendation
[01:19:44.760 --> 01:19:53.540]   engine be 10% more accurate and they offered a data set, 100 million ratings of 17,000
[01:19:53.540 --> 01:19:55.720]   movies from half a million customers.
[01:19:55.720 --> 01:20:02.600]   They had all of these AI people working on this and they had a winner.
[01:20:02.600 --> 01:20:06.200]   They gave away the million dollars, but they never implemented it because it wasn't that
[01:20:06.200 --> 01:20:07.200]   good.
[01:20:07.200 --> 01:20:16.700]   So it's easier for Elon Musk and his team to do dueling, synchronized rocket booster
[01:20:16.700 --> 01:20:17.700]   wings.
[01:20:17.700 --> 01:20:18.700]   Yes.
[01:20:18.700 --> 01:20:19.700]   Yes.
[01:20:19.700 --> 01:20:20.700]   Dan, to get my ratings.
[01:20:20.700 --> 01:20:21.700]   Yes.
[01:20:21.700 --> 01:20:26.260]   If you think about it and if you think about computer programming, yes, it's much easier
[01:20:26.260 --> 01:20:27.260]   to do that.
[01:20:27.260 --> 01:20:28.260]   Holy crap.
[01:20:28.260 --> 01:20:30.000]   That's what computers are good at.
[01:20:30.000 --> 01:20:31.600]   You know, why don't we get variables?
[01:20:31.600 --> 01:20:35.020]   We got variables like let's make them land at the same time.
[01:20:35.020 --> 01:20:38.900]   But to understand how humans work, forget it.
[01:20:38.900 --> 01:20:43.780]   We need to upload that record storage, jerks consciousness to the Internet.
[01:20:43.780 --> 01:20:47.620]   And then that will solve the problem.
[01:20:47.620 --> 01:20:57.140]   And it really is why I'm not too worried about AI because humans are intractable problems.
[01:20:57.140 --> 01:20:59.380]   We don't make any sense.
[01:20:59.380 --> 01:21:03.380]   Machines are in a different world from us.
[01:21:03.380 --> 01:21:07.180]   Did you see that thing that was going around on Twitter about the video?
[01:21:07.180 --> 01:21:13.580]   You guys, I'm sure, have all seen it, that video of that figure that learned how to
[01:21:13.580 --> 01:21:15.980]   walk and then run.
[01:21:15.980 --> 01:21:17.420]   And there was an animation of it.
[01:21:17.420 --> 01:21:18.420]   Do you know what I'm talking about?
[01:21:18.420 --> 01:21:19.420]   With machine learning.
[01:21:19.420 --> 01:21:20.420]   For lost dynamics.
[01:21:20.420 --> 01:21:21.420]   Yeah.
[01:21:21.420 --> 01:21:27.420]   And, well, not the actual robot, but just it was a representation.
[01:21:27.420 --> 01:21:28.420]   Yeah.
[01:21:28.420 --> 01:21:32.620]   And the way that it ran is completely silly and ridiculous.
[01:21:32.620 --> 01:21:36.420]   The way that it learned how to run and learned how to balance.
[01:21:36.420 --> 01:21:40.980]   And the people were just talking about it on Twitter last week, basically saying we're
[01:21:40.980 --> 01:21:43.780]   all going to die, but it's going to be hilarious.
[01:21:43.780 --> 01:21:47.260]   Just the way that it, there you go.
[01:21:47.260 --> 01:21:48.260]   That's the one.
[01:21:48.260 --> 01:21:50.100]   That's the guy.
[01:21:50.100 --> 01:21:51.100]   Okay.
[01:21:51.100 --> 01:21:52.100]   Okay.
[01:21:52.100 --> 01:21:53.900]   This is deep mind.
[01:21:53.900 --> 01:22:00.460]   It's Google's big AI engine teaching itself how to walk and run.
[01:22:00.460 --> 01:22:03.260]   But the point is it works, right?
[01:22:03.260 --> 01:22:04.260]   Yeah.
[01:22:04.260 --> 01:22:06.500]   And Google is really good at go.
[01:22:06.500 --> 01:22:07.500]   Yeah.
[01:22:07.500 --> 01:22:12.680]   Google's not saying it had to look good or it could people didn't have to laugh at it,
[01:22:12.680 --> 01:22:13.680]   but it's just that you had to make progress.
[01:22:13.680 --> 01:22:16.860]   I remember, well, my kids were little.
[01:22:16.860 --> 01:22:23.120]   I used to put a screensaver on their computer called the Breathe Walker, B-R-E-V-E, which
[01:22:23.120 --> 01:22:29.040]   was a four-legged thing that started just flopped on the ground and then would have tried
[01:22:29.040 --> 01:22:30.900]   different strategies to learn to walk.
[01:22:30.900 --> 01:22:34.140]   And you just let it run on your computer for days, weeks, months.
[01:22:34.140 --> 01:22:36.420]   It really took a long time.
[01:22:36.420 --> 01:22:38.580]   And eventually it would run to learn to walk.
[01:22:38.580 --> 01:22:40.740]   I don't like this.
[01:22:40.740 --> 01:22:42.740]   You have to jump.
[01:22:42.740 --> 01:22:47.680]   I could jump over the wall.
[01:22:47.680 --> 01:22:49.160]   Yes, I can.
[01:22:49.160 --> 01:22:53.840]   But imagine a killer robot about to destroy you.
[01:22:53.840 --> 01:22:54.920]   It runs like this.
[01:22:54.920 --> 01:22:56.240]   You better not laugh.
[01:22:56.240 --> 01:22:58.720]   You better run the other way.
[01:22:58.720 --> 01:23:04.280]   Oh, see, see, this is that we're in trouble because this is, it's only going to get, it's
[01:23:04.280 --> 01:23:09.720]   only going to get worse and it's going to come as long as the water hose.
[01:23:09.720 --> 01:23:10.720]   That's right.
[01:23:10.720 --> 01:23:12.240]   Just some frozen water.
[01:23:12.240 --> 01:23:13.400]   That's all we need.
[01:23:13.400 --> 01:23:15.240]   That's all we need.
[01:23:15.240 --> 01:23:16.800]   Oh, good news.
[01:23:16.800 --> 01:23:22.200]   Apparently, an office 2000 update is available on the machine that we're calling Ant on.
[01:23:22.200 --> 01:23:24.640]   You might want to install that update now.
[01:23:24.640 --> 01:23:25.640]   Get the latest.
[01:23:25.640 --> 01:23:27.480]   Let me go ahead and install it right now.
[01:23:27.480 --> 01:23:33.000]   I don't think it's you.
[01:23:33.000 --> 01:23:34.680]   You know, thank you, office.
[01:23:34.680 --> 01:23:35.680]   Thank you, Microsoft.
[01:23:35.680 --> 01:23:39.560]   Microsoft is so, speaking of idiot computers.
[01:23:39.560 --> 01:23:47.400]   Microsoft is so adept at stopping, just interrupting whatever you're doing with worthless dialogue
[01:23:47.400 --> 01:23:49.040]   boxes.
[01:23:49.040 --> 01:23:53.200]   I was at an event, big conference with lots of booths and tables and they had a, they're
[01:23:53.200 --> 01:23:58.640]   projecting up in the wall information and a big Windows update box shows up.
[01:23:58.640 --> 01:24:01.480]   So we've got a new version of, it sat there for 20 minutes.
[01:24:01.480 --> 01:24:02.480]   I took a picture of it.
[01:24:02.480 --> 01:24:03.840]   We got a new version of Windows.
[01:24:03.840 --> 01:24:04.840]   You want to update?
[01:24:04.840 --> 01:24:07.400]   Man, that happened to me at an airport.
[01:24:07.400 --> 01:24:12.840]   I think I was in Atlanta somewhere and the, the pop up was on the screen and it just totally
[01:24:12.840 --> 01:24:17.200]   freaked people out and I'm like, who's watching this?
[01:24:17.200 --> 01:24:19.280]   This is the last place that should pop up.
[01:24:19.280 --> 01:24:20.520]   You should see it.
[01:24:20.520 --> 01:24:22.160]   It just, it is ridiculous.
[01:24:22.160 --> 01:24:23.160]   So yeah, you're right.
[01:24:23.160 --> 01:24:25.200]   This is why I'm not worried about AI.
[01:24:25.200 --> 01:24:31.080]   We're not even, we're not even close, not even close.
[01:24:31.080 --> 01:24:34.360]   Although it is fun to look at those Boston dynamics videos.
[01:24:34.360 --> 01:24:35.360]   It is.
[01:24:35.360 --> 01:24:36.680]   It's the most interesting thing.
[01:24:36.680 --> 01:24:46.000]   If you want an actual forecast into the next like maybe three decades, Nick Bostrom's book,
[01:24:46.000 --> 01:24:49.640]   "Superintelligence" is a pretty good read.
[01:24:49.640 --> 01:24:55.020]   It will help you understand the realities of, and I even hate saying artificial and tau,
[01:24:55.020 --> 01:25:05.900]   and tough moment of the one to top of the one to top of the one about the one to top of the one to top of one to pop on top of the next
[01:25:05.900 --> 01:25:23.120]   saves from the life of the man has a Fit
[01:25:23.120 --> 01:25:23.960]   - Who's...
[01:25:23.960 --> 01:25:27.280]   - Changing my default camera and my default microphone.
[01:25:27.280 --> 01:25:29.180]   - 'Cause it knows better.
[01:25:29.180 --> 01:25:30.180]   Yeah, yeah, yeah.
[01:25:30.180 --> 01:25:32.740]   - No you stupid human you don't know anything,
[01:25:32.740 --> 01:25:35.080]   I'm gonna take care of this all for you.
[01:25:35.080 --> 01:25:35.920]   - Yeah.
[01:25:35.920 --> 01:25:36.840]   - We interviewed, didn't we?
[01:25:36.840 --> 01:25:38.800]   Carson I'm gonna, I'm pretty sure we interviewed
[01:25:38.800 --> 01:25:40.760]   Nick Bostrom about super intelligence
[01:25:40.760 --> 01:25:43.560]   on triangulation a year or two ago.
[01:25:43.560 --> 01:25:46.440]   And he's great, he's legendary, he's the guy who came up
[01:25:46.440 --> 01:25:51.440]   with the, what do they call that theory that we're all
[01:25:52.080 --> 01:25:54.080]   in a simulation, the simulation theory.
[01:25:54.080 --> 01:25:55.160]   He's written a lot about that.
[01:25:55.160 --> 01:25:56.320]   - Simulation hypothesis.
[01:25:56.320 --> 01:25:57.160]   - Yeah.
[01:25:57.160 --> 01:25:59.000]   - He's also the paperclip guy, right?
[01:25:59.000 --> 01:26:01.840]   - Yes, unlimited paperclips.
[01:26:01.840 --> 01:26:06.160]   - He said, if you design an AI to make paperclips,
[01:26:06.160 --> 01:26:08.800]   it'll optimize for paperclips until it consumes
[01:26:08.800 --> 01:26:11.560]   all the resources in the universe
[01:26:11.560 --> 01:26:14.120]   and turns them into paperclips.
[01:26:14.120 --> 01:26:16.000]   It is a very good, now he's a little more,
[01:26:16.000 --> 01:26:18.800]   as I remember, it's been a while, he's a little more,
[01:26:18.800 --> 01:26:21.120]   he is not sanguine about the future of AI,
[01:26:21.120 --> 01:26:23.280]   he's a little more worried about AI, right?
[01:26:23.280 --> 01:26:24.120]   - Oh yeah.
[01:26:24.120 --> 01:26:24.960]   - Yeah.
[01:26:24.960 --> 01:26:26.800]   - And he's certainly very knowledgeable.
[01:26:26.800 --> 01:26:30.040]   - The future of humanity institute, right?
[01:26:30.040 --> 01:26:32.840]   - Yeah, apparently it's not good.
[01:26:32.840 --> 01:26:36.580]   (laughing)
[01:26:36.580 --> 01:26:39.280]   Okay, let's take a little pause here,
[01:26:39.280 --> 01:26:41.720]   pause to refresh, you may,
[01:26:41.720 --> 01:26:44.640]   you make all consume beverages while we take a look
[01:26:44.640 --> 01:26:49.280]   at a little video we made of the fun time we had this week
[01:26:49.280 --> 01:26:50.120]   on Twitch.
[01:26:50.120 --> 01:26:50.960]   (gagging)
[01:26:50.960 --> 01:26:52.440]   - Previously on Twitch.
[01:26:52.440 --> 01:26:53.680]   - Of course, the big news of the week,
[01:26:53.680 --> 01:26:56.680]   Amazon's Echo is laughing at people.
[01:26:56.680 --> 01:26:59.000]   (laughing)
[01:26:59.000 --> 01:27:00.560]   So there's a couple of things at play here.
[01:27:00.560 --> 01:27:03.960]   First of all, why does he have a giant Toblerone bar?
[01:27:03.960 --> 01:27:05.040]   - That is a lot of chocos.
[01:27:05.040 --> 01:27:06.680]   - And where can I get that?
[01:27:06.680 --> 01:27:08.560]   - Sure, I can laugh.
[01:27:08.560 --> 01:27:10.040]   - Teehee.
[01:27:10.040 --> 01:27:11.320]   - All about Android.
[01:27:11.320 --> 01:27:14.040]   - This is a Google clips, it is not on right now,
[01:27:14.040 --> 01:27:16.680]   I'm gonna show you how it works on here in a second,
[01:27:16.680 --> 01:27:18.840]   but to turn it on, all I have to do is this.
[01:27:19.680 --> 01:27:23.160]   - And then I would place it down or beyond.
[01:27:23.160 --> 01:27:25.760]   $208 is a lot to spend on a machine learning,
[01:27:25.760 --> 01:27:28.520]   on a camera that uses kind of the same machine learning,
[01:27:28.520 --> 01:27:30.680]   that's already in the Pixel 2 phone.
[01:27:30.680 --> 01:27:32.920]   - I hope it didn't capture me picking my nose.
[01:27:32.920 --> 01:27:33.760]   - I hope not either.
[01:27:33.760 --> 01:27:34.600]   (laughing)
[01:27:34.600 --> 01:27:36.120]   - Oh, I did.
[01:27:36.120 --> 01:27:37.640]   We're good, we're good.
[01:27:37.640 --> 01:27:39.080]   - Mega week weekly.
[01:27:39.080 --> 01:27:41.680]   - 911 recordings reveal.
[01:27:41.680 --> 01:27:46.760]   There is a problem at the new Apple campus.
[01:27:46.760 --> 01:27:48.840]   We had an individual ran into a glass wall pane
[01:27:48.840 --> 01:27:50.320]   and they hit their head.
[01:27:50.320 --> 01:27:51.920]   An Apple caller said on one of the calls
[01:27:51.920 --> 01:27:53.080]   they have a small cut in their head
[01:27:53.080 --> 01:27:55.560]   and they are bleeding slightly disoriented.
[01:27:55.560 --> 01:27:57.640]   I have a suggestion.
[01:27:57.640 --> 01:27:59.680]   - Exactly what Apple needs,
[01:27:59.680 --> 01:28:02.400]   which is some rainbow Apple stickers.
[01:28:02.400 --> 01:28:03.240]   - Yes.
[01:28:03.240 --> 01:28:06.240]   - Right, just put those on the windows Apple.
[01:28:06.240 --> 01:28:08.920]   That would be, it would fit in, it would be beautiful.
[01:28:08.920 --> 01:28:12.160]   - Twit, tell your boss it's job related.
[01:28:12.160 --> 01:28:14.580]   (laughing)
[01:28:14.580 --> 01:28:19.340]   - It is, it's job related.
[01:28:19.340 --> 01:28:22.540]   Our show today brought to you by the Ring Video Doorbell.
[01:28:22.540 --> 01:28:25.660]   Big fan of the rings got rings all over my house.
[01:28:25.660 --> 01:28:26.760]   I got Ring Doorbell in the front.
[01:28:26.760 --> 01:28:27.940]   We put that in a couple of years ago
[01:28:27.940 --> 01:28:29.880]   and I did it by the way, I feel very proud.
[01:28:29.880 --> 01:28:33.780]   I'm no handy man, as Lisa, my wife tells me all the time,
[01:28:33.780 --> 01:28:35.240]   but I said, no, no, I can do this.
[01:28:35.240 --> 01:28:38.260]   The Ring Doorbell comes with all the tools you need
[01:28:38.260 --> 01:28:40.020]   and a little level and everything.
[01:28:40.020 --> 01:28:41.800]   It's easy, you unscrew your old doorbell.
[01:28:41.800 --> 01:28:44.380]   There's two wires coming out of the frame there.
[01:28:44.380 --> 01:28:46.080]   It's actually much nicer installed
[01:28:46.080 --> 01:28:47.140]   than a traditional doorbell.
[01:28:47.140 --> 01:28:48.740]   It's got a bracket, a mounting bracket,
[01:28:48.740 --> 01:28:49.820]   everything to put it in there.
[01:28:49.820 --> 01:28:51.300]   You had to pair it to your wifi
[01:28:51.300 --> 01:28:54.440]   and now you've got eyes on your front door.
[01:28:54.440 --> 01:28:56.820]   The Ring Doorbell pairs to your wifi
[01:28:56.820 --> 01:28:59.300]   and then communicates with the Ring app on your phone.
[01:28:59.300 --> 01:29:03.060]   And anytime anybody walks by, it's got motion detection.
[01:29:03.060 --> 01:29:05.860]   You could set the range in the area that it's looking at.
[01:29:05.860 --> 01:29:07.100]   You can get a notification.
[01:29:07.100 --> 01:29:08.740]   Anytime anybody rings a doorbell,
[01:29:08.740 --> 01:29:10.060]   you can get a notification.
[01:29:10.060 --> 01:29:12.060]   And you can talk to them because it's got a speaker
[01:29:12.060 --> 01:29:13.660]   and it's got a microphone.
[01:29:13.660 --> 01:29:17.900]   Actually, it's really fun to make people jump
[01:29:17.900 --> 01:29:20.100]   with the Ring Video Doorbell.
[01:29:20.100 --> 01:29:23.580]   There are some wonderful videos on the Ring Twitter feed.
[01:29:23.580 --> 01:29:24.660]   Here's, this is a good one.
[01:29:24.660 --> 01:29:26.940]   Actually, I think turn on the audio on this one.
[01:29:26.940 --> 01:29:28.940]   (engine revving)
[01:29:28.940 --> 01:29:30.580]   They're opening the box.
[01:29:30.580 --> 01:29:31.860]   This is, these are very dedicated.
[01:29:31.860 --> 01:29:34.460]   - Hey, hey, hey, get away.
[01:29:34.460 --> 01:29:39.140]   - And then watch, one of them runs the wrong way.
[01:29:39.140 --> 01:29:41.140]   So she comes back and goes the other way.
[01:29:41.140 --> 01:29:43.380]   (laughing)
[01:29:43.380 --> 01:29:45.580]   Hours of fun watching people.
[01:29:45.580 --> 01:29:46.420]   - Ringed up.
[01:29:46.420 --> 01:29:47.900]   - Everybody open my box.
[01:29:47.900 --> 01:29:48.820]   - Can I hear you?
[01:29:48.820 --> 01:29:49.660]   - You're win.
[01:29:49.660 --> 01:29:50.500]   - Oh, no.
[01:29:50.500 --> 01:29:51.340]   - No way.
[01:29:51.340 --> 01:29:53.380]   (laughing)
[01:29:53.380 --> 01:29:56.460]   - Actual footage from an actual Ring Video Doorbell.
[01:29:56.460 --> 01:29:58.860]   Twitter.com/ring, it's always fun.
[01:29:58.860 --> 01:30:02.660]   The doorbell is great because most of the time
[01:30:02.660 --> 01:30:04.300]   I don't have people stealing packages,
[01:30:04.300 --> 01:30:06.500]   although if you have a problem with that, it's fabulous.
[01:30:06.500 --> 01:30:08.140]   A lot of the time, it's just somebody at the doorbell
[01:30:08.140 --> 01:30:09.860]   and I can say, "I'll be right there."
[01:30:09.860 --> 01:30:12.820]   Or if it's the UPS person with a package,
[01:30:12.820 --> 01:30:14.900]   I want to say, "I am in the bathtub."
[01:30:14.900 --> 01:30:16.460]   Joe, you know me, just leave it there.
[01:30:16.460 --> 01:30:18.420]   I'll sign for it tomorrow and it always works.
[01:30:18.420 --> 01:30:20.100]   Then you can keep an eye on the package.
[01:30:20.100 --> 01:30:23.180]   You can also get the really great Ring floodlight cams.
[01:30:23.180 --> 01:30:25.620]   And I've got a couple to replace the,
[01:30:25.620 --> 01:30:27.980]   there's old cameras, not cameras,
[01:30:27.980 --> 01:30:29.540]   lights that you have on the side of your house
[01:30:29.540 --> 01:30:30.780]   that light up when you walk there.
[01:30:30.780 --> 01:30:32.860]   So these replace those security lights.
[01:30:32.860 --> 01:30:34.380]   They're better, actually, in a lot of ways.
[01:30:34.380 --> 01:30:35.780]   They're LEDs, they're brighter,
[01:30:35.780 --> 01:30:38.780]   they never have to replace the bulb,
[01:30:38.780 --> 01:30:40.340]   but they also have the Ring camera,
[01:30:40.340 --> 01:30:43.980]   high def camera, speaker, microphone, motion sensor,
[01:30:43.980 --> 01:30:48.420]   and 110 decibel alarm on there.
[01:30:48.420 --> 01:30:50.740]   And now when somebody comes around the back of my house,
[01:30:50.740 --> 01:30:52.740]   not only do I see them, I can scare them away.
[01:30:52.740 --> 01:30:54.540]   I would actually mostly raccoons for me,
[01:30:54.540 --> 01:30:55.540]   but it's great.
[01:30:55.540 --> 01:30:58.460]   Raccoons do not like the alarm, I've found.
[01:30:58.460 --> 01:30:59.620]   So I have a couple of those.
[01:30:59.620 --> 01:31:02.980]   Now I've got a Ring of security all the way around my house.
[01:31:02.980 --> 01:31:05.780]   I love the Ring video doorbell.
[01:31:05.780 --> 01:31:08.380]   You're going to end the Ring floodlight cams.
[01:31:08.380 --> 01:31:11.140]   You're going to get up to $150 off a Ring of security kit
[01:31:11.140 --> 01:31:15.940]   for your house when you go to ring.com/twit.
[01:31:15.940 --> 01:31:18.620]   Thieves just can't hide with Ring.
[01:31:18.620 --> 01:31:19.940]   Stop crying before it happens.
[01:31:19.940 --> 01:31:22.540]   Make your neighborhood a safer place with Ring.
[01:31:22.540 --> 01:31:25.340]   Save up to $150 on the Ring of security kit
[01:31:25.340 --> 01:31:30.020]   at ring.com/twit, ring-ring.com/twit.
[01:31:30.020 --> 01:31:35.460]   This is a great device for you,
[01:31:35.460 --> 01:31:36.660]   and if you've already got one,
[01:31:36.660 --> 01:31:39.540]   consider it maybe for family and friends.
[01:31:39.540 --> 01:31:42.420]   Older parents, this is a really great thing to have.
[01:31:42.420 --> 01:31:44.500]   They don't have to get up and go to the door.
[01:31:44.500 --> 01:31:45.420]   They can see who's there.
[01:31:45.420 --> 01:31:48.380]   They could talk to them Ring.com/twit,
[01:31:48.380 --> 01:31:52.740]   and you'll save up to $150 on a Ring of security kit.
[01:31:52.740 --> 01:31:54.980]   Actually, kind of is a news story.
[01:31:54.980 --> 01:31:59.180]   Ring got purchased last week by somebody we know pretty well.
[01:31:59.180 --> 01:32:02.540]   Amazon, for something like $1 billion,
[01:32:02.540 --> 01:32:06.500]   Recode said it was upwards, maybe at $1.2 or $1.4 billion.
[01:32:06.500 --> 01:32:08.100]   We had a conference call last week.
[01:32:08.100 --> 01:32:08.940]   We were going to talk,
[01:32:08.940 --> 01:32:10.100]   as we often do with sponsors,
[01:32:10.100 --> 01:32:11.500]   we were going to talk to them.
[01:32:11.500 --> 01:32:13.220]   It was the day after the announcement,
[01:32:13.220 --> 01:32:14.300]   and they didn't show up, and I thought,
[01:32:14.300 --> 01:32:17.140]   you know, they're probably a little hungover shocking.
[01:32:17.140 --> 01:32:18.900]   (laughing)
[01:32:18.900 --> 01:32:21.580]   A little bit of champagne for Jamie and the crew,
[01:32:21.580 --> 01:32:23.780]   so congratulations Ring on that.
[01:32:23.780 --> 01:32:28.820]   I'm glad to see that one acquisition made by Google
[01:32:28.820 --> 01:32:30.820]   is now being cut loose.
[01:32:30.820 --> 01:32:35.260]   Are you guys fans of the Zagit guides, Zagit guides?
[01:32:35.260 --> 01:32:37.180]   I'm a huge fan.
[01:32:37.180 --> 01:32:39.780]   Google bought them for an awful lot of money,
[01:32:39.780 --> 01:32:40.780]   hundreds of millions of dollars.
[01:32:40.780 --> 01:32:42.860]   I enjoyed it as a got YouTube channel,
[01:32:42.860 --> 01:32:46.140]   but outside of that, I'd never see a thing about it.
[01:32:46.140 --> 01:32:46.980]   No, not anymore.
[01:32:46.980 --> 01:32:51.100]   Google bought them for $151 million in 2012,
[01:32:51.100 --> 01:32:53.220]   and did nothing.
[01:32:53.220 --> 01:32:54.340]   Basically killed these.
[01:32:54.340 --> 01:32:57.260]   These were the best restaurant guides ever.
[01:32:57.260 --> 01:32:59.580]   You have to be, I don't know if there's one for Charlotte,
[01:32:59.580 --> 01:33:03.540]   but boy, in New York or San Francisco or London or Paris,
[01:33:03.540 --> 01:33:04.820]   it's the best way to go.
[01:33:04.820 --> 01:33:08.460]   And Google just, I don't know, let it die.
[01:33:08.460 --> 01:33:13.460]   I guess they slowly rolled it into their maps,
[01:33:13.460 --> 01:33:17.660]   but then they decided instead to use their own ratings.
[01:33:17.660 --> 01:33:21.740]   And so Zagit, which is a great brand, just kind of languished.
[01:33:21.740 --> 01:33:25.100]   I'm glad the Zagit family got the $151,
[01:33:25.100 --> 01:33:27.420]   but now Zagit has been passed along
[01:33:27.420 --> 01:33:30.780]   for I think a considerable less lower amount of money
[01:33:30.780 --> 01:33:33.340]   to a company called the Infatuation.
[01:33:34.180 --> 01:33:38.340]   I don't know who they are, but I hope they do a bit.
[01:33:38.340 --> 01:33:41.180]   The Infatuation is, I guess,
[01:33:41.180 --> 01:33:45.740]   some sort of restaurant,
[01:33:45.740 --> 01:33:49.900]   I recommend, two former music industry executives
[01:33:49.900 --> 01:33:52.660]   wanted a way to recommend restaurants and bars
[01:33:52.660 --> 01:33:54.060]   to their friends.
[01:33:54.060 --> 01:33:56.620]   So they created the Infatuation,
[01:33:56.620 --> 01:33:59.100]   unlike Zagit, which uses real people for reviews.
[01:33:59.100 --> 01:34:01.460]   They had an in-house team of reviewers.
[01:34:01.460 --> 01:34:05.100]   They were in New York, San Francisco, Los Angeles, London.
[01:34:05.100 --> 01:34:08.940]   You may remember them from hashtag eats.
[01:34:08.940 --> 01:34:11.220]   I don't.
[01:34:11.220 --> 01:34:12.060]   Can't say that.
[01:34:12.060 --> 01:34:13.060]   (laughing)
[01:34:13.060 --> 01:34:14.460]   So, no, no.
[01:34:14.460 --> 01:34:16.780]   They also did.
[01:34:16.780 --> 01:34:19.980]   Zagit always showed up in, I feel like Zagit always showed up
[01:34:19.980 --> 01:34:22.980]   when I would Google something for a while, Google or business.
[01:34:22.980 --> 01:34:26.340]   But of course, Google always put its own ratings above.
[01:34:26.340 --> 01:34:28.700]   And it always felt like a little bit of an afterthought.
[01:34:28.700 --> 01:34:30.740]   Like the Zagit, the information around this
[01:34:30.740 --> 01:34:34.060]   Zagit rating that would sort of pop up in the business profile
[01:34:34.060 --> 01:34:37.260]   was so minimal and like was so different
[01:34:37.260 --> 01:34:39.740]   from the actual Google rating
[01:34:39.740 --> 01:34:42.580]   that I was always like, "Eh, I guess I'll use the Google rating
[01:34:42.580 --> 01:34:44.220]   'cause I can actually read the reviews."
[01:34:44.220 --> 01:34:45.540]   - Yeah.
[01:34:45.540 --> 01:34:48.540]   - And yeah, it just never really made sense to me
[01:34:48.540 --> 01:34:51.340]   how that stuff, how Google was pulling that message.
[01:34:51.340 --> 01:34:52.180]   - That's just me.
[01:34:52.180 --> 01:34:53.180]   I loved Zagit.
[01:34:53.180 --> 01:34:54.820]   I lived by Zagit guides.
[01:34:54.820 --> 01:34:56.140]   I would, when I came to a town,
[01:34:56.140 --> 01:34:58.860]   I would try to eat at the top Zagit restaurants.
[01:34:58.860 --> 01:35:02.860]   I always found their reviews were very helpful.
[01:35:02.860 --> 01:35:03.860]   But maybe it's--
[01:35:03.860 --> 01:35:06.420]   - But Google was telling them, "Google killed him."
[01:35:06.420 --> 01:35:07.420]   - Yeah, I told him.
[01:35:07.420 --> 01:35:09.420]   - Google told the interview I said to the local guides.
[01:35:09.420 --> 01:35:10.740]   - Yeah.
[01:35:10.740 --> 01:35:11.580]   - So that was--
[01:35:11.580 --> 01:35:13.300]   - And I enjoyed the local guides.
[01:35:13.300 --> 01:35:15.620]   I've gotten a lot of value out of local guides
[01:35:15.620 --> 01:35:18.820]   more so than anything else because I know it's real people.
[01:35:18.820 --> 01:35:19.740]   - That's true.
[01:35:19.740 --> 01:35:22.060]   - A lot of the times they actually lived there.
[01:35:22.060 --> 01:35:24.420]   - Well, that was the idea of Zagit as well.
[01:35:24.420 --> 01:35:25.860]   I've done local guides.
[01:35:25.860 --> 01:35:28.060]   Google will ask you if you've been somewhere,
[01:35:28.060 --> 01:35:29.820]   "Oh, can you answer some questions?"
[01:35:29.820 --> 01:35:31.740]   I actually have some local guide points.
[01:35:31.740 --> 01:35:32.740]   I do agree with you, Ann.
[01:35:32.740 --> 01:35:34.100]   That's a good solution.
[01:35:34.100 --> 01:35:37.460]   So maybe Zagit is old school.
[01:35:37.460 --> 01:35:39.380]   Maybe it's going the way of the checking account.
[01:35:39.380 --> 01:35:40.380]   I don't know.
[01:35:40.380 --> 01:35:41.340]   - Yeah, pretty much.
[01:35:41.340 --> 01:35:42.340]   - March 10th.
[01:35:42.340 --> 01:35:45.300]   Did you know yesterday was Mario Day?
[01:35:45.300 --> 01:35:47.780]   - No.
[01:35:47.780 --> 01:35:48.860]   (laughs)
[01:35:48.860 --> 01:35:49.780]   - Mario Day?
[01:35:49.780 --> 01:35:51.020]   - And ready or--
[01:35:51.020 --> 01:35:53.340]   - Mario, Mario.
[01:35:53.340 --> 01:35:54.260]   You know, Mario.
[01:35:54.260 --> 01:35:55.740]   - Which season?
[01:35:55.740 --> 01:35:59.060]   - At March 10th, get an M-A-R-I-O.
[01:35:59.060 --> 01:35:59.900]   I don't know.
[01:35:59.900 --> 01:36:03.220]   Anyway, Google put Mario on Google Maps.
[01:36:03.220 --> 01:36:05.100]   It's actually still there.
[01:36:05.100 --> 01:36:07.060]   You could, so I'll show you how you do it.
[01:36:07.060 --> 01:36:08.980]   If you're getting directions on Google Maps,
[01:36:08.980 --> 01:36:11.020]   you have to do it on your smartphone.
[01:36:11.020 --> 01:36:14.300]   So let's go to Google Maps and I'm gonna get directions.
[01:36:14.300 --> 01:36:18.340]   And you press a button, you become Mario.
[01:36:18.340 --> 01:36:20.300]   There's even sound, which we can't hear,
[01:36:20.300 --> 01:36:23.220]   but you become Mario and as you drive,
[01:36:23.220 --> 01:36:24.220]   what does it sound like?
[01:36:24.220 --> 01:36:25.060]   (blows raspberry)
[01:36:25.060 --> 01:36:27.540]   - You had to opt into this?
[01:36:27.540 --> 01:36:29.820]   - Yeah, you got a problem with that?
[01:36:29.820 --> 01:36:31.300]   - No, I was curious to--
[01:36:31.300 --> 01:36:32.140]   - Let me go out.
[01:36:32.140 --> 01:36:34.860]   - I had an appointment today and I had to have directions
[01:36:34.860 --> 01:36:36.380]   and I didn't see Mario on my screen.
[01:36:36.380 --> 01:36:39.220]   - So see that question mark next to that?
[01:36:39.220 --> 01:36:40.060]   - Okay.
[01:36:40.060 --> 01:36:43.580]   - So you tap that for the directions
[01:36:43.580 --> 01:36:48.020]   and it goes, "Bruhng, oh yeah, Mario time."
[01:36:48.020 --> 01:36:50.980]   And then you press the button that says, "Let's go."
[01:36:52.340 --> 01:36:55.380]   And by the way, I'm going to a, for some reason,
[01:36:55.380 --> 01:36:59.700]   a restaurant in Austin, Texas,
[01:36:59.700 --> 01:37:01.700]   that's a day and a half away, but okay.
[01:37:01.700 --> 01:37:03.420]   (laughs)
[01:37:03.420 --> 01:37:04.740]   And he says, "Liz, you hear?"
[01:37:04.740 --> 01:37:06.220]   - We wait for the old Redwood highway north.
[01:37:06.220 --> 01:37:08.700]   - No, that's not Mario, but before it was Mario.
[01:37:08.700 --> 01:37:09.540]   (laughs)
[01:37:09.540 --> 01:37:10.380]   - Oh wow.
[01:37:10.380 --> 01:37:12.220]   - I'll be there tomorrow, one day, one hour.
[01:37:12.220 --> 01:37:16.460]   I'll be there tomorrow for some barbecue, 8.26 p.m. tomorrow.
[01:37:16.460 --> 01:37:17.540]   Mario.
[01:37:17.540 --> 01:37:20.500]   It's kinda silly, I don't know.
[01:37:20.500 --> 01:37:21.340]   Do you think they get paid?
[01:37:21.340 --> 01:37:22.980]   - It's not bad for an Easter egg.
[01:37:22.980 --> 01:37:24.380]   - That's cool. - It's not bad for an Easter egg.
[01:37:24.380 --> 01:37:25.820]   - Yeah.
[01:37:25.820 --> 01:37:27.500]   - Yeah, I hope they leave it in for a little while.
[01:37:27.500 --> 01:37:29.660]   It's still there as of today.
[01:37:29.660 --> 01:37:32.180]   Take a screenshot of your root share it with Google Maps
[01:37:32.180 --> 01:37:35.860]   on Twitter and Instagram with a hashtag Mario Maps.
[01:37:35.860 --> 01:37:39.460]   And nothing will happen.
[01:37:39.460 --> 01:37:41.460]   - Yeah, I won't be doing that, it got enough on me.
[01:37:41.460 --> 01:37:43.300]   (laughs)
[01:37:43.300 --> 01:37:45.820]   - Spotty-o, come on!
[01:37:45.820 --> 01:37:46.660]   I like it.
[01:37:46.660 --> 01:37:49.100]   I like your response, Mario and Dreddy?
[01:37:49.100 --> 01:37:50.100]   I like that.
[01:37:50.100 --> 01:37:50.940]   - That's next.
[01:37:50.940 --> 01:37:51.860]   (laughs)
[01:37:51.860 --> 01:37:53.100]   That's next time.
[01:37:53.100 --> 01:37:55.580]   Let's see.
[01:37:55.580 --> 01:38:00.820]   Moving right along, Facebook asks users,
[01:38:00.820 --> 01:38:04.420]   "Should we allow men to ask children for sexual images?"
[01:38:04.420 --> 01:38:10.300]   I think the answer's no, but yeah, might as well ask.
[01:38:10.300 --> 01:38:12.940]   It was a mistake, they had a survey question.
[01:38:12.940 --> 01:38:16.060]   - Was this more AI?
[01:38:16.060 --> 01:38:18.620]   - Yeah, yeah, blame the computer.
[01:38:19.900 --> 01:38:22.740]   One question began, "There are a wide range of topics
[01:38:22.740 --> 01:38:25.140]   "and behaviors that appear on Facebook.
[01:38:25.140 --> 01:38:27.100]   "In thinking about an ideal world
[01:38:27.100 --> 01:38:29.220]   "where you could set Facebook's policies,
[01:38:29.220 --> 01:38:31.140]   "how would you handle the following?
[01:38:31.140 --> 01:38:33.140]   "A private message in which an adult man
[01:38:33.140 --> 01:38:36.060]   "asked a 14 year old girl for sexual pictures?"
[01:38:36.060 --> 01:38:41.580]   Just in case you're wondering the choices are,
[01:38:41.580 --> 01:38:43.620]   this content should not be allowed on Facebook
[01:38:43.620 --> 01:38:45.460]   and no one should be able to see it too.
[01:38:45.460 --> 01:38:47.260]   This content should be allowed on Facebook
[01:38:47.260 --> 01:38:49.060]   and I would not mind seeing it.
[01:38:49.060 --> 01:38:50.580]   (laughing)
[01:38:50.580 --> 01:38:51.900]   - Oh my God.
[01:38:51.900 --> 01:38:53.940]   - This is a place higher than a straight copy.
[01:38:53.940 --> 01:38:55.780]   - Oh my God.
[01:38:55.780 --> 01:38:57.780]   Please compare this to the Alexa laugh
[01:38:57.780 --> 01:39:00.540]   and it's really, you know, the Alexa laugh.
[01:39:00.540 --> 01:39:02.540]   I'll take the Alexa laugh over there.
[01:39:02.540 --> 01:39:03.580]   This is for sure.
[01:39:03.580 --> 01:39:07.180]   - We're asking, here's a tweet from Jonathan Haines,
[01:39:07.180 --> 01:39:09.820]   we're asking a small group of people for their opinion.
[01:39:09.820 --> 01:39:12.780]   Could you take a few minutes to answer this short survey?
[01:39:12.780 --> 01:39:15.940]   Or I have no preference, you know?
[01:39:15.940 --> 01:39:17.700]   - This is what they should tell regulators.
[01:39:17.700 --> 01:39:19.580]   Like, you want us to stop fake news?
[01:39:19.580 --> 01:39:21.700]   We can't write a survey correctly.
[01:39:21.700 --> 01:39:23.140]   - We can't even do this.
[01:39:23.140 --> 01:39:23.980]   - How can we stop?
[01:39:23.980 --> 01:39:24.820]   - We can't even do this.
[01:39:24.820 --> 01:39:25.660]   - Oh my gosh.
[01:39:25.660 --> 01:39:27.900]   - We are fake news.
[01:39:27.900 --> 01:39:32.420]   Did you see the science study of Twitter that said,
[01:39:32.420 --> 01:39:34.460]   "If you want to share on Twitter
[01:39:34.460 --> 01:39:37.940]   "and you want to get reshared, better lie.
[01:39:37.940 --> 01:39:40.700]   "Four and a half million tweets analyzed.
[01:39:40.700 --> 01:39:45.700]   "Falsehoods, fake news, 70% more likely to get shared."
[01:39:46.220 --> 01:39:51.220]   And this isn't just now, this is over 10 years from 2017 to 2006.
[01:39:51.220 --> 01:39:55.780]   Inaccurate news stories spread faster and further
[01:39:55.780 --> 01:39:58.860]   on Twitter than true stories.
[01:39:58.860 --> 01:40:00.460]   - That is shocking.
[01:40:00.460 --> 01:40:04.100]   - Just discuss whether they're outlandish things
[01:40:04.100 --> 01:40:06.660]   or is it just something that was, you know,
[01:40:06.660 --> 01:40:09.780]   it was a tomato and not a potato, things like that.
[01:40:09.780 --> 01:40:10.740]   (laughing)
[01:40:10.740 --> 01:40:12.740]   - That's a black and gold dress.
[01:40:12.740 --> 01:40:14.940]   No, no, you're right, I agree.
[01:40:14.940 --> 01:40:19.940]   Some people, they just go off on these sensationalized headlines
[01:40:19.940 --> 01:40:24.740]   that are, you know, oh wow, Robert Downey Jr. said what?
[01:40:24.740 --> 01:40:26.140]   You know, versus--
[01:40:26.140 --> 01:40:27.660]   - Well, the study was done here.
[01:40:27.660 --> 01:40:29.980]   I'll read, I don't know, the answer to your question.
[01:40:29.980 --> 01:40:31.180]   The study was done by MIT.
[01:40:31.180 --> 01:40:36.220]   They took 126,000 tweet cascades.
[01:40:36.220 --> 01:40:37.660]   - Over a decade, right?
[01:40:37.660 --> 01:40:38.700]   - Yeah, over a decade.
[01:40:38.700 --> 01:40:40.180]   - Over a decade.
[01:40:40.180 --> 01:40:44.500]   - 2,400 news stories, all of which had been either verified
[01:40:44.500 --> 01:40:48.420]   or debunked by at least one fact-checking organization.
[01:40:48.420 --> 01:40:50.740]   So they were really looking at kind of almost
[01:40:50.740 --> 01:40:54.180]   an epidemiological study, how far and fast
[01:40:54.180 --> 01:40:56.700]   each cascade spread.
[01:40:56.700 --> 01:40:57.900]   True news stories,
[01:40:57.900 --> 01:41:01.540]   stories that were verifiably true took six times longer
[01:41:01.540 --> 01:41:04.820]   to spread than false ones.
[01:41:04.820 --> 01:41:06.940]   - Mark Hamill is dead, those kind of twists.
[01:41:06.940 --> 01:41:09.020]   - Yeah, but yeah, I mean, if you think about it,
[01:41:09.020 --> 01:41:11.460]   of course that spreads faster, right?
[01:41:11.460 --> 01:41:12.300]   - All right.
[01:41:12.300 --> 01:41:16.580]   And if we think about it, it's good that Twitter
[01:41:16.580 --> 01:41:19.260]   and other organizations are able to analyze their network
[01:41:19.260 --> 01:41:21.300]   and show results like this.
[01:41:21.300 --> 01:41:25.300]   But if we think about bad actors,
[01:41:25.300 --> 01:41:27.700]   they've known this for a long time.
[01:41:27.700 --> 01:41:30.420]   And these systems, Twitter, Facebook,
[01:41:30.420 --> 01:41:32.260]   the rest of the social web,
[01:41:32.260 --> 01:41:36.740]   has been easy, easy exploitation for a very long time.
[01:41:36.740 --> 01:41:40.900]   And it feels disingenuous for these companies to say,
[01:41:40.900 --> 01:41:42.940]   "Oh, geez, we're just figuring this out now."
[01:41:42.940 --> 01:41:43.780]   - Yeah, they knew that.
[01:41:43.780 --> 01:41:44.620]   - Perhaps they are, perhaps they are.
[01:41:44.620 --> 01:41:45.460]   - Yeah.
[01:41:45.460 --> 01:41:46.780]   - Yeah, right.
[01:41:46.780 --> 01:41:50.940]   I mean, I don't, again, I don't want to say anybody's evil
[01:41:50.940 --> 01:41:54.620]   or had malicious intent or that these are bad actors
[01:41:54.620 --> 01:41:56.300]   running these companies, they're not,
[01:41:56.300 --> 01:42:00.860]   but it's ridiculous that they didn't know this long
[01:42:00.860 --> 01:42:04.820]   before these type of public studies are released.
[01:42:04.820 --> 01:42:06.700]   - I think it's more likely that they can't figure out
[01:42:06.700 --> 01:42:07.740]   how to solve it.
[01:42:07.740 --> 01:42:10.100]   And this is like, that's their way of putting out of it.
[01:42:10.100 --> 01:42:11.140]   Admitting that.
[01:42:11.140 --> 01:42:14.180]   That basically, they're like, "Ah, this is terrible stuff.
[01:42:14.180 --> 01:42:16.020]   "It's been going on for a really long time
[01:42:16.020 --> 01:42:18.180]   "and we don't know how to fix it."
[01:42:18.180 --> 01:42:20.060]   Like, that's a more embarrassing answer.
[01:42:20.060 --> 01:42:22.500]   And I feel like, I mean, did you guys watch that,
[01:42:22.500 --> 01:42:26.540]   that sort of like Twitter, Periscope chat this week
[01:42:26.540 --> 01:42:30.220]   and how that went immediately into a dumpster fire?
[01:42:30.220 --> 01:42:34.220]   Like, I feel like, I just feel like they don't,
[01:42:34.220 --> 01:42:36.180]   they don't know how to fix it.
[01:42:36.180 --> 01:42:39.820]   And that's the true and maybe
[01:42:39.820 --> 01:42:43.020]   they're happy to take advertising dollars.
[01:42:43.020 --> 01:42:44.380]   - Right.
[01:42:44.380 --> 01:42:48.260]   - Well, and even further to support their contention,
[01:42:48.260 --> 01:42:49.460]   they can't do much about it.
[01:42:49.460 --> 01:42:54.460]   The study also did both included and then excluded bots.
[01:42:54.460 --> 01:42:58.460]   And it turned out the automated Twitter accounts
[01:42:58.460 --> 01:43:01.540]   promoted traffic unlike humans about equally.
[01:43:01.540 --> 01:43:05.020]   They didn't prefer fake news.
[01:43:05.020 --> 01:43:07.020]   It's the humans.
[01:43:07.020 --> 01:43:09.980]   It's the humans that prefer fake news.
[01:43:09.980 --> 01:43:11.060]   But again, - There's no patch
[01:43:11.060 --> 01:43:12.180]   for human stupidity.
[01:43:12.180 --> 01:43:13.860]   - It's not surprising at all.
[01:43:13.860 --> 01:43:14.860]   - As the security, right?
[01:43:14.860 --> 01:43:16.140]   - If I, you nailed it.
[01:43:16.140 --> 01:43:18.740]   If I said, if I tweeted Mark Hamill who's dead,
[01:43:18.740 --> 01:43:22.900]   that's gonna spread much farther than Mark Hamill's alive.
[01:43:22.900 --> 01:43:23.740]   - Right.
[01:43:23.740 --> 01:43:25.740]   - You know, that's just not gonna,
[01:43:25.740 --> 01:43:26.900]   but that's always been that way.
[01:43:26.900 --> 01:43:28.140]   In fact, I think you could probably say
[01:43:28.140 --> 01:43:30.900]   that even predates social media.
[01:43:30.900 --> 01:43:33.420]   That's just the way we are built.
[01:43:33.420 --> 01:43:37.380]   Conspiracy theories spread farther and faster.
[01:43:37.380 --> 01:43:40.580]   You know, if you say Kennedy was shot by a lone assailant
[01:43:40.580 --> 01:43:42.460]   on the grassy knoll,
[01:43:42.460 --> 01:43:44.060]   that's so much less interesting
[01:43:44.060 --> 01:43:46.060]   than the Russians did it or the mob did it
[01:43:46.060 --> 01:43:47.300]   and there were 15 shooters.
[01:43:47.300 --> 01:43:49.020]   And I mean, it's just not interesting.
[01:43:49.020 --> 01:43:53.220]   - And the answer, go ahead.
[01:43:53.220 --> 01:43:57.460]   - Is that Dan who wants to talk?
[01:43:57.460 --> 01:43:58.380]   Go ahead, Dan.
[01:43:58.380 --> 01:44:01.260]   - No, I was telling Ant to go ahead.
[01:44:01.260 --> 01:44:03.060]   But the real, Leo to your point,
[01:44:03.060 --> 01:44:05.580]   the real answer to many, many questions is that,
[01:44:05.580 --> 01:44:08.220]   well, the answer is nuanced and complicated
[01:44:08.220 --> 01:44:12.700]   and might take some knowledge that is difficult to acquire.
[01:44:12.700 --> 01:44:16.860]   That's just way easier to say, here's the answer.
[01:44:16.860 --> 01:44:19.340]   - So here's the, so it was Jack Dorsey.
[01:44:19.340 --> 01:44:20.700]   I didn't see this actually.
[01:44:20.700 --> 01:44:25.380]   Jack Dorsey on a periscope,
[01:44:25.380 --> 01:44:29.140]   inviting users to ask questions of him.
[01:44:29.140 --> 01:44:32.300]   And what happened?
[01:44:32.300 --> 01:44:37.300]   - It just, it just was terrible, right?
[01:44:37.300 --> 01:44:39.700]   - Yeah, I watched a little bit of it.
[01:44:39.700 --> 01:44:43.020]   And it was just, you know, I mean, it was just full of trolls.
[01:44:43.020 --> 01:44:45.300]   It was full of people saying, you know,
[01:44:45.300 --> 01:44:48.100]   because you can comment, right, in periscope.
[01:44:48.100 --> 01:44:49.700]   And clearly that's what they wanted,
[01:44:49.700 --> 01:44:51.860]   is they wanted questions, but like,
[01:44:51.860 --> 01:44:53.740]   it just immediately got, you know,
[01:44:53.740 --> 01:44:56.580]   the sort of reasonable voices immediately.
[01:44:56.580 --> 01:44:57.420]   - Wish I'd seen that. - You know,
[01:44:57.420 --> 01:44:58.900]   very quickly got chatted out.
[01:44:58.900 --> 01:44:59.820]   It was, oof.
[01:44:59.820 --> 01:45:01.140]   - You don't have, you know,
[01:45:01.140 --> 01:45:04.700]   anybody who's ever watched unmoderated live comment streams
[01:45:04.700 --> 01:45:06.140]   anywhere.
[01:45:06.140 --> 01:45:10.940]   I mean, if you ever used the HQ, the trivia app,
[01:45:10.940 --> 01:45:13.620]   what a bunch of trash in the comment streams,
[01:45:13.620 --> 01:45:16.140]   but they're un-moderated live comment streams.
[01:45:16.140 --> 01:45:19.260]   And it just brings out the worst in us in human beings.
[01:45:19.260 --> 01:45:22.180]   - Unlike the Twit IRC, unlike the Twit IRC.
[01:45:22.180 --> 01:45:25.580]   - Well, the difference is it's heavily moderated, right?
[01:45:25.580 --> 01:45:27.420]   - Yeah, by humans.
[01:45:27.420 --> 01:45:30.220]   - Yeah, by actual people, not bots.
[01:45:31.220 --> 01:45:34.060]   Actually during the Academy Awards,
[01:45:34.060 --> 01:45:37.820]   HQ gave away $25,000,
[01:45:37.820 --> 01:45:42.020]   which is their largest prize ever.
[01:45:42.020 --> 01:45:46.980]   And the idea was they were gonna continue
[01:45:46.980 --> 01:45:49.340]   until just one player was left,
[01:45:49.340 --> 01:45:52.580]   and that player would get all of the $25,000.
[01:45:52.580 --> 01:45:55.460]   This was a bid to get attention right before
[01:45:55.460 --> 01:45:57.060]   they raised even more money.
[01:45:58.380 --> 01:46:00.460]   - Have you any of you done this?
[01:46:00.460 --> 01:46:06.740]   HQ, $15 million more in their venture fund.
[01:46:06.740 --> 01:46:11.060]   - I've played HQ.
[01:46:11.060 --> 01:46:14.540]   - It's fun, but I don't think it has legs.
[01:46:14.540 --> 01:46:16.300]   Maybe it does.
[01:46:16.300 --> 01:46:20.460]   The biggest beneficiary of HQ is their host, Scott Rogowski,
[01:46:20.460 --> 01:46:22.700]   who's now become somewhat of a celebrity.
[01:46:22.700 --> 01:46:25.580]   - They had-- - If the CEO does
[01:46:25.580 --> 01:46:28.300]   then fire him for being featured.
[01:46:28.300 --> 01:46:29.700]   - He won't now, I could promise you.
[01:46:29.700 --> 01:46:32.100]   They had, I did log in during the Oscars
[01:46:32.100 --> 01:46:35.460]   to see how many people were trying to win that prize.
[01:46:35.460 --> 01:46:37.940]   Two million people live.
[01:46:37.940 --> 01:46:40.540]   That's interesting too, because a livestream
[01:46:40.540 --> 01:46:43.420]   to two million people is a non-trivial enterprise.
[01:46:43.420 --> 01:46:44.300]   I know that.
[01:46:44.300 --> 01:46:46.980]   - Yeah, and it makes giving away $25,000
[01:46:46.980 --> 01:46:48.380]   seem fairly trivial.
[01:46:48.380 --> 01:46:51.020]   - Right, if they've got that kind of view.
[01:46:51.020 --> 01:46:53.260]   Give more, we want more.
[01:46:53.260 --> 01:46:55.420]   Twitter says eventually everybody's gonna,
[01:46:55.420 --> 01:46:56.980]   you're all gonna get a blue badge,
[01:46:56.980 --> 01:46:59.500]   so that's gonna make it really valuable.
[01:46:59.500 --> 01:47:00.340]   No, they'll have--
[01:47:00.340 --> 01:47:01.420]   (laughing)
[01:47:01.420 --> 01:47:02.700]   You get one, and you get one,
[01:47:02.700 --> 01:47:06.020]   they're gonna, this is part of the Periscope stream.
[01:47:06.020 --> 01:47:08.940]   Adorsey said that we're gonna figure out a way
[01:47:08.940 --> 01:47:10.940]   so that anybody can get verified
[01:47:10.940 --> 01:47:14.780]   with obviously providing some documentation and so forth.
[01:47:14.780 --> 01:47:17.740]   - I was wondering why they kept shutting me down.
[01:47:17.740 --> 01:47:20.420]   Oh, well, it's probably 'cause I'm not that important.
[01:47:20.420 --> 01:47:21.540]   - You don't have a blue check?
[01:47:21.540 --> 01:47:23.100]   You need a blue check.
[01:47:23.100 --> 01:47:24.260]   - I do need a blue check.
[01:47:24.260 --> 01:47:25.660]   - They wouldn't have blue checked.
[01:47:25.660 --> 01:47:27.340]   - They haven't, they wouldn't approve it.
[01:47:27.340 --> 01:47:28.500]   - It looked for a while,
[01:47:28.500 --> 01:47:30.420]   and I think Twitter even thought this way,
[01:47:30.420 --> 01:47:32.180]   that it was a reward from Twitter.
[01:47:32.180 --> 01:47:36.140]   Like this person is, you know, an important person.
[01:47:36.140 --> 01:47:40.220]   And that's why when they wanted to publish Milo Yiannopoulos,
[01:47:40.220 --> 01:47:41.660]   instead of banning him from Twitter,
[01:47:41.660 --> 01:47:44.460]   at first they just took away his blue check.
[01:47:44.460 --> 01:47:45.700]   No blue check for you.
[01:47:45.700 --> 01:47:46.980]   And that was dumb to put this part.
[01:47:46.980 --> 01:47:48.340]   - You remember this?
[01:47:48.340 --> 01:47:50.500]   - The suggested userless drama.
[01:47:50.500 --> 01:47:51.700]   - Oh God, that was the worst.
[01:47:51.700 --> 01:47:53.300]   - Oh yeah.
[01:47:53.300 --> 01:47:54.140]   Yeah.
[01:47:54.140 --> 01:47:56.460]   I didn't like that.
[01:47:56.460 --> 01:47:59.740]   'Cause I wasn't a, I was never a suggested user.
[01:47:59.740 --> 01:48:01.340]   Stop me cold.
[01:48:01.340 --> 01:48:05.420]   Let's see, let's see.
[01:48:05.420 --> 01:48:09.180]   We talked a little bit on security now
[01:48:09.180 --> 01:48:12.540]   about the largest DDoS attack ever.
[01:48:12.540 --> 01:48:18.460]   First it was GitHub, 1.3 terabits per second,
[01:48:18.460 --> 01:48:21.060]   an amplified memcache attack,
[01:48:21.060 --> 01:48:24.820]   and then OVH and Arbor,
[01:48:24.820 --> 01:48:27.140]   shortly thereafter a similar attack,
[01:48:27.140 --> 01:48:32.140]   UDP port 11,211, of 1.7 terabits.
[01:48:32.140 --> 01:48:35.860]   And this is all because of a flaw
[01:48:35.860 --> 01:48:37.380]   in the memcache protocol,
[01:48:37.380 --> 01:48:40.100]   which should never be a lap pointed to the public.
[01:48:40.100 --> 01:48:43.020]   But because it was on many machines that were misconfigured,
[01:48:43.020 --> 01:48:45.860]   many, many, many machines that were misconfigured,
[01:48:45.860 --> 01:48:48.260]   people were able to send a ping to the memcache
[01:48:48.260 --> 01:48:53.020]   and get it to flood the target with a lot of information.
[01:48:53.020 --> 01:48:54.900]   So these amplification attacks are powerful
[01:48:54.900 --> 01:48:58.820]   because you don't have to have 1.3 or 1.7 terabits
[01:48:58.820 --> 01:49:00.540]   outbound traffic.
[01:49:00.540 --> 01:49:02.620]   You don't have to have a giant botnet
[01:49:02.620 --> 01:49:04.100]   to take over the stuff all you have to do
[01:49:04.100 --> 01:49:06.100]   is hit these memcache servers enough
[01:49:06.100 --> 01:49:07.900]   with small one or two bytes
[01:49:07.900 --> 01:49:10.020]   and they'll send out thousands of bytes.
[01:49:10.020 --> 01:49:11.500]   - Oh man, that's brutal.
[01:49:11.500 --> 01:49:13.580]   - And that's brutal.
[01:49:13.580 --> 01:49:14.700]   - Our friends at Cloudflare,
[01:49:14.700 --> 01:49:17.460]   who are of course sponsors of our shows
[01:49:17.460 --> 01:49:20.140]   and long time friends point out that really the issue though
[01:49:20.140 --> 01:49:22.660]   isn't merely misconfigured memcache,
[01:49:22.660 --> 01:49:24.340]   it is IP spoofing.
[01:49:24.340 --> 01:49:25.340]   And this is, well, you know,
[01:49:25.340 --> 01:49:28.140]   Steve Gibson's been talking about this forever.
[01:49:28.140 --> 01:49:32.500]   If you can fake your IP address,
[01:49:32.500 --> 01:49:36.740]   it's very difficult to stop these kinds of attacks.
[01:49:36.740 --> 01:49:40.020]   And really it's ultimately gonna come down to,
[01:49:40.020 --> 01:49:42.180]   in my opinion, networks saying,
[01:49:42.180 --> 01:49:45.100]   you know, you can't come out of my network
[01:49:45.100 --> 01:49:46.900]   with a fake IP address.
[01:49:47.900 --> 01:49:49.860]   And there's no reason for a network
[01:49:49.860 --> 01:49:52.260]   to allow outbound UDP traffic either.
[01:49:52.260 --> 01:49:55.180]   Unless, you know, so there's a number of things
[01:49:55.180 --> 01:49:57.260]   that people could do unfortunately.
[01:49:57.260 --> 01:49:59.420]   Somebody, nobody seems to wanna do anything about it
[01:49:59.420 --> 01:50:02.420]   and these DDoS attacks will probably continue.
[01:50:02.420 --> 01:50:05.260]   - Well, it's tricky right because IP spoofing
[01:50:05.260 --> 01:50:08.660]   is gonna like getting rid of IP spoofing theoretically
[01:50:08.660 --> 01:50:12.660]   would basically, it would create some problems
[01:50:12.660 --> 01:50:16.060]   with things like VPN, wouldn't it?
[01:50:16.060 --> 01:50:17.420]   - Oh, maybe. - Completely.
[01:50:17.420 --> 01:50:18.660]   - But if you're a VP-- - Stop that.
[01:50:18.660 --> 01:50:20.980]   - Yeah, if you're running a VP, yeah, let me think about that.
[01:50:20.980 --> 01:50:22.140]   Yeah.
[01:50:22.140 --> 01:50:23.460]   - Thing is, if you're running it first thing--
[01:50:23.460 --> 01:50:24.300]   - I think you came to mama.
[01:50:24.300 --> 01:50:25.460]   - You're expecting that.
[01:50:25.460 --> 01:50:27.700]   That's an interesting question.
[01:50:27.700 --> 01:50:28.820]   I think it's, well, I don't know,
[01:50:28.820 --> 01:50:31.220]   I'll have to read the blog and we'll see.
[01:50:31.220 --> 01:50:33.500]   I think it's more an issue of networks,
[01:50:33.500 --> 01:50:36.860]   internet service providers not allowing IP addresses
[01:50:36.860 --> 01:50:39.700]   that don't belong to them to be broadcast out
[01:50:39.700 --> 01:50:40.860]   from their networks.
[01:50:40.860 --> 01:50:44.220]   So a VPN I don't think would be affected by that
[01:50:44.220 --> 01:50:46.020]   because you're going out with your IP address.
[01:50:46.020 --> 01:50:47.380]   - I'm not following. - VPN, you're tunneling
[01:50:47.380 --> 01:50:50.340]   and then going somewhere else.
[01:50:50.340 --> 01:50:51.180]   - That makes sense.
[01:50:51.180 --> 01:50:55.220]   - Yeah, requires network operators to block fake IP addresses
[01:50:55.220 --> 01:50:56.580]   coming out of their servers.
[01:50:56.580 --> 01:50:58.380]   If it's not part of my range,
[01:50:58.380 --> 01:51:00.020]   it shouldn't come out of my server.
[01:51:00.020 --> 01:51:02.260]   This is a little scary.
[01:51:02.260 --> 01:51:05.620]   I'm more scared about this than artificial intelligence,
[01:51:05.620 --> 01:51:08.500]   but it's been going on in China for some time.
[01:51:08.500 --> 01:51:12.820]   Pre-crime, in China, they're using information
[01:51:12.820 --> 01:51:16.260]   that they can gather about people to block crime
[01:51:16.260 --> 01:51:18.740]   before it happens.
[01:51:18.740 --> 01:51:20.660]   - Minority report from life.
[01:51:20.660 --> 01:51:21.500]   - Yeah, yeah. - Yeah.
[01:51:21.500 --> 01:51:22.580]   - Yep.
[01:51:22.580 --> 01:51:26.180]   There's a police force in China
[01:51:26.180 --> 01:51:29.620]   called the Integrated Joint Operations Platform,
[01:51:29.620 --> 01:51:33.300]   which gathers information from face recognition cameras,
[01:51:33.300 --> 01:51:36.660]   Wi-Fi internet sniffers, license plate cameras,
[01:51:36.660 --> 01:51:39.700]   police checkpoints, banking records.
[01:51:39.700 --> 01:51:43.060]   See, I'm not worried about ads.
[01:51:43.060 --> 01:51:45.540]   This is what I'm worried about.
[01:51:45.540 --> 01:51:48.620]   Police reports made on mobile apps from home visits.
[01:51:48.620 --> 01:51:50.460]   If it flags anything suspicious,
[01:51:50.460 --> 01:51:52.940]   like a large purchase of fertilizer,
[01:51:52.940 --> 01:51:55.340]   stockpiles of food considered a marker of terrorism,
[01:51:55.340 --> 01:51:58.780]   like hummus, it notifies police
[01:51:58.780 --> 01:52:00.460]   who are expected to respond the same day
[01:52:00.460 --> 01:52:03.340]   and act according to what they find.
[01:52:03.340 --> 01:52:04.660]   - Why is this large,
[01:52:04.660 --> 01:52:05.660]   - That's even scar-headed,
[01:52:05.660 --> 01:52:08.340]   - You buy in 20 pounds of ground beef.
[01:52:08.340 --> 01:52:11.740]   - Yeah, I happen like burgers, okay?
[01:52:11.740 --> 01:52:13.220]   - That's much. - That's much, man.
[01:52:13.220 --> 01:52:14.060]   That's much.
[01:52:14.060 --> 01:52:17.460]   So interesting.
[01:52:17.460 --> 01:52:20.220]   And of course, you can do this in authoritarian countries
[01:52:20.220 --> 01:52:22.860]   where nobody's overseeing the police force.
[01:52:22.860 --> 01:52:25.900]   And one of the things that I've talked to people
[01:52:25.900 --> 01:52:28.820]   who are familiar with the culture there,
[01:52:28.820 --> 01:52:33.500]   the people in China sometimes embrace this
[01:52:33.500 --> 01:52:35.180]   because they prefer order.
[01:52:35.180 --> 01:52:36.980]   They're willing, as long as you don't arrest me,
[01:52:36.980 --> 01:52:39.020]   I think this is a good thing.
[01:52:39.020 --> 01:52:41.340]   So this is something for us to pay attention to.
[01:52:41.340 --> 01:52:43.260]   Our desire for law and order,
[01:52:43.260 --> 01:52:46.900]   we have to be very careful that it doesn't outpace
[01:52:46.900 --> 01:52:51.660]   our desire for freedom and privacy, right?
[01:52:51.660 --> 01:52:53.740]   Sometimes people are so interested in order
[01:52:53.740 --> 01:52:56.780]   that they're willing to sacrifice rights.
[01:52:56.780 --> 01:52:58.460]   That's not a good thing.
[01:52:58.460 --> 01:53:02.140]   - Yeah, and the primary tool for creating that situation
[01:53:02.140 --> 01:53:05.180]   is usually kind of fear of terrorism,
[01:53:05.180 --> 01:53:07.820]   sort of things like that, at least in the US.
[01:53:07.820 --> 01:53:09.140]   That's what it seems to be used for.
[01:53:09.140 --> 01:53:10.380]   I mean, that's what we talked about
[01:53:10.380 --> 01:53:13.260]   with the whole cracking into the iPhone thing, right?
[01:53:13.260 --> 01:53:14.100]   - Yep.
[01:53:14.100 --> 01:53:15.540]   - So, yeah.
[01:53:15.540 --> 01:53:17.500]   - Yeah, it generates, you know, that fear,
[01:53:17.500 --> 01:53:21.620]   when generates this willingness to give up human rights,
[01:53:21.620 --> 01:53:24.620]   and the real problem is it's meant,
[01:53:24.620 --> 01:53:25.900]   means something completely different
[01:53:25.900 --> 01:53:29.340]   in this modern era of big data that it meant 20 years ago.
[01:53:29.340 --> 01:53:32.380]   Governments have so much data.
[01:53:32.380 --> 01:53:36.660]   This is a perfect example that they really can act on this stuff
[01:53:36.660 --> 01:53:38.820]   in a way that is very scary.
[01:53:38.820 --> 01:53:43.180]   - I can't say I'd like that over here though.
[01:53:43.180 --> 01:53:44.460]   - No, I hope not.
[01:53:44.460 --> 01:53:46.580]   I think we have, I don't think that's gonna happen here.
[01:53:46.580 --> 01:53:47.700]   I hope it's not anyway.
[01:53:47.700 --> 01:53:54.420]   Although, if you're the Marriott employee
[01:53:54.420 --> 01:54:00.140]   who hit the like button on a Tibetan separatist group,
[01:54:00.140 --> 01:54:02.820]   maybe you think it could happen here.
[01:54:02.820 --> 01:54:07.660]   He was working for the Marriott Corporation
[01:54:07.660 --> 01:54:09.140]   in the United States.
[01:54:09.140 --> 01:54:13.180]   He actually, he was only a $14 an hour job.
[01:54:13.180 --> 01:54:16.660]   He ran social media accounts for Marriott,
[01:54:16.660 --> 01:54:19.580]   and he was using an official company account
[01:54:19.580 --> 01:54:21.420]   to like a post on Twitter,
[01:54:21.420 --> 01:54:25.220]   from a Tibetan separatist group.
[01:54:27.460 --> 01:54:30.980]   China complained and got the guy fired.
[01:54:30.980 --> 01:54:34.500]   Marriott fired him on January 14th.
[01:54:34.500 --> 01:54:38.540]   Because Marriott's got business in China.
[01:54:38.540 --> 01:54:43.260]   So he's not only that you can't speak freely in China,
[01:54:43.260 --> 01:54:45.580]   you may not be able to speak freely outside of China
[01:54:45.580 --> 01:54:49.820]   if the company you work for has some relationship with that China.
[01:54:49.820 --> 01:54:51.300]   - It also is just,
[01:54:51.300 --> 01:54:54.780]   some workers are more likely to be impacted by incidents.
[01:54:56.100 --> 01:54:59.180]   And we'll likely never hear from this person again.
[01:54:59.180 --> 01:55:01.380]   But those are the people who will lose their jobs
[01:55:01.380 --> 01:55:04.100]   and don't have the social proof or the social following
[01:55:04.100 --> 01:55:09.100]   to be able to recover their careers or yeah.
[01:55:09.100 --> 01:55:12.820]   - Yeah, yeah.
[01:55:12.820 --> 01:55:15.140]   Just, you know, and by the way,
[01:55:15.140 --> 01:55:17.980]   I'm kind of in favor of Tibetan separatist groups.
[01:55:17.980 --> 01:55:22.140]   Just for what it's worth, I would like them.
[01:55:22.140 --> 01:55:23.660]   Fortunately, I don't have to worry
[01:55:23.660 --> 01:55:25.340]   about getting fired by my company.
[01:55:26.340 --> 01:55:28.340]   (laughing)
[01:55:28.340 --> 01:55:30.780]   But you guys, you better not say anything.
[01:55:30.780 --> 01:55:32.340]   - I gotta do, I gotta scram.
[01:55:32.340 --> 01:55:34.140]   But this has been truly enjoyable.
[01:55:34.140 --> 01:55:37.020]   Ben and Leo, thank you very much for your time today.
[01:55:37.020 --> 01:55:38.220]   - Five o'clock, I tell you what,
[01:55:38.220 --> 01:55:39.700]   we're gonna wrap it up for everybody.
[01:55:39.700 --> 01:55:42.180]   Thank you, Dan Patterson, always a pleasure.
[01:55:42.180 --> 01:55:43.020]   - You too.
[01:55:43.020 --> 01:55:45.860]   - Tech Republic, CBS Interactive @DanPatterson.
[01:55:45.860 --> 01:55:47.180]   - Hey, Tech Public.
[01:55:47.180 --> 01:55:49.100]   - All right, we'll give it to Tech Republic.
[01:55:49.100 --> 01:55:50.220]   Hey, while we take a break,
[01:55:50.220 --> 01:55:52.420]   we'll wrap it up with the rest of the bunch in just a second.
[01:55:52.420 --> 01:55:55.060]   But first a word from WordPress.
[01:55:55.060 --> 01:55:55.900]   - Second.
[01:55:55.900 --> 01:55:58.620]   - The number one content management system
[01:55:58.620 --> 01:56:01.180]   in the world, 30% of all the websites
[01:56:01.180 --> 01:56:02.860]   in the world run on WordPress.
[01:56:02.860 --> 01:56:06.900]   30% including mine and some of the best publications
[01:56:06.900 --> 01:56:10.540]   in the world, worldpress.com is my home on the internet.
[01:56:10.540 --> 01:56:13.780]   If you go to leoloport.com, I love WordPress.com
[01:56:13.780 --> 01:56:18.100]   because it makes it easy for me to share my voice, my work,
[01:56:18.100 --> 01:56:20.500]   your voice, your way, your business,
[01:56:20.500 --> 01:56:23.980]   make wordpress.com your site on the internet,
[01:56:23.980 --> 01:56:24.980]   your place in the internet.
[01:56:24.980 --> 01:56:28.100]   It's one thing to have a Facebook page or a Twitter account,
[01:56:28.100 --> 01:56:30.620]   but you need to have a place that you control,
[01:56:30.620 --> 01:56:35.620]   a place that customers, friends, followers can go to
[01:56:35.620 --> 01:56:37.220]   that's yours.
[01:56:37.220 --> 01:56:41.220]   And of course with wordpress.com's social sharing plugins,
[01:56:41.220 --> 01:56:44.380]   they can go there and help promote your brand
[01:56:44.380 --> 01:56:46.540]   to the rest of the world through their Facebook page,
[01:56:46.540 --> 01:56:47.540]   their Twitter page.
[01:56:47.540 --> 01:56:49.820]   And when you tweet, you wanna point back
[01:56:49.820 --> 01:56:53.180]   to your personal site 'cause you control that site.
[01:56:53.180 --> 01:56:55.220]   You don't, by the way, don't feel intimidated,
[01:56:55.220 --> 01:56:56.260]   you don't need to be a coder,
[01:56:56.260 --> 01:56:59.140]   you don't need to understand HTML or CSS,
[01:56:59.140 --> 01:57:01.100]   WordPress gives you all the tools you need
[01:57:01.100 --> 01:57:04.140]   to get your site up and running hundreds of beautiful templates,
[01:57:04.140 --> 01:57:06.980]   they even have e-commerce solutions that are as simple
[01:57:06.980 --> 01:57:08.780]   as a simple buy button on your site
[01:57:08.780 --> 01:57:10.260]   to a complete online store.
[01:57:10.260 --> 01:57:11.980]   And if you ever do have a question,
[01:57:11.980 --> 01:57:14.260]   their customer support team is there 24/7
[01:57:14.260 --> 01:57:17.140]   to help Monday through Friday, weekends too.
[01:57:17.140 --> 01:57:18.380]   And I've used them, they're great.
[01:57:18.380 --> 01:57:20.220]   They really are fast and efficient
[01:57:20.220 --> 01:57:21.260]   and they do a good job.
[01:57:21.260 --> 01:57:22.660]   Plan started at wordpress.com
[01:57:22.660 --> 01:57:24.820]   at just $4 a month.
[01:57:24.820 --> 01:57:26.980]   And when you're ready to expand your online reach,
[01:57:26.980 --> 01:57:29.940]   WordPress makes it easy, built in SEO, social sharing,
[01:57:29.940 --> 01:57:32.100]   specialized plugins to meet your needs.
[01:57:32.100 --> 01:57:33.700]   I use the AMP plugin for instance,
[01:57:33.700 --> 01:57:38.020]   which makes my site loads super fast on smartphones.
[01:57:38.020 --> 01:57:40.660]   No wonder 30% of all websites run on WordPress.
[01:57:40.660 --> 01:57:44.060]   It is my home on the net and should be yours too.
[01:57:44.060 --> 01:57:47.140]   WordPress.com/twit, if you get started today
[01:57:47.140 --> 01:57:52.140]   at wordpress.com/twit, you'll get 15% off any new plan purchase.
[01:57:52.260 --> 01:57:56.740]   That's wordpress.com/twit, 15% off your brand new website.
[01:57:56.740 --> 01:57:59.580]   Join the 30% of the world.
[01:57:59.580 --> 01:58:02.980]   That's a huge number that uses WordPress
[01:58:02.980 --> 01:58:04.620]   for their presence on the net.
[01:58:04.620 --> 01:58:07.380]   WordPress.com/twit.
[01:58:07.380 --> 01:58:09.980]   We thank them so much for their support.
[01:58:09.980 --> 01:58:13.260]   So many other things we could talk about,
[01:58:13.260 --> 01:58:15.380]   but I think we'll just say,
[01:58:15.380 --> 01:58:17.300]   let's save that for another day
[01:58:17.300 --> 01:58:20.500]   because it is getting late and you guys have been great.
[01:58:20.500 --> 01:58:22.380]   And prove it always a pleasure having you on.
[01:58:22.380 --> 01:58:24.060]   We gotta have you back soon.
[01:58:24.060 --> 01:58:25.140]   Anything you want to plug?
[01:58:25.140 --> 01:58:26.940]   I know we see your stuff on tech or public.
[01:58:26.940 --> 01:58:31.340]   I follow you on Instagram because your images are fabulous.
[01:58:31.340 --> 01:58:33.180]   And underscore, prove it on Twitter.
[01:58:33.180 --> 01:58:34.180]   What else you want to plug?
[01:58:34.180 --> 01:58:35.420]   Anything?
[01:58:35.420 --> 01:58:37.740]   - Well, definitely follow me on Instagram.
[01:58:37.740 --> 01:58:41.540]   I'm wanting to do a little more behind the scenes stuff
[01:58:41.540 --> 01:58:43.180]   with Instagram stories.
[01:58:43.180 --> 01:58:46.180]   Just taking people with me far as when I set up my shots
[01:58:46.180 --> 01:58:50.020]   or if I'm doing an edit on a video or photograph
[01:58:50.020 --> 01:58:51.820]   and I think that'll be a little more fun
[01:58:51.820 --> 01:58:52.660]   for people to watch.
[01:58:52.660 --> 01:58:55.300]   Then just see here, here's another photo I took.
[01:58:55.300 --> 01:58:56.140]   - I love that.
[01:58:56.140 --> 01:58:58.260]   What's your Instagram handle?
[01:58:58.260 --> 01:58:59.580]   - It is @antpruit.
[01:58:59.580 --> 01:59:00.540]   No one to score.
[01:59:00.540 --> 01:59:01.420]   - Easy enough.
[01:59:01.420 --> 01:59:04.300]   And it's got an underscore on the Twitter as well.
[01:59:04.300 --> 01:59:06.740]   Instagram. - It hits the whole verification thing
[01:59:06.740 --> 01:59:08.300]   that I've been trying to get.
[01:59:08.300 --> 01:59:10.300]   (laughing)
[01:59:10.300 --> 01:59:13.980]   - Do you, are you, I think there's verification on,
[01:59:13.980 --> 01:59:18.660]   I want to say there's verification on Instagram, is there?
[01:59:18.660 --> 01:59:21.460]   - I think there is, but I haven't really had an issue
[01:59:21.460 --> 01:59:23.460]   with that on Twitter on the other hand.
[01:59:23.460 --> 01:59:26.700]   I've had issues of people faking me.
[01:59:26.700 --> 01:59:28.300]   - Pretending to be you?
[01:59:28.300 --> 01:59:29.900]   That sucks.
[01:59:29.900 --> 01:59:30.980]   - I'm like, come on, man.
[01:59:30.980 --> 01:59:32.700]   - That's common, man.
[01:59:32.700 --> 01:59:33.980]   - I love your images.
[01:59:33.980 --> 01:59:36.460]   Look at this, this is beautiful stuff.
[01:59:36.460 --> 01:59:37.620]   Gorgeous. - Thank you, sir.
[01:59:37.620 --> 01:59:38.460]   - Yeah.
[01:59:38.460 --> 01:59:39.540]   And this is just the still stuff.
[01:59:39.540 --> 01:59:41.940]   You can see the stories too for more videos
[01:59:41.940 --> 01:59:43.500]   and behind the scenes stuff.
[01:59:43.500 --> 01:59:45.580]   Ant always a pleasure.
[01:59:45.580 --> 01:59:46.660]   Thank you for being here.
[01:59:46.660 --> 01:59:47.500]   - Thank you, friend, sir.
[01:59:47.500 --> 01:59:49.780]   And it's always great to have Ben on,
[01:59:49.780 --> 01:59:53.380]   Ben is a senior producer at WBUR, Ben Brock Johnson.
[01:59:53.380 --> 01:59:55.500]   He's the Brock Johnson on Twitter.
[01:59:55.500 --> 01:59:56.900]   Anything else you want to plug?
[01:59:56.900 --> 01:59:58.980]   You've got that new Reddit show.
[01:59:58.980 --> 02:00:00.900]   I think that's a good one.
[02:00:00.900 --> 02:00:02.060]   - Yeah, endless thread.
[02:00:02.060 --> 02:00:05.540]   It's only worth your while once you're done
[02:00:05.540 --> 02:00:07.060]   with listening to Twit, but it's--
[02:00:07.060 --> 02:00:08.700]   - Oh, no, you don't have to say that.
[02:00:08.700 --> 02:00:10.380]   I have to say that. (laughing)
[02:00:10.380 --> 02:00:11.580]   - No, we have a lot of fun with it.
[02:00:11.580 --> 02:00:13.100]   And Leo, I was gonna say, actually,
[02:00:13.100 --> 02:00:14.580]   as we were going through,
[02:00:16.020 --> 02:00:19.620]   there's a WordPress subreddit that's very active.
[02:00:19.620 --> 02:00:21.260]   - I follow it. - Yep.
[02:00:21.260 --> 02:00:23.900]   - Yes, so that one's interesting.
[02:00:23.900 --> 02:00:27.100]   And then there's another one that's a 23 and me subreddit
[02:00:27.100 --> 02:00:28.500]   that's really interesting.
[02:00:28.500 --> 02:00:29.340]   - I didn't know that.
[02:00:29.340 --> 02:00:31.140]   I'm gonna follow that too.
[02:00:31.140 --> 02:00:36.140]   - Yeah, there's a lot of interesting people post their data
[02:00:36.140 --> 02:00:39.860]   on there and some of their results.
[02:00:39.860 --> 02:00:41.540]   - Oh, that's cool.
[02:00:41.540 --> 02:00:42.860]   - It was super interesting.
[02:00:42.860 --> 02:00:47.100]   - Reddit gets slammed a lot for whatever,
[02:00:47.100 --> 02:00:48.780]   the hate sites and that's stuff.
[02:00:48.780 --> 02:00:51.340]   And then some of it, they've let sit there
[02:00:51.340 --> 02:00:54.140]   and most of it, they've killed, they've clobbered.
[02:00:54.140 --> 02:00:56.860]   It's a challenge, but I have to say,
[02:00:56.860 --> 02:00:58.260]   it's all up to you.
[02:00:58.260 --> 02:01:01.180]   If you follow great subreddits on Reddit, it is.
[02:01:01.180 --> 02:01:03.020]   For me, it's a huge resource.
[02:01:03.020 --> 02:01:04.380]   I love it.
[02:01:04.380 --> 02:01:06.820]   And I follow on some of the geek sub,
[02:01:06.820 --> 02:01:09.860]   like the ThinkPad subreddit.
[02:01:09.860 --> 02:01:11.740]   There's some fun entertaining ones like,
[02:01:11.740 --> 02:01:15.020]   no, no, no, which is videos of people doing stupid things
[02:01:15.020 --> 02:01:17.580]   and they're results of it.
[02:01:17.580 --> 02:01:19.180]   There's some fun stuff on Reddit.
[02:01:19.180 --> 02:01:22.700]   I turn your eyes away from the bad stuff
[02:01:22.700 --> 02:01:24.940]   and follow the good stuff and you're gonna get a great feed.
[02:01:24.940 --> 02:01:26.020]   I really love Reddit.
[02:01:26.020 --> 02:01:27.260]   - I found a Game Boy.
[02:01:27.260 --> 02:01:29.540]   I found an old Game Boy the other day
[02:01:29.540 --> 02:01:32.780]   that I hadn't turned on in a really long time.
[02:01:32.780 --> 02:01:35.980]   And I posted it and I put some batteries in
[02:01:35.980 --> 02:01:40.100]   and it was working okay, but not that well.
[02:01:40.100 --> 02:01:42.540]   The screen was garbled and stuff.
[02:01:42.540 --> 02:01:46.380]   And I posted that to the console repair subreddit
[02:01:46.380 --> 02:01:50.820]   and I immediately got like 15 answers of how to fix the thing.
[02:01:50.820 --> 02:01:52.380]   Which is just amazing.
[02:01:52.380 --> 02:01:54.380]   - There's word, cool.
[02:01:54.380 --> 02:01:56.300]   - Wordpress people are like Linux geeks.
[02:01:56.300 --> 02:01:58.100]   It's fascinating.
[02:01:58.100 --> 02:02:02.220]   - Yeah, I follow all the Linux geeks
[02:02:02.220 --> 02:02:06.540]   and the BSD geeks and all the programming languages too.
[02:02:06.540 --> 02:02:08.020]   And that means I get a very,
[02:02:08.020 --> 02:02:10.700]   this is one of my favorites, data is ugly.
[02:02:10.700 --> 02:02:15.060]   Where people just put up the worst diagrams
[02:02:15.060 --> 02:02:18.500]   you've ever seen.
[02:02:18.500 --> 02:02:21.740]   - I didn't even subscribe to that.
[02:02:21.740 --> 02:02:28.180]   - It's just, you look at these and go,
[02:02:28.180 --> 02:02:31.100]   what were they thinking?
[02:02:31.100 --> 02:02:33.980]   You know, what, really, what were they thinking
[02:02:33.980 --> 02:02:34.980]   when they created that?
[02:02:34.980 --> 02:02:36.340]   - Somebody approved it too.
[02:02:36.340 --> 02:02:38.380]   - That's a big problem.
[02:02:38.380 --> 02:02:40.740]   Somebody spent a lot of energy on it, you know?
[02:02:40.740 --> 02:02:42.980]   (laughing)
[02:02:42.980 --> 02:02:47.780]   Anyway, so great to see you Ben.
[02:02:47.780 --> 02:02:48.620]   Thank you, Ant.
[02:02:48.620 --> 02:02:49.460]   Thanks to Dan.
[02:02:49.460 --> 02:02:50.620]   Thank you all for being here.
[02:02:50.620 --> 02:02:52.300]   We do this week in tech.
[02:02:52.300 --> 02:02:54.620]   My favorite time of the week every Sunday afternoon,
[02:02:54.620 --> 02:02:57.380]   3 p.m. Pacific, 6 p.m. Eastern, 23.
[02:02:57.380 --> 02:02:59.340]   Actually, it's now 2,200 UTC
[02:02:59.340 --> 02:03:01.860]   'cause we sprang forward this morning.
[02:03:01.860 --> 02:03:05.060]   Thank you for all coming here a little bit early.
[02:03:05.060 --> 02:03:07.220]   2,200 UTC.
[02:03:07.220 --> 02:03:09.060]   Make sure you make a habit to watch it live
[02:03:09.060 --> 02:03:10.780]   if you can, twit.tv/live.
[02:03:10.780 --> 02:03:12.780]   And if you do that, be in the chat room.
[02:03:12.780 --> 02:03:15.500]   It's moderated, but it's still fun.
[02:03:15.500 --> 02:03:17.460]   I-R-C.twit.tv.
[02:03:17.460 --> 02:03:19.220]   If you'd like to be in the studio,
[02:03:19.220 --> 02:03:21.060]   we have seats for the studio audience.
[02:03:21.060 --> 02:03:23.140]   We have an open studio, but we do ask that you email us
[02:03:23.140 --> 02:03:24.340]   ahead of time for tickets.
[02:03:24.340 --> 02:03:26.740]   Tickets at twit.tv.
[02:03:26.740 --> 02:03:28.660]   Tickets at twit.tv.
[02:03:28.660 --> 02:03:30.020]   You can also watch On Demand,
[02:03:30.020 --> 02:03:32.700]   and that's really the bulk of our audience listens
[02:03:32.700 --> 02:03:34.100]   at their convenience.
[02:03:34.100 --> 02:03:36.700]   All you have to do is go to twit.tv
[02:03:36.700 --> 02:03:39.620]   for any of our shows and download
[02:03:39.620 --> 02:03:42.200]   your favorite episodes or subscribe.
[02:03:42.200 --> 02:03:45.420]   If you've got a podcast program,
[02:03:45.420 --> 02:03:46.540]   we work with all of them.
[02:03:46.540 --> 02:03:50.460]   Pod, you know, podcasts from Apple and from Samsung
[02:03:50.460 --> 02:03:52.620]   and from Stitcher and of course,
[02:03:52.620 --> 02:03:54.140]   Pocket Cast and Overcast.
[02:03:54.140 --> 02:03:55.540]   You just subscribe to our podcast
[02:03:55.540 --> 02:03:57.900]   and that way you'll automatically
[02:03:57.900 --> 02:04:00.340]   get every episode the minute it's available.
[02:04:00.340 --> 02:04:02.220]   It's kind of a great way to start your commute
[02:04:02.220 --> 02:04:04.340]   on a Monday morning is to have twit,
[02:04:04.340 --> 02:04:06.860]   sitting there on your phone, ready for you to play.
[02:04:06.860 --> 02:04:07.700]   Thanks for being here.
[02:04:07.700 --> 02:04:08.540]   We'll see you next time.
[02:04:08.540 --> 02:04:10.700]   Another twit is in the can.
[02:04:10.700 --> 02:04:13.280]   (upbeat music)
[02:04:13.280 --> 02:04:14.340]    Do it the twit 
[02:04:14.340 --> 02:04:15.180]    Do it the twit 
[02:04:15.180 --> 02:04:16.180]    All right 
[02:04:16.180 --> 02:04:18.060]    Do it the twit, baby 
[02:04:18.060 --> 02:04:18.900]    Do it the twit 
[02:04:18.900 --> 02:04:19.900]    All right 

