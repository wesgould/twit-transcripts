
[00:00:00.000 --> 00:00:02.720]   It's time for Twent this week in Tech.
[00:00:02.720 --> 00:00:06.200]   Andy Inaco is slumming, visiting us from heckbreak weekly.
[00:00:06.200 --> 00:00:10.880]   All the way from Austin, Texas, Wesley Faulkner, his first time on, and from Tech Crunch and
[00:00:10.880 --> 00:00:13.360]   Crunchbase News, Alex Wilhelm.
[00:00:13.360 --> 00:00:18.800]   We'll talk about Ready Player One Cloud Flares April Fool's Joke, or was it?
[00:00:18.800 --> 00:00:23.760]   And something kind of sad that will be happening to people who want to visit the US in the
[00:00:23.760 --> 00:00:24.760]   near future.
[00:00:24.760 --> 00:00:29.840]   It's all coming up next on Twent.
[00:00:29.840 --> 00:00:32.240]   NetCasts You Love.
[00:00:32.240 --> 00:00:34.840]   From People You Trust.
[00:00:34.840 --> 00:00:39.720]   This is Twent.
[00:00:39.720 --> 00:00:51.840]   Bandwidth for this week in Tech is provided by CashFly at CACHEFLY.com.
[00:00:51.840 --> 00:00:52.840]   This is Twent.
[00:00:52.840 --> 00:00:59.040]   This week in Tech, Episode 660, recorded Sunday, April 1, 2018.
[00:00:59.040 --> 00:01:01.520]   Bank What?
[00:01:01.520 --> 00:01:07.240]   This week in Tech is brought to you by ITProTV, flexible and entertaining training for your
[00:01:07.240 --> 00:01:08.480]   IT career.
[00:01:08.480 --> 00:01:14.320]   Visit itpro.tv/twit and use the code TWIT30 to get a free seven day trial and 30% off
[00:01:14.320 --> 00:01:18.560]   a monthly membership for the lifetime of your active subscription.
[00:01:18.560 --> 00:01:23.360]   And by Wink the best way to discover new wines that you'll love.
[00:01:23.360 --> 00:01:28.680]   Go to trywink.com/twit and get $20 off your first shipment.
[00:01:28.680 --> 00:01:31.160]   And by Rocket Mortgage from Quick and Loans.
[00:01:31.160 --> 00:01:32.600]   Home plays a big role in your life.
[00:01:32.600 --> 00:01:35.480]   That's why Quick and Loans created Rocket Mortgage.
[00:01:35.480 --> 00:01:39.680]   It lets you apply simply and understand the entire mortgage process fully so you can be
[00:01:39.680 --> 00:01:42.440]   confident you're getting the right mortgage for you.
[00:01:42.440 --> 00:01:46.760]   Get started at rocketmortgage.com/twit2.
[00:01:46.760 --> 00:01:48.240]   And by Casper.
[00:01:48.240 --> 00:01:53.440]   A sleep brand that continues to revolutionize its line of products to create an exceptionally
[00:01:53.440 --> 00:01:56.520]   comfortable sleep experience one night at a time.
[00:01:56.520 --> 00:02:02.080]   You can say $50 towards select mattresses by visiting Casper.com/twit and using the promo
[00:02:02.080 --> 00:02:07.600]   code TWIT at check-in.
[00:02:07.600 --> 00:02:10.120]   It's time for TWIT this week in Tech, the show where we get together and talk about
[00:02:10.120 --> 00:02:13.280]   the week's Tech News.
[00:02:13.280 --> 00:02:17.960]   And there is a lot of it, but fortunately we won't be talking about any of it because
[00:02:17.960 --> 00:02:22.280]   it's the good time panel this week.
[00:02:22.280 --> 00:02:24.000]   I recognize that, Chordle.
[00:02:24.000 --> 00:02:26.000]   That's Andy and Ico.
[00:02:26.000 --> 00:02:28.800]   And that's formerly of the Chicago Sun Times.
[00:02:28.800 --> 00:02:30.720]   Now geek at large.
[00:02:30.720 --> 00:02:38.520]   Yes, now I've asked for my bio for my fast company piece and I said, "It's just a veteran
[00:02:38.520 --> 00:02:39.520]   journalist."
[00:02:39.520 --> 00:02:40.520]   Veteran.
[00:02:40.520 --> 00:02:41.520]   Veteran.
[00:02:41.520 --> 00:02:45.440]   Because it's like I've been looking at other people's bylines and I feel as though the
[00:02:45.440 --> 00:02:48.080]   more stuff you put into it, the less impressive it sounds.
[00:02:48.080 --> 00:02:51.280]   If you just simply say, "They know who I am."
[00:02:51.280 --> 00:02:52.880]   And they do.
[00:02:52.880 --> 00:02:57.880]   If they don't, they ought to.
[00:02:57.880 --> 00:02:58.600]   Andy is, of course, his regular co-host on Mac Break Weekly on Tuesdays.
[00:02:58.600 --> 00:03:01.240]   He's the material podcast at relay.fm.
[00:03:01.240 --> 00:03:04.640]   He's actually the busiest unemployed person I know.
[00:03:04.640 --> 00:03:08.880]   You will hear him on WBUR in Boston on NPR Radio There.
[00:03:08.880 --> 00:03:09.880]   WBGBH, by the way.
[00:03:09.880 --> 00:03:10.880]   Oh, it's GBH.
[00:03:10.880 --> 00:03:11.880]   I'm sorry.
[00:03:11.880 --> 00:03:13.880]   BUR is that other guy who comes on the show.
[00:03:13.880 --> 00:03:16.320]   We are a two public radio station.
[00:03:16.320 --> 00:03:17.480]   That's amazing.
[00:03:17.480 --> 00:03:19.360]   We also have a Burger King and a McDonald's.
[00:03:19.360 --> 00:03:20.360]   But you're on the good one.
[00:03:20.360 --> 00:03:22.840]   You're on the McDonald's of NPR.
[00:03:22.840 --> 00:03:26.560]   Well, obviously, I would not be on the Internet.
[00:03:26.560 --> 00:03:27.560]   You're on the Internet.
[00:03:27.560 --> 00:03:29.720]   We're not the best damn radio station.
[00:03:29.720 --> 00:03:32.680]   You're on the stake in shake of NPR stations.
[00:03:32.680 --> 00:03:35.560]   I feel like we can get into a long riff now about which fast food place to the best.
[00:03:35.560 --> 00:03:36.720]   But we can also just move on.
[00:03:36.720 --> 00:03:38.160]   Which fast food place is the best?
[00:03:38.160 --> 00:03:39.160]   That's Alex Wilhelm.
[00:03:39.160 --> 00:03:40.160]   He ought to know.
[00:03:40.160 --> 00:03:46.000]   He's a young and also editor in chief of Crunchbase News, which gives him some gravitas
[00:03:46.000 --> 00:03:47.000]   in this world.
[00:03:47.000 --> 00:03:48.000]   I'm a modicum.
[00:03:48.000 --> 00:03:49.000]   I wouldn't go with a veteran.
[00:03:49.000 --> 00:03:51.400]   And he's about to move into my childhood home.
[00:03:51.400 --> 00:03:52.400]   That's true.
[00:03:52.400 --> 00:03:53.400]   It's Rhode Island.
[00:03:53.400 --> 00:03:54.400]   It's nice to see you, Alex.
[00:03:54.400 --> 00:03:55.400]   Good to be back.
[00:03:55.400 --> 00:03:56.640]   And we want to welcome a newbie to the show.
[00:03:56.640 --> 00:03:57.640]   So be kind, be nice.
[00:03:57.640 --> 00:03:58.640]   Wesley Faulkner is here.
[00:03:58.640 --> 00:04:02.280]   I met Wesley in Austin when we were down for South By.
[00:04:02.280 --> 00:04:04.360]   And I was so impressed.
[00:04:04.360 --> 00:04:05.360]   You know why I was impressed?
[00:04:05.360 --> 00:04:07.120]   Because Stacy Higginbotham gave you the biggest tug.
[00:04:07.120 --> 00:04:09.120]   And I thought, well, he must be one of the good guys.
[00:04:09.120 --> 00:04:10.880]   Because Stacy's very finicky.
[00:04:10.880 --> 00:04:11.880]   Yes.
[00:04:11.880 --> 00:04:12.880]   It's nice to see you, Wesley.
[00:04:12.880 --> 00:04:13.880]   Well, that's what you want.
[00:04:13.880 --> 00:04:14.880]   It's a surname.
[00:04:14.880 --> 00:04:15.880]   She met you when you were at AMD.
[00:04:15.880 --> 00:04:16.880]   Yes.
[00:04:16.880 --> 00:04:17.880]   You and IOT stuff there.
[00:04:17.880 --> 00:04:18.880]   That was over 10 years ago, yeah.
[00:04:18.880 --> 00:04:19.880]   Yeah.
[00:04:19.880 --> 00:04:20.880]   Wow.
[00:04:20.880 --> 00:04:21.880]   But you still keep in touch.
[00:04:21.880 --> 00:04:22.880]   Yes.
[00:04:22.880 --> 00:04:23.880]   Yes.
[00:04:23.880 --> 00:04:24.880]   So jealous.
[00:04:24.880 --> 00:04:25.880]   Absolutely.
[00:04:25.880 --> 00:04:26.880]   I'd say Austin's a small town.
[00:04:26.880 --> 00:04:28.280]   This is-- I should tell everybody.
[00:04:28.280 --> 00:04:29.480]   I should warn everybody.
[00:04:29.480 --> 00:04:32.140]   This is April Fools.
[00:04:32.140 --> 00:04:36.080]   You know, though, it used to be you would walk onto the internet on April Fools Day with
[00:04:36.080 --> 00:04:42.000]   a flack jacket going like this, be where it seems to have calmed down a lot.
[00:04:42.000 --> 00:04:43.000]   Because of Zester.
[00:04:43.000 --> 00:04:44.000]   Isn't that it?
[00:04:44.000 --> 00:04:45.000]   Yeah.
[00:04:45.000 --> 00:04:46.000]   It's the first time since I was born.
[00:04:46.000 --> 00:04:47.000]   That's right.
[00:04:47.000 --> 00:04:50.000]   Most of my life times that Eastern April Fools fall on the same day.
[00:04:50.000 --> 00:04:52.680]   Those to the wise and the highmers are at mass today.
[00:04:52.680 --> 00:04:54.240]   Is that what it is?
[00:04:54.240 --> 00:04:56.640]   I also think a lot of the good jokes have been done.
[00:04:56.640 --> 00:05:01.480]   I mean, if you think back to when this kind of blew up, Gmail had its, like Gmail paper
[00:05:01.480 --> 00:05:02.480]   joke.
[00:05:02.480 --> 00:05:04.600]   They were going to print out our emails to you and send them to you.
[00:05:04.600 --> 00:05:06.160]   And everyone almost bought it for a second.
[00:05:06.160 --> 00:05:08.440]   Back then, it was a fresh kind of cool take on it.
[00:05:08.440 --> 00:05:10.880]   And now it's kind of like-- it's like South by Southwest, no offense to Austin.
[00:05:10.880 --> 00:05:13.960]   But it's been so commercialized, the life's been beaten out of it.
[00:05:13.960 --> 00:05:16.040]   And now it's a mere husk of what it used to be.
[00:05:16.040 --> 00:05:22.440]   It feels like at one point Google was spending about half of its time preparing for April
[00:05:22.440 --> 00:05:23.440]   Fools Day.
[00:05:23.440 --> 00:05:28.040]   Every division of Google had an April Fools page or joke.
[00:05:28.040 --> 00:05:29.440]   It's calmed down a lot.
[00:05:29.440 --> 00:05:30.920]   Google Maps had a Where's Waldo.
[00:05:30.920 --> 00:05:35.400]   If you go to your Maps app on your phone, a little Waldo peers out and there's a Where's
[00:05:35.400 --> 00:05:37.960]   Waldo game on it, which isn't really even.
[00:05:37.960 --> 00:05:42.440]   You know, the one that upset people the most I'm hearing, Pokemon Go had eight bit Pokemon.
[00:05:42.440 --> 00:05:44.160]   I hear that was popular though.
[00:05:44.160 --> 00:05:45.160]   People liked that.
[00:05:45.160 --> 00:05:46.160]   But it was unpopular.
[00:05:46.160 --> 00:05:47.160]   People didn't like it.
[00:05:47.160 --> 00:05:48.760]   Well, according to my Twitter timeline, it wasn't--
[00:05:48.760 --> 00:05:49.920]   According to my Twitter--
[00:05:49.920 --> 00:05:52.120]   And we're off to the races.
[00:05:52.120 --> 00:05:53.120]   What about the Twitter--
[00:05:53.120 --> 00:05:54.600]   According to my Twitter timeline--
[00:05:54.600 --> 00:05:55.760]   So here's an idea though.
[00:05:55.760 --> 00:05:59.560]   In that case, if it was popular among a certain subset, should they not build that out as
[00:05:59.560 --> 00:06:01.360]   an actual feature as a toggle, an option?
[00:06:01.360 --> 00:06:03.800]   I think that's why the unpopular set wasn't liking it.
[00:06:03.800 --> 00:06:04.800]   They don't want to see it.
[00:06:04.800 --> 00:06:05.800]   I presume it'll go away tomorrow.
[00:06:05.800 --> 00:06:06.800]   Yeah.
[00:06:06.800 --> 00:06:07.800]   I mean, these have to be one day a phenomenon.
[00:06:07.800 --> 00:06:08.800]   Yeah.
[00:06:08.800 --> 00:06:12.360]   But the worst element of this is now people are going early or late on their April Fools
[00:06:12.360 --> 00:06:15.800]   joke to make them a bit more compelling, like a March 30th or 30th verse April Fool's
[00:06:15.800 --> 00:06:16.800]   joke.
[00:06:16.800 --> 00:06:17.800]   Not funny.
[00:06:17.800 --> 00:06:19.600]   And I don't think we should be doing that in the news media.
[00:06:19.600 --> 00:06:20.600]   It's trying to be as a--
[00:06:20.600 --> 00:06:21.600]   OK, funny or not funny.
[00:06:21.600 --> 00:06:24.880]   Google Cloud hummus API.
[00:06:24.880 --> 00:06:27.200]   What?
[00:06:27.200 --> 00:06:28.200]   Not funny.
[00:06:28.200 --> 00:06:29.200]   Not funny.
[00:06:29.200 --> 00:06:30.200]   Not funny, Google.
[00:06:30.200 --> 00:06:31.200]   See, that's the big problem.
[00:06:31.200 --> 00:06:32.200]   Is that like in Israel?
[00:06:32.200 --> 00:06:33.200]   Who?
[00:06:33.200 --> 00:06:34.200]   National dish.
[00:06:34.200 --> 00:06:35.560]   We have more than 20 types of--
[00:06:35.560 --> 00:06:36.960]   Maybe it's from Google Cloud Israel.
[00:06:36.960 --> 00:06:37.960]   I don't know.
[00:06:37.960 --> 00:06:38.960]   Maybe it's funny in Israel.
[00:06:38.960 --> 00:06:41.840]   But isn't there a machine like voice thing called taco?
[00:06:41.840 --> 00:06:42.840]   Yes.
[00:06:42.840 --> 00:06:43.840]   Taco Trons.
[00:06:43.840 --> 00:06:47.040]   We were talking about that on Twig on Wednesday.
[00:06:47.040 --> 00:06:48.040]   The Taco Trons.
[00:06:48.040 --> 00:06:49.040]   I mean, it's kind of believable.
[00:06:49.040 --> 00:06:50.680]   Let's go from Taco to hummus.
[00:06:50.680 --> 00:06:55.520]   Carl Pei, founder of One Plus, has apparently announced cryptocurrency called Paycoin.
[00:06:55.520 --> 00:06:57.240]   I did that joke back in 2014.
[00:06:57.240 --> 00:06:59.640]   I called it Crunchcoin at TC and no one was funny.
[00:06:59.640 --> 00:07:00.640]   Not that funny.
[00:07:00.640 --> 00:07:01.640]   Yeah.
[00:07:01.640 --> 00:07:02.640]   No.
[00:07:02.640 --> 00:07:03.640]   This one's all right.
[00:07:03.640 --> 00:07:04.640]   This is T-Mobile.
[00:07:04.640 --> 00:07:05.640]   They announced a smart shoe phone.
[00:07:05.640 --> 00:07:08.040]   That was the video was stupid.
[00:07:08.040 --> 00:07:09.040]   Funny, stupid.
[00:07:09.040 --> 00:07:10.040]   Yeah.
[00:07:10.040 --> 00:07:12.040]   It's all stars with a phone.
[00:07:12.040 --> 00:07:13.040]   It's time for a call back.
[00:07:13.040 --> 00:07:14.040]   Get the sidekick.
[00:07:14.040 --> 00:07:15.040]   Yeah, the sidekicks.
[00:07:15.040 --> 00:07:16.040]   Oh, get it.
[00:07:16.040 --> 00:07:19.840]   Oh, Google is bringing back the sidekick.
[00:07:19.840 --> 00:07:20.840]   And it's even--
[00:07:20.840 --> 00:07:24.360]   Actually, this is painful because if they brought back the sidekick, I'd actually be
[00:07:24.360 --> 00:07:25.360]   happy.
[00:07:25.360 --> 00:07:26.360]   You'd be stoked about that.
[00:07:26.360 --> 00:07:27.720]   I want them to bring back the sidekick.
[00:07:27.720 --> 00:07:29.600]   If you have a banana phone, you shouldn't have a phone.
[00:07:29.600 --> 00:07:31.400]   I want a banana phone, too.
[00:07:31.400 --> 00:07:32.400]   Did anybody order one?
[00:07:32.400 --> 00:07:34.040]   They announced it at Mobile World Congress.
[00:07:34.040 --> 00:07:37.840]   This is the phone that Neo used to get out of the office.
[00:07:37.840 --> 00:07:38.840]   I have one coming.
[00:07:38.840 --> 00:07:39.840]   Did you really?
[00:07:39.840 --> 00:07:42.280]   They say they're sending me one.
[00:07:42.280 --> 00:07:44.120]   I don't know when it's coming up.
[00:07:44.120 --> 00:07:45.120]   I feel like if you were in--
[00:07:45.120 --> 00:07:46.120]   I see that email.
[00:07:46.120 --> 00:07:52.680]   Mr. Nato, Nokia's pleased to announce that you will be receiving a banana phone.
[00:07:52.680 --> 00:07:54.520]   Please try not to lord it all over everybody.
[00:07:54.520 --> 00:07:56.720]   You've got to bring it to an Apple event.
[00:07:56.720 --> 00:07:58.520]   Or do they just go really run anything?
[00:07:58.520 --> 00:08:01.360]   Hello, Andy.
[00:08:01.360 --> 00:08:03.760]   You've got five seconds to get out of there.
[00:08:03.760 --> 00:08:05.480]   That is the DeLorean of phones.
[00:08:05.480 --> 00:08:06.480]   It's the DeLorean of phones.
[00:08:06.480 --> 00:08:08.160]   And I do not mean that as a positive analogy.
[00:08:08.160 --> 00:08:09.880]   I mean, that in the root is possible way.
[00:08:09.880 --> 00:08:10.880]   It's not pretty.
[00:08:10.880 --> 00:08:11.880]   It's just nostalgia.
[00:08:11.880 --> 00:08:12.880]   It's not going to be useful.
[00:08:12.880 --> 00:08:14.400]   And you can't tweet from it.
[00:08:14.400 --> 00:08:15.400]   Speak on nostalgia.
[00:08:15.400 --> 00:08:17.920]   Well, that's what makes it useful for a lot of people.
[00:08:17.920 --> 00:08:22.920]   But I love the idea of saying, what if we were to make a $99 phone and making it run
[00:08:22.920 --> 00:08:25.680]   smartphone type apps was not the hugest priority?
[00:08:25.680 --> 00:08:29.520]   What if it just has to run the basic social media apps that most people use and run them
[00:08:29.520 --> 00:08:31.760]   extremely, extremely well?
[00:08:31.760 --> 00:08:35.960]   And if you can do that for $100 and it's also a hotspot and it's not just a flip phone,
[00:08:35.960 --> 00:08:41.720]   it really is like a modern operating system with a really good GUI and not crappy, but
[00:08:41.720 --> 00:08:43.640]   not not crappy camera.
[00:08:43.640 --> 00:08:44.680]   There are a lot of people for them.
[00:08:44.680 --> 00:08:46.880]   They just want a good phone that works for them.
[00:08:46.880 --> 00:08:49.240]   And for 99 bucks, you can give this to your kid.
[00:08:49.240 --> 00:08:50.680]   They can't get into much trouble with it.
[00:08:50.680 --> 00:08:56.160]   And if they drop it down a toilet or down a well, well, it won't take long to most a
[00:08:56.160 --> 00:08:57.720]   few lawns and be able to afford another one.
[00:08:57.720 --> 00:08:59.360]   It does have snake on it.
[00:08:59.360 --> 00:09:01.480]   See, I used to put a snake on the old note here.
[00:09:01.480 --> 00:09:02.480]   That's cool.
[00:09:02.480 --> 00:09:03.480]   The retro stuff.
[00:09:03.480 --> 00:09:06.320]   All right, so that's it on April Fools, right?
[00:09:06.320 --> 00:09:08.680]   We got the, do we cover the waterfront?
[00:09:08.680 --> 00:09:13.560]   You know, I can't believe I used to really dread it because I would go look at the night
[00:09:13.560 --> 00:09:17.600]   to be my beat check and there would, I'd have to figure out what was real and what wasn't
[00:09:17.600 --> 00:09:18.600]   real.
[00:09:18.600 --> 00:09:22.440]   And it was a, and you're partly the blame for this, Alex Wilham, because I think you had
[00:09:22.440 --> 00:09:24.040]   some of those tech crunch articles.
[00:09:24.040 --> 00:09:25.040]   Yeah, yeah, we did.
[00:09:25.040 --> 00:09:26.440]   But that's what I thought I was funny.
[00:09:26.440 --> 00:09:27.440]   And then I realized that I wasn't.
[00:09:27.440 --> 00:09:32.160]   So I gave it up because it requires a certain level of like, you'd be confident in your
[00:09:32.160 --> 00:09:36.080]   sense of humor to make a joke like that on behalf of your team without telling them.
[00:09:36.080 --> 00:09:37.840]   And then you just, you didn't tell them?
[00:09:37.840 --> 00:09:38.840]   Oh, no.
[00:09:38.840 --> 00:09:39.840]   Uh, no.
[00:09:39.840 --> 00:09:42.760]   We would just write articles and ship them and then see what would happen.
[00:09:42.760 --> 00:09:44.000]   See if anybody noticed.
[00:09:44.000 --> 00:09:45.000]   Um, yes.
[00:09:45.000 --> 00:09:49.120]   But I mean, it was fun, but I wouldn't go write the crunch coin article again.
[00:09:49.120 --> 00:09:50.120]   Right?
[00:09:50.120 --> 00:09:55.600]   I mean, of course, if you think about anybody who would still think April Fools jokes are
[00:09:55.600 --> 00:09:57.720]   funny, it would be Elon Musk.
[00:09:57.720 --> 00:10:04.440]   Mm. Elon was found passed out against a Tesla model three surrounded by Tesla, Kila bottles,
[00:10:04.440 --> 00:10:08.360]   the tracks of dried tears still visible on his cheeks.
[00:10:08.360 --> 00:10:15.160]   This is not a forward looking statement because obviously what's the point that's got a cardboard
[00:10:15.160 --> 00:10:18.080]   Tesla box with the words bank wupped.
[00:10:18.080 --> 00:10:19.080]   Yeah.
[00:10:19.080 --> 00:10:20.080]   That's not funny.
[00:10:20.080 --> 00:10:21.240]   It's kind of sad.
[00:10:21.240 --> 00:10:26.160]   It's well, no, I'm sure he thinks it's funny because he thinks that there's no way that
[00:10:26.160 --> 00:10:28.960]   Tesla could possibly fail and that he couldn't be bankrupt.
[00:10:28.960 --> 00:10:32.560]   The rest of us are like, Oh, let's, let's right click and save this for the, for the
[00:10:32.560 --> 00:10:33.560]   song.
[00:10:33.560 --> 00:10:36.560]   Who was the phone before that?
[00:10:36.560 --> 00:10:37.880]   He was a lot of Photoshop.
[00:10:37.880 --> 00:10:41.480]   There are many chapters of bankruptcy and his critics so rightly pointed out Tesla has
[00:10:41.480 --> 00:10:44.880]   them all, including chapter 14 and a half.
[00:10:44.880 --> 00:10:45.880]   The worst one.
[00:10:45.880 --> 00:10:47.520]   So am I missing something?
[00:10:47.520 --> 00:10:51.640]   The joke here, if you don't get it, is that Tesla consumes tons of cash to operate and
[00:10:51.640 --> 00:10:55.360]   needs to borrow money constantly at a very high interest rate to funds operations.
[00:10:55.360 --> 00:10:59.600]   And we've recently seen the cost of its debt go up dramatically, implying a lack of investor
[00:10:59.600 --> 00:11:02.720]   faith that it's going to be able to repay its debts and also his chair prices are down.
[00:11:02.720 --> 00:11:06.080]   So he's making a joke about it, but it's not funny because it might happen.
[00:11:06.080 --> 00:11:07.080]   This is too true.
[00:11:07.080 --> 00:11:09.280]   It's too, it's too close to home to be whimsical.
[00:11:09.280 --> 00:11:10.280]   It's just kind of sad.
[00:11:10.280 --> 00:11:11.520]   There's a whole go down.
[00:11:11.520 --> 00:11:14.720]   Don't you want to go down laughing, I guess?
[00:11:14.720 --> 00:11:18.800]   I mean, yeah, but in that picture, he just looks kind of sad and alone and that's true.
[00:11:18.800 --> 00:11:19.800]   That's true.
[00:11:19.800 --> 00:11:21.120]   I'm going down to my terms.
[00:11:21.120 --> 00:11:22.760]   I mean, he also owns SpaceX.
[00:11:22.760 --> 00:11:25.360]   I mean, I think Elon himself is doing fine.
[00:11:25.360 --> 00:11:26.360]   Yeah.
[00:11:26.360 --> 00:11:27.360]   Yeah.
[00:11:27.360 --> 00:11:31.640]   Well, if he's going to be like bankrupt and homeless, okay, pretty slick to be sleeping
[00:11:31.640 --> 00:11:35.360]   in a Tesla three as your home, but remember that he's got those, he's got those crew modules
[00:11:35.360 --> 00:11:36.360]   at SpaceX.
[00:11:36.360 --> 00:11:37.840]   He can be sleeping in instead.
[00:11:37.840 --> 00:11:39.560]   That's got to be better space.
[00:11:39.560 --> 00:11:44.200]   You get to, you know, pick up your unemployment check in one of those astronaut suits that he
[00:11:44.200 --> 00:11:45.720]   was modeling about a year ago.
[00:11:45.720 --> 00:11:46.720]   Oh, that's right.
[00:11:46.720 --> 00:11:47.720]   I forgot about that.
[00:11:47.720 --> 00:11:50.000]   He's probably kind of bummed that he sent his car into space now.
[00:11:50.000 --> 00:11:51.000]   He might have been able to.
[00:11:51.000 --> 00:11:52.000]   There you go.
[00:11:52.000 --> 00:11:56.240]   Well, at least like looking to change out of the ashtray first, you know, you could use
[00:11:56.240 --> 00:11:57.240]   that.
[00:11:57.240 --> 00:11:58.240]   All right.
[00:11:58.240 --> 00:11:59.240]   Now we're falling for the whole.
[00:11:59.240 --> 00:12:00.240]   Now we're doing what they want.
[00:12:00.240 --> 00:12:01.240]   Yes.
[00:12:01.240 --> 00:12:04.200]   You know, there was an April Fool's I thought joke.
[00:12:04.200 --> 00:12:05.360]   It was an April Fool's announcement.
[00:12:05.360 --> 00:12:07.600]   I thought for sure was a joke from Cloudflare.
[00:12:07.600 --> 00:12:08.840]   So that wasn't a joke.
[00:12:08.840 --> 00:12:09.840]   It wasn't a joke.
[00:12:09.840 --> 00:12:10.880]   Oh, I thought it was.
[00:12:10.880 --> 00:12:14.200]   So Cloudflare announced, yeah, I know.
[00:12:14.200 --> 00:12:15.640]   I thought it was too.
[00:12:15.640 --> 00:12:18.920]   Cloudflare announced a new DNS service.
[00:12:18.920 --> 00:12:21.920]   1.1.1.1.
[00:12:21.920 --> 00:12:26.640]   And the idea would be that you would replace your internet service provider.
[00:12:26.640 --> 00:12:29.800]   Let me go to the Cloudflare blog post instead of the.
[00:12:29.800 --> 00:12:32.640]   So it's like a new DNS then.
[00:12:32.640 --> 00:12:33.640]   Yes.
[00:12:33.640 --> 00:12:35.960]   You would replace your DNS with this.
[00:12:35.960 --> 00:12:36.960]   There's others.
[00:12:36.960 --> 00:12:38.680]   There's quad nine.
[00:12:38.680 --> 00:12:40.400]   This one's privacy focused.
[00:12:40.400 --> 00:12:44.400]   And I think it's kind of interesting because certainly Cloudflare has a bandwidth to do
[00:12:44.400 --> 00:12:45.400]   this.
[00:12:45.400 --> 00:12:46.400]   They do DDoS protection for people.
[00:12:46.400 --> 00:12:47.400]   They have a CDN.
[00:12:47.400 --> 00:12:50.880]   They have, you know, probably more bandwidth than almost anybody.
[00:12:50.880 --> 00:12:58.240]   1.1.1 would continue to use an existing authoritative DNS service Cloudflare provides.
[00:12:58.240 --> 00:13:00.120]   But it'd be open to the public.
[00:13:00.120 --> 00:13:01.120]   It's encrypted.
[00:13:01.120 --> 00:13:03.760]   It uses HTTPS, which not all DNS does.
[00:13:03.760 --> 00:13:06.240]   And it keeps your ISP from seeing what you're doing.
[00:13:06.240 --> 00:13:07.920]   So it protects your privacy.
[00:13:07.920 --> 00:13:12.800]   It doesn't have any other features like quad nine malware protection or anything like that.
[00:13:12.800 --> 00:13:14.000]   Wait, let's, can you do that on that?
[00:13:14.000 --> 00:13:15.160]   Oh, that's a good question.
[00:13:15.160 --> 00:13:20.320]   I wasn't able to set it up because it's surprisingly very busy right now.
[00:13:20.320 --> 00:13:23.920]   I set up in the afternoon and I was, I had, I think I had been using open DNS on this
[00:13:23.920 --> 00:13:29.600]   MacBook and I really did immediately see pages loading a lot faster because they, I think
[00:13:29.600 --> 00:13:33.800]   they say that when you see the numbers that they are giving for how much faster it is
[00:13:33.800 --> 00:13:37.520]   than competing services, it doesn't look that much faster.
[00:13:37.520 --> 00:13:42.360]   But then when you realize that when you go to, when you go to like, you know, New York
[00:13:42.360 --> 00:13:46.440]   Times.com, you're not just getting New York, you're not just resolving New York Times.com.
[00:13:46.440 --> 00:13:51.640]   You're resolving like 30 different ad networks and 30 different tracker sort of URLs.
[00:13:51.640 --> 00:13:53.280]   So yeah, I noticed an immediate speed up.
[00:13:53.280 --> 00:13:59.740]   So it's going to stay that way until inevitably I start researching the, here's how the 1.1.1.1.16
[00:13:59.740 --> 00:14:02.000]   Cam worked articles.
[00:14:02.000 --> 00:14:05.000]   You know, it performance is what cloud flares all about.
[00:14:05.000 --> 00:14:06.800]   They are by the way, we should mention a sponsor.
[00:14:06.800 --> 00:14:07.800]   We are big fans.
[00:14:07.800 --> 00:14:11.960]   I've known their CTO John Graham coming for many years.
[00:14:11.960 --> 00:14:17.720]   The blog post, which yes, Matthew Prince, the CEO wrote on April Fool's Day and admitted,
[00:14:17.720 --> 00:14:20.080]   I understand you're going to think this is phony.
[00:14:20.080 --> 00:14:24.560]   But after all, when better to announce 1.1.1 than for one.
[00:14:24.560 --> 00:14:25.880]   There are four ones.
[00:14:25.880 --> 00:14:26.880]   Yeah.
[00:14:26.880 --> 00:14:30.440]   Also, I like the PR team gets a shout out in the next paragraph.
[00:14:30.440 --> 00:14:34.120]   He's like, my PR team can remind me that Jimmy, a launch able first, but it wasn't Sunday
[00:14:34.120 --> 00:14:36.160]   and it wasn't Easter.
[00:14:36.160 --> 00:14:37.560]   That's just go for it, man.
[00:14:37.560 --> 00:14:38.560]   Do you?
[00:14:38.560 --> 00:14:39.560]   Do you?
[00:14:39.560 --> 00:14:43.160]   So I think this is going to be very interesting to watch.
[00:14:43.160 --> 00:14:47.520]   Well, I'm sure Steve Gibson will cover it a little bit.
[00:14:47.520 --> 00:14:49.680]   I've probably shipped everything to 1.1.
[00:14:49.680 --> 00:14:55.880]   I use OpenDNS like you, Andy, but if it's faster, I think this is a, kind of really
[00:14:55.880 --> 00:14:56.880]   cool.
[00:14:56.880 --> 00:14:58.600]   Thank you, CloudFlare, for providing this.
[00:14:58.600 --> 00:15:05.320]   They said they got the 1.1 from APNIC, the Asia Pacific NIC.
[00:15:05.320 --> 00:15:15.520]   And apparently they had it and AP, their research group had 1.1.1 and 1.001.
[00:15:15.520 --> 00:15:19.800]   But the addresses were valid, but many people had entered them into various random systems.
[00:15:19.800 --> 00:15:23.720]   They were continuously overwhelmed by a flood of garbage traffic.
[00:15:23.720 --> 00:15:27.080]   This is too easy to enter four ones, right?
[00:15:27.080 --> 00:15:30.520]   APNIC wanted to know where it's coming from.
[00:15:30.520 --> 00:15:33.560]   So the deal was, CloudFlare said, let us do this.
[00:15:33.560 --> 00:15:35.280]   APNIC said, that's a great idea.
[00:15:35.280 --> 00:15:39.560]   And we will give you information on the garbage traffic you're getting in exchange for being
[00:15:39.560 --> 00:15:41.200]   able to put the DNS resolver there.
[00:15:41.200 --> 00:15:44.040]   So I have to say, this is good.
[00:15:44.040 --> 00:15:47.360]   Does it have a lot of disclosure about what they're going to be doing with the data?
[00:15:47.360 --> 00:15:48.360]   Do you not trust them?
[00:15:48.360 --> 00:15:49.360]   You're right.
[00:15:49.360 --> 00:15:50.360]   Even if we did trust them.
[00:15:50.360 --> 00:15:51.360]   What is their retention policy?
[00:15:51.360 --> 00:15:54.280]   Are they going to be flushing it once a month, once a week?
[00:15:54.280 --> 00:15:55.280]   Good question.
[00:15:55.280 --> 00:16:00.360]   Well, the page does notice that does note that they have an outside company that's going
[00:16:00.360 --> 00:16:03.160]   to be auditing their data to keep them on the up and up.
[00:16:03.160 --> 00:16:08.240]   So if you don't trust them, you hopefully can start to trust the other companies.
[00:16:08.240 --> 00:16:11.360]   And after all, CloudFlare's business is not selling advertising, right?
[00:16:11.360 --> 00:16:14.040]   It's not spying on us.
[00:16:14.040 --> 00:16:17.720]   So they're just, I mean, their business model is not built around it.
[00:16:17.720 --> 00:16:20.640]   And they've been known to be very good citizens, I think, on the internet.
[00:16:20.640 --> 00:16:21.640]   They really support people.
[00:16:21.640 --> 00:16:26.480]   They got, remember they got a little bit of heat because Daily Stormer was running for
[00:16:26.480 --> 00:16:27.480]   CloudFlare.
[00:16:27.480 --> 00:16:28.480]   Oh, it was just about to be a man.
[00:16:28.480 --> 00:16:29.480]   Yeah.
[00:16:29.480 --> 00:16:32.160]   And at first, Matthew Prince said, I think in a quite principled way, look, we don't
[00:16:32.160 --> 00:16:35.920]   want to be responsible for editing the internet.
[00:16:35.920 --> 00:16:37.640]   And we offer this service to anybody.
[00:16:37.640 --> 00:16:41.920]   And this is, you know, this, but eventually I think the pressure, he decided, all right,
[00:16:41.920 --> 00:16:43.520]   and we're going to make an exception.
[00:16:43.520 --> 00:16:47.200]   This is one case where we are going to yank the Daily Stormer and he did.
[00:16:47.200 --> 00:16:50.280]   But I understand his reluctance because that's a slippery slope, isn't it?
[00:16:50.280 --> 00:16:53.520]   Well, he said we should not have this power, but he said he did it because he woke up
[00:16:53.520 --> 00:16:55.920]   anger and he just wanted to get him off the internet.
[00:16:55.920 --> 00:16:57.480]   And I can kind of grok both sides of it.
[00:16:57.480 --> 00:16:58.720]   And he also has to run the business.
[00:16:58.720 --> 00:17:02.840]   He's not responsible for the health and safety of the entire internet and just take care
[00:17:02.840 --> 00:17:03.840]   of his company.
[00:17:03.840 --> 00:17:08.200]   But, geez, I'm glad I don't have that responsibility on a day to day basis because people will
[00:17:08.200 --> 00:17:09.440]   come at you with all sorts of things.
[00:17:09.440 --> 00:17:13.640]   Well, and apparently it didn't open a can of worms, which I think would be a reasonable
[00:17:13.640 --> 00:17:14.640]   fear that yet.
[00:17:14.640 --> 00:17:15.640]   Yeah.
[00:17:15.640 --> 00:17:16.640]   Well, that was it.
[00:17:16.640 --> 00:17:17.640]   Well, I was like a year ago that.
[00:17:17.640 --> 00:17:19.120]   Oh, no, that can't be a year ago.
[00:17:19.120 --> 00:17:20.120]   Oh, gosh.
[00:17:20.120 --> 00:17:21.120]   Yeah, I think so.
[00:17:21.120 --> 00:17:22.680]   Oh, dear heavens.
[00:17:22.680 --> 00:17:26.520]   I can't believe it's been a year since you got a job.
[00:17:26.520 --> 00:17:28.840]   So thanks, Leo.
[00:17:28.840 --> 00:17:29.840]   I know it's crunchy.
[00:17:29.840 --> 00:17:33.560]   This is important news is a year old to turn a year old in the middle of March.
[00:17:33.560 --> 00:17:34.560]   Yeah.
[00:17:34.560 --> 00:17:35.560]   That's nice.
[00:17:35.560 --> 00:17:36.560]   Let me have congratulations.
[00:17:36.560 --> 00:17:37.560]   Thank you.
[00:17:37.560 --> 00:17:38.560]   That's great.
[00:17:38.560 --> 00:17:42.320]   In fact, if you go, I guess you can go to 1.1.1.1 as a web page and they explain a little bit
[00:17:42.320 --> 00:17:43.480]   more of the service there.
[00:17:43.480 --> 00:17:49.800]   So and it does say we will never sell your data or use it to target ads period.
[00:17:49.800 --> 00:17:52.800]   And I'm having my usual browser.
[00:17:52.800 --> 00:17:55.800]   You are two minutes away from browsing a faster, more private internet.
[00:17:55.800 --> 00:17:58.320]   So this is actually a good page for explaining it.
[00:17:58.320 --> 00:18:00.400]   We will never log your IP address.
[00:18:00.400 --> 00:18:01.600]   There's your answer, Wesley.
[00:18:01.600 --> 00:18:07.080]   But also, if you don't ever sign like a term of service, because you, they could attach
[00:18:07.080 --> 00:18:09.640]   it to your IP address, that's it.
[00:18:09.640 --> 00:18:11.840]   Which is, by the way, what you're going to answer is providers.
[00:18:11.840 --> 00:18:12.920]   Yeah, exactly.
[00:18:12.920 --> 00:18:14.160]   And they know who you are.
[00:18:14.160 --> 00:18:16.760]   But there's also no proof that you sign a disclosure.
[00:18:16.760 --> 00:18:20.240]   So you never have to say, if I don't agree to it, then they can't do anything with your
[00:18:20.240 --> 00:18:21.240]   IP address.
[00:18:21.240 --> 00:18:22.240]   That's a good point.
[00:18:22.240 --> 00:18:23.240]   Yeah.
[00:18:23.240 --> 00:18:24.800]   And KPMG has been retained to audit annually.
[00:18:24.800 --> 00:18:26.240]   I think this is great.
[00:18:26.240 --> 00:18:27.240]   Good.
[00:18:27.240 --> 00:18:28.240]   You know what?
[00:18:28.240 --> 00:18:32.440]   Crazy to announce this on April Fool's Day, but I want to be the first to say, it's real
[00:18:32.440 --> 00:18:36.480]   and Andy, you verified it by trying it and congratulations.
[00:18:36.480 --> 00:18:37.640]   That's really nice.
[00:18:37.640 --> 00:18:38.640]   Thank you, Matthew and Clap.
[00:18:38.640 --> 00:18:40.480]   And there's no competing news today.
[00:18:40.480 --> 00:18:41.480]   None.
[00:18:41.480 --> 00:18:44.240]   Because no one else was going to launch anything on April 1st.
[00:18:44.240 --> 00:18:45.320]   So good to them.
[00:18:45.320 --> 00:18:46.320]   Is that true?
[00:18:46.320 --> 00:18:48.720]   There were no launches of any kind today?
[00:18:48.720 --> 00:18:49.720]   Sunday.
[00:18:49.720 --> 00:18:52.400]   And I couldn't even bike pancakes this morning.
[00:18:52.400 --> 00:18:54.120]   It was everything was closed.
[00:18:54.120 --> 00:18:55.840]   Two different diners were closed.
[00:18:55.840 --> 00:18:58.000]   In that case, let's just go home.
[00:18:58.000 --> 00:18:59.000]   There you go.
[00:18:59.000 --> 00:19:00.080]   That's what I'm talking about.
[00:19:00.080 --> 00:19:01.080]   Thank you, everybody.
[00:19:01.080 --> 00:19:03.400]   And look at the ad reads.
[00:19:03.400 --> 00:19:06.880]   Well, let's tell you the truth.
[00:19:06.880 --> 00:19:09.400]   Twit is here to separate the ad reads.
[00:19:09.400 --> 00:19:11.840]   Basically that's the one.
[00:19:11.840 --> 00:19:14.240]   That's why we're going to keep going.
[00:19:14.240 --> 00:19:16.760]   Otherwise I just have to do four ads in a row.
[00:19:16.760 --> 00:19:17.760]   That would be no jokes.
[00:19:17.760 --> 00:19:18.760]   That'd be terrible.
[00:19:18.760 --> 00:19:20.480]   That'd be no fun.
[00:19:20.480 --> 00:19:24.200]   Mr. Huggy in our chatroom always a reliable source.
[00:19:24.200 --> 00:19:28.680]   Said I did a DNS benchmark on 1.0 and Quad9 was faster.
[00:19:28.680 --> 00:19:31.560]   But remember, that's at your place.
[00:19:31.560 --> 00:19:33.760]   So that's going to vary everybody.
[00:19:33.760 --> 00:19:39.040]   Steve Gibson offers a benchmark for DNS for free on his website, grc.com.
[00:19:39.040 --> 00:19:44.760]   I think it'd probably be sensible to try different places and see what you get.
[00:19:44.760 --> 00:19:48.600]   Quad9 does something different anyway than Quad1.
[00:19:48.600 --> 00:19:49.600]   Quad1 already.
[00:19:49.600 --> 00:19:54.200]   We already got a nickname for Quad1.
[00:19:54.200 --> 00:19:57.800]   Did anybody watch the Apple event on Tuesday?
[00:19:57.800 --> 00:20:00.600]   We couldn't watch it because it wasn't live.
[00:20:00.600 --> 00:20:01.600]   Later.
[00:20:01.600 --> 00:20:03.360]   Andy was there.
[00:20:03.360 --> 00:20:04.520]   You watched it in person.
[00:20:04.520 --> 00:20:05.720]   You could watch it.
[00:20:05.720 --> 00:20:06.800]   It was in Chicago.
[00:20:06.800 --> 00:20:10.680]   So here we are a few days later.
[00:20:10.680 --> 00:20:16.280]   I have to say that the response has in general been fairly lukewarm.
[00:20:16.280 --> 00:20:22.440]   There's some people excited that you can now use an Apple pencil on an iPad for $329 on
[00:20:22.440 --> 00:20:23.920]   the low-end iPad.
[00:20:23.920 --> 00:20:24.920]   That's about it though.
[00:20:24.920 --> 00:20:28.920]   I don't hear people jumping up and down about the new software offerings.
[00:20:28.920 --> 00:20:30.640]   I haven't talked to a lot of educators.
[00:20:30.640 --> 00:20:36.320]   Andy, have you heard from anybody about what the education folks are saying about Apple's
[00:20:36.320 --> 00:20:37.320]   announcements?
[00:20:37.320 --> 00:20:41.560]   Well, there have always been really two groups of people inside education.
[00:20:41.560 --> 00:20:46.960]   The ones who really, whatever curriculum they have or whatever goals they have for the classroom
[00:20:46.960 --> 00:20:51.400]   and certainly whatever budget they have for the classroom makes an iPad at least a possible
[00:20:51.400 --> 00:20:53.160]   sort of thing for the class to have.
[00:20:53.160 --> 00:20:56.440]   The ones for whom it's just not relevant.
[00:20:56.440 --> 00:20:59.280]   We're not talking about, oh, I favor this over the other.
[00:20:59.280 --> 00:21:04.560]   An iPad is just not relevant because they're dealing with core curriculums.
[00:21:04.560 --> 00:21:09.200]   They're dealing with requirements for purchasing that really say that if this device does not
[00:21:09.200 --> 00:21:14.520]   have a built-in keyboard, you can't buy them because our schools need devices with keyboards.
[00:21:14.520 --> 00:21:21.120]   To say nothing of how closed the system is for Apple, how smaller the marketplace of
[00:21:21.120 --> 00:21:25.800]   workers for IT and for content developers are, you can get basically anybody who knows how
[00:21:25.800 --> 00:21:30.280]   to make content for a web browser can develop for Chrome.
[00:21:30.280 --> 00:21:35.880]   However, you need an iOS developer to give you customized content for your iPad.
[00:21:35.880 --> 00:21:38.960]   However, the ones that, again, the ones that do have those resources are really, really
[00:21:38.960 --> 00:21:45.000]   pleased about it because Apple seems to, Apple's goal wasn't to try to fight back against Chromebook.
[00:21:45.000 --> 00:21:51.080]   It was to make sure that if people are predisposed to getting iPads in their classrooms, they're
[00:21:51.080 --> 00:21:56.360]   going to remove, Apple wanted to try to remove as many of the obstacles as they could possibly
[00:21:56.360 --> 00:21:59.840]   do and there were so many obstacles.
[00:21:59.840 --> 00:22:03.760]   Does anyone ever do studies to see if this even helps kids?
[00:22:03.760 --> 00:22:08.680]   I would assume that if you have access to more technology, you'll do better.
[00:22:08.680 --> 00:22:11.400]   But is it $300 or $500 better?
[00:22:11.400 --> 00:22:15.040]   Well, I also wonder if you don't have--
[00:22:15.040 --> 00:22:19.760]   Maybe the other question is if you don't have access to-- if you never learn about technology
[00:22:19.760 --> 00:22:22.640]   in school, are you at a disadvantage when you get into the workforce?
[00:22:22.640 --> 00:22:24.400]   I mean, compared to a Chromebook.
[00:22:24.400 --> 00:22:25.400]   Oh, right.
[00:22:25.400 --> 00:22:26.400]   It's better than what Google puts out.
[00:22:26.400 --> 00:22:29.280]   If you ask me, I'll be the first to say it.
[00:22:29.280 --> 00:22:32.920]   I don't think Apple makes any sense in education that a Chromebook makes much more sense in
[00:22:32.920 --> 00:22:33.920]   education.
[00:22:33.920 --> 00:22:38.520]   Not only is it cheaper, it's got a better IT management story to tell.
[00:22:38.520 --> 00:22:40.080]   It's more robust.
[00:22:40.080 --> 00:22:42.560]   It's got a keyboard.
[00:22:42.560 --> 00:22:44.720]   And more importantly to me, it's more open.
[00:22:44.720 --> 00:22:51.480]   I think my biggest problem with iPad in the classroom is iPad is a closed environment.
[00:22:51.480 --> 00:22:54.800]   You're buying into an ecosystem and the only way it's going to work is if you're Apple
[00:22:54.800 --> 00:22:55.800]   everywhere.
[00:22:55.800 --> 00:22:58.480]   Of course, that's good for Apple, but I don't think that's good for education.
[00:22:58.480 --> 00:23:02.960]   It would make more sense if that approach means it actually works better in terms of
[00:23:02.960 --> 00:23:03.960]   learning and getting kids.
[00:23:03.960 --> 00:23:04.960]   Like if you can prove.
[00:23:04.960 --> 00:23:05.960]   Yeah.
[00:23:05.960 --> 00:23:10.880]   The studies I've seen haven't said that the school systems that we're using education
[00:23:10.880 --> 00:23:14.160]   based on iPads were doing better than Chromebooks.
[00:23:14.160 --> 00:23:16.560]   But there's so many variables associated with that.
[00:23:16.560 --> 00:23:22.440]   It really depends on how really, really worked up was the school system was about having
[00:23:22.440 --> 00:23:24.080]   an iPad based curriculum.
[00:23:24.080 --> 00:23:29.160]   Or they didn't do more focus things like what if we have Chromebooks for most of the school,
[00:23:29.160 --> 00:23:32.400]   but there are one or two tracks.
[00:23:32.400 --> 00:23:37.720]   There's a language lab or a science lab or a physics lab that will have a cart of iPads
[00:23:37.720 --> 00:23:38.960]   inside the room.
[00:23:38.960 --> 00:23:43.520]   So I think if you're looking to say nothing of the fact that when Apple did big deals
[00:23:43.520 --> 00:23:48.680]   with the state of Maine, when they did big deals with Los Angeles, it wound up being huge
[00:23:48.680 --> 00:23:49.680]   disasters.
[00:23:49.680 --> 00:23:53.600]   And these were the every kid gets an iPad sort of solutions that I don't think the iPad
[00:23:53.600 --> 00:23:54.600]   is really well suited for.
[00:23:54.600 --> 00:23:55.600]   Yeah.
[00:23:55.600 --> 00:23:57.960]   I'm trying to imagine what point in time in high school it would have been better for
[00:23:57.960 --> 00:24:00.240]   me to have an iPad as opposed to a Chromebook or they kind of equivalent.
[00:24:00.240 --> 00:24:01.920]   And I can't think of a single example.
[00:24:01.920 --> 00:24:07.240]   I got some really interesting emails from people who said, "You're old."
[00:24:07.240 --> 00:24:09.920]   I get that one every day.
[00:24:09.920 --> 00:24:13.240]   But you're old and you think you still need a keyboard.
[00:24:13.240 --> 00:24:14.520]   Kids today don't need keyboards.
[00:24:14.520 --> 00:24:16.560]   I find that very hard to believe.
[00:24:16.560 --> 00:24:18.160]   Do they not create anything?
[00:24:18.160 --> 00:24:19.160]   You need to write.
[00:24:19.160 --> 00:24:23.320]   If you're going to get a job, even 10 years from now.
[00:24:23.320 --> 00:24:28.440]   I can't imagine that you'll not be at some point keying writing reports and memos and
[00:24:28.440 --> 00:24:29.440]   things.
[00:24:29.440 --> 00:24:30.440]   I can't imagine that.
[00:24:30.440 --> 00:24:31.440]   Maybe I am.
[00:24:31.440 --> 00:24:35.040]   If you want to write code using handwriting, go be my guest.
[00:24:35.040 --> 00:24:37.480]   I don't think that's going to work in your class.
[00:24:37.480 --> 00:24:42.120]   No, I mean, people, again, there's a really good argument to be made that touch screens
[00:24:42.120 --> 00:24:48.000]   are super relevant because just like the first, my first interaction with the computer
[00:24:48.000 --> 00:24:49.600]   was touching a keyboard.
[00:24:49.600 --> 00:24:54.280]   And then the generation after me, the first interaction was by touching a mouse or a trackpad.
[00:24:54.280 --> 00:24:57.720]   And then the generations after that, their first interaction with the computer was touching
[00:24:57.720 --> 00:25:00.120]   a sheet of glass, touching a touchscreen.
[00:25:00.120 --> 00:25:01.680]   So it's not as though that's irrelevant.
[00:25:01.680 --> 00:25:07.120]   But the thing is nothing has ever really gotten rid of the basic trinity of keyboard, mouse,
[00:25:07.120 --> 00:25:10.960]   and screen for the core computer experience.
[00:25:10.960 --> 00:25:13.880]   So if you're going to have something that your entire curriculum is going to be based
[00:25:13.880 --> 00:25:18.120]   around, if you're going to be creating a plan by which each one of your students has access
[00:25:18.120 --> 00:25:19.120]   to a computer.
[00:25:19.120 --> 00:25:21.600]   It really has to be something along the lines of a laptop.
[00:25:21.600 --> 00:25:25.720]   Ideally, something that in the advertising, in the advertising for it, basically both of
[00:25:25.720 --> 00:25:29.360]   how many ounces of milk you can spill into the keyboard before it starts to have a problem.
[00:25:29.360 --> 00:25:33.080]   Yeah, there's still a heavy lift for teachers where they have to figure this out, how they're
[00:25:33.080 --> 00:25:34.920]   going to use it the most effective.
[00:25:34.920 --> 00:25:38.960]   I also got emails because I was talking about that and Apple does have teacher Tuesday in
[00:25:38.960 --> 00:25:40.320]   the Apple stores.
[00:25:40.320 --> 00:25:41.960]   But I think Apple needs to do more than that.
[00:25:41.960 --> 00:25:49.360]   They had in 2014 a hundred million dollar fund to help schools and get equipment and teachers.
[00:25:49.360 --> 00:25:50.360]   I think that's really important.
[00:25:50.360 --> 00:25:51.960]   A hundred million doesn't seem like a lot.
[00:25:51.960 --> 00:25:53.240]   I think they need to commit more.
[00:25:53.240 --> 00:25:57.320]   And I don't see any, I don't know if they've added to that fund since then.
[00:25:57.320 --> 00:26:02.280]   The LA Unified School District wanted to buy a billion iPads, a billion dollars worth
[00:26:02.280 --> 00:26:03.280]   of iPads.
[00:26:03.280 --> 00:26:05.560]   That was an amazing verbal time.
[00:26:05.560 --> 00:26:07.160]   There is a big difference.
[00:26:07.160 --> 00:26:12.480]   But a billion is a big number either way you look at it and they end up suing both Apple
[00:26:12.480 --> 00:26:16.160]   and Pearson, the company that was supposed to make the curriculum and never did.
[00:26:16.160 --> 00:26:20.360]   And they got a fairly hefty settlement, a several hundred million dollar settlement
[00:26:20.360 --> 00:26:21.360]   and all this.
[00:26:21.360 --> 00:26:23.400]   This was a famous failure.
[00:26:23.400 --> 00:26:28.240]   But if the Chromebooks of 2015 take over more of the education market than the iPads
[00:26:28.240 --> 00:26:30.160]   will, which seems to be kind of our consensus here.
[00:26:30.160 --> 00:26:33.680]   Are we seeing kind of a repeat of the old school Mac versus PC argument from the early
[00:26:33.680 --> 00:26:34.680]   90s?
[00:26:34.680 --> 00:26:39.000]   Like give away most of the market to the cheaper, less quality products and then take over
[00:26:39.000 --> 00:26:42.200]   kind of the niche smaller part of the market, it's more specialized.
[00:26:42.200 --> 00:26:43.200]   iPads are grown.
[00:26:43.200 --> 00:26:44.200]   But I mean.
[00:26:44.200 --> 00:26:50.840]   What I think is that Apple is going by, is reverting to the basic Apple playbook, which
[00:26:50.840 --> 00:26:54.640]   is to, especially with the Mac, they understand that there's no way that they're going to
[00:26:54.640 --> 00:26:56.960]   ever have more than 10 or 12% of the market.
[00:26:56.960 --> 00:27:03.200]   And so their job is to sell Macs and Mac books to that 12% of the people for whom Windows
[00:27:03.200 --> 00:27:07.360]   either doesn't work for them or they don't like them or they were never going to be,
[00:27:07.360 --> 00:27:10.220]   they're not adaptable for Windows anyway.
[00:27:10.220 --> 00:27:14.040]   And make sure that those people who buy those 12% of the people get the best experience
[00:27:14.040 --> 00:27:16.080]   that those 12% possibly can.
[00:27:16.080 --> 00:27:19.600]   So I think that that's where they're going for education now, where they know that they
[00:27:19.600 --> 00:27:22.000]   really can't compete with Chromebooks.
[00:27:22.000 --> 00:27:27.560]   But there is maybe going to be, I don't know, 5%, 6%, 7% of schools that have a place for
[00:27:27.560 --> 00:27:29.480]   iPads in their curriculum.
[00:27:29.480 --> 00:27:34.000]   And let's make sure that those 5%, 6%, 7% will have the best experience possible.
[00:27:34.000 --> 00:27:36.840]   They'll say that there's a reason why we went iPad and not Chromebook.
[00:27:36.840 --> 00:27:38.480]   It's not because they were interchangeable.
[00:27:38.480 --> 00:27:43.560]   It was because we have plans for using computer and education, at least for this track, for
[00:27:43.560 --> 00:27:46.320]   this class, that really couldn't be met by a Chromebook.
[00:27:46.320 --> 00:27:50.080]   So that's why when I saw the immediate response that, oh, well, this is not going to save
[00:27:50.080 --> 00:27:52.040]   Apple's experience and education.
[00:27:52.040 --> 00:27:53.200]   It's not going to matter.
[00:27:53.200 --> 00:27:54.960]   I agree with both of those things.
[00:27:54.960 --> 00:27:55.960]   Yes.
[00:27:55.960 --> 00:27:56.960]   I don't think that was.
[00:27:56.960 --> 00:28:00.480]   I remember that Apple has the minority of phones out there.
[00:28:00.480 --> 00:28:03.840]   They seem to be making a pretty good, junk could change off the iPhone anyway.
[00:28:03.840 --> 00:28:05.080]   So it works for them.
[00:28:05.080 --> 00:28:06.080]   Yeah.
[00:28:06.080 --> 00:28:09.480]   Number two is very profitable, but they did cut the price of the Apple pencil from $99
[00:28:09.480 --> 00:28:11.320]   to $89 for education.
[00:28:11.320 --> 00:28:13.280]   Now that is a hefty discount.
[00:28:13.280 --> 00:28:17.760]   Well, multiply that by 500, multiply it by 1,000 and suddenly, and then translate that
[00:28:17.760 --> 00:28:21.240]   into how many iPads you can now buy with the money you saved.
[00:28:21.240 --> 00:28:26.080]   Really in the people, that's why you also can't complain about the race to the bottom,
[00:28:26.080 --> 00:28:30.360]   so to speak, on Chromebooks that if you can save 10 bucks on a Chromebook, again, when
[00:28:30.360 --> 00:28:35.080]   you're buying 500, 1,000 of these, that means that suddenly 40 kids get Chromebooks that
[00:28:35.080 --> 00:28:36.920]   wouldn't have been able to get them before.
[00:28:36.920 --> 00:28:42.320]   So yeah, but it's the big, the other big thing though is that I'm with the addition of Apple
[00:28:42.320 --> 00:28:49.040]   pencil to this $329 consumer, 32 gigabyte iPad with a modern CPU.
[00:28:49.040 --> 00:28:54.040]   I finally feel as though Apple at least has a credible answer to the question, why doesn't
[00:28:54.040 --> 00:28:58.040]   Apple have any computers for people who are in the budget range?
[00:28:58.040 --> 00:29:02.360]   It's not a replacement for a notebook, but at least you can say it's not nothing.
[00:29:02.360 --> 00:29:08.200]   It's not a water soluble computer thrown together just to make a certain price point.
[00:29:08.200 --> 00:29:12.680]   It's actually a really good computer that gives an experience that $300, $400 Windows
[00:29:12.680 --> 00:29:14.680]   machine or Chromebook can't deliver.
[00:29:14.680 --> 00:29:18.280]   I would still love to see them make a MacBook that is affordable.
[00:29:18.280 --> 00:29:20.840]   I don't think we're ever going to see that, but I'm glad to see that they're bringing
[00:29:20.840 --> 00:29:24.800]   good features to the bottom of the line iPad at least.
[00:29:24.800 --> 00:29:25.800]   I'll take the argument.
[00:29:25.800 --> 00:29:31.200]   I didn't think of the small dollar differential over a multi-unit kind of buy being that important,
[00:29:31.200 --> 00:29:32.200]   but you're right.
[00:29:32.200 --> 00:29:35.320]   So I was being a bit rude, but still a $10 discount, they can be better than that when
[00:29:35.320 --> 00:29:36.320]   I cut it like 20 bucks.
[00:29:36.320 --> 00:29:39.240]   Well, they have the Crayola one, right?
[00:29:39.240 --> 00:29:40.240]   Yeah, the $50.
[00:29:40.240 --> 00:29:42.280]   The logic to the Crayon or whatever it's called.
[00:29:42.280 --> 00:29:43.280]   Do we think that's cool?
[00:29:43.280 --> 00:29:45.960]   Do we think it's going to be useful or is that just kind of like a cheaper?
[00:29:45.960 --> 00:29:50.560]   I mean, yeah, but if you're buying an iPad that can run a pencil and you're not a student,
[00:29:50.560 --> 00:29:52.520]   why would you buy the cheaper one?
[00:29:52.520 --> 00:29:54.000]   Did you get a demo of the Logitech?
[00:29:54.000 --> 00:29:57.480]   Because it is not a full Apple pencil experience.
[00:29:57.480 --> 00:30:01.080]   It's not a full Apple pencil.
[00:30:01.080 --> 00:30:03.000]   It doesn't have pressure sensitivity.
[00:30:03.000 --> 00:30:04.720]   You can't use the side of it.
[00:30:04.720 --> 00:30:05.720]   I don't believe so.
[00:30:05.720 --> 00:30:07.800]   It has one, but not the other.
[00:30:07.800 --> 00:30:12.520]   Also, it really wasn't designed to be used with any other iPad except for this one.
[00:30:12.520 --> 00:30:14.720]   This really was designed to be used with education.
[00:30:14.720 --> 00:30:15.720]   Because it's not Bluetooth.
[00:30:15.720 --> 00:30:16.720]   It's using some.
[00:30:16.720 --> 00:30:17.720]   Right, exactly.
[00:30:17.720 --> 00:30:18.720]   Yeah.
[00:30:18.720 --> 00:30:19.720]   And that's an education requirement.
[00:30:19.720 --> 00:30:21.960]   It's just use and so fried.
[00:30:21.960 --> 00:30:25.680]   That's the same reason why you can't just add a Bluetooth keyboard to an iPad and meet
[00:30:25.680 --> 00:30:28.600]   the requirement that a computer in the school has to have a keyboard.
[00:30:28.600 --> 00:30:32.440]   They really are concerned that if you have Bluetooth active, then kids who are using
[00:30:32.440 --> 00:30:36.280]   these during exams are going to use Bluetooth to swap answers, which would totally have
[00:30:36.280 --> 00:30:38.280]   happened when I was a kid.
[00:30:38.280 --> 00:30:40.360]   We went to the store and got bought those sharp.
[00:30:40.360 --> 00:30:44.680]   I remember from one exam, we actually bought those sharp data bank watches that actually
[00:30:44.680 --> 00:30:48.120]   attached to a keyboard because the store had a 30-day return policy.
[00:30:48.120 --> 00:30:53.280]   So we cleaned out our savings accounts, bought these watches, loaded up the watches with
[00:30:53.280 --> 00:30:55.480]   like all the dates and times of things.
[00:30:55.480 --> 00:30:56.480]   Okay.
[00:30:56.480 --> 00:30:59.320]   Not because only because of the ones you went to a school for weird.
[00:30:59.320 --> 00:31:00.320]   Or awesome.
[00:31:00.320 --> 00:31:01.320]   Yeah.
[00:31:01.320 --> 00:31:04.160]   And we were technology oriented.
[00:31:04.160 --> 00:31:08.440]   And there's a chrome tablet that comes with the stylus.
[00:31:08.440 --> 00:31:09.440]   Yeah.
[00:31:09.440 --> 00:31:10.440]   Yeah.
[00:31:10.440 --> 00:31:11.440]   There are a number of chrome tablets.
[00:31:11.440 --> 00:31:13.640]   The Samsungs come with the stylus.
[00:31:13.640 --> 00:31:15.480]   Of course, the Pixelbook does.
[00:31:15.480 --> 00:31:16.480]   Yeah.
[00:31:16.480 --> 00:31:17.480]   Do the new Acer ones.
[00:31:17.480 --> 00:31:18.480]   Yeah.
[00:31:18.480 --> 00:31:19.480]   Does that new Acer tablet?
[00:31:19.480 --> 00:31:25.000]   The weirdly coincidentally priced 329 Acer Chromebook tablet that comes with the stylus.
[00:31:25.000 --> 00:31:26.000]   And it slides inside.
[00:31:26.000 --> 00:31:27.000]   And it slides inside.
[00:31:27.000 --> 00:31:28.000]   No, I lose.
[00:31:28.000 --> 00:31:29.000]   Yeah.
[00:31:29.000 --> 00:31:31.160]   You don't pay extra for it and it's whack them compatible.
[00:31:31.160 --> 00:31:33.600]   So it's not as though it's a hacked off solution.
[00:31:33.600 --> 00:31:38.440]   I just, I really feel like schools should embrace something more open than the Apple
[00:31:38.440 --> 00:31:39.440]   ecosystem.
[00:31:39.440 --> 00:31:42.320]   I think it's of course sexy and desirable.
[00:31:42.320 --> 00:31:47.120]   And I'm sure a lot of kids would jump for joy that they were getting an iPad.
[00:31:47.120 --> 00:31:50.800]   Although one of the problems the LA Unified School District had is the kids immediately
[00:31:50.800 --> 00:31:52.360]   hacked the iPad.
[00:31:52.360 --> 00:31:54.760]   So now I'm sure Apple has a better system now.
[00:31:54.760 --> 00:32:00.520]   But at the time in 2014, the Apple's had a profile for the kid that would lock it down.
[00:32:00.520 --> 00:32:03.120]   And the kid found out, "You just go on settings and delete the profile."
[00:32:03.120 --> 00:32:04.920]   You could do anything you want.
[00:32:04.920 --> 00:32:06.720]   That is some really weak obstacles.
[00:32:06.720 --> 00:32:07.720]   That's pretty weak.
[00:32:07.720 --> 00:32:08.720]   Even I know that's bad.
[00:32:08.720 --> 00:32:10.280]   I know nothing about security.
[00:32:10.280 --> 00:32:11.280]   Yeah.
[00:32:11.280 --> 00:32:12.640]   So I can understand.
[00:32:12.640 --> 00:32:17.080]   I think, you know, I think the ideal situation, if money weren't an issue, but money obviously
[00:32:17.080 --> 00:32:21.320]   is a huge issue in education, would be to have some iPads and some Chromebooks and have
[00:32:21.320 --> 00:32:22.320]   a variety, right?
[00:32:22.320 --> 00:32:23.320]   Heterogeneous.
[00:32:23.320 --> 00:32:24.320]   Just the dissect frogs.
[00:32:24.320 --> 00:32:25.320]   Yeah.
[00:32:25.320 --> 00:32:26.320]   That's pretty cool.
[00:32:26.320 --> 00:32:27.320]   That's that.
[00:32:27.320 --> 00:32:31.760]   Now see, my question is during the demo, it looked like you could like make the skin
[00:32:31.760 --> 00:32:35.000]   translucent, translucent, make the muscles translucent.
[00:32:35.000 --> 00:32:36.400]   You can see the heart beating.
[00:32:36.400 --> 00:32:40.040]   My question is, are we training these kids to become vivisectionists?
[00:32:40.040 --> 00:32:46.160]   I want to see that dying, beating heart as I peel layers of flesh away from this God's
[00:32:46.160 --> 00:32:47.000]   creature tonight.
[00:32:47.000 --> 00:32:48.000]   I can still have a pallet.
[00:32:48.000 --> 00:32:49.000]   I can still smell the beef.
[00:32:49.000 --> 00:32:50.000]   Oh no, because of the frog.
[00:32:50.000 --> 00:32:59.000]   Yeah, I remember the formaldehyde, but we also had live frogs because one of the experiments,
[00:32:59.000 --> 00:33:01.000]   oh yeah.
[00:33:01.000 --> 00:33:03.640]   Now in hindsight, I'm going, oh my God.
[00:33:03.640 --> 00:33:06.800]   Because one of the experiments was you'd open it up the heart of the beating and then
[00:33:06.800 --> 00:33:12.040]   you'd inject it with a norepinephrine or adrenaline to see how it affected the...
[00:33:12.040 --> 00:33:14.000]   Yeah, we would call that cruel now.
[00:33:14.000 --> 00:33:15.800]   I don't think they would do that.
[00:33:15.800 --> 00:33:17.560]   No, Peter will be all over that.
[00:33:17.560 --> 00:33:20.680]   Also, you're much tougher than I am because when we did that, we had just little squids
[00:33:20.680 --> 00:33:21.680]   that were dead.
[00:33:21.680 --> 00:33:24.160]   We dissected and I was such a was-I had to run out of the ribbon or the vomit because
[00:33:24.160 --> 00:33:25.400]   I couldn't take it.
[00:33:25.400 --> 00:33:29.160]   So I'm glad I didn't get the live frog beating heart injection game.
[00:33:29.160 --> 00:33:30.160]   So I think that would have been...
[00:33:30.160 --> 00:33:33.360]   None of you had the live frog.
[00:33:33.360 --> 00:33:35.120]   Did anybody in the chair have a live frog?
[00:33:35.120 --> 00:33:36.120]   Maybe I'm just...
[00:33:36.120 --> 00:33:37.120]   Maybe this is...
[00:33:37.120 --> 00:33:39.120]   Maybe your science teacher was just a little bit weird.
[00:33:39.120 --> 00:33:41.520]   Maybe you went to the weird kid school.
[00:33:41.520 --> 00:33:42.520]   I think it was me.
[00:33:42.520 --> 00:33:43.520]   It was my school.
[00:33:43.520 --> 00:33:44.520]   It was weird.
[00:33:44.520 --> 00:33:48.480]   So we're going to have a field trip to St. Sebastian's Cemetery.
[00:33:48.480 --> 00:33:49.480]   There's been a recent funeral.
[00:33:49.480 --> 00:33:53.080]   I'm going to need nine of you that can lift, two that can dig.
[00:33:53.080 --> 00:33:56.400]   And there will be no permission slips because we're not going to be telling your parents
[00:33:56.400 --> 00:33:57.400]   what we're doing.
[00:33:57.400 --> 00:34:00.160]   And we're looking for brains from someone named Abby Normal.
[00:34:00.160 --> 00:34:02.720]   See if you can find that one.
[00:34:02.720 --> 00:34:07.320]   Our chatroom, Senior Gravy in our chatroom says, "My local district had white MacBooks.
[00:34:07.320 --> 00:34:10.640]   The IT called them mobile porn studios."
[00:34:10.640 --> 00:34:12.600]   There you go.
[00:34:12.600 --> 00:34:13.600]   That's what we needed for.
[00:34:13.600 --> 00:34:17.000]   We're going to take a little break, come back with more.
[00:34:17.000 --> 00:34:22.080]   Our esteemed panel, Alex Wilhelm from Crunchbase News, Editor in Chief there.
[00:34:22.080 --> 00:34:28.120]   His title belies his youth, but you are a dignified, good-looking fella.
[00:34:28.120 --> 00:34:29.120]   Well, that's kind.
[00:34:29.120 --> 00:34:30.560]   I'm going to say nothing about that.
[00:34:30.560 --> 00:34:31.560]   Nothing.
[00:34:31.560 --> 00:34:32.560]   Say nothing.
[00:34:32.560 --> 00:34:33.560]   Say nothing.
[00:34:33.560 --> 00:34:34.560]   Also, brand new and great to have him.
[00:34:34.560 --> 00:34:36.560]   Wesley Faulkner from Austin, Texas.
[00:34:36.560 --> 00:34:39.840]   He's marketing manager at FSG at Wesley 83.
[00:34:39.840 --> 00:34:40.840]   Is that when you...
[00:34:40.840 --> 00:34:41.840]   That's your Twitter handle.
[00:34:41.840 --> 00:34:42.840]   Is that what you...
[00:34:42.840 --> 00:34:44.760]   The 83 stands for.
[00:34:44.760 --> 00:34:46.160]   It's not when you were born.
[00:34:46.160 --> 00:34:47.160]   Nope.
[00:34:47.160 --> 00:34:48.000]   Man have mis-
[00:34:48.000 --> 00:34:49.000]   Graduated from high school.
[00:34:49.000 --> 00:34:50.000]   All right.
[00:34:50.000 --> 00:34:51.160]   He's not going to say anything, is he?
[00:34:51.160 --> 00:34:52.160]   Football number?
[00:34:52.160 --> 00:34:53.160]   Football number.
[00:34:53.160 --> 00:34:54.160]   Nope.
[00:34:54.160 --> 00:34:55.160]   Oh.
[00:34:55.160 --> 00:34:58.520]   And Annie and I go and I who have no football number.
[00:34:58.520 --> 00:35:02.160]   Annie and I go, "Of course, I'm a Chicago..."
[00:35:02.160 --> 00:35:07.000]   Oh, I said it from celestial waste of bandwidth.
[00:35:07.000 --> 00:35:08.560]   Veteran technology journalist.
[00:35:08.560 --> 00:35:12.000]   Veteran technology journalist.
[00:35:12.000 --> 00:35:15.680]   So your piece on that event, by the way, was in Fast Company this week.
[00:35:15.680 --> 00:35:16.680]   Yep.
[00:35:16.680 --> 00:35:18.280]   So let's all point him there.
[00:35:18.280 --> 00:35:19.840]   Can I say from Fast Company?
[00:35:19.840 --> 00:35:25.920]   No, I haven't settled on a forever home yet, but I've hopefully used more stuff about that.
[00:35:25.920 --> 00:35:26.920]   Oh, life.
[00:35:26.920 --> 00:35:27.920]   Oh, life.
[00:35:27.920 --> 00:35:28.920]   Journey.
[00:35:28.920 --> 00:35:31.120]   They informed me I did not stink up the jogging so much as I really did.
[00:35:31.120 --> 00:35:32.120]   No, it was really good.
[00:35:32.120 --> 00:35:33.120]   I liked it.
[00:35:33.120 --> 00:35:37.400]   I thought it was even-handed, well-fought-out and as always well-written.
[00:35:37.400 --> 00:35:43.800]   And I like it that they, Fast Company, very kindly put next to your byline, "Long read."
[00:35:43.800 --> 00:35:46.680]   Is that a warning?
[00:35:46.680 --> 00:35:49.560]   This is a long one, folks.
[00:35:49.560 --> 00:35:54.840]   Hey, I will happily take that as my middle name, like sort of, "Hash" name.
[00:35:54.840 --> 00:35:57.040]   Andy Long-Reed and I go.
[00:35:57.040 --> 00:35:59.040]   Andy Long-Reed and I go in the house.
[00:35:59.040 --> 00:36:01.120]   I'll show you today brought to you by my friends.
[00:36:01.120 --> 00:36:03.440]   Actually, they're going to be in the house next week, I think.
[00:36:03.440 --> 00:36:06.200]   The Tim and Don from ITProTV.
[00:36:06.200 --> 00:36:07.200]   Love these guys.
[00:36:07.200 --> 00:36:09.640]   They came to me some years ago.
[00:36:09.640 --> 00:36:14.680]   They were IT trainers and they had been at a panel I was on at NAB in which I'm kind
[00:36:14.680 --> 00:36:18.560]   of promoting the idea of Twit and what we do and there should be lots of niche, you
[00:36:18.560 --> 00:36:22.360]   know, internet based basically TV stations.
[00:36:22.360 --> 00:36:27.400]   And they came up and said, "Would you mind if we basically did what you do for IT training?"
[00:36:27.400 --> 00:36:28.400]   I said, "Mind."
[00:36:28.400 --> 00:36:29.400]   I think that'd be awesome.
[00:36:29.400 --> 00:36:38.600]   ITProTV was born and man, as an effective, now 90,000 members strong, not just individuals.
[00:36:38.600 --> 00:36:40.640]   A lot of teams as well.
[00:36:40.640 --> 00:36:44.480]   I know the Harvard IT department signed up for ITProTV.
[00:36:44.480 --> 00:36:48.560]   It's great if you're not yet in IT, but you want to take the tests, get the certs and
[00:36:48.560 --> 00:36:52.880]   get that first job in IT and that's kind of the initial idea of it.
[00:36:52.880 --> 00:36:57.240]   But it also is a great way to keep your skills up to date, to add new skills, to get new
[00:36:57.240 --> 00:37:03.720]   certs and man, do they have a lot of content, 3300 hours of on-demand content and they're
[00:37:03.720 --> 00:37:05.120]   always making more.
[00:37:05.120 --> 00:37:07.600]   They have five studios now.
[00:37:07.600 --> 00:37:10.520]   They're doing 125 new hours every single week.
[00:37:10.520 --> 00:37:13.600]   They do much as you can see in the video if you're watching it, much as we do.
[00:37:13.600 --> 00:37:19.480]   They have really cool looking studios, great teachers and presenters and a chat room going
[00:37:19.480 --> 00:37:23.800]   at the same time so you can interact with the teachers as they're giving the courses.
[00:37:23.800 --> 00:37:25.160]   There's Don.
[00:37:25.160 --> 00:37:28.600]   And it's really a great training class.
[00:37:28.600 --> 00:37:35.920]   From CompTIA to Cisco to AWS, even things like Cali Linux and Certified Ethical Hacker,
[00:37:35.920 --> 00:37:39.040]   they have you covered.
[00:37:39.040 --> 00:37:40.320]   This is a great field to get into.
[00:37:40.320 --> 00:37:42.920]   If you're listening to the show, I know you're in the tech.
[00:37:42.920 --> 00:37:47.000]   If you're thinking about a career change, did you know there are 1 million open jobs
[00:37:47.000 --> 00:37:49.760]   in security and IT security right now?
[00:37:49.760 --> 00:37:54.800]   Right now, awaiting for somebody, get the certs, get the skills, get the job.
[00:37:54.800 --> 00:37:57.680]   You can watch ITPro TV on anything you've got.
[00:37:57.680 --> 00:38:01.120]   They've got Roku, Apple TV, Fire TV apps.
[00:38:01.120 --> 00:38:02.880]   They've got Android apps, iOS apps.
[00:38:02.880 --> 00:38:04.520]   You can watch on a Chromecast.
[00:38:04.520 --> 00:38:07.160]   You can even download courses for on-the-go learning.
[00:38:07.160 --> 00:38:11.840]   This is not one of those boring voiceover slides, snooze fest.
[00:38:11.840 --> 00:38:17.680]   This is engaging, interactive IT training, your team and you will actually enjoy watching.
[00:38:17.680 --> 00:38:19.760]   And by the way, if you have a team, the team portal is great.
[00:38:19.760 --> 00:38:22.560]   You get control over the schedule and you can track results.
[00:38:22.560 --> 00:38:27.440]   You can see metrics like logins, viewing time, courses viewed, tracks completed.
[00:38:27.440 --> 00:38:30.520]   If you're looking for a more engaging way to keep your team up to date or you want to
[00:38:30.520 --> 00:38:33.520]   accelerate your career, ITPro TV.
[00:38:33.520 --> 00:38:37.160]   Go to itpro.tv/twit.
[00:38:37.160 --> 00:38:40.680]   You can learn more about the team solution and request a free team trial.
[00:38:40.680 --> 00:38:43.600]   And of course, there's individual monthly memberships.
[00:38:43.600 --> 00:38:49.320]   If you want to try it as an individual, go to itpro.tv/twit and use the offer code TWIT30.
[00:38:49.320 --> 00:38:53.640]   You can see there the blue button start my free trial and you get seven days to try it unlimited
[00:38:53.640 --> 00:38:56.320]   access to the site, all the features.
[00:38:56.320 --> 00:39:01.040]   And if you decide to subscribe 30% off your subscription for as long as you stay active,
[00:39:01.040 --> 00:39:05.000]   forever in other words, as long as you're still active and you probably will stay active
[00:39:05.000 --> 00:39:09.440]   because even when you get that perfect job, you're going to want to add skills.
[00:39:09.440 --> 00:39:12.840]   A premium, just to give you a sense, a premium subscription and that's the top of the line
[00:39:12.840 --> 00:39:15.760]   that includes the Trans Cender Practice Exams.
[00:39:15.760 --> 00:39:18.080]   That's worth, I think, 90 bucks by itself.
[00:39:18.080 --> 00:39:23.520]   The virtual labs, which means you don't have to have, say, Windows Server 2019 is coming
[00:39:23.520 --> 00:39:24.520]   out, right?
[00:39:24.520 --> 00:39:25.520]   You don't have to have it.
[00:39:25.520 --> 00:39:29.120]   All you need is an HTML5 browser and you could set up the server, set up the clients.
[00:39:29.120 --> 00:39:34.280]   I like that because when I screw things up and I always do, I just close the browser window
[00:39:34.280 --> 00:39:38.320]   and no one will know, no harm, no foul.
[00:39:38.320 --> 00:39:41.960]   Premium subscriptions include the virtual labs, the Trans Cender Practice Exams.
[00:39:41.960 --> 00:39:45.680]   Normally that'd be $857 a year, which I still think is a great price.
[00:39:45.680 --> 00:39:52.200]   But use the offer code TWIT $30, $600 a year, $50 a month.
[00:39:52.200 --> 00:39:55.600]   That's cheaper than buying the materials let alone and going to a technical school.
[00:39:55.600 --> 00:39:56.840]   This is better.
[00:39:56.840 --> 00:40:05.240]   Flexible training, binge-worthy content, ROI-proven, itpro.tv/twit, use the offer code TWIT $30
[00:40:05.240 --> 00:40:14.640]   and join the 90,000 folks now learning to be IT professionals at ITPro.tv.
[00:40:14.640 --> 00:40:22.520]   When we go with the show, let's see, we did April Fool's Day, we did Apple's event.
[00:40:22.520 --> 00:40:23.880]   I thought it was kind of interesting.
[00:40:23.880 --> 00:40:25.400]   I don't know if I have this article.
[00:40:25.400 --> 00:40:31.000]   I saw that the FBI, remember that San Bernardino shooter with the FBI went to Apple, said unlock
[00:40:31.000 --> 00:40:32.000]   the phone.
[00:40:32.000 --> 00:40:36.920]   It might have been an internysing battle going on because one division of the FBI said,
[00:40:36.920 --> 00:40:38.200]   "Oh yeah, we could unlock it."
[00:40:38.200 --> 00:40:41.000]   But they just never told the other division.
[00:40:41.000 --> 00:40:47.360]   The FBI sued Apple to unlock phone, says, "Tech Crunch," without considering all the
[00:40:47.360 --> 00:40:48.360]   options.
[00:40:48.360 --> 00:40:54.120]   Apparently, it really was more about getting the word out and getting some heat on Apple
[00:40:54.120 --> 00:40:55.720]   than actually unlocking that phone.
[00:40:55.720 --> 00:40:57.720]   We thought it might have been the case, right?
[00:40:57.720 --> 00:40:58.720]   I would do the same when you...
[00:40:58.720 --> 00:41:00.560]   Oh, can you turn on Wesley's mic?
[00:41:00.560 --> 00:41:01.560]   Oh.
[00:41:01.560 --> 00:41:02.560]   There you go.
[00:41:02.560 --> 00:41:03.560]   Hello?
[00:41:03.560 --> 00:41:04.560]   I said I would do the same thing too.
[00:41:04.560 --> 00:41:05.560]   Wait a minute.
[00:41:05.560 --> 00:41:10.160]   If I was in their position, if I could add another tool to my toolbox, why not?
[00:41:10.160 --> 00:41:11.160]   Why not do it?
[00:41:11.160 --> 00:41:12.160]   Why not, Sue?
[00:41:12.160 --> 00:41:13.160]   But they made a big stick about this.
[00:41:13.160 --> 00:41:14.160]   They had to have it.
[00:41:14.160 --> 00:41:15.920]   It was national security and all of this.
[00:41:15.920 --> 00:41:16.920]   Come on.
[00:41:16.920 --> 00:41:20.160]   Well, they can't tell me that and tell me that and then have it be a lie and expect
[00:41:20.160 --> 00:41:21.920]   me to really believe you the next time.
[00:41:21.920 --> 00:41:23.400]   It needs bad for the FBI.
[00:41:23.400 --> 00:41:25.960]   The FBI needs to be credible, right?
[00:41:25.960 --> 00:41:28.320]   It was plausible to not have built it, right?
[00:41:28.320 --> 00:41:30.520]   This was from the office of the inspector general.
[00:41:30.520 --> 00:41:34.360]   This is an investigation of the FBI.
[00:41:34.360 --> 00:41:37.840]   So it's not like some, you know, journalist dug it up.
[00:41:37.840 --> 00:41:38.840]   No, the Elijah.
[00:41:38.840 --> 00:41:42.520]   I hear they're plugged into what's going on over there.
[00:41:42.520 --> 00:41:48.840]   So yeah, I think this is a bad thing to do to hit an agenda as opposed to a real need.
[00:41:48.840 --> 00:41:49.840]   You're right.
[00:41:49.840 --> 00:41:50.840]   You're right.
[00:41:50.840 --> 00:41:51.840]   It's a tactical point of view.
[00:41:51.840 --> 00:41:53.840]   And it only came out because they lost, right?
[00:41:53.840 --> 00:41:54.840]   It's not encouraging.
[00:41:54.840 --> 00:41:55.840]   It was just like if they...
[00:41:55.840 --> 00:41:57.840]   You wouldn't have known if I hadn't lost.
[00:41:57.840 --> 00:41:59.480]   I would have gone away with it too.
[00:41:59.480 --> 00:42:01.280]   It wasn't for your meddling kids.
[00:42:01.280 --> 00:42:02.280]   They just gambled.
[00:42:02.280 --> 00:42:04.920]   They thought it's a really good upside, really big upside.
[00:42:04.920 --> 00:42:05.920]   It's a perfect case.
[00:42:05.920 --> 00:42:06.920]   It's terrorists.
[00:42:06.920 --> 00:42:07.920]   Why would you do it?
[00:42:07.920 --> 00:42:10.440]   You know, truthfully, Wesley, we even knew that was happening.
[00:42:10.440 --> 00:42:11.440]   Yeah.
[00:42:11.440 --> 00:42:12.440]   We were saying...
[00:42:12.440 --> 00:42:14.680]   I mean, there was no way this was the one time they absolutely had to have access.
[00:42:14.680 --> 00:42:16.280]   But Andy, you were saying something.
[00:42:16.280 --> 00:42:19.000]   No, no, I was going to say they really want this precedent.
[00:42:19.000 --> 00:42:20.960]   They really want this to be tried in court.
[00:42:20.960 --> 00:42:24.720]   They really want to judge to say that the FBI has a right to...
[00:42:24.720 --> 00:42:29.520]   Excuse me, that the makers of technology have an obligation to break through encryption.
[00:42:29.520 --> 00:42:34.400]   At the same time this came out, the FBI was once again, again, throwing their shorts
[00:42:34.400 --> 00:42:41.200]   on fire about how important it is that this is a dark moment for law enforcement because
[00:42:41.200 --> 00:42:45.000]   Google and Facebook and Apple, and they're all in cahoots with criminals and allowing
[00:42:45.000 --> 00:42:47.440]   them to continue to do their jobs.
[00:42:47.440 --> 00:42:53.960]   They're also citing things that turned out to be really just research from certain people
[00:42:53.960 --> 00:42:59.440]   who are saying that there is a way to do some sort of a backdoor that would be only a disaster,
[00:42:59.440 --> 00:43:02.200]   not a complete but are unmitigated disaster.
[00:43:02.200 --> 00:43:07.240]   Or there's other researchers that are saying there might be a way that you could put a
[00:43:07.240 --> 00:43:15.320]   backdoor encryption on live communications like live chat, texting, video streaming,
[00:43:15.320 --> 00:43:20.040]   but you could have a different sort of encryption on file encryption so that you could protect
[00:43:20.040 --> 00:43:21.720]   one but not the other.
[00:43:21.720 --> 00:43:26.200]   But that once again really shows you, they are going to keep at this and they're going
[00:43:26.200 --> 00:43:29.520]   to keep you at this until they get a judge to say those magic words.
[00:43:29.520 --> 00:43:36.560]   You are commanded by the federal judge to help the FBI crack open this phone and then
[00:43:36.560 --> 00:43:37.560]   God help us all.
[00:43:37.560 --> 00:43:40.760]   Well, right, because every single person that I know who works in security actually knows
[00:43:40.760 --> 00:43:44.080]   anything about this says you cannot create a magical backdoor that only the FBI can
[00:43:44.080 --> 00:43:45.080]   open.
[00:43:45.080 --> 00:43:46.080]   It is a weakness.
[00:43:46.080 --> 00:43:47.080]   What about?
[00:43:47.080 --> 00:43:48.080]   Okay.
[00:43:48.080 --> 00:43:50.240]   So there and we talked about this last week but not with you guys.
[00:43:50.240 --> 00:43:51.600]   So I'll bring it up again.
[00:43:51.600 --> 00:43:54.800]   There was a National Academy of Sciences panel.
[00:43:54.800 --> 00:44:00.240]   Ray Aussie was on it, former chief software architect at Microsoft, Stephen Savage.
[00:44:00.240 --> 00:44:02.240]   I'm going to call it that because that's a good name.
[00:44:02.240 --> 00:44:04.200]   It could be Savage.
[00:44:04.200 --> 00:44:12.360]   Savage, computer science professor at UC San Diego, Ernie Brekel, former CSO at Intel.
[00:44:12.360 --> 00:44:17.440]   And they proposed that it might be, what if, what if, here's that question for you guys.
[00:44:17.440 --> 00:44:24.480]   What if there were a way to create a secure enclave on a phone that had a key that Apple
[00:44:24.480 --> 00:44:28.000]   let's say could unlock that would only unlock that phone.
[00:44:28.000 --> 00:44:31.360]   So the law enforcement goes to Apple says we want this phone unlocked.
[00:44:31.360 --> 00:44:36.200]   It would not extend to Wesley's phone or your phone or anybody else's.
[00:44:36.200 --> 00:44:38.120]   It would just do the bad guys phone.
[00:44:38.120 --> 00:44:39.120]   What if we could do that?
[00:44:39.120 --> 00:44:40.120]   Wouldn't that be?
[00:44:40.120 --> 00:44:41.120]   I'd still be against it.
[00:44:41.120 --> 00:44:44.920]   Like a hardware access only like physical access.
[00:44:44.920 --> 00:44:45.920]   Yeah.
[00:44:45.920 --> 00:44:46.920]   Well, let's, okay.
[00:44:46.920 --> 00:44:51.440]   So yeah, presumably they have access to the phone because you have to have access to get
[00:44:51.440 --> 00:44:52.800]   the enclave opened up.
[00:44:52.800 --> 00:44:55.200]   So Apple, so it's a double key.
[00:44:55.200 --> 00:45:01.080]   Imagine a safe and there's a box, a strong box outside the safe that has a key in it.
[00:45:01.080 --> 00:45:03.400]   Only Apple has the key to that key.
[00:45:03.400 --> 00:45:06.400]   That key unlocks just that safe.
[00:45:06.400 --> 00:45:11.480]   Apple upon being provided with a appropriate process.
[00:45:11.480 --> 00:45:16.080]   Now that may be an issue too after the cloud act, but let's set that aside.
[00:45:16.080 --> 00:45:20.920]   Apple was being provided with a appropriate warrant says, okay, we're going to unlock
[00:45:20.920 --> 00:45:22.320]   that box here law enforcement.
[00:45:22.320 --> 00:45:25.600]   This is the key, but it's not as we have been concerned about the key to all the phones.
[00:45:25.600 --> 00:45:27.240]   It's just the key to this phone.
[00:45:27.240 --> 00:45:29.600]   But then China, Russia, that's the problem.
[00:45:29.600 --> 00:45:32.040]   I was going to say, you build this for the US government.
[00:45:32.040 --> 00:45:35.320]   You have to build it for everybody and therefore no Apple device is going to work and be safe
[00:45:35.320 --> 00:45:38.400]   anywhere in the world that messes with journalists, activists, dissidents.
[00:45:38.400 --> 00:45:40.320]   And we have the cloud act now.
[00:45:40.320 --> 00:45:42.960]   Yeah, which is the law, which is bad.
[00:45:42.960 --> 00:45:43.960]   Yeah.
[00:45:43.960 --> 00:45:48.440]   And the bad people will still find a better, will basically use just illegal encryption
[00:45:48.440 --> 00:45:49.720]   to get their job done.
[00:45:49.720 --> 00:45:51.800]   For me though, it's a much bigger thing.
[00:45:51.800 --> 00:45:56.720]   I think that this is a foundational principle that we've never, at least in this country,
[00:45:56.720 --> 00:46:00.440]   in 200 and some odd years, we have never had to answer this question before because
[00:46:00.440 --> 00:46:04.880]   it's never been possible to have a real secret from the government before that that's been
[00:46:04.880 --> 00:46:05.880]   written down.
[00:46:05.880 --> 00:46:08.920]   Do you have the right to have a secret from the government?
[00:46:08.920 --> 00:46:09.920]   Yes.
[00:46:09.920 --> 00:46:10.920]   Yeah.
[00:46:10.920 --> 00:46:16.080]   And so everything, all laws preceding this are based on if you put it in a safe, then
[00:46:16.080 --> 00:46:17.440]   we can blow up the safe and get it.
[00:46:17.440 --> 00:46:18.880]   So we're going to let you put it in the safe.
[00:46:18.880 --> 00:46:23.480]   Or we're going to let you shred it because we can put that back together again.
[00:46:23.480 --> 00:46:27.520]   We will not stop you from trying to secure or destroy your data now.
[00:46:27.520 --> 00:46:33.560]   But if there's a way for me to encrypt my data such that law enforcement cannot get
[00:46:33.560 --> 00:46:39.080]   it for me when the FBI says that this should not be allowed to me.
[00:46:39.080 --> 00:46:46.000]   And I'm not saying this in a stock piling toilet paper and canned goods in a shack in
[00:46:46.000 --> 00:46:47.000]   the woods way.
[00:46:47.000 --> 00:46:51.080]   I feel as though this is overreach from the government.
[00:46:51.080 --> 00:46:55.680]   I feel as though I have the right to have a secret that the government cannot get if
[00:46:55.680 --> 00:46:57.800]   I choose to protect it in that fashion.
[00:46:57.800 --> 00:46:59.480]   It doesn't matter what that secret is.
[00:46:59.480 --> 00:47:05.960]   So that's why in addition to all the far more simple reasons that again, if you have if
[00:47:05.960 --> 00:47:10.120]   you think that only the good guys are going to be able to get at this data, you're wrong,
[00:47:10.120 --> 00:47:11.800]   it just will fail eventually.
[00:47:11.800 --> 00:47:16.120]   I just think that it's a basic right that if I want to lock something up so that I can
[00:47:16.120 --> 00:47:19.280]   have a secret that the government cannot get, that's a basic right.
[00:47:19.280 --> 00:47:20.520]   It's scary to me.
[00:47:20.520 --> 00:47:23.760]   If the government say you're not allowed to write something down that we can't read,
[00:47:23.760 --> 00:47:24.920]   that's bad.
[00:47:24.920 --> 00:47:27.760]   We have a right to privacy as interpreted by the Supreme Court.
[00:47:27.760 --> 00:47:29.760]   It's a very important bit of our kind of court law.
[00:47:29.760 --> 00:47:30.760]   And I think we should respect that.
[00:47:30.760 --> 00:47:32.560]   Not in the Constitution, but it is.
[00:47:32.560 --> 00:47:34.320]   It was read from the Constitution.
[00:47:34.320 --> 00:47:35.320]   Right.
[00:47:35.320 --> 00:47:37.040]   It's not an exact phrase.
[00:47:37.040 --> 00:47:40.960]   But also if you read back to 1984, I know everyone's favorite example of this, you cannot
[00:47:40.960 --> 00:47:44.440]   even in your apartment, Winston can't actually get away from the screen that can see him.
[00:47:44.440 --> 00:47:46.680]   And that's that constant feeling of being watched.
[00:47:46.680 --> 00:47:47.680]   I think you're right.
[00:47:47.680 --> 00:47:50.600]   If you don't have the ability to put something away yourself, nothing feels secure.
[00:47:50.600 --> 00:47:51.960]   You go definitely act differently.
[00:47:51.960 --> 00:47:53.840]   It's poisonous and it's anti-democratic.
[00:47:53.840 --> 00:47:54.840]   It's bad.
[00:47:54.840 --> 00:47:57.080]   It's also the Panopticon, right?
[00:47:57.080 --> 00:47:58.080]   Yeah.
[00:47:58.080 --> 00:48:03.320]   And that's, I mean, the Panopticon was this 19th century conception that you could build
[00:48:03.320 --> 00:48:08.640]   a prison where prisoners wouldn't know whether they're being observed or not, but they could
[00:48:08.640 --> 00:48:12.240]   assume that at some point they were being observed.
[00:48:12.240 --> 00:48:15.800]   And so they acted as if they were always being observed.
[00:48:15.800 --> 00:48:20.320]   And in the mind of the jailers, that meant that they would always behave.
[00:48:20.320 --> 00:48:24.880]   But of course, as we know, that's not how it works out when it happens.
[00:48:24.880 --> 00:48:25.960]   No.
[00:48:25.960 --> 00:48:30.040]   But I think a lot of us maybe watching right now are not as full of confidence in our
[00:48:30.040 --> 00:48:33.240]   government as we have been in recent half decades, say.
[00:48:33.240 --> 00:48:36.800]   And so the idea of giving out these tools to, I don't know, even our own government right
[00:48:36.800 --> 00:48:40.040]   now seems very terrifying, let alone in the foreign government example.
[00:48:40.040 --> 00:48:45.720]   By the way, just a side note, not really related, but the guy who conceived of the Panopticon,
[00:48:45.720 --> 00:48:49.120]   Jeremy Bentham, you can see him stuffed in New York right now.
[00:48:49.120 --> 00:48:50.120]   Yeah.
[00:48:50.120 --> 00:48:51.120]   His body stuffed.
[00:48:51.120 --> 00:48:52.120]   Yeah.
[00:48:52.120 --> 00:48:53.120]   They let him travel.
[00:48:53.120 --> 00:48:56.960]   He's normally in the cabinet in his alma mater.
[00:48:56.960 --> 00:48:57.960]   Yeah.
[00:48:57.960 --> 00:48:58.960]   It came right there somewhere.
[00:48:58.960 --> 00:49:02.040]   But it's the head traveling with them too or just the whole thing.
[00:49:02.040 --> 00:49:03.040]   So we just went in.
[00:49:03.040 --> 00:49:07.560]   It's kind of bringing out once a year and like, "Ah, Bentham, here it is."
[00:49:07.560 --> 00:49:12.040]   It's just, I think it's just his bones inside a case.
[00:49:12.040 --> 00:49:13.040]   I'm not sure.
[00:49:13.040 --> 00:49:14.880]   This is very weird.
[00:49:14.880 --> 00:49:19.520]   He decided, he was a philosopher and he decided that he wanted to be stuffed and mounted so
[00:49:19.520 --> 00:49:22.840]   that his friends could still see him kind of in a funny way.
[00:49:22.840 --> 00:49:24.360]   He actually was friends.
[00:49:24.360 --> 00:49:27.080]   He was planning, he was planning this throughout his whole life as a matter of fact.
[00:49:27.080 --> 00:49:30.440]   He had like the eyes for, that would be, of course, you know, the eyes are going to
[00:49:30.440 --> 00:49:32.960]   go nuts, go crazy in the head after he dies.
[00:49:32.960 --> 00:49:35.960]   But he had glass eyes made, used to carry them around with them and show them these
[00:49:35.960 --> 00:49:37.560]   are going to be my eyes after I die.
[00:49:37.560 --> 00:49:38.560]   Yeah.
[00:49:38.560 --> 00:49:41.720]   And this is why he told you that philosophers are not really kind of dinner party invites.
[00:49:41.720 --> 00:49:42.880]   That's why they don't go outside.
[00:49:42.880 --> 00:49:44.440]   It's a university college London.
[00:49:44.440 --> 00:49:45.960]   There's a, there's Germany in his case.
[00:49:45.960 --> 00:49:47.800]   But it is in New York now.
[00:49:47.800 --> 00:49:53.480]   Here is an exhibit at the, I think this is a museum of modern art.
[00:49:53.480 --> 00:49:54.880]   And he's part of that exhibit.
[00:49:54.880 --> 00:49:56.640]   That's the worst thing I've seen all day.
[00:49:56.640 --> 00:49:58.280]   That's what he thought.
[00:49:58.280 --> 00:50:00.360]   Well, you know, you know how they, they could get him in.
[00:50:00.360 --> 00:50:04.040]   He didn't have any social media footprint that the audience, Dan, that's good job.
[00:50:04.040 --> 00:50:05.800]   Oh, let's talk about that.
[00:50:05.800 --> 00:50:08.880]   You want to talk about government overreach.
[00:50:08.880 --> 00:50:14.120]   This was entered into the federal register this week.
[00:50:14.120 --> 00:50:18.840]   So it's not yet the rule of the land, but I think this is, I, I'm not a lawyer.
[00:50:18.840 --> 00:50:23.880]   I'm not sure what the rules are, but I think this is the first step to making it a rule
[00:50:23.880 --> 00:50:25.440]   of the land.
[00:50:25.440 --> 00:50:32.760]   Customs and Border Patrol is going to ask any, let me see if I can find the notice.
[00:50:32.760 --> 00:50:33.760]   These applicants.
[00:50:33.760 --> 00:50:34.760]   Any visa applicants.
[00:50:34.760 --> 00:50:36.880]   This is even a victorious visa.
[00:50:36.880 --> 00:50:37.880]   This is not just to live here.
[00:50:37.880 --> 00:50:41.960]   A permanent residency, but this is just somebody who wants to visit.
[00:50:41.960 --> 00:50:46.680]   Would be required to hand over five years worth of social media postings.
[00:50:46.680 --> 00:50:47.680]   Well, their accounts.
[00:50:47.680 --> 00:50:48.680]   Well, their accounts.
[00:50:48.680 --> 00:50:52.560]   I got identifiers, phone numbers they've used in the past five years.
[00:50:52.560 --> 00:50:57.040]   I was pleased to see that doesn't include passwords so they can check your private messages.
[00:50:57.040 --> 00:50:58.040]   Even so, okay.
[00:50:58.040 --> 00:51:01.720]   Well, you're assuming, you're assuming they can't with warrants and subpoenas and.
[00:51:01.720 --> 00:51:06.600]   I mean, that would be, on a per you couldn't do that for every single person.
[00:51:06.600 --> 00:51:07.600]   That'd be too much work.
[00:51:07.600 --> 00:51:11.520]   You couldn't get subpoenaed for each one, but the online application for a non-immigrant
[00:51:11.520 --> 00:51:18.160]   visa would include, and by the way, it's submitted electronically over an encrypted connection,
[00:51:18.160 --> 00:51:27.520]   by the way, so the applicant will be instructed to provide social media information.
[00:51:27.520 --> 00:51:34.880]   Their accounts, email addresses and phone numbers used over the past five years.
[00:51:34.880 --> 00:51:38.240]   Whether the applicant's been deported or removed from any country, whether specified family
[00:51:38.240 --> 00:51:42.280]   members have been involved in terrorist activities, all that I understand, but really they need
[00:51:42.280 --> 00:51:43.280]   the tweets.
[00:51:43.280 --> 00:51:45.960]   They need all the tweets.
[00:51:45.960 --> 00:51:48.960]   And that is going to be, you said you saw Chris Sade.
[00:51:48.960 --> 00:51:49.960]   Yes.
[00:51:49.960 --> 00:51:50.960]   Or you talk to him.
[00:51:50.960 --> 00:51:51.960]   Yeah.
[00:51:51.960 --> 00:51:55.360]   He's in Australia, former head of product at Uber.
[00:51:55.360 --> 00:51:57.560]   He's back down in his home country.
[00:51:57.560 --> 00:51:58.560]   But what was his reaction?
[00:51:58.560 --> 00:52:02.920]   He said, I won't be in the US for a while, which also makes sense because you're not
[00:52:02.920 --> 00:52:06.480]   just making, they're not just looking at your profile when you give an account.
[00:52:06.480 --> 00:52:10.160]   They look at every profile you've ever associated with.
[00:52:10.160 --> 00:52:15.240]   And what if you're a third degree connected to a terrorist, you wouldn't necessarily know?
[00:52:15.240 --> 00:52:18.960]   Well, and by the way, if you were a terrorist, would you be tweeting?
[00:52:18.960 --> 00:52:21.720]   I can't wait to come to the US and blow things up.
[00:52:21.720 --> 00:52:22.720]   Maybe in your DMs.
[00:52:22.720 --> 00:52:24.840]   DMs, now they don't get access to those.
[00:52:24.840 --> 00:52:26.920]   No, they have access to your username.
[00:52:26.920 --> 00:52:29.720]   Who knows if they go to Twitter.
[00:52:29.720 --> 00:52:37.080]   If there is this deep vetting that's supposed to be coming through for certain countries,
[00:52:37.080 --> 00:52:40.200]   they might have a blanket, say they're not American citizens.
[00:52:40.200 --> 00:52:41.200]   Right.
[00:52:41.200 --> 00:52:43.720]   They don't have the same protections.
[00:52:43.720 --> 00:52:47.200]   This would affect 14 million visa applications a year.
[00:52:47.200 --> 00:52:48.200]   That's insane.
[00:52:48.200 --> 00:52:49.200]   Yeah.
[00:52:49.200 --> 00:52:50.200]   And it would take time.
[00:52:50.200 --> 00:52:51.200]   I don't know if it makes it safer.
[00:52:51.200 --> 00:52:52.200]   That's the real question.
[00:52:52.200 --> 00:52:56.400]   I don't remember my base username.
[00:52:56.400 --> 00:52:58.320]   I mean, I don't think they want that one.
[00:52:58.320 --> 00:52:59.320]   I just--
[00:52:59.320 --> 00:53:00.320]   I have five years any accounts that--
[00:53:00.320 --> 00:53:01.320]   Oh, geez.
[00:53:01.320 --> 00:53:02.320]   I wouldn't even know all the sites I've joined for a day.
[00:53:02.320 --> 00:53:07.160]   But I just deleted about two months ago, like all my tweets.
[00:53:07.160 --> 00:53:08.160]   Really?
[00:53:08.160 --> 00:53:09.160]   Yeah.
[00:53:09.160 --> 00:53:10.640]   Well, I was on Twitter since I was 17.
[00:53:10.640 --> 00:53:12.560]   And I didn't want those following me around for life.
[00:53:12.560 --> 00:53:14.040]   I can see a thousand and eight hours.
[00:53:14.040 --> 00:53:16.040]   The zero button that you can push that says to delete all your tweets.
[00:53:16.040 --> 00:53:19.200]   There's an app called Heck Tweeter's Slide.
[00:53:19.200 --> 00:53:20.200]   I think it's like $3.
[00:53:20.200 --> 00:53:21.200]   Tweet it down, sir.
[00:53:21.200 --> 00:53:22.160]   Tweet it down.
[00:53:22.160 --> 00:53:23.560]   Yeah, Ryan Lawler got me on that.
[00:53:23.560 --> 00:53:24.840]   I committed tweet.
[00:53:24.840 --> 00:53:30.680]   So if I'm the Department of Border Protection, I'm not going to let you into the country at
[00:53:30.680 --> 00:53:32.440]   all because who knows what was in those tweets.
[00:53:32.440 --> 00:53:33.440]   You're hiding something.
[00:53:33.440 --> 00:53:35.440]   Well, I've got a bunch of thousand news.
[00:53:35.440 --> 00:53:37.400]   What kind of names will help anyway?
[00:53:37.400 --> 00:53:38.400]   It's German.
[00:53:38.400 --> 00:53:39.400]   Yeah.
[00:53:39.400 --> 00:53:40.400]   OK.
[00:53:40.400 --> 00:53:42.960]   You're not getting in.
[00:53:42.960 --> 00:53:43.960]   OK.
[00:53:43.960 --> 00:53:47.040]   No, but the cool thing is if you just delete all your tweets, what do they do about that?
[00:53:47.040 --> 00:53:50.400]   Well, they presume your social media accounts will maintain the fidelity.
[00:53:50.400 --> 00:53:52.120]   Well, it's deleted from your end, right?
[00:53:52.120 --> 00:53:53.800]   Oh, yeah, fair enough.
[00:53:53.800 --> 00:53:58.360]   This is not-- I mean, they have been doing this for applicants selected for Extra scrutiny.
[00:53:58.360 --> 00:54:00.440]   Have you ever been selected for Extra scrutiny?
[00:54:00.440 --> 00:54:01.440]   Yes, I have.
[00:54:01.440 --> 00:54:02.440]   Yes, they write SS.
[00:54:02.440 --> 00:54:03.440]   I married her.
[00:54:03.440 --> 00:54:04.600]   You married Extra scrutiny?
[00:54:04.600 --> 00:54:05.600]   No, no.
[00:54:05.600 --> 00:54:06.600]   Oh, you're talking about--
[00:54:06.600 --> 00:54:11.440]   That's the first time I was going to get up line.
[00:54:11.440 --> 00:54:14.240]   High Wesley, I'd like some extra scrutiny.
[00:54:14.240 --> 00:54:15.800]   It worked?
[00:54:15.800 --> 00:54:19.080]   No, I'm talking about CPP.
[00:54:19.080 --> 00:54:20.080]   OK.
[00:54:20.080 --> 00:54:21.080]   CPP.
[00:54:21.080 --> 00:54:23.400]   Well, you're OK.
[00:54:23.400 --> 00:54:27.040]   Now, I just-- I feel like we talked yesterday to a family-- we get a lot of visitors from
[00:54:27.040 --> 00:54:28.040]   all over the world.
[00:54:28.040 --> 00:54:29.920]   Yesterday we had a family visiting for Berlin.
[00:54:29.920 --> 00:54:30.920]   I asked them.
[00:54:30.920 --> 00:54:33.000]   They said, yeah, we would be much less likely to come to the US.
[00:54:33.000 --> 00:54:39.440]   Tourism is down 30 or 40% because of the stuff that's going on.
[00:54:39.440 --> 00:54:41.800]   Daniel, you came from Sweden.
[00:54:41.800 --> 00:54:45.200]   If they asked you that the next time you come to this country, would you think twice
[00:54:45.200 --> 00:54:47.080]   about coming here?
[00:54:47.080 --> 00:54:48.680]   Maybe, maybe not.
[00:54:48.680 --> 00:54:49.680]   You might.
[00:54:49.680 --> 00:54:53.960]   It seems like it would be a deterrent to some people.
[00:54:53.960 --> 00:54:58.560]   And maybe even-- I mean, look, people are deleting Facebook for no apparent reason.
[00:54:58.560 --> 00:55:00.800]   For actually many, many apparent reasons.
[00:55:00.800 --> 00:55:01.800]   Very obvious.
[00:55:01.800 --> 00:55:02.800]   Evident reasons.
[00:55:02.800 --> 00:55:04.440]   Why literally you face it?
[00:55:04.440 --> 00:55:09.600]   So this has been going on in the past, but they're asking now-- apparently 65,000 people
[00:55:09.600 --> 00:55:12.040]   last year got this Extra scrutiny.
[00:55:12.040 --> 00:55:15.120]   But they're asking now that they could do it for all 14 million.
[00:55:15.120 --> 00:55:17.800]   Now, it doesn't mean necessarily-- they have the information.
[00:55:17.800 --> 00:55:18.800]   Would they use it?
[00:55:18.800 --> 00:55:19.800]   I see they can't.
[00:55:19.800 --> 00:55:20.800]   You're right.
[00:55:20.800 --> 00:55:22.920]   But Leslie's absolutely right.
[00:55:22.920 --> 00:55:28.840]   It's not about, hey, look, this person is a member of a Twitter group or Facebook group
[00:55:28.840 --> 00:55:31.440]   that is known to be sending terrorists abroad.
[00:55:31.440 --> 00:55:34.240]   It really is about these enforcement agencies.
[00:55:34.240 --> 00:55:40.640]   They're trying to convince themselves that they can predict invisible future terrorists
[00:55:40.640 --> 00:55:44.360]   based on who they've been colluding with and where they've been traveling in the past.
[00:55:44.360 --> 00:55:50.040]   And so it really does, even though a person X traveling to the country is absolutely no
[00:55:50.040 --> 00:55:56.040]   threat whatsoever, that could be the reason why five years later on, another innocent person
[00:55:56.040 --> 00:55:58.680]   Y gets detained and gets special searching.
[00:55:58.680 --> 00:56:01.840]   And now they don't know why they're in this database that causes them to never be able
[00:56:01.840 --> 00:56:05.600]   to get back into the country again or to be held for three hours at a checkpoint because
[00:56:05.600 --> 00:56:11.000]   some algorithm has said that you are in some sort of Venn diagram of people that has had
[00:56:11.000 --> 00:56:17.120]   enough incidental contact, maybe without even their knowledge with people that we think
[00:56:17.120 --> 00:56:19.120]   are terrorists that we can't trust these people.
[00:56:19.120 --> 00:56:21.200]   That's the never you will they'll never find out about it.
[00:56:21.200 --> 00:56:23.760]   They'll never never be able to fix it and they'll never be able to escape it.
[00:56:23.760 --> 00:56:26.360]   So that's why the stuff is can be really scary.
[00:56:26.360 --> 00:56:29.560]   This proposal went up on Friday.
[00:56:29.560 --> 00:56:31.760]   It is a 60 day notice.
[00:56:31.760 --> 00:56:37.080]   You can actually comment and I hope people will by going to regulations.gov.
[00:56:37.080 --> 00:56:39.800]   That helps with the internet privacy, right?
[00:56:39.800 --> 00:56:45.680]   And yeah, and search for a docket number dos 2018 002.
[00:56:45.680 --> 00:56:49.240]   I see there are a total of 10 public comments so far.
[00:56:49.240 --> 00:56:52.680]   So we're just we're just really on our way.
[00:56:52.680 --> 00:56:54.680]   Well they jumped on Friday before.
[00:56:54.680 --> 00:56:56.520]   Yeah, but come on religious weekend.
[00:56:56.520 --> 00:56:59.440]   That's a great way to stuff it away from the news cycle, right?
[00:56:59.440 --> 00:57:01.520]   This is why I announced that it's a recent crash.
[00:57:01.520 --> 00:57:02.520]   That's true.
[00:57:02.520 --> 00:57:03.520]   I don't find it turned on.
[00:57:03.520 --> 00:57:04.520]   That's true Friday.
[00:57:04.520 --> 00:57:05.520]   Friday on the long weekend.
[00:57:05.520 --> 00:57:06.520]   It's called taking out the trash.
[00:57:06.520 --> 00:57:07.520]   So you do with any story you don't want.
[00:57:07.520 --> 00:57:09.320]   You just drop it when everyone's home.
[00:57:09.320 --> 00:57:10.320]   I mean, it's smart.
[00:57:10.320 --> 00:57:11.320]   It's also frustrating.
[00:57:11.320 --> 00:57:12.720]   I mean, this is a huge policy change.
[00:57:12.720 --> 00:57:16.760]   And back to Andy's comment, I just I don't want the government to really build this muscle.
[00:57:16.760 --> 00:57:18.200]   This is not something I want them to get good at.
[00:57:18.200 --> 00:57:20.560]   I mean, this is a relatively early look at what they could do with this down the road
[00:57:20.560 --> 00:57:24.320]   for all of us, but it's naive or not, but I just don't want them to get better at it.
[00:57:24.320 --> 00:57:26.320]   It's not a good skill for the government to have.
[00:57:26.320 --> 00:57:27.320]   Yeah.
[00:57:27.320 --> 00:57:31.280]   And by the way, all 10 comments 100 I'm just going to say this 100% of the comments so
[00:57:31.280 --> 00:57:32.840]   far are very negative.
[00:57:32.840 --> 00:57:33.840]   Wow.
[00:57:33.840 --> 00:57:36.280]   100% wait until the Russian bots find it.
[00:57:36.280 --> 00:57:37.280]   Oh crap.
[00:57:37.280 --> 00:57:39.880]   Oh, you see the snap the snapchat.
[00:57:39.880 --> 00:57:41.720]   Everyone fools joke.
[00:57:41.720 --> 00:57:42.720]   No.
[00:57:42.720 --> 00:57:43.720]   All right.
[00:57:43.720 --> 00:57:44.720]   All right.
[00:57:44.720 --> 00:57:45.720]   We're going to go backwards a little bit.
[00:57:45.720 --> 00:57:46.720]   Get out the snapchat.
[00:57:46.720 --> 00:57:47.720]   All right.
[00:57:47.720 --> 00:57:49.400]   So I believe actually let's I'll just tell you guys.
[00:57:49.400 --> 00:57:56.680]   So they did a filter that looks like Facebook, but it's in Russian, which Casey Newton from
[00:57:56.680 --> 00:57:58.600]   the Verge called it quote nuclear shade.
[00:57:58.600 --> 00:58:05.200]   And I thought that was the right way to describe that because did you see on the Silicon Valley,
[00:58:05.200 --> 00:58:08.320]   the TV show, it came back in the show open.
[00:58:08.320 --> 00:58:12.200]   You know, they have like all these little doodles or doodles of Silicon Valley.
[00:58:12.200 --> 00:58:15.920]   The Facebook kind of turns into Cyrillic and then back.
[00:58:15.920 --> 00:58:18.840]   Although if you look at it closely, it's not all Cyrillic.
[00:58:18.840 --> 00:58:20.400]   There's one Turkish character in there.
[00:58:20.400 --> 00:58:21.400]   It's very strange.
[00:58:21.400 --> 00:58:24.480]   I don't know if that's what that is, but it looks like Facebook and.
[00:58:24.480 --> 00:58:25.480]   Yeah.
[00:58:25.480 --> 00:58:28.400]   I mean, there's been a lot of good shade against Facebook in the last couple of weeks.
[00:58:28.400 --> 00:58:32.920]   And again, it's a little bit to your earlier comment deserved, but it's a little self serving
[00:58:32.920 --> 00:58:34.520]   for snapchat to do it.
[00:58:34.520 --> 00:58:35.520]   Well, snap loses tons of money.
[00:58:35.520 --> 00:58:36.520]   Facebook makes a lot of money.
[00:58:36.520 --> 00:58:39.440]   I'm not going to worry about that spit fight, you know, whatever.
[00:58:39.440 --> 00:58:42.040]   I'm sure a whole bunch of people want to snapchat to go see it.
[00:58:42.040 --> 00:58:45.240]   Oh, yeah, which is a great way to hack and get short term.
[00:58:45.240 --> 00:58:49.240]   Also, it was just like is the only April Foolish joke that I saw at the cycle that was good.
[00:58:49.240 --> 00:58:52.400]   Also it lets people know if you're on Instagram, you're on Facebook.
[00:58:52.400 --> 00:58:53.400]   True.
[00:58:53.400 --> 00:58:54.400]   True.
[00:58:54.400 --> 00:58:55.400]   Yeah.
[00:58:55.400 --> 00:58:56.740]   Yeah, yeah, which we should get to at some point in time because I've thoughts about that.
[00:58:56.740 --> 00:58:59.280]   So you're not on Facebook or you just what did you do?
[00:58:59.280 --> 00:59:02.800]   I'm deactivated on Facebook for the last couple of months and I haven't missed it a single
[00:59:02.800 --> 00:59:03.800]   time.
[00:59:03.800 --> 00:59:07.040]   So I wasn't a big messenger user, so I've gotten kind of lucky about that.
[00:59:07.040 --> 00:59:08.560]   Now Leo is taking a picture of his face.
[00:59:08.560 --> 00:59:10.720]   You can tell by the expression he's making.
[00:59:10.720 --> 00:59:11.720]   He makes the duck face.
[00:59:11.720 --> 00:59:12.720]   That's the duck.
[00:59:12.720 --> 00:59:13.720]   Yeah, I know.
[00:59:13.720 --> 00:59:14.720]   It's quite kissy if I may.
[00:59:14.720 --> 00:59:17.920]   So if you're not watching the video, you're missing out, but it is that is that is top notch.
[00:59:17.920 --> 00:59:19.880]   Apparently I can be an Easter bunny.
[00:59:19.880 --> 00:59:20.880]   Okay.
[00:59:20.880 --> 00:59:23.400]   Keep trying Easter again.
[00:59:23.400 --> 00:59:24.400]   It is.
[00:59:24.400 --> 00:59:25.880]   I am a crazy clone.
[00:59:25.880 --> 00:59:26.880]   Where is this thing?
[00:59:26.880 --> 00:59:27.880]   I saw it on Twitter.
[00:59:27.880 --> 00:59:28.880]   I don't use snap.
[00:59:28.880 --> 00:59:31.400]   I used to I could be these are this.
[00:59:31.400 --> 00:59:32.800]   Are you snappy as a athlete?
[00:59:32.800 --> 00:59:33.720]   No, never.
[00:59:33.720 --> 00:59:37.160]   I'm not the only hip young person in this group.
[00:59:37.160 --> 00:59:43.080]   Well, that part of the person might be true.
[00:59:43.080 --> 00:59:44.080]   I'm not.
[00:59:44.080 --> 00:59:45.080]   Oh, wait a minute.
[00:59:45.080 --> 00:59:46.080]   Is this it?
[00:59:46.080 --> 00:59:47.080]   Did you find it?
[00:59:47.080 --> 00:59:48.080]   No.
[00:59:48.080 --> 00:59:49.080]   Nope.
[00:59:49.080 --> 00:59:50.080]   Hello.
[00:59:50.080 --> 00:59:51.080]   Remember they say how the how the how the old can't make snap work?
[00:59:51.080 --> 00:59:52.080]   I'm making it work.
[00:59:52.080 --> 00:59:54.080]   You actually you better think with what I it's just not in there.
[00:59:54.080 --> 00:59:56.440]   Although that is an awfully cute fuzzy puppy.
[00:59:56.440 --> 00:59:58.480]   Snapchat filter Facebook.
[00:59:58.480 --> 00:59:59.480]   Hi.
[00:59:59.480 --> 01:00:03.120]   Why is Carsten Bundy in here?
[01:00:03.120 --> 01:00:06.400]   Carsten, this is what my face looks like when it merges with yours.
[01:00:06.400 --> 01:00:08.840]   I don't like it.
[01:00:08.840 --> 01:00:11.760]   This is what it looks like with Casey Newton.
[01:00:11.760 --> 01:00:12.760]   Yeah.
[01:00:12.760 --> 01:00:13.760]   Yeah.
[01:00:13.760 --> 01:00:14.760]   I don't know.
[01:00:14.760 --> 01:00:16.680]   I don't know why I'm not seeing that.
[01:00:16.680 --> 01:00:20.920]   But anyway, maybe they know that I am secretly.
[01:00:20.920 --> 01:00:21.920]   I'm a red sparrow.
[01:00:21.920 --> 01:00:23.320]   Did you know that?
[01:00:23.320 --> 01:00:24.400]   That's that movie they came out.
[01:00:24.400 --> 01:00:25.400]   Yeah.
[01:00:25.400 --> 01:00:26.800]   I didn't see that.
[01:00:26.800 --> 01:00:32.240]   Maybe they just put up one of those like on audio they put up in a very, very high frequency
[01:00:32.240 --> 01:00:36.880]   high be sure to look for the there's an invisible button just center of the left.
[01:00:36.880 --> 01:00:37.880]   I can't hear it.
[01:00:37.880 --> 01:00:38.880]   You can hear this.
[01:00:38.880 --> 01:00:42.040]   I can't that they would do that, wouldn't they?
[01:00:42.040 --> 01:00:47.040]   And all you all be I'd be very pleased and impressed if they had a way to just clean out
[01:00:47.040 --> 01:00:52.320]   the old people by by exploiting our rock concert attendance in our in our high school years.
[01:00:52.320 --> 01:00:53.320]   Exactly.
[01:00:53.320 --> 01:00:54.320]   Exactly.
[01:00:54.320 --> 01:00:55.600]   I used to be hip.
[01:00:55.600 --> 01:00:58.720]   I feel like I should try out snap again because it's the product is still pretty cool.
[01:00:58.720 --> 01:01:02.080]   Wesley Instagram Facebook Instagram not Facebook.
[01:01:02.080 --> 01:01:03.200]   I'm on Facebook too.
[01:01:03.200 --> 01:01:04.200]   You are.
[01:01:04.200 --> 01:01:05.200]   And Twitter of course.
[01:01:05.200 --> 01:01:06.200]   Yeah.
[01:01:06.200 --> 01:01:09.200]   Nobody's not on Twitter except for you're on Twitter but no tweets.
[01:01:09.200 --> 01:01:11.960]   I mean I have thousands of new tweets committed tweet aside.
[01:01:11.960 --> 01:01:14.960]   I've committed tweet aside but that was that that was my piece of mind.
[01:01:14.960 --> 01:01:18.480]   Like I just didn't want what if I got drunk in college and like said one dumb thing that
[01:01:18.480 --> 01:01:19.480]   someone's gonna find.
[01:01:19.480 --> 01:01:21.640]   So you didn't go back through me just to see what it was.
[01:01:21.640 --> 01:01:22.640]   There were 185,000 tweets.
[01:01:22.640 --> 01:01:23.640]   Yeah.
[01:01:23.640 --> 01:01:24.640]   We're saying like that.
[01:01:24.640 --> 01:01:26.800]   How did you get out of college?
[01:01:26.800 --> 01:01:29.360]   I wanted to leave Chicago because it was cold.
[01:01:29.360 --> 01:01:30.360]   Yeah.
[01:01:30.360 --> 01:01:34.400]   Just because of that reporter editor who got a promotion and then 24 hours.
[01:01:34.400 --> 01:01:36.240]   Oh you're talking about Quinn Norton?
[01:01:36.240 --> 01:01:37.240]   Yeah Quinn Norton.
[01:01:37.240 --> 01:01:40.480]   We've gotten on the editorial board of the New York Times for a hot cup of coffee.
[01:01:40.480 --> 01:01:41.480]   Yeah.
[01:01:41.480 --> 01:01:44.120]   It was actually one fifth of the Skaemuchi I think which is a pretty short period of time.
[01:01:44.120 --> 01:01:45.520]   That is the shortest time I know.
[01:01:45.520 --> 01:01:46.520]   Yeah that was rough.
[01:01:46.520 --> 01:01:50.120]   I mean but I think I think people should be just cognizant of what they put out there.
[01:01:50.120 --> 01:01:53.600]   I went through my Reddit account and deleted just a bunch of innocuous stuff just so you
[01:01:53.600 --> 01:01:54.840]   can't go back and nail that.
[01:01:54.840 --> 01:01:59.680]   I'm tired of you know my online life intelligently I think for longevity.
[01:01:59.680 --> 01:02:01.760]   You're absolutely right.
[01:02:01.760 --> 01:02:06.320]   The worst day of my life will come if someone, if the Internet Archive gets all of CompuServe
[01:02:06.320 --> 01:02:07.320]   back.
[01:02:07.320 --> 01:02:09.400]   Then I'm going to say hi.
[01:02:09.400 --> 01:02:13.800]   I'm going to have to move to France and enable that right to be forgotten law because of
[01:02:13.800 --> 01:02:14.800]   CompuServe.
[01:02:14.800 --> 01:02:20.160]   I was 17, 18, 19, 20.
[01:02:20.160 --> 01:02:23.480]   I knew everything I really did and then I forgot most of it and now I don't want to
[01:02:23.480 --> 01:02:24.480]   remember it again.
[01:02:24.480 --> 01:02:29.520]   You can't thank GDPR because Facebook, many sites, Twitter has added it.
[01:02:29.520 --> 01:02:31.400]   I'm going to have a delete my data button now.
[01:02:31.400 --> 01:02:32.400]   Which is huge.
[01:02:32.400 --> 01:02:33.400]   That's a requirement.
[01:02:33.400 --> 01:02:34.400]   Which is which GDPR.
[01:02:34.400 --> 01:02:35.400]   Yeah.
[01:02:35.400 --> 01:02:36.400]   Isn't that terrible?
[01:02:36.400 --> 01:02:42.800]   In Europe they actually have a concept that individuals have a right to the data that
[01:02:42.800 --> 01:02:43.960]   people collect on them.
[01:02:43.960 --> 01:02:46.840]   They can't just simply exploit them forever.
[01:02:46.840 --> 01:02:51.080]   There are limits to what Facebook and Apple and Google and all these companies can do.
[01:02:51.080 --> 01:02:53.680]   That's just mind-blowing to an American.
[01:02:53.680 --> 01:02:59.240]   You've just created a CompuServe storm on IRC.
[01:02:59.240 --> 01:03:03.680]   People remembering my, I remember mine, 75106, 3135.
[01:03:03.680 --> 01:03:04.680]   Do you remember yours, Andy?
[01:03:04.680 --> 01:03:05.680]   I do.
[01:03:05.680 --> 01:03:09.240]   Do you want to say it out loud on the show?
[01:03:09.240 --> 01:03:11.200]   In case somebody has an archive.
[01:03:11.200 --> 01:03:13.200]   Oh, that's a good point.
[01:03:13.200 --> 01:03:16.760]   I'm happy to anyone who went to the comics and animation forum.
[01:03:16.760 --> 01:03:18.120]   I was big, happy there.
[01:03:18.120 --> 01:03:19.120]   The Roger Ebert forum.
[01:03:19.120 --> 01:03:20.360]   I was very happy there.
[01:03:20.360 --> 01:03:21.360]   Wow.
[01:03:21.360 --> 01:03:22.600]   Other places I take to the grave with me.
[01:03:22.600 --> 01:03:23.600]   It's funny.
[01:03:23.600 --> 01:03:30.600]   I'm not trying to be rude.
[01:03:30.600 --> 01:03:32.080]   I'm actually just curious.
[01:03:32.080 --> 01:03:34.000]   Why is there a comma in the middle of your username?
[01:03:34.000 --> 01:03:52.560]   Instead of having actual user names, your account number was like five digits than a
[01:03:52.560 --> 01:03:55.800]   comma and then three digits.
[01:03:55.800 --> 01:03:58.840]   Then your name would be attached to your message, but that's how you logged in.
[01:03:58.840 --> 01:04:03.960]   I remember mine because I first got CompuServe when I became a columnist for a Ziff Davis
[01:04:03.960 --> 01:04:08.280]   magazine when I was 18 or 19.
[01:04:08.280 --> 01:04:12.680]   I asked now, because CompuServe, they build by the minute or I think it was by the minute
[01:04:12.680 --> 01:04:13.680]   or by the hour.
[01:04:13.680 --> 01:04:15.320]   I said, "No, how much?"
[01:04:15.320 --> 01:04:18.520]   I know it's for communicating with my editors and doing research.
[01:04:18.520 --> 01:04:21.720]   How much time can I spend before I go over?
[01:04:21.720 --> 01:04:23.800]   Then they laughed, "Oh, believe me.
[01:04:23.800 --> 01:04:27.640]   We have a brother/sister deal with CompuServe."
[01:04:27.640 --> 01:04:31.640]   There is no way you could possibly use so much CompuServe, there would be a problem.
[01:04:31.640 --> 01:04:34.240]   And then fast forward five weeks later, like, "Yeah."
[01:04:34.240 --> 01:04:38.440]   I'm using way too much CompuServe.
[01:04:38.440 --> 01:04:43.240]   I remember, actually, I was just thinking about this yesterday and I'm going to tell
[01:04:43.240 --> 01:04:45.320]   you why because I saw Ready Player One.
[01:04:45.320 --> 01:04:49.600]   I was thinking about the old days in Atari and I had a friend who worked at Atari who
[01:04:49.600 --> 01:04:54.600]   gave me his CompuServe account and said, "Use it all you want."
[01:04:54.600 --> 01:04:57.680]   The reason I wanted to, this was back in the days when I had a phone and I put it on
[01:04:57.680 --> 01:04:58.680]   the acoustic...
[01:04:58.680 --> 01:04:59.680]   You don't remember.
[01:04:59.680 --> 01:05:03.080]   There was acoustic coupler, there were suction cups of...
[01:05:03.080 --> 01:05:04.080]   [Sings]
[01:05:04.080 --> 01:05:08.280]   I really got sound from my "Fitties Can't Note 'em."
[01:05:08.280 --> 01:05:11.640]   Yeah, well, this didn't actually make all those sounds because it was...
[01:05:11.640 --> 01:05:13.880]   Don't forget the other important part of that sound.
[01:05:13.880 --> 01:05:16.400]   "Mom, don't take off the phone!
[01:05:16.400 --> 01:05:18.080]   You're the winner!"
[01:05:18.080 --> 01:05:22.960]   And I spent hours playing Colossal Caves, the text adventure, and thank God I had the
[01:05:22.960 --> 01:05:27.600]   free account because that would have been thousands of dollars, sure.
[01:05:27.600 --> 01:05:29.600]   [Sings]
[01:05:29.600 --> 01:05:33.160]   The "Gong-Gong" is the 56K.
[01:05:33.160 --> 01:05:34.160]   That's why you recognize it.
[01:05:34.160 --> 01:05:35.600]   See, that's what I grew up with.
[01:05:35.600 --> 01:05:37.720]   You might have noticed I'm pouring myself a little glass of wine.
[01:05:37.720 --> 01:05:38.720]   I see that, Leo.
[01:05:38.720 --> 01:05:40.520]   This show is going downhill.
[01:05:40.520 --> 01:05:42.840]   No, because my wink came.
[01:05:42.840 --> 01:05:47.600]   Wink is our sponsor for this portion of this week in tech and it's the best way to
[01:05:47.600 --> 01:05:49.800]   discover new wines you will love.
[01:05:49.800 --> 01:05:50.800]   Wink is a winery.
[01:05:50.800 --> 01:05:51.800]   W-I-N-C.
[01:05:51.800 --> 01:05:55.160]   It's a winery.
[01:05:55.160 --> 01:05:58.360]   And what I love about it is it's great wine.
[01:05:58.360 --> 01:06:01.320]   They make wine from all over the world.
[01:06:01.320 --> 01:06:06.400]   And it is a great way to get to know new wines, to have wines for your...
[01:06:06.400 --> 01:06:08.440]   You know, there's this...
[01:06:08.440 --> 01:06:09.960]   There's four bottles a month subscription.
[01:06:09.960 --> 01:06:12.880]   Of course, you can take a month off and that kind of thing.
[01:06:12.880 --> 01:06:14.560]   But that's just about right for me.
[01:06:14.560 --> 01:06:18.720]   We can bottle a week for dinner on Fridays, right?
[01:06:18.720 --> 01:06:22.200]   And then maybe one week we bring a nice bottle of wine.
[01:06:22.200 --> 01:06:24.960]   This one's always popular with the weather's heating up.
[01:06:24.960 --> 01:06:28.080]   Here's a New Zealand Sauvignon Blanc.
[01:06:28.080 --> 01:06:29.960]   This is from our most recent shipment.
[01:06:29.960 --> 01:06:31.160]   You can probably bring that to a party.
[01:06:31.160 --> 01:06:32.160]   Like for Easter.
[01:06:32.160 --> 01:06:34.680]   This we should bring this for the Easter dinner tonight.
[01:06:34.680 --> 01:06:36.720]   Outer Sounds from Marlboro, New Zealand.
[01:06:36.720 --> 01:06:39.640]   I love these wink wines.
[01:06:39.640 --> 01:06:42.120]   We went down and we met the winemaker.
[01:06:42.120 --> 01:06:45.120]   Here's an albarino, which is a really nice varietal.
[01:06:45.120 --> 01:06:49.960]   This one comes from California, but it's based in an Italian style white.
[01:06:49.960 --> 01:06:50.960]   You can choose.
[01:06:50.960 --> 01:06:51.960]   Here's what I want you to do.
[01:06:51.960 --> 01:06:57.360]   If you go to t-r-y-w-i-n-c-dot-com-try-wink-dot-com-slash-twit.
[01:06:57.360 --> 01:06:59.560]   And you can go through the taste test.
[01:06:59.560 --> 01:07:01.160]   They'll ask you questions.
[01:07:01.160 --> 01:07:02.760]   It's called a palette profile test.
[01:07:02.760 --> 01:07:07.240]   They'll ask you questions like, "Do you like coffee or how do you like it?"
[01:07:07.240 --> 01:07:08.660]   How do you like your coffee, Wesley?
[01:07:08.660 --> 01:07:09.660]   Do you drink it?
[01:07:09.660 --> 01:07:10.660]   I don't drink coffee.
[01:07:10.660 --> 01:07:11.660]   Okay.
[01:07:11.660 --> 01:07:12.660]   Drink it.
[01:07:12.660 --> 01:07:13.660]   There you go.
[01:07:13.660 --> 01:07:14.660]   Put that there's that's on there.
[01:07:14.660 --> 01:07:15.660]   How do you like salt?
[01:07:15.660 --> 01:07:16.660]   Do you use salt?
[01:07:16.660 --> 01:07:17.660]   Of course you use salt.
[01:07:17.660 --> 01:07:18.660]   Yes.
[01:07:18.660 --> 01:07:19.660]   Yes.
[01:07:19.660 --> 01:07:20.660]   Do you like it on everything all the time?
[01:07:20.660 --> 01:07:21.660]   No.
[01:07:21.660 --> 01:07:22.660]   Citrus?
[01:07:22.660 --> 01:07:23.660]   How do you feel?
[01:07:23.660 --> 01:07:24.660]   Mushrooms?
[01:07:24.660 --> 01:07:25.660]   So you take the test.
[01:07:25.660 --> 01:07:26.660]   Don't do shrooms.
[01:07:26.660 --> 01:07:27.660]   Don't do shrooms.
[01:07:27.660 --> 01:07:28.660]   Okay.
[01:07:28.660 --> 01:07:29.660]   You don't like the earthy, but I bet you like the berries.
[01:07:29.660 --> 01:07:30.660]   Do you like the berries?
[01:07:30.660 --> 01:07:31.660]   Yes.
[01:07:31.660 --> 01:07:32.660]   Blueberry, but yeah.
[01:07:32.660 --> 01:07:33.660]   And everything all the time?
[01:07:33.660 --> 01:07:34.660]   Yep.
[01:07:34.660 --> 01:07:35.660]   Peppers?
[01:07:35.660 --> 01:07:36.660]   You're from Austin.
[01:07:36.660 --> 01:07:37.660]   You better like the pepper.
[01:07:37.660 --> 01:07:38.660]   So there you go.
[01:07:38.660 --> 01:07:40.820]   So you go through the taste test and then they make recommendations.
[01:07:40.820 --> 01:07:44.220]   There's a little slider there you can have all red, all white or anything in between.
[01:07:44.220 --> 01:07:46.580]   So you get to choose what you like.
[01:07:46.580 --> 01:07:47.660]   We've got a half and half here.
[01:07:47.660 --> 01:07:50.060]   This is from it's called Cape Route.
[01:07:50.060 --> 01:07:53.180]   This is a South African wine from the Western Cape.
[01:07:53.180 --> 01:07:54.180]   Oh man.
[01:07:54.180 --> 01:07:57.220]   I just so you're going to try wines you've never tried before.
[01:07:57.220 --> 01:08:02.500]   This is a whole lot better than going to the grocery store or trader Joe's or even a liquor
[01:08:02.500 --> 01:08:05.780]   store and saying, ah, pick that one.
[01:08:05.780 --> 01:08:07.140]   That's no way to choose a wine.
[01:08:07.140 --> 01:08:08.140]   This is great.
[01:08:08.140 --> 01:08:09.140]   Ooh.
[01:08:09.140 --> 01:08:10.140]   A little French wine.
[01:08:10.140 --> 01:08:11.580]   This one didn't you Lisa?
[01:08:11.580 --> 01:08:13.500]   She loves the French wines.
[01:08:13.500 --> 01:08:22.420]   A Merlot pie door from Indicacin de Grapic, Portaget, Portaget de France.
[01:08:22.420 --> 01:08:25.100]   I'm going to drink right now a little bit of this.
[01:08:25.100 --> 01:08:26.980]   This is something we just had.
[01:08:26.980 --> 01:08:28.340]   Look at the, I love the labels too.
[01:08:28.340 --> 01:08:30.340]   They get local artists to do the labels.
[01:08:30.340 --> 01:08:31.340]   They're beautiful.
[01:08:31.340 --> 01:08:33.380]   Each month, new delicious wines.
[01:08:33.380 --> 01:08:36.740]   You're going to definitely want to get that summer water, Rose, that is one of their most
[01:08:36.740 --> 01:08:38.180]   popular wines.
[01:08:38.180 --> 01:08:39.180]   No membership fees.
[01:08:39.180 --> 01:08:40.180]   You can skip any month.
[01:08:40.180 --> 01:08:43.580]   You can cancel anytime and shipping is covered.
[01:08:43.580 --> 01:08:44.580]   And here's the best part.
[01:08:44.580 --> 01:08:46.700]   I said, well, what if I don't like one of these?
[01:08:46.700 --> 01:08:47.700]   They said, no problem.
[01:08:47.700 --> 01:08:48.700]   I said, I don't want to ship it back.
[01:08:48.700 --> 01:08:49.700]   They said, no, no, no.
[01:08:49.700 --> 01:08:50.700]   We're not going to make you shipping back.
[01:08:50.700 --> 01:08:51.900]   We just send you another bottle.
[01:08:51.900 --> 01:08:53.660]   No questions asked.
[01:08:53.660 --> 01:08:56.060]   So you know, you never stuck with something you don't like.
[01:08:56.060 --> 01:08:58.940]   You'll get four bottles you love every single month.
[01:08:58.940 --> 01:09:01.700]   Why settle for the same bottle of wine you always get.
[01:09:01.700 --> 01:09:03.780]   Discover great wine today.
[01:09:03.780 --> 01:09:05.100]   Try wink.com/twit.
[01:09:05.100 --> 01:09:11.460]   $20 off your first shipment.
[01:09:11.460 --> 01:09:15.420]   You can buy individual bottles if you really want to taste a great wine.
[01:09:15.420 --> 01:09:17.340]   Leo's pick for the week.
[01:09:17.340 --> 01:09:18.340]   Okay.
[01:09:18.340 --> 01:09:21.220]   Is that okay if I do that?
[01:09:21.220 --> 01:09:22.940]   Field theory.
[01:09:22.940 --> 01:09:24.420]   You know how much we love it?
[01:09:24.420 --> 01:09:27.780]   We're all out.
[01:09:27.780 --> 01:09:29.260]   We are all out, right?
[01:09:29.260 --> 01:09:30.620]   We tried to have some last night.
[01:09:30.620 --> 01:09:33.220]   I said, I could use a glass of that field.
[01:09:33.220 --> 01:09:35.220]   This comes in this cute little bottle.
[01:09:35.220 --> 01:09:37.620]   It's so, it's kind of like this, but it's a red.
[01:09:37.620 --> 01:09:38.620]   Oh, it's so good.
[01:09:38.620 --> 01:09:39.620]   Oh, wait a minute.
[01:09:39.620 --> 01:09:40.620]   This is field theory white.
[01:09:40.620 --> 01:09:41.620]   They have a white.
[01:09:41.620 --> 01:09:43.300]   This is the Alberinio field theory.
[01:09:43.300 --> 01:09:44.900]   Oh, so which one do we have?
[01:09:44.900 --> 01:09:45.900]   Field theory red?
[01:09:45.900 --> 01:09:47.380]   So good.
[01:09:47.380 --> 01:09:49.940]   I have to try the Alberinio now.
[01:09:49.940 --> 01:09:50.940]   Try wink.
[01:09:50.940 --> 01:09:51.940]   Here's to you.
[01:09:51.940 --> 01:09:52.940]   Try wink.com/twit.
[01:09:52.940 --> 01:09:55.140]   $20 off your first shipment.
[01:09:55.140 --> 01:09:57.460]   T-R-Y-W-I-N-C.com.
[01:09:57.460 --> 01:09:58.460]   Try wink.com/twit.
[01:09:58.460 --> 01:10:00.660]   Oh, that is so good.
[01:10:00.660 --> 01:10:07.420]   You know what I realized, and I think I really can credit wink with this, that wine is actually
[01:10:07.420 --> 01:10:09.220]   an ingredient in a meal.
[01:10:09.220 --> 01:10:13.700]   That when you have wine that's properly matched to what you're eating, you eat, you take a
[01:10:13.700 --> 01:10:16.700]   bite of the food and a list of the wine, and you guys don't understand this, but...
[01:10:16.700 --> 01:10:17.700]   Oh, I do.
[01:10:17.700 --> 01:10:21.180]   And you understand it way too well.
[01:10:21.180 --> 01:10:28.940]   And it's like an ingredient, and it can actually make the flavor just go boom in your mouth.
[01:10:28.940 --> 01:10:31.620]   That's probably not the best way to describe it, but that's how I'm going to do it.
[01:10:31.620 --> 01:10:32.620]   Try wink.com/twit.
[01:10:32.620 --> 01:10:36.020]   Andy, if you were here, I'd pour you a glass.
[01:10:36.020 --> 01:10:38.780]   I know you would.
[01:10:38.780 --> 01:10:39.780]   This is...
[01:10:39.780 --> 01:10:41.020]   These are glasses that a fan brought us.
[01:10:41.020 --> 01:10:42.620]   These are hand-blown...
[01:10:42.620 --> 01:10:44.380]   It's like Venetian glass.
[01:10:44.380 --> 01:10:45.380]   Aren't they beautiful?
[01:10:45.380 --> 01:10:46.380]   He brought us.
[01:10:46.380 --> 01:10:47.380]   Well, 20 of them are.
[01:10:47.380 --> 01:10:48.540]   It's not 24 of them.
[01:10:48.540 --> 01:10:49.540]   Oh.
[01:10:49.540 --> 01:10:52.940]   I have a bottle of port and a bottle of whiskey, and that's pretty much it.
[01:10:52.940 --> 01:10:53.940]   But they're good.
[01:10:53.940 --> 01:10:54.940]   I like them.
[01:10:54.940 --> 01:10:57.340]   I don't have them all the time, but when I have them, I enjoy them very much.
[01:10:57.340 --> 01:10:58.340]   What's your whiskey?
[01:10:58.340 --> 01:11:01.980]   My favorite is green spot.
[01:11:01.980 --> 01:11:02.980]   Never heard of it.
[01:11:02.980 --> 01:11:04.740]   Which I find really good.
[01:11:04.740 --> 01:11:06.740]   It actually put me on a whiskey to begin with.
[01:11:06.740 --> 01:11:09.740]   It was a gift when I gave a talk in Dublin, Ireland.
[01:11:09.740 --> 01:11:11.380]   It used to be only produced.
[01:11:11.380 --> 01:11:15.260]   It used to be you could only get it in Ireland and they started exporting it, but you have
[01:11:15.260 --> 01:11:17.940]   to find a place that can get it for you.
[01:11:17.940 --> 01:11:18.940]   It was so good.
[01:11:18.940 --> 01:11:23.980]   I sampled the glass there and was so good, I thought, "Okay, I'm going to...
[01:11:23.980 --> 01:11:27.060]   I'm going to pay the money to check my carry-on bag.
[01:11:27.060 --> 01:11:30.180]   I'm going to wrap this in lots and lots of laundry."
[01:11:30.180 --> 01:11:34.900]   If my bag arrives in the United States, smelling like whiskey, okay, that's just going to happen.
[01:11:34.900 --> 01:11:36.420]   Boy, was it worth it.
[01:11:36.420 --> 01:11:37.620]   There you go.
[01:11:37.620 --> 01:11:38.620]   Green spot.
[01:11:38.620 --> 01:11:39.620]   It's Irish.
[01:11:39.620 --> 01:11:40.620]   Single pot still.
[01:11:40.620 --> 01:11:41.620]   It turns out.
[01:11:41.620 --> 01:11:42.620]   There you go.
[01:11:42.620 --> 01:11:49.300]   The guys who do the windows Franklin, to do the windows, Paul, Carl Franklin, they can
[01:11:49.300 --> 01:11:50.940]   buy and they brought all this whiskey.
[01:11:50.940 --> 01:11:51.940]   Remember that episode?
[01:11:51.940 --> 01:11:52.940]   That was not a...
[01:11:52.940 --> 01:11:56.140]   I don't think anybody remembers that.
[01:11:56.140 --> 01:11:57.140]   They brought something.
[01:11:57.140 --> 01:11:58.660]   I think it was called the Angels Share.
[01:11:58.660 --> 01:12:01.540]   The Angels Share is the stuff that evaporates.
[01:12:01.540 --> 01:12:03.260]   It was amazing.
[01:12:03.260 --> 01:12:04.260]   Also Angels Envy.
[01:12:04.260 --> 01:12:05.260]   We're seeking to stand there.
[01:12:05.260 --> 01:12:06.260]   That was the Angels Envy.
[01:12:06.260 --> 01:12:08.740]   Angels Envy is fantastic.
[01:12:08.740 --> 01:12:09.740]   That's the one.
[01:12:09.740 --> 01:12:10.740]   It was Angels Envy.
[01:12:10.740 --> 01:12:11.740]   Thank you.
[01:12:11.740 --> 01:12:12.740]   That's one of the...
[01:12:12.740 --> 01:12:14.340]   That's a solid B plus on the whiskey grid.
[01:12:14.340 --> 01:12:15.340]   B plus?
[01:12:15.340 --> 01:12:17.340]   Well, the stuff gets better.
[01:12:17.340 --> 01:12:19.180]   It's just very good.
[01:12:19.180 --> 01:12:20.180]   We...
[01:12:20.180 --> 01:12:22.940]   Lisa and I were at a fancy restaurant and I had...
[01:12:22.940 --> 01:12:27.980]   What is that whiskey that everybody in Silicon Valley talks about all the time?
[01:12:27.980 --> 01:12:29.220]   It's a silly name.
[01:12:29.220 --> 01:12:30.220]   Pappy...
[01:12:30.220 --> 01:12:31.220]   Oh, Pappy Van Winkle.
[01:12:31.220 --> 01:12:32.220]   Pappy Van Winkle.
[01:12:32.220 --> 01:12:33.220]   Ah!
[01:12:33.220 --> 01:12:34.220]   Pappy's good?
[01:12:34.220 --> 01:12:35.220]   Is it good?
[01:12:35.220 --> 01:12:36.220]   I drink Pappy on both coasts.
[01:12:36.220 --> 01:12:37.220]   I had a Pappy.
[01:12:37.220 --> 01:12:38.220]   It was very, very expensive.
[01:12:38.220 --> 01:12:39.220]   You get...
[01:12:39.220 --> 01:12:39.980]   Literally, you get like...
[01:12:39.980 --> 01:12:40.980]   It's not a finger.
[01:12:40.980 --> 01:12:42.140]   It's a finger nail.
[01:12:42.140 --> 01:12:44.620]   The trick is go to a restaurant where your friend is a part owner.
[01:12:44.620 --> 01:12:45.620]   Ah.
[01:12:45.620 --> 01:12:47.180]   Then drink their Pappy.
[01:12:47.180 --> 01:12:48.180]   That's the solution.
[01:12:48.180 --> 01:12:49.180]   It was good.
[01:12:49.180 --> 01:12:50.180]   That's a long play.
[01:12:50.180 --> 01:12:51.180]   It was good.
[01:12:51.180 --> 01:12:52.180]   I don't know if it was...
[01:12:52.180 --> 01:12:53.180]   For Buffalo Trace.
[01:12:53.180 --> 01:12:54.180]   That's...
[01:12:54.180 --> 01:12:56.020]   So I wish to change my answer.
[01:12:56.020 --> 01:12:59.180]   My favorite kind of whiskey is complimentary.
[01:12:59.180 --> 01:13:00.820]   All right.
[01:13:00.820 --> 01:13:01.820]   Yes.
[01:13:01.820 --> 01:13:10.140]   Tim Cook, right after the Chicago event, the MSNBC recorded a roundtable with Carish
[01:13:10.140 --> 01:13:12.140]   Swisher and Chris Hayes.
[01:13:12.140 --> 01:13:16.140]   It's going to air April 6th, but I guess some people from the Verge were there, Lauren
[01:13:16.140 --> 01:13:17.860]   Good writing about it.
[01:13:17.860 --> 01:13:22.140]   And of course, Tim took this as an opportunity to talk about privacy.
[01:13:22.140 --> 01:13:27.140]   This is really going to be increasingly Apple's selling point, right?
[01:13:27.140 --> 01:13:30.460]   We don't have to care.
[01:13:30.460 --> 01:13:31.820]   We sell hardware.
[01:13:31.820 --> 01:13:33.340]   We don't have to follow you around.
[01:13:33.340 --> 01:13:36.660]   We don't have to surveil you.
[01:13:36.660 --> 01:13:37.660]   Cook...
[01:13:37.660 --> 01:13:44.540]   Lauren says MSNBC's Hayes and Swisher pressed Cook on the issue of privacy and regulation.
[01:13:44.540 --> 01:13:47.420]   I don't know if when you throw somebody a softball, is that called pressing?
[01:13:47.420 --> 01:13:48.420]   It's called helping.
[01:13:48.420 --> 01:13:49.420]   I think I feel like.
[01:13:49.420 --> 01:13:53.300]   Cook said, "We've never believed that these detailed profiles of people that have incredibly
[01:13:53.300 --> 01:13:58.380]   deep personal information that has patched together from several sources should exist."
[01:13:58.380 --> 01:14:00.900]   He said, "They could be abused against our democracy.
[01:14:00.900 --> 01:14:02.460]   It could be abused by advertisers as well."
[01:14:02.460 --> 01:14:08.020]   See, I don't mind advertisers giving me ads for stuff I might be interested in.
[01:14:08.020 --> 01:14:09.660]   That's not what's worrying me.
[01:14:09.660 --> 01:14:13.180]   Are they pledging that their marketing department aren't using these same tools?
[01:14:13.180 --> 01:14:15.180]   That's a good question.
[01:14:15.180 --> 01:14:19.220]   You are the put to the fire guy here.
[01:14:19.220 --> 01:14:23.940]   I think if it's available from somewhere else, they're going to use it if they can.
[01:14:23.940 --> 01:14:28.300]   He says, "I think the best regulation is no regulation.
[01:14:28.300 --> 01:14:29.300]   Self-regulation."
[01:14:29.300 --> 01:14:30.300]   The corporations said that?
[01:14:30.300 --> 01:14:33.060]   Tim Cook said, "However, I think we're beyond that.
[01:14:33.060 --> 01:14:37.620]   I think it's time that a set of people think deeply about what can be done."
[01:14:37.620 --> 01:14:40.620]   I agree with what he's saying here.
[01:14:40.620 --> 01:14:41.820]   I definitely do.
[01:14:41.820 --> 01:14:46.820]   But every time he speaks about privacy and protecting user data, he always talks about
[01:14:46.820 --> 01:14:47.820]   Facebook.
[01:14:47.820 --> 01:14:48.820]   He always talks about Google.
[01:14:48.820 --> 01:14:50.660]   He talks about those two big competitors.
[01:14:50.660 --> 01:14:54.660]   He doesn't talk about what I feel is the larger threat from advertisers and from marketers,
[01:14:54.660 --> 01:14:59.140]   from just being on the web that they're collecting all these kind of data from you.
[01:14:59.140 --> 01:15:05.500]   I'm really very disappointed that he can be giving a talk at a tech conference in China
[01:15:05.500 --> 01:15:09.460]   and talk about how privacy and finding against Facebook is important.
[01:15:09.460 --> 01:15:15.340]   But he has never seen him make a statement about here is the line with China and other
[01:15:15.340 --> 01:15:21.180]   large governments that likes to use technology to control its people and make you disappear
[01:15:21.180 --> 01:15:22.180]   ways sometimes.
[01:15:22.180 --> 01:15:25.500]   I've not seen a make a statement about saying, "Here is where the line is drawn.
[01:15:25.500 --> 01:15:30.740]   Here is where we withdraw from the China market if they ask us to comply with a law that we
[01:15:30.740 --> 01:15:39.020]   feel is going to subscript our iPhones into harming Chinese citizens."
[01:15:39.020 --> 01:15:40.900]   Again, I agree with what he says.
[01:15:40.900 --> 01:15:42.140]   He wasn't China last week.
[01:15:42.140 --> 01:15:43.140]   He did speak.
[01:15:43.140 --> 01:15:44.860]   He didn't say anything about privacy.
[01:15:44.860 --> 01:15:51.340]   Didn't he make a comment about, I'm trying to speak more?
[01:15:51.340 --> 01:15:52.340]   I'm looking here.
[01:15:52.340 --> 01:15:53.340]   He talked about trade.
[01:15:53.340 --> 01:15:57.940]   It does feel like he said something about, I could be conflating.
[01:15:57.940 --> 01:16:04.300]   He did keynote at a, speak at a previous, their big like national internet government
[01:16:04.300 --> 01:16:07.580]   conference, I think was in November, I want to say.
[01:16:07.580 --> 01:16:09.460]   No, this is most recently.
[01:16:09.460 --> 01:16:16.740]   He calls for stronger privacy regulations at the China Development Forum in Beijing.
[01:16:16.740 --> 01:16:19.340]   He said, "I think what?"
[01:16:19.340 --> 01:16:24.180]   Then at the same time they moved the iCloud keys to the Chinese servers.
[01:16:24.180 --> 01:16:25.180]   Right.
[01:16:25.180 --> 01:16:29.820]   It's a little commentary from Karsten throwing up that article.
[01:16:29.820 --> 01:16:32.220]   That was actually before Tim went to China.
[01:16:32.220 --> 01:16:35.900]   But regarding the where to draw the line point from Andy, does that make him more of a hypocrite
[01:16:35.900 --> 01:16:39.820]   or more of a coward in regards to not wanting to draw the line clearly and then also treating
[01:16:39.820 --> 01:16:41.620]   different governments differently?
[01:16:41.620 --> 01:16:43.860]   I don't know how to probably understand why.
[01:16:43.860 --> 01:16:47.700]   If you're Apple, you have to do what, if you're in a country, this is why Google pulled
[01:16:47.700 --> 01:16:48.940]   out a chair.
[01:16:48.940 --> 01:16:52.100]   If you're in a country, you have to abide by the laws of the country or pull out.
[01:16:52.100 --> 01:16:53.100]   That's your choice.
[01:16:53.100 --> 01:16:54.100]   Right.
[01:16:54.100 --> 01:16:56.100]   You can't say, "No, we're going to stay here and we're going to break your laws."
[01:16:56.100 --> 01:16:57.100]   Right.
[01:16:57.100 --> 01:16:58.100]   Yeah.
[01:16:58.100 --> 01:16:59.100]   They'll shut you down.
[01:16:59.100 --> 01:17:00.100]   Well, I mean, Google loves.
[01:17:00.100 --> 01:17:02.300]   Basically, it's not Apple pull out.
[01:17:02.300 --> 01:17:04.100]   Well they have a manufacturing problem.
[01:17:04.100 --> 01:17:05.100]   Right.
[01:17:05.100 --> 01:17:08.980]   They have a lot of problems because they also need those billion Chinese consumers to keep
[01:17:08.980 --> 01:17:09.980]   growth problems.
[01:17:09.980 --> 01:17:12.340]   Oh no, no, I was outling one of the problems.
[01:17:12.340 --> 01:17:15.420]   But I mean, like that's the sort of moral decision you have to make and you should be
[01:17:15.420 --> 01:17:19.060]   able to make those choices before you go off and pontificate about how Facebook and Google
[01:17:19.060 --> 01:17:20.060]   are going to be bad kids.
[01:17:20.060 --> 01:17:21.060]   Shut up.
[01:17:21.060 --> 01:17:22.220]   Apple could get the iPhone made not in China.
[01:17:22.220 --> 01:17:24.180]   There's plenty of places they could go to Thailand.
[01:17:24.180 --> 01:17:25.180]   They could go to Korea.
[01:17:25.180 --> 01:17:27.500]   I mean, Samsung makes his phones in Korea.
[01:17:27.500 --> 01:17:28.900]   There's ones made in Thailand.
[01:17:28.900 --> 01:17:30.700]   They could go to Taiwan where HTC manufacturing.
[01:17:30.700 --> 01:17:32.900]   That would be a massive change in their supplies.
[01:17:32.900 --> 01:17:35.540]   Splice chain and I mean, that would be enormous.
[01:17:35.540 --> 01:17:39.180]   And kind of if they're going to make that change, they may as well bring it stateside.
[01:17:39.180 --> 01:17:44.660]   And because another another organization they're closing up to is of course the current presidential
[01:17:44.660 --> 01:17:48.660]   administration, they might be able to get some good some good vibes from them.
[01:17:48.660 --> 01:17:51.820]   I'm not suggesting this would be an easy thing for them to do.
[01:17:51.820 --> 01:17:53.820]   I'm not suggesting that they need to pull out of China.
[01:17:53.820 --> 01:17:58.300]   I just need I'm just saying that I'm getting more and more impatient with Tim Cook's silence
[01:17:58.300 --> 01:18:05.380]   on again, but at what point does a government say we need the iPhone to be able to track
[01:18:05.380 --> 01:18:10.580]   our citizens this way or we need your iPhones to be able to control this or if we need to
[01:18:10.580 --> 01:18:14.820]   find somebody or we need to find out what somebody has been up to, we need your iPhones
[01:18:14.820 --> 01:18:16.460]   to be able to give us this data.
[01:18:16.460 --> 01:18:18.660]   At what point do you say, no, you don't get that.
[01:18:18.660 --> 01:18:21.980]   And if we you kick us out of your country, we simply pull out of your country.
[01:18:21.980 --> 01:18:26.620]   I just need some sort of statement that there is a line that Apple will not cross.
[01:18:26.620 --> 01:18:28.900]   And I'm surprised that at this point they haven't made it yet.
[01:18:28.900 --> 01:18:30.980]   There is a third route at which I didn't mention.
[01:18:30.980 --> 01:18:35.860]   Is it possible Apple behind the scenes, not in public is negotiating, is trying to exert
[01:18:35.860 --> 01:18:36.860]   some pressure.
[01:18:36.860 --> 01:18:41.740]   I mean, certainly Apple must represent an important economic opportunity for China.
[01:18:41.740 --> 01:18:42.740]   Right.
[01:18:42.740 --> 01:18:43.740]   Yeah, it's weird there.
[01:18:43.740 --> 01:18:47.700]   If you ask human rights leaders of human rights groups about what the responsibilities
[01:18:47.700 --> 01:18:52.660]   of companies like Facebook and Apple are, they will actually say that they can do a lot of
[01:18:52.660 --> 01:19:00.020]   good for the people by being a presence, by being some for at least a compromised form
[01:19:00.020 --> 01:19:05.020]   of a communication network that didn't exist before is better than having no ability to
[01:19:05.020 --> 01:19:06.780]   communicate with each other at all.
[01:19:06.780 --> 01:19:09.140]   So there's that part of the argument too.
[01:19:09.140 --> 01:19:14.140]   I also, I mean, I try, I'm sorry, I got another bottle of wine.
[01:19:14.140 --> 01:19:15.140]   I busted.
[01:19:15.140 --> 01:19:19.140]   This is like the Today Show, hour three with Coda.
[01:19:19.140 --> 01:19:20.140]   Yeah.
[01:19:20.140 --> 01:19:21.140]   Yeah.
[01:19:21.140 --> 01:19:22.740]   I have to say now, maybe I'm wrong.
[01:19:22.740 --> 01:19:25.900]   I trust Wesley, you, you're the one who's putting the feet of the fire.
[01:19:25.900 --> 01:19:26.900]   I trust Tim Cook.
[01:19:26.900 --> 01:19:28.740]   I don't trust Mark Zuckerberg.
[01:19:28.740 --> 01:19:30.740]   That's a completely personal point of view.
[01:19:30.740 --> 01:19:32.300]   No, I don't know either of them.
[01:19:32.300 --> 01:19:35.060]   I don't know anything about either of them besides what we all know.
[01:19:35.060 --> 01:19:37.700]   But I look at Tim and I feel like Tim's not lying to me.
[01:19:37.700 --> 01:19:46.020]   I look at Zuck and I go unless he releases an internal policy memo to all employees,
[01:19:46.020 --> 01:19:47.020]   all departments.
[01:19:47.020 --> 01:19:48.860]   And that goes to everyone.
[01:19:48.860 --> 01:19:50.660]   And it's a public stance.
[01:19:50.660 --> 01:19:54.980]   People in different divisions will do what they think is better for their division.
[01:19:54.980 --> 01:19:55.980]   Yeah.
[01:19:55.980 --> 01:19:56.980]   That's a good point.
[01:19:56.980 --> 01:20:00.620]   As long as it's not going against a public leadership role, if he wants anything to
[01:20:00.620 --> 01:20:02.420]   change, yes, he has to do that.
[01:20:02.420 --> 01:20:05.580]   And he has not done that or has he?
[01:20:05.580 --> 01:20:06.580]   Has he done sufficiently?
[01:20:06.580 --> 01:20:09.820]   He certainly, he certainly stuck at the Facebook.
[01:20:09.820 --> 01:20:12.820]   Oh, because he's taking a stand though.
[01:20:12.820 --> 01:20:14.140]   I mean, Andy is right.
[01:20:14.140 --> 01:20:15.220]   Where's the line?
[01:20:15.220 --> 01:20:16.220]   Be honest, be upfront.
[01:20:16.220 --> 01:20:17.300]   Tell us what you're doing.
[01:20:17.300 --> 01:20:20.340]   And tell their people what the line is too.
[01:20:20.340 --> 01:20:24.660]   If he's not instructing people below him not to do this, they're going to do it.
[01:20:24.660 --> 01:20:25.660]   Yeah.
[01:20:25.660 --> 01:20:26.980]   That's a really good point.
[01:20:26.980 --> 01:20:29.940]   The word where the phrase that is, the fish rots in the head or in this case, the good
[01:20:29.940 --> 01:20:32.260]   stuff comes down from the leadership of the company.
[01:20:32.260 --> 01:20:33.260]   So I agree.
[01:20:33.260 --> 01:20:35.260]   If you like rotten fish, that could be the good stuff.
[01:20:35.260 --> 01:20:36.900]   Well, isn't it like you fill the fish?
[01:20:36.900 --> 01:20:38.900]   It's like Sweden or something like that.
[01:20:38.900 --> 01:20:39.900]   Yeah.
[01:20:39.900 --> 01:20:40.900]   I don't think anyone would like stuff.
[01:20:40.900 --> 01:20:43.100]   God, you just put me off my wine.
[01:20:43.100 --> 01:20:45.460]   And that is not easy.
[01:20:45.460 --> 01:20:47.780]   Apple is changing its privacy controls.
[01:20:47.780 --> 01:20:52.580]   They are, as everyone will be, responding to the May launch of the general data protection
[01:20:52.580 --> 01:20:53.940]   regulation in Europe.
[01:20:53.940 --> 01:20:59.140]   Apple will update its webpage for managing Apple IDs to let users.
[01:20:59.140 --> 01:21:00.140]   This is so great.
[01:21:00.140 --> 01:21:01.140]   I love this.
[01:21:01.140 --> 01:21:02.940]   I wish they'd done this a years ago.
[01:21:02.940 --> 01:21:06.980]   Download a copy of all the data they have about you.
[01:21:06.980 --> 01:21:12.740]   It will also let customers correct personal information, temporarily deactivate their account
[01:21:12.740 --> 01:21:14.260]   and completely delete it.
[01:21:14.260 --> 01:21:16.420]   This is what Facebook has already done.
[01:21:16.420 --> 01:21:21.040]   So what everybody's going to have to do if they want to do business in Europe.
[01:21:21.040 --> 01:21:23.220]   Is there anything about offshore data?
[01:21:23.220 --> 01:21:25.660]   Like let's say I'm Apple.
[01:21:25.660 --> 01:21:29.180]   Can I have a server in Australia that has a copy of this and delete everything in the
[01:21:29.180 --> 01:21:30.180]   Europe server?
[01:21:30.180 --> 01:21:32.180]   I would put it in cold storage.
[01:21:32.180 --> 01:21:33.180]   I'm just asking.
[01:21:33.180 --> 01:21:34.180]   That would be devious.
[01:21:34.180 --> 01:21:39.220]   They, GDPR, by the way, is a lot of lines of code.
[01:21:39.220 --> 01:21:44.180]   But having read through it several times to understand it, my sense is that if any
[01:21:44.180 --> 01:21:50.340]   EU citizen is doing business with the company, that that company has to, and that's why Apple
[01:21:50.340 --> 01:21:51.340]   has to do this.
[01:21:51.340 --> 01:21:52.420]   It's not for your benefit.
[01:21:52.420 --> 01:21:54.220]   It's for the EU citizens.
[01:21:54.220 --> 01:21:57.980]   The company has to offer these features and it has to be global.
[01:21:57.980 --> 01:21:59.820]   It has to be 100%.
[01:21:59.820 --> 01:22:01.980]   Even if it's a third party company?
[01:22:01.980 --> 01:22:05.020]   So if you share the data to someone else, do you have to make them delete the data as
[01:22:05.020 --> 01:22:06.020]   well as better?
[01:22:06.020 --> 01:22:07.020]   Oh, that's a good question.
[01:22:07.020 --> 01:22:11.860]   Or if I spin up a third party company, just call it Apple Backup.
[01:22:11.860 --> 01:22:15.820]   Wow.
[01:22:15.820 --> 01:22:19.420]   I would think that the EU regulators would consider that an end around and would say
[01:22:19.420 --> 01:22:20.420]   that.
[01:22:20.420 --> 01:22:21.420]   They have a bunch of bureaucrats and bells.
[01:22:21.420 --> 01:22:23.220]   And the penalty for this is significant.
[01:22:23.220 --> 01:22:24.740]   How big is it?
[01:22:24.740 --> 01:22:27.660]   I think it's, I want to say, is it $40,000 per violation?
[01:22:27.660 --> 01:22:28.660]   Let me look.
[01:22:28.660 --> 01:22:30.260]   Oh, actually, no, I take it back.
[01:22:30.260 --> 01:22:32.180]   It's a percentage of your revenue.
[01:22:32.180 --> 01:22:33.180]   Oh, yes.
[01:22:33.180 --> 01:22:34.180]   Yeah.
[01:22:34.180 --> 01:22:35.180]   So it's a slightly small.
[01:22:35.180 --> 01:22:38.420]   Remember that Google got that SmackDown of $12.8 billion?
[01:22:38.420 --> 01:22:45.340]   Yeah, for antitrust complications, this is a place where they will hold people accountable
[01:22:45.340 --> 01:22:51.620]   and they will let you try to have a second go with a higher court, but you're going to
[01:22:51.620 --> 01:22:54.900]   put up the money to make sure that you're going to pay no matter what.
[01:22:54.900 --> 01:22:58.660]   So yeah, this is a good place for these laws to be in effect.
[01:22:58.660 --> 01:23:02.140]   And if all of us benefit from it, thank goodness.
[01:23:02.140 --> 01:23:03.140]   Thank you, Belgians.
[01:23:03.140 --> 01:23:04.140]   You're wonderful.
[01:23:04.140 --> 01:23:05.140]   You gave us a hookup.
[01:23:05.140 --> 01:23:06.140]   Porot, Boffles and this.
[01:23:06.140 --> 01:23:07.140]   Here's one of those.
[01:23:07.140 --> 01:23:13.900]   A warning in writing in the first case, first non-intentional non-compliance, regular periodic
[01:23:13.900 --> 01:23:18.980]   data protection audits of fine of up to 20 million euros or up to 4% of the annual worldwide
[01:23:18.980 --> 01:23:24.020]   turnover of the previous financial year, whichever is greater.
[01:23:24.020 --> 01:23:32.900]   So 4% of your revenue, 4% of your revenue, fine up to $10 million or 2% if there's an
[01:23:32.900 --> 01:23:37.100]   infringement on the, let's see.
[01:23:37.100 --> 01:23:38.420]   That's the privacy stuff.
[01:23:38.420 --> 01:23:41.380]   So it's up to 2% of the revenue for 2%.
[01:23:41.380 --> 01:23:46.780]   Yeah, for transfers of personal data to recipient in a third country, there's your answer or
[01:23:46.780 --> 01:23:49.540]   an international organization.
[01:23:49.540 --> 01:23:54.140]   The data subjects right, pursuant, if you violate their rights, pursuant to articles
[01:23:54.140 --> 01:23:58.860]   12 to 22, that's all of the right of access, right of deletion.
[01:23:58.860 --> 01:24:02.340]   Non-compliance with an order or temporary or definitive limitation on processing or the
[01:24:02.340 --> 01:24:03.340]   suspension.
[01:24:03.340 --> 01:24:04.340]   I think this is pretty serious.
[01:24:04.340 --> 01:24:06.620]   I don't think you're going to try to get around this.
[01:24:06.620 --> 01:24:10.180]   So I just pulled up Apple's trailing 12-month revenue, do some math.
[01:24:10.180 --> 01:24:18.220]   So 2% of Apple's last 12-month revenue is $4.8 billion and 4% is just under $9.6 billion.
[01:24:18.220 --> 01:24:20.060]   That's more than 20 million euro, you'll note.
[01:24:20.060 --> 01:24:21.060]   That's a lot of money.
[01:24:21.060 --> 01:24:22.980]   So that's the larger of the two.
[01:24:22.980 --> 01:24:25.220]   That's a staggering amount of money.
[01:24:25.220 --> 01:24:26.220]   That's not a punch in the face.
[01:24:26.220 --> 01:24:28.420]   That's not just kicking the knees.
[01:24:28.420 --> 01:24:32.380]   Berkeley Steve Heierman is saying if you want to get more information on GDPR, I know
[01:24:32.380 --> 01:24:36.580]   Denise Howell, who was on last week, was working to get a great This Week in Law together
[01:24:36.580 --> 01:24:37.580]   for Friday.
[01:24:37.580 --> 01:24:38.580]   She did.
[01:24:38.580 --> 01:24:40.020]   She covered GDPR in our Law Show on Friday.
[01:24:40.020 --> 01:24:41.340]   So listen to that one.
[01:24:41.340 --> 01:24:43.940]   If you want to know a competent first thing.
[01:24:43.940 --> 01:24:47.260]   But the first time this happens though, you think the company might just pull out.
[01:24:47.260 --> 01:24:49.300]   And just pull out of Europe?
[01:24:49.300 --> 01:24:50.300]   Yeah.
[01:24:50.300 --> 01:24:55.540]   I mean, that's significant amount of money, which might prompt significant action.
[01:24:55.540 --> 01:24:56.940]   Yeah, wow.
[01:24:56.940 --> 01:25:05.260]   I mean, especially if Google's not threatening to pull out of Europe, what would you say
[01:25:05.260 --> 01:25:06.260]   the Google final was?
[01:25:06.260 --> 01:25:07.260]   It was several billion, right?
[01:25:07.260 --> 01:25:08.420]   I think it said 12.8, right?
[01:25:08.420 --> 01:25:09.420]   Holy cow.
[01:25:09.420 --> 01:25:10.420]   I remember 12.8.
[01:25:10.420 --> 01:25:11.420]   Holy cow.
[01:25:11.420 --> 01:25:12.420]   That's yeah.
[01:25:12.420 --> 01:25:16.580]   Because in America, we find a bank like 48 cents whenever they just mean it's awful.
[01:25:16.580 --> 01:25:17.580]   What was the fine?
[01:25:17.580 --> 01:25:20.380]   Remind me what Equifax paid?
[01:25:20.380 --> 01:25:22.060]   What kind of fines do Equifax?
[01:25:22.060 --> 01:25:24.260]   It was three coupons and a group on.
[01:25:24.260 --> 01:25:25.260]   I mean, it was nothing.
[01:25:25.260 --> 01:25:26.260]   Nothing.
[01:25:26.260 --> 01:25:27.260]   It was a golden parachute.
[01:25:27.260 --> 01:25:30.900]   No, no, no, those are the positive ones you get when you have to step down.
[01:25:30.900 --> 01:25:33.180]   What did Equifax pay in fines?
[01:25:33.180 --> 01:25:34.180]   Oh, in fines.
[01:25:34.180 --> 01:25:35.180]   Oh, that's fine.
[01:25:35.180 --> 01:25:36.180]   That's a fun game.
[01:25:36.180 --> 01:25:37.180]   Oh, nothing.
[01:25:37.180 --> 01:25:38.180]   Oh, it was nothing.
[01:25:38.180 --> 01:25:39.180]   Nothing.
[01:25:39.180 --> 01:25:40.580]   Zero, zero, not a American way.
[01:25:40.580 --> 01:25:41.580]   They made money.
[01:25:41.580 --> 01:25:42.580]   Yep.
[01:25:42.580 --> 01:25:47.540]   The only one prosecuted has been so far the executive who suspiciously decided to move a
[01:25:47.540 --> 01:25:51.460]   lot of Equifax stock right before the announcement came out.
[01:25:51.460 --> 01:25:52.460]   Yeah, I'm glad they asked.
[01:25:52.460 --> 01:25:54.500]   That's going to be a financial Darwin award right there.
[01:25:54.500 --> 01:25:58.860]   Like, you know, like you got to be a real class of idiot to think that's going to fly.
[01:25:58.860 --> 01:25:59.860]   But it keeps happening.
[01:25:59.860 --> 01:26:01.580]   Well, people keep steam being dumb.
[01:26:01.580 --> 01:26:03.500]   I mean, stupidity doesn't leave the human race.
[01:26:03.500 --> 01:26:04.500]   It just persists.
[01:26:04.500 --> 01:26:06.660]   But oh my gosh, more on.
[01:26:06.660 --> 01:26:07.660]   Yeah.
[01:26:07.660 --> 01:26:09.740]   And it's gone back.
[01:26:09.740 --> 01:26:12.900]   So enough of this financial talk.
[01:26:12.900 --> 01:26:13.900]   Boo.
[01:26:13.900 --> 01:26:15.380]   I know this.
[01:26:15.380 --> 01:26:18.420]   I know you love money, Alex, but enough of this.
[01:26:18.420 --> 01:26:20.580]   Oh, well, maybe one more.
[01:26:20.580 --> 01:26:21.580]   Oracle.
[01:26:21.580 --> 01:26:22.780]   It looks like.
[01:26:22.780 --> 01:26:26.140]   It was the suit that never.
[01:26:26.140 --> 01:26:29.740]   It just goes on and on.
[01:26:29.740 --> 01:26:30.740]   My friends.
[01:26:30.740 --> 01:26:32.820]   So I tried to explain this on Wednesday, made a hash of it.
[01:26:32.820 --> 01:26:33.980]   Let me try again.
[01:26:33.980 --> 01:26:37.380]   This goes back to Google's use of Java in Android.
[01:26:37.380 --> 01:26:39.900]   Of course, they didn't use Java API.
[01:26:39.900 --> 01:26:45.220]   They copied Java and they copied more particularly the Java API because if you're going to be
[01:26:45.220 --> 01:26:50.060]   a program and you think you're sitting on Java, not Google's version of Java, you need
[01:26:50.060 --> 01:26:51.420]   to make Java calls.
[01:26:51.420 --> 01:26:52.540]   So Google said, well, it's fine.
[01:26:52.540 --> 01:26:54.460]   You make a standard Java call.
[01:26:54.460 --> 01:26:57.260]   We'll respond in a standard way, but it'll be our code.
[01:26:57.260 --> 01:27:01.020]   That doesn't require a license from Oracle.
[01:27:01.020 --> 01:27:06.260]   Oracle begs to differ and took them to court eight years ago.
[01:27:06.260 --> 01:27:07.260]   Yeah.
[01:27:07.260 --> 01:27:08.660]   For a point eight billion dollars.
[01:27:08.660 --> 01:27:09.660]   Yes.
[01:27:09.660 --> 01:27:10.660]   Eight years ago.
[01:27:10.660 --> 01:27:13.940]   And then Oracle lost.
[01:27:13.940 --> 01:27:17.100]   And then they did an interesting thing.
[01:27:17.100 --> 01:27:26.220]   They decided to make the case not be about using Android, but really about using a copyrighted
[01:27:26.220 --> 01:27:27.900]   API.
[01:27:27.900 --> 01:27:32.540]   And this got very interesting, very fast.
[01:27:32.540 --> 01:27:33.540]   They lost.
[01:27:33.540 --> 01:27:36.220]   Google lost in that case the court ruling.
[01:27:36.220 --> 01:27:39.380]   I think this was so hard to follow.
[01:27:39.380 --> 01:27:40.380]   Four years ago.
[01:27:40.380 --> 01:27:47.180]   I remember Judge Alsop who learned Java so that he could write this some Java code.
[01:27:47.180 --> 01:27:52.740]   And then he ruled in favor of Google, but then on appeal, the Federal Circuit, which
[01:27:52.740 --> 01:27:59.180]   is the Washington DC Federal Appeals Court, which is often very much more in favor of
[01:27:59.180 --> 01:28:00.680]   IP holders.
[01:28:00.680 --> 01:28:04.540]   They have a reputation of being very strongly in favor of copyright holders.
[01:28:04.540 --> 01:28:11.940]   They ruled in favor of Oracle or a Google appeal to the Supreme Court, which declined
[01:28:11.940 --> 01:28:18.980]   to review sending it back, but saying, here's the issue.
[01:28:18.980 --> 01:28:20.780]   Is it fair use?
[01:28:20.780 --> 01:28:25.340]   So there's no question now the courts have held and the Supreme Court has refused to
[01:28:25.340 --> 01:28:28.100]   review the notion that you can copyright an API.
[01:28:28.100 --> 01:28:29.740]   That's done.
[01:28:29.740 --> 01:28:34.780]   The only defense Google had was, well, but okay, but it was fair use.
[01:28:34.780 --> 01:28:40.660]   And now the appeals court again in DC has said, nope, wasn't fair use.
[01:28:40.660 --> 01:28:45.940]   You owe Oracle, Oracle, you owe Oracle.
[01:28:45.940 --> 01:28:46.940]   $8.8 billion.
[01:28:46.940 --> 01:28:51.700]   So can they go back to the Supreme Court to relitigate the fair use question?
[01:28:51.700 --> 01:28:52.820]   Or is that now done?
[01:28:52.820 --> 01:28:53.820]   I think that's done.
[01:28:53.820 --> 01:28:58.820]   I think the Supreme Court is the one that sent it back to the district court saying rule
[01:28:58.820 --> 01:29:00.660]   on the fair use thing.
[01:29:00.660 --> 01:29:01.660]   I don't think there is.
[01:29:01.660 --> 01:29:02.660]   I think that's done.
[01:29:02.660 --> 01:29:03.660]   Maybe not.
[01:29:03.660 --> 01:29:05.100]   You can't double dip on the Supreme Court.
[01:29:05.100 --> 01:29:06.100]   I'm no lawyer.
[01:29:06.100 --> 01:29:07.100]   Yeah, I mean either.
[01:29:07.100 --> 01:29:08.100]   I'm no lawyer.
[01:29:08.100 --> 01:29:12.540]   They'll use their previous precedent to.
[01:29:12.540 --> 01:29:16.540]   I'll just say I would go down in flames before I gave Oracle a dollar.
[01:29:16.540 --> 01:29:19.140]   I remember talking to Jonathan Schwartz.
[01:29:19.140 --> 01:29:24.180]   He was the CEO of Sun and was at Sun when it was Sun was sold to Oracle and among the
[01:29:24.180 --> 01:29:26.900]   things that were transferred over was Java.
[01:29:26.900 --> 01:29:30.740]   And he said, we have to pull this up, Carson, from the triangulation interview because it
[01:29:30.740 --> 01:29:32.420]   was very interesting.
[01:29:32.420 --> 01:29:38.780]   He said, I remember these discussions when the Oracle folks sat down with Sun and I was
[01:29:38.780 --> 01:29:43.460]   really surprised because they really didn't seem that interested in Java.
[01:29:43.460 --> 01:29:48.460]   What was really exciting to the lawyers, they were practically rubbing their hands in Glee
[01:29:48.460 --> 01:29:51.180]   was the intellectual property rights.
[01:29:51.180 --> 01:29:53.260]   Oh, we could sue that one.
[01:29:53.260 --> 01:29:57.860]   We could go and I think they really wanted to go after Google right there and then just
[01:29:57.860 --> 01:29:58.860]   for the cash grab.
[01:29:58.860 --> 01:30:01.060]   That's what they saw as the value of Sun.
[01:30:01.060 --> 01:30:02.700]   It wasn't Java.
[01:30:02.700 --> 01:30:04.700]   It wasn't Solaris.
[01:30:04.700 --> 01:30:08.260]   It wasn't heard in a while.
[01:30:08.260 --> 01:30:11.740]   It was the property rights, the intellectual property rights.
[01:30:11.740 --> 01:30:13.660]   That's really what was going on from day one.
[01:30:13.660 --> 01:30:15.100]   That's really whether the point of this all was.
[01:30:15.100 --> 01:30:19.740]   Now it's a shame because frankly, APIs need to be uncopy-writable.
[01:30:19.740 --> 01:30:21.180]   That's to do their job.
[01:30:21.180 --> 01:30:24.180]   Do you need?
[01:30:24.180 --> 01:30:29.860]   I think Google is likely to, according to Bloomberg Technology, ask that either the
[01:30:29.860 --> 01:30:35.140]   three-judge panel at the district court reconsider its decision.
[01:30:35.140 --> 01:30:36.340]   What does that look like?
[01:30:36.340 --> 01:30:37.340]   Please, no!
[01:30:37.340 --> 01:30:43.100]   Do it over or have the issue go before all the active judges.
[01:30:43.100 --> 01:30:45.820]   I guess the issue was maybe all the judges weren't there.
[01:30:45.820 --> 01:30:50.140]   The losing party could then ask the Supreme Court to take the case and that's what Google's
[01:30:50.140 --> 01:30:52.020]   supporters are calling for.
[01:30:52.020 --> 01:30:55.260]   So yes, your answer is it could go back to the Supreme Court.
[01:30:55.260 --> 01:30:56.540]   But I think the song is correct.
[01:30:56.540 --> 01:30:57.540]   This is back.
[01:30:57.540 --> 01:30:59.380]   The never-ending court sequence.
[01:30:59.380 --> 01:31:02.420]   I just hope that it doesn't end up with Oracle managing to patent troll their way into a
[01:31:02.420 --> 01:31:04.060]   one-quarter EPS bump.
[01:31:04.060 --> 01:31:05.060]   That's amazing.
[01:31:05.060 --> 01:31:07.060]   But then to finance dork terms.
[01:31:07.060 --> 01:31:11.460]   By the way, we should tell you that they bought Sun in January 2010 when this lawsuit,
[01:31:11.460 --> 01:31:16.060]   shortly before this lawsuit began, for 7.4 billion, eight months later sued Google for
[01:31:16.060 --> 01:31:17.060]   8.8 billion.
[01:31:17.060 --> 01:31:19.660]   We're trying to get that $1.4 billion in profit.
[01:31:19.660 --> 01:31:20.660]   What's it?
[01:31:20.660 --> 01:31:24.540]   Little do they know, they'd spent a couple of billion dollars on lawyers between then
[01:31:24.540 --> 01:31:25.540]   and now.
[01:31:25.540 --> 01:31:29.020]   What's the line between copyright and not...
[01:31:29.020 --> 01:31:33.700]   So does the judge who learned Java, does he have to... did he violate copyright by using
[01:31:33.700 --> 01:31:34.700]   the...
[01:31:34.700 --> 01:31:35.700]   That's a good question.
[01:31:35.700 --> 01:31:36.700]   Judge Alsop.
[01:31:36.700 --> 01:31:37.700]   Judge Alsop.
[01:31:37.700 --> 01:31:40.060]   He was the guy who was doing the Uber Waymo case as well recently.
[01:31:40.060 --> 01:31:41.100]   Yeah, he gets all the good way.
[01:31:41.100 --> 01:31:42.700]   He's in, I guess, Ninth Circuit.
[01:31:42.700 --> 01:31:46.180]   He's in Silicon Valley location.
[01:31:46.180 --> 01:31:51.780]   The fact that Android is free of charge does not make Google's use of the Java API packages
[01:31:51.780 --> 01:31:52.780]   non-commercial.
[01:31:52.780 --> 01:31:53.780]   That was Google's defense.
[01:31:53.780 --> 01:31:54.780]   It's non-commercial.
[01:31:54.780 --> 01:31:57.340]   We don't charge for Android.
[01:31:57.340 --> 01:32:02.220]   The three-judged federal circuit panel noted that Android had generated more than 42 billion
[01:32:02.220 --> 01:32:03.220]   dollars in revenue.
[01:32:03.220 --> 01:32:04.220]   They can't really...
[01:32:04.220 --> 01:32:06.220]   We don't charge it anymore.
[01:32:06.220 --> 01:32:07.220]   All right.
[01:32:07.220 --> 01:32:08.220]   Yeah.
[01:32:08.220 --> 01:32:09.220]   That's free.
[01:32:09.220 --> 01:32:10.220]   Yeah.
[01:32:10.220 --> 01:32:12.060]   And Google didn't alter the copyrighted material in any way.
[01:32:12.060 --> 01:32:13.940]   They just used it.
[01:32:13.940 --> 01:32:17.260]   So actually Oracle's apparently going to ask for more than 8.8 billion.
[01:32:17.260 --> 01:32:18.260]   Of course they are.
[01:32:18.260 --> 01:32:19.260]   Why not?
[01:32:19.260 --> 01:32:20.500]   Why not add a zero to that?
[01:32:20.500 --> 01:32:22.660]   Well, 42 billion, we should get at least...
[01:32:22.660 --> 01:32:23.660]   42 billion.
[01:32:23.660 --> 01:32:24.660]   Yeah.
[01:32:24.660 --> 01:32:25.660]   That.
[01:32:25.660 --> 01:32:26.660]   Plus damages.
[01:32:26.660 --> 01:32:31.460]   Aren't some of the calls in Java extremely similar to other...
[01:32:31.460 --> 01:32:32.820]   Ooh, wouldn't that be interesting?
[01:32:32.820 --> 01:32:33.820]   I don't know.
[01:32:33.820 --> 01:32:35.860]   Could this then go back?
[01:32:35.860 --> 01:32:36.860]   They still are calls.
[01:32:36.860 --> 01:32:37.860]   Yeah.
[01:32:37.860 --> 01:32:39.700]   That's the thing about an API.
[01:32:39.700 --> 01:32:45.380]   API calls tend to be very similar because they do the same thing.
[01:32:45.380 --> 01:32:50.460]   I mean, we have an API that we publish and allow people to use to their hearts content
[01:32:50.460 --> 01:32:52.700]   for our back-end.
[01:32:52.700 --> 01:32:57.300]   So if people want to make a Twitter app, a podcast app, they can make API calls and populate
[01:32:57.300 --> 01:33:00.740]   the information from our servers.
[01:33:00.740 --> 01:33:02.540]   Now that's a normal use of an API.
[01:33:02.540 --> 01:33:08.340]   If somebody said, "I'm going to duplicate the Twitter API and write my own back in," I'm
[01:33:08.340 --> 01:33:10.340]   going to...
[01:33:10.340 --> 01:33:12.540]   That's nuts to say, "Oh, you can't do that."
[01:33:12.540 --> 01:33:14.020]   So you wouldn't care?
[01:33:14.020 --> 01:33:16.300]   Well, I don't want to say that in case somebody doesn't.
[01:33:16.300 --> 01:33:18.220]   We could sue them for 42 billion dollars.
[01:33:18.220 --> 01:33:20.340]   I don't think you would generate that much revenue though.
[01:33:20.340 --> 01:33:21.340]   No offense to Twitter.
[01:33:21.340 --> 01:33:23.340]   That's a lot of dollars.
[01:33:23.340 --> 01:33:24.340]   That is exactly it.
[01:33:24.340 --> 01:33:25.900]   There's no offended party here.
[01:33:25.900 --> 01:33:26.900]   There is...
[01:33:26.900 --> 01:33:30.980]   There is insert 7.1 billion dollars into this slot.
[01:33:30.980 --> 01:33:33.940]   Retrieve 8.1 billion dollars from that slot.
[01:33:33.940 --> 01:33:36.700]   That is what this is all about.
[01:33:36.700 --> 01:33:39.140]   It's not about a company that wants to protect its IP.
[01:33:39.140 --> 01:33:43.860]   It's not about a business plan that it wants to pursue, that it can't because Google has
[01:33:43.860 --> 01:33:44.860]   eaten its lunch.
[01:33:44.860 --> 01:33:48.780]   This is just, again, buy low, sell high.
[01:33:48.780 --> 01:33:49.780]   This is what they're getting.
[01:33:49.780 --> 01:33:53.020]   They bought a lawsuit and they're going to sell that lawsuit for a pretty good amount of money.
[01:33:53.020 --> 01:33:55.260]   That's the worst M&A strategy ever.
[01:33:55.260 --> 01:33:56.260]   Be a good movie though.
[01:33:56.260 --> 01:33:58.060]   Honey, we bought a lawsuit.
[01:33:58.060 --> 01:34:00.060]   Honey, I should also...
[01:34:00.060 --> 01:34:04.620]   I'll be honest, if we're at a cocktail party and you tell me that and I've got a check
[01:34:04.620 --> 01:34:09.420]   for $1.3 billion from Prof. My Pocket, I will not and say, "You're right, I should be ashamed."
[01:34:09.420 --> 01:34:12.860]   And then you'll pat their pocket and be like, "Yes, good job me."
[01:34:12.860 --> 01:34:16.380]   I would say, "I'm not going to pay for that guy's drink, even though I could have paid
[01:34:16.380 --> 01:34:20.020]   for his drink about 40 billion times over again."
[01:34:20.020 --> 01:34:22.540]   Stupid journalist.
[01:34:22.540 --> 01:34:23.540]   Let's take a break.
[01:34:23.540 --> 01:34:24.540]   Our show today brought to you.
[01:34:24.540 --> 01:34:26.620]   Actually, before we do the commercial, let me...
[01:34:26.620 --> 01:34:33.740]   We have a little short movie that we made to celebrate a fun week at Twitch.
[01:34:33.740 --> 01:34:35.100]   Previously on Twitch.
[01:34:35.100 --> 01:34:37.020]   Time for me to put on my...
[01:34:37.020 --> 01:34:38.020]   Oh, shit.
[01:34:38.020 --> 01:34:39.020]   Oh, come on too.
[01:34:39.020 --> 01:34:40.020]   And you all matter, hat?
[01:34:40.020 --> 01:34:41.020]   What's my hat?
[01:34:41.020 --> 01:34:42.020]   Terrible.
[01:34:42.020 --> 01:34:43.020]   My hat's straight.
[01:34:43.020 --> 01:34:44.020]   A Mountie hat.
[01:34:44.020 --> 01:34:45.020]   Oh, Mountie hat.
[01:34:45.020 --> 01:34:46.020]   Or a Smokey the Bear hat.
[01:34:46.020 --> 01:34:47.020]   Mm-hmm.
[01:34:47.020 --> 01:34:48.020]   You get to pick.
[01:34:48.020 --> 01:34:49.020]   The new screensabers.
[01:34:49.020 --> 01:34:50.020]   You did something exciting.
[01:34:50.020 --> 01:34:51.420]   Yeah, I went down to Mountie actually.
[01:34:51.420 --> 01:34:56.980]   They have an omnidirectional treadmill, Ready Player One, that just launched in theaters.
[01:34:56.980 --> 01:34:57.980]   You're going to actually see this treadmill.
[01:34:57.980 --> 01:35:00.260]   I got to check it out in VR.
[01:35:00.260 --> 01:35:01.340]   Triangulation.
[01:35:01.340 --> 01:35:04.300]   I am very excited to talk to John Battelle.
[01:35:04.300 --> 01:35:06.820]   He is the founder of six companies.
[01:35:06.820 --> 01:35:08.780]   He helped launch Wired Magazine.
[01:35:08.780 --> 01:35:16.700]   This is a story of massively powerful platforms that we do not understand well enough.
[01:35:16.700 --> 01:35:18.580]   I'm not saying we should not trust.
[01:35:18.580 --> 01:35:23.860]   I'm saying we should not expect the people who run these companies to be responsible
[01:35:23.860 --> 01:35:31.020]   for fixing this because this is the intersection of two of the most powerful forces in the
[01:35:31.020 --> 01:35:34.780]   last two centuries, technology and democracy.
[01:35:34.780 --> 01:35:35.780]   To it.
[01:35:35.780 --> 01:35:44.100]   It's where your brain and tech meet.
[01:35:44.100 --> 01:35:48.580]   Sometimes I just watch that.
[01:35:48.580 --> 01:35:50.620]   I don't care what anybody in the chat room is saying right now.
[01:35:50.620 --> 01:35:52.620]   I thought that that Australian accent was on point.
[01:35:52.620 --> 01:35:54.580]   Nothing could be so embarrassing.
[01:35:54.580 --> 01:35:55.580]   It was pretty bad.
[01:35:55.580 --> 01:35:56.580]   Do watch that John Battelle.
[01:35:56.580 --> 01:35:58.380]   Very good points, John made.
[01:35:58.380 --> 01:36:01.700]   Although I thought he said technology and government, I thought he was going to say technology
[01:36:01.700 --> 01:36:02.700]   and advertising.
[01:36:02.700 --> 01:36:07.900]   Those are the two most powerful forces of the last 200 years that A-bomb was in there.
[01:36:07.900 --> 01:36:08.900]   Yeah, so three.
[01:36:08.900 --> 01:36:09.900]   The A-bomb.
[01:36:09.900 --> 01:36:11.860]   All right, government might have something to do with it.
[01:36:11.860 --> 01:36:14.020]   Our show today brought to you by Rocket Mortgage.
[01:36:14.020 --> 01:36:19.220]   If you're buying a home and you're not writing a check for the total amount, which certainly
[01:36:19.220 --> 01:36:21.020]   in this area you wouldn't be doing.
[01:36:21.020 --> 01:36:24.740]   I think in most areas you might need a home loan or maybe you've got a home loan and you
[01:36:24.740 --> 01:36:28.140]   want to lock in the low interest rate as interest rates go up.
[01:36:28.140 --> 01:36:32.460]   Now's the time to go to quicken loans, the number one lender in the country and try out
[01:36:32.460 --> 01:36:37.300]   Rocket Mortgage, the modern 21st century way to get a home loan.
[01:36:37.300 --> 01:36:38.780]   First of all, it's entirely online.
[01:36:38.780 --> 01:36:44.580]   No more going to the bank, hat in hand, begging for money, filling that along application,
[01:36:44.580 --> 01:36:49.260]   then going back to home and digging through the attic, papers, trying to find pay stubs
[01:36:49.260 --> 01:36:52.420]   and bank statements, none of that.
[01:36:52.420 --> 01:36:55.620]   You could actually do this at an open house.
[01:36:55.620 --> 01:36:59.500]   Let's say, okay, let's say you go to an open house, you see a house you want to buy and
[01:36:59.500 --> 01:37:01.220]   you go, honey, we should get this house.
[01:37:01.220 --> 01:37:02.540]   All right, we need a loan.
[01:37:02.540 --> 01:37:03.540]   Okay, watch.
[01:37:03.540 --> 01:37:06.900]   You go to Rocket Mortgage.com/Twit2 on your phone.
[01:37:06.900 --> 01:37:08.980]   You could do this on your phone, any browser.
[01:37:08.980 --> 01:37:09.980]   And you answer a few questions.
[01:37:09.980 --> 01:37:11.340]   You don't even need to go to the attic.
[01:37:11.340 --> 01:37:14.540]   You don't even go to the brain attic because you know the answers, home address, birth
[01:37:14.540 --> 01:37:16.540]   date, that kind of thing.
[01:37:16.540 --> 01:37:20.140]   And then thanks to their relationships, quicken loans, relationships with all the big financial
[01:37:20.140 --> 01:37:22.940]   institutions, all you have to do is give them permission.
[01:37:22.940 --> 01:37:24.660]   They'll get the information they need.
[01:37:24.660 --> 01:37:25.900]   You don't have to go to the attic.
[01:37:25.900 --> 01:37:27.820]   They'll do it for you.
[01:37:27.820 --> 01:37:33.860]   Crunch the numbers and under 10 minutes, I mean, while you're at the open house, you will
[01:37:33.860 --> 01:37:38.540]   be offered based on income assets and credit, all the home loan options for which you qualify.
[01:37:38.540 --> 01:37:41.700]   You choose the rate, the term, the down payment.
[01:37:41.700 --> 01:37:43.260]   They say approved, you're done.
[01:37:43.260 --> 01:37:44.860]   You can hold it up, show the realtor.
[01:37:44.860 --> 01:37:47.820]   Hey, we're good for the loan amount.
[01:37:47.820 --> 01:37:49.780]   We'd like to make an offer.
[01:37:49.780 --> 01:37:53.300]   By the way, I have some experience in this that really puts you at the head of the line.
[01:37:53.300 --> 01:37:58.460]   If you're coming there with a mortgage approval already, that's the way to make an offer.
[01:37:58.460 --> 01:38:00.220]   Rocket Mortgage from Quicken Loans.
[01:38:00.220 --> 01:38:03.620]   Quicken Loans knew there was a better way and they created it.
[01:38:03.620 --> 01:38:07.500]   Apply simply, understand fully and mortgage confidently.
[01:38:07.500 --> 01:38:09.860]   Rocket Mortgage.com/twit2.
[01:38:09.860 --> 01:38:12.220]   Rocket Mortgage.com/twit.
[01:38:12.220 --> 01:38:17.460]   And the number two equal housing lender licensed in all 50 states and MLS consumer access.org
[01:38:17.460 --> 01:38:18.460]   number 3030.
[01:38:18.460 --> 01:38:20.660]   Rocket Mortgage from Quicken Loans.
[01:38:20.660 --> 01:38:24.140]   Rocket Mortgage.com/twit.
[01:38:24.140 --> 01:38:26.660]   And the number two.
[01:38:26.660 --> 01:38:32.100]   We're talking tech and the in not go the celestial waste of bandwidth.
[01:38:32.100 --> 01:38:34.900]   Vintage, what is it?
[01:38:34.900 --> 01:38:35.900]   Veteran.
[01:38:35.900 --> 01:38:36.900]   Veteran.
[01:38:36.900 --> 01:38:37.900]   Veteran.
[01:38:37.900 --> 01:38:38.900]   Veteran technology reporter.
[01:38:38.900 --> 01:38:39.900]   Or vintage.
[01:38:39.900 --> 01:38:43.380]   Yo, the cassette playoff journalism.
[01:38:43.380 --> 01:38:44.540]   I'm vintage.
[01:38:44.540 --> 01:38:45.540]   I'm vintage technology.
[01:38:45.540 --> 01:38:46.540]   You're classic, Leo.
[01:38:46.540 --> 01:38:47.540]   I'm a classic.
[01:38:47.540 --> 01:38:48.540]   Also, that's the--
[01:38:48.540 --> 01:38:52.900]   It's a confencil in my ear and twist to getting anything out of me, right?
[01:38:52.900 --> 01:38:58.300]   And also the young Whopper Snapper here on my left, Alex Wilhelm, editor in chief.
[01:38:58.300 --> 01:39:00.580]   Crunchbase news at Alex on the Twitter.
[01:39:00.580 --> 01:39:01.580]   Nice to have you.
[01:39:01.580 --> 01:39:04.780]   You've been visiting Rhode Island a lot lately.
[01:39:04.780 --> 01:39:07.340]   Yes, I am staring monthly.
[01:39:07.340 --> 01:39:09.420]   And I certainly love flying them.
[01:39:09.420 --> 01:39:12.660]   I see a little exchange of jewelry occurred.
[01:39:12.660 --> 01:39:13.660]   Oh, yes.
[01:39:13.660 --> 01:39:14.660]   If you want to get a--
[01:39:14.660 --> 01:39:15.660]   A little exchange-ish.
[01:39:15.660 --> 01:39:16.660]   Congratulations.
[01:39:16.660 --> 01:39:17.660]   Yay.
[01:39:17.660 --> 01:39:20.100]   Liza, who is a doll, she's wonderful.
[01:39:20.100 --> 01:39:22.620]   She's a resident in psychiatry right now.
[01:39:22.620 --> 01:39:25.820]   Triple board, so pediatrics, psych, and then child psych.
[01:39:25.820 --> 01:39:26.820]   Oh, god.
[01:39:26.820 --> 01:39:28.220]   Wasn't enough just to have one, huh?
[01:39:28.220 --> 01:39:30.340]   No, apparently she wanted all three.
[01:39:30.340 --> 01:39:35.660]   She's super smart, she's great, and she is weirdly living in my childhood home in Providence.
[01:39:35.660 --> 01:39:37.660]   Yeah, which we're improving right now.
[01:39:37.660 --> 01:39:40.340]   That means you're in my childhood home.
[01:39:40.340 --> 01:39:41.980]   I hope you're not in my bedroom.
[01:39:41.980 --> 01:39:44.220]   I think I'm in your parents' bedroom, and I'm going to live there.
[01:39:44.220 --> 01:39:46.220]   Oh, that's even creepier.
[01:39:46.220 --> 01:39:47.220]   Hey.
[01:39:47.220 --> 01:39:49.900]   In my defense, you took us there, not me.
[01:39:49.900 --> 01:39:53.060]   Yeah, I'm going to live there half time the next couple of months.
[01:39:53.060 --> 01:39:54.060]   Nice.
[01:39:54.060 --> 01:39:55.060]   Yeah, I'm really pleased, though.
[01:39:55.060 --> 01:39:57.460]   Oh, you know, it just makes me so happy to know you and Liza are living there.
[01:39:57.460 --> 01:39:58.700]   That is so awesome.
[01:39:58.700 --> 01:40:01.300]   Congratulations, too, for both of you.
[01:40:01.300 --> 01:40:02.300]   Thank you.
[01:40:02.300 --> 01:40:04.060]   Will you be moving back there, you think?
[01:40:04.060 --> 01:40:05.460]   Just half time.
[01:40:05.460 --> 01:40:07.460]   You're going to spend half your time back and forth?
[01:40:07.460 --> 01:40:11.100]   Well, my six months, your job is on Market Street in San Francisco.
[01:40:11.100 --> 01:40:12.900]   So that's a difference.
[01:40:12.900 --> 01:40:14.540]   So you're going to go like one week a month?
[01:40:14.540 --> 01:40:15.540]   What two weeks?
[01:40:15.540 --> 01:40:17.020]   No, I'm going to go two weeks a month out there, two weeks here.
[01:40:17.020 --> 01:40:18.580]   I'm going to go show you that at work right now.
[01:40:18.580 --> 01:40:19.580]   That's not the end of the world.
[01:40:19.580 --> 01:40:21.020]   No, it's just a lot of flights.
[01:40:21.020 --> 01:40:22.020]   Yeah, it's OK.
[01:40:22.020 --> 01:40:23.020]   All right, good stuff done.
[01:40:23.020 --> 01:40:24.020]   Yeah.
[01:40:24.020 --> 01:40:26.340]   And I am thrilled that Wesley Faulkner came all the way up here.
[01:40:26.340 --> 01:40:27.340]   You didn't have to.
[01:40:27.340 --> 01:40:28.580]   Skype, like most people.
[01:40:28.580 --> 01:40:29.580]   It was fun.
[01:40:29.580 --> 01:40:30.580]   I wanted to be in the studio.
[01:40:30.580 --> 01:40:31.580]   It's thrilled.
[01:40:31.580 --> 01:40:34.140]   I met Wesley for the first time in Austin.
[01:40:34.140 --> 01:40:35.140]   We were down there for South.
[01:40:35.140 --> 01:40:36.460]   Not the first time.
[01:40:36.460 --> 01:40:37.460]   That's right.
[01:40:37.460 --> 01:40:38.460]   We met at CES.
[01:40:38.460 --> 01:40:39.460]   We're at everything.
[01:40:39.460 --> 01:40:41.220]   Well, South by your first time.
[01:40:41.220 --> 01:40:42.220]   Your first time.
[01:40:42.220 --> 01:40:47.660]   The famous Stubbs, the back pack with the stat gandalf staff camera.
[01:40:47.660 --> 01:40:48.660]   Yeah, wow.
[01:40:48.660 --> 01:40:50.060]   Anyway, it's great to see you.
[01:40:50.060 --> 01:40:51.060]   Thank you for coming up.
[01:40:51.060 --> 01:40:52.060]   Thanks for having me.
[01:40:52.060 --> 01:40:53.820]   I really appreciate it.
[01:40:53.820 --> 01:40:57.300]   Has anybody seen Ready Player One yet?
[01:40:57.300 --> 01:40:59.540]   See, I have an apology to make.
[01:40:59.540 --> 01:41:01.500]   John, I want to make this apology to you.
[01:41:01.500 --> 01:41:03.740]   Everybody raved about the novel.
[01:41:03.740 --> 01:41:05.940]   And I tried to read it a few times.
[01:41:05.940 --> 01:41:08.460]   And I'm such a snob.
[01:41:08.460 --> 01:41:13.180]   I got stopped right away because there were a few cliches that just bugged me.
[01:41:13.180 --> 01:41:14.740]   And it just bugged me.
[01:41:14.740 --> 01:41:15.740]   You too, Alex?
[01:41:15.740 --> 01:41:20.500]   So the whole book was a bunch of cliches strung together with odd cultural references.
[01:41:20.500 --> 01:41:23.980]   But the reason why the book worked for me in the end was that it had a huge creative
[01:41:23.980 --> 01:41:25.860]   vision and a lot of problems.
[01:41:25.860 --> 01:41:29.180]   So if you were willing to look at the vision of what would life be like if we all lived
[01:41:29.180 --> 01:41:32.260]   in a virtual world because the world world was bad, fun.
[01:41:32.260 --> 01:41:35.460]   If you got bogged down in the '70s or '80s references, whatever the heck that was going
[01:41:35.460 --> 01:41:37.100]   on the entire time, it was awful.
[01:41:37.100 --> 01:41:38.900]   And you're too young probably to remember much of the '80s.
[01:41:38.900 --> 01:41:39.900]   I didn't get any of them.
[01:41:39.900 --> 01:41:40.900]   Yes, yeah, I got them all.
[01:41:40.900 --> 01:41:41.900]   Right.
[01:41:41.900 --> 01:41:43.700]   And you still did it like better.
[01:41:43.700 --> 01:41:46.780]   Anyway, I saw the movie last night, Steven Spielberg.
[01:41:46.780 --> 01:41:49.220]   Now, he's been getting mixed reviews in New York Times.
[01:41:49.220 --> 01:41:52.460]   What was the quote in the New York Times is a hoot?
[01:41:52.460 --> 01:41:57.500]   Something like, let me see if I can find it because it's about as they're throwing shade.
[01:41:57.500 --> 01:41:59.980]   It's the keep going, Carsten.
[01:41:59.980 --> 01:42:01.540]   It's the last line of...
[01:42:01.540 --> 01:42:02.540]   Nope, nope.
[01:42:02.540 --> 01:42:03.540]   No, I don't know.
[01:42:03.540 --> 01:42:05.540]   This is my browsing by the Braille method.
[01:42:05.540 --> 01:42:06.540]   I know.
[01:42:06.540 --> 01:42:08.540]   I got to find it because it's the funniest line.
[01:42:08.540 --> 01:42:11.380]   What's the gist of the...
[01:42:11.380 --> 01:42:16.980]   That Steven Spielberg is simultaneously the best person and the worst person to make this
[01:42:16.980 --> 01:42:17.980]   movie.
[01:42:17.980 --> 01:42:21.580]   He's the best person because he is an '80s icon himself.
[01:42:21.580 --> 01:42:24.980]   In fact, he can parody his own movies in there.
[01:42:24.980 --> 01:42:28.700]   On the other hand, they feel like...
[01:42:28.700 --> 01:42:30.140]   I think they felt like he may be...
[01:42:30.140 --> 01:42:32.500]   I don't know.
[01:42:32.500 --> 01:42:34.140]   I'm not sure what they said.
[01:42:34.140 --> 01:42:35.140]   It was...
[01:42:35.140 --> 01:42:38.060]   Let's see if I can find this because it's...
[01:42:38.060 --> 01:42:39.060]   Yeah.
[01:42:39.060 --> 01:42:40.060]   There's a lot of my favorite line.
[01:42:40.060 --> 01:42:45.340]   It was when he describes the actor playing the hero in the film set in 24/25, "Wait
[01:42:45.340 --> 01:42:51.100]   Watts, a young man played by the "agreeably bland, blendly agreeable" tie Sheridan."
[01:42:51.100 --> 01:42:52.100]   Oh, yes.
[01:42:52.100 --> 01:42:55.140]   Oh, that's a hell of a phrase.
[01:42:55.140 --> 01:42:56.140]   Yes.
[01:42:56.140 --> 01:42:57.140]   Okay.
[01:42:57.140 --> 01:42:58.140]   Yes.
[01:42:58.140 --> 01:43:00.300]   Also, it had a $175 million budget according to...
[01:43:00.300 --> 01:43:02.180]   But what did it make?
[01:43:02.180 --> 01:43:05.060]   So far, 181.2, but I'm going to verify that box office.
[01:43:05.060 --> 01:43:06.060]   They're doing okay.
[01:43:06.060 --> 01:43:08.060]   They had a very good first weekend.
[01:43:08.060 --> 01:43:09.660]   We're all talking about it, right?
[01:43:09.660 --> 01:43:11.460]   They spent a lot at Southby.
[01:43:11.460 --> 01:43:12.460]   Promo...
[01:43:12.460 --> 01:43:13.460]   Didn't they?
[01:43:13.460 --> 01:43:16.380]   They had the Radi Player 1 experience, a VR experience.
[01:43:16.380 --> 01:43:20.740]   71% of its box office so far has been foreign and not domestic.
[01:43:20.740 --> 01:43:22.660]   It's kind of a dead point.
[01:43:22.660 --> 01:43:23.660]   What?
[01:43:23.660 --> 01:43:24.660]   Yep.
[01:43:24.660 --> 01:43:28.340]   128 million foreign, 53.2 million domestic per box office mojo.
[01:43:28.340 --> 01:43:29.340]   Huh.
[01:43:29.340 --> 01:43:35.300]   Well, I saw it last night and I loved it and I want to apologize because A, the movie
[01:43:35.300 --> 01:43:38.100]   was really good and the story...
[01:43:38.100 --> 01:43:39.100]   And you're right.
[01:43:39.100 --> 01:43:42.340]   I think Alex, maybe the thing I liked about it was the...
[01:43:42.340 --> 01:43:45.300]   It was an interesting idea, a conception.
[01:43:45.300 --> 01:43:48.940]   And I'm going back and reading the novel and I apologize also to Ernest Cline, who now
[01:43:48.940 --> 01:43:51.100]   I wrote the novel, wrote the screen cover of the screenplay.
[01:43:51.100 --> 01:43:52.100]   Oh, I didn't know that.
[01:43:52.100 --> 01:43:53.100]   That's awesome.
[01:43:53.100 --> 01:43:54.100]   Yeah, and he was a producer.
[01:43:54.100 --> 01:43:55.820]   So he had a lot of hand in this.
[01:43:55.820 --> 01:43:58.700]   And I think Spielberg was just right for it because it had...
[01:43:58.700 --> 01:44:03.860]   It felt like an 80s Spielberg, feel-good ending Spielberg movie.
[01:44:03.860 --> 01:44:06.100]   And it was good replayability.
[01:44:06.100 --> 01:44:07.100]   You'd watch it.
[01:44:07.100 --> 01:44:08.100]   Oh, yeah.
[01:44:08.100 --> 01:44:10.260]   Lots because it's full of these references.
[01:44:10.260 --> 01:44:16.100]   These 80s, wherever the music, Van Halen, and I mean, it's definitely a nostalgia fest
[01:44:16.100 --> 01:44:17.740]   for people a little older than you, Alex.
[01:44:17.740 --> 01:44:19.220]   No, one of these movies was very good.
[01:44:19.220 --> 01:44:21.500]   They're going to put a bunch of early Metallica in there on down.
[01:44:21.500 --> 01:44:22.500]   There's no Metallica.
[01:44:22.500 --> 01:44:24.140]   That's what it means, what they're going to have in there.
[01:44:24.140 --> 01:44:27.940]   They're going to put the bad stuff from the 80s and Van Halen on my P-Tire.
[01:44:27.940 --> 01:44:32.020]   This is what's really throwing me off of it though.
[01:44:32.020 --> 01:44:37.860]   I remember I've been going to the MIT flea market every month for since like the 90s.
[01:44:37.860 --> 01:44:44.100]   I've seen nostalgia affect markets and how sad it becomes when you realize that the
[01:44:44.100 --> 01:44:50.820]   reason why, wow, there's the thing that keeps coming back to my mind is like vintage radios.
[01:44:50.820 --> 01:44:56.220]   You go to MIT flea market and there'd be a dozen people with tables full of brilliant,
[01:44:56.220 --> 01:45:00.460]   beautiful vintage radios that you couldn't possibly afford because when I was a kid going
[01:45:00.460 --> 01:45:06.700]   to the MIT flea market, the people who were like in their 40s and 50s and 60s who remember
[01:45:06.700 --> 01:45:11.340]   radios in their parents' houses growing up, wanted to buy and wanted to re-experience
[01:45:11.340 --> 01:45:12.980]   what they had growing up.
[01:45:12.980 --> 01:45:18.820]   And then in the 2000s and 20 teens, suddenly the same radios that were going for hundreds
[01:45:18.820 --> 01:45:26.540]   of dollars were going for like $25, $10, $50 because all the people who were nostalgic
[01:45:26.540 --> 01:45:30.940]   about that sort of stuff had died or go into nursing homes.
[01:45:30.940 --> 01:45:35.380]   I think what's bothering me about Ready Player One and to an extent like all the emulation
[01:45:35.380 --> 01:45:40.900]   of old games and old systems is that now I'm in that 40s, 50s, 60s demographic.
[01:45:40.900 --> 01:45:47.300]   And it's like, are these things popular because again, we want to recapture all of our childhoods
[01:45:47.300 --> 01:45:51.900]   and then in 10 years time, nobody's going to care about it because we'll all be dead.
[01:45:51.900 --> 01:45:55.860]   And nostalgia is such a boring concept.
[01:45:55.860 --> 01:46:00.700]   It's like, I'm hoping that if I went to see this movie, it won't be, hey, I recognize
[01:46:00.700 --> 01:46:01.700]   that car.
[01:46:01.700 --> 01:46:03.300]   Hey, I recognize that guy.
[01:46:03.300 --> 01:46:05.180]   I want it to be a really good story.
[01:46:05.180 --> 01:46:08.740]   And nostalgia is completely peripheral to the story.
[01:46:08.740 --> 01:46:14.060]   It's there without being in any way a critical part except, and I don't want to give you
[01:46:14.060 --> 01:46:15.060]   any spoilers.
[01:46:15.060 --> 01:46:19.140]   So I won't say there is one exception and it's actually the most important part of the
[01:46:19.140 --> 01:46:27.540]   movie does rely on something that brought me back to my younger days.
[01:46:27.540 --> 01:46:30.580]   I was actually much older than you at the time, Alex.
[01:46:30.580 --> 01:46:34.100]   But I don't know how I can describe this.
[01:46:34.100 --> 01:46:40.100]   It involved playing a game on the Atari 2600 and it appropriately enough for Easter Sunday,
[01:46:40.100 --> 01:46:43.020]   the very first Easter egg ever.
[01:46:43.020 --> 01:46:45.300]   And yeah, you know it from the novel.
[01:46:45.300 --> 01:46:47.220]   I think I know you're talking about it.
[01:46:47.220 --> 01:46:50.580]   And to me, I remember vividly.
[01:46:50.580 --> 01:46:54.740]   So there was a nostalgic moment for me playing this game, looking for this Easter egg very
[01:46:54.740 --> 01:46:55.740]   much.
[01:46:55.740 --> 01:46:58.100]   This was a big deal.
[01:46:58.100 --> 01:47:01.940]   So in that sense, there was some nostalgia, but it isn't an nostalgia fest.
[01:47:01.940 --> 01:47:03.780]   And there's some really good performances.
[01:47:03.780 --> 01:47:10.220]   Mark Reiland's who is one of my favorite actors and normally plays prestige roles, plays
[01:47:10.220 --> 01:47:11.580]   a nerd.
[01:47:11.580 --> 01:47:12.580]   He plays a job.
[01:47:12.580 --> 01:47:14.420]   Are you seeing a nerd from the opposite of this?
[01:47:14.420 --> 01:47:18.500]   Well, he plays basically on the spectrum nerd.
[01:47:18.500 --> 01:47:21.620]   And it's really well done and it's quite funny.
[01:47:21.620 --> 01:47:23.540]   And at first I'm going, who the hell is that?
[01:47:23.540 --> 01:47:25.420]   That's Mark Reiland's.
[01:47:25.420 --> 01:47:26.420]   But he's really good.
[01:47:26.420 --> 01:47:27.660]   He's really, really good at this.
[01:47:27.660 --> 01:47:30.620]   I agree the leads are kind of bland, but they're supposed to be.
[01:47:30.620 --> 01:47:33.340]   It's a young adult kind of fiction kind of thing.
[01:47:33.340 --> 01:47:35.020]   Here's the New York Times quote.
[01:47:35.020 --> 01:47:40.220]   "Steven Spielberg is the only person who could have made this movie and the last person who
[01:47:40.220 --> 01:47:42.780]   should have been allowed near the material.
[01:47:42.780 --> 01:47:46.580]   They also conclude, and I think this probably, the New York Times is strangely ambivalent
[01:47:46.580 --> 01:47:47.580]   in all of this.
[01:47:47.580 --> 01:47:50.300]   I think they feel guilty because they wrote a follow up article that said, and it made
[01:47:50.300 --> 01:47:53.140]   a billion dollars."
[01:47:53.140 --> 01:47:57.140]   It says, "Ready Player One is far from a masterpiece, but as the fan boys say, it's
[01:47:57.140 --> 01:47:58.140]   canon."
[01:47:58.140 --> 01:48:00.340]   And I think that's accurate.
[01:48:00.340 --> 01:48:01.700]   That strikes me as a dodge.
[01:48:01.700 --> 01:48:02.700]   It is a dodge.
[01:48:02.700 --> 01:48:05.980]   It is a little bit of a dodge.
[01:48:05.980 --> 01:48:11.860]   The Times feels guilty because their headline today is, "Ready Player One, overcomes challenges
[01:48:11.860 --> 01:48:14.340]   to dominate box office."
[01:48:14.340 --> 01:48:18.300]   And the first line is, "Steven Spielberg aced his test."
[01:48:18.300 --> 01:48:22.100]   He's 71, but I think he did a really good job with it.
[01:48:22.100 --> 01:48:23.100]   Good for him.
[01:48:23.100 --> 01:48:26.020]   He finally made that big one, that big, powerful success.
[01:48:26.020 --> 01:48:28.620]   71 years of trying for that big break.
[01:48:28.620 --> 01:48:29.620]   Yeah.
[01:48:29.620 --> 01:48:30.620]   What are we saying though?
[01:48:30.620 --> 01:48:34.140]   If this is supposed to be a world where everyone kind of goes and congregates, why is there
[01:48:34.140 --> 01:48:38.100]   a stereotype that the person or the people who are in it are nerds?
[01:48:38.100 --> 01:48:42.540]   Or would it be everyday regular people all the time if most people are congregate?
[01:48:42.540 --> 01:48:43.540]   It is.
[01:48:43.540 --> 01:48:47.140]   Okay, so the nerd is the guy who made it.
[01:48:47.140 --> 01:48:49.940]   And he is a central part of it.
[01:48:49.940 --> 01:48:55.620]   But one of the things they say is that nearly everybody takes place in Columbus, Ohio, which
[01:48:55.620 --> 01:49:00.300]   is unaccountably the fastest growing city in the world at this time.
[01:49:00.300 --> 01:49:03.300]   That's what they say at the beginning of the movie, which is bizarre.
[01:49:03.300 --> 01:49:05.860]   No, well, there's a reason.
[01:49:05.860 --> 01:49:07.300]   I don't want to get into it.
[01:49:07.300 --> 01:49:09.020]   There's a reason why it's the fastest growing.
[01:49:09.020 --> 01:49:13.900]   But the people they say in it, everybody plays at least a little bit every day.
[01:49:13.900 --> 01:49:18.260]   And what you see as you go down the streets is everybody's wearing their VR Pfizer.
[01:49:18.260 --> 01:49:20.580]   It's all the time.
[01:49:20.580 --> 01:49:23.300]   But also inside the world keeping this really generic.
[01:49:23.300 --> 01:49:26.540]   There are certain people who take part in the VR world as a social event and some that
[01:49:26.540 --> 01:49:29.100]   search inside of it for a specific set of things.
[01:49:29.100 --> 01:49:30.100]   Right.
[01:49:30.100 --> 01:49:31.100]   Right.
[01:49:31.100 --> 01:49:32.100]   And that's big enough.
[01:49:32.100 --> 01:49:35.780]   And the nostalgia that comes to it because, well, I don't know how we can talk about this
[01:49:35.780 --> 01:49:37.300]   without spoiling something.
[01:49:37.300 --> 01:49:40.420]   The nostalgia is an artifact of what's going on.
[01:49:40.420 --> 01:49:43.260]   It is not something that's normal in society.
[01:49:43.260 --> 01:49:46.700]   In fact, it says very clearly in the first pages of the book, nobody knew or cared about
[01:49:46.700 --> 01:49:50.980]   the 80s until.
[01:49:50.980 --> 01:49:53.780]   And I'll leave the until on set because I don't want to spoil it for you.
[01:49:53.780 --> 01:49:55.580]   Yeah, that's a teaser.
[01:49:55.580 --> 01:49:56.580]   It's a great movie.
[01:49:56.580 --> 01:49:57.580]   Now I have to go watch it.
[01:49:57.580 --> 01:49:58.580]   You have to go see it.
[01:49:58.580 --> 01:49:59.580]   I'm not watching it.
[01:49:59.580 --> 01:50:00.580]   Okay.
[01:50:00.580 --> 01:50:03.220]   Here's some weird tidbits that I got from our home theater expert, Scott Wilkinson.
[01:50:03.220 --> 01:50:06.300]   I thought, well, this must have been shot on digital, right?
[01:50:06.300 --> 01:50:07.500]   Thirty five millimeter.
[01:50:07.500 --> 01:50:08.500]   No way.
[01:50:08.500 --> 01:50:10.620]   Don't steal Spielberg.
[01:50:10.620 --> 01:50:14.900]   And then I said, well, but at least the CGI, which is probably half the movie, that must
[01:50:14.900 --> 01:50:15.900]   be UHD.
[01:50:15.900 --> 01:50:16.900]   Nope.
[01:50:16.900 --> 01:50:19.660]   No CGI in any movie is more than 1080p.
[01:50:19.660 --> 01:50:22.420]   It would be too costly and time consuming.
[01:50:22.420 --> 01:50:25.460]   Even for movie that costs $181 million to make.
[01:50:25.460 --> 01:50:26.460]   Wow.
[01:50:26.460 --> 01:50:27.940]   Now it's about time.
[01:50:27.940 --> 01:50:28.980]   Time is the most viable thing.
[01:50:28.980 --> 01:50:30.540]   You cannot manufacture enough of it.
[01:50:30.540 --> 01:50:33.700]   Because you gotta make a movie in a year.
[01:50:33.700 --> 01:50:34.700]   You can't.
[01:50:34.700 --> 01:50:35.700]   I take 10 years.
[01:50:35.700 --> 01:50:36.700]   Yeah.
[01:50:36.700 --> 01:50:37.700]   It's on effects on this scale.
[01:50:37.700 --> 01:50:40.900]   They don't have enough time to do everything other effects at 4K.
[01:50:40.900 --> 01:50:41.900]   I've read it.
[01:50:41.900 --> 01:50:43.540]   So maybe there'll be an 8-bit version.
[01:50:43.540 --> 01:50:44.540]   Yeah.
[01:50:44.540 --> 01:50:45.540]   Yeah.
[01:50:45.540 --> 01:50:46.540]   Just like Pokemon Go.
[01:50:46.540 --> 01:50:52.340]   I know you've just described an Adam Sandler movie that I thought I'd do.
[01:50:52.340 --> 01:50:56.220]   It's good Netflix brain right there.
[01:50:56.220 --> 01:50:57.980]   There are some anachronisms.
[01:50:57.980 --> 01:51:03.180]   The Iron Giant is in it, even though I vividly remember the Iron Giant emerged in the 90s,
[01:51:03.180 --> 01:51:04.180]   not in the 80s.
[01:51:04.180 --> 01:51:05.180]   But okay.
[01:51:05.180 --> 01:51:06.180]   Okay.
[01:51:06.180 --> 01:51:07.180]   But there is-
[01:51:07.180 --> 01:51:08.860]   Did you know that just some people wouldn't know there are problems with it and talk about
[01:51:08.860 --> 01:51:10.660]   it more and then word of mouth it?
[01:51:10.660 --> 01:51:11.660]   Because-
[01:51:11.660 --> 01:51:13.220]   I think it was a sopp to people of your generation.
[01:51:13.220 --> 01:51:14.980]   Did you grow up with the Iron Giant movie?
[01:51:14.980 --> 01:51:19.700]   No, I was on the kind of like sheltered Christian side of things.
[01:51:19.700 --> 01:51:20.700]   Yeah.
[01:51:20.700 --> 01:51:22.220]   Not our Davy and Goliath.
[01:51:22.220 --> 01:51:25.380]   I was more veggie tails than anything, if you will.
[01:51:25.380 --> 01:51:26.940]   Veggie tails is weird.
[01:51:26.940 --> 01:51:30.220]   Veggie tails looking back surreal, odd at the time.
[01:51:30.220 --> 01:51:31.500]   Adorable and full fun.
[01:51:31.500 --> 01:51:32.500]   Yeah.
[01:51:32.500 --> 01:51:35.220]   It's kind of like those weird YouTube videos.
[01:51:35.220 --> 01:51:36.940]   Which veggie YouTube video?
[01:51:36.940 --> 01:51:40.180]   I think it's the inspiration for the weird kid videos on YouTube.
[01:51:40.180 --> 01:51:42.500]   Oh, they're out all the controversy a few months ago.
[01:51:42.500 --> 01:51:43.500]   Yeah.
[01:51:43.500 --> 01:51:44.500]   Yeah.
[01:51:44.500 --> 01:51:45.500]   I don't know.
[01:51:45.500 --> 01:51:48.980]   I want to talk about this, but I don't know if I should because I know you won't like
[01:51:48.980 --> 01:51:50.700]   it.
[01:51:50.700 --> 01:51:53.260]   Turns out cell phones might cause cancer after all.
[01:51:53.260 --> 01:51:57.020]   Well, what's a little concept between friends with cell phones?
[01:51:57.020 --> 01:51:58.020]   Like analog or not?
[01:51:58.020 --> 01:52:00.140]   Oh, they take cell phones.
[01:52:00.140 --> 01:52:07.620]   So this is a study from a reliable organization, the federal government, the US National Toxicology
[01:52:07.620 --> 01:52:08.620]   Program.
[01:52:08.620 --> 01:52:13.260]   It was a study design in 2009 that is concluded.
[01:52:13.260 --> 01:52:18.180]   They exposed rats for two years to cell phone radiation.
[01:52:18.180 --> 01:52:23.020]   What's weird about this is the results of the study as published said that there were
[01:52:23.020 --> 01:52:24.020]   a quivicle.
[01:52:24.020 --> 01:52:28.740]   To understand this, you need to understand how the US National Toxicology Program rates
[01:52:28.740 --> 01:52:29.740]   evidence.
[01:52:29.740 --> 01:52:32.260]   There are four different levels.
[01:52:32.260 --> 01:52:36.140]   There's no evidence, which is we can't draw any conclusion from the study.
[01:52:36.140 --> 01:52:40.860]   Equivocal evidence, which means, well, it's hard to say, some evidence and clear evidence.
[01:52:40.860 --> 01:52:46.300]   The study itself said that there were a quivicle evidence that the cell phones had caused
[01:52:46.300 --> 01:52:51.860]   tumors in the hearts of male rats and female rats.
[01:52:51.860 --> 01:52:52.860]   Yeah.
[01:52:52.860 --> 01:52:53.860]   Go ahead, Andy.
[01:52:53.860 --> 01:52:58.620]   Well, I've read the study or at least the dumb down version, but the official dumb down
[01:52:58.620 --> 01:52:59.820]   version.
[01:52:59.820 --> 01:53:05.500]   And so there's a lot of reason not to be terribly worried.
[01:53:05.500 --> 01:53:08.820]   It's a study that tells you that there should be more study.
[01:53:08.820 --> 01:53:13.620]   They tested it on male rats, female rats, male mice and female rights mice.
[01:53:13.620 --> 01:53:18.760]   They subjected us what they could only have done, which is essentially it's like being
[01:53:18.760 --> 01:53:25.700]   immersed in a bath of the type of radio signals you would expect that 2G and 3G phones, not
[01:53:25.700 --> 01:53:28.580]   4G and LTE phones emit.
[01:53:28.580 --> 01:53:33.220]   And so it's essentially like imagine you're in a, you're in a, you're in a sun bed and
[01:53:33.220 --> 01:53:37.180]   the entire instead of fluorescent tubes, it's like all one huge phone.
[01:53:37.180 --> 01:53:42.900]   They found, so they found tumors in the male rats, not significant tumors in the female
[01:53:42.900 --> 01:53:46.060]   rats or in the mice at all.
[01:53:46.060 --> 01:53:51.220]   They also found, but they also found other effects that were affecting the male rats in
[01:53:51.220 --> 01:53:53.060]   other biological ways.
[01:53:53.060 --> 01:53:59.100]   It wasn't so, and the dosage was at the maximum that is permittable.
[01:53:59.100 --> 01:54:03.700]   So it's not as though they're doing 10 times, 100 times, 1000 times the dosage.
[01:54:03.700 --> 01:54:11.380]   But the exposure was something like 10 minute intervals with an accumulation of like 9 hours
[01:54:11.380 --> 01:54:12.780]   per day.
[01:54:12.780 --> 01:54:20.340]   So we're talking about a test that is definitely applicable to male rats, not necessarily applicable
[01:54:20.340 --> 01:54:26.620]   to other rodents, but definitely says that the language as it is, is absolutely correct
[01:54:26.620 --> 01:54:32.540]   that if you're asking, did exposure to phone radiation create tumors in the test subject
[01:54:32.540 --> 01:54:35.100]   or did it not, it did.
[01:54:35.100 --> 01:54:37.740]   And should we say that it clearly created results?
[01:54:37.740 --> 01:54:41.060]   Yes, it did, as opposed to it's in some, but not others.
[01:54:41.060 --> 01:54:45.820]   No, definitely in this situation, they caused some biological badness to happen in male
[01:54:45.820 --> 01:54:51.380]   rats, but it wasn't, it wasn't enough to start people getting concerned about using their
[01:54:51.380 --> 01:54:52.380]   phones.
[01:54:52.380 --> 01:54:54.180]   So here's the thing that is interesting.
[01:54:54.180 --> 01:54:58.420]   And I think deserves more examination.
[01:54:58.420 --> 01:55:00.500]   We're going to submit this, by the way, to the FDA.
[01:55:00.500 --> 01:55:03.620]   The FDA will then decide what recommendations to make.
[01:55:03.620 --> 01:55:05.180]   That hasn't happened yet.
[01:55:05.180 --> 01:55:10.220]   The original paper as submitted and published earlier this year said the results were equivocal.
[01:55:10.220 --> 01:55:14.700]   By the way, that matches pretty much every study ever done on this, that they're really,
[01:55:14.700 --> 01:55:16.620]   it's hard to say there's a connection.
[01:55:16.620 --> 01:55:19.780]   It's equivocal means we can't, we're not sure, we don't know.
[01:55:19.780 --> 01:55:21.580]   In other words, it's non-conclusive.
[01:55:21.580 --> 01:55:23.060]   And that's what every study has said so far.
[01:55:23.060 --> 01:55:27.900]   And that's what this study said until last week, then the National Institutes of Health,
[01:55:27.900 --> 01:55:34.100]   which does a peer review session on this stuff, brought together brain and heart pathologists,
[01:55:34.100 --> 01:55:39.820]   toxicologists, bio-statisticians, s-engineers, a panel of peer reviewers, they did something
[01:55:39.820 --> 01:55:40.820]   unprecedented.
[01:55:40.820 --> 01:55:45.660]   Traditionally, typically when an NTP studies peer review like this, the peer reviews just
[01:55:45.660 --> 01:55:47.700]   say, yeah, you're right.
[01:55:47.700 --> 01:55:53.060]   At best, they might send it back and say there's some methodology issues, but they never
[01:55:53.060 --> 01:55:54.060]   upgrade.
[01:55:54.060 --> 01:55:55.420]   In this case, they upgraded.
[01:55:55.420 --> 01:56:01.340]   The peer review took equivocal and re-evaluated the data, upgraded several of the conclusions
[01:56:01.340 --> 01:56:07.300]   to some evidence and, and this is the one that's concerning, clear evidence.
[01:56:07.300 --> 01:56:12.860]   So the peer review said, you know, this, this is a good study.
[01:56:12.860 --> 01:56:15.100]   It's accurate.
[01:56:15.100 --> 01:56:21.620]   And we feel that it's significant enough that we're going to upgrade these findings.
[01:56:21.620 --> 01:56:23.220]   I don't know what to say about this.
[01:56:23.220 --> 01:56:26.420]   Well, like all I can say is I feel like it's our responsibility to bring it up because
[01:56:26.420 --> 01:56:31.380]   we have said for years, even though people have said, well, there could be, I would be
[01:56:31.380 --> 01:56:36.340]   prudent, but we've said there's never been a study after study over decades now.
[01:56:36.340 --> 01:56:39.420]   There's never been anything to say there's a link.
[01:56:39.420 --> 01:56:40.940]   This is the first time.
[01:56:40.940 --> 01:56:42.300]   And I think it's appropriate to say it.
[01:56:42.300 --> 01:56:43.860]   We should mention it.
[01:56:43.860 --> 01:56:47.180]   I had this discussion with my wife about radio waves.
[01:56:47.180 --> 01:56:51.940]   And we're talking about like how depending on the wavelength, it can interact and not
[01:56:51.940 --> 01:56:52.940]   interact with cells.
[01:56:52.940 --> 01:56:53.940]   It's not ionizing.
[01:56:53.940 --> 01:56:55.780]   This is the kind that is safer.
[01:56:55.780 --> 01:56:59.420]   But when we got to a point where I can say where I got to the point where I said, okay,
[01:56:59.420 --> 01:57:10.260]   well, I can kind of see that is that large emitting electrical equipment can cause a current
[01:57:10.260 --> 01:57:13.940]   or an electrical interference.
[01:57:13.940 --> 01:57:20.060]   So I wonder, depending on the proximity of the waves to the equipment emitting the waves,
[01:57:20.060 --> 01:57:24.500]   the equipment itself could also be doing this to the rats and not just the waves.
[01:57:24.500 --> 01:57:25.500]   Not just the waves.
[01:57:25.500 --> 01:57:30.500]   Because if the equipment is pulling a current that changes, I mean, our bodies are full
[01:57:30.500 --> 01:57:32.380]   of electrical signals.
[01:57:32.380 --> 01:57:39.340]   And if it's changing that and interacting with that through the magnetic waves or with
[01:57:39.340 --> 01:57:42.580]   a current, if you've pushed enough current through it, that could be causing some of
[01:57:42.580 --> 01:57:48.140]   the problems if it's emitting like 2G signals and stuff like that.
[01:57:48.140 --> 01:57:52.580]   I have to defer to the peer review committee and presume that these people are experts.
[01:57:52.580 --> 01:57:55.940]   And that's the kind of thing that they eliminated.
[01:57:55.940 --> 01:57:59.940]   I don't see any political gain for them to recommend this.
[01:57:59.940 --> 01:58:02.860]   In fact, I'm sure there's pressure to say otherwise, right?
[01:58:02.860 --> 01:58:03.860]   Huge.
[01:58:03.860 --> 01:58:07.300]   Because there's a huge economic incentive to say cell phones are safe.
[01:58:07.300 --> 01:58:12.700]   So I think that the other thing we know, and this is part of what you were talking about
[01:58:12.700 --> 01:58:18.660]   Wesley is that it's the inverse square law that the farther away the radiation gets,
[01:58:18.660 --> 01:58:19.660]   the source gets.
[01:58:19.660 --> 01:58:22.700]   It drops very rapidly by the inverse of the square.
[01:58:22.700 --> 01:58:26.500]   So even a foot is a significantly less exposure.
[01:58:26.500 --> 01:58:30.420]   Which means that maybe for tower workers, this could be applicable or...
[01:58:30.420 --> 01:58:35.420]   No, I remember climbing Sutra Tower, the big TV tower in San Francisco.
[01:58:35.420 --> 01:58:39.260]   An engineer took me up there and I came back down and I had white spots all over my hands
[01:58:39.260 --> 01:58:40.700]   and he said, "Oh yeah, yeah, no big deal."
[01:58:40.700 --> 01:58:42.900]   There's radiation burns in the tower.
[01:58:42.900 --> 01:58:45.780]   And he said, "We get those all the time."
[01:58:45.780 --> 01:58:51.340]   But they changed the law a month later to make you wear a metal mesh suit when you come
[01:58:51.340 --> 01:58:53.060]   up there from now on.
[01:58:53.060 --> 01:58:58.020]   So yes, proximity, the amount of power, that's a hundred thousand one, time of exposure.
[01:58:58.020 --> 01:59:00.420]   Time of exposure, all of that's relevant.
[01:59:00.420 --> 01:59:02.300]   What the FDA will recommend, I don't know.
[01:59:02.300 --> 01:59:05.020]   But I think at this point, anybody who carries a cell phone might want to...
[01:59:05.020 --> 01:59:07.180]   You shouldn't be sleeping on it.
[01:59:07.180 --> 01:59:09.060]   A lot of people take it to bed with them.
[01:59:09.060 --> 01:59:11.380]   I sleep with my phone under my pillow.
[01:59:11.380 --> 01:59:12.900]   Might be a bad idea every night.
[01:59:12.900 --> 01:59:14.460]   Might want to put it on the bedside table.
[01:59:14.460 --> 01:59:15.460]   That's far enough.
[01:59:15.460 --> 01:59:16.460]   You just need a foot or two.
[01:59:16.460 --> 01:59:18.340]   Well, don't put it next to your chest.
[01:59:18.340 --> 01:59:21.140]   Now I will never answer the phone again because I don't like to anyways.
[01:59:21.140 --> 01:59:23.740]   I'll say that I don't answer the phone but I have to put it near my head and then I'll
[01:59:23.740 --> 01:59:24.740]   die.
[01:59:24.740 --> 01:59:26.300]   Sorry, I couldn't take your call.
[01:59:26.300 --> 01:59:29.300]   I have to choose between whether I'm...
[01:59:29.300 --> 01:59:31.340]   What's going to end my life sooner?
[01:59:31.340 --> 01:59:36.620]   Exposure to the phone radiation or the lack of sleep I'm getting because I'm not using
[01:59:36.620 --> 01:59:40.420]   the sleep tracker that requires me to have the phone in the bed.
[01:59:40.420 --> 01:59:44.260]   Even then, it's not going to be a full power.
[01:59:44.260 --> 01:59:45.260]   Right.
[01:59:45.260 --> 01:59:48.820]   There's still so many questions to answer because you're right.
[01:59:48.820 --> 01:59:52.620]   Distance is the safety thing with all radiation.
[01:59:52.620 --> 01:59:54.340]   But nonetheless, you're talking about...
[01:59:54.340 --> 01:59:57.740]   So we're not really worried that much about people holding their phones against their
[01:59:57.740 --> 01:59:59.980]   heads because how often do you do that?
[01:59:59.980 --> 02:00:05.380]   But if you're carrying your phone in an inside jacket pocket, realize that the radios are
[02:00:05.380 --> 02:00:08.700]   working even when you're not having a phone call take place.
[02:00:08.700 --> 02:00:14.980]   So it's possible that if you are carrying that there for 12 to 18 hours a day over time,
[02:00:14.980 --> 02:00:19.540]   this is why scientists get grant money because these are questions you can't solve unless
[02:00:19.540 --> 02:00:21.940]   you throw lots and lots of money at grant students.
[02:00:21.940 --> 02:00:22.940]   We love cell phones.
[02:00:22.940 --> 02:00:26.420]   As much as I love cell phones, I carry several at all times.
[02:00:26.420 --> 02:00:29.780]   It's important if there is an issue, I don't want to bury it.
[02:00:29.780 --> 02:00:31.380]   I think people need to know that.
[02:00:31.380 --> 02:00:32.380]   Yeah.
[02:00:32.380 --> 02:00:33.380]   Right.
[02:00:33.380 --> 02:00:35.380]   Respond to the property.
[02:00:35.380 --> 02:00:38.860]   At the same time, you have to make sure that there's a reason why they use the language
[02:00:38.860 --> 02:00:42.660]   that they do in scientific papers because they are speaking to other scientists.
[02:00:42.660 --> 02:00:48.220]   So other scientists understand that we said that this is what happened to mice in these
[02:00:48.220 --> 02:00:49.460]   situations.
[02:00:49.460 --> 02:00:53.100]   And it's hard when you're a journalist to make sure you're not communicating.
[02:00:53.100 --> 02:00:55.540]   Scientists have demonstrated you should be careful about your cell phone.
[02:00:55.540 --> 02:01:00.100]   Like, well, no, they haven't unless you're a mouse and you're living a little house for
[02:01:00.100 --> 02:01:02.380]   which the roof is a huge cell phone.
[02:01:02.380 --> 02:01:03.380]   Then yes, definitely.
[02:01:03.380 --> 02:01:06.260]   Well, this is not a big market for radiation proof pillowcases.
[02:01:06.260 --> 02:01:09.340]   Therefore, I can keep my phone with me at all times and not worry about it.
[02:01:09.340 --> 02:01:12.300]   I would pay a lot of money for that.
[02:01:12.300 --> 02:01:13.540]   All right.
[02:01:13.540 --> 02:01:16.020]   Let's we're just close to the end of the show.
[02:01:16.020 --> 02:01:18.380]   I hear I want to make sure we get everything in.
[02:01:18.380 --> 02:01:20.180]   Oh, here's another one.
[02:01:20.180 --> 02:01:21.340]   Here's some happy news.
[02:01:21.340 --> 02:01:23.620]   I always like to end with happy news.
[02:01:23.620 --> 02:01:32.340]   The FCC has approved SpaceX's plan to launch 4,425 satellites for a broad band.
[02:01:32.340 --> 02:01:34.940]   And network that will blanket the earth in radiation.
[02:01:34.940 --> 02:01:37.620]   Yeah, I was about to say that's kind of awesome before we did the last story.
[02:01:37.620 --> 02:01:38.620]   No, I'm not sure.
[02:01:38.620 --> 02:01:40.620]   No, it's way up there.
[02:01:40.620 --> 02:01:41.620]   They're 100 miles away.
[02:01:41.620 --> 02:01:44.700]   Okay, well, think of it as like this, this new network is good.
[02:01:44.700 --> 02:01:48.540]   Silent network is going to be like a Faraday cage that protects us from space radiation.
[02:01:48.540 --> 02:01:53.540]   Until the big solar flare comes and knocks out both it and us and then kind of GGL around.
[02:01:53.540 --> 02:01:57.300]   So this is why I don't want Elon Musk to end up in a cardboard box with a tear stained
[02:01:57.300 --> 02:02:02.300]   face saying what saying bank what because I want SpaceX.
[02:02:02.300 --> 02:02:08.340]   To do this, they'll have to start launching a lot of them if they're going to get 4,425
[02:02:08.340 --> 02:02:11.340]   up.
[02:02:11.340 --> 02:02:14.140]   The part of the agreement says that they will launch at least half of these satellites
[02:02:14.140 --> 02:02:16.180]   within six years.
[02:02:16.180 --> 02:02:22.140]   So the FCC says, yeah, but you got to get 2,200 of them up quick.
[02:02:22.140 --> 02:02:26.860]   The Falcon launch, I didn't know this could carry two SpaceX test satellites for global
[02:02:26.860 --> 02:02:28.940]   broad band.
[02:02:28.940 --> 02:02:31.780]   The service is going to be called Starlink.
[02:02:31.780 --> 02:02:32.780]   That's awesome.
[02:02:32.780 --> 02:02:33.780]   I love that.
[02:02:33.780 --> 02:02:35.780]   Starlink.
[02:02:35.780 --> 02:02:39.780]   And they will be fairly high altitude at 1,150 kilometers.
[02:02:39.780 --> 02:02:40.780]   That's high, right, John?
[02:02:40.780 --> 02:02:42.340]   That's not a, but you do that.
[02:02:42.340 --> 02:02:43.940]   So you have a larger footprint.
[02:02:43.940 --> 02:02:46.300]   It's not low earth orbit.
[02:02:46.300 --> 02:02:50.180]   No, it's kind of more of a standard orbit.
[02:02:50.180 --> 02:02:59.220]   You also have to keep the satellites separated by 125 kilometers of each other.
[02:02:59.220 --> 02:03:02.660]   There are those, including people with satellites already up there who are a little concerned
[02:03:02.660 --> 02:03:07.020]   about traffic jams in space.
[02:03:07.020 --> 02:03:08.580]   Yeah.
[02:03:08.580 --> 02:03:09.580]   More junk.
[02:03:09.580 --> 02:03:15.060]   But the whole point of this is to essentially make sure that there is no corner of the planet
[02:03:15.060 --> 02:03:18.300]   that can't directly get internet.
[02:03:18.300 --> 02:03:23.020]   It differs from standard communication satellites because these are communications.
[02:03:23.020 --> 02:03:27.500]   The old way is you got communication satellites that will then downlink to a station that
[02:03:27.500 --> 02:03:30.900]   then turns it into some sort of useful broadband for where you are.
[02:03:30.900 --> 02:03:34.700]   The idea is that your phone, just like your phone, could communicate with GPS satellites
[02:03:34.700 --> 02:03:38.420]   directly will be able to communicate with this constellation directly.
[02:03:38.420 --> 02:03:46.460]   Which if Ashit Pai is really, he's making lots of happy noises about this.
[02:03:46.460 --> 02:03:48.660]   And when he makes happy noises, that could be good news.
[02:03:48.660 --> 02:03:51.060]   That could be very bad news for consumers.
[02:03:51.060 --> 02:03:57.380]   But if one of his mandates, one of his priorities really is making sure that the entire country
[02:03:57.380 --> 02:03:59.260]   every community gets access to broadband.
[02:03:59.260 --> 02:04:06.740]   This is one way to solve that without having to run cable and optical wire everywhere in
[02:04:06.740 --> 02:04:09.820]   every community where it doesn't make a financial sense.
[02:04:09.820 --> 02:04:11.740]   So I hope so.
[02:04:11.740 --> 02:04:13.900]   So actually this is low Earth orbit.
[02:04:13.900 --> 02:04:19.300]   A geostationary orbit is typically 22,000 miles up.
[02:04:19.300 --> 02:04:23.460]   So this is actually fairly low Earth orbit, 823 miles.
[02:04:23.460 --> 02:04:26.660]   And then by the way, this is only the beginning.
[02:04:26.660 --> 02:04:29.980]   The total plan is for 12,000 satellites.
[02:04:29.980 --> 02:04:32.780]   And many of them at 684 miles up.
[02:04:32.780 --> 02:04:37.820]   Well, to put that in context, there are, last night, I think there are only 1500 satellites
[02:04:37.820 --> 02:04:40.180]   total in the air operational right now.
[02:04:40.180 --> 02:04:42.140]   I saw this on total for everything.
[02:04:42.140 --> 02:04:44.020]   Oh, the animated movie.
[02:04:44.020 --> 02:04:45.020]   Yeah.
[02:04:45.020 --> 02:04:46.500]   Oh my gosh, all the space junk.
[02:04:46.500 --> 02:04:52.460]   But every time that he does a launch, in order to do the telemetry, he has to rent it
[02:04:52.460 --> 02:04:54.660]   from NASA to be able to track his satellites.
[02:04:54.660 --> 02:04:59.580]   And I'm guessing with this constellation that he'll be able to do that himself, especially
[02:04:59.580 --> 02:05:02.380]   with the accelerating of their launches.
[02:05:02.380 --> 02:05:09.980]   And then if you're talking about possibly with the point to point Earth launching with
[02:05:09.980 --> 02:05:18.900]   Falcon Heavy, not Falcon Heavy, but the BFR, that they're going to need a continuous communication
[02:05:18.900 --> 02:05:23.900]   channel when they launch from point to point, if that is indeed in their future.
[02:05:23.900 --> 02:05:27.460]   So it's advantageous for them to be able to control all that.
[02:05:27.460 --> 02:05:29.620]   So this is as much for their communications.
[02:05:29.620 --> 02:05:31.140]   It is for internet.
[02:05:31.140 --> 02:05:32.140]   Yeah.
[02:05:32.140 --> 02:05:33.140]   Interesting.
[02:05:33.140 --> 02:05:34.140]   Interesting.
[02:05:34.140 --> 02:05:39.380]   Well, I mean, you can say this is for disadvantaged nations, but it's going to be equal across
[02:05:39.380 --> 02:05:41.100]   the face of the Earth, I would guess.
[02:05:41.100 --> 02:05:43.220]   So we're going to have all the potential access.
[02:05:43.220 --> 02:05:44.740]   Well, all benefit, right?
[02:05:44.740 --> 02:05:52.140]   Well, there's problems with places like China and places like Russia where you can't just
[02:05:52.140 --> 02:05:54.140]   give them internet.
[02:05:54.140 --> 02:05:55.140]   Why not?
[02:05:55.140 --> 02:05:56.140]   They don't like that.
[02:05:56.140 --> 02:05:58.740]   They don't like their people that free access to the government.
[02:05:58.740 --> 02:06:02.860]   It doesn't like it, but I might put a dish in my backyard in Turkestan.
[02:06:02.860 --> 02:06:03.860]   Yeah.
[02:06:03.860 --> 02:06:07.340]   Yeah, but then you couldn't sell Teslas in Turkestan because I'm sure the government
[02:06:07.340 --> 02:06:11.220]   would be like, well, Elon, one man, two companies, he breaks out of laws with one, he'll be a
[02:06:11.220 --> 02:06:12.980]   lot of them import the other, right?
[02:06:12.980 --> 02:06:16.340]   I don't see them just saying when it's over China, the rules are different.
[02:06:16.340 --> 02:06:18.820]   You can't put up the, you know, the great Chinese firewall in the sky.
[02:06:18.820 --> 02:06:19.820]   I don't know.
[02:06:19.820 --> 02:06:20.820]   I hope you can.
[02:06:20.820 --> 02:06:22.340]   So what are they going to shoot them down?
[02:06:22.340 --> 02:06:25.220]   No, no, no, just ban access to them, right?
[02:06:25.220 --> 02:06:26.220]   Well, to the receivers.
[02:06:26.220 --> 02:06:27.220]   Yeah, it makes me to the receivers.
[02:06:27.220 --> 02:06:28.220]   Yeah.
[02:06:28.220 --> 02:06:29.220]   Oh, that's fine.
[02:06:29.220 --> 02:06:34.060]   Then we'll just we'll use it here and we'll beat them in the race to better.
[02:06:34.060 --> 02:06:35.060]   Great.
[02:06:35.060 --> 02:06:36.060]   Yeah.
[02:06:36.060 --> 02:06:37.060]   Yeah.
[02:06:37.060 --> 02:06:40.700]   Let's take a break in our final thoughts coming up in just a second.
[02:06:40.700 --> 02:06:41.700]   Andy, a knock out.
[02:06:41.700 --> 02:06:43.940]   Thank you for being here on your Easter Sunday.
[02:06:43.940 --> 02:06:47.180]   Did you bake a little tiny ham in your sous vide?
[02:06:47.180 --> 02:06:54.900]   No, but I had the traditional like lamb shaped cake from the 1953 Betty Crocker kit that
[02:06:54.900 --> 02:06:56.100]   my grandma used to have.
[02:06:56.100 --> 02:06:57.100]   Did you really?
[02:06:57.100 --> 02:07:02.020]   No, no, no, there was when my parents died, there was a lot of really, really brutal fighting
[02:07:02.020 --> 02:07:04.740]   over the lamb shaped mold cake mold.
[02:07:04.740 --> 02:07:10.180]   Unfortunately, my my my sister was both had more upper body strength and was far more
[02:07:10.180 --> 02:07:16.980]   wily and was able to best me for control of the lamb shaped cake, but I'm but I I she's
[02:07:16.980 --> 02:07:18.820]   she sent me pictures of the lamb.
[02:07:18.820 --> 02:07:19.820]   Good news, Andy.
[02:07:19.820 --> 02:07:21.380]   They've got him on Amazon.
[02:07:21.380 --> 02:07:23.540]   Oh, no, not not like this one.
[02:07:23.540 --> 02:07:25.540]   You could kill somebody with this one.
[02:07:25.540 --> 02:07:27.140]   This is like a 53.
[02:07:27.140 --> 02:07:28.140]   How about this?
[02:07:28.140 --> 02:07:30.620]   How about some baby bunny cake?
[02:07:30.620 --> 02:07:33.620]   Imagine an iron maiden for torturing lambs.
[02:07:33.620 --> 02:07:36.900]   That's the scale and the impressiveness of this kitchen device.
[02:07:36.900 --> 02:07:41.020]   Some Slavic retro Easter lamb cake.
[02:07:41.020 --> 02:07:43.860]   Is it a stand up lamb or is it a sit down lamb?
[02:07:43.860 --> 02:07:49.100]   It's a kneeling lamb, you know, the peaceful lamb of God that you then again, bake and then
[02:07:49.100 --> 02:07:54.180]   put frosting and sprinkles over like like like like the like Jesus himself.
[02:07:54.180 --> 02:07:56.820]   Here's a here's a cat.
[02:07:56.820 --> 02:07:59.060]   Vatican two really did change a lot of things.
[02:07:59.060 --> 02:08:02.700]   The Latin mass was only something like this looks like it.
[02:08:02.700 --> 02:08:04.260]   It's even a little rusty.
[02:08:04.260 --> 02:08:05.260]   It's something like that.
[02:08:05.260 --> 02:08:06.260]   Yes.
[02:08:06.260 --> 02:08:07.260]   What's that way?
[02:08:07.260 --> 02:08:10.020]   How much is the cake thing way?
[02:08:10.020 --> 02:08:11.020]   It's substantial.
[02:08:11.020 --> 02:08:12.980]   I think it's like four five four pounds.
[02:08:12.980 --> 02:08:13.980]   I'm like that.
[02:08:13.980 --> 02:08:16.740]   Oh, well, you hit pretty hard, but you know what?
[02:08:16.740 --> 02:08:23.140]   I have a lamb cake mold curing recipe that could save this lamb cake mold clearly needs
[02:08:23.140 --> 02:08:24.380]   saving.
[02:08:24.380 --> 02:08:26.900]   I think we should I'm going to get this for you, Andy.
[02:08:26.900 --> 02:08:27.900]   Fix it up.
[02:08:27.900 --> 02:08:28.900]   Send it off.
[02:08:28.900 --> 02:08:30.900]   Then you can say happy resurrection.
[02:08:30.900 --> 02:08:32.540]   Yeah, the lamb was resurrected.
[02:08:32.540 --> 02:08:35.700]   Oh, now we're going straight to hell.
[02:08:35.700 --> 02:08:37.820]   I've never by the way seen those before.
[02:08:37.820 --> 02:08:38.820]   Are those a thing?
[02:08:38.820 --> 02:08:42.020]   This is like kind must be a Russian slotted.
[02:08:42.020 --> 02:08:43.020]   Okay.
[02:08:43.020 --> 02:08:44.020]   All right.
[02:08:44.020 --> 02:08:47.020]   I think I think it's most often used for meats then for like savory.
[02:08:47.020 --> 02:08:49.340]   Oh, you put spice lamb in there.
[02:08:49.340 --> 02:08:50.340]   Yeah.
[02:08:50.340 --> 02:08:52.300]   You make spice lamb in the shape of a little lamb.
[02:08:52.300 --> 02:08:53.300]   Yeah.
[02:08:53.300 --> 02:08:58.660]   That's just that just feels somehow kind of weird and wrong and bad.
[02:08:58.660 --> 02:09:00.300]   And I I'm not happy.
[02:09:00.300 --> 02:09:01.300]   I don't know.
[02:09:01.300 --> 02:09:05.180]   You'd much rather you'd much rather that the kids would enjoy seeing and it is a little
[02:09:05.180 --> 02:09:10.940]   lamb being slaughtered in the in the in the drive way and then bled out hung by its back
[02:09:10.940 --> 02:09:16.060]   hooves over the next of the Cordova and then served perhaps again with a still remorseful
[02:09:16.060 --> 02:09:17.580]   tongue lolling in its face.
[02:09:17.580 --> 02:09:20.900]   We're in Petaluma have cake in Petaluma.
[02:09:20.900 --> 02:09:24.460]   There is a truck that goes around this time of year.
[02:09:24.460 --> 02:09:28.060]   It's the lamb slaughter truck and the people who raise lambs.
[02:09:28.060 --> 02:09:31.700]   The truck comes to their house in go lambs outcome chops.
[02:09:31.700 --> 02:09:32.700]   Yeah.
[02:09:32.700 --> 02:09:33.980]   And this is something we all grow up with.
[02:09:33.980 --> 02:09:35.220]   It's just part of life.
[02:09:35.220 --> 02:09:38.260]   My first year in 4-H when I sold my lamb at the end of the summer and it was going to
[02:09:38.260 --> 02:09:41.100]   be slaughtered and I just realized that I just cried for like several hours.
[02:09:41.100 --> 02:09:42.100]   Sorry.
[02:09:42.100 --> 02:09:44.380]   You're getting a manly experience of life.
[02:09:44.380 --> 02:09:45.380]   No.
[02:09:45.380 --> 02:09:47.700]   I was getting a child crying to fucking lie.
[02:09:47.700 --> 02:09:49.980]   It's going to kill fluffy.
[02:09:49.980 --> 02:09:50.980]   It's never okay.
[02:09:50.980 --> 02:09:53.740]   First thing they learned in farm country you never name your lamb.
[02:09:53.740 --> 02:09:56.740]   Yeah, my parents were not farmers so when I was doing this they did not tell me to not
[02:09:56.740 --> 02:09:57.740]   name it Winston.
[02:09:57.740 --> 02:10:00.460]   Never name anything you're going to eat.
[02:10:00.460 --> 02:10:01.460]   Don't name it.
[02:10:01.460 --> 02:10:03.500]   Did Winston at least taste good?
[02:10:03.500 --> 02:10:06.740]   No, I didn't eat Winston.
[02:10:06.740 --> 02:10:07.740]   Long story.
[02:10:07.740 --> 02:10:10.740]   I'm not going to eat details but I didn't have to eat.
[02:10:10.740 --> 02:10:11.740]   Sorry.
[02:10:11.740 --> 02:10:13.220]   I didn't mean to trigger something.
[02:10:13.220 --> 02:10:17.700]   Oh no, it's about the 4-H process and no one cares on a tech show about a farm program
[02:10:17.700 --> 02:10:18.700]   for kids.
[02:10:18.700 --> 02:10:19.700]   So I'll just let them.
[02:10:19.700 --> 02:10:20.700]   Oh, we haven't here though boy.
[02:10:20.700 --> 02:10:21.700]   Everybody here.
[02:10:21.700 --> 02:10:24.860]   Lisa's nephew raises beautiful pigs.
[02:10:24.860 --> 02:10:25.860]   Giant big sows.
[02:10:25.860 --> 02:10:26.860]   Pigs are mean.
[02:10:26.860 --> 02:10:27.860]   I'll bring you one some.
[02:10:27.860 --> 02:10:28.860]   Oh, they're not just mean.
[02:10:28.860 --> 02:10:29.860]   They're huge.
[02:10:29.860 --> 02:10:30.860]   They're huge enemies.
[02:10:30.860 --> 02:10:31.860]   It's scary.
[02:10:31.860 --> 02:10:32.860]   Yeah.
[02:10:32.860 --> 02:10:39.140]   Let's let's let's let's let's write this up with a reference to our fabulous mattress.
[02:10:39.140 --> 02:10:40.580]   You spend a third of your life.
[02:10:40.580 --> 02:10:44.140]   Maybe more in my case half my life on the mattress.
[02:10:44.140 --> 02:10:47.100]   You want to have a good mattress and I got the best.
[02:10:47.100 --> 02:10:48.540]   I got a Casper.
[02:10:48.540 --> 02:10:50.580]   Let me tell you something.
[02:10:50.580 --> 02:10:53.260]   Casper is a online.
[02:10:53.260 --> 02:10:55.420]   You're going to you're going to say no, no Leo.
[02:10:55.420 --> 02:11:01.220]   A mattress this affordable cannot be this good and I'm going to say I beg to differ because
[02:11:01.220 --> 02:11:03.140]   Casper has done something really good.
[02:11:03.140 --> 02:11:05.420]   They've eliminated the middleman.
[02:11:05.420 --> 02:11:09.060]   That means all of that, you know, the middleman and the match.
[02:11:09.060 --> 02:11:10.060]   It was funny.
[02:11:10.060 --> 02:11:12.020]   The guys who came up with Casper, they're looking around.
[02:11:12.020 --> 02:11:15.580]   They're saying what is a business that can where we're disintermediation could really
[02:11:15.580 --> 02:11:21.940]   help everybody like where is the most ridiculous markup happening and it is in the mattress
[02:11:21.940 --> 02:11:22.940]   store.
[02:11:22.940 --> 02:11:27.540]   I mean, they are and and and the sales practices.
[02:11:27.540 --> 02:11:29.220]   We're going to use car salesman.
[02:11:29.220 --> 02:11:30.460]   So you go in a mattress store.
[02:11:30.460 --> 02:11:32.540]   I know we used to do this.
[02:11:32.540 --> 02:11:36.260]   You go in, you lie in a mattress for five minutes with a sales lady looking at you like
[02:11:36.260 --> 02:11:38.380]   this and then you say, I'll take that one.
[02:11:38.380 --> 02:11:42.060]   It's the wrong I guarantee you that's the wrong mattress for you.
[02:11:42.060 --> 02:11:45.660]   What you need to do is get a match eliminate the middleman.
[02:11:45.660 --> 02:11:52.180]   So you're going to save a lot, get the mattress and sleep on it in what do they call that
[02:11:52.180 --> 02:11:53.340]   in in vitro?
[02:11:53.340 --> 02:11:54.340]   In vivo.
[02:11:54.340 --> 02:11:55.340]   In vivo.
[02:11:55.340 --> 02:11:56.340]   In vivo.
[02:11:56.340 --> 02:12:00.140]   You got to sleep on it in vivo in your life.
[02:12:00.140 --> 02:12:07.620]   And and and and experience it with all the vicissitudes of fortune, the ups, the downs,
[02:12:07.620 --> 02:12:13.500]   the ups and downs and downs and ups and all of the things that happen so that you know
[02:12:13.500 --> 02:12:16.300]   that this is the right mattress for you and you don't have to decide that in one day or
[02:12:16.300 --> 02:12:18.500]   two days or three days or a week or a month.
[02:12:18.500 --> 02:12:24.980]   You have nine, no, a hundred, a hundred days, one of three months, a hundred days of sleeping
[02:12:24.980 --> 02:12:28.220]   on this mattress to decide, is this the mattress for me and believe me?
[02:12:28.220 --> 02:12:31.980]   It is, but if for any reason you don't like it, I love Casper.
[02:12:31.980 --> 02:12:33.460]   They come, they take it away.
[02:12:33.460 --> 02:12:35.260]   They give you back every penny.
[02:12:35.260 --> 02:12:38.940]   It's as if it never happened, but you're not going to want that because you're going
[02:12:38.940 --> 02:12:41.420]   to say, no, don't take my mat.
[02:12:41.420 --> 02:12:44.020]   You can't have my mattress.
[02:12:44.020 --> 02:12:48.660]   The Casper mattress is obsessively engineered to combine multiple.
[02:12:48.660 --> 02:12:50.020]   This is the original Casper.
[02:12:50.020 --> 02:12:54.260]   The one we have combines multiple supportive memory phones for a sleep surface with just
[02:12:54.260 --> 02:12:58.460]   the right sink and just the right bounce plus it's breathable design helps you sleep cool.
[02:12:58.460 --> 02:12:59.460]   I like that.
[02:12:59.460 --> 02:13:00.460]   I don't like sleeping hot.
[02:13:00.460 --> 02:13:04.460]   It sleeps, breathes your temperatures regulated through the night.
[02:13:04.460 --> 02:13:07.100]   By the way, I've had mattresses where you have to open them up and let them lie there
[02:13:07.100 --> 02:13:09.700]   for a week, but to air out, not the Casper.
[02:13:09.700 --> 02:13:10.700]   Boom.
[02:13:10.700 --> 02:13:12.140]   It comes in a surprisingly compact box.
[02:13:12.140 --> 02:13:16.100]   You open the box, the mattress is full size, smells great.
[02:13:16.100 --> 02:13:18.500]   You can sleep on it right away and you're going to want to.
[02:13:18.500 --> 02:13:22.140]   In fact, I took a nap the first day we got it right away.
[02:13:22.140 --> 02:13:23.460]   I said, I got to sleep on this.
[02:13:23.460 --> 02:13:25.140]   It's so good.
[02:13:25.140 --> 02:13:26.140]   You could buy it online.
[02:13:26.140 --> 02:13:27.180]   It's completely risk free.
[02:13:27.180 --> 02:13:33.460]   By the way, that is true now in the US and Canada and the UK, free shipping and returns.
[02:13:33.460 --> 02:13:36.660]   They're made in the US with the highest environmental production standards.
[02:13:36.660 --> 02:13:39.340]   They're really, really great mattresses.
[02:13:39.340 --> 02:13:43.100]   You're going to get $50 towards select mattresses when you go to Casper.com/twits.
[02:13:43.100 --> 02:13:46.140]   Not only do you save by eliminating the middleman, not only do you have a great experience
[02:13:46.140 --> 02:13:49.540]   to get a great mattress, you're going to save $50 and select mattresses.
[02:13:49.540 --> 02:13:52.300]   Casper.com/twit, but you have to do this for me.
[02:13:52.300 --> 02:13:54.820]   Use the promo code TWIT at checkout.
[02:13:54.820 --> 02:13:56.420]   Some terms and conditions apply.
[02:13:56.420 --> 02:13:59.220]   Casper.com/twit, promo code TWIT.
[02:13:59.220 --> 02:14:04.140]   We ended up getting a Casper for, well, the kids when they went to college, my life felt
[02:14:04.140 --> 02:14:05.140]   so bad.
[02:14:05.140 --> 02:14:09.580]   Henry got to the dorm room and he said, "The mattress had been through several generations."
[02:14:09.580 --> 02:14:11.500]   Of college people.
[02:14:11.500 --> 02:14:12.500]   Yeah.
[02:14:12.500 --> 02:14:14.780]   He was on the second floor.
[02:14:14.780 --> 02:14:15.780]   He comes in a box.
[02:14:15.780 --> 02:14:16.780]   He got it upstairs.
[02:14:16.780 --> 02:14:18.540]   I could probably get it for me to help him.
[02:14:18.540 --> 02:14:20.500]   I said, "At the end of the four years, leave it there.
[02:14:20.500 --> 02:14:21.500]   It's okay.
[02:14:21.500 --> 02:14:22.500]   I'm not going to do it."
[02:14:22.500 --> 02:14:23.500]   I'm not going to do it.
[02:14:23.500 --> 02:14:24.500]   I'm not going to do it.
[02:14:24.500 --> 02:14:25.500]   I'm not going to do it.
[02:14:25.500 --> 02:14:26.500]   I'm not going to do it.
[02:14:26.500 --> 02:14:27.500]   I'm not going to do it.
[02:14:27.500 --> 02:14:28.500]   I'm not going to do it.
[02:14:28.500 --> 02:14:29.500]   I'm not going to do it.
[02:14:29.500 --> 02:14:30.500]   I'm not going to do it.
[02:14:30.500 --> 02:14:31.500]   I'm not going to do it.
[02:14:31.500 --> 02:14:32.500]   I'm not going to do it.
[02:14:32.500 --> 02:14:33.500]   I'm not going to do it.
[02:14:33.500 --> 02:14:34.500]   I'm not going to do it.
[02:14:34.500 --> 02:14:35.500]   I'm not going to do it.
[02:14:35.500 --> 02:14:36.500]   I'm not going to do it.
[02:14:36.500 --> 02:14:37.500]   I'm not going to do it.
[02:14:37.500 --> 02:14:38.500]   I'm not going to do it.
[02:14:38.500 --> 02:14:39.500]   I'm not going to do it.
[02:14:39.500 --> 02:14:40.500]   I'm not going to do it.
[02:14:40.500 --> 02:14:41.500]   I'm not going to do it.
[02:14:41.500 --> 02:14:42.500]   I'm not going to do it.
[02:14:42.500 --> 02:14:43.500]   I'm not going to do it.
[02:14:43.500 --> 02:14:48.020]   Hamilton was leading from the start third place.
[02:14:48.020 --> 02:14:50.700]   There was one of those slowdowns.
[02:14:50.700 --> 02:14:57.220]   They called it a virtual safety car, VSC, because one of the American team's cars,
[02:14:57.220 --> 02:14:58.220]   wheel nuts became loose.
[02:14:58.220 --> 02:15:01.300]   They took it off, and then they do a software slowdown, which is, I'd never heard of this.
[02:15:01.300 --> 02:15:02.300]   You guys are familiar with this one?
[02:15:02.300 --> 02:15:03.300]   Sounds like a governor.
[02:15:03.300 --> 02:15:04.700]   We have a formula in Austin.
[02:15:04.700 --> 02:15:05.700]   Austin?
[02:15:05.700 --> 02:15:06.700]   Yeah.
[02:15:06.700 --> 02:15:07.700]   I know.
[02:15:07.700 --> 02:15:08.700]   When is that coming up?
[02:15:08.700 --> 02:15:09.700]   It's always in the year, usually it's in the first.
[02:15:09.700 --> 02:15:11.700]   I want to be a Formula One fan, but I can't afford it.
[02:15:11.700 --> 02:15:13.300]   What does it cost you to fan?
[02:15:13.300 --> 02:15:14.300]   It costs a lot of money.
[02:15:14.300 --> 02:15:17.100]   Let's just say most people use private shoppers to get there.
[02:15:17.100 --> 02:15:18.100]   Yeah.
[02:15:18.100 --> 02:15:19.580]   It's like big bucks.
[02:15:19.580 --> 02:15:20.780]   It's not NASCAR, baby.
[02:15:20.780 --> 02:15:21.780]   Yeah.
[02:15:21.780 --> 02:15:22.780]   I just...
[02:15:22.780 --> 02:15:23.780]   We talk about it on top gears.
[02:15:23.780 --> 02:15:26.380]   I can say top, formerly the one words, but that's been all I got.
[02:15:26.380 --> 02:15:30.900]   We were when we visited Monaco, which by the way, even going to Monaco for a night is
[02:15:30.900 --> 02:15:31.900]   like you need to be...
[02:15:31.900 --> 02:15:36.660]   I mean, it's crazy, but we stayed at the hotel that's on the hairpin turn in Monaco, and
[02:15:36.660 --> 02:15:41.620]   I walked along where they go under the tunnels and said it would be so cool to see that race
[02:15:41.620 --> 02:15:42.620]   there.
[02:15:42.620 --> 02:15:47.060]   Anyway, the VSC, when it's active, the drivers have to slow down.
[02:15:47.060 --> 02:15:48.580]   They can't pass.
[02:15:48.580 --> 02:15:54.420]   They can't go below minimum times for each circuit sector, otherwise they get penalties.
[02:15:54.420 --> 02:15:57.300]   This is all because they want to keep the race state the same, right?
[02:15:57.300 --> 02:15:58.300]   Nobody passes.
[02:15:58.300 --> 02:16:00.100]   So, safety marshals have time.
[02:16:00.100 --> 02:16:04.860]   Everything's a little slower, but nobody gets to advance.
[02:16:04.860 --> 02:16:12.340]   During the VSC, the number two guy ducked into the pit lane, picked up fresh tires, and
[02:16:12.340 --> 02:16:17.460]   because the speed rules don't apply in the pit lane, he passed Hamilton.
[02:16:17.460 --> 02:16:22.300]   Hamilton said my software thought he would spend at least 15 seconds making the pit stop,
[02:16:22.300 --> 02:16:24.780]   so we allowed him to have 15 seconds.
[02:16:24.780 --> 02:16:26.300]   He got out in 11 seconds.
[02:16:26.300 --> 02:16:29.620]   He got a four second jump on the guy.
[02:16:29.620 --> 02:16:35.540]   And Hamilton said, basically, my software failed me, and I lost the race because of that.
[02:16:35.540 --> 02:16:39.700]   I would be unbelievably mad if he said it was a punch in the gut.
[02:16:39.700 --> 02:16:40.700]   Yeah.
[02:16:40.700 --> 02:16:41.700]   It was Hamilton's amazing.
[02:16:41.700 --> 02:16:42.700]   He did something weird.
[02:16:42.700 --> 02:16:46.700]   Later, he switched his engine management system into party mode.
[02:16:46.700 --> 02:16:47.700]   Yeah.
[02:16:47.700 --> 02:16:51.140]   It's not as ludicrous mode in a Tesla.
[02:16:51.140 --> 02:16:54.100]   Party mode for maximum power.
[02:16:54.100 --> 02:16:57.340]   It basically is the mode that says, okay, software, you're an idiot.
[02:16:57.340 --> 02:16:58.340]   Let me do it.
[02:16:58.340 --> 02:16:59.340]   Let me do it.
[02:16:59.340 --> 02:17:00.340]   Let me do all the decisions.
[02:17:00.340 --> 02:17:01.340]   Party mode.
[02:17:01.340 --> 02:17:02.340]   It makes me blow up the car.
[02:17:02.340 --> 02:17:03.340]   All right.
[02:17:03.340 --> 02:17:04.340]   Yeah.
[02:17:04.340 --> 02:17:09.100]   The software, I am so fascinated by the engineering of these cars, particularly all the software
[02:17:09.100 --> 02:17:15.020]   that goes into it, because this thing, it absolutely can't go 10 feet without software
[02:17:15.020 --> 02:17:16.380]   translating.
[02:17:16.380 --> 02:17:20.100]   Translating what the driver wants it to do with all of this technology that is just
[02:17:20.100 --> 02:17:21.980]   so on the edge.
[02:17:21.980 --> 02:17:25.700]   It just wants to either not run or explode.
[02:17:25.700 --> 02:17:28.580]   And without software, it will do both at the same time.
[02:17:28.580 --> 02:17:29.580]   It's amazing stuff.
[02:17:29.580 --> 02:17:31.340]   Ian Thompson wrote this article.
[02:17:31.340 --> 02:17:36.340]   Next time he's here, I'll have him explain all this Formula One stuff, but I have party
[02:17:36.340 --> 02:17:37.340]   mode.
[02:17:37.340 --> 02:17:38.340]   Yeah.
[02:17:38.340 --> 02:17:40.660]   Those cars are ridiculously expensive and sophisticated.
[02:17:40.660 --> 02:17:41.660]   It's cool.
[02:17:41.660 --> 02:17:43.860]   I mean, that's their platform for a reason.
[02:17:43.860 --> 02:17:46.580]   I mean, that's where they do all the development.
[02:17:46.580 --> 02:17:50.140]   And the reason why, I mean, look at just this picture, you can see that the sponsors,
[02:17:50.140 --> 02:17:52.140]   Armorswades, bins, and Ferrari.
[02:17:52.140 --> 02:17:53.900]   Yeah, that's their audience, right?
[02:17:53.900 --> 02:17:56.140]   That's why it's expensive, because that's their demographic.
[02:17:56.140 --> 02:17:58.700]   So they're not really catering to us, I don't think.
[02:17:58.700 --> 02:17:59.700]   All right.
[02:17:59.700 --> 02:18:03.740]   We would get like, I want a car with party mode.
[02:18:03.740 --> 02:18:05.580]   Speaking of party mode, here's the sad story.
[02:18:05.580 --> 02:18:10.140]   Of course, the Apple engineer who was driving his Model X Tesla, same model as mine, had
[02:18:10.140 --> 02:18:14.060]   the same problem I've had many times in my Model X Tesla, which is the autopilot tried
[02:18:14.060 --> 02:18:20.020]   to drive him into the side barrier, the big cement barriers that they put up during construction.
[02:18:20.020 --> 02:18:21.220]   And he complained to Tesla.
[02:18:21.220 --> 02:18:22.580]   He brought his Tesla in.
[02:18:22.580 --> 02:18:25.860]   I did the same thing because there's a curve in Marin.
[02:18:25.860 --> 02:18:27.980]   I brought mine in.
[02:18:27.980 --> 02:18:29.420]   He got the same response with Tesla.
[02:18:29.420 --> 02:18:30.420]   Nothing wrong with it.
[02:18:30.420 --> 02:18:31.920]   It's doing everything it's supposed to do.
[02:18:31.920 --> 02:18:36.480]   His mistake was he left it on and mustn't have been paying attention.
[02:18:36.480 --> 02:18:40.200]   And unfortunately, it was a kind of a double whammy because that barrier, which is supposed
[02:18:40.200 --> 02:18:45.240]   to be a crash absorption barrier, had been crashed into earlier in the week and had not
[02:18:45.240 --> 02:18:46.240]   been replaced.
[02:18:46.240 --> 02:18:47.640]   So it wasn't protecting him.
[02:18:47.640 --> 02:18:50.400]   And it's actually the worst Tesla crash I've ever seen the car just.
[02:18:50.400 --> 02:18:52.120]   Yeah, the whole front half is gone.
[02:18:52.120 --> 02:18:53.120]   Gone.
[02:18:53.120 --> 02:18:54.120]   Yeah, passed away, right?
[02:18:54.120 --> 02:18:55.120]   He passed away.
[02:18:55.120 --> 02:18:57.640]   Apple engineer, 38 years old, very sad.
[02:18:57.640 --> 02:18:59.680]   And Tesla said, yes, the autopilot was on.
[02:18:59.680 --> 02:19:01.560]   I think they kind of weaseled out a little bit.
[02:19:01.560 --> 02:19:04.680]   They said, but it told him to put his hands on the wheels, which of course it tells you
[02:19:04.680 --> 02:19:07.560]   all the time.
[02:19:07.560 --> 02:19:11.440]   I think the lesson the PSA here is they call it autopilot.
[02:19:11.440 --> 02:19:13.040]   It's not autopilot.
[02:19:13.040 --> 02:19:14.040]   It's pilot-sist.
[02:19:14.040 --> 02:19:15.040]   Exactly.
[02:19:15.040 --> 02:19:16.040]   Exactly.
[02:19:16.040 --> 02:19:19.400]   It really people had the same.
[02:19:19.400 --> 02:19:20.400]   It was it.
[02:19:20.400 --> 02:19:22.320]   This isn't just a funny story.
[02:19:22.320 --> 02:19:25.680]   With cruise control first, first of fear, people thought that, oh, I can just put cruise
[02:19:25.680 --> 02:19:28.960]   control on and then does it go into the back scene, take a nap.
[02:19:28.960 --> 02:19:32.000]   No, it's all it's going to do is maintain a speed for you.
[02:19:32.000 --> 02:19:33.000]   And that's it.
[02:19:33.000 --> 02:19:37.960]   So it's all this millions and millions of dollars going into autopilot technology.
[02:19:37.960 --> 02:19:42.160]   And so much of that money should be going into explaining to the owner what this software
[02:19:42.160 --> 02:19:44.480]   can and can't do.
[02:19:44.480 --> 02:19:50.600]   It's a dumb people are people are not dumb, but they have they're very predictable ways
[02:19:50.600 --> 02:19:52.440]   in which you can get people to screw up.
[02:19:52.440 --> 02:19:57.520]   And it's so easy, it seems to get them to not screw up by simply calling it a system
[02:19:57.520 --> 02:19:58.520]   mode.
[02:19:58.520 --> 02:20:02.160]   This is right after the Uber killing pedestrian.
[02:20:02.160 --> 02:20:04.320]   I feel like this was a bad week.
[02:20:04.320 --> 02:20:07.400]   Yeah, this was the bad week that we've been waiting for for a long time.
[02:20:07.400 --> 02:20:08.400]   This was going to happen.
[02:20:08.400 --> 02:20:09.400]   Yeah.
[02:20:09.400 --> 02:20:12.800]   I mean, if you if you push tech in this way in the real world, there will be real consequences
[02:20:12.800 --> 02:20:14.840]   and we've all known this was the bad dream.
[02:20:14.840 --> 02:20:15.840]   Did we rush it?
[02:20:15.840 --> 02:20:17.640]   Did we rush self-driving in autonomy?
[02:20:17.640 --> 02:20:21.960]   I don't think anyone else absolutely here has enough credentials to call that, but I
[02:20:21.960 --> 02:20:22.960]   think any is right.
[02:20:22.960 --> 02:20:25.040]   The answer is probably or possibly.
[02:20:25.040 --> 02:20:30.760]   I'm you're absolutely right, but I've spoken to engineers who are not comfortable with
[02:20:30.760 --> 02:20:34.080]   certain platforms being allowed on public roads.
[02:20:34.080 --> 02:20:39.280]   They're comfortable with them being allowed on controlled environments, like again, the
[02:20:39.280 --> 02:20:42.600]   test neighborhoods that they've bought and set up for the sort of thing.
[02:20:42.600 --> 02:20:48.320]   They're comfortable with these modes being used in in on highways where things are relatively
[02:20:48.320 --> 02:20:56.520]   predictable, but in the major scrum of a public street where you can have people places where
[02:20:56.520 --> 02:21:00.920]   people are would be idiots to try to cross on foot, but they do cross on foot.
[02:21:00.920 --> 02:21:07.200]   And we have people doing the most unpredictable and stupid things counting on a on a human
[02:21:07.200 --> 02:21:11.240]   driver behind them to do the right thing to preserve both their lives.
[02:21:11.240 --> 02:21:13.360]   They just don't work very, very well.
[02:21:13.360 --> 02:21:18.240]   And so it's this is the last 5% of this problem is going to take 10 years to solve.
[02:21:18.240 --> 02:21:21.520]   And that's the that's the window in which a lot of people are going to die.
[02:21:21.520 --> 02:21:26.360]   But the the the the last the last thing to say I want to say about this though is that
[02:21:26.360 --> 02:21:29.720]   people are going to get killed with human drivers as well.
[02:21:29.720 --> 02:21:35.360]   So a lot of this is again, human interface, trying to explain to people that yes, a human
[02:21:35.360 --> 02:21:38.720]   driver would not have caused this fatality.
[02:21:38.720 --> 02:21:44.940]   But this car over the 10,000 miles that it drove autonomously or with in the system mode
[02:21:44.940 --> 02:21:50.860]   save probably eight lives or collectively this fleet of vehicles saved well over 100
[02:21:50.860 --> 02:21:53.300]   more lives than they took.
[02:21:53.300 --> 02:21:57.200]   Because again, this is such a twitchy thing driving a car.
[02:21:57.200 --> 02:22:02.380]   People get hurt people get killed, but it's you feel like it's completely unsuitable when
[02:22:02.380 --> 02:22:08.660]   it wasn't a person you can blame for being distracted texting or or just not paying attention.
[02:22:08.660 --> 02:22:12.780]   It's hard when you have this black box that you don't understand at all was responsible
[02:22:12.780 --> 02:22:14.300]   for the taking of human life.
[02:22:14.300 --> 02:22:19.420]   You just you just would mentally on some level, you would much rather have 20 more people
[02:22:19.420 --> 02:22:23.860]   to die to the one person that would be killed by the autonomous car than simply accept that
[02:22:23.860 --> 02:22:26.940]   a box you don't understand took a human life.
[02:22:26.940 --> 02:22:28.540]   The question is what was it doing?
[02:22:28.540 --> 02:22:29.540]   How did the crash happen?
[02:22:29.540 --> 02:22:34.780]   I mean, did it just turn the very explaining that had veered into the barrier and I've
[02:22:34.780 --> 02:22:36.220]   had that happen with my Tesla.
[02:22:36.220 --> 02:22:39.820]   But if I actually yesterday had it go over the dotted line, which is not supposed to do
[02:22:39.820 --> 02:22:45.380]   in autopilot mode, but you learn as a dry you hope you learn and I feel bad for the driver
[02:22:45.380 --> 02:22:47.380]   in this case, not to trust the Tesla.
[02:22:47.380 --> 02:22:50.800]   You keep your hand on the wheel and if it starts doing anything weird, especially since he
[02:22:50.800 --> 02:22:54.340]   complained about it doing it in the past, you keep an eye on it and maybe don't use it
[02:22:54.340 --> 02:22:55.740]   in that stretch of the road.
[02:22:55.740 --> 02:22:57.700]   Lisa won't use the autopilot at all anymore.
[02:22:57.700 --> 02:23:00.860]   So it would be safer probably if he was in the center lane.
[02:23:00.860 --> 02:23:05.820]   Yeah, but the truth is that it has software to follow the lanes.
[02:23:05.820 --> 02:23:07.020]   It's far from perfect.
[02:23:07.020 --> 02:23:08.020]   Yeah.
[02:23:08.020 --> 02:23:11.460]   So Michael in Fast Company that I think is very interesting.
[02:23:11.460 --> 02:23:12.500]   I want to give her credit.
[02:23:12.500 --> 02:23:17.500]   This is by Ruth Reader and she raises the specter at the end of something she calls a
[02:23:17.500 --> 02:23:24.980]   flash crash in the autonomy space and actually David Soss now deserves credit for that,
[02:23:24.980 --> 02:23:26.100]   pointing that.
[02:23:26.100 --> 02:23:30.860]   In the case of high frequency training algorithms, remember the flash crash in 2010 when the
[02:23:30.860 --> 02:23:34.860]   stock market bottomed out because all of the software kind of interacted in a way that
[02:23:34.860 --> 02:23:40.300]   was disastrous, if there's a flash crash in the autonomy space space says David Soss
[02:23:40.300 --> 02:23:43.300]   now, there's no reset button the following day.
[02:23:43.300 --> 02:23:46.500]   A lot of people have died or been seamlessly injured.
[02:23:46.500 --> 02:23:48.260]   Every this is the scary thing.
[02:23:48.260 --> 02:23:51.740]   This is so hard Fox who's a co-founder of Aurora Labs.
[02:23:51.740 --> 02:23:56.580]   Every thousand lines of code in a car contains an average of 50 errors.
[02:23:56.580 --> 02:24:00.140]   Standard QA testing misses about 15% of those errors.
[02:24:00.140 --> 02:24:03.820]   That you could figure out what that leaves behind.
[02:24:03.820 --> 02:24:09.340]   Those errors are an issue and can cause in a car a death.
[02:24:09.340 --> 02:24:12.060]   So this is something we really software is not perfect.
[02:24:12.060 --> 02:24:15.300]   Seven and a half errors per thousand lines of code sounds like a lot if it's going to
[02:24:15.300 --> 02:24:18.700]   involve making decisions on the fly for me about life and death.
[02:24:18.700 --> 02:24:20.780]   But I'm not a human to make far more.
[02:24:20.780 --> 02:24:21.780]   Yeah, I'm about to say that.
[02:24:21.780 --> 02:24:25.740]   I'm not a very good driver because I'm very distracted and also I don't like driving that
[02:24:25.740 --> 02:24:26.740]   much.
[02:24:26.740 --> 02:24:29.620]   I enjoy it like maybe on a road occasionally but like no, it's I'm not good.
[02:24:29.620 --> 02:24:30.620]   I'm never going to be good.
[02:24:30.620 --> 02:24:34.500]   And as soon as this can help me not drive, the world will be safer.
[02:24:34.500 --> 02:24:35.500]   Yeah.
[02:24:35.500 --> 02:24:36.820]   So I think that's generally true.
[02:24:36.820 --> 02:24:40.740]   It's just that there might be some losses in the.
[02:24:40.740 --> 02:24:44.860]   Yeah, but you can't there's no good phrase for that in English.
[02:24:44.860 --> 02:24:51.420]   Well, a few weeks back, I'm sure you saw the Waymo 360 YouTube video and it actually
[02:24:51.420 --> 02:24:53.460]   draws lines and says what it's thinking.
[02:24:53.460 --> 02:24:54.460]   Right.
[02:24:54.460 --> 02:24:59.580]   What you're doing, which if you said your car was veering, you could use this interface
[02:24:59.580 --> 02:25:04.460]   to help kind of debug yourself, understand the patterns and be able to report that.
[02:25:04.460 --> 02:25:06.900]   And presumably collects all this information.
[02:25:06.900 --> 02:25:09.500]   Yes, but they don't expose to you in real time.
[02:25:09.500 --> 02:25:10.500]   Right.
[02:25:10.500 --> 02:25:15.420]   And so maybe you would be more vigilant if you were doing being more active in the process
[02:25:15.420 --> 02:25:17.100]   of autonomous driving, right?
[02:25:17.100 --> 02:25:22.900]   Instead of being more relaxed, you can actually say, okay, I know I'm coming up on a concrete
[02:25:22.900 --> 02:25:25.500]   barrier that has reflective tape on it.
[02:25:25.500 --> 02:25:29.660]   And every time it seems to do this, then you can you can set out these patterns on your
[02:25:29.660 --> 02:25:33.100]   own, which they don't give you this access to the do that, which is.
[02:25:33.100 --> 02:25:39.100]   That reminds me of an interview that I once read between a pilot who's talking about all
[02:25:39.100 --> 02:25:44.260]   the technology, how glass cockpits have changed the nature of flying within a certain generation
[02:25:44.260 --> 02:25:46.060]   of pilots.
[02:25:46.060 --> 02:25:49.780]   And he said that we're as historically when you think of what what makes this person a
[02:25:49.780 --> 02:25:50.780]   great pilot.
[02:25:50.780 --> 02:25:55.780]   Traditionally, this would be he's a good stick and rudder man, or she under just by feeling
[02:25:55.780 --> 02:26:01.380]   the pedals, what the feeling the pedals, what's happening with the plane, just by sensing
[02:26:01.380 --> 02:26:03.220]   what's what's around him or her.
[02:26:03.220 --> 02:26:05.140]   Here's what the plane is doing in this air.
[02:26:05.140 --> 02:26:09.900]   And now a we the definition of what what makes this person a great pilot is this person is
[02:26:09.900 --> 02:26:12.620]   a great manager of the cockpit systems.
[02:26:12.620 --> 02:26:17.540]   So it's okay if their controls are not directly controlled to any connected anything that
[02:26:17.540 --> 02:26:22.940]   is controlled to sensors that tell the computers where he wants he or she wants to go.
[02:26:22.940 --> 02:26:26.660]   This is a person that can keep an eye on these four screens, figure out what it's telling
[02:26:26.660 --> 02:26:31.380]   them about the air around them, about the performance of the airplane and use that to
[02:26:31.380 --> 02:26:33.660]   guide the computers to do their best work.
[02:26:33.660 --> 02:26:37.740]   So maybe we're looking at that where it's a new form of driving where it's not turn on
[02:26:37.740 --> 02:26:40.660]   the autopilot's going to the backseat for for a nap.
[02:26:40.660 --> 02:26:45.500]   It really is you're still driving your still your brain is still active, but rather than
[02:26:45.500 --> 02:26:49.380]   really actively keeping your car within the lane and keeping a space between yourself
[02:26:49.380 --> 02:26:53.020]   and the car ahead of you, you're managing the systems that are informing you of what's
[02:26:53.020 --> 02:26:56.020]   going on ahead and keeping you and all the other drivers safe.
[02:26:56.020 --> 02:27:02.180]   Yeah, this is that video Wesley was talking about with the yeah, it's pretty amazing what's
[02:27:02.180 --> 02:27:04.660]   what this car can do.
[02:27:04.660 --> 02:27:07.260]   But Waymo has far fewer failures.
[02:27:07.260 --> 02:27:12.660]   The Uber I saw a stat that Uber self driving car, the safety driver had to take over about
[02:27:12.660 --> 02:27:17.700]   once every 15 miles, the Waymo was more like once every 5,400 miles.
[02:27:17.700 --> 02:27:23.100]   Well, when you think about the long technology pedigree, there's Uber and then there's Google.
[02:27:23.100 --> 02:27:24.940]   And they're distinct.
[02:27:24.940 --> 02:27:30.060]   You look at how many miles each of these cars have driven you Uber is essentially a 15 and
[02:27:30.060 --> 02:27:32.100]   a half year old with the learner's permit.
[02:27:32.100 --> 02:27:36.820]   Whereas at this point, the amount of experience in terms of miles on the road, you're talking
[02:27:36.820 --> 02:27:41.360]   about collectively about a 21 22 year old still with a lot of people to a lot of things
[02:27:41.360 --> 02:27:42.500]   to learn.
[02:27:42.500 --> 02:27:49.540]   But it's why machine learning people forget that the accident is on the word learning.
[02:27:49.540 --> 02:27:52.180]   It has to learn it has to have experiences.
[02:27:52.180 --> 02:27:56.980]   And so that's why Uber I've been talking to more people than I used to since the that
[02:27:56.980 --> 02:28:03.460]   Uber crash that Uber is not very well respected, not because they don't have good people working
[02:28:03.460 --> 02:28:08.420]   on them, but because they don't have enough nearly enough experience in these a eyes to
[02:28:08.420 --> 02:28:12.760]   put it in a live fire exercise and with in a world with bicyclists in them.
[02:28:12.760 --> 02:28:13.760]   Yeah.
[02:28:13.760 --> 02:28:16.200]   Andy and I co always a pleasure.
[02:28:16.200 --> 02:28:17.680]   Thank you for taking a little extra time with us.
[02:28:17.680 --> 02:28:20.240]   We'll see you on Tuesday for Mac break weekly.
[02:28:20.240 --> 02:28:23.440]   You'll find Andy's website CWOB.com.
[02:28:23.440 --> 02:28:30.600]   He's also at an Akko I H N A T K O on the Twitter and don't forget his material podcast
[02:28:30.600 --> 02:28:31.600]   at relay.fm.
[02:28:31.600 --> 02:28:32.760]   Thank you, Andy for being here.
[02:28:32.760 --> 02:28:33.760]   Really appreciate it.
[02:28:33.760 --> 02:28:34.760]   Great to see you.
[02:28:34.760 --> 02:28:35.760]   Thanks.
[02:28:35.760 --> 02:28:37.440]   Good luck with the the lamb mold this evening.
[02:28:38.440 --> 02:28:46.200]   If she if she doesn't save me the head, there's going to be some more arguments here.
[02:28:46.200 --> 02:28:48.220]   Wesley Wagner, thank you so much for coming here.
[02:28:48.220 --> 02:28:49.220]   You got something you want to plug?
[02:28:49.220 --> 02:28:50.600]   You came all the way up from Austin.
[02:28:50.600 --> 02:28:52.100]   I'm so grateful to you.
[02:28:52.100 --> 02:28:55.560]   Yes, I came with a long laundry list of plugs.
[02:28:55.560 --> 02:28:59.420]   The first one is my one of my bosses, Joe Hill.
[02:28:59.420 --> 02:29:00.660]   Thank you for letting me come here.
[02:29:00.660 --> 02:29:01.660]   Oh, that's nice of him.
[02:29:01.660 --> 02:29:03.140]   Yeah, without him, I wouldn't be here.
[02:29:03.140 --> 02:29:04.140]   Yes.
[02:29:04.140 --> 02:29:05.140]   Thank you.
[02:29:05.140 --> 02:29:06.140]   We should have.
[02:29:06.140 --> 02:29:10.600]   Of course, my company, F S G. Thank you.
[02:29:10.600 --> 02:29:11.600]   Thank you.
[02:29:11.600 --> 02:29:14.400]   Your wife first, you're dead.
[02:29:14.400 --> 02:29:15.760]   I won an Emmy once.
[02:29:15.760 --> 02:29:17.400]   Yes, forgot to thank my wife.
[02:29:17.400 --> 02:29:18.400]   Yes, thank you.
[02:29:18.400 --> 02:29:20.920]   Never will live it down ever.
[02:29:20.920 --> 02:29:22.000]   And I'll never win another Emmy.
[02:29:22.000 --> 02:29:23.000]   So that's that.
[02:29:23.000 --> 02:29:24.000]   Yes.
[02:29:24.000 --> 02:29:25.800]   Thank you, Joe Hill.
[02:29:25.800 --> 02:29:31.280]   And our website for our company is F S G I dot com.
[02:29:31.280 --> 02:29:35.600]   So if you are if you have a building or a structure, you need solar panels, you need
[02:29:35.600 --> 02:29:38.780]   battery storage, you need smart, smart, brilliant controls.
[02:29:38.780 --> 02:29:40.740]   Oh, this is what you do.
[02:29:40.740 --> 02:29:41.740]   Yep.
[02:29:41.740 --> 02:29:45.300]   I work and there are many divisions of F S G, but I work in the energy division where
[02:29:45.300 --> 02:29:48.540]   we do controls.
[02:29:48.540 --> 02:29:50.780]   How cool is that?
[02:29:50.780 --> 02:29:53.520]   And should I get the Tesla wall battery?
[02:29:53.520 --> 02:29:54.820]   They just offered it to me.
[02:29:54.820 --> 02:29:56.300]   I have panels.
[02:29:56.300 --> 02:29:58.620]   Should I get the wall or should I call you guys and still?
[02:29:58.620 --> 02:29:59.620]   All us.
[02:29:59.620 --> 02:30:00.620]   Yeah, I think so.
[02:30:00.620 --> 02:30:01.620]   Yeah, we do mostly.
[02:30:01.620 --> 02:30:02.620]   We don't do residential.
[02:30:02.620 --> 02:30:03.620]   We do commercial.
[02:30:03.620 --> 02:30:04.620]   All right.
[02:30:04.620 --> 02:30:05.620]   I know a guy inside.
[02:30:05.620 --> 02:30:10.280]   Yeah, you can have access to our people through me.
[02:30:10.280 --> 02:30:17.640]   And I want to give a shout out to someone I also admire in the space.
[02:30:17.640 --> 02:30:18.640]   No, really.
[02:30:18.640 --> 02:30:20.000]   That's okay.
[02:30:20.000 --> 02:30:22.000]   Yeah.
[02:30:22.000 --> 02:30:23.000]   Everybody's laughing.
[02:30:23.000 --> 02:30:24.000]   Why is everybody laughing?
[02:30:24.000 --> 02:30:26.320]   His name is Brian Tom from C net.
[02:30:26.320 --> 02:30:33.840]   Yeah, he is independent now and he just launched a Patreon to continue on Apple bite as an independent.
[02:30:33.840 --> 02:30:34.840]   What a great idea.
[02:30:34.840 --> 02:30:40.980]   So if you just go to Twitter, go to Brian Tong's Twitter handle, it's a pen there.
[02:30:40.980 --> 02:30:43.440]   Contribute to his his Patreon.
[02:30:43.440 --> 02:30:45.780]   He's a he's a great guy, a great person.
[02:30:45.780 --> 02:30:46.780]   And he does really great work.
[02:30:46.780 --> 02:30:51.860]   I have a feeling we should get Brian on Mac break weekly here and give him a plug straight
[02:30:51.860 --> 02:30:53.180]   from the show.
[02:30:53.180 --> 02:30:54.660]   That's great.
[02:30:54.660 --> 02:30:55.700]   Thank you for bringing that up.
[02:30:55.700 --> 02:30:56.900]   I did not know that.
[02:30:56.900 --> 02:31:01.580]   And lastly, I am the advisor of a company called Ultimatum.
[02:31:01.580 --> 02:31:03.600]   It's to help raise money for charities.
[02:31:03.600 --> 02:31:06.640]   So if you go to your ultimatum.com, sign up.
[02:31:06.640 --> 02:31:10.080]   The beta is going to be launching later on in April.
[02:31:10.080 --> 02:31:13.140]   And we would love to have you.
[02:31:13.140 --> 02:31:15.220]   And of course, my wife and my two kids.
[02:31:15.220 --> 02:31:16.220]   Thank you for.
[02:31:16.220 --> 02:31:23.780]   Is this going to be like a crowdsourcing for political change kind of thing?
[02:31:23.780 --> 02:31:24.780]   Yes.
[02:31:24.780 --> 02:31:27.340]   More of like, if this than that.
[02:31:27.340 --> 02:31:34.240]   So if this legislation passes, then donate to this cause that'll help those people.
[02:31:34.240 --> 02:31:36.240]   What a great idea.
[02:31:36.240 --> 02:31:38.720]   It's more like a direct change for direct action.
[02:31:38.720 --> 02:31:45.840]   So if you feel really strongly against not sharing your data when you want to get a visa
[02:31:45.840 --> 02:31:51.560]   to United States, you say if this passes, give money to ACLU or whatever group that would
[02:31:51.560 --> 02:31:52.760]   help focus that.
[02:31:52.760 --> 02:31:53.760]   Nice.
[02:31:53.760 --> 02:31:56.760]   Ultimatum.com.
[02:31:56.760 --> 02:31:57.980]   And that launches in April.
[02:31:57.980 --> 02:31:59.820]   So come back in April and tell us about it.
[02:31:59.820 --> 02:32:01.820]   That's like today.
[02:32:01.820 --> 02:32:02.820]   Yes.
[02:32:02.820 --> 02:32:10.540]   I can't believe it's going to be officially launching, I think, in Collision in New Orleans
[02:32:10.540 --> 02:32:12.100]   after the end of the month.
[02:32:12.100 --> 02:32:13.100]   Great.
[02:32:13.100 --> 02:32:14.100]   Wesley, real real pleasure.
[02:32:14.100 --> 02:32:16.100]   I hope you come back next time you don't have to come on.
[02:32:16.100 --> 02:32:17.100]   All right.
[02:32:17.100 --> 02:32:18.100]   Thank you.
[02:32:18.100 --> 02:32:19.100]   Tell Joe that.
[02:32:19.100 --> 02:32:20.100]   Okay.
[02:32:20.100 --> 02:32:21.100]   I don't know who to thank for you, Alex Wilham.
[02:32:21.100 --> 02:32:22.940]   Mr. and Mrs. Wilham probably.
[02:32:22.940 --> 02:32:28.560]   And many years of veggie tales, Alex Wilham is the editor in chief at Crunchbase News.
[02:32:28.560 --> 02:32:32.760]   He owns @Alex, which is remarkable in the habit itself.
[02:32:32.760 --> 02:32:33.760]   It's a good handle.
[02:32:33.760 --> 02:32:36.800]   I'm glad I made that way around Twitter back when Funfeed was blowing up.
[02:32:36.800 --> 02:32:37.800]   Yeah.
[02:32:37.800 --> 02:32:38.800]   It was a weird error.
[02:32:38.800 --> 02:32:41.640]   You saw everybody was leaving Twitter and you thought I'd put my stake there.
[02:32:41.640 --> 02:32:42.640]   Put me on my flag.
[02:32:42.640 --> 02:32:44.480]   You know, you're lucky sometimes.
[02:32:44.480 --> 02:32:45.480]   Yeah.
[02:32:45.480 --> 02:32:46.480]   So when's the date?
[02:32:46.480 --> 02:32:47.480]   Have you said a date?
[02:32:47.480 --> 02:32:52.000]   I'll give you a month because we're on air June 2019.
[02:32:52.000 --> 02:32:53.000]   A year from June.
[02:32:53.000 --> 02:32:54.980]   Well, we were going to get engaged in June.
[02:32:54.980 --> 02:32:55.980]   We stood it earlier.
[02:32:55.980 --> 02:32:56.980]   So we're kind of keeping that.
[02:32:56.980 --> 02:32:58.580]   Your June is a good month to get married.
[02:32:58.580 --> 02:33:00.020]   I hear the weather is good in Providence.
[02:33:00.020 --> 02:33:01.020]   Oh, it is.
[02:33:01.020 --> 02:33:02.020]   Yeah.
[02:33:02.020 --> 02:33:03.020]   Yeah.
[02:33:03.020 --> 02:33:04.020]   It's going to be fun.
[02:33:04.020 --> 02:33:05.020]   It's the one month it's actually teaching.
[02:33:05.020 --> 02:33:07.260]   I just learned how to shovel snow off a walk.
[02:33:07.260 --> 02:33:09.140]   Oh, you went through four.
[02:33:09.140 --> 02:33:11.100]   Not one, not two, but four, nor Easter.
[02:33:11.100 --> 02:33:16.180]   It was a lot of snow and I learned that I don't like snow and that the East Coast is
[02:33:16.180 --> 02:33:17.180]   too cold and shouldn't exist.
[02:33:17.180 --> 02:33:18.180]   You know what I'm going to do?
[02:33:18.180 --> 02:33:21.420]   I'm going to send you a Casper for my parents' bedroom.
[02:33:21.420 --> 02:33:22.420]   They'd appreciate it.
[02:33:22.420 --> 02:33:24.420]   There's no response to that whatsoever.
[02:33:24.420 --> 02:33:27.400]   Is that what my opinion troubles some weird?
[02:33:27.400 --> 02:33:29.360]   So I'm just going to drop that.
[02:33:29.360 --> 02:33:32.040]   If you just tuned in, it makes sense, honest.
[02:33:32.040 --> 02:33:33.040]   Thank you for joining us.
[02:33:33.040 --> 02:33:34.380]   We appreciate it.
[02:33:34.380 --> 02:33:38.080]   We do tweet every Sunday afternoon, 3 p.m. Pacific, 6 p.m. Eastern time.
[02:33:38.080 --> 02:33:39.080]   Sometimes there's wine.
[02:33:39.080 --> 02:33:44.140]   If there is, I invite you to join us if you're over 21 and share.
[02:33:44.140 --> 02:33:48.220]   If you want to watch live, do join us in the chatroom at IRC.twit.tv because that's
[02:33:48.220 --> 02:33:50.240]   where all the smart kids are in the back of the class.
[02:33:50.240 --> 02:33:51.880]   Throw in spitballs and stuff.
[02:33:51.880 --> 02:33:52.880]   We love those guys.
[02:33:52.880 --> 02:33:53.880]   Thank you, chatroom.
[02:33:53.880 --> 02:33:58.160]   IRC.twit.tv, the livestreams at twitter.tv/live.
[02:33:58.160 --> 02:34:02.560]   And of course, on-demand, audio and video, everything we do at Twitter is available at
[02:34:02.560 --> 02:34:03.720]   our website.
[02:34:03.720 --> 02:34:06.760]   That's twitter.tv.
[02:34:06.760 --> 02:34:09.920]   You can find subscription links as well there.
[02:34:09.920 --> 02:34:11.880]   In fact, if you can, subscribe that way.
[02:34:11.880 --> 02:34:13.920]   You'll get it every week automatically.
[02:34:13.920 --> 02:34:16.840]   The minute it's available, you'll have it for your Monday commute.
[02:34:16.840 --> 02:34:17.840]   Thanks for being here.
[02:34:17.840 --> 02:34:18.840]   We'll see you next time.
[02:34:18.840 --> 02:34:19.840]   Another Twitter.
[02:34:19.840 --> 02:34:20.840]   Bye bye.
[02:34:20.840 --> 02:34:30.440]   [outro music]

