
[00:00:00.000 --> 00:00:05.200]   It's time for Twit this week in Tech. Great panel for you. Larry Maggot is here from connect safely.org.
[00:00:05.200 --> 00:00:10.720]   Mike Elgin from Oaxaca, Mexico. And Jason Heiner, editor-in-chief of ZDNet.
[00:00:10.720 --> 00:00:15.440]   Of course, we're going to have to talk a little bit about Elon. We'll also talk about Tesla
[00:00:15.440 --> 00:00:21.920]   self-driving, how safe it is. Apple's backing out of the Sunday ticket negotiations. Who is
[00:00:21.920 --> 00:00:30.240]   John Mastodon? And should TikTok be banned that whole lot more, including John Carmack quitting
[00:00:30.240 --> 00:00:41.280]   meta? What's up next on Twit? Podcasts you love from people you trust. This is Twit.
[00:00:47.280 --> 00:00:55.520]   This is Twit this week at Tech. Episode 906 recorded Sunday, December 18th, 2022.
[00:00:55.520 --> 00:01:02.640]   A bad year for billionaires. This week at Tech is brought to you by Stamps.com. This holiday season
[00:01:02.640 --> 00:01:09.360]   trade late nights for silent nights and get started with Stamps.com today. Sign up at Stamps.com.
[00:01:09.360 --> 00:01:14.000]   Click the microphone at the top of the page, enter the code TWIT for a special offer that includes
[00:01:14.000 --> 00:01:17.920]   a four-week trial plus free postage and a digital scale.
[00:01:17.920 --> 00:01:26.720]   And by Noom. Stay focused on what's important to you with Noom Waits psychology-based approach.
[00:01:26.720 --> 00:01:32.160]   And check out Noom's first-ever book available for pre-order, The Noom Mindset, a deep dive
[00:01:32.160 --> 00:01:38.640]   into the psychology of behavior change. Sign up for your trial at noom.com/twits.
[00:01:39.600 --> 00:01:47.280]   And by Audible. Audible lets you enjoy all of your audio entertainment in one app. Let Audible help
[00:01:47.280 --> 00:01:53.760]   you discover new ways to laugh, be inspired, or be entertained. New members can try it free
[00:01:53.760 --> 00:02:00.800]   for 30 days visit audible.com/twits or text TWIT to 500-500.
[00:02:00.800 --> 00:02:07.520]   And by World Wide Technology. An Intel with an innovative culture,
[00:02:07.520 --> 00:02:11.760]   thousands of IT engineers, application developers, unmatched labs,
[00:02:11.760 --> 00:02:16.480]   and integration centers for testing and deploying technology at scale.
[00:02:16.480 --> 00:02:22.240]   WWT helps customers bridge the gap between strategy and execution. To learn more about
[00:02:22.240 --> 00:02:27.360]   WWT visit www.wt.com/twits.
[00:02:27.360 --> 00:02:31.040]   It's time for TWIT this weekend.
[00:02:31.040 --> 00:02:37.440]   Tech the show we cover the latest tech news. Our last live show of 2022.
[00:02:37.440 --> 00:02:45.760]   Next week Christmas Day we have a very special and a very fun episode we recorded a couple of days
[00:02:45.760 --> 00:02:54.560]   ago with some of the old timers Steve Gibson, Jeff Jarvis, Doc Serals, and Paul Therott.
[00:02:54.560 --> 00:03:00.000]   Kind of a look back at the year so that'll be your Sunday next Sunday. New Year's Day will be the
[00:03:00.000 --> 00:03:06.000]   best of and then we will be back on January 8th with a new TWIT. So the last TWIT of 2022,
[00:03:06.000 --> 00:03:10.800]   well if it's the last TWIT of 2022 you know I'm gonna bring in my favorite people start with
[00:03:10.800 --> 00:03:17.040]   Mike Elgin who's joining us from Oaxaca as he's a Nomad, a Gastron Nomad.
[00:03:17.040 --> 00:03:22.480]   Yep and it's beautiful here. I'm up on a rooftop. I can see the whole city from up here.
[00:03:22.480 --> 00:03:28.320]   Oh fantastic. We were with Mike in a mirror Halloween last year, David and Dad in Oaxaca.
[00:03:28.320 --> 00:03:32.480]   It was incredible and the food was so good and we had such a good time.
[00:03:32.480 --> 00:03:38.000]   So we just finished one and and Chef Alex says hi to you and some of the other
[00:03:38.000 --> 00:03:45.760]   I want to send him my son Hank down there to apprentice with Chef because Hank as you know
[00:03:45.760 --> 00:03:50.480]   is a Twitter Chef which is not quite the same as a real world chef and I thought it'd be great
[00:03:50.480 --> 00:03:54.480]   if he could go down and that's it but he wants to do that sometimes so I would love to arrange
[00:03:54.480 --> 00:03:59.360]   that because it would be not just Chef Alex but several other chefs and others here that could
[00:03:59.360 --> 00:04:05.040]   he could apprentice with. That'd be amazing. That is wonderful. I appreciate that. Thank you.
[00:04:05.040 --> 00:04:11.440]   Also with us Larry Maggett who has quite the tale to tell this week, President and CEO of
[00:04:11.440 --> 00:04:18.240]   Safely.org. Another radio refugee. Hi Larry good to see you. Good to see you Leo.
[00:04:18.240 --> 00:04:24.320]   Everybody. And the man who elected me President of the Internet. My good friend Jason Heiner
[00:04:24.320 --> 00:04:28.080]   formerly of Tech Republic. He's now editor in chief of all of ZDnet. Hi Jason.
[00:04:28.080 --> 00:04:33.200]   Hey great to be here Leo. Always a pleasure. So not always nice to see you.
[00:04:33.200 --> 00:04:38.720]   This is this is a great time to have kind of I like to do at the end of the year kind of bring
[00:04:38.720 --> 00:04:44.080]   together people I know and love and have known for years and we get to talk about the tech news
[00:04:44.080 --> 00:04:50.080]   and God I was hoping we wouldn't have to talk about Elon Musk. I was praying this will be quick.
[00:04:53.280 --> 00:05:00.080]   By the way, Elon has inadvertently created a new hero in the world John Mastodon.
[00:05:00.080 --> 00:05:10.960]   So Elon yesterday banned any mention of Mastodon. You can't link to it. In fact when you try to link
[00:05:10.960 --> 00:05:17.200]   to it, you'll get on Twitter. You'll get oh this site is malicious and dangerous
[00:05:18.320 --> 00:05:28.320]   which it's not. Mastodon is a thousand social networks. Many Twitter refugees have fled to Mastodon.
[00:05:28.320 --> 00:05:32.880]   We've been running a Mastodon since 2019. We're one of the Mastons that is blocked.
[00:05:32.880 --> 00:05:39.040]   But there was an odd somebody wrote an article that misunderstood because one of the
[00:05:39.040 --> 00:05:46.720]   Twitter handles blocked was join Mastodon. And somehow some editorial writer thought it was
[00:05:46.720 --> 00:05:51.520]   John Mastodon and even said the founder of a competing social network has been banned.
[00:05:51.520 --> 00:05:58.240]   And ever since everybody at Mastodon has taken up the charge for John Mastodon. John Mastodon
[00:05:58.240 --> 00:06:06.640]   accounts. There's a whole legend of John Mastodon now. It's exactly how the internet should respond
[00:06:06.640 --> 00:06:13.680]   to an infection like what's happening over on Twitter. I just saw that he now Elon has banned
[00:06:13.680 --> 00:06:19.280]   Paul Graham for mentioning his Mastodon account. Paul ironically a venture capitalist founder of
[00:06:19.280 --> 00:06:24.240]   Y Combinator. Very well known in the community, beloved in the community and somebody who had been
[00:06:24.240 --> 00:06:31.600]   supporting Elon all this time. Now he's banned. Taylor Lawrence banned not much of a surprise
[00:06:31.600 --> 00:06:37.680]   along with many many other journalists. I'll be honest with you. My and maybe Mike because
[00:06:37.680 --> 00:06:43.680]   you're a journalist you can tell me I'm wrong. But who the hell cares if Twitter bans journalists
[00:06:43.680 --> 00:06:51.680]   Elon has now firmly shown this is his play thing. This is his his crib. He has the right and legal
[00:06:51.680 --> 00:06:57.440]   right to do whatever he wants for the EU to weigh in his complete nonsense for for journalists to
[00:06:57.440 --> 00:07:06.160]   whine is complete nonsense. The writing is on the wall. This is his Twitter. So yeah, move on. Right?
[00:07:06.160 --> 00:07:12.560]   Or no. Well move on. Yes. But to get reinstated is ridiculous.
[00:07:12.560 --> 00:07:20.320]   I mean journalists whether they have been banned or reinstated or not should care because many of us
[00:07:20.320 --> 00:07:27.200]   have been cultivating audiences and readership on Twitter in my case since 2007.
[00:07:27.200 --> 00:07:33.760]   Almost every day almost all day and now all of a sudden he's explicitly said that
[00:07:35.680 --> 00:07:40.720]   people have to start building credibility on the platform. I mean it's really it's you know,
[00:07:40.720 --> 00:07:48.960]   yes, it's his legally he owns it. But our relationships are not his. The connections we have with our
[00:07:48.960 --> 00:07:54.960]   readership are not his. And so it's really a bummer to start over on another platform when so many
[00:07:54.960 --> 00:07:59.680]   of us have invested so much in this platform. Well, I mean, I'm not completely immune to that.
[00:07:59.680 --> 00:08:03.040]   I have a half million more than half million followers on Twitter, but I have no problem
[00:08:04.000 --> 00:08:08.560]   leaving. I mean, that was the mistake perhaps is to say, this is our Twitter's ours. It's our
[00:08:08.560 --> 00:08:14.480]   relationships. Guess what? It never was. Maybe it looked like it was Jason. How do you feel about
[00:08:14.480 --> 00:08:20.160]   this? You're also a journalist obviously all three of you are. Yeah, you know, I will say that I
[00:08:20.160 --> 00:08:26.880]   Twitter was by far the platform that I was most engaged in for the longest time. And really in
[00:08:26.880 --> 00:08:33.040]   2018, I kind of pulled back from all social media when it became pretty clear that there wasn't
[00:08:33.040 --> 00:08:41.840]   as much value. It was it was very toxic. And so to be upfront, I have spent less and less time
[00:08:41.840 --> 00:08:48.400]   there. And it has been clear that Twitter itself was was a little bit lost in the wilderness trying
[00:08:48.400 --> 00:08:56.400]   to find its way. And now it really is sad to see what's happening. Because I think one of the things
[00:08:56.400 --> 00:09:02.240]   that is easy to forget about Twitter is that when face whatever you felt about Facebook,
[00:09:02.240 --> 00:09:07.360]   Facebook became a much more valuable company. Instagram became a rocket ship,
[00:09:07.360 --> 00:09:16.240]   TikTok, the new rocket ship. Twitter always still had some very strong brand value among
[00:09:16.240 --> 00:09:22.560]   journalists, among celebrities, mostly among those though, right? I mean, normal people didn't
[00:09:22.560 --> 00:09:29.120]   know it had no brand at all, right? For sure. But I'd say among people who were doing like Mike said,
[00:09:29.120 --> 00:09:36.560]   cultivating audiences, it had a very high brand value. And it's in a matter of 12 months,
[00:09:36.560 --> 00:09:42.000]   almost all that brand value has been destroyed. And that this is significant,
[00:09:42.000 --> 00:09:49.680]   significant destruction of value that is going to be very difficult to reestablish. Because
[00:09:49.680 --> 00:09:53.680]   you know, the old saying goes that trust comes in on foot and it goes out on horseback.
[00:09:54.640 --> 00:10:00.400]   It takes so long to build and it takes so short of a amount of time to get rid of.
[00:10:00.400 --> 00:10:06.320]   And my feeling is that, you know, Twitter for me and most of other people, it's really lost
[00:10:06.320 --> 00:10:08.720]   a lot of trust. It's going to be very difficult to reestablish.
[00:10:08.720 --> 00:10:14.480]   You know, Elon, Elon owns it. But I think your point, Jason, is fair, Mike. I mean,
[00:10:14.480 --> 00:10:22.560]   it's not exactly a public utility, I admit. But it has that flavor in the sense that we all use
[00:10:22.560 --> 00:10:27.200]   it or have used it. We all have depended on it. I mean, it's the first thing I think about,
[00:10:27.200 --> 00:10:31.760]   I've got something to say, I want to get it out there right away. You know, what other platform
[00:10:31.760 --> 00:10:36.560]   do any of us have, you know, that we can get right out, maybe you guys do it, maybe you can
[00:10:36.560 --> 00:10:40.160]   do it perhaps, but where you can, you know, three in the morning, you get an idea, you want to
[00:10:40.160 --> 00:10:45.040]   say something and you can say it. He is taking something away from all of us. Does he have the
[00:10:45.040 --> 00:10:49.760]   legal right to do it? Yes. Does he have the moral right to do it? Maybe not. And should he have
[00:10:49.760 --> 00:10:54.960]   the legal right to do it? That's actually, I guess the answer is still yes, but I think it's worth
[00:10:54.960 --> 00:11:01.920]   debating about. I think it would. Yeah. I mean, I guess it's, I think we've should,
[00:11:01.920 --> 00:11:05.920]   this is a lesson we should have learned a long time ago that these giant corporate-owned
[00:11:05.920 --> 00:11:13.200]   public forums are not ours. And they never have been ours. Mark Zuckerberg's completely in control
[00:11:13.200 --> 00:11:19.600]   of Facebook, Instagram, completely in control of it. And things happen all the time there.
[00:11:19.600 --> 00:11:26.240]   And it has been in their interest all this time to cultivate you content creators to say,
[00:11:26.240 --> 00:11:31.040]   yeah, come on, create your content. YouTube is going to be the same way. But at the ultimately,
[00:11:31.040 --> 00:11:36.640]   they control it. And it's a mistake to believe you do. And what an opportunity I think we have to
[00:11:36.640 --> 00:11:41.680]   learn here to stay away from these centralized platforms. I see so many people, so many journalists
[00:11:41.680 --> 00:11:47.600]   making the same mistake, migrating to post, which is owned by Mark Andreessen, which has,
[00:11:47.600 --> 00:11:55.280]   in its policies, you may not badmouthed billionaires. It's clearly the wrong place to go. It's the same
[00:11:55.280 --> 00:12:00.560]   lesson. And some people have not learned it. There is, I mean, this is one of the reasons why
[00:12:00.560 --> 00:12:08.160]   I think Elon is so threatened by Mastodon. Mastodon is completely decentralized. No one controls it.
[00:12:08.160 --> 00:12:11.840]   You know, it's funny, a lot of companies no longer give out their web address, they give
[00:12:11.840 --> 00:12:18.000]   out their Facebook page or their Twitter handle. I mean, technically my website is hosted by somebody,
[00:12:18.000 --> 00:12:23.920]   but I do own it. And I have control. So maybe we go a little bit back to the, you know, there was
[00:12:23.920 --> 00:12:29.520]   a reason why for years people like Kevin Marks and the indie web folks have been saying you need to
[00:12:29.520 --> 00:12:34.080]   own, I've been saying this, I've been saying this to teenagers, you need to own your presence on
[00:12:34.080 --> 00:12:41.600]   the web. You cannot let Instagram, Facebook, YouTube, TikTok, Twitter, Snapchat, tell people who you are.
[00:12:42.160 --> 00:12:47.040]   You need to do that. You need to have your own website. Is that asking too much of people?
[00:12:47.040 --> 00:12:51.120]   I don't think it's asking too much, but I would, I would encourage everyone who does own their
[00:12:51.120 --> 00:12:57.120]   own website to do what I did this afternoon, which is to remove Twitter from almost every website
[00:12:57.120 --> 00:13:02.480]   has a Twitter like go see us on Twitter. We should all remove that because, because Twitter has
[00:13:02.480 --> 00:13:07.520]   basically decided that they're not going to provide free publicity to other social networks. So
[00:13:07.520 --> 00:13:13.040]   why should we provide free publicity for Twitter? Absolutely. I have, I took Twitter off ages ago.
[00:13:13.040 --> 00:13:18.080]   If you go to my website, you'll see two links, a mastodon link and an email link. And that's it.
[00:13:18.080 --> 00:13:25.360]   Used to be, and this software allows for Facebook, Snapchat, TikTok, Twitter, but yeah,
[00:13:25.360 --> 00:13:31.280]   that's a lesson we should learn. We should take with us. If you don't own it,
[00:13:31.280 --> 00:13:36.800]   in the sense that you control what's on that platform, you're always at risk. And I think we're
[00:13:36.800 --> 00:13:39.920]   going to learn that about YouTube as well in the long run.
[00:13:39.920 --> 00:13:47.520]   And I think the future is the reason that these platforms, Web 2.0 centralized a lot of control,
[00:13:47.520 --> 00:13:51.120]   right? And what happens with central, this is good in all of human history. What happens is,
[00:13:51.120 --> 00:13:56.640]   when resources get centralized, then a very small number of people extract all the value,
[00:13:56.640 --> 00:14:01.600]   right? It makes billionaires out of people a very few number. And then everybody else
[00:14:02.800 --> 00:14:07.840]   is left fighting for the scraps. And so we've seen this time and at time again.
[00:14:07.840 --> 00:14:14.080]   I do feel like, and it is somewhat of a utopian vision, but I think we are on the direction toward
[00:14:14.080 --> 00:14:19.120]   this future of federated identity. This is what Web 3 is trying to solve,
[00:14:19.120 --> 00:14:28.320]   which is trying to create this federated identity using the blockchain for each of us to be a node
[00:14:28.320 --> 00:14:35.280]   and have a node that is not controlled. We control what information and private information we give
[00:14:35.280 --> 00:14:44.640]   to anyone we interact with. It is putting more of an onus on users. But I think that the users who are,
[00:14:44.640 --> 00:14:53.760]   call it 35 and under, they have this innate comfort with these platforms and with technology
[00:14:53.760 --> 00:15:01.600]   in the ways that they aren't scared away from this kind of idea. And so I do think it's not an
[00:15:01.600 --> 00:15:08.800]   easy road and it's not going to happen in 2022 or 2023. But I think we are on the road to a place
[00:15:08.800 --> 00:15:15.200]   where we have federated identity and Web 3, whatever you want to call it, blockchain-based
[00:15:15.200 --> 00:15:20.800]   internet that will fundamentally change the way that these things are built. And we're not going
[00:15:20.800 --> 00:15:29.280]   to fall for the promises that we did in Web 2 that essentially centralized a lot of value in a few
[00:15:29.280 --> 00:15:35.120]   hands and they extracted all of the value. And then we are left with what? Not much.
[00:15:35.120 --> 00:15:41.360]   Only thing I disagree with you on is the blockchain Web 3 thing. That's
[00:15:41.360 --> 00:15:46.800]   owned by Andreessen Horowitz. That's not as bad as anything else. But the idea, the notion of
[00:15:46.800 --> 00:15:52.480]   decentralized, Tim Berners-Lee, the promise is so geeky at this point. But Tim Berners-Lee has
[00:15:52.480 --> 00:15:58.720]   been promoting this with his solid project, solidproject.org. The idea of using Web standards,
[00:15:58.720 --> 00:16:02.560]   he's the guy who invented the worldwide Web. He's at the World Wide Web Consortium,
[00:16:02.560 --> 00:16:08.720]   using Web standards to allow people to control their data, control their privacy, control who
[00:16:08.720 --> 00:16:15.360]   they are on the internet. To me, this is a huge opportunity. If Fencer capitalists weren't so
[00:16:15.360 --> 00:16:21.520]   goddamn greedy and if it weren't dominated by billionaires who hate the idea of people controlling
[00:16:21.520 --> 00:16:26.400]   their destiny, this would already have happened. Somebody needs to step forward and make this
[00:16:26.400 --> 00:16:31.520]   possible. Gargront has done that with Mastodon, but that's just one tiny bit of a much larger ecosystem
[00:16:31.520 --> 00:16:36.640]   that could be created where you own your identity and you control it. And I think that we need to
[00:16:36.640 --> 00:16:41.360]   make this easy for everybody because otherwise they'll just keep falling into the Twitter trap.
[00:16:42.320 --> 00:16:48.480]   And the Fediverse seems to me to be perfectly unstoppable. I mean, this is something where-
[00:16:48.480 --> 00:16:53.120]   That's the irony. Elon can't buy it. No one can buy it. No one can buy it. And you just,
[00:16:53.120 --> 00:16:57.360]   you can see how it's already sort of subsuming old brands like Tumblr and
[00:16:57.360 --> 00:17:03.680]   what's that photo flicker and so on. Tumblr has joined the activity pub, which means Tumblr will be
[00:17:03.680 --> 00:17:10.400]   a peer on the Fediverse, which means you could have your presence on Tumblr, for instance,
[00:17:10.960 --> 00:17:16.240]   and absolutely. And Fediverse. I mean, you could even imagine a future because obviously Elon Musk
[00:17:16.240 --> 00:17:21.200]   is destroying Twitter and it's going to be a shell of its former self in pretty short order.
[00:17:21.200 --> 00:17:27.360]   You can imagine it changing hands and then itself becoming part of the Fediverse post Elon Musk.
[00:17:27.360 --> 00:17:31.520]   Yeah. Well, you know, it's interesting. They talk about the town square, right? The analogy
[00:17:31.520 --> 00:17:35.840]   is Twitter like the town square, but the town square is truly public property. I mean,
[00:17:35.840 --> 00:17:42.480]   that's the problem. That's why Twitter was by kind of the de facto town square isn't truly the town
[00:17:42.480 --> 00:17:49.120]   square. No, it isn't. And North Facebook for that matter, any privately owned property is not
[00:17:49.120 --> 00:17:55.440]   a town square. By definition, almost, it's public property. The municipal place that every citizen
[00:17:55.440 --> 00:18:01.200]   of that community owns. And which you could you imagine if in order for Leo, you and I decided we
[00:18:01.200 --> 00:18:05.200]   wanted to hang out together, we somehow had to get permission from some billionaires. We could
[00:18:05.200 --> 00:18:13.040]   talk to each other. One of the things perhaps that's slowing the Fediverse down is it's kind of
[00:18:13.040 --> 00:18:20.480]   built in antipathy toward brands and businesses. It is a little bit of a socialist empire.
[00:18:20.480 --> 00:18:28.480]   I think brands are starting to show up on Mastodon. News brands should be on Mastodon. A lot have
[00:18:28.480 --> 00:18:34.000]   pro public is there. A lot of there's journey.host where a lot of journalists who are refugees from
[00:18:34.000 --> 00:18:39.680]   Twitter are going. This all began, which we should probably should say, although I imagine you all
[00:18:39.680 --> 00:18:45.760]   know, when Elon claims, and by the way, there's no support for this claim, but claims that his car
[00:18:45.760 --> 00:18:53.680]   containing his child ex was jumped in Los Angeles. And that the reason it was jumped is because
[00:18:53.680 --> 00:19:00.960]   Jack Sweeney, who's a college student in Florida, has been posting the Jets location, Elon's jet
[00:19:00.960 --> 00:19:08.080]   location, along with many others, by creating a bot that republishes the AD, what is it, a DSB
[00:19:08.080 --> 00:19:16.000]   database. This database is created by airline enthusiasts who have little Raspberry Pies. I
[00:19:16.000 --> 00:19:21.520]   thought it was an official database. Your tail number is public and you have a transponder on the
[00:19:21.520 --> 00:19:28.720]   plane that is necessary so that people know who you are as you fly around. But these enthusiasts
[00:19:28.720 --> 00:19:33.040]   have been using Raspberry Pies on the ground to gather information about what's flying overhead
[00:19:33.040 --> 00:19:40.240]   and post it to this ADSB database. So there isn't a central, you know, public database for airplane
[00:19:40.240 --> 00:19:49.040]   location, but ADSB exchange exists so that people can upload and that information is really there.
[00:19:49.040 --> 00:19:55.600]   It's kind of like open, open stream map. I didn't say it's a yeah, it's a so this is one of the
[00:19:55.600 --> 00:19:59.280]   biggest of the exchange, but there are many others. This is open source intelligence,
[00:19:59.280 --> 00:20:06.800]   their public information. The planes are required by law to broadcast their exact location every
[00:20:06.800 --> 00:20:13.040]   three seconds. And it's not there. It's illegal to keep the location of an airplane secret.
[00:20:13.040 --> 00:20:21.120]   And so, you know, what's funny to me is that, you know, Elon Musk is until recently the world's
[00:20:21.120 --> 00:20:26.720]   richest person. He's obviously a public figure. He's somebody who would be the target of maybe
[00:20:26.720 --> 00:20:33.520]   foreign spies or stalkers and paparazzi and so on. Somebody like that has to have to
[00:20:33.520 --> 00:20:39.920]   hire security, do whatever they have to do to protect protect themselves. He also has the option
[00:20:39.920 --> 00:20:47.920]   if if the location of his airplane is is a security risk to not full not own an airplane, fly in
[00:20:47.920 --> 00:20:53.280]   another kind of airplane, airplane airlines, even for executives exists all the time.
[00:20:53.280 --> 00:20:59.440]   And nobody knows where, you know, which individual executive is in what plane.
[00:20:59.440 --> 00:21:04.000]   He's got a bunch of things that he can do to protect his family. And I, of course,
[00:21:04.000 --> 00:21:10.000]   I think he absolutely should protect his family, including by the way, not owning his private jet,
[00:21:10.000 --> 00:21:13.760]   but leasing it from a company so that no one would know he was on that plane.
[00:21:14.720 --> 00:21:18.560]   Exactly. There are things you can do, but he doesn't he never liked Jack Sweeney's
[00:21:18.560 --> 00:21:23.600]   Elon Tracker. Jack's tracks everybody else too, including Jeff Bezos. He never liked it.
[00:21:23.600 --> 00:21:29.920]   Always complained about it. At one point, it was said offered $5,000 to the kid to take it down.
[00:21:29.920 --> 00:21:35.760]   The kid said he never received that offer. And by the time he asked for it, Elon said, no.
[00:21:35.760 --> 00:21:41.360]   Once Elon owned Twitter was, you know, he said, I'll never take it down, but that was just a matter
[00:21:41.360 --> 00:21:46.640]   of time before he took it down. But what he did, which was a little shocking, I think, to
[00:21:46.640 --> 00:21:51.840]   journalists who thought somehow they had a right to be on Twitter, he took down any journalist
[00:21:51.840 --> 00:21:58.400]   who mentioned the existence of this, uh, Elon's jet account or that it had moved to mastodon.
[00:21:58.400 --> 00:22:02.880]   And mentioned it not even on Twitter, like they mentioned it in an article, in the news article,
[00:22:02.880 --> 00:22:08.080]   on the New York Times, and then they were banned on Twitter and everywhere else at CNN. And so he
[00:22:08.080 --> 00:22:13.440]   banned them. Now some of them I think are coming back. He had a poll. He loves these polls, which
[00:22:13.440 --> 00:22:19.520]   apparently is as far as I could tell, the stupidest thing ever, because anybody anybody can vote
[00:22:19.520 --> 00:22:26.160]   in these polls, including the Russian GRU and the internet troll factories. Anyway, he had a poll
[00:22:26.160 --> 00:22:30.400]   and said, should I bring him back at seven days? You know, I don't remember what the answer was.
[00:22:30.400 --> 00:22:36.560]   But I think he's reinstated some. But who cares? This to me is all you need to hear.
[00:22:37.680 --> 00:22:41.840]   Goodbye, Twitter. I don't understand why brands are still on Twitter. I really don't.
[00:22:41.840 --> 00:22:47.600]   You know the story about what happened to me on Monday night. What happened to you? Oh,
[00:22:47.600 --> 00:22:52.400]   actually, let's get into this. So you, uh, through connect safely.org, which you run,
[00:22:52.400 --> 00:22:58.720]   are a member, we're a member of the Twitter, uh, safety advisory council, right? That's correct.
[00:22:58.720 --> 00:23:04.080]   That's since 2016. I was actually a charter member. And we, you know, used to have meetings and we
[00:23:04.080 --> 00:23:08.960]   would give them advice and we would test out some of their safety related products and product
[00:23:08.960 --> 00:23:13.120]   changes and had productive conversations. They didn't listen to everything we had to say.
[00:23:13.120 --> 00:23:17.520]   We were not a decision making body, which is very clear. And the other thing that's very
[00:23:17.520 --> 00:23:23.600]   important is we were divided into committees. So for example, some of my colleagues on the board
[00:23:23.600 --> 00:23:29.040]   have been trolled allegedly for participating in child pornography because they didn't
[00:23:29.600 --> 00:23:35.120]   proactively do anything to take down alleged child porn on Twitter. But the fact is that none
[00:23:35.120 --> 00:23:38.880]   of these people were actually even on that committee, the people who were on the committee that dealt
[00:23:38.880 --> 00:23:43.360]   with child pornography with a national center for missing and exploited children, Thorne Foundation
[00:23:43.360 --> 00:23:49.920]   and other world rebound experts in that particular field. I am not a world or non expert on a constant
[00:23:49.920 --> 00:23:54.400]   child pornography, but we are somebody who advises on things like harassment, cyber bullying,
[00:23:54.400 --> 00:23:58.880]   stalking and all of those other things. And you were volunteers, right? Yeah, we weren't paid. And
[00:23:58.880 --> 00:24:03.360]   Twitter actually, even though we put them down as a contributor, the only money they gave
[00:24:03.360 --> 00:24:07.120]   connects safely was they gave us some advertising revenue, which is significant advertising inventory.
[00:24:07.120 --> 00:24:11.520]   So we could do ad free advertising on Twitter. So that was significant. But other than that,
[00:24:11.520 --> 00:24:15.600]   they weren't one of our more generous sponsors. And we're very public, by the way, we get money
[00:24:15.600 --> 00:24:19.920]   from Meta and Google and all these other companies. So we don't hide that.
[00:24:19.920 --> 00:24:26.400]   Did when Elon bought Twitter end of November, did anything change in that relationship?
[00:24:26.400 --> 00:24:29.600]   No, we never heard from the only thing changed, we stopped hearing from them.
[00:24:29.600 --> 00:24:33.360]   And I just about decided I just still get the ad inventory.
[00:24:33.360 --> 00:24:37.680]   Well, they didn't take it away as far as I know. It's still there. They've already given it to us.
[00:24:37.680 --> 00:24:41.200]   So we suppose it's in our account should advertise Massadon.
[00:24:41.200 --> 00:24:47.360]   Oh, you're taking that immediately. Yeah, really. So anyway, so I happen to be in
[00:24:47.360 --> 00:24:53.280]   Washington, DC on when you're at a meta safety and meta safety summit that I was speaking at.
[00:24:53.280 --> 00:24:56.400]   And eight o'clock comes along and we're having dinner with the meta folks. And I say,
[00:24:56.400 --> 00:24:59.760]   I have to excuse myself. I've got to go do this Twitter thing and everybody sort of chuckles.
[00:24:59.760 --> 00:25:04.080]   And I was a zoom a zoom call that. Yeah, zoom or something like that.
[00:25:04.080 --> 00:25:07.920]   Advisory group was going to be on. All right, so I'm walking down the streets of Washington,
[00:25:07.920 --> 00:25:12.240]   DC with my phone, I dial in, you know, through zoom and nobody's there. And I said,
[00:25:12.240 --> 00:25:16.480]   well, maybe I got the wrong link. So I go search my email and there's an email saying,
[00:25:16.480 --> 00:25:21.600]   thank you very much for your service. We no longer need you and there's no more safety advisory board.
[00:25:21.600 --> 00:25:26.480]   So this board that and what's interesting about it is it is meeting that was supposed to happen
[00:25:26.480 --> 00:25:32.880]   Monday was hastily called after some of my colleagues had resigned a couple people resigned last week
[00:25:32.880 --> 00:25:37.360]   or the week before they hastily called the meeting and they escalated it to bring in some
[00:25:37.360 --> 00:25:41.760]   of their more senior people. The I don't know if Elon was supposed to be on the call, but
[00:25:41.760 --> 00:25:45.360]   some of their more senior people were going to be on much more senior than we usually get on our
[00:25:45.360 --> 00:25:49.520]   calls, but then they just abruptly ended. So clearly they don't want to hear from us.
[00:25:49.520 --> 00:25:54.080]   They don't want our advice. I was probably going to resign any way after the meeting.
[00:25:54.080 --> 00:25:58.800]   I wanted to hear what they had to say, but now Elon can say, you can't quit. I fired you. So,
[00:25:58.800 --> 00:26:01.840]   you know, I'm no longer on the board. There is no more board.
[00:26:01.840 --> 00:26:08.960]   Elon, I also promised to create a moderation board to determine who should be brought back
[00:26:08.960 --> 00:26:14.960]   to the site and who should be. I'm not going to. And that board never happened. There was nothing
[00:26:15.520 --> 00:26:19.760]   to do. And he's making all choices at this time.
[00:26:19.760 --> 00:26:28.640]   So, okay, I mean, there's, you know, I guess my attitude, it was easy for me because I abandoned
[00:26:28.640 --> 00:26:34.320]   Twitter in my mind months ago. No, I mean, there was essentially no point in having a board to
[00:26:34.320 --> 00:26:38.320]   advise a company that's run by a guy that doesn't want to listen to anybody's advice.
[00:26:38.320 --> 00:26:39.200]   That's what you want to do.
[00:26:39.200 --> 00:26:39.840]   That's what you want to do.
[00:26:39.840 --> 00:26:40.320]   That's what you want to do.
[00:26:40.320 --> 00:26:40.800]   Yeah, that's what you want to do.
[00:26:40.800 --> 00:26:47.920]   When he left, and then of course, Elon some weeks later started to slime him with false accusations.
[00:26:47.920 --> 00:26:52.320]   A couple of my colleagues got slimed. I don't remember this guy. Some alt-right guy with a
[00:26:52.320 --> 00:26:57.760]   million followers slammed a couple of my colleagues on the board and then Elon retweeted it.
[00:26:57.760 --> 00:26:58.320]   Yeah.
[00:26:58.320 --> 00:27:03.600]   And again, blaming them for child pornography. I mean, come on. That's like QAnon crap.
[00:27:03.600 --> 00:27:08.880]   That's not as low as you could get to accuse somebody of having anything to do with child
[00:27:08.880 --> 00:27:12.560]   pornography who's completely innocent of that charge. I mean, it's a horrible thing to say about
[00:27:12.560 --> 00:27:12.560]   it.
[00:27:12.560 --> 00:27:14.800]   But it's one of Elon's favorite tactics.
[00:27:14.800 --> 00:27:16.080]   Yes, absolutely.
[00:27:16.080 --> 00:27:24.480]   Remember, Pete O'Guy, the false claim against the person rescuing the kids and all that stuff?
[00:27:24.480 --> 00:27:24.640]   Yeah.
[00:27:24.640 --> 00:27:25.280]   Terrible.
[00:27:25.280 --> 00:27:28.800]   It makes McCarthy of them look benign. I mean, it's just a horrible thing to do to somebody.
[00:27:28.800 --> 00:27:35.120]   Yeah. It strikes me that, Elon, I mean, again, it's his company. He spent a lot of money.
[00:27:35.120 --> 00:27:40.080]   He can burn it to the ground if he wants. If somebody wants to buy something and burn it,
[00:27:40.080 --> 00:27:49.040]   that's their prerogative. It strikes me that he right now likes the power that it gives him
[00:27:49.040 --> 00:27:56.880]   to wield these troll armies against whoever he feels like it. He's always felt that way, I think.
[00:27:56.880 --> 00:28:02.400]   He did that with Dogecoin. Remember, it was a magician's trick. He waved his hand and Doge
[00:28:02.400 --> 00:28:07.040]   went up, then he waved his hand and Doge went down. You experience that once and you go,
[00:28:07.040 --> 00:28:11.360]   "That's pretty cool," and you want to do it more. I feel like that's what Elon's doing now.
[00:28:11.360 --> 00:28:16.960]   I feel like anybody who continues on Twitter is merely sharpening that sword for Mr. Musk.
[00:28:16.960 --> 00:28:18.880]   But you seem to think that's a big mistake.
[00:28:18.880 --> 00:28:22.560]   He's going to pay the price, but he can afford it.
[00:28:22.560 --> 00:28:23.040]   Look, Elon...
[00:28:23.040 --> 00:28:24.160]   You saw a million to stockholders.
[00:28:24.160 --> 00:28:29.360]   Yeah. Well, maybe you should have thought twice about buying stock in Tesla.
[00:28:29.360 --> 00:28:29.840]   Maybe so.
[00:28:31.920 --> 00:28:36.240]   I think it's pretty clear that Tesla is not being run at all right now,
[00:28:36.240 --> 00:28:38.880]   and I think Tesla shareholders are suing over that as well.
[00:28:38.880 --> 00:28:44.640]   It actually bothers me. As you know, Leo, I have a Model 3, and it occurs to me because of the
[00:28:44.640 --> 00:28:52.400]   fact that this car can be controlled remotely, that a madman is capable of driving me into a cliff.
[00:28:52.400 --> 00:29:00.560]   I'm not suggesting he would do that, but it does concern me that have somebody like Elon Musk
[00:29:01.120 --> 00:29:03.200]   technically can control the car that I drive.
[00:29:03.200 --> 00:29:03.680]   Yeah.
[00:29:03.680 --> 00:29:04.960]   It makes me fair.
[00:29:04.960 --> 00:29:06.880]   It makes me think twice about whether I want to keep that car.
[00:29:06.880 --> 00:29:11.200]   The larger story to me, and it's more a political story than a tech story, although tech really
[00:29:11.200 --> 00:29:20.080]   becomes weaponized in this story, is that authoritarians and the very rich have formed an alliance,
[00:29:20.080 --> 00:29:24.480]   and maybe some cases the very rich are becoming authoritarian.
[00:29:26.000 --> 00:29:34.000]   We as the people have really got to be careful now because these tools are extremely powerful,
[00:29:34.000 --> 00:29:40.160]   and authoritarian, and authoritarian, wielding Twitter, we know this can have immense power,
[00:29:40.160 --> 00:29:42.480]   but that's only if we give it to them.
[00:29:42.480 --> 00:29:51.680]   And so I think as normal people, we got to remember, you're just helping an authoritarian.
[00:29:51.680 --> 00:29:53.600]   It's time to stop helping authoritarians.
[00:29:53.600 --> 00:29:55.440]   They're not in acting in our interest.
[00:29:55.440 --> 00:29:59.440]   That's more political, probably, than technical, but it is the case, right?
[00:29:59.440 --> 00:30:02.480]   All right.
[00:30:02.480 --> 00:30:08.800]   Anything else that you want to say about this sad person and what's happening to what's sadly
[00:30:08.800 --> 00:30:12.240]   happening to Twitter, which was a pretty cool thing at one point.
[00:30:12.240 --> 00:30:14.320]   I guess it's over.
[00:30:14.320 --> 00:30:19.360]   No, it's just upsetting to think that somebody with a big checkbook can take over an organization,
[00:30:19.360 --> 00:30:22.640]   which we all, I didn't love Twitter, but I liked Twitter.
[00:30:22.640 --> 00:30:23.360]   I used it.
[00:30:23.360 --> 00:30:24.560]   We all used it.
[00:30:24.560 --> 00:30:28.800]   And he can just arbitrarily, one man can do that just because he's got the money to do it.
[00:30:28.800 --> 00:30:30.800]   Well, it can take capitalism, my friend.
[00:30:30.800 --> 00:30:31.360]   I know.
[00:30:31.360 --> 00:30:32.560]   That's the way of the world.
[00:30:32.560 --> 00:30:34.400]   You know, it's time to open your eyes.
[00:30:34.400 --> 00:30:36.080]   Well, you know, I go back.
[00:30:36.080 --> 00:30:37.040]   I never do.
[00:30:37.040 --> 00:30:38.880]   I went to Berkeley, so I know all about that.
[00:30:38.880 --> 00:30:41.760]   I'm sympathetic.
[00:30:41.760 --> 00:30:47.440]   I wish the world were a better place, but it's pretty clear that the guy who writes the checks.
[00:30:48.640 --> 00:30:51.680]   Well, the other question that you would have bored, I mean, the Twitter board forced him to
[00:30:51.680 --> 00:30:53.760]   make the purchase when they could have backed out.
[00:30:53.760 --> 00:30:54.560]   Yeah.
[00:30:54.560 --> 00:30:56.000]   Again, they had a nice day.
[00:30:56.000 --> 00:30:57.680]   They got 5420 a share.
[00:30:57.680 --> 00:31:01.760]   By the way, Elon is now going around to friends and other investors saying, hey,
[00:31:01.760 --> 00:31:03.840]   you can buy more for 5420 a share.
[00:31:03.840 --> 00:31:04.400]   Yeah, we're right.
[00:31:04.400 --> 00:31:10.560]   Anybody there are there are people who will sign up who still have said, like, look, you know,
[00:31:10.560 --> 00:31:14.160]   Elon's created more value in these organizations.
[00:31:14.160 --> 00:31:18.800]   Now I did one of one of even his biggest fans who now I'm forgetting the name of,
[00:31:18.800 --> 00:31:23.520]   did say he'd like to see the vision for where it's going from here.
[00:31:23.520 --> 00:31:26.000]   One of his big investors, a guy who was heavily invested.
[00:31:26.000 --> 00:31:28.160]   Yeah, Ross Gerber, that's what it was.
[00:31:28.160 --> 00:31:28.160]   Yeah.
[00:31:28.160 --> 00:31:30.640]   He said, I'm not putting more money until I see the vision.
[00:31:30.640 --> 00:31:32.480]   What's the vision?
[00:31:32.480 --> 00:31:32.960]   What's the vision?
[00:31:32.960 --> 00:31:39.840]   I think it's clear that, you know, well, what is clear is that there isn't necessarily one.
[00:31:40.720 --> 00:31:47.920]   But, you know, the thing that is interesting is I believe it was at least in the last six months,
[00:31:47.920 --> 00:31:49.760]   maybe 18 months.
[00:31:49.760 --> 00:31:55.840]   I do remember Jack Dorsey saying, having a bit of a retrospective, knowing the direction that
[00:31:55.840 --> 00:32:01.520]   Twitter had gone and saying, you know, the mistake we made was going public that, and we,
[00:32:01.520 --> 00:32:06.800]   and also losing, because once we went public and then we had to create revenue to create,
[00:32:06.800 --> 00:32:11.920]   you know, to get the advertising dollars, to be a growth company and to get investors,
[00:32:11.920 --> 00:32:15.920]   you know, and that's when, remember, and I'm sure you all remember this, you know, when they,
[00:32:15.920 --> 00:32:25.200]   they banned all of the, the API, they closed down the API because Twitter was originally a bit
[00:32:25.200 --> 00:32:32.960]   more decentralized like we were talking about, and it was, it was really evolving quite powerfully.
[00:32:32.960 --> 00:32:39.680]   And the beginning of the end was, from my perspective, was when they shut off the API,
[00:32:39.680 --> 00:32:43.760]   they went public, they put all of their focus on advertising.
[00:32:43.760 --> 00:32:50.160]   And I said that, I believe I've said that in columns in the past, and it was about,
[00:32:50.160 --> 00:32:54.720]   like I said, somewhere between like six, 12, 18 months ago, then Jack Dorsey, you know,
[00:32:54.720 --> 00:32:59.840]   essentially said, you know, that's where we made the mistake, and we sort of, we, we lost control
[00:32:59.840 --> 00:33:05.840]   of this thing. And even at that time, when he said that, to me, that was him saying, you know,
[00:33:05.840 --> 00:33:10.720]   that, you know, kind of he was on his way out, and he didn't really see a great path forward for
[00:33:10.720 --> 00:33:17.440]   Twitter. And you know, it's played out. No, no one could have imagined it accelerating the demise
[00:33:17.440 --> 00:33:22.880]   of what we've seen in the last, you know, few months, but, but that was, you know, that was the,
[00:33:22.880 --> 00:33:25.920]   the exclamation point or the period on the sentence, I think.
[00:33:25.920 --> 00:33:30.480]   The thing I've found really chilling is, I think it was Kevin Russe's article in The New York Times
[00:33:30.480 --> 00:33:34.880]   saying they won't admit it, but Silicon Valley is watching what Elon does, wondering if they can
[00:33:34.880 --> 00:33:40.240]   do it with their company too. That is chilling. I think that's specifically talking about the
[00:33:40.240 --> 00:33:49.040]   layoffs, but what it really, what it really is, I think, is a lot of the, the tech CEOs are, are,
[00:33:49.040 --> 00:33:55.200]   are nervous. We know this, Amazon and Apple, especially are nervous about the employees
[00:33:55.200 --> 00:34:00.000]   standing up to them. And they're watching with great interest to see if you can beat them down
[00:34:00.000 --> 00:34:07.360]   with a stick and survive. So that was, that was a story in The New York Times this week. I was
[00:34:07.360 --> 00:34:12.160]   kind of like, well, I hope that's not a wide, a widespread point of view.
[00:34:12.160 --> 00:34:22.880]   We'll see. We'll see. I think Elon is not doing good news for himself. This was the story.
[00:34:22.880 --> 00:34:31.360]   Elon Musk management guru. Why the Twitter owners ruthless, unsparing style has made him a hero
[00:34:31.360 --> 00:34:35.360]   to many bosses in Silicon Valley. I hope Kevin is wrong on that.
[00:34:35.360 --> 00:34:39.680]   I hope that's not what he and Tim Cook talked about where they walked around, Apple Park, a couple
[00:34:39.680 --> 00:34:44.800]   of things ago. Hey, Elon, how's that working out for you? We'd like to try that here at the campus.
[00:34:44.800 --> 00:34:48.800]   And actually, you know, one of the stories we talked about on our Christmas episode,
[00:34:48.800 --> 00:34:54.320]   which is coming up Sundays, is the is the is the shift in power, I think, in tech companies,
[00:34:54.320 --> 00:34:59.360]   where engineers at Google told Google, we don't want to do you, you know, military contracts,
[00:34:59.360 --> 00:35:06.640]   Microsoft said the same problem. Employees at Apple, Starbucks, Amazon attempting to unionize,
[00:35:06.640 --> 00:35:10.000]   employees are realizing they have a little bit more power than they thought. And that's got to
[00:35:10.000 --> 00:35:17.200]   scare the C suites at these companies. So, well, I think hopefully these tech CEOs who are watching
[00:35:17.200 --> 00:35:25.200]   this will sort of revise their opinion once Elon Musk totally destroys Twitter and loses
[00:35:25.200 --> 00:35:30.080]   billions and billions of dollars, which is almost certainly going to happen. I mean, he's just failing
[00:35:30.080 --> 00:35:36.160]   in almost every way. And it's hard to imagine he's kind of turning the whole thing into Parlor.
[00:35:36.160 --> 00:35:42.480]   And, you know, how's a site like Parlor going to, you know, have advertisers and revenue and so on.
[00:35:42.480 --> 00:35:50.720]   So it's really going to be a good lesson for all the tech CEOs in some ways. Right. So,
[00:35:50.720 --> 00:35:55.280]   the other thing is that I hope the thing that I've listened from it, not the wrong lesson that
[00:35:55.280 --> 00:36:02.400]   I spend almost all my energy on Twitter criticizing Elon Musk now. So I sort of use that as a great
[00:36:02.400 --> 00:36:10.480]   place to do that. And I'm a lot of comments on his tweets. And he's got this army of trolls that's
[00:36:10.480 --> 00:36:17.440]   exactly like Donald Trump's troll. So there's certain types of people lying narcissists always
[00:36:17.440 --> 00:36:21.600]   make false claims about all the great things they're doing. And there are certain types of,
[00:36:21.600 --> 00:36:24.960]   I think it's a personality trait or something. There's just some people who believe them when
[00:36:24.960 --> 00:36:30.320]   they do that. Like they get their information about a lying narcissist from the lying narcissist.
[00:36:30.320 --> 00:36:35.200]   And so people are like, oh, he's fixing everything. Well, he's what he's doing is he's destroying
[00:36:35.200 --> 00:36:41.440]   a feature that Twitter had already. And then he's replacing it with a worse one. And this is true
[00:36:41.440 --> 00:36:47.120]   and almost everything from verification to everything else. And so it's just like it has that sort of
[00:36:47.120 --> 00:36:52.880]   like that 2016 kind of feeling these arguments I'm having with these Twitter accounts that are
[00:36:52.880 --> 00:36:58.480]   one month old have zero followers, no profile picture and a fake name, right? Millions of these
[00:36:58.480 --> 00:37:04.160]   accounts are on there all supporting Elon Musk. So it's just a, it's just become a weird place.
[00:37:04.160 --> 00:37:13.280]   And I still find it to poke fun at Elon Musk on his own thread. So yeah, I
[00:37:13.280 --> 00:37:20.560]   prefer to just leave him alone to his own devices. By the way, I have to announce as of this minute,
[00:37:20.560 --> 00:37:25.520]   I just I just refreshed my supporter page of Connect Safely and Twitter's logo was no longer
[00:37:25.520 --> 00:37:28.800]   on it. My associate must have taken it down. You're on the hair.
[00:37:28.800 --> 00:37:34.480]   Talking is it? Oh, nice. Let's get that off of it. I took it off on my sites actually while we
[00:37:34.480 --> 00:37:43.120]   were here. There's some serious concerns. There's the trusted safety. People are gone. So are the
[00:37:43.120 --> 00:37:48.960]   CSAM people. There's some concern about Twitter's ability to block CSAM, let alone it's desire to
[00:37:48.960 --> 00:37:53.760]   do so. So I think that's probably appropriate to for. Oh, yeah. No, the problem. I mean,
[00:37:53.760 --> 00:37:58.240]   there are reports of increased hate speech. I mean, there's all sorts of reports of things
[00:37:58.240 --> 00:38:03.200]   happening on Twitter that are negative. And he's banning journalists, yet leaving
[00:38:03.200 --> 00:38:09.600]   along the trolls. And as we pointed out earlier, the box are still there as well. So he's going
[00:38:09.600 --> 00:38:15.840]   after the wrong people. All right, enough of that. We're going to move on. But as little as I want
[00:38:15.840 --> 00:38:21.280]   to talk about this, and I know as much as you guys want us to not talk about it, it's kind of
[00:38:21.280 --> 00:38:26.000]   important stuff going on. And I don't think we can. It looks like Trump. You know, it's should we,
[00:38:26.800 --> 00:38:31.920]   a lot of media people are accepting some blame for putting Trump on the front page day after day
[00:38:31.920 --> 00:38:35.520]   after day. Right. Yet how do you ignore it? I mean, how do you not cover a train wreck,
[00:38:35.520 --> 00:38:42.240]   which, you know, I guess this is what I'm trying to say is, okay, it's over. Twitter's dead.
[00:38:42.240 --> 00:38:49.600]   Elon's dead to me. Let's move on. The problem is nobody wants to move on. Everybody wants to
[00:38:49.600 --> 00:38:53.440]   have their Twitter account. I still have people in this company. I would love to tell my
[00:38:54.400 --> 00:39:00.720]   marketing team to stop using Twitter. But, you know, it's impossible to get people to move on.
[00:39:00.720 --> 00:39:06.800]   So as long as people continue to try to, I don't know what, save Twitter, participate in the
[00:39:06.800 --> 00:39:10.720]   dumpster fire, I don't know what it is, I guess we'll have to cover it. I would love to see it.
[00:39:10.720 --> 00:39:15.040]   That's irrelevant. Just, I mean, we don't talk about 4chan. It's irrelevant.
[00:39:15.040 --> 00:39:23.280]   But all my, you know, the people I know are not on 4chan. That's the difference. And with Facebook,
[00:39:23.280 --> 00:39:29.920]   we went through this. I left Facebook a few years ago. But what I left was all my family and friends
[00:39:29.920 --> 00:39:35.280]   who don't use anything but Facebook. That's what I left. And so, in the case of Twitter,
[00:39:35.280 --> 00:39:43.360]   it's easier because a lot of my readership and followers and so on have moved to Massadon,
[00:39:43.360 --> 00:39:49.040]   which is great. With Facebook, that way, you know, it's harder to get, you know, your grandma or
[00:39:49.040 --> 00:39:53.440]   somebody like that to move to another social network just because you did. So when I was like,
[00:39:53.440 --> 00:39:56.640]   come on, everybody, let's all leave Facebook. And then nobody did. Just think.
[00:39:56.640 --> 00:40:04.160]   Fortunately, it's if grandma does not use Twitter. No, she does not.
[00:40:04.160 --> 00:40:11.600]   Really, the, I think the real problem is people are addicted. I mean, like, almost physically
[00:40:11.600 --> 00:40:18.720]   addicted to the churn of Twitter and. Massadon is just as addictive. It's the same.
[00:40:19.680 --> 00:40:23.120]   It's going to be a little dynamics. Yeah, exactly. I'm not. I'm not. I'm not. I'm not
[00:40:23.120 --> 00:40:28.240]   a little offensive. That's my point. Go to if you're addicted to Twitter, go, go be addicted
[00:40:28.240 --> 00:40:34.080]   to Massadon instead. You need that. Dorphin hit. You won't get the big outrage arguments, though.
[00:40:34.080 --> 00:40:39.440]   It's not like methadone, right? Yeah, it's methadone. Exactly. It's Twitter without the high.
[00:40:39.440 --> 00:40:42.480]   Right. Yeah. Exactly. Yeah. Yeah. Yeah.
[00:40:42.480 --> 00:40:47.520]   Our show. Let's take a little break. We'll come back with more in just a bit. No more Elon.
[00:40:48.240 --> 00:40:54.480]   Or Twitter. And well, one more thing. There are people that the people in chat was that Twitter
[00:40:54.480 --> 00:41:02.000]   is not dead. Is Twitter not dead? Let me go to Twitter and find out.
[00:41:02.000 --> 00:41:09.040]   It has a good story. But yeah, I guess it could come back. Elon's now acting all contrite, saying
[00:41:09.040 --> 00:41:13.360]   he just posted this a couple of minutes ago. Going forward, there'll be a vote for major policy
[00:41:13.360 --> 00:41:19.840]   changes. My apologies won't happen again. A vote. You mean like a poll on Twitter? Oh, that's good.
[00:41:19.840 --> 00:41:27.120]   That's good. I appreciate it. I mean, my space is still alive. Yeah, that's right. It'll be a lot.
[00:41:27.120 --> 00:41:32.240]   It'll be alive like my space is alive. Just put it on the Fediverse. Yeah, they should.
[00:41:32.240 --> 00:41:37.680]   They would be involved. I think I'm going to buy it. If I had a couple of billion dollars,
[00:41:37.680 --> 00:41:42.160]   I might put a bit on it. And Elon'd be so glad to get out of the promise. There's debt.
[00:41:42.720 --> 00:41:48.000]   And you can't buy two bucks because there's 13 billion dollars in debt. What are you going to do
[00:41:48.000 --> 00:41:53.120]   about that? Right. That's the problem. That's not going away. And even if I get a two billion,
[00:41:53.120 --> 00:41:58.560]   the number one debtor is the Saudi sovereign fund. And you don't want to cross MBS.
[00:41:58.560 --> 00:42:03.280]   I hear he can be very angry. Nor do you want to write him a check either. Well, yeah.
[00:42:03.280 --> 00:42:08.800]   Yeah. Either one. Yeah. Right. Our show today brought to you by Stamps.com.
[00:42:08.800 --> 00:42:14.960]   Oh, it is the season to be jolly, but not to go to the post office.
[00:42:14.960 --> 00:42:22.160]   If you're a small business, it's hard because the post office is full of wonderful,
[00:42:22.160 --> 00:42:30.400]   cheerful people with arms full of gifts. They're mailing and those long lines are going to slow
[00:42:30.400 --> 00:42:34.000]   you down. The good news is if you're a small business, you don't have to
[00:42:34.960 --> 00:42:41.440]   slay through the traffic to the post office. If your inbox is more like a blizzard than a
[00:42:41.440 --> 00:42:45.040]   winter wonderland, are you rushing to send cards and gifts to your loyal clients?
[00:42:45.040 --> 00:42:53.040]   Don't you don't have to go to the post office. Go to stamps.com. It is not too late to get your
[00:42:53.040 --> 00:42:58.400]   holiday mailing and shipping under control with stamps.com. There's no lines. There's no lines.
[00:42:58.400 --> 00:43:02.560]   Sign up now. You'll be printing your own postage in minutes. There's no postage made or no
[00:43:02.560 --> 00:43:08.800]   special link. Just your computer, your printer and stamps.com. How do I know? We've been using it
[00:43:08.800 --> 00:43:13.920]   for more than a decade now. In fact, stamps.com has been advertising on our show since 2012,
[00:43:13.920 --> 00:43:20.400]   which means I'm wondering if you've heard me talk about it for 10 years and you still haven't
[00:43:20.400 --> 00:43:27.440]   tried it. What are you waiting for? This is the time your 24/7 post office right at your desk.
[00:43:27.440 --> 00:43:31.760]   Stamps.com. And by the way, it's more than just the US Postal Service. This is something that
[00:43:31.760 --> 00:43:36.640]   happened just this year. I'm so excited about it. For more than 20 years, stamps.com has been
[00:43:36.640 --> 00:43:41.120]   indispensable for over a million businesses using it to conduct business with the US Postal Service.
[00:43:41.120 --> 00:43:50.080]   Well, now you get the US Postal Service and UPS. UPS. So everything you need for all your mailing
[00:43:50.080 --> 00:43:54.960]   and shipping is right there at your desk, your computer. No lines, no traffic, no hassle.
[00:43:54.960 --> 00:44:00.240]   And I love it because stamps.com has arranged major discounts with both services that you can't
[00:44:00.240 --> 00:44:09.840]   get at the post office. UPS and USPS rates up to 86% off. I think stamps.com is great. A stress-free
[00:44:09.840 --> 00:44:15.760]   solution for every small business. So use it. Use it. Stamps.com. We do for goodness sakes.
[00:44:15.760 --> 00:44:22.080]   Stamps.com. You could print postage right on the envelope if you want your pre- your logo. It
[00:44:22.080 --> 00:44:26.800]   fills in the return address. It'll even take the sender's address from your website. So if you're
[00:44:26.800 --> 00:44:32.160]   on eBay, Etsy, Amazon, if you're a seller there, you don't even have to fill out anything. It'll fill
[00:44:32.160 --> 00:44:38.800]   out overseas international mailing forms. It'll fill out, you know, certify me all the different
[00:44:38.800 --> 00:44:45.200]   forms. It fills out automatically, customs forms from the website, right? And when it's time for
[00:44:45.200 --> 00:44:51.440]   the package pickup, you just push a button on your dashboard. An official, a uniformed
[00:44:52.240 --> 00:44:57.680]   official with the United States government, aka your mail carrier, will come or the guy in the
[00:44:57.680 --> 00:45:02.000]   brown shorts from UPS will come and they'll pick it up. They'll take it. You don't have to ever get
[00:45:02.000 --> 00:45:06.240]   up from your desk. One other thing I love about stamps.com, rates are constantly changing. It's
[00:45:06.240 --> 00:45:10.640]   very hard to keep track of who's going to be the best person to use. With stamps.com, switch and
[00:45:10.640 --> 00:45:17.120]   save feature. You can easily compare carriers and rates. So you know you're getting the best deal
[00:45:17.120 --> 00:45:22.800]   every time. And I love this feature. When you're mailing something and stamps.com says, "Oh, is that
[00:45:22.800 --> 00:45:26.240]   a book? You could do it media mail? They'll save you money." That makes suggestions to save you money.
[00:45:26.240 --> 00:45:30.400]   You even get a scale so you know exactly how much it's going to cost. You always print exactly
[00:45:30.400 --> 00:45:34.640]   the right postage. And it looks so much more professional. I can't tell you how many times
[00:45:34.640 --> 00:45:40.720]   I've got a netsy package that's tied up with brown twine and brown paper and somebody's stuck
[00:45:40.720 --> 00:45:47.040]   like 30 stamps onto the front of it. That is not a good, I guess maybe you want to look at really
[00:45:47.040 --> 00:45:53.440]   kind of down home. But it's not the most professional look. And it's also happened many times to me.
[00:45:53.440 --> 00:45:57.760]   Postage do not with stamps.com. You got the scale. You always have exact, you don't pay
[00:45:57.760 --> 00:46:02.240]   up any more or less than you have to. If you're working in an online store,
[00:46:02.240 --> 00:46:09.760]   like I said, Amazon Etsy eBay, it works seamlessly with all the major shopping carts and marketplaces.
[00:46:09.760 --> 00:46:15.040]   Saves you time, saves you typing. Makes it very easy and very professional. Really, really professional.
[00:46:15.600 --> 00:46:22.080]   This holiday season trade late nights for silent nights. Get started with stamps.com today.
[00:46:22.080 --> 00:46:27.680]   Sign up with our promo code TWIT. You'll get a special offer. It's four weeks of stamps.com,
[00:46:27.680 --> 00:46:33.040]   a four week trial, free postage that you can use over a period of times. I think it's a significant
[00:46:33.040 --> 00:46:37.760]   amount of free postage. You'll get that free USB scale so you know exactly what you're sending.
[00:46:37.760 --> 00:46:43.840]   No long term commitments, no contracts. All you have to do, go to stamps.com. There's a
[00:46:43.840 --> 00:46:48.480]   microphone in the upper right hand corner. It says, "Hurt it on a podcast." You click that
[00:46:48.480 --> 00:46:53.200]   and you enter TWIT. Immediately, you'll see what a great deal we have for you.
[00:46:53.200 --> 00:46:58.720]   Four week trial, free postage, free digital scale, no long term commitment. Stamps.com.
[00:46:58.720 --> 00:47:03.760]   I cannot recommend it more highly. It's just the best. We couldn't live without it these days.
[00:47:03.760 --> 00:47:11.440]   I'm kind of in the TWIT hangover here.
[00:47:13.280 --> 00:47:22.000]   Now another story that makes me mad. The Senate by acclimation. Unanimously has voted to ban TikTok
[00:47:22.000 --> 00:47:30.480]   on government devices. The No TikTok on Government Devices Act introduced by Senator Josh Hawley,
[00:47:30.480 --> 00:47:37.920]   of course, passed by unanimous consent late Wednesday. No one objected. The proposal prohibits
[00:47:37.920 --> 00:47:43.280]   certain individuals from downloading or using TikTok on any device issued by the United States
[00:47:43.280 --> 00:47:49.600]   or a government corporation. Now obviously, 13 states have done the same. They can't ban TikTok
[00:47:49.600 --> 00:47:55.680]   from my phone because my personal phone or your personal phone or even a government employees'
[00:47:55.680 --> 00:48:01.600]   personal phone. But they sure would like to. Hawley said TikTok is a Trojan horse
[00:48:01.600 --> 00:48:07.200]   for the Chinese Communist Party, a major security risk to the United States and until it is forced
[00:48:07.200 --> 00:48:13.680]   to sever ties with China completely. It is no place on government devices. Mike, you agree?
[00:48:13.680 --> 00:48:23.840]   No, I think that there is a case for certain types of military personnel. For example,
[00:48:23.840 --> 00:48:30.000]   if you recall years ago, you could tell where there were secret bases for special forces in
[00:48:30.000 --> 00:48:35.680]   Afghanistan because the Fitbit data showed everybody running around. All these Americans
[00:48:35.680 --> 00:48:40.560]   running around in the Afghan desert or something like that. But that's a rare case. Most of us are not
[00:48:40.560 --> 00:48:47.600]   special forces deployed on a secret basis. So I think there's a case to be made not just for
[00:48:47.600 --> 00:48:55.840]   TikTok but for any sort of device that harvests information. I think the states who are banning
[00:48:55.840 --> 00:49:02.080]   TikTok for government employees and now the Senate is still has to be passed by the House and signed
[00:49:02.080 --> 00:49:09.120]   by the president. I think what the government, if the US was serious about it, they'd really
[00:49:09.120 --> 00:49:13.120]   understand the risk. The risk isn't so much data. We've talked about this on this show before. The
[00:49:13.120 --> 00:49:20.000]   risk is their ability during a conflict to have a lot of propaganda. It's a powerful propaganda
[00:49:20.000 --> 00:49:25.920]   tool. I think that the US government should figure out how to sort of monitor TikTok to a certain
[00:49:25.920 --> 00:49:32.720]   extent to have a way to pull the plug. If there was a conflict with China, that sort of thing.
[00:49:32.720 --> 00:49:42.800]   That would be rational. This is just irrational. It's just a lot of posturing and pandering to
[00:49:42.800 --> 00:49:47.600]   the ignorant, essentially, making it seem like, "Oh, the Chinese government's watching everything we do,"
[00:49:47.600 --> 00:49:54.960]   etc. Yeah, I think it's BS. I have to say, if I were the Chinese government trying to sway the
[00:49:54.960 --> 00:50:01.520]   American electorate, I might rush to Twitter faster than I'd rush to TikTok or Facebook.
[00:50:01.520 --> 00:50:08.080]   It's causing me $1 a month. Yeah. TikTok, it's a little harder to sway public opinion.
[00:50:08.080 --> 00:50:13.040]   I mean, I guess there's two potential threats to TikTok. One is that it's gathering more
[00:50:13.040 --> 00:50:20.480]   information on you than you think or know. For that, I will refer you to a Kaspersky
[00:50:21.440 --> 00:50:28.480]   study. TikTok privacy and security is TikTok safe to use. Steve Gibson talked about this on
[00:50:28.480 --> 00:50:36.720]   security now this week. Essentially, their conclusion is it's no different than any other app on your
[00:50:36.720 --> 00:50:44.000]   phone. According to the New York Times, the CIA reportedly investigated TikTok, found no concrete
[00:50:44.000 --> 00:50:49.920]   evidence that Chinese intelligence authorities are spying on users. It does not exfiltrate an
[00:50:49.920 --> 00:50:55.360]   abnormal amount of information from your phone. If you're using an iPhone, it adheres to the same
[00:50:55.360 --> 00:51:03.120]   limits that Apple imposes on other social networks. So the two possibilities are it's
[00:51:03.120 --> 00:51:07.840]   spying on you or that it's going to be used to propagandize you. If it's not spying on you,
[00:51:07.840 --> 00:51:11.360]   propaganda is a lot easier over on Twitter and Facebook.
[00:51:11.360 --> 00:51:18.640]   I'm sorry. Go ahead. Well, I'm saying I want to disclose that they are one of our supporters.
[00:51:18.640 --> 00:51:23.920]   One of the next three supporters. We do in our parents' guided TikTok raised a China issue. We
[00:51:23.920 --> 00:51:28.400]   did this a little bit two years ago. We raised a China issue and simply reported what they claimed
[00:51:28.400 --> 00:51:32.320]   at the time is that they have no servers in China. Although it doesn't matter because you can be
[00:51:32.320 --> 00:51:37.680]   sitting in China and access a server that's anywhere in the world. I do think TikTok has moved their
[00:51:37.680 --> 00:51:42.480]   US data to Oracle. I think that's right. But it's theoretically possible for somebody to be sitting
[00:51:42.480 --> 00:51:47.600]   Beijing and log in to a server that's located anywhere. But the point is, I think that much of
[00:51:47.600 --> 00:51:54.400]   the information that's on TikTok is quasi-public to begin with. I can go to TikTok and I can
[00:51:54.400 --> 00:52:00.320]   watch people do what they do. Now admittedly, I don't know what they're watching. Only TikTok
[00:52:00.320 --> 00:52:08.000]   knows that kind of data. But I'm with Mike on this. Do I worry at all about China and TikTok?
[00:52:08.000 --> 00:52:12.880]   Yes. But I also worry about the fact that Apple has relationship with China. Everybody
[00:52:12.880 --> 00:52:16.480]   has a relationship with China. There's Chinese chips in this phone that I have.
[00:52:16.480 --> 00:52:17.520]   Except Google.
[00:52:17.520 --> 00:52:20.240]   Well, you're saying there's no Chinese chips in a Pixel phone?
[00:52:20.240 --> 00:52:26.640]   Oh, well, that's the phone. Yeah. We're all using it. Unless using Samsung, most phones that
[00:52:26.640 --> 00:52:31.440]   certainly have phones and Google are Google phones made in China? Well, even if they're not made in
[00:52:31.440 --> 00:52:34.480]   China, I can't believe it's something that's... They used to be made by HTC, but I don't know.
[00:52:34.480 --> 00:52:38.720]   They might be made in China. Anyway, my point is that China is everywhere. You can't shop at
[00:52:38.720 --> 00:52:44.560]   Walmart without doing business in China with China. I'm not saying that China is benign.
[00:52:44.560 --> 00:52:49.360]   I'm not saying that there isn't the possibility of extracting data, but I'm saying there's so much
[00:52:49.360 --> 00:52:56.000]   of that. It is a fundamental, almost an existential question that Americans have to ask themselves
[00:52:56.000 --> 00:53:02.400]   if we are worried about China. If we really think China is the evil empire of this century,
[00:53:02.960 --> 00:53:09.680]   then our entire economy has to be intertwined with it because we are so in bed with China.
[00:53:09.680 --> 00:53:16.240]   I mean, again, when I was a kid, if you wanted to buy a pair of jeans, and I looked, it was
[00:53:16.240 --> 00:53:22.720]   something like $12 in the 1950s to buy a pair of jeans. That's like $200 or something today.
[00:53:22.720 --> 00:53:29.760]   You can buy jeans at Walmart or Amazon for $10, $12 made in China or maybe Vietnam or
[00:53:29.760 --> 00:53:34.560]   somewhere else. But the point is that if we want to break ties with China, we better get it ready
[00:53:34.560 --> 00:53:41.920]   to pay a lot more for our goods, not to mention. Actually, the biggest risk from TikTok is just how
[00:53:41.920 --> 00:53:48.400]   compelling the content is. Here's a perspective I can give that as somebody who lives in all kinds
[00:53:48.400 --> 00:53:51.920]   of different countries all the time, almost everywhere you go, there are a lot in a lot of
[00:53:51.920 --> 00:53:57.120]   countries like Morocco, we spend a lot of time in Morocco, for example. Police are posted in public
[00:53:57.760 --> 00:54:04.400]   places and they stand there and their job is to watch what's going on. And almost to a person,
[00:54:04.400 --> 00:54:09.680]   the police are watching TikTok on their phones. Security guards, it's the same thing here in
[00:54:09.680 --> 00:54:14.480]   Wahaki. You see, if a police person isn't driving or something like that, they're watching TikTok.
[00:54:14.480 --> 00:54:16.400]   Great, they're watching TikTok and not you. That's good.
[00:54:16.400 --> 00:54:23.360]   TikTok is a guy. If there's anything wrong with TikTok, it's that it's extremely addictive and
[00:54:23.360 --> 00:54:28.960]   entertaining. Yes, exactly. And there are reasons for that because it's pure algorithmic. It's not
[00:54:28.960 --> 00:54:36.240]   about social cues or anything like that. And it's an amazing thing that's the sort of thing that
[00:54:36.240 --> 00:54:39.760]   others still feel works. I will agree with that. They are the best at gathering
[00:54:39.760 --> 00:54:44.400]   algorithm, rhythmically gathering what you're interested in. They're very, very good at that.
[00:54:44.400 --> 00:54:48.800]   Nobody does that better. That's right. Is that the slow ground? None of us,
[00:54:50.240 --> 00:54:53.520]   but it's so good that none of us should admit what we see when we go to TikTok.
[00:54:53.520 --> 00:55:00.800]   Because it's very telling. That explains a couple thoughts on TikTok is,
[00:55:00.800 --> 00:55:08.640]   one of the things that TikTok is done and there were signals that this was going to happen,
[00:55:08.640 --> 00:55:14.720]   that somebody was going to get this right for a while, which was the idea of mapping from the
[00:55:14.720 --> 00:55:19.200]   social graph, meaning that it's all about who you follow and you have to follow the right people.
[00:55:19.200 --> 00:55:27.920]   And then you'll get the content that is aimed at you. What TikTok did and has done and is doing
[00:55:27.920 --> 00:55:33.120]   and that others haven't been able to replicate yet, but are working on is they've mapped the
[00:55:33.120 --> 00:55:37.760]   interest graph. So they understand your interests. They've been better, essentially,
[00:55:37.760 --> 00:55:42.800]   at machine learning and data. And they map your interests better. And so when you go there,
[00:55:42.800 --> 00:55:50.080]   you see, I see a higher number of things that I actually want to see on TikTok than I do on
[00:55:50.080 --> 00:55:56.560]   Instagram, far more than Twitter, Facebook, I don't really go to any longer YouTube even. So
[00:55:56.560 --> 00:56:02.160]   they have done this so well, because that's what they were all about. They focused everything on
[00:56:02.160 --> 00:56:08.560]   that and they're doing it better. I think the others will catch up. And I think we do have to
[00:56:09.120 --> 00:56:15.360]   keep in mind that TikTok is doing, I think, as much as they can to sort of put themselves at
[00:56:15.360 --> 00:56:23.600]   arm distance, arms like from China, from the Chinese government. Yet there are signs that there's still
[00:56:23.600 --> 00:56:31.840]   some close ties there. I'll just share one. It's a little bit exceptional, but it is data-based and
[00:56:32.400 --> 00:56:39.440]   value-tainment last week. And Patrick Bette-David, who runs that, had this very inflammatory headline
[00:56:39.440 --> 00:56:43.440]   in this YouTube video that says how TikTok is destroying American, why it needs to be banned,
[00:56:43.440 --> 00:56:48.560]   which I think is over the top. However, he did run this experiment where he showed,
[00:56:48.560 --> 00:56:58.000]   here's what all of my views were. And the number of videos that I had that had zero to 20,000 views,
[00:56:58.000 --> 00:57:04.240]   20 to 100,000 views, 100,000 to a million and over a million. And he ran this experiment where he
[00:57:04.240 --> 00:57:11.040]   says he, after he did that and he collected that data, he published a video very, and I think it
[00:57:11.040 --> 00:57:19.840]   was in August of this year. He published a video that was inflammatory and critical of the Chinese
[00:57:19.840 --> 00:57:27.520]   government. And then he tracked what the data was, the popularity of his videos afterwards,
[00:57:27.520 --> 00:57:35.600]   up until last week. And you see that they massively dropped off. And we're now no longer promoted.
[00:57:35.600 --> 00:57:40.160]   But is that a hazard to us that anything we say negative about the Chinese government will not
[00:57:40.160 --> 00:57:44.000]   appear on TikTok? Is that what we're worried about?
[00:57:46.640 --> 00:57:49.600]   By the way, you can't say anything about Mastin on Twitter either. I mean, is that what we're
[00:57:49.600 --> 00:57:53.040]   worried about really? I mean, is that what we're worried about? I think I'm more worried about,
[00:57:53.040 --> 00:58:01.120]   to be honest, value-tainment. YouTube is much more of a problem in terms of radicalization.
[00:58:01.120 --> 00:58:06.560]   If TikTok wants personal information, they can buy it like anybody else can from a data broker.
[00:58:06.560 --> 00:58:14.160]   If TikTok wants to sway our opinions, maybe that's possible. But the fact that TikTok down
[00:58:14.160 --> 00:58:21.120]   grades negative comments about China, if that's the hazard we're worried about, that seems kind of
[00:58:21.120 --> 00:58:27.280]   demeanourous. I've dipped my toe in the TikTok waters here and there. And people talk about things
[00:58:27.280 --> 00:58:33.040]   like views of the Chinese political system and all this stuff. I never saw anything like that
[00:58:33.040 --> 00:58:38.320]   when I go to TikTok. It's all more frivolous things and people doing things with fish and whatever.
[00:58:38.320 --> 00:58:42.640]   It's their interests, their commercial interests to promote stuff you're going to watch more of.
[00:58:42.640 --> 00:58:49.280]   Period. But again, I think there's a potential, and I think the Chinese government, by the way,
[00:58:49.280 --> 00:58:57.120]   bans TikTok. TikTok is banned in China, all the enough. But I think the Chinese government
[00:58:57.120 --> 00:59:05.200]   views TikTok as one lever of many that they have, if they were to invade Taiwan, for example,
[00:59:05.200 --> 00:59:10.080]   and there's a global conflict or whatever, I think they would go there. I would worry more if you
[00:59:10.080 --> 00:59:15.360]   were the only source of information people were getting. And maybe it is young people, I don't know.
[00:59:15.360 --> 00:59:25.360]   But that's why my view is that we should be aware of that of the potential propaganda element.
[00:59:25.360 --> 00:59:31.680]   Should that ever occur? And at that point, the plug could be pulled. I just hope it never comes
[00:59:31.680 --> 00:59:39.520]   to that. I hope there's no conflict over Taiwan. But in the meantime, it seems like a lot of the
[00:59:40.240 --> 00:59:46.720]   political rhetoric around TikTok is kind of BS. It also feels a little bit
[00:59:46.720 --> 00:59:53.200]   xenophobic to me because there are plenty of American companies that are invading our privacy
[00:59:53.200 --> 00:59:59.840]   far more and not doing anything about that. And I will say, I'm sorry. And again, TikTok,
[00:59:59.840 --> 01:00:05.280]   rather, the Chinese Communist Party, if they want to influence Americans, have much more direct
[01:00:05.280 --> 01:00:11.920]   avenues to do so. And TikTok is pretty good. I mean, as again, they are one of the groups that
[01:00:11.920 --> 01:00:17.200]   companies we work with that connect safely. And their parental controls and their child protection
[01:00:17.200 --> 01:00:24.320]   systems, while none of them are perfect, are on par with what you would expect from a decent
[01:00:24.320 --> 01:00:30.720]   company. I mean, they do a good job trying to protect kids from bullying and other harm. So,
[01:00:30.720 --> 01:00:34.880]   you know, from where I fit, I don't have any huge complaints about that after.
[01:00:34.880 --> 01:00:40.160]   There was a story this week, which I didn't read because it seemed like Linkbait to me that TikTok
[01:00:40.160 --> 01:00:45.040]   pushes harmful content every two minutes. No. I can't how you define harmful content.
[01:00:45.040 --> 01:00:48.160]   If it's bikini, maybe, I don't know.
[01:00:48.160 --> 01:00:55.920]   Saying that if you are a teenager and you sign up that every few minutes, you're immediately pushed,
[01:00:55.920 --> 01:01:02.240]   you know, toward content, they know nothing about you, you're immediately pushed toward content that
[01:01:02.240 --> 01:01:06.560]   is pushing you toward eating, distorted kind of things.
[01:01:06.560 --> 01:01:07.840]   And self harm stuff.
[01:01:07.840 --> 01:01:13.360]   So this is from the Center for Countering Digital Hate report they published this week,
[01:01:13.360 --> 01:01:17.920]   FANDA can take less than three minutes after signing up for a TikTok account to see content
[01:01:17.920 --> 01:01:22.320]   related to suicide, which I have never seen on TikTok. I must be doing something.
[01:01:22.320 --> 01:01:27.120]   Yeah. Or about five more minutes to find a community promoting eating disorder content.
[01:01:27.120 --> 01:01:30.240]   Again, I must be doing something wrong because I haven't seen that.
[01:01:30.240 --> 01:01:36.080]   I think the thing to think about, I think here, just to sort of put it in perspective,
[01:01:36.080 --> 01:01:46.480]   is that if we put one of the other platforms on the table, if it was Instagram or Facebook or
[01:01:47.440 --> 01:01:52.400]   Twitter, we'll sort of put the rest of our conversation aside.
[01:01:52.400 --> 01:02:00.400]   And we felt like as soon as you started, you know, discriminating or posting, you know, hate
[01:02:00.400 --> 01:02:05.360]   speech or we'll not even call it hate speech, criticism of, because to be fair, the value
[01:02:05.360 --> 01:02:11.920]   of the entertainment example, it was just criticism of the policies of the Chinese government.
[01:02:11.920 --> 01:02:19.120]   If any of us started publishing policies on any of these US-based Twitter platforms
[01:02:19.120 --> 01:02:26.960]   and all of criticism of the US government and all of a sudden our, you know, content
[01:02:26.960 --> 01:02:34.160]   started having lower thresholds of followers and those kinds of things, I think we would have a
[01:02:34.160 --> 01:02:38.640]   problem with that. I think we would feel like that's not something we want to support. And that's
[01:02:38.640 --> 01:02:46.160]   not something that we want to think of as a platform that, you know, is creating the sort of atmosphere
[01:02:46.160 --> 01:02:52.960]   that we want. And so I'm not saying that everyone shouldn't stop using TikTok. I still use TikTok
[01:02:52.960 --> 01:02:57.840]   myself. I'm just saying we should have, we should go into all these things with awareness we talked
[01:02:57.840 --> 01:03:04.800]   about earlier, the fact that we, there was this false narrative that we were having a public
[01:03:04.800 --> 01:03:11.680]   town square and come to find out it's not really public. And now we need to think about sort of
[01:03:11.680 --> 01:03:17.360]   a different path forward. And certainly this is just another example of the fact that these
[01:03:17.360 --> 01:03:24.000]   platforms are owned by companies, but now these companies are influenced by governments in ways
[01:03:24.000 --> 01:03:30.080]   that really we should have some transparency around the facts of what's really happening
[01:03:30.080 --> 01:03:36.560]   and what's really driving, especially these interest draft, you know, driven phenomenon,
[01:03:36.560 --> 01:03:41.760]   which is let, which is in TikTok today, but is likely to be in all of these platforms in the
[01:03:41.760 --> 01:03:46.240]   years ahead. Yeah, I think we're going to have a what Jeff Jarvis would call a moral panic over
[01:03:46.240 --> 01:03:51.840]   TikTok. What the real thing we should be panicking about or freaking out about or thinking about
[01:03:51.840 --> 01:03:59.600]   is the fact that algorithms and artificial intelligence that can custom tailor things just
[01:03:59.600 --> 01:04:04.960]   the way we want them. This is going to be ubiquitous. It's not because this is not about TikTok. It's
[01:04:04.960 --> 01:04:10.240]   about everything, right? So you have you, we're entering in a world, we're entering in a world of
[01:04:10.240 --> 01:04:16.560]   where the vast majority, almost all of content that will be posted online would be synthetic media,
[01:04:16.560 --> 01:04:22.240]   right? AI is going to write the words we read. It's going to create the pictures that we see.
[01:04:22.240 --> 01:04:28.880]   It's going to create videos we see. And this will be highly tweakable and customizable. And this is
[01:04:28.880 --> 01:04:33.040]   something that I think nobody's really talking about. TikTok is kind of doing us a favor because
[01:04:33.040 --> 01:04:37.360]   they're saying, here's a little tiny glimpse of how everything is going to work in the future. And
[01:04:37.360 --> 01:04:40.880]   that's what we should be talking about. And it's going to get worse with the metaverse in AR and VR
[01:04:40.880 --> 01:04:45.360]   and whatever it was from this. We are going, we are because we're voluntarily putting ourselves
[01:04:45.360 --> 01:04:50.720]   into a virtual environment anyway, right? How do I know who that avatar really is? How do I know
[01:04:50.720 --> 01:04:55.040]   who's behind that avatar? That car that drives by, how do I know whether that's just some cool car
[01:04:55.040 --> 01:04:59.280]   somebody created or whether it's something that Ford is trying to get me to buy? I mean, there's so
[01:04:59.280 --> 01:05:06.160]   much that we are going to have to put our critical thinking caps on if we want to survive the
[01:05:06.160 --> 01:05:11.440]   metaverse and it's going to just be overwhelming. I think the metaverse is going nowhere, honestly.
[01:05:11.440 --> 01:05:19.040]   I think it's... I feel like there's a homeostatic mechanism in humans that we are, we'll eat too
[01:05:19.040 --> 01:05:25.920]   much sugar or we'll watch too many TikTok videos. And then we start to go, oh, yeah, and we protect
[01:05:25.920 --> 01:05:29.440]   ourselves. There's some people who are going to fall down the rabbit hole. But most humans,
[01:05:29.440 --> 01:05:35.840]   when they're faced with addictive behavior, eventually go, yeah, this isn't working for me
[01:05:35.840 --> 01:05:40.000]   and back off, or maybe that's not the case. No, no, I think that is the case. And I think we've
[01:05:40.000 --> 01:05:45.280]   already seen it with the election. So the midterm elections, the sway of disinformation,
[01:05:46.160 --> 01:05:50.880]   deliberate political disinformation, it was less persuasive this time around,
[01:05:50.880 --> 01:05:55.440]   even though there's a lot more of it. And so we basically... We've weaved our self-directing
[01:05:55.440 --> 01:06:01.680]   mechanism off of it, sort of. Enough to the point where the election denier types mostly lost.
[01:06:01.680 --> 01:06:09.280]   And so it was just a couple of years ago when disinformation was way more effective.
[01:06:09.280 --> 01:06:15.040]   So I think we are capable of learning, of adapting and of protecting ourselves and finding out
[01:06:15.040 --> 01:06:19.360]   what's healthy, what's unhealthy, and so on. And again, like you say, Leo, some people are just
[01:06:19.360 --> 01:06:25.200]   getting into McDonald's every day. But most of us don't. Yeah. And I would hope it's not the
[01:06:25.200 --> 01:06:29.840]   government's role to protect ourselves. I hate to throw cold water in you, but I was a little
[01:06:29.840 --> 01:06:34.880]   rock ark and saw about a year ago. And I couldn't help notice that almost everybody I ran into with
[01:06:34.880 --> 01:06:39.680]   obese. I mean, I would just shock. It's a national problem. Yeah. It's a, but it's especially when
[01:06:39.680 --> 01:06:44.240]   you get away from the coast, especially when you get into the red states. It is... There is a very
[01:06:44.240 --> 01:06:49.440]   large segment of our population that is not stepping away from the excessive sugar. And I'm almost using
[01:06:49.440 --> 01:06:55.440]   that as a metaphor. I mean, whether it's overeating or voting in a way that's against
[01:06:55.440 --> 01:06:59.920]   your self-interest or whatever, there are people in this country who for whatever reason are not
[01:06:59.920 --> 01:07:03.840]   thinking about what is truly in their best interest, at least not acting on it.
[01:07:03.840 --> 01:07:09.040]   It's a perfect metaphor, actually, because the companies that create the most compelling
[01:07:09.040 --> 01:07:16.960]   junk food have done that by reverse engineering our desires to salt and fat and sugar and so on.
[01:07:16.960 --> 01:07:20.960]   TikTok is doing it, except instead of with their eyeballs, with our taste buds. Yeah. Yeah.
[01:07:20.960 --> 01:07:26.720]   Yeah. It's true. Yeah. But I do think we're learning. I honestly, the news is kind of,
[01:07:26.720 --> 01:07:31.440]   it's slow, but the news is going forth. We've got in a BC, the epidemic. People are getting sick.
[01:07:31.440 --> 01:07:36.880]   What we were telling, partly it was because the US government was saying, don't eat fat.
[01:07:37.520 --> 01:07:45.360]   And so people were choosing Cheerios. And I think that's kind of turned a little bit.
[01:07:45.360 --> 01:07:53.120]   I don't know. Maybe it's the arc of justice is long and bends towards less Cheerios. I don't know.
[01:07:53.120 --> 01:08:01.440]   But I feel like, to paraphrase Martin Luther King, I feel like you can have some hope.
[01:08:01.440 --> 01:08:07.200]   All I know is when I go to TikTok, all I really ever want to see is more and more cheesy
[01:08:07.200 --> 01:08:12.160]   Gordita crunches because talking about junk food. That's junk food, but it's my son.
[01:08:12.160 --> 01:08:19.040]   That's delicious. So you might, people might say, oh, here you'll like this one. This is
[01:08:19.040 --> 01:08:24.800]   four and a half million views. People might say, oh, Leo, you like TikTok because your son
[01:08:24.800 --> 01:08:31.040]   makes his living on TikTok. But even he understands that this isn't going to look at that sandwich.
[01:08:31.040 --> 01:08:34.080]   How do you stay so thin? He doesn't eat this stuff. Are you kidding?
[01:08:34.080 --> 01:08:42.800]   He's a pusher. I don't know because he's never brought it over to my house. He makes it, but
[01:08:42.800 --> 01:08:46.080]   he never makes it. I hate to admit it, but he could come over and take it over to my house.
[01:08:46.080 --> 01:08:55.120]   To me, that's TikTok. That's all I need is just food, food porn.
[01:08:55.120 --> 01:09:00.960]   Let's take a little break, come back with more. I do think, I just make it clear. It's perfectly
[01:09:00.960 --> 01:09:05.440]   legitimate for government to say government employees can't have TikTok on their government
[01:09:05.440 --> 01:09:10.640]   owned phone. That's fine. If an employer wants to say that, that's fine. The department events
[01:09:10.640 --> 01:09:17.120]   ban Strava, the running app because it turned out you could tell where stuff was at the Pentagon
[01:09:17.120 --> 01:09:22.880]   because everybody was using it. That's appropriate. I'm not saying you shouldn't ban it from government
[01:09:22.880 --> 01:09:30.080]   phones. I'm just saying, I feel like there is a move in Congress to the FCC. There's an FCC
[01:09:30.080 --> 01:09:35.280]   commissioner saying we should ban TikTok nationally. There's a move to banning it. I think that
[01:09:35.280 --> 01:09:38.960]   that's one of those things where you go, "Okay, good. We took care of social. What's next?"
[01:09:38.960 --> 01:09:45.600]   There's really a much larger problem. It's somewhat virtual signaling. It's virtual signaling.
[01:09:45.600 --> 01:09:53.280]   Exactly. It kills two birds with one stone, mostly on the right politically, because TikTok
[01:09:53.280 --> 01:09:59.920]   is a new thing. It's a very powerful cultural force. China is involved. You can
[01:09:59.920 --> 01:10:05.840]   rack up votes by opposing those two things all at once. Really, how many government employees
[01:10:05.840 --> 01:10:13.760]   have government phones? I have no idea, but I would guess most don't. I don't think postal
[01:10:13.760 --> 01:10:20.320]   workers have government phones. I don't think we're talking about a few thousand phones.
[01:10:20.320 --> 01:10:24.000]   I guarantee you, one thing, if they have a government phone, they also have a personal phone where they
[01:10:24.000 --> 01:10:27.280]   can put TikTok on it. I'm sure they do. You can't find that.
[01:10:27.280 --> 01:10:31.600]   They should have any social apps on their government phones unless you want it in social media.
[01:10:31.600 --> 01:10:36.640]   They should be very social media apps. Exactly. If I provide a phone to an employee,
[01:10:36.640 --> 01:10:43.280]   it's my right to say, "You can't be using the ... At work, they can't be sitting watching
[01:10:43.280 --> 01:10:46.720]   TikTok at work all the time. I don't stop. They have no expectation of privacy either.
[01:10:46.720 --> 01:10:49.600]   No, that's right. You can use your spy on your employees. Of course, if I've upheld that
[01:10:49.600 --> 01:10:53.680]   time and time again, you're using my gear, my internet. I can tell you what the rules are.
[01:10:54.400 --> 01:10:57.440]   But it's okay, John. You can watch all the TikTok you want. I don't like it.
[01:10:57.440 --> 01:10:59.520]   As long as it's salthanks. Research.
[01:10:59.520 --> 01:11:03.280]   Salt salthanks, Gordita Crutches. He's unmasted on right now. Good job.
[01:11:03.280 --> 01:11:11.440]   I do not own a stake in Mastodon, by the way. No one does. In fact, Mastodon just costs us money.
[01:11:11.440 --> 01:11:18.640]   It doesn't make us any money. Our show today, speaking of America's obesity crisis, brought to
[01:11:18.640 --> 01:11:25.040]   you by NUAM. Now, I am ... This is an app you absolutely should put on your phone.
[01:11:25.040 --> 01:11:29.200]   I don't go anywhere without my NUAM app. What is NUAM? It's not a diet.
[01:11:29.200 --> 01:11:34.320]   So that's really important because diets ... I think we've learned diets don't work. If I tell you,
[01:11:34.320 --> 01:11:38.880]   you may not eat something, what are you going to crave more than anything else, that thing?
[01:11:38.880 --> 01:11:46.240]   And eventually, you're going to eat it. You really are. NUAM is different. NUAM is different.
[01:11:46.240 --> 01:11:53.760]   It is a psychology first approach that lets you stay focused on what's important to you.
[01:11:53.760 --> 01:11:58.240]   When you decide to lose weight, it's not just the number on the scale. There's a lot of reasons
[01:11:58.240 --> 01:12:03.120]   people want to lose weight to be healthier, to be more active, to be better looking.
[01:12:03.120 --> 01:12:09.360]   Whatever your reason for losing weight, whatever reason for wanting ... I shouldn't even say losing
[01:12:09.360 --> 01:12:16.560]   weight. For wanting to take control of your body, NUAM is there to help. Do you eat because you're
[01:12:16.560 --> 01:12:22.960]   bored? Can you ... This is a bad one for me. Can you pass up food when it's free? If somebody brings
[01:12:22.960 --> 01:12:29.440]   me donuts, I'm going to eat the donut. If the answer is yes, don't stress. NUAM weight helps you
[01:12:29.440 --> 01:12:35.840]   break the cycle and change your habits for good. I, for instance, I'm a fogg eater. And I know this
[01:12:35.840 --> 01:12:41.760]   because I'm having done NUAM now for more than a year. I've gone through all the lessons you get
[01:12:41.760 --> 01:12:47.680]   with NUAM. You get all sorts of things to help you understand what you're doing. I've learned that
[01:12:47.680 --> 01:12:52.240]   now I observe, I go in and I'm not paying attention. I'm stuffing my mouth because I'm watching a
[01:12:52.240 --> 01:12:56.080]   Tiktok or whatever. I'm watching those videos from Henry and I got to eat something, right?
[01:12:56.080 --> 01:13:02.320]   But that insight is so much better than being restrictive. Sam is saying, "Don't do this. Don't
[01:13:02.320 --> 01:13:07.760]   do that." It's understanding what you do so you can make a choice. And that's how you break the
[01:13:07.760 --> 01:13:13.440]   cycle. That's how you change your habits for good. NUAM weight is not a diet. It's different. It uses
[01:13:13.440 --> 01:13:17.440]   psychology to help you understand your eating habits, to learn how to make healthier choices
[01:13:17.440 --> 01:13:23.840]   every day. That's why they say losing weight starts with your brain. The program helps you
[01:13:23.840 --> 01:13:28.240]   understand the science behind your eating choices, why you're craving what you crave.
[01:13:29.040 --> 01:13:34.800]   And it's such a success. To date, NUAM weight has helped more than 4.6 million people lose weight.
[01:13:34.800 --> 01:13:41.600]   Active NUAMers lose an average of 15 pounds in 16 weeks. 95% of customers say NUAM weight is a good
[01:13:41.600 --> 01:13:47.280]   long-term solution. And I know it. I've been using it. Lisa loves it. She didn't have much
[01:13:47.280 --> 01:13:51.920]   weight to lose, but those last few pounds were very hard for NUAM. Made it all the difference.
[01:13:51.920 --> 01:13:56.640]   And a year later, she hasn't gained the weight back. We also have members of our community,
[01:13:56.640 --> 01:14:01.280]   Branna Wu. She's been looking fantastic. I said, what have you been doing? She said,
[01:14:01.280 --> 01:14:07.680]   I did NUAM. I lost 100 pounds. Now, not everybody loses 100 pounds, obviously.
[01:14:07.680 --> 01:14:13.600]   Not everybody should lose 100 pounds. Lisa lost, I think, five or 10. But she's very, very happy.
[01:14:13.600 --> 01:14:17.840]   And I'll tell you what, both of us, every meal, we pull out our phones, we do our NUAM.
[01:14:17.840 --> 01:14:22.960]   Every evening, we do our lessons. You can have a regular counselor who works with you. You can
[01:14:22.960 --> 01:14:28.080]   have a group that works with you. You get to choose how NUAM works. In fact, one of the things you'll
[01:14:28.080 --> 01:14:32.320]   notice when you first sign up for NUAM is it asks you a lot of questions. That's so it can tailor
[01:14:32.320 --> 01:14:40.720]   a program specifically to you. Their flexible program focuses on progress, not perfection.
[01:14:40.720 --> 01:14:46.560]   We're not talking to giving up carbs or creating other restrictions because that's counterproductive.
[01:14:46.560 --> 01:14:52.800]   If you've got cravings or food FOMO, I definitely have food FOMO when it's pizza day at Twitch,
[01:14:52.800 --> 01:14:58.720]   and sorry for me. But NUAM weight has helped me lose weight while enjoying my favorite foods,
[01:14:58.720 --> 01:15:03.360]   being conscious about what I'm doing. You choose your level of support from five-minute daily
[01:15:03.360 --> 01:15:08.480]   check-ins to personal coaching. They publish more than 30 peer-reviewed scientific articles
[01:15:08.480 --> 01:15:14.000]   to inform users, practitioners, scientists, the public. Peer-reviewed articles about their methods
[01:15:14.000 --> 01:15:18.560]   and effective is, in fact, they're doing a book. You can pre-order it. The first book ever,
[01:15:18.560 --> 01:15:24.560]   the NUAM mindset, a deep dive into the psychology of behavior change. They use cognitive behavioral
[01:15:24.560 --> 01:15:31.360]   therapy and other established psychological techniques to help you understand what you're doing and
[01:15:31.360 --> 01:15:36.480]   to take control of your health. I love it. Stay focused on what's important to you with NUAM weight
[01:15:36.480 --> 01:15:41.840]   psychology-based approach. Sign up for your trial today. You could, I know, you're smart. You can go
[01:15:41.840 --> 01:15:47.760]   to the App Store and download it. But please do me a favor. First, go to NUAM, N-double-o-m.com/twit.
[01:15:47.760 --> 01:15:53.040]   NUAM.com/twit. A, that's where you'll sign up for the trial. B, if you do that, then they know
[01:15:53.040 --> 01:15:56.880]   that you saw it here. We love these guys. We want to keep them as a sponsor. We want to keep them
[01:15:56.880 --> 01:16:03.440]   happy. So go to NUAM.com/twit. Let them know you saw it on the show. NUAM. It has worked for me.
[01:16:03.440 --> 01:16:09.200]   It works for Lisa. It works for so many people. I know one of our chat regular chatters lost 60
[01:16:09.200 --> 01:16:15.360]   pounds. In fact, he was on yesterday. We were practicing for a new show and he called in and
[01:16:15.360 --> 01:16:22.320]   I was watching the chat room. People were saying, "What? Is that retcon five? What? I didn't recognize
[01:16:22.320 --> 01:16:32.560]   them either." NUAM. It works. All right. Let's see. What else to talk about? Samuel Bankman Freed.
[01:16:34.960 --> 01:16:41.280]   Arrested in the Bahamas. Charges from the US District. Used to turn for the Southern District of New
[01:16:41.280 --> 01:16:50.480]   York. He will be presumably extradited from the Bahamas to face criminal charges in the US.
[01:16:50.480 --> 01:16:55.760]   This is, of course, the founder of FTX. In fact, the funny thing is they arrested him
[01:16:55.760 --> 01:17:03.280]   that day before he was supposed to testify in Congress. This guy was acting as if these things
[01:17:03.280 --> 01:17:06.960]   happened and didn't do anything wrong. I was puzzling me that he was not...
[01:17:06.960 --> 01:17:14.240]   Was it true he did nothing illegal? Well, maybe he did. It's a bad year for billionaires.
[01:17:14.240 --> 01:17:24.720]   I hope that we stop worshipping billionaires, freaking billionaires in America. To some degree,
[01:17:24.720 --> 01:17:30.080]   he got away with what he did, just like Bernie Madoff, because we do worship wealth. We do,
[01:17:30.080 --> 01:17:35.200]   yeah. I remember when the industry standard, which was this Silicon Valley magazine,
[01:17:35.200 --> 01:17:39.440]   came out, and they used to put all these people on their cover. The only thing these people had
[01:17:39.440 --> 01:17:44.320]   ever accomplished was that they raised money. They didn't make money. They didn't have a product
[01:17:44.320 --> 01:17:48.480]   that was profitable. They just got other people to give them money, and that got them on the cover
[01:17:48.480 --> 01:17:56.320]   of a magazine. I don't know what it is that Bankman accomplished other than convincing people to
[01:17:56.960 --> 01:18:01.360]   turn money over to him. Why don't we reserve those covers where people actually accomplish
[01:18:01.360 --> 01:18:09.040]   something? Here's the question. By the way, people who did ads for FDX, including Tom Brady,
[01:18:09.040 --> 01:18:14.880]   his wife, Giselle Boynton, Larry David, the famous ad on the Super Bowl, Larry David saying,
[01:18:14.880 --> 01:18:24.720]   all did endorsements. Shaq saying, "Hey, his defense is, he's being sued. They all are. Hey,
[01:18:25.280 --> 01:18:29.920]   just a paid endorsement." I don't know anything about crypto. I just a paid endorser.
[01:18:29.920 --> 01:18:34.640]   Yeah. His defense is, he was lying. By the way, that defense works.
[01:18:34.640 --> 01:18:38.960]   Isn't that what, who was it? Tucker Carlson's defense?
[01:18:38.960 --> 01:18:43.280]   Everybody should take me seriously. No, we should take me seriously. It's an
[01:18:43.280 --> 01:18:51.440]   entertainer. Well, the thing that's so interesting about this is that he was flying so high. He's
[01:18:51.440 --> 01:18:59.520]   like the guy from WeWork or Elizabeth Holmes or any of these other narcissistic money razors
[01:18:59.520 --> 01:19:05.200]   and just had all the answers, right? He's right out of school practically and just had all the
[01:19:05.200 --> 01:19:11.360]   answers about how to do his business. But he was just doing shady business pumping the people's
[01:19:11.360 --> 01:19:18.080]   money into Alameda research, doing all these shady things. By the way, I bet he can't wait to
[01:19:18.080 --> 01:19:22.320]   get extradited because the jail he's been in in the Bahamas is supposed to be a horrible jail.
[01:19:22.320 --> 01:19:28.400]   The inmates supposedly have to remove the feces or the pocket and all this kind of, I mean,
[01:19:28.400 --> 01:19:36.080]   it's really kind of not a happy place to be. But he could get a slap on the rest. He could get a
[01:19:36.080 --> 01:19:41.440]   few years in jail at the end of this or he could get a life sentence. Nobody knows. I fear they
[01:19:41.440 --> 01:19:50.160]   may choose to make an example out of them. And then he could get a couple of life sentences like
[01:19:50.160 --> 01:19:54.720]   Bernie Madoff did. Well, we know that in this country, the worst crime you can commit is to
[01:19:54.720 --> 01:19:59.440]   steal from rich people. That's why Elizabeth Holmes will be doing more than 12 years,
[01:19:59.440 --> 01:20:06.960]   sunny Balanee more than 14 years because not because they hurt people's health by proposing a way to
[01:20:06.960 --> 01:20:13.040]   test blood by the droplet. But because they hurt because rich people lost money. So that's the
[01:20:13.040 --> 01:20:17.040]   worst thing you can do. So I wouldn't be surprised if they throw the book at him. He has been indicted
[01:20:17.040 --> 01:20:23.760]   on charges of conspiracy to commit wire fraud, wire fraud, conspiracy to commit commodities fraud,
[01:20:23.760 --> 01:20:29.120]   conspiracy to commit securities fraud, money laundering, conspiracy to defraud the federal
[01:20:29.120 --> 01:20:33.200]   election commission because he was giving a lot of money to candidates both left and right
[01:20:33.840 --> 01:20:43.760]   and to commit campaign finance violations. So I guess the larger question is, I saw a member of
[01:20:43.760 --> 01:20:54.400]   Congress on the floor say, you know, we shouldn't, this guy was a fraud, but we shouldn't extend this
[01:20:54.400 --> 01:21:04.160]   to doubting Bitcoin. Is that fair? Is this this isn't a crime of crypto? This is something separate.
[01:21:04.160 --> 01:21:09.680]   Yeah, no, I think it is. I think that is fair on its face. I don't recommend this coin.
[01:21:09.680 --> 01:21:15.120]   This connoissement must have been sponsored by crypto.com, but okay, or by an answer.
[01:21:15.120 --> 01:21:19.200]   No, but but but to Larry's point, you know, we should we should be investing our money in
[01:21:19.200 --> 01:21:23.360]   things that employ people that things that feed people things that provide goods and services
[01:21:23.360 --> 01:21:29.120]   people need and use instead of crypto where it's just like, yeah, just make me rich. I don't care
[01:21:29.120 --> 01:21:33.840]   if I'm contributing anything society. I just want money. And therefore, I'm an investor in
[01:21:33.840 --> 01:21:37.680]   Bitcoin. I think that's the best reason to avoid Bitcoin. But I don't think, you know,
[01:21:37.680 --> 01:21:44.400]   the crimes of this particular case are specific to how he ran his businesses. And I don't think they
[01:21:44.400 --> 01:21:49.120]   necessarily reflect on Bitcoin generally, even though there are other exchanges that are also
[01:21:49.120 --> 01:21:57.840]   doing shady things in addition to him. Yeah, sorry. Good. He a little bit, I think,
[01:21:57.840 --> 01:22:04.800]   green washed his activities by talking about effective altruism, by donating the fraudulently
[01:22:04.800 --> 01:22:12.640]   earned money. Because there was money in some form or fashion. He delivered
[01:22:12.640 --> 01:22:18.800]   delivered $40 million in political campaign contributions, mostly to the DNC and other
[01:22:19.600 --> 01:22:25.440]   left wing. The biggest one was to protect our future pack, which was the effective
[01:22:25.440 --> 01:22:32.160]   Alcherism pack $27 million to that to the House majority pack a super packed supporting House
[01:22:32.160 --> 01:22:39.680]   Democrats $6 million. But he also had other, you know, other donations to Republican candidates as
[01:22:39.680 --> 01:22:44.480]   well. I mean, if you're making political donations, a smart thing to do is to spread it around so
[01:22:44.480 --> 01:22:50.880]   that everybody owes you. But also, I think he was using that as a way of, because remember all those
[01:22:50.880 --> 01:22:59.760]   glowing articles about SBF and what a benefactor society he was. Yeah, he was an amazing PR person.
[01:22:59.760 --> 01:23:05.920]   Like you also can't, you know, get around the fact that he talked a big game. People wanted to
[01:23:05.920 --> 01:23:12.960]   believe we just still have this obsession. The media has a obsession with creating heroes and
[01:23:12.960 --> 01:23:20.240]   they love to make billionaire heroes. And so, you know, that whole, you know, that whole
[01:23:20.240 --> 01:23:29.200]   theme is sort of under also under scrutiny, right? Because he was one. Elon Musk was one for many
[01:23:29.200 --> 01:23:36.560]   years, right? Now, we're seeing that those things create these just terrible, terrible outcomes,
[01:23:36.560 --> 01:23:42.560]   almost, you know, one after another. I think the thing that I would like to say though,
[01:23:42.560 --> 01:23:48.720]   in terms of crypto is, you know, crypto is the best performing asset of the past decade.
[01:23:48.720 --> 01:23:52.800]   Is that true? Because of that. Even after the crash. Wow, I didn't realize that.
[01:23:52.800 --> 01:23:57.200]   Yeah, it is over a period of time, right? If you bought early enough, if you bought
[01:23:57.200 --> 01:24:04.320]   Bitcoin when it was a nickel, you're doing fine. Yeah. Right. So, so the thing is, is that makes it
[01:24:04.320 --> 01:24:09.360]   a platform for a corruption too, right? But that's the, to me, that's the real problem.
[01:24:09.360 --> 01:24:13.840]   It's not that there's something wrong with Bitcoin, but it's very easy because it's new,
[01:24:13.840 --> 01:24:18.800]   it's technology. It's very easy to scam people. It was a lot of your recipe. You have to scam people
[01:24:18.800 --> 01:24:26.240]   than Bernie Madoff. Because he wasn't doing dollars. The core, remember what blockchain and
[01:24:26.240 --> 01:24:34.000]   Bitcoin came out of though was the, you know, '09 financial crisis where there was this lack of
[01:24:34.000 --> 01:24:40.640]   accountability, this lack of transparency in the financial system. And it was essentially trying to
[01:24:40.640 --> 01:24:47.040]   find a way to get beyond that. And I think the core of that, and then it has since then advanced
[01:24:47.040 --> 01:24:53.520]   into this idea of also helping the unbanked throughout the world who get taken advantage of
[01:24:53.520 --> 01:25:01.600]   through greedy forces that sometimes victimize them and put them in positions where they,
[01:25:02.160 --> 01:25:08.400]   you know, end up working jobs or other things for others who, again, centralize resources,
[01:25:08.400 --> 01:25:15.040]   extract the value, leave the average worker, the average person without much power and without
[01:25:15.040 --> 01:25:22.720]   much opportunity. And so cryptocurrency blockchain at its core does have some answers to some of
[01:25:22.720 --> 01:25:28.640]   those problems. And I think we shouldn't lose sight of that with the fact that there are
[01:25:28.640 --> 01:25:36.160]   charlatans going into this that are using it as a platform to steal from people, to, you know,
[01:25:36.160 --> 01:25:42.880]   do their get rich quick schemes and all of that. Just as cash is used, just as other platforms are
[01:25:42.880 --> 01:25:48.880]   used, the markets themselves are used. It does need regulation and it needs it fast. And the hard
[01:25:48.880 --> 01:25:53.760]   thing is regulation is going to be very, it's going to continue to have a very difficult time
[01:25:53.760 --> 01:25:59.360]   catching up with and staying up with as fast as cryptocurrency and sort of blockchain and the
[01:25:59.360 --> 01:26:07.680]   crypto economy are evolving and moving right now. So yeah, I just think we should keep in mind that
[01:26:07.680 --> 01:26:15.200]   the core of this is not, I don't think we should call into question the value of Bitcoin or
[01:26:15.200 --> 01:26:19.920]   cryptocurrency with what happened with FTX. But isn't isn't part of the value proposition,
[01:26:19.920 --> 01:26:24.160]   the lack of regulation? I mean, it's not what they're there thereafter.
[01:26:24.160 --> 01:26:30.080]   Yeah. And also, go ahead, Larry. No, I mean, the lack of regulation and also the lack of any
[01:26:30.080 --> 01:26:35.360]   connection to real world value. I mean, if you, if I bought a CD the other day, 4 and a half percent,
[01:26:35.360 --> 01:26:38.800]   well, I know what's going to happen with my CD. Somebody else going to borrow the money,
[01:26:38.800 --> 01:26:44.080]   the bank's going to make a spread. Maybe somebody gets to buy a house. I mean, something potentially
[01:26:44.080 --> 01:26:49.040]   positive will happen to the result of that CD. I invest in a stock market. Well, that's a little
[01:26:49.040 --> 01:26:53.280]   bit of a casino. But at least there's some correlation between the performance of the company and the
[01:26:53.280 --> 01:27:00.720]   value of my stock. I don't see, if I had a Bitcoin portfolio and I have a very tiny one, like a
[01:27:00.720 --> 01:27:04.720]   couple of hundred dollars just to play with it, just figure it out, I don't see any relationship
[01:27:04.720 --> 01:27:10.640]   between my portfolio and any value in the world other than what somebody can make from Bitcoin.
[01:27:10.640 --> 01:27:16.320]   It's also a little value, just as the US dollar is though, right? So the US dollar only has as much
[01:27:16.320 --> 01:27:23.280]   value as the people who believe in it think it is, right? It's like, I think that's, that is a more
[01:27:23.280 --> 01:27:27.920]   app. I'll tell you the difference, Jason. People don't buy a dollar to speculate
[01:27:27.920 --> 01:27:32.800]   because the dollar is so stable. Nobody buys, I'm going to buy a hundred thousand dollars
[01:27:32.800 --> 01:27:37.600]   figuring some that next month it'll be worth two hundred thousand dollars. So that's the biggest
[01:27:37.600 --> 01:27:45.360]   difference. And that's why people buy cryptocurrency and NFTs is this is and so the volatility kind of
[01:27:45.360 --> 01:27:51.200]   gives you this casino-like effect like I could make it big. So you're right, Jason, to say over the
[01:27:51.200 --> 01:27:58.640]   total lifespan of crypto, it's been a great investment. But as you narrow that down, it becomes less
[01:27:58.640 --> 01:28:03.200]   and less good. For instance, here's from a tweet from somebody in the chatroom put up,
[01:28:03.200 --> 01:28:08.480]   total returns over the past five years, Bitcoin's five and a half percent. T-bills,
[01:28:09.040 --> 01:28:18.880]   much like your CDs, 5.4 percent. But Ben says, the Bitcoin was a little more volatile than the other.
[01:28:18.880 --> 01:28:24.960]   This is actually a more interesting analysis, this is from Chain Analysis. This is the FTX
[01:28:24.960 --> 01:28:32.960]   investor impact. It was not the biggest impact on cryptocurrency of the year. Far worse,
[01:28:33.680 --> 01:28:43.440]   the FTX collapses here. Far worse, the Celsius collapse, the Terra UST token collapse, the three
[01:28:43.440 --> 01:28:50.880]   arrows capital collapse. So here's Terra, here's Celsius, three arrows capital. That cost investors
[01:28:50.880 --> 01:28:58.320]   billions and billions of dollars. Celsius, that is the fundamental analysis you can do on blockchain
[01:28:58.320 --> 01:29:02.880]   too. And to be clear, my- That's a good point. Those would be similar.
[01:29:02.880 --> 01:29:07.040]   These losses and gains would be hidden in many other investments because it's on blockchain.
[01:29:07.040 --> 01:29:10.480]   It's public. So somebody can go through that blockchain and say, "Well, here's what people
[01:29:10.480 --> 01:29:14.080]   gain in here. People lost." That's a very good point. So that is the fundamental analysis like
[01:29:14.080 --> 01:29:19.680]   you would do with a stock, right? That's a similar- I was saying, my connection with Bitcoin is very
[01:29:19.680 --> 01:29:24.960]   similar to Larry's. I own a very small amount, mostly out of curiosity to follow it as a tech
[01:29:24.960 --> 01:29:31.520]   journalist, right? To understand it, but not. It's not a fundamental part of my portfolio or
[01:29:31.520 --> 01:29:38.400]   anything like that. But I think that we should- It's a very difficult thing to understand and to
[01:29:38.400 --> 01:29:44.880]   also to try to understand what the future of it is and where it's going and what the possibilities
[01:29:44.880 --> 01:29:51.200]   are. And there is a lot of froth and there's a lot of get rich quick people that are chasing it.
[01:29:51.200 --> 01:29:56.960]   As you mentioned, Leo, and that is one of the things that we have to understand about it, right?
[01:29:56.960 --> 01:30:04.160]   There are essentially Ponzi schemes that are parading as cryptocurrencies, and that is one of
[01:30:04.160 --> 01:30:10.320]   the most dangerous parts about it. And that's why there is the need for regulation. I do believe what
[01:30:10.320 --> 01:30:17.520]   the folks like the Coinbase and a few others are saying that we just need some rules and
[01:30:17.520 --> 01:30:23.600]   guidelines we think everyone will be better off because they know that there are some really
[01:30:23.600 --> 01:30:30.560]   negative things happening and those are- have the potential to destroy or take away from
[01:30:30.560 --> 01:30:38.160]   the fundamental value of what people who want to build some things to bring resources to the unbanked,
[01:30:38.160 --> 01:30:45.120]   to create a store of value that's not just tied to a government and a government spending and
[01:30:45.120 --> 01:30:51.680]   those kinds of things. And those are values that I think are still potentially valuable with
[01:30:51.680 --> 01:30:57.120]   cryptocurrency, but the story is still unwritten and an interesting one.
[01:30:57.120 --> 01:31:01.840]   How about in the interviews? I really like what you're saying about the unbanked people who are
[01:31:01.840 --> 01:31:08.240]   not participants in the overall financial operation of the world. They are really left out. And so
[01:31:08.240 --> 01:31:13.360]   perhaps a crypto- cryptocurrency, although I have to say El Salvador does not do itself any favors
[01:31:13.360 --> 01:31:20.400]   by changing its currency to Bitcoin. For sure. No, not at all. And Bitcoin is, as you mentioned,
[01:31:20.400 --> 01:31:25.840]   it's a way to get rich quick and it's also a currency. As a currency, it seems to me that
[01:31:25.840 --> 01:31:32.480]   it's used mostly by cyber criminals for things like ransomware, DDoS, extortion, crypto-jacking,
[01:31:32.480 --> 01:31:38.480]   and crypto theft itself. There's a lot of theft of cryptocurrencies. And then
[01:31:38.480 --> 01:31:46.400]   that's when the enthusiasts feel really burned about the lack of the kinds of protections that
[01:31:46.400 --> 01:31:51.520]   exist in the conventional financial markets where you're protected to a certain extent.
[01:31:51.520 --> 01:31:57.440]   If somebody steals, somebody hacks and robs the place where you're keeping your
[01:31:57.440 --> 01:32:02.480]   crypto currencies and steals them all, well, too bad. You're out of luck. That's the end of the story.
[01:32:02.480 --> 01:32:07.840]   To be fair, more fraud is committed with the US dollar with dollars than are committed with
[01:32:07.840 --> 01:32:11.600]   cryptocurrency. But we have a prediction. But that's the deal that's still have the blockchain
[01:32:11.600 --> 01:32:16.320]   to track things too. That's been a global currency for centuries. You can't compare this
[01:32:16.320 --> 01:32:21.680]   new thing that most people don't even know what it is to the US dollar, which by the way,
[01:32:21.680 --> 01:32:26.960]   for counterfeiters, for North Korea, for all of the drug traffickers, the $100 bill
[01:32:26.960 --> 01:32:31.520]   is the currency of crime globally. Yes, that's true. But it's not really asking about it.
[01:32:31.520 --> 01:32:35.760]   Let me ask you about it. You're a bank account. You're not really an honest.
[01:32:35.760 --> 01:32:39.280]   Yeah, you're a protection. If somebody hacks into your bank,
[01:32:39.280 --> 01:32:44.800]   federal law requires that the bank make you whole. So it's not a regulation, right?
[01:32:44.800 --> 01:32:50.720]   I'm sorry. I was conforming. Maybe that's the biggest mistake that we've made is that we haven't
[01:32:50.720 --> 01:32:56.560]   regulated crypto as a security. Maybe it should be regulated as a security.
[01:32:56.560 --> 01:33:04.720]   Maybe insured like the FDIC. How about it? You buy your Donald Trump trading card.
[01:33:04.720 --> 01:33:09.920]   So, you know what? We're going to make fun of it, right? $99. Here it is. They were the cheesiest,
[01:33:10.800 --> 01:33:18.720]   the worst bad Photoshop's. Apparently, they took clothing from catalogs and public domain
[01:33:18.720 --> 01:33:26.880]   sources and put his face on them. But I got to point out something. Not only did it sell out
[01:33:26.880 --> 01:33:34.160]   at $99 each, but it is currently the floor price is $230.
[01:33:34.160 --> 01:33:40.720]   Do you have a good investment? It was a very good investment. If you sell it,
[01:33:40.720 --> 01:33:45.520]   if you sell it, the Trump organization gets 10%. 10%. That's the way that
[01:33:45.520 --> 01:33:56.800]   FDs often work. The one of one NFTs, which are only 2.4% of the 45,000 unit collection,
[01:33:56.800 --> 01:34:02.720]   about 1,000 cards, they're selling as much as 6 ETH at the time of writing.
[01:34:02.720 --> 01:34:11.760]   This one, here's the one that really could cost you a lot of money there. It's $3,667.
[01:34:11.760 --> 01:34:20.560]   It was $99 if you got it. There's Mr. Trump looking young and fit and his hair is marvelous,
[01:34:20.560 --> 01:34:25.360]   holding the torch from the Statue of Liberty in front of the Statue of Liberty, holding
[01:34:26.000 --> 01:34:29.760]   the same torch. This would be way funnier if the Statue of Liberty didn't have a torch.
[01:34:29.760 --> 01:34:39.120]   Like you stole it. But hey, if you bought it, it's $3,667 now.
[01:34:39.120 --> 01:34:42.960]   I wonder if somebody's manipulating that though. I wonder if that's really a natural market or
[01:34:42.960 --> 01:34:48.240]   somebody's producing. It is possible to manipulate it. You can buy it and sell it to yourself and
[01:34:48.240 --> 01:34:55.920]   get the price to go up. Perhaps, I mean, we mocked it this week on Twig when it came out. I thought,
[01:34:55.920 --> 01:35:01.040]   this is just a play. If you apply Trump's razor, that is the explanation. Trump's razor is that
[01:35:01.040 --> 01:35:06.080]   when it comes to Donald Trump, the stupidest explanation is the one that's likely to be true.
[01:35:06.080 --> 01:35:11.680]   So yeah, somebody's... This is one with him writing a red, white and blue elephant. I wish I got that one.
[01:35:11.680 --> 01:35:15.600]   I actually expected by now he was going to tell us all with a joke, but
[01:35:15.600 --> 01:35:19.840]   because I thought it would be an absolute disaster for him. Even Steve Bannon thought this was dumb.
[01:35:19.840 --> 01:35:23.120]   He mocked it. He said it's a terrible, you know, this is a scam.
[01:35:23.120 --> 01:35:26.480]   I ever agreed on any... But I got to tell you, it may be a scam, but
[01:35:26.480 --> 01:35:34.480]   by the way, here he is signing a tablet with a... Digital Sharpie.
[01:35:34.480 --> 01:35:39.600]   It's something sorry. Because that's an Apple pencil. Is this an iPad? I don't...
[01:35:39.600 --> 01:35:45.680]   I'm very confused about it. It is a digital Sharpie. But these are digital. You don't have a physical
[01:35:45.680 --> 01:35:52.400]   NFT. But I just have to point out, if you were cagey enough to pick up one of these cards,
[01:35:53.360 --> 01:35:57.440]   you're making a lot of his fans are like, "Where's my card? I thought I was buying a physical card.
[01:35:57.440 --> 01:36:00.640]   Where is it?" I can't find it. Yeah, they probably didn't know.
[01:36:00.640 --> 01:36:06.560]   I don't know. I still think there's something going on. I just can't believe that there are that
[01:36:06.560 --> 01:36:10.720]   many people that actually would have bought. I want to see stupid, but on the other hand,
[01:36:10.720 --> 01:36:16.000]   maybe they're not so stupid if they're double, triple their money. Let me sort this by price high
[01:36:16.000 --> 01:36:18.720]   to low. But the other question is, what's they going to be worth a month from now?
[01:36:19.280 --> 01:36:23.280]   Well, that's why if you got it, sell it. Wait a minute. Now, some of these are think...
[01:36:23.280 --> 01:36:31.280]   This is a one-of-one. Somebody says current price is 118 quadrillion dollars.
[01:36:31.280 --> 01:36:38.000]   I don't think that's definitely suspicious. That's not actually what it's been trading for.
[01:36:38.000 --> 01:36:41.040]   You can sell it for any price you want. I guess. Yeah.
[01:36:41.040 --> 01:36:45.120]   Did it make a point? Here's it. They're going to try to...
[01:36:45.120 --> 01:36:47.360]   Maybe they were worth a lot for a little while.
[01:36:47.360 --> 01:36:51.200]   They're just... The funny thing is that it's the worst Photoshop job I've ever seen.
[01:36:51.200 --> 01:36:58.080]   You could have spent some money on just... I mean, it's the same... They use the same face at all of them.
[01:36:58.080 --> 01:37:01.200]   Well, but they needed 45,000 of them. They probably didn't. Oh, maybe that's what they
[01:37:01.200 --> 01:37:08.000]   were talking about. Yeah. All right. I will no longer mock anybody buying an NFT.
[01:37:08.000 --> 01:37:16.640]   NFTs, they do have some potentially good uses longer term. There's the idea that
[01:37:16.640 --> 01:37:22.080]   they could be used for a number of authentication and cybersecurity uses.
[01:37:22.080 --> 01:37:27.360]   So the technology there is something that has the opportunity to have
[01:37:27.360 --> 01:37:32.560]   some positive impact as well. I know I keep getting into these kinds of things. But I think
[01:37:32.560 --> 01:37:38.560]   looking at the larger ecosystem of these things, it is interesting. And there's also that one of
[01:37:38.560 --> 01:37:48.240]   the more interesting thoughts I've seen about NFTs is that if we have this idea that we create
[01:37:48.240 --> 01:37:56.880]   value around digital goods and we spend more time purchasing or more resources, I should say,
[01:37:56.880 --> 01:38:04.800]   purchasing digital goods, because then you have it and we're creating less or buying fewer
[01:38:05.600 --> 01:38:10.240]   physical goods, which is having this negative impact on the environment with all the things
[01:38:10.240 --> 01:38:16.480]   that are shipped and all of that. But if I own it, essentially, digitally, and we have different
[01:38:16.480 --> 01:38:23.040]   and more evolved sense of digital ownership that you can call it up and look at it. And it's a bit
[01:38:23.040 --> 01:38:27.920]   of a one of a kind that there are some potential good uses of that, especially if they are less
[01:38:27.920 --> 01:38:33.280]   expensive and over time you're collecting things and creating less...
[01:38:34.800 --> 01:38:41.760]   I'd be more interested in the use of the provenance blockchain on physical goods. Like if I had a
[01:38:41.760 --> 01:38:48.080]   Honus Wagner card and you could prove the provenance, the card still is the item.
[01:38:48.080 --> 01:38:56.480]   Although I can't knock it, they sold 45,000 of these at 100 bucks. That's 4.5 million. And they
[01:38:56.480 --> 01:39:02.800]   get 10% of every secondary sale. This is potentially hundreds of millions dollars.
[01:39:03.600 --> 01:39:07.120]   And all it does is it paid some kids 17 bucks an hour to make
[01:39:07.120 --> 01:39:11.520]   crappy information. The reason I wouldn't buy an NFT, even if it was a piece of art that I really
[01:39:11.520 --> 01:39:17.360]   appreciated it is because unlike even a print, I mean, you kind of the point you made, I mean,
[01:39:17.360 --> 01:39:22.320]   if I had any interest in enjoying one of these Donald Trump things, I'd just download an image of
[01:39:22.320 --> 01:39:27.120]   it and put them on a wall. That's all you need? Yeah, I wouldn't own it, but I get to enjoy it.
[01:39:27.120 --> 01:39:32.560]   Well, if you're this an ego, there are some aspects. I mean, I've got some art that's
[01:39:32.560 --> 01:39:37.280]   numbered. And yeah, but frankly, I don't care about it. The fact that I may only own one
[01:39:37.280 --> 01:39:42.720]   120. I'm in a way a confession last Christmas. Maybe it was too Christmas as a good remember
[01:39:42.720 --> 01:39:48.480]   Trump got COVID. They made it the White House. There's a White House gift shop. This is not
[01:39:48.480 --> 01:39:54.240]   affiliated. Yeah, right. They made a challenge coin with a Trump's likeness on it and, you know,
[01:39:54.240 --> 01:39:59.200]   conquers COVID on it. And I and I bought two. I bought one for my father-in-law, who's a Trump
[01:39:59.200 --> 01:40:05.360]   fan. And I bought one because I thought this is history in some perverse way.
[01:40:05.360 --> 01:40:11.360]   And now I own it. I don't know what I'm going to do with it. But I also, since you all were
[01:40:11.360 --> 01:40:17.520]   making an F.T. I'll make an F.T. Since you all were good and revealed your stake in Bitcoin,
[01:40:17.520 --> 01:40:23.040]   not like, you know, it's all having a stock in that company we cover, but I somewhere have a
[01:40:23.040 --> 01:40:29.680]   wallet with 7.85 Bitcoin in it. I can't unlock it because I forgot the password. It's well known.
[01:40:29.680 --> 01:40:36.800]   But if it some there are people who say Bitcoin's going to come back, it's very much like the
[01:40:36.800 --> 01:40:43.120]   same people said, save your Confederate dollars, boys, the south will rise again. But if it goes
[01:40:43.120 --> 01:40:47.200]   up to somebody, some analysts said, don't worry, it's going to quarter of a million dollars per coin.
[01:40:48.480 --> 01:40:54.320]   I got my retirement, man. I'm good. I'll spend the rest of my days trying to find the password.
[01:40:54.320 --> 01:40:57.680]   I think you'll ever unlock the OST and then.
[01:40:57.680 --> 01:41:04.640]   Good bye, my own radio station. All right. Let's take it. By the way, Jason, I don't know if
[01:41:04.640 --> 01:41:09.920]   you've noticed, in effect, I have. This is what Twitter is. It's like a little radio TV station.
[01:41:09.920 --> 01:41:14.720]   When I was in starting out in radio, every was every DJ's goal to own a radio station.
[01:41:14.720 --> 01:41:18.400]   Right? Larry used to work. Oh, yeah, of course. I'll own a radio station.
[01:41:18.400 --> 01:41:24.400]   I without even attempting it, I've done it. Yeah, you have. You know, I don't have anything as
[01:41:24.400 --> 01:41:28.960]   significant as Twitter, but I remember when I first registered my web page. Larry, you can feel
[01:41:28.960 --> 01:41:35.360]   it. I'm a publisher. Nobody would ever make me a publisher. You know, I don't get millions of
[01:41:35.360 --> 01:41:38.640]   readers, but I, you know, there's something nice about owning your own piece of meat. That's
[01:41:38.640 --> 01:41:42.880]   what I'm saying. That's why everybody should have their own presence on the web that they control
[01:41:42.880 --> 01:41:48.560]   that they own. Yeah. That's the best way to assure that your reputation is owned by you.
[01:41:48.560 --> 01:41:55.200]   Actually, my reaction, I don't know, you all blog. My first reaction was, this is so self-centered.
[01:41:55.200 --> 01:42:01.200]   I can't believe I'm posting on my site an article about me. I thought I was kind of embarrassed by
[01:42:01.200 --> 01:42:06.880]   the whole thing. I got over it. That's because you're not an artist. That's right. Right. You're not an
[01:42:06.880 --> 01:42:10.960]   artist. Doesn't everybody want to read about me? If you had gone to Trump University, you would have
[01:42:10.960 --> 01:42:16.160]   learned. I should have already had to be an narcissist. Exactly. All right. Let's take a break.
[01:42:16.160 --> 01:42:21.760]   I do want to talk about something that is near and dear to my heart. I have been a audible customer
[01:42:21.760 --> 01:42:28.320]   since the year 2000. Audible has been, I think, is our longest running advertiser of all.
[01:42:28.320 --> 01:42:35.600]   We love Audible since even before they were bought by Amazon. For 15 years, we've been talking about
[01:42:35.600 --> 01:42:43.840]   audiobooks from Audible. I have in my library more than 500 audiobooks from Audible in every possible
[01:42:43.840 --> 01:42:52.320]   arena. Lately, I've been doing a lot of sci-fi. I didn't realize this, but apparently,
[01:42:52.320 --> 01:42:57.680]   Mr. Musk is heavily influenced by Ian Banks, the Scottish, the late Scottish sci-fi author,
[01:42:57.680 --> 01:43:07.280]   and by his culture series. In fact, the barges that those space boosters land on, that very cool
[01:43:07.280 --> 01:43:13.600]   thing, those are all named after things in the novel. Honey, I love you or whatever it's called.
[01:43:13.600 --> 01:43:19.760]   So I've decided to go through the culture series. They're all on Audible. It just comes to life in
[01:43:19.760 --> 01:43:25.520]   your brain. I think your brain is so much better than Hollywood at making the sets, at making the
[01:43:25.520 --> 01:43:32.240]   people. And you imagine it, your imagination takes off. That's one of the reasons I love audiobooks
[01:43:32.240 --> 01:43:37.120]   from Audible.com. I want to encourage you, if you've been hearing our ads and you've been holding off,
[01:43:37.120 --> 01:43:42.000]   this would be a great time. By the way, a great time to give the gift of Audible as well
[01:43:42.000 --> 01:43:48.240]   for the holidays. When it comes to audio entertainment, there's no better place than Audible. It's the
[01:43:48.240 --> 01:43:54.320]   home for stories told by the biggest stars in Hollywood, Ethan Hawke, Kerry Washington,
[01:43:54.320 --> 01:43:59.120]   Kevin Hart, Audible's home to epic adventures, chilling mysteries,
[01:43:59.120 --> 01:44:05.520]   Can't Miss comedies. I've done almost all of the Agatha Christie audiobooks. I just love them.
[01:44:05.520 --> 01:44:11.600]   Let your imagination soar with audiobooks, podcasts, Audible originals. One of the things Audible
[01:44:11.600 --> 01:44:17.600]   does that I really love is they're doing recordings of classic sci-fi that never got recorded because
[01:44:17.600 --> 01:44:22.960]   back in the day, you know, toward and have the budget to record those. So Audible's doing it in
[01:44:22.960 --> 01:44:29.840]   their own studios. You can get the Dune series done beautifully by Audible. You can get Asimov's
[01:44:29.840 --> 01:44:34.720]   Foundation series done beautifully by Audible. Never recorded originally Audible made them.
[01:44:34.720 --> 01:44:39.920]   I love that. Audible is the home of storytelling. All your audio entertainment in one app, get the
[01:44:39.920 --> 01:44:46.000]   app on your phone, text, Twitch to 500 500 right now. They'll give you a link and download it.
[01:44:46.640 --> 01:44:54.000]   And then start listening. As a member of Audible, you also get access to a huge and growing library
[01:44:54.000 --> 01:45:00.720]   of included audiobooks. So stuff that Audible just, for instance, I was listening to the
[01:45:00.720 --> 01:45:08.400]   Fletch after I saw the movie with John Hamm Fletch, Confess Fletch. It turned out they were all kind
[01:45:08.400 --> 01:45:14.240]   of part of my subscription. It was great. They're just part of the deal. You can download and stream
[01:45:14.240 --> 01:45:20.240]   all the included titles as much as you want. You get to choose a title a month from their catalog
[01:45:20.240 --> 01:45:30.160]   to keep. So that's how I've accumulated 500 plus audio books over the last 22 years. Wow.
[01:45:30.160 --> 01:45:36.400]   The latest bestsellers are their new releases classics. Also an incredible selection of audiobooks,
[01:45:36.400 --> 01:45:44.160]   every genre bestsellers, new releases, celebrity memoirs. Audible is a place your imagination
[01:45:44.160 --> 01:45:50.640]   can run wild. Listen about the lives of celebrities journey to your best self. Check out the spider
[01:45:50.640 --> 01:45:55.760]   web of true crimes, discover new worlds, old worlds, how to make a better world. New members
[01:45:55.760 --> 01:46:02.160]   can try it free for 30 days. Let Audible help you discover new ways to laugh, be inspired or
[01:46:02.160 --> 01:46:07.680]   be entertained. I love Audible. I know you will too. If you're not yet a member, I know most of you
[01:46:07.680 --> 01:46:14.080]   are. But if you are not yet a member, join the join the club audible.com/twit or again text
[01:46:14.080 --> 01:46:22.480]   twit to 500 500 audible.com/twit or text twit to 500 500. That'll give you a chance to try
[01:46:22.480 --> 01:46:28.080]   audible for free for 30 days. You get the title, but you also get this huge selection of audible
[01:46:28.080 --> 01:46:38.720]   content available to you. Audible, A-U-D-I-B-L-E.com/twit. I'm a huge fan. I think we're going on a
[01:46:38.720 --> 01:46:45.120]   little vacation after the holidays and I think I'm going to bring up a bunch of audiobooks to
[01:46:45.120 --> 01:46:48.880]   listen to. I love those audiobooks. They're so great.
[01:46:48.880 --> 01:46:51.120]   >> The recommendation, Leo?
[01:46:51.120 --> 01:46:56.560]   >> Yeah. Jason, have you been around long enough? We like to hear your audible recommendations.
[01:46:56.560 --> 01:47:01.360]   Yeah. I'll just throw a quick one. Atomic habits, I've been relistening to this one.
[01:47:01.360 --> 01:47:02.000]   >> That's a classic.
[01:47:02.000 --> 01:47:08.480]   >> I love it. There's one line in there and I think it connects to some things we've been
[01:47:08.480 --> 01:47:16.640]   talking about today that I love, which is we tend to think that we rise to the level of our goals
[01:47:16.640 --> 01:47:19.680]   when the truth is we often fall to the level of our systems.
[01:47:19.680 --> 01:47:20.640]   >> Oh, yes.
[01:47:21.520 --> 01:47:26.720]   And that happens for human beings. That's where the habits part come in, but it also happens for
[01:47:26.720 --> 01:47:33.280]   organizations as well. And so I think that that is just maybe a little bit of a taste.
[01:47:33.280 --> 01:47:35.520]   That's my biggest takeaway from this book.
[01:47:35.520 --> 01:47:39.840]   >> That's really profound, though. And I think that that's really true. I know that's true in my
[01:47:39.840 --> 01:47:48.880]   life and for our company. It's very easy to settle and instead of rising to your highest
[01:47:48.880 --> 01:47:54.800]   hopes and aspirations. I like that. I've never read this. I'm putting on my list right now.
[01:47:54.800 --> 01:47:59.760]   It's going into my wish list because I don't have any credits yet, but I will have a couple on the
[01:47:59.760 --> 01:48:00.240]   20 seconds.
[01:48:00.240 --> 01:48:03.680]   >> It's funny. You're talking earlier, what are you doing? That thing for Zoom. I've lost some
[01:48:03.680 --> 01:48:09.360]   weight also. And one of the ways I've lost weight, I do a lot of walking and listening to books while
[01:48:09.360 --> 01:48:14.160]   I walk is fantastic. I mean, I almost encourage you to walk to listen to books.
[01:48:14.160 --> 01:48:14.800]   >> That's right.
[01:48:14.800 --> 01:48:18.880]   >> Apple has that thing where you have walk with Dolly partner or whatever.
[01:48:18.880 --> 01:48:25.760]   And it's kind of funny because I think these people are in a studio and they're putting walking
[01:48:25.760 --> 01:48:30.240]   sounds behind them. I don't think they're actually walking, but they make it out like they're walking.
[01:48:30.240 --> 01:48:36.880]   Sometimes they get a little bit out of breath. It's hysterical. These fitness plus walk walking.
[01:48:36.880 --> 01:48:39.120]   >> I wouldn't have picked Dolly Parton if my walking partner.
[01:48:39.120 --> 01:48:43.760]   >> That was my favorite one of all things. I really enjoyed it. I'm walking with Dolly.
[01:48:43.760 --> 01:48:46.880]   But she only walked for about 20 minutes and I had to keep going and she turned around.
[01:48:46.880 --> 01:48:51.680]   So that's why it's better to listen to an audiobook. It'll take you the whole way.
[01:48:51.680 --> 01:48:53.120]   Actually, I'm trying to walk more.
[01:48:53.120 --> 01:48:58.160]   >> I never understand celebrities and what they endure. It's like, why would you buy a fragrance
[01:48:58.160 --> 01:49:01.440]   from a basketball player? I don't imagine basketball players.
[01:49:01.440 --> 01:49:03.840]   >> Fresh sweat.
[01:49:03.840 --> 01:49:03.840]   >> Fresh sweat.
[01:49:03.840 --> 01:49:04.800]   >> Yeah.
[01:49:04.800 --> 01:49:12.960]   >> No, one of the things I learned from Noom is if you walk after a meal, it brings your blood sugar
[01:49:12.960 --> 01:49:19.840]   down. There's something about walking that is really not even a long walk or a fast walk,
[01:49:19.840 --> 01:49:25.040]   just a stroll for 10 minutes after a meal. It makes a huge difference.
[01:49:25.040 --> 01:49:27.280]   >> It also gives you digestion too.
[01:49:27.280 --> 01:49:30.080]   >> Well, yeah. Your body expects this.
[01:49:30.080 --> 01:49:38.560]   >> Leo, Helen Putnam Regional Park is the most beautiful walking space on the planet.
[01:49:38.560 --> 01:49:39.200]   >> Love it.
[01:49:39.200 --> 01:49:40.640]   >> It is paradise.
[01:49:40.640 --> 01:49:44.080]   There's only one bad thing about it. There's a very steep hill.
[01:49:44.080 --> 01:49:46.960]   >> Yes, we call it the Widowmaker.
[01:49:46.960 --> 01:49:53.360]   >> So I'm huffing and puffing. At least it's going, "What the hell?" I'm going, "Wait for me.
[01:49:53.360 --> 01:49:57.680]   I'm getting there." It's pretty steep. But then when you come back, you go down the hill.
[01:49:57.680 --> 01:49:58.400]   So it's okay.
[01:49:58.400 --> 01:49:58.800]   >> Right.
[01:49:58.800 --> 01:50:01.680]   >> With all of you walking downhill.
[01:50:01.680 --> 01:50:03.200]   >> I'm better off walking uphill.
[01:50:03.200 --> 01:50:04.400]   >> Yeah, me too. I'm the same way.
[01:50:04.400 --> 01:50:05.920]   >> I'm trudging uphill. I agree with you.
[01:50:05.920 --> 01:50:06.480]   >> Yeah.
[01:50:06.480 --> 01:50:10.080]   When I lived in San Francisco, in the hills of San Francisco, for some reason,
[01:50:10.080 --> 01:50:14.320]   women would, they'd take off their heels and walk backwards up the hills.
[01:50:14.320 --> 01:50:18.400]   There must have been some books somewhere that said, "It's good for your butt if you walk
[01:50:18.400 --> 01:50:21.360]   backwards up the hill." I never did that. I thought that was something like fun.
[01:50:21.360 --> 01:50:23.760]   I'd rather walk forward up the hill.
[01:50:23.760 --> 01:50:27.680]   All right. That's our fitness segment for the day.
[01:50:27.680 --> 01:50:30.320]   Thank God that's over.
[01:50:30.320 --> 01:50:31.280]   >> Yeah.
[01:50:31.280 --> 01:50:34.400]   >> By the way, while we had our Elon conversation, sorry to bring this back,
[01:50:34.400 --> 01:50:37.680]   he posted in the middle of our conversation, coincidence maybe,
[01:50:37.680 --> 01:50:42.880]   he posted, "Should I step down as head of Twitter? I will abide by the results of this poll."
[01:50:42.880 --> 01:50:43.840]   >> Oh, I'll vote.
[01:50:43.840 --> 01:50:52.000]   >> And now or later, it's 58% say yes. After it jumped up to 58%, he posted,
[01:50:52.000 --> 01:50:55.440]   "Be careful what you wish for." Yeah.
[01:50:55.440 --> 01:50:56.640]   >> We're gonna hear it.
[01:50:56.640 --> 01:50:57.200]   >> So dumb.
[01:50:57.200 --> 01:51:00.720]   >> He is such a master of attention. He's a tension whore.
[01:51:00.720 --> 01:51:01.440]   >> Yes.
[01:51:01.440 --> 01:51:03.120]   >> Such a tension whore.
[01:51:03.120 --> 01:51:03.680]   >> He's a trouble.
[01:51:03.680 --> 01:51:07.440]   >> He'll be worth it if he hired Kanye to take over. I mean, what could be worse?
[01:51:07.440 --> 01:51:12.240]   >> Well, first of all, I have to presume that because he posted this, he's got somebody.
[01:51:12.240 --> 01:51:14.000]   And it's probably Jason Kelliganis.
[01:51:14.000 --> 01:51:19.760]   Or who's the other guy who's in the room? Apparently, there's a small number of people in the room.
[01:51:19.760 --> 01:51:25.840]   One of his investor VC, my camera is named, he's always tweeting to defend Elon.
[01:51:25.840 --> 01:51:28.960]   So I think he already has a candidate.
[01:51:28.960 --> 01:51:34.160]   Besides, he's under a lot of pressure from his shareholders and his other companies.
[01:51:34.160 --> 01:51:35.760]   >> He's gonna lose his Tesla job.
[01:51:35.760 --> 01:51:42.720]   >> Yeah, exactly. So I think there's a lot of pressure on him to maybe step down.
[01:51:42.720 --> 01:51:47.520]   Yeah, maybe he's sending a little bit of contrite. Maybe he didn't expect it. Maybe the booze at the
[01:51:47.520 --> 01:51:48.400]   Chappelle concert.
[01:51:48.400 --> 01:51:49.760]   >> Yeah. That was a big deal.
[01:51:49.760 --> 01:51:50.080]   >> Yeah.
[01:51:50.080 --> 01:51:51.200]   >> I don't know.
[01:51:51.200 --> 01:51:52.880]   >> I don't know.
[01:51:52.880 --> 01:51:58.640]   Anyway, we'll see. But it's interesting. I think he might have thought, he might have also thought,
[01:51:58.880 --> 01:52:03.280]   "Oh, I don't have to worry about this because all of the bots from the GRU and etc.
[01:52:03.280 --> 01:52:09.840]   We're gonna vote." No. It's interesting. So I didn't vote. So you can see the result right now,
[01:52:09.840 --> 01:52:10.160]   Jason.
[01:52:10.160 --> 01:52:11.120]   >> Yeah.
[01:52:11.120 --> 01:52:13.280]   >> When the polls close?
[01:52:13.280 --> 01:52:14.880]   >> It's 10 hours left.
[01:52:14.880 --> 01:52:18.080]   >> It says 4.1 million votes. Wow.
[01:52:18.080 --> 01:52:22.000]   >> Yeah, 57.9% say yes.
[01:52:22.000 --> 01:52:22.320]   >> Whoa!
[01:52:22.320 --> 01:52:24.480]   >> Okay.
[01:52:24.480 --> 01:52:25.360]   >> That's very interesting.
[01:52:25.360 --> 01:52:27.120]   >> I am so tempted to think that. >> People have spoken.
[01:52:27.120 --> 01:52:28.000]   But I'm not gonna.
[01:52:28.000 --> 01:52:32.720]   He will says I will abide by the results of this poll.
[01:52:32.720 --> 01:52:36.880]   Well, see?
[01:52:36.880 --> 01:52:38.000]   >> See? Of course he's a liar.
[01:52:38.000 --> 01:52:40.080]   >> We said we weren't gonna talk about him.
[01:52:40.080 --> 01:52:40.480]   >> Yeah.
[01:52:40.480 --> 01:52:42.480]   >> And he said, "I'll fix that."
[01:52:42.480 --> 01:52:46.240]   >> Yeah. I sure am enjoying my Robotaxia that I bought for him.
[01:52:46.240 --> 01:52:47.040]   >> Oh, yeah.
[01:52:47.040 --> 01:52:50.400]   Did you pay for the extra $5,000?
[01:52:50.400 --> 01:52:55.520]   >> In my case, it wound up being 7,000. And I did it as a tech journalist, frankly,
[01:52:55.520 --> 01:52:57.680]   since he wasn't gonna give me an eval copy, right?
[01:52:57.680 --> 01:53:02.560]   To loan me. I did as a tech journalist. I wanted to understand what self-driving was all about.
[01:53:02.560 --> 01:53:07.120]   And so I think I benefited from it professionally. But as a driver, it's nonsense.
[01:53:07.120 --> 01:53:09.040]   >> Did you get FSD? You finally got it?
[01:53:09.040 --> 01:53:10.720]   >> Oh, yeah. I got the full vote.
[01:53:10.720 --> 01:53:12.160]   >> And how does it work for you?
[01:53:12.160 --> 01:53:16.320]   >> Sometimes. I mean, it works, but you have to watch.
[01:53:16.320 --> 01:53:17.200]   Put it this way.
[01:53:17.200 --> 01:53:20.320]   Every driver has to be aware of their own potential mistakes.
[01:53:20.320 --> 01:53:21.680]   And then it takes some other drivers.
[01:53:21.680 --> 01:53:25.200]   Now I have to worry about that, plus the mistakes of my car.
[01:53:25.200 --> 01:53:30.400]   And if you don't, it can do some very outrageous things, like,
[01:53:30.400 --> 01:53:32.000]   you know, zip into the wrong lane.
[01:53:32.000 --> 01:53:32.560]   >> Yeah.
[01:53:32.560 --> 01:53:36.320]   >> Or make a left turn from the right lane, or the right turn from the left lane.
[01:53:36.320 --> 01:53:38.240]   And it does also have some weird stuff.
[01:53:38.240 --> 01:53:44.400]   >> I paid $5,000 when I got my Tesla Model X, which was six years ago,
[01:53:44.400 --> 01:53:47.440]   and he never released it. So I was $5,000 out the window.
[01:53:47.440 --> 01:53:50.240]   >> I know. >> Those who have spent $15,000.
[01:53:50.240 --> 01:53:50.960]   >> Right.
[01:53:50.960 --> 01:53:53.840]   >> Everybody has it now, although this is an article.
[01:53:53.840 --> 01:53:55.280]   >> Oh, you still have to buy it. You still have to buy.
[01:53:55.280 --> 01:53:57.680]   Everybody who bought it has access to it.
[01:53:57.680 --> 01:54:00.800]   But I think you still have to pay the $15K at whatever cost.
[01:54:00.800 --> 01:54:01.840]   >> Oh, really?
[01:54:01.840 --> 01:54:02.560]   >> I think so.
[01:54:02.560 --> 01:54:03.360]   >> Oh.
[01:54:03.360 --> 01:54:04.800]   >> If not, I got kind of ripped off.
[01:54:04.800 --> 01:54:06.720]   I mean, yeah, because I did buy it.
[01:54:06.720 --> 01:54:07.680]   You still have to buy it.
[01:54:07.680 --> 01:54:09.840]   The thing is, you got really ripped off because you leased it.
[01:54:09.840 --> 01:54:12.000]   And so you had to return the car and got no value.
[01:54:12.000 --> 01:54:12.480]   >> Got nothing.
[01:54:12.480 --> 01:54:13.360]   >> Got nothing.
[01:54:13.360 --> 01:54:16.400]   And by the way, anybody who bought that car would not get.
[01:54:16.960 --> 01:54:17.760]   >> Right.
[01:54:17.760 --> 01:54:20.720]   >> The value that I spent for $5,000, whoever got that car,
[01:54:20.720 --> 01:54:24.800]   or if I'd sold it myself, wouldn't get the, it's per person.
[01:54:24.800 --> 01:54:27.040]   >> And here's the other thing that's crazy.
[01:54:27.040 --> 01:54:28.800]   >> It used to stay with the vehicle.
[01:54:28.800 --> 01:54:29.920]   >> It doesn't now, though.
[01:54:29.920 --> 01:54:30.560]   >> Yeah.
[01:54:30.560 --> 01:54:31.600]   >> Here's the other thing.
[01:54:31.600 --> 01:54:34.720]   If you buy a new, now at this point, I'm never going to buy a Tesla.
[01:54:34.720 --> 01:54:38.880]   But I used to want to think, I used to think I was going to buy a new Tesla at some point.
[01:54:38.880 --> 01:54:41.520]   If I did, I'd have to reinvest that all over again.
[01:54:41.520 --> 01:54:45.040]   I can't take my software with me like I can on my computer, right?
[01:54:45.040 --> 01:54:48.960]   If I get a new PC, I can take Microsoft off of it with me to the new PC.
[01:54:48.960 --> 01:54:51.600]   Not any Tesla software.
[01:54:51.600 --> 01:54:53.440]   >> So this is an appeal.
[01:54:53.440 --> 01:54:54.160]   Sorry, go ahead.
[01:54:54.160 --> 01:55:00.880]   >> This article from Electric, Fred Lambert writing, says, I think what we would like to know is,
[01:55:00.880 --> 01:55:05.040]   an every self-driving vehicle Waymo crews releases this information,
[01:55:05.040 --> 01:55:13.600]   but Tesla refuses to, is the disengagement release data and the driver intervention data.
[01:55:13.600 --> 01:55:16.960]   In other words, how often do drivers have to take over?
[01:55:16.960 --> 01:55:18.320]   How often is this?
[01:55:18.320 --> 01:55:19.760]   >> Every time, in my case.
[01:55:19.760 --> 01:55:24.080]   >> No, literally, almost every time I use it within about 15 minutes,
[01:55:24.080 --> 01:55:28.080]   maybe I didn't have to take over, maybe I could have just sat there and I would have survived.
[01:55:28.080 --> 01:55:32.800]   But something happens to scare me and to hit my foot on the brake and to take over.
[01:55:32.800 --> 01:55:36.480]   Just because, you know, this, I'm not saying it would have crashed, but it certainly
[01:55:36.480 --> 01:55:38.880]   got close enough to scare me.
[01:55:38.880 --> 01:55:44.480]   >> The, there is a group of Tesla FSD beta testers who have been self-reporting the data.
[01:55:44.480 --> 01:55:51.120]   According to this article, the miles driven per disengagement have gone down by 54% since
[01:55:51.120 --> 01:55:55.600]   March. So it's getting smarter. Wait a minute, but it currently sits around the same level it
[01:55:55.600 --> 01:55:57.120]   was around this time last year.
[01:55:57.120 --> 01:55:58.080]   >> Yeah, good.
[01:55:58.080 --> 01:56:00.000]   >> So it got dumber and then it got smarter.
[01:56:00.000 --> 01:56:06.720]   It's actually, my overall miles per disengagement is actually getting worse.
[01:56:06.720 --> 01:56:12.000]   Oh, I'm sorry. Down miles driven is down by 54%.
[01:56:12.000 --> 01:56:13.920]   >> How many miles?
[01:56:13.920 --> 01:56:17.200]   >> I don't know what it's again.
[01:56:17.200 --> 01:56:19.680]   >> It's essentially saying there are more disengagement.
[01:56:19.680 --> 01:56:20.320]   >> Per mile.
[01:56:20.320 --> 01:56:20.800]   >> Yeah.
[01:56:20.800 --> 01:56:24.400]   >> Per mile, which I think is not to put this in perspective.
[01:56:24.400 --> 01:56:30.160]   And I also, I have a Tesla Model Y. I did not buy FSD, but I did get the subscription where
[01:56:30.160 --> 01:56:36.640]   you pay $200 for it. So for the same reason, Larry did is to test it as a
[01:56:36.640 --> 01:56:42.800]   tech journalist. I think this isn't surprising in the sense that more and more people are
[01:56:42.800 --> 01:56:46.640]   using it, right? And so I think that that's not surprising.
[01:56:46.640 --> 01:56:47.200]   >> Oh, right.
[01:56:47.200 --> 01:56:55.440]   >> I think you also have to take into account that Twitter, so Twitter, Tesla is posting.
[01:56:55.440 --> 01:56:56.960]   >> See, there's the problem right there.
[01:56:56.960 --> 01:56:57.440]   >> I know.
[01:56:57.440 --> 01:56:58.160]   >> It's confusing.
[01:56:58.160 --> 01:56:58.560]   >> Yeah.
[01:56:58.560 --> 01:57:06.400]   >> It is confusing. Too many Ts. The Tesla is pushing this out
[01:57:06.400 --> 01:57:10.800]   way. In fact, I wouldn't even call it beta. I call it more like alpha software.
[01:57:10.800 --> 01:57:11.040]   >> Yeah.
[01:57:11.040 --> 01:57:11.040]   >> Right?
[01:57:11.040 --> 01:57:11.600]   >> Yeah.
[01:57:11.600 --> 01:57:17.200]   >> They're pushing this out so more people have access with lots of disclaimers.
[01:57:17.200 --> 01:57:22.800]   And you also have to pass the, well, for most of the year, you had to pass the test of being,
[01:57:22.800 --> 01:57:24.080]   you know, a generally safe driver.
[01:57:24.080 --> 01:57:25.760]   >> Now it's easier. You don't have to be a safe driver.
[01:57:25.760 --> 01:57:26.880]   >> It is easier now.
[01:57:26.880 --> 01:57:27.600]   >> Which is worse.
[01:57:27.600 --> 01:57:29.200]   >> Which makes it worse.
[01:57:29.200 --> 01:57:33.920]   >> They've let less and less safe drivers into it throughout the year.
[01:57:33.920 --> 01:57:38.720]   That's my problem because, I mean, it's fine with me if you guys want to spend money on it.
[01:57:38.720 --> 01:57:43.360]   But I'm the beta tester. I'm the guy walking across the street in front of a Tesla or driving
[01:57:43.360 --> 01:57:49.360]   my car, getting a lane in the opposite direction. And I don't know, you know, you're using public
[01:57:49.360 --> 01:57:54.720]   highways and the rest of the world as your test. And yes, of course, it's going to get better.
[01:57:54.720 --> 01:57:56.800]   This stuff is neural network. It's going to learn.
[01:58:00.400 --> 01:58:05.920]   The self-reporting metric is a mere 72,000 miles compared to 60 million miles
[01:58:05.920 --> 01:58:10.080]   driven total by FSD beta. So it is a small fraction.
[01:58:10.080 --> 01:58:15.120]   That's my only complaint is it's fine. I just don't want to be the guinea pig.
[01:58:15.120 --> 01:58:19.120]   >> But on the highway, it works great. I mean, I really love it on the freeway.
[01:58:19.120 --> 01:58:22.880]   And I like the fact that it will stop at stoplights and stop signs. And it's pretty good about that.
[01:58:22.880 --> 01:58:23.680]   It's pretty reliable.
[01:58:23.680 --> 01:58:27.280]   >> I use their adaptive cruise control.
[01:58:27.280 --> 01:58:27.920]   >> Right.
[01:58:27.920 --> 01:58:31.760]   >> And lane change capability. And that was I stopped using the lane change. That one,
[01:58:31.760 --> 01:58:36.480]   you just you signal lane change. The car would do it. It would cut off cars all the time. So I
[01:58:36.480 --> 01:58:40.960]   stopped doing that. And I always, you know, with this one, you have the old one, you had to keep
[01:58:40.960 --> 01:58:41.680]   your hands on the wheel.
[01:58:41.680 --> 01:58:42.400]   >> You still do.
[01:58:42.400 --> 01:58:43.120]   >> You still do.
[01:58:43.120 --> 01:58:44.880]   You can't take your hands off the wheel. Well, that's interesting.
[01:58:44.880 --> 01:58:45.760]   >> Oh, no, I just know.
[01:58:45.760 --> 01:58:51.600]   >> Both GM and Ford have a hands-free solution. Highways only, though, map highways only.
[01:58:51.600 --> 01:58:56.960]   I think it's easier. Easier in a highway. Stop signs, red lights, green lights, pedestrians.
[01:58:56.960 --> 01:59:00.400]   >> So do you want to succeed in getting me? I don't know when I'm going to buy a new car,
[01:59:00.400 --> 01:59:02.560]   but I doubt very much whether it can be from him.
[01:59:02.560 --> 01:59:06.320]   >> If nothing else, it's bad for your reputation.
[01:59:06.320 --> 01:59:08.960]   >> I'm thinking about putting that bumper sticker.
[01:59:08.960 --> 01:59:09.760]   >> Hold on.
[01:59:09.760 --> 01:59:10.400]   >> Before I knew it.
[01:59:10.400 --> 01:59:10.960]   >> Oh, look.
[01:59:10.960 --> 01:59:15.120]   >> Oh, look. Milano tweeted. I remember this. She tweeted,
[01:59:15.120 --> 01:59:18.480]   "I'm getting rid of my Tesla and buying a VW."
[01:59:18.480 --> 01:59:24.320]   To which somebody said, "You mean you're going to buy a car literally designed by Nazis?"
[01:59:24.320 --> 01:59:30.480]   >> Right. VW is no longer a Nazi owned. I think it's safe to say.
[01:59:30.480 --> 01:59:34.160]   >> I think the VW's designed the not-
[01:59:34.160 --> 01:59:36.320]   They're not, he's designed the VW, but they no longer work there.
[01:59:36.320 --> 01:59:39.600]   When Elon designed the Tesla, I'm not sure he was a Nazi yet.
[01:59:39.600 --> 01:59:40.640]   >> No, yeah, but now.
[01:59:40.640 --> 01:59:41.120]   >> Yeah.
[01:59:41.120 --> 01:59:44.080]   >> And he's not truly a Nazi. I don't know what he is.
[01:59:44.080 --> 01:59:49.440]   >> Keep in mind with Tesla, too. Is Elon lost interest in Tesla over two years ago, right?
[01:59:49.440 --> 01:59:49.920]   >> Yeah.
[01:59:49.920 --> 01:59:55.680]   >> Once they got the Model 3 and that was, Elon is good at some things.
[01:59:55.680 --> 02:00:00.560]   Let's be honest. He loves trying to put a lot of energy into big problems.
[02:00:00.560 --> 02:00:00.880]   >> Right.
[02:00:00.880 --> 02:00:06.240]   >> And he's very good at that. But when he lost interest in Tesla after they got the Model 3
[02:00:06.240 --> 02:00:12.720]   delivered, and since then it's really becoming an operas, they need to operationalize.
[02:00:12.720 --> 02:00:13.040]   >> Right.
[02:00:13.040 --> 02:00:17.920]   >> Excuse me. This is kind of the level of the systems thing. They need to build systems that
[02:00:17.920 --> 02:00:24.240]   make cars for less money, that put them in local areas. That's why they built the
[02:00:24.240 --> 02:00:30.640]   plant in Shanghai, the plant in Berlin. They need to do all the things to become a great car
[02:00:30.640 --> 02:00:35.040]   company. That's what they're working on now. And that's not a big problem that Elon needs to
[02:00:35.040 --> 02:00:40.000]   solve. So really other people have been running Tesla for the past two to three years, and Elon
[02:00:40.000 --> 02:00:45.920]   has barely been involved. He pulled back from the earnings calls. It was clear on the earnings
[02:00:45.920 --> 02:00:51.280]   calls at times the CFO would interrupt him and say, well, actually here's sort of,
[02:00:51.280 --> 02:00:57.920]   he would do it in the most polite, politic way possible. But it was clear that Elon barely
[02:00:57.920 --> 02:01:03.040]   had been briefed on what Tesla was doing when you listen to him on earnings calls to be able to
[02:01:03.040 --> 02:01:08.800]   speak to it. And then other people picked up and really his done had been doing the real work for
[02:01:08.800 --> 02:01:15.600]   years over at Tesla. And frankly, they've done some magnificent work. I mean, I'm not really a
[02:01:15.600 --> 02:01:20.880]   car person. I've had the car for two years. It's the best car I've ever owned by far.
[02:01:20.880 --> 02:01:28.240]   And I really looked at it was really hard decision for me because I'd owned a Ford for like 20 years
[02:01:28.240 --> 02:01:33.360]   and loved Ford. And I had to choose between the Machi and the Tesla Model Y and then the VW,
[02:01:33.360 --> 02:01:40.720]   they're, now I'm forgetting the name of it all of a sudden. And it took me about six months to
[02:01:40.720 --> 02:01:48.240]   kind of decide. And now I would not, I don't regret it at all. Like it was by far the one of the
[02:01:48.240 --> 02:01:52.640]   better decisions. When I bought mine, it's been, it'll be four, it actually has been four years.
[02:01:52.640 --> 02:01:57.280]   The decision was literally, I was debating between that and I can't remember what else. I think
[02:01:57.280 --> 02:02:03.120]   a Honda had a pretty interesting car. And I saw a newspaper article which told me what I already knew,
[02:02:03.120 --> 02:02:07.920]   which is that Tesla has software updates. And I thought to myself, I have never owned a car that
[02:02:07.920 --> 02:02:12.960]   isn't worse than it was the day I bought it. And the idea that my Tesla and your Tesla are better
[02:02:12.960 --> 02:02:16.400]   than they were when we bought them. That's cool. My case, four years ago, it's kind of cool.
[02:02:16.400 --> 02:02:19.280]   Yeah. That's probably going to be true with all modern cars, I assume.
[02:02:19.280 --> 02:02:24.000]   I think because of over the year updates that almost all modern cars use, that's probably true.
[02:02:24.000 --> 02:02:28.880]   But Tesla was the first to make that happen. Absolutely. I mean, I have a 2016 Prius, which
[02:02:28.880 --> 02:02:33.920]   still has the same GPS coordinates it had when I bought it, probably designed in 2014.
[02:02:34.960 --> 02:02:42.000]   You know, I loved my model X. My wife did not. I like my Ford Mach-E, which is electric and has
[02:02:42.000 --> 02:02:45.840]   many of the same features. It's kind of like a Ford. Do they update it pretty often?
[02:02:45.840 --> 02:02:50.240]   Yeah, it gets over the year updates every few weeks. Yeah. Good. So I think there's a lot to be
[02:02:50.240 --> 02:02:54.560]   said for. By the way, the name of the guy I was trying to remember is David Sacks, who was a vice
[02:02:54.560 --> 02:03:00.720]   VC at Kraft Ventures. He's one of the so-called guys in the room with Jason Calicanis.
[02:03:02.160 --> 02:03:10.000]   And I can't remember the other name. Chamath Palaptaya. These various people who are kind of
[02:03:10.000 --> 02:03:16.560]   advisors, one of them will almost certainly become the CEO. Are any of them adult supervision?
[02:03:16.560 --> 02:03:20.720]   No, they're the worst. Just read David Sacks tweets. He's the worst.
[02:03:20.720 --> 02:03:25.360]   I think he's egging Elon on, to be honest with you.
[02:03:25.360 --> 02:03:28.960]   I mean, Elise Zuckerberg had Cheryl Sandberg for a while. I mean,
[02:03:28.960 --> 02:03:34.880]   yeah. Yeah. My guess is one of those guys will become CEO of Twitter. And of course,
[02:03:34.880 --> 02:03:38.560]   they're pawns of Elon in the long run. So it doesn't really much matter. He gets to do what he
[02:03:38.560 --> 02:03:44.560]   wants no matter what. All right. I want to take one more break. And then I have like 40 stories,
[02:03:44.560 --> 02:03:50.320]   but they're all short that we haven't gotten to. Yeah, we'll just do the rapid fire drill in just a
[02:03:50.320 --> 02:03:56.080]   bit with a wonderful panel. Jason Heiner, founder of the Tech Republic. He's now editor in chief of
[02:03:56.080 --> 02:03:59.120]   ZD net, just proof positive. Nice guys finish first.
[02:03:59.120 --> 02:04:07.600]   Yeah, sometimes very rarely. But are you a football, a soccer fan? Jason, you feel like you are?
[02:04:07.600 --> 02:04:14.320]   I'm not. Maybe it's because maybe it is sort of European.
[02:04:14.320 --> 02:04:18.080]   You know, I look like a hooligan, a soccer hooligan. I just thought,
[02:04:18.080 --> 02:04:24.560]   I played baseball and basketball going up and runner. Be careful. He might beat you up if you
[02:04:24.560 --> 02:04:31.440]   want to be a soccer hooligan. It was it was, of course, a very exciting one. No spoilers.
[02:04:31.440 --> 02:04:37.920]   World Cup final this morning. Well, at least the people who were fans tell me it was exciting.
[02:04:37.920 --> 02:04:44.800]   I'm not wasn't there to me. It was like a bunch of guys running around in their shorts. And
[02:04:44.800 --> 02:04:52.320]   eventually something happened. But, you know, I feel like I like gridiron, American football.
[02:04:53.040 --> 02:04:57.440]   We had two more exciting games yesterday in American football than we had in the World Cup
[02:04:57.440 --> 02:05:02.320]   final this morning. I don't know. So that's just my thought anyway. More happening. Yeah,
[02:05:02.320 --> 02:05:10.160]   were they all like all jumping up and down in Oaxaca? They were they shouting, go, anything like that?
[02:05:10.160 --> 02:05:16.240]   No, nothing. No. Okay. I was thinking I should have watched it on Univision instead of on Fox.
[02:05:16.240 --> 02:05:20.000]   It might have been more exciting, even if I could understand what they were saying.
[02:05:20.640 --> 02:05:23.920]   I mean, the French must have been going crazy right up till the end. I mean,
[02:05:23.920 --> 02:05:30.320]   it's I've seen big soccer matches while in in France. And you can hear it across the town,
[02:05:30.320 --> 02:05:34.320]   all the streaming. I'm sure. I mean, it couldn't have been a better final between Argentina and
[02:05:34.320 --> 02:05:40.480]   France to major soccer powers and fans. And I mean, it was very exciting watching Messi and
[02:05:40.480 --> 02:05:44.800]   Mbappe. And that was whenever I mean, Europe, I worry about what color shirt I'm wearing.
[02:05:44.800 --> 02:05:45.280]   Yes.
[02:05:45.280 --> 02:05:49.200]   Either that somehow it's going to offend the local fans. Are you in the crypts of the bloods?
[02:05:49.200 --> 02:05:52.960]   That's I know dangerous. Anyway, I thought I'd mentioned that.
[02:05:52.960 --> 02:05:58.880]   Apparently no soccer fans here. So it's okay. I just was going to give you some time to talk
[02:05:58.880 --> 02:06:05.040]   and and jump up and down. I have too short of attention fans. Yeah. I mean, I can't watch baseball
[02:06:05.040 --> 02:06:08.800]   anymore. Exactly. Same thing. I need excitement every three seconds.
[02:06:10.000 --> 02:06:15.680]   Going to happen. TikTok has ruined it all for us. TikTok has ruined us for soccer.
[02:06:15.680 --> 02:06:22.080]   Our show today brought to you by World Wide Technology. And Intel, World Wide Technology,
[02:06:22.080 --> 02:06:26.400]   we talk about a lot. WWT is at the forefront of innovation working with clients all over the
[02:06:26.400 --> 02:06:32.080]   world to transform their businesses. One of the reasons businesses love WWT is because, yes,
[02:06:32.080 --> 02:06:35.920]   they're technologists. Yes, they understand this stuff, but they also understand business.
[02:06:35.920 --> 02:06:41.520]   And they are very serious about business strategy. And they know that no technology
[02:06:41.520 --> 02:06:44.960]   makes any sense unless it fits your business strategy. Right?
[02:06:44.960 --> 02:06:50.720]   At the heart of WWT is this amazing advanced technology center. That's what Lisa and I went out
[02:06:50.720 --> 02:06:58.880]   to visit in March of 2020. The last trip we took went before COVID struck. We saw the ATC and it is
[02:06:58.880 --> 02:07:04.720]   a mind-boggling. It started in one small building with just a few racks. Now it's several buildings.
[02:07:05.680 --> 02:07:10.960]   Mile after mile of racks, more than half a billion dollars in the top of the line,
[02:07:10.960 --> 02:07:15.680]   OEM equipment, the kind of equipment you're going to be using. And that's how
[02:07:15.680 --> 02:07:22.560]   WWT uses it. It's a research and testing lab so that their engineers can spin up proofs of
[02:07:22.560 --> 02:07:28.720]   concept, can understand the technology, can get a better handle on it. The ATC is also for you,
[02:07:29.760 --> 02:07:36.480]   more than 50,000 members of the ATC platform, which is free, get access to hundreds of on-demand,
[02:07:36.480 --> 02:07:41.600]   schedulable labs that you can do anywhere in the world anytime of the day or night.
[02:07:41.600 --> 02:07:47.440]   Featuring solutions that include technologies like Intel's Xeon scalable processors and Intel
[02:07:47.440 --> 02:07:53.120]   Optane Persistent Memory, Optane SSDs and others. It's in the rack. You can try it. They represent
[02:07:53.120 --> 02:07:58.480]   the newest advances in every area of enterprise technology. Multicloud architecture is their
[02:07:58.480 --> 02:08:04.880]   security, networking, primary and secondary storage data analytics and AI. DevOps is so much more.
[02:08:04.880 --> 02:08:09.440]   I'll never forget. I mean, when we're talking about security, there was a whole series of racks
[02:08:09.440 --> 02:08:13.680]   that were isolated. They were often a cage. They were air gapped from the rest of us. I said,
[02:08:13.680 --> 02:08:17.920]   what's over there? They said, that's where we do any virus testing and virus testing. That's
[02:08:17.920 --> 02:08:23.120]   where we keep some of the biggest threats to enterprise because we've got to understand them
[02:08:23.120 --> 02:08:29.760]   so we can protect you against them. That's commitment. That's awesome. WWT's engineers and partners like
[02:08:29.760 --> 02:08:36.320]   you use the ATC to quickly spin up proofs of concept and pilots so that customers can confidently
[02:08:36.320 --> 02:08:43.040]   select the best solutions. That means evaluation time can be cut from months to weeks. It means
[02:08:43.040 --> 02:08:48.160]   there's no mystery. You're not going in with your eyes closed. You know eyes wide open exactly what
[02:08:48.160 --> 02:08:53.120]   these technologies are going to do. With the ATC, you can test out products and solutions just
[02:08:53.120 --> 02:08:59.360]   like the engineers at WWT. You can access technical articles. You can access expert insights,
[02:08:59.360 --> 02:09:05.040]   demonstration videos, white papers, those hands on labs and all the tools you need to help you stay
[02:09:05.040 --> 02:09:10.560]   up to date with the latest technology. You should also check out the ATC community. WWT
[02:09:10.560 --> 02:09:16.240]   events and communities. We did an event there when we were out there. Great ways to learn from the
[02:09:16.240 --> 02:09:21.040]   smartest people in the business about technology trends here about the latest research and insights
[02:09:21.040 --> 02:09:28.080]   from the experts at WWT and from outside experts they bring in. It's not just a physical lab space.
[02:09:28.080 --> 02:09:35.200]   It's a virtual space. Everybody anywhere in the world can participate in 365 days a year.
[02:09:35.200 --> 02:09:40.960]   So whatever your business need, I want to remind you, WWT is there to scale, deliver scalable,
[02:09:40.960 --> 02:09:46.880]   tried and tested tailored solutions. WWT, they bring strategy and execution together
[02:09:46.880 --> 02:09:53.520]   to make that new world happen. To learn more about WWT, the ATC to gain access to all their free
[02:09:53.520 --> 02:10:01.040]   resources, visit www.wt.com/twit. Create that account. It's free on the ATC platform and dig in.
[02:10:01.040 --> 02:10:09.360]   You're going to love it. www.wt.com/twit. We thank you so much for supporting this week in tech. This
[02:10:09.360 --> 02:10:15.520]   week was a great week on TWIT and we have a little video that we've made to show you all the highlights
[02:10:15.520 --> 02:10:20.720]   watch. Between Ant and Stacy, I'm getting a lot of shade here. I got to tell you. I like you.
[02:10:20.720 --> 02:10:28.880]   I like to remember. No shade. No shade. No shade. It's not shade. It's obvious.
[02:10:28.880 --> 02:10:38.800]   This is the 49th shade of grey on the scale. There's no side I would say. It's just straight
[02:10:38.800 --> 02:10:45.600]   of 50 shades of Stacy. I like it. Previously on TWIT, all about Android.
[02:10:45.600 --> 02:10:52.640]   So iCoo is a subsidiary of Chinese manufacturer Vivo and they also have announced new flagship
[02:10:52.640 --> 02:11:01.760]   devices. The iCoo 11 and 11 Pro. You've got a vapor chamber liquid cooling system. You got
[02:11:01.760 --> 02:11:07.920]   liquid cooling like in a phone. Hands-on photography. I got my hands on a nice new camera from the
[02:11:07.920 --> 02:11:13.200]   folks at Canon. It's the Canon R7. This is one of their latest mirrorless bodies.
[02:11:13.200 --> 02:11:19.200]   This week in Google, we were joined by the first engineer to be fired by Elon Musk at
[02:11:19.200 --> 02:11:26.240]   Twitter, Manu Cornette. This one was actually 100% stolen from something Stacy said in one
[02:11:26.240 --> 02:11:32.000]   episode. So that's Stacy saying you break it, you buy it. TWIT. I have inspired art.
[02:11:32.000 --> 02:11:42.480]   You're so excited. This is awesome. Manu Cornette was great. He his claim to fame. He was the
[02:11:42.480 --> 02:11:48.720]   first engineer to be fired at Twitter shortly after. He was actually thrilled when Elon showed
[02:11:48.720 --> 02:11:52.640]   up with the sink. He said, oh, this is a guy with a sense of humor. He's a cartoonist. Of course,
[02:11:52.640 --> 02:12:01.520]   he likes all that stuff. He said, his thrill changed to dismay when he even gave Elon
[02:12:01.520 --> 02:12:06.800]   one of those cartoons. It's pretty cool. Shame it happened during the tech downturn that there
[02:12:06.800 --> 02:12:09.760]   aren't a gazillion jobs for all these people because if it happened a couple of years ago,
[02:12:09.760 --> 02:12:13.600]   they would all would have been rehired right away by somebody. Well, I suspect,
[02:12:13.600 --> 02:12:20.320]   well, hopefully. This right now, there's such a shortage of engineers that I feel like they'll
[02:12:20.320 --> 02:12:25.120]   will. You're right though. I mean, it's not the four or 5,000 people from Twitter. It's the
[02:12:25.120 --> 02:12:31.360]   11,000 from Facebook. Exactly. Yeah. Leo, can we take one second for reflection? I thought
[02:12:31.360 --> 02:12:39.440]   this was really interesting that if I remember right, Twit started spring of 2005.
[02:12:39.440 --> 02:12:51.520]   And one of the first big things was WWDC in that year. At that WWDC in June, I think it was,
[02:12:51.520 --> 02:12:58.800]   they announced the Intel transition. That was like the big news, right? Was the Intel transition.
[02:12:58.800 --> 02:13:04.720]   For Apple. Yeah. For Apple. And now we've come full circle. Who could have imagined that this
[02:13:04.720 --> 02:13:13.440]   many years later, now Intel is actually advertising on Twit. That's pretty cool.
[02:13:13.440 --> 02:13:19.200]   I have to say, the best thing about this beat, and I'm sure you all agree, is that it's never boring.
[02:13:19.200 --> 02:13:24.080]   If you're covering politics, it's kind of the same story over and over. If you're covering
[02:13:24.880 --> 02:13:32.720]   local politics is worse. But technology, it's kind of this best, nobody dies, nobody bleeds.
[02:13:32.720 --> 02:13:37.840]   So you don't have to go to a helicopter crash and call the family and ask for the reaction,
[02:13:37.840 --> 02:13:42.880]   which is the worst thing in local news. But yeah, so it's not, but at the same time,
[02:13:42.880 --> 02:13:47.440]   it is important is changing the world. It's shaping our world. So it's great. It's like the
[02:13:47.440 --> 02:13:52.160]   toy store, but it's still important. It's not like sport. It's metaphorical train wreck.
[02:13:52.160 --> 02:13:56.240]   Yeah. It's not actual. When I got the LA Times gig in 1983, I called up a friend of mine,
[02:13:56.240 --> 02:13:59.520]   said, "Good news and bad news. What's the good news? Good news. I'm now writing for the second
[02:13:59.520 --> 02:14:04.080]   biggest paper in America. That's the bad news. Oh, I've got to write about computers." And it's
[02:14:04.080 --> 02:14:10.000]   a fun. I really felt like I was a second-class journalist because I wasn't writing. And now
[02:14:10.000 --> 02:14:14.560]   everybody wants to be on the tech. That's right. And Mossberg came around from the State Department.
[02:14:14.560 --> 02:14:19.120]   That's what made me feel the Wall Mossberg went from State Department to tech. I said, "How?
[02:14:19.120 --> 02:14:22.320]   Maybe I got somewhere. I might be on to something here."
[02:14:22.320 --> 02:14:28.320]   Big stories, quick ones. We'll get through these fast.
[02:14:28.320 --> 02:14:35.920]   Apple has apparently, according to Puck News, backed out of the negotiations for the NFL
[02:14:35.920 --> 02:14:41.440]   Sunday ticket. You remember that this was given up by DirecTV. They own it right now,
[02:14:41.440 --> 02:14:48.560]   billion and a half a year. According to Dylan Byers writing in Puck, which I pay for, but I'm
[02:14:48.560 --> 02:14:54.320]   currently not logged into, so I can't show you the article. Apple has pulled out,
[02:14:54.320 --> 02:15:02.000]   but Amazon and Google still in the bidding. This is the NFL Sunday ticket is the right to show
[02:15:02.000 --> 02:15:09.360]   all the games on a Sunday. DirecTV used it to build subscription, new subscribers,
[02:15:09.360 --> 02:15:14.320]   bars, especially wanted this, access to this, so they could show all the games. But it's very
[02:15:14.320 --> 02:15:18.480]   expensive, billion and a half a year. DirecTV never made any money. I lost money on it.
[02:15:18.880 --> 02:15:24.720]   But a company like Apple, Google, Amazon, it's not their business. It's a way of adding to their
[02:15:24.720 --> 02:15:31.280]   annual revenue per user, their ARPU. So they can build a lot more than a network or a satellite
[02:15:31.280 --> 02:15:37.600]   company could ever build. So watch now. We'll see if Google or Amazon get it. Google would put
[02:15:37.600 --> 02:15:43.040]   it on their YouTube TV. Amazon would put it on Amazon. Prime presumably, where Thursday Night
[02:15:43.040 --> 02:15:48.800]   Football already lives. According to buyers, one of the problems was that the NFL,
[02:15:48.800 --> 02:15:53.680]   the Apple wanted to give it away. We wanted Apple TV plus subscribers to get it for free.
[02:15:53.680 --> 02:16:00.240]   And the NFL says over our dead bodies, give it away the crown jewel. All right, fine.
[02:16:00.240 --> 02:16:11.520]   Virtual reality pioneer, John Carmack has had it with Meta and has quit. He's joined Meta as
[02:16:11.520 --> 02:16:19.920]   Chief Technology Officer of Oculus when they acquired Oculus. He quit in a huff, or at least a minute
[02:16:19.920 --> 02:16:29.360]   at a huff. He, old, Groucho Marx joke, he said Meta, which is in the midst of transitioning from a
[02:16:29.360 --> 02:16:34.480]   social networking company to one focused on the immersive world of the metaverse, was operating at
[02:16:34.480 --> 02:16:40.240]   quote, half the effectiveness and has quote, a ridiculous amount of people and resources.
[02:16:40.240 --> 02:16:49.360]   But we constantly self sabotage and squander effort. He wrote in the post, which by the way, he says
[02:16:49.360 --> 02:16:55.840]   the times is missing the context. And so he's posted the entire post publicly now. But he wrote,
[02:16:55.840 --> 02:16:59.840]   "It's been a struggle for me. I have a voice at the highest levels here. So it feels like I should
[02:16:59.840 --> 02:17:04.160]   be able to move things, but I'm evidently not persuasive enough."
[02:17:05.680 --> 02:17:13.120]   And for the record, he wasn't an employee. He was a consultant. I'm pretty sure. And so,
[02:17:13.120 --> 02:17:20.880]   I think it's a combination of him changing his own personal career and also
[02:17:20.880 --> 02:17:26.800]   nobody's happy with the whole metaverse direction of Facebook, it seems.
[02:17:26.800 --> 02:17:33.040]   Yeah, nobody. I think that's probably we were talking about, my wife and I were talking about
[02:17:33.040 --> 02:17:37.600]   why Sheryl Sandberg left. And I said, well, ostensibly it's because she was getting married and had a
[02:17:37.600 --> 02:17:42.080]   new family and she wanted to spend more time with her money. But I think it must have also
[02:17:42.080 --> 02:17:49.040]   something to do with this new direction, which is really being promoted by Mark, but maybe not
[02:17:49.040 --> 02:17:54.400]   as well supported by the rest of the company. Yeah, he was an executive consultant for virtual
[02:17:54.400 --> 02:17:55.760]   reality. Yeah.
[02:17:57.760 --> 02:18:05.200]   Yeah, it's a weird thing because the metaverse nomenclature is, I mean, it was always a dystopian
[02:18:05.200 --> 02:18:12.000]   concept. He turned it into the branding of the company, Meta, and has been talking nonstop about
[02:18:12.000 --> 02:18:17.600]   it. But we're talking about virtual reality and augmented reality and things like that. All of that
[02:18:17.600 --> 02:18:23.120]   was always going to be inevitable. And Facebook, the biggest problem is just Facebook is not very
[02:18:23.120 --> 02:18:29.600]   good at it. So they can talk all they want, they can squander billions, but at the end of the day,
[02:18:29.600 --> 02:18:33.280]   they're just not very good at doing what Mark Zuckerberg calls the metaverse.
[02:18:33.280 --> 02:18:41.600]   Yeah. It depends on what you look at. I mean, it's not clear to me whether Meta is
[02:18:41.600 --> 02:18:48.000]   a application developer or a platform. And they're really both, right? So Horizon World, for example,
[02:18:48.000 --> 02:18:55.040]   doesn't isn't doing very well. But VRChat and other, there are products on the quest platform
[02:18:55.040 --> 02:18:59.840]   that do reasonably well, I mean, are actually very well done. So it may turn out that as a
[02:18:59.840 --> 02:19:04.480]   platform, they actually aren't that bad, but they've got some problems with their own apps,
[02:19:04.480 --> 02:19:09.520]   I have to admit. And again, full disclosure, I actually wrote some of their safety guides. So
[02:19:09.520 --> 02:19:14.080]   we work with them as well. Got a great safety team. I'll tell you I'll say that much about them.
[02:19:14.800 --> 02:19:21.760]   But I think of the platform, I think it's too early to judge. And of course, they may acquire or
[02:19:21.760 --> 02:19:26.080]   somehow make, you know, Horizon World may get better. Let's hope it does.
[02:19:26.080 --> 02:19:32.720]   His final words in his post, enough complaining, I'm worried of the fight and have my own startup
[02:19:32.720 --> 02:19:38.400]   to run. But the fight is still winnable. VR can bring value to most of the people in the world.
[02:19:38.400 --> 02:19:44.080]   And no company is better positioned to do it than Meta. Maybe it is actually possible to get
[02:19:44.080 --> 02:19:48.960]   there by just plowing ahead with current practices. But there's plenty of room for improvement.
[02:19:48.960 --> 02:19:52.400]   Make better decisions and fill your products with give a damn.
[02:19:52.400 --> 02:19:58.160]   Notice he said VR, right? So the problem is that AR is going to be
[02:19:58.160 --> 02:20:04.720]   bad, like fastly bigger than VR and Apple is going to completely cross on that market, I think.
[02:20:04.720 --> 02:20:09.600]   Yeah. I mean, they are. They are going to be huge. It makes a lot more sense. And of course,
[02:20:09.600 --> 02:20:12.400]   Meta is going to go there too. Question is whether they go there fast enough.
[02:20:12.400 --> 02:20:17.600]   In a way they have, I have the Oculus Pro or the Quest Pro that they just made the $1,600 one.
[02:20:17.600 --> 02:20:24.720]   Call me crazy. But because it has good color cameras in the front, you can see stuff. In fact,
[02:20:24.720 --> 02:20:28.000]   they have some good games that are AR games involving your own.
[02:20:28.000 --> 02:20:33.520]   It's a shame that I have the Quest Pro 2 and it is eons better than the Quest 2. And it's a shame
[02:20:33.520 --> 02:20:37.040]   that the only way to get the really, really good one is to have to pay $1,500.
[02:20:37.040 --> 02:20:41.520]   Well, maybe it's just that expensive to make. I mean, yeah, no, hopefully it'll come down. I think
[02:20:41.520 --> 02:20:47.760]   it will. But Apple, it's rumored when they do release their augmented reality headset.
[02:20:47.760 --> 02:20:54.560]   And the rumor is they'll do it next year, late in the year, but that it'll cost around $3,000.
[02:20:54.560 --> 02:20:59.200]   It's not going to be cheap. That's not starting. Well, it's a developer tool at that point, right?
[02:20:59.200 --> 02:21:03.760]   Nobody is. It is. It's a with HoloLens or it's a with Google. They all are, really.
[02:21:07.520 --> 02:21:15.040]   Let's see what else here. Instagram, which has long had a problem with hacked accounts,
[02:21:15.040 --> 02:21:19.600]   but never admitted it, I think, has finally launched a new tool to help hacked users
[02:21:19.600 --> 02:21:26.000]   regain account access. So, okay, you go to instagram.com/act.
[02:21:26.000 --> 02:21:33.360]   This happens a lot. Far too often. And maybe it's the fault of the users who aren't turning on
[02:21:33.360 --> 02:21:39.760]   to factor or whatever. But this is the problem with these giant free services.
[02:21:39.760 --> 02:21:44.800]   Because they make no money on you, they don't really have the incentive to give you any support
[02:21:44.800 --> 02:21:49.360]   at all. So, when your Google account is hacked or your Facebook account is hacked or your Insta
[02:21:49.360 --> 02:21:57.120]   account is hacked, good luck. You're dealing with a giant robot bureaucracy. So, I hope that this
[02:21:57.120 --> 02:22:04.160]   makes a difference. I hear from a lot of people who get hacked. Netflix is giving money back
[02:22:04.160 --> 02:22:13.760]   to advertisers. Remember, they launched an ad supported tier. Well, so they have a lower cost
[02:22:13.760 --> 02:22:19.520]   to people. Well, apparently it's not taken off like crazy. Netflix has only delivered roughly 80%
[02:22:19.520 --> 02:22:25.840]   of the expected audience according to some agencies, five agency executives talking to Digide.
[02:22:26.960 --> 02:22:31.520]   And so, they're giving some of that money back. That's the normal practice we do it to in media.
[02:22:31.520 --> 02:22:37.360]   If you don't reach the numbers, you have to give the money back. I don't know if it's a long-term
[02:22:37.360 --> 02:22:40.880]   problem with an ad supported version of Netflix. It's still pretty new.
[02:22:40.880 --> 02:22:47.920]   I pay the ridiculous, what is it? $15 a month now? It's outrageous.
[02:22:47.920 --> 02:22:54.000]   Yeah, I mean, I have ad free versions of just about everything I get.
[02:22:54.560 --> 02:22:58.240]   Because I've just gotten conditioned to not have to watch ads. And on television, on broadcast
[02:22:58.240 --> 02:23:02.160]   television, I could skip the ads. I know ads that support you Leo. I understand that. But,
[02:23:02.160 --> 02:23:08.000]   on broadcast, I've got a DVR. You can skip the ads on our show, Larry. It's okay.
[02:23:08.000 --> 02:23:10.400]   Oh, no, I love your ad. I'll allow you.
[02:23:10.400 --> 02:23:15.280]   It's called a club toy. It's called club toy. It's called club toy.
[02:23:15.280 --> 02:23:20.320]   Yeah. But honestly, that's why we started club twig. Because I thought there are people who
[02:23:20.320 --> 02:23:25.520]   don't want to hear ads. And so I want to give them a chance to hear our shows without ads.
[02:23:25.520 --> 02:23:28.880]   But we need to monetize somehow. Club twits stuff pretty well.
[02:23:28.880 --> 02:23:32.880]   Well, it's exactly what Netflix is. I guess it is. The ad free version.
[02:23:32.880 --> 02:23:33.920]   And only with the other way, right?
[02:23:33.920 --> 02:23:38.560]   They started with the ad free version. We started with the ad version. Maybe it's a little
[02:23:38.560 --> 02:23:44.000]   easier to get people to pay for something first. It said it'd be very difficult to get people to
[02:23:44.000 --> 02:23:48.080]   pay for something they're getting for free. I would say, I don't know what the exact
[02:23:48.080 --> 02:23:52.720]   percentage is, but it's something like 2% or less of our audience pays for it.
[02:23:52.720 --> 02:23:59.440]   I'd love to get that to a higher number. Frankly, if they nobody overpay for television or water.
[02:23:59.440 --> 02:24:05.040]   Right. And we do both. We do both. Yeah. So maybe that's good. That's encouraging.
[02:24:05.040 --> 02:24:10.240]   If we could get to 5%, we wouldn't need advertisers. That's all we take. 5% of the people who listen
[02:24:10.240 --> 02:24:15.040]   to pay for it. I'm sure it's going up all the time, though. It is. It's probably never stops going up.
[02:24:15.040 --> 02:24:17.920]   And what I do is I make people feel really guilty.
[02:24:17.920 --> 02:24:25.760]   I've decided if it works for public broadcasting, I ought to do a pledge of nights and
[02:24:25.760 --> 02:24:30.560]   you know, have a phone bank of operators or taking your call. All you gotta do is go to club
[02:24:30.560 --> 02:24:36.800]   to it. I'll tweet that TV slash club to it. I'm terrible at this. $7. It's a buck less than a
[02:24:36.800 --> 02:24:43.040]   blue check on Twitter and you get ad free versions for all of our shows. You get the Discord,
[02:24:43.040 --> 02:24:48.560]   which is actually a wonderful place to hang out. I know some of you are in there and I see you
[02:24:48.560 --> 02:24:53.440]   once in a while. I pay you $8. We give me a check mark at least. I will give you anything you want.
[02:24:53.440 --> 02:24:58.560]   In fact, if you want, I'll give all three of you. It's standing offered any of our contributors to
[02:24:58.560 --> 02:25:05.440]   have a free access to the Discord, which is a great place to talk. And we do have every time.
[02:25:05.440 --> 02:25:09.360]   Yeah. If you want to pay for it, Jeff pays for it, I think a couple people pay for it.
[02:25:09.360 --> 02:25:14.720]   I do too. Yeah. Thank you. I appreciate it. It really does help us out. And we have some shows
[02:25:14.720 --> 02:25:18.800]   that we don't put out in public like hands on windows and hands on Mac Ettosha. The untitled
[02:25:18.800 --> 02:25:24.080]   Linux show that it's club only. We've got some actual space space. No, that's that's a good example
[02:25:24.080 --> 02:25:28.800]   of a show that's making space that started in the club. That's right. It's been advertising.
[02:25:28.800 --> 02:25:31.760]   We put it out in public and now it's doing so well. We're going to give them video.
[02:25:31.760 --> 02:25:36.320]   So we like a farm program. Yeah, we've decided it's better to start that way, start small and
[02:25:36.320 --> 02:25:41.760]   work its way up, then launch it and then have to cancel it because it's too expensive to do.
[02:25:41.760 --> 02:25:45.920]   That's awesome. Because I don't have venture capital. I don't have anybody putting money
[02:25:45.920 --> 02:25:49.360]   in the pocket. So we got to figure it out. You actually have reality to deal with here.
[02:25:49.360 --> 02:25:54.000]   It's good. You know, I have friends at revision three and they got, I don't know,
[02:25:54.000 --> 02:25:57.840]   not a small amount of money, like $7 million in VC. And they spend it very quickly.
[02:25:57.840 --> 02:26:03.600]   And I'm just, I've always felt grateful that I didn't have that because it's hard to know what
[02:26:03.600 --> 02:26:06.880]   if you got some million burning a hole in your pocket, you don't know what you need right now.
[02:26:06.880 --> 02:26:11.360]   I'd much rather bootstrap it. So that's what you don't have $44 billion to buy a social media
[02:26:11.360 --> 02:26:16.400]   company. I wish. I wish. It costs about three and a half million dollars a year to run to it
[02:26:16.400 --> 02:26:24.000]   with staff, electricity, rent, all that stuff. So we only, Lisa and I only take a salary if we
[02:26:24.000 --> 02:26:29.280]   make more than three and a half million a year. And frankly, this year, I think it's right at
[02:26:29.280 --> 02:26:34.000]   3.4 million. It's a little bit low. That's why we're pushing the funding page for you.
[02:26:34.000 --> 02:26:38.240]   Just we need the club. That's all coming up Thursday, January 12th,
[02:26:38.240 --> 02:26:41.920]   Project Hail Mary and the book club with Stacy. There's going to be an inside
[02:26:41.920 --> 02:26:46.400]   twit. Lisa and I will talk about those numbers and more with our club members on January 19th.
[02:26:46.400 --> 02:26:51.360]   Wind To Dow is doing a fireside chat on the ninth. We just had one with Glenn Fleischman,
[02:26:51.360 --> 02:26:56.080]   which went really, really well. And I think we're going to try to get Manu in there and a few
[02:26:56.080 --> 02:27:01.360]   other people to join us in our club events. So this is, we're trying to make it more of a fun place
[02:27:01.360 --> 02:27:06.080]   to hang out. Thanks to Emperor, our community manager. So we're just, we're doing what we can.
[02:27:06.080 --> 02:27:12.160]   We're doing what we can. And I want Netflix to succeed. I absolutely, absolutely do.
[02:27:12.160 --> 02:27:18.320]   I mean, I'm paying 15, 99 a month. They have good stuff. What did I just watch? Oh, bullet
[02:27:18.320 --> 02:27:24.240]   train is free on it. I would have paid more, renting it on Apple if I had known. So that's good
[02:27:24.240 --> 02:27:27.760]   thing I saw it on. Have you ever paid for a movie and then found out you could have streamed it
[02:27:27.760 --> 02:27:32.880]   every time? I did. It's completely chance I saw that was on Netflix. I was about to buy it.
[02:27:32.880 --> 02:27:44.880]   Every time. I think we're done. I think I think there's other things, but I think we've talked about
[02:27:44.880 --> 02:27:49.200]   everything. Well, I have something to say if I can. Oh, you've got some, you've got some stuff to
[02:27:49.200 --> 02:27:54.560]   give away. I'm giving away money. So, you know, as you know, I connect safely and we are the
[02:27:54.560 --> 02:27:58.960]   official US host of Safer Internet Day and maybe I'll come back in February and talk about it.
[02:27:58.960 --> 02:28:03.360]   Please do. You have an invitation to do that. But normally what we would do back before the
[02:28:03.360 --> 02:28:07.280]   pandemic, we'd have these really big events where we'd spend tens of thousands of dollars and we
[02:28:07.280 --> 02:28:12.960]   bring in people like Hava Lahara, and Cheryl Sandberg, and 300 kids from a community would all
[02:28:12.960 --> 02:28:17.440]   come in. Well, we're not doing that this year. Instead, we're giving out a $1,000 grant to
[02:28:17.440 --> 02:28:22.640]   teachers around the country. Nice. Nice. They can put on a local event and we will give them
[02:28:22.640 --> 02:28:27.440]   everything they need. PowerPoints, videos, lesson plans, discussion points, everything they need
[02:28:27.440 --> 02:28:32.000]   to deliver the event and a thousand bucks to incentivize them or print material,
[02:28:32.000 --> 02:28:36.800]   they buy pizza, whatever they need. All they need to go is go to connect safely.org and on the
[02:28:36.800 --> 02:28:42.160]   front page, you'll see a blog post. You click on that. It takes you to an application 10 minutes
[02:28:42.160 --> 02:28:47.120]   on Google. Now, we're not going to give everybody. It's a competitive program, but there are still
[02:28:47.120 --> 02:28:53.280]   some slots open there. If people want to apply, we'd be happy to look at your application and we're
[02:28:53.280 --> 02:28:57.120]   really trying to get a diverse group. I mean, from around the country, we're helping to get
[02:28:57.120 --> 02:29:02.320]   maybe some tribal schools to sign up. We really want to get a lot of schools around the country
[02:29:02.320 --> 02:29:06.960]   doing these programs and we've raised some money to be able to subsidize it.
[02:29:06.960 --> 02:29:12.560]   I like that. I think that's a great way to use that money is to go directly to the schools and
[02:29:12.560 --> 02:29:16.800]   help them do that education. And the money comes from all those companies who've been talking
[02:29:16.800 --> 02:29:22.080]   about. Yeah, I see it right here at the bottom. We've got meta, Google, Amazon Kids, Twitch,
[02:29:22.080 --> 02:29:29.840]   TikTok, Snapchat, Discord, thank you Discord, Roblox, Trend Micro, the NCTA, the internet
[02:29:29.840 --> 02:29:35.360]   and television association, Meet Group and Zepeto. Zepeto, which is a Korean company.
[02:29:35.360 --> 02:29:40.400]   Oh, nice. Wonderful. You know what? They should put money into that. That's fantastic.
[02:29:41.120 --> 02:29:45.760]   Connectsafelie.org. Larry is the president and CEO and does a great job there.
[02:29:45.760 --> 02:29:51.280]   Spending, I think, more time there now that you don't do as much radio and stuff.
[02:29:51.280 --> 02:29:54.400]   That's right. I think that's fantastic. We actually do have to, we have the
[02:29:54.400 --> 02:29:58.880]   Connects Safely Report on CBS News Radio. So we still have a real radio show.
[02:29:58.880 --> 02:30:02.960]   Yeah. It's not as much. Do you host that? I do. It's one minute long.
[02:30:02.960 --> 02:30:08.160]   Perfect length. If I could do a one minute show, I would. Never have.
[02:30:10.160 --> 02:30:14.800]   Thank you for the work. Thank you for the work you do, Larry. I really, I think it's important.
[02:30:14.800 --> 02:30:18.720]   It's great. Thank you. Agreed. Mike Elgin, the wind has been kicking up in
[02:30:18.720 --> 02:30:24.160]   Wohaka. The sun has gone down. It's a beautiful night. What are you going to do with the rest of
[02:30:24.160 --> 02:30:29.040]   your evening? I have no idea. We're actually flying back to California tomorrow not to
[02:30:29.040 --> 02:30:36.880]   docks myself, but what's the tail number? Yeah. I'll be getting my tail number back to
[02:30:36.880 --> 02:30:41.680]   California tomorrow. No, but we're going to probably go out and just do Wohaka. It's a
[02:30:41.680 --> 02:30:47.600]   non-stop party, as you know, in this town. It's just such a cool place. Went to a big event last
[02:30:47.600 --> 02:30:53.520]   night. It was really fantastic. We just finished the Wohaka experience a few days ago. So that
[02:30:53.520 --> 02:31:00.480]   was really, really fun. Gastroknomad.net. I've done the Wohaka experience and I will never
[02:31:00.480 --> 02:31:07.600]   have a better time eating better food than hanging out with Mike in Amira. You probably sold out on
[02:31:07.600 --> 02:31:13.200]   some of these. What's the next opening you've got here? Well, let's see. Mexico City sold out in
[02:31:13.200 --> 02:31:20.960]   April and then I think Provence is the first one in June, late June. That one still, I believe,
[02:31:20.960 --> 02:31:26.000]   has a few rooms available if you want to sign up and I highly recommend that one. Oh, boy.
[02:31:26.000 --> 02:31:33.600]   And then Prosecco after that. And it's just become, I mean, it's really, really popular nowadays.
[02:31:33.600 --> 02:31:40.160]   We have people repeating not only doing multiple events, but now people are repeating the same
[02:31:40.160 --> 02:31:45.520]   event they already did. So we had some people on this one that did Wohaka last year. It's so funny.
[02:31:45.520 --> 02:31:52.000]   I know every one of these people, it's hysterical. Yeah, you get a lot of repeats, but they're
[02:31:52.000 --> 02:31:55.520]   great people that you want to hang out with. A lot of them, Twit listeners.
[02:31:55.520 --> 02:32:01.760]   Yeah, so much fun. So much fun. And it's a small group. Yeah, it's a pretty small group.
[02:32:01.760 --> 02:32:06.800]   This Wohaka experience was 14 people, which is the biggest one we've ever done. But normally,
[02:32:06.800 --> 02:32:13.120]   they range from, you know, six to 10 or something like that. And it's a really nice tight-knit group.
[02:32:13.120 --> 02:32:18.000]   And I thank you for letting me talk about it, Leo. But can I tell you one other exciting piece of
[02:32:18.000 --> 02:32:23.920]   news over in Chatterbox territory, which Kevin's innovating like crazy over there. And he's doing
[02:32:23.920 --> 02:32:28.560]   this thing. You can check it out at Lachowterbox. Oh, wait a minute. He's doing AI art with Chatterbox.
[02:32:28.560 --> 02:32:34.400]   Yes. Oh, wow. Rolling out in the first quarter, even though he's essentially
[02:32:34.400 --> 02:32:40.640]   built it already. But basically, the kids will build the skill and the skill builder.
[02:32:40.640 --> 02:32:45.120]   And then they do it with voice. So they top the button and they give the text prompts by voice.
[02:32:45.120 --> 02:32:51.920]   Cool. And then the pictures, the pictures show up in the skill builder. Oh, so cool. Oh, that's
[02:32:51.920 --> 02:32:57.520]   one way to engage kids. Holy cow, they're going to have so much fun. And he's making it safe. So
[02:32:57.520 --> 02:33:02.000]   they can't do objectionable content or anything like that. He's got a really good engine for doing
[02:33:02.000 --> 02:33:08.560]   that already. And so this is a way for kids because the ultimate purpose of Chatterbox is to teach
[02:33:08.560 --> 02:33:13.920]   AI literacy, which is very, very important. And this is this is what's happening in AI right now.
[02:33:13.920 --> 02:33:16.880]   It's AI art. So it's really cool stuff.
[02:33:16.880 --> 02:33:20.480]   Have you reached out to me? Because we love to promote, especially smaller companies.
[02:33:20.480 --> 02:33:23.600]   Yeah. Oh, this is a good one for you. We're going to hit them up for money.
[02:33:23.600 --> 02:33:27.600]   We just like to promote them. No, this is a really good one for you. Hello, Chatterbox.com.
[02:33:27.600 --> 02:33:36.240]   I wish that the chat GPT could be, you know, that is a great tool. It's so much smarter than
[02:33:36.240 --> 02:33:44.800]   Echo or Amazon or Google voice or it's a lot smarter than Siri. I know it's expensive to run,
[02:33:44.800 --> 02:33:48.640]   but boy, it'd be really cool if you could. I think it's just a matter of time for the voice
[02:33:48.640 --> 02:33:55.040]   assistants start being as smart as chat GPT. Right. The big thing chat GPT lacks is real-time
[02:33:55.040 --> 02:34:01.200]   information. Yes. It's old. Everything is already in the database. And so people might think that
[02:34:01.200 --> 02:34:09.440]   Chatterbox, for example, is kind of a much lesser version and has less capabilities than Alexa or
[02:34:09.440 --> 02:34:13.520]   whatever, but it doesn't. Kids can build skills and get the weather, they get all this real-time
[02:34:13.520 --> 02:34:17.760]   information using APIs and teaches them how APIs work, which is really important.
[02:34:17.760 --> 02:34:24.720]   You can actually do more things with Chatterbox theoretically than you can with Siri or Google
[02:34:24.720 --> 02:34:30.160]   Voice or any of these. Yeah. It uses its own Chatterblocks language. It's a customized version
[02:34:30.160 --> 02:34:36.320]   of Google Blockly. Yeah. Really, really, really neat stuff. Yeah. I love it.
[02:34:36.320 --> 02:34:42.400]   Sometimes I think if I retire, I should become a school teacher because there's so many great
[02:34:42.400 --> 02:34:48.800]   things now to do with your kids. It's called working. That's very cool. You teach every day.
[02:34:48.800 --> 02:34:56.000]   What am I saying? Kevin is looking for beta testers who are teachers.
[02:34:56.880 --> 02:35:00.880]   And so if you're a teacher, reach out. Hello, Chatterbox.com. He'd love to hear from you.
[02:35:00.880 --> 02:35:07.120]   Oh, that's great. Oh, that's really great. Jason Heiner, editor and chief, ZDNet. You got a big
[02:35:07.120 --> 02:35:12.480]   job, but you're doing a great one. I think ZDNet has gotten better over the years. Thank you for
[02:35:12.480 --> 02:35:16.720]   doing such an excellent job there. Thank you. Anything you want to plug?
[02:35:16.720 --> 02:35:23.520]   So I will plug something for the audience. One of the things that we've done over the last few
[02:35:23.520 --> 02:35:30.720]   days at the end of last week was there's this myth that the biggest shopping of the day of the year
[02:35:30.720 --> 02:35:37.280]   is Black Friday, but it's actually the Saturday before Christmas. Oh, really?
[02:35:37.280 --> 02:35:41.360]   Oh, really? Last minute. Leading up to it. Yeah. Because Saturday is Christmas Eve.
[02:35:41.360 --> 02:35:45.920]   So that's when I shop Christmas Eve. Yes. Usually I'm 8PM Christmas Eve.
[02:35:45.920 --> 02:35:51.520]   So we did last best let. You had it up on the screen. Best last minute tech. I made these.
[02:35:52.080 --> 02:35:58.880]   There. So we had all of our editors on. We did a live stream and we had them come on and talk about
[02:35:58.880 --> 02:36:07.280]   our picks. So our team's been scouring the best deals for the past month. And also lining that up
[02:36:07.280 --> 02:36:12.240]   with some of the products that were our favorite ones that we got our hands on this year. So
[02:36:12.240 --> 02:36:17.520]   not all of these are ones we got our hands on, but most of them are ones that we tested. So we found
[02:36:17.520 --> 02:36:22.560]   the best deals on our favorite products of the year and put this list together of like here's some
[02:36:22.560 --> 02:36:28.800]   really good options for you if you're looking for those last minute. Yeah, gifts for somebody to
[02:36:28.800 --> 02:36:32.640]   find them, get them some useful stuff that's going to really be good and that they're going to be
[02:36:32.640 --> 02:36:39.840]   happy. There's only six shopping days left, kids. znet.com. It's right there on the front page.
[02:36:40.720 --> 02:36:48.640]   And thank you so much. Jason, Mike, Larry, I consider you three of my best friends,
[02:36:48.640 --> 02:36:53.920]   my best buddies. And it's a great way to end our year with this shoot of pleasure.
[02:36:53.920 --> 02:36:58.800]   It was a lot of fun today. Yeah, it's always good conversation when you get smart people on
[02:36:58.800 --> 02:37:05.120]   talking about Elon Musk. What can go wrong? Let's not do that too much Nick. No, no, I don't want
[02:37:05.120 --> 02:37:12.960]   to do anymore. I'm done. I'm so done. If only, if only, we do to it, of course, on Sundays. Now,
[02:37:12.960 --> 02:37:19.040]   I got to tell you normally we do a Sunday two to five p.m. Eastern or rather a Pacific time five
[02:37:19.040 --> 02:37:27.280]   to eight p.m. Eastern time. That's 2200 UTC. Next week is Christmas. We're not going to make
[02:37:27.280 --> 02:37:32.320]   anybody do a show with us on Christmas. We've already recorded our Christmas episode. A lot of fun
[02:37:32.320 --> 02:37:39.520]   with the old, the old koots, Doc Serals, Steve Gibson, Paul Therat, Jeff Jarvis, and I get together and
[02:37:39.520 --> 02:37:46.480]   kind of yell at the clouds, talk about the year in history. And then the following week is a best
[02:37:46.480 --> 02:37:54.720]   of some of the best clips from the year 2022. We will though be back January 8th for our first
[02:37:55.280 --> 02:38:02.400]   return to the live format. So I hope you will come back then two to five p.m. Eastern. I mean,
[02:38:02.400 --> 02:38:09.760]   Pacific here on Sunday. So you can watch live at live.twit.tv. There's a live video stream. There's
[02:38:09.760 --> 02:38:16.800]   also a live audio stream there. Chat with us live at irc.twit.tv. And I imagine the IRC is not going to
[02:38:16.800 --> 02:38:21.280]   go away during the holidays. So if you get a little lonely, go on into the IRC. Or if you're
[02:38:21.280 --> 02:38:27.040]   a club twit, the Discord, I'll be hanging out in both from time to time, wave in hello and so forth.
[02:38:27.040 --> 02:38:33.200]   You can you can don't don't feel alone. There's geeks ready and willing to talk to you in the chats.
[02:38:33.200 --> 02:38:41.920]   Join us. We also of course have all of our shows available after the fact on the website twit.tv.
[02:38:41.920 --> 02:38:46.320]   There's YouTube channel for this week in tech and many of our other shows. Best things are
[02:38:46.320 --> 02:38:50.160]   you subscribe in your favorite podcast player, you'll get it automatically the minute it's available.
[02:38:50.160 --> 02:38:59.440]   So I guess I will be here this week. We're going to have our usual shows. We don't go into best of
[02:38:59.440 --> 02:39:06.640]   mode until after twit next Sunday and then we'll be in best of mode all that week. So I will see
[02:39:06.640 --> 02:39:13.280]   you on Tuesday. I'll be back Tuesday with Mac break weekly. And of course, in three weeks for this
[02:39:13.280 --> 02:39:17.680]   week in tech. Thanks everybody. If I don't see you between now and the holidays have a happy
[02:39:17.680 --> 02:39:23.920]   Hanukkah tonight, happy Christmas, happy new year, and we'll see you in the new year on Twit.
[02:39:23.920 --> 02:39:26.560]   Take care everybody. Another twit. He's in the can. Bye bye.
[02:39:26.560 --> 02:39:38.960]   He's amazing.

