
[00:00:00.000 --> 00:00:03.280]   Hi, this is Alex Lindsey-Sittinen for Leo Laport.
[00:00:03.280 --> 00:00:07.200]   I'm here with Greg Farrow and Justine Esaric, and we're going to be talking about how do
[00:00:07.200 --> 00:00:09.680]   we fix California's housing crisis?
[00:00:09.680 --> 00:00:11.880]   Should the FBI track our faces?
[00:00:11.880 --> 00:00:14.360]   And who's signing up for Apple TV Plus?
[00:00:14.360 --> 00:00:17.360]   Coming up next on This Week in Tech.
[00:00:17.360 --> 00:00:33.440]   This is Twit.
[00:00:33.440 --> 00:00:41.000]   This is Twit, Episode 744 for November 10, 2019, Boiling the Privacy Frog.
[00:00:41.000 --> 00:00:44.080]   This week in Tech is brought to you by Zip Recruiter.
[00:00:44.080 --> 00:00:46.320]   Hiring isn't easy.
[00:00:46.320 --> 00:00:50.160]   But there's one place you can go where hiring is simple and smart.
[00:00:50.160 --> 00:00:55.560]   That place is Zip Recruiter, where growing businesses connect to qualified candidates.
[00:00:55.560 --> 00:01:00.160]   Try it free at zipprecruiter.com/twit.
[00:01:00.160 --> 00:01:03.040]   And by Wasabi Hot Cloud Storage.
[00:01:03.040 --> 00:01:06.680]   If you're thinking about moving your data storage to the cloud, you need to know about
[00:01:06.680 --> 00:01:13.400]   Wasabi Enterprise Class Cloud Storage at 1/5th the price of Amazon S3 and up to 6 times
[00:01:13.400 --> 00:01:18.160]   faster with no hidden fees for egress or API requests.
[00:01:18.160 --> 00:01:27.120]   Calculate your savings and try Wasabi with free unlimited storage for a month at Wasabi.com/twit.
[00:01:27.120 --> 00:01:29.120]   And by CapTerra.
[00:01:29.120 --> 00:01:33.280]   Find the right tools to make an informed software decision for your business.
[00:01:33.280 --> 00:01:39.240]   Visit CapTerra's free website at capterra.com/twit.
[00:01:39.240 --> 00:01:41.240]   And by Mint Mobile.
[00:01:41.240 --> 00:01:45.400]   Mint Mobile provides the same premium network coverage you're used to, but at a fraction
[00:01:45.400 --> 00:01:48.640]   of the cost because everything is online.
[00:01:48.640 --> 00:01:53.680]   Mint Mobile makes it easy to cut your wireless bill down to just $15 a month with their three-month
[00:01:53.680 --> 00:01:55.240]   introductory plan.
[00:01:55.240 --> 00:02:00.680]   And get the plan shipped to your door for free at mintmobile.com/twit.
[00:02:00.680 --> 00:02:03.080]   Hi everyone.
[00:02:03.080 --> 00:02:05.360]   Welcome to this week in Tech.
[00:02:05.360 --> 00:02:09.640]   This is Alex Lindsey and I am sitting in obviously for Leo.
[00:02:09.640 --> 00:02:13.440]   He was still out and enjoying some part of the world.
[00:02:13.440 --> 00:02:16.200]   And I'm joined here with Greg Farrow.
[00:02:16.200 --> 00:02:17.200]   Hi Greg.
[00:02:17.200 --> 00:02:18.200]   Hey, how are you doing?
[00:02:18.200 --> 00:02:19.200]   I'm doing well.
[00:02:19.200 --> 00:02:20.200]   I'm back in studio this time too.
[00:02:20.200 --> 00:02:21.200]   I am.
[00:02:21.200 --> 00:02:22.200]   It's crazy.
[00:02:22.200 --> 00:02:23.200]   You're in studio.
[00:02:23.200 --> 00:02:24.200]   I'm in studio.
[00:02:24.200 --> 00:02:26.400]   Unfortunately, Justine Esurich is not in studio.
[00:02:26.400 --> 00:02:27.400]   But unfortunately she's here.
[00:02:27.400 --> 00:02:28.400]   I'm in Los Angeles.
[00:02:28.400 --> 00:02:29.400]   I'm here virtually.
[00:02:29.400 --> 00:02:32.520]   And you were just up here, weren't you?
[00:02:32.520 --> 00:02:33.520]   I was.
[00:02:33.520 --> 00:02:34.520]   I was in Cupertino for the final cut summit.
[00:02:34.520 --> 00:02:35.520]   So it was really fun.
[00:02:35.520 --> 00:02:36.520]   It's so sad.
[00:02:36.520 --> 00:02:38.000]   You weren't able to make it here.
[00:02:38.000 --> 00:02:39.000]   I know.
[00:02:39.000 --> 00:02:40.000]   I just thought about it.
[00:02:40.000 --> 00:02:41.160]   I was like, man, I should have stayed a couple of extra days.
[00:02:41.160 --> 00:02:42.160]   Yes.
[00:02:42.160 --> 00:02:43.160]   Yes.
[00:02:43.160 --> 00:02:47.200]   So but we've got lots of news and lots to talk about.
[00:02:47.200 --> 00:02:49.680]   So we'll just jump right back into it.
[00:02:49.680 --> 00:02:53.360]   Now this is something that is a little bit California-centric but it is affecting a
[00:02:53.360 --> 00:02:56.560]   lot of places around the world.
[00:02:56.560 --> 00:03:02.040]   One of the articles here from New York Times is why $4.5 billion from Big Tech won't in
[00:03:02.040 --> 00:03:04.120]   the California housing crisis.
[00:03:04.120 --> 00:03:10.080]   The housing is becoming in urban areas, is becoming almost unworkable.
[00:03:10.080 --> 00:03:17.240]   What is the real question here is, what can we do, Greg, about what can we do?
[00:03:17.240 --> 00:03:18.240]   This is all up to you.
[00:03:18.240 --> 00:03:19.240]   Yeah, it's yeah.
[00:03:19.240 --> 00:03:22.200]   What can we do about the housing crisis from a tech perspective?
[00:03:22.200 --> 00:03:25.560]   I think that these tech companies that talk about doing remote working should actually
[00:03:25.560 --> 00:03:26.560]   just do that.
[00:03:26.560 --> 00:03:28.760]   Why would you put houses here at all?
[00:03:28.760 --> 00:03:34.080]   I think in any realistic world, Silicon Valley is an improbably bad place to do business.
[00:03:34.080 --> 00:03:35.800]   It's prone to fires.
[00:03:35.800 --> 00:03:38.320]   You've got structural challenges around electricity.
[00:03:38.320 --> 00:03:40.400]   It's an earthquake zone.
[00:03:40.400 --> 00:03:45.240]   And the cost of buying up land and the government resistance like the bureaucratic process which
[00:03:45.240 --> 00:03:52.200]   can either be hijacked by people, by the community or by the government themselves means that
[00:03:52.200 --> 00:04:00.120]   I don't think there's any answers here about what we're doing and why would you do business
[00:04:00.120 --> 00:04:01.120]   here at all?
[00:04:01.120 --> 00:04:02.120]   I'm a bit baffled by that at all.
[00:04:02.120 --> 00:04:04.800]   I can't understand why you would even build another house here.
[00:04:04.800 --> 00:04:08.000]   Why don't I just go somewhere else and set up an office in London?
[00:04:08.000 --> 00:04:09.000]   Here's the problem.
[00:04:09.000 --> 00:04:14.520]   Here's the issue that a lot of folks will bring up in this situation.
[00:04:14.520 --> 00:04:21.720]   Number one is, if you're not at a headquarters, a lot of times it's seen if you want to move
[00:04:21.720 --> 00:04:26.480]   up in a corporation, it's hard to do that from a satellite office.
[00:04:26.480 --> 00:04:31.800]   And so a lot of folks aspire to get to the headquarters office because that's where you're
[00:04:31.800 --> 00:04:36.440]   going to be running into the right people quote unquote that they're going to help kind
[00:04:36.440 --> 00:04:38.080]   of move you forward.
[00:04:38.080 --> 00:04:44.320]   Also in the competition for programmers and staff and so on and so forth, there becomes
[00:04:44.320 --> 00:04:49.440]   this issue of can you find people that want to live in Kansas?
[00:04:49.440 --> 00:04:52.640]   And I think that that argument is slowly sliding with this expense.
[00:04:52.640 --> 00:04:56.960]   I think that the argument is starting to slide against, there's a lot of people that would
[00:04:56.960 --> 00:05:01.280]   love to move to Kansas because they're tired of spending so much.
[00:05:01.280 --> 00:05:02.840]   There's a couple of things there.
[00:05:02.840 --> 00:05:07.720]   I think one is that attitude of you have to be in head office to get ahead is an old attitude.
[00:05:07.720 --> 00:05:09.440]   It's not something that's true anymore.
[00:05:09.440 --> 00:05:12.560]   There's certainly a lot of organizations for whom they--
[00:05:12.560 --> 00:05:16.800]   It's pretty accepted at a lot of these-- it's not so much whether it's true or not.
[00:05:16.800 --> 00:05:18.800]   It's where the people think it's true.
[00:05:18.800 --> 00:05:19.800]   Exactly.
[00:05:19.800 --> 00:05:21.760]   And increasingly what we're seeing is there's a turn away from that.
[00:05:21.760 --> 00:05:24.840]   So if you're still working for a traditional organization with traditional managers, with
[00:05:24.840 --> 00:05:26.480]   traditional approaches and little stuff--
[00:05:26.480 --> 00:05:30.480]   I'm talking about like-- those are sensitivities that like information companies.
[00:05:30.480 --> 00:05:31.480]   Yeah, yeah.
[00:05:31.480 --> 00:05:33.480]   It's not like we're not talking about like a steel company.
[00:05:33.480 --> 00:05:34.720]   Well, how's our brand still run like that?
[00:05:34.720 --> 00:05:36.080]   But increasingly that's no longer true.
[00:05:36.080 --> 00:05:40.240]   I mean, one of the interesting things about this is that the challenge around the immigration
[00:05:40.240 --> 00:05:44.840]   policy in the US has actually seen a substantial rise in remote working.
[00:05:44.840 --> 00:05:48.880]   And this idea of we used to bring all of the people in from all around the world, from
[00:05:48.880 --> 00:05:53.120]   India, from Europe, from Asia, and they would all come here and get visas and work here
[00:05:53.120 --> 00:05:54.400]   for two years.
[00:05:54.400 --> 00:05:57.400]   And as the immigration policies change, a lot of these companies have actually just picked
[00:05:57.400 --> 00:06:00.960]   up all the divisions that used to be based here and sent them back to other countries.
[00:06:00.960 --> 00:06:03.600]   So they're now basing them in those countries.
[00:06:03.600 --> 00:06:07.760]   And if somebody from India needs to move to somewhere in Asia to get that team together,
[00:06:07.760 --> 00:06:08.760]   that's what they're doing.
[00:06:08.760 --> 00:06:09.760]   Right.
[00:06:09.760 --> 00:06:11.800]   Justine, what are your opinions on this?
[00:06:11.800 --> 00:06:13.600]   I mean, I love working remotely.
[00:06:13.600 --> 00:06:16.480]   Everyone that I work with, we all work from wherever.
[00:06:16.480 --> 00:06:20.360]   I mean, basically I work just all around the world constantly.
[00:06:20.360 --> 00:06:25.240]   But I think there is nothing that can replace passing off a hard drive to somebody and knowing
[00:06:25.240 --> 00:06:26.680]   that that's actually going to get there.
[00:06:26.680 --> 00:06:28.560]   They're not going to have to wait for download speeds.
[00:06:28.560 --> 00:06:33.600]   So I think being in the office is such a huge advantage like you were talking about because
[00:06:33.600 --> 00:06:37.320]   you actually see the people you meet with the people and you are face to face with them.
[00:06:37.320 --> 00:06:42.020]   And me as someone who is so in-attack and loves it so much, there is really nothing
[00:06:42.020 --> 00:06:46.280]   different than just actually being with a person and having those conversations because
[00:06:46.280 --> 00:06:50.120]   that's when a lot of things do happen when you can actually sit down and look at somebody.
[00:06:50.120 --> 00:06:51.880]   Because even though we're doing this, it's virtual, it's great.
[00:06:51.880 --> 00:06:55.480]   But I think sometimes you really do have to be in the room with somebody to really get
[00:06:55.480 --> 00:06:57.560]   a feel for a person and to get the vibe.
[00:06:57.560 --> 00:06:59.160]   So that's what you're losing.
[00:06:59.160 --> 00:07:01.760]   And I admit, I thought about this looking at this article.
[00:07:01.760 --> 00:07:04.080]   Last week, I was in the East Coast.
[00:07:04.080 --> 00:07:09.240]   And I had a bunch of meetings and then there are just discussions, just talking to folks.
[00:07:09.240 --> 00:07:10.240]   But I did it in person.
[00:07:10.240 --> 00:07:16.360]   And I went from Boston to New York to DC because there was a need to at least have that first
[00:07:16.360 --> 00:07:20.200]   conversation in person with them while you're in.
[00:07:20.200 --> 00:07:23.280]   A lot of times you're talking to a handful of people.
[00:07:23.280 --> 00:07:26.320]   And I think part of the problem also is that some of our virtual conversations as we talked
[00:07:26.320 --> 00:07:29.520]   about before the show is this can be a little rocky.
[00:07:29.520 --> 00:07:32.360]   Don't use those comments.
[00:07:32.360 --> 00:07:33.360]   I agree with you.
[00:07:33.360 --> 00:07:34.920]   There's certainly value in face-to-face time.
[00:07:34.920 --> 00:07:39.360]   And there's a very powerful, high density information-rich conversation that happens
[00:07:39.360 --> 00:07:41.040]   when you're face-to-face, right?
[00:07:41.040 --> 00:07:42.040]   And it can be very valuable.
[00:07:42.040 --> 00:07:46.280]   And it's also very useful to establish a base-rowing relationship between two people, a professional
[00:07:46.280 --> 00:07:47.280]   relationship.
[00:07:47.280 --> 00:07:49.320]   It happens very quickly, if that makes sense.
[00:07:49.320 --> 00:07:53.000]   The challenge after that is when you start getting people working in four or five times
[00:07:53.000 --> 00:07:57.640]   and so our business runs and we have people in Australia, East and West Coast of the US.
[00:07:57.640 --> 00:08:00.920]   We've got some in Europe and a lot of us are moving around all the time.
[00:08:00.920 --> 00:08:05.480]   And what we've now found is it's much easier to talk asynchronously once you get practiced
[00:08:05.480 --> 00:08:06.480]   at it.
[00:08:06.480 --> 00:08:07.480]   And this is the challenge.
[00:08:07.480 --> 00:08:10.640]   If you spend all your life face-to-facing people and going eyeball-to-eyeball with a high
[00:08:10.640 --> 00:08:14.840]   density conversation, you get comfortable with that mode of communication.
[00:08:14.840 --> 00:08:15.840]   Does that make sense?
[00:08:15.840 --> 00:08:19.480]   And if you go to working, then you have to change your habits.
[00:08:19.480 --> 00:08:22.760]   You have to change the metaphor I've sometimes used for it.
[00:08:22.760 --> 00:08:26.600]   Remember reading books and then you started reading from the screen?
[00:08:26.600 --> 00:08:28.560]   Do you actually read a book now at all?
[00:08:28.560 --> 00:08:29.840]   I didn't before.
[00:08:29.840 --> 00:08:30.840]   Yeah.
[00:08:30.840 --> 00:08:31.840]   Sorry.
[00:08:31.840 --> 00:08:33.840]   I've been listening to books since the late '80s.
[00:08:33.840 --> 00:08:35.640]   It started on tapes and everything.
[00:08:35.640 --> 00:08:36.640]   I was like, I don't...
[00:08:36.640 --> 00:08:39.120]   The idea of sitting down and actually reading a book in my own.
[00:08:39.120 --> 00:08:40.120]   Why not ask you?
[00:08:40.120 --> 00:08:41.120]   It's just an horrible idea.
[00:08:41.120 --> 00:08:42.120]   You just do.
[00:08:42.120 --> 00:08:43.120]   Does the metaphor apply to you?
[00:08:43.120 --> 00:08:44.920]   Do you still read books or do you do everything on ebooks?
[00:08:44.920 --> 00:08:45.920]   It's all...
[00:08:45.920 --> 00:08:46.920]   I mean, I listen to a lot of audiobooks as well.
[00:08:46.920 --> 00:08:50.080]   I mean, it's just like I can be doing something else and also listening.
[00:08:50.080 --> 00:08:53.000]   So driving or traveling, it's like I can be listening.
[00:08:53.000 --> 00:08:54.000]   I can be...
[00:08:54.000 --> 00:08:55.560]   Let me ask you how long did it take to take the notes?
[00:08:55.560 --> 00:08:58.800]   Of listening to audiobooks before you started to absorb that correctly.
[00:08:58.800 --> 00:09:01.960]   The first time you listened to an audiobook, you would have had struggled to listen.
[00:09:01.960 --> 00:09:02.960]   Now I listen to...
[00:09:02.960 --> 00:09:06.400]   For me, it's mostly how long did it take me to get the 2X?
[00:09:06.400 --> 00:09:07.400]   Yes.
[00:09:07.400 --> 00:09:08.400]   You know, in my listening speed.
[00:09:08.400 --> 00:09:09.400]   Oh, yeah, that's a great point.
[00:09:09.400 --> 00:09:10.400]   Yeah.
[00:09:10.400 --> 00:09:11.400]   Yeah.
[00:09:11.400 --> 00:09:12.400]   I'm more of like a...
[00:09:12.400 --> 00:09:15.000]   I mean, I'm also a visual learner, but I feel like for me, I retain things much better
[00:09:15.000 --> 00:09:16.200]   just listening to it.
[00:09:16.200 --> 00:09:19.760]   So even if I'm trying to memorize something, like I can't look at it, I have to like hear
[00:09:19.760 --> 00:09:20.760]   it.
[00:09:20.760 --> 00:09:23.920]   So I think a lot of people, again, going back to this, a lot of people learn different.
[00:09:23.920 --> 00:09:29.000]   So there's so many aspects of personalities that also kind of play into this, whereas
[00:09:29.000 --> 00:09:31.840]   I would work much better in a situation that I'm in now.
[00:09:31.840 --> 00:09:35.000]   If you give me my tasks, I will go off by myself and get them done.
[00:09:35.000 --> 00:09:36.440]   But some people can't work that way.
[00:09:36.440 --> 00:09:40.640]   So I think it's kind of tailoring to the way that people learn and the way that people
[00:09:40.640 --> 00:09:42.840]   work is one of the most important things.
[00:09:42.840 --> 00:09:46.680]   I think that when it comes to like hiring, it's like, how does this person work best?
[00:09:46.680 --> 00:09:49.960]   What can I do to help this person perform the best work possible?
[00:09:49.960 --> 00:09:54.840]   And I do also think our current workspaces are very much targeted at extroverts.
[00:09:54.840 --> 00:09:58.720]   They say something like 70 to 80% of the population is extroverts, and they are people
[00:09:58.720 --> 00:10:03.040]   who thrive on face-to-face communications, thrive on a room full of people.
[00:10:03.040 --> 00:10:06.120]   But the people who actually do get the job done is the introverts.
[00:10:06.120 --> 00:10:09.640]   They're the people who go off and sit in a room quietly and just grind away at the task
[00:10:09.640 --> 00:10:12.000]   and bring it back, complete it.
[00:10:12.000 --> 00:10:14.040]   And remote work works very well for them.
[00:10:14.040 --> 00:10:18.200]   And it's going to be a challenge for the extroverts to change their mode of this face-to-face drawing
[00:10:18.200 --> 00:10:20.520]   energy from a room standing around a desk.
[00:10:20.520 --> 00:10:21.520]   But I think that it's also...
[00:10:21.520 --> 00:10:29.440]   I think that one of the challenges that was brought up in the chat room is that our video
[00:10:29.440 --> 00:10:32.120]   conferencing software still sticks.
[00:10:32.120 --> 00:10:40.080]   So for me, I was teaching classes in Rwanda at a school that I built there.
[00:10:40.080 --> 00:10:44.480]   So we're teaching classes and I couldn't be down there and I got frustrated.
[00:10:44.480 --> 00:10:48.000]   So I ended up building a bunch of hardware that makes that go away.
[00:10:48.000 --> 00:10:53.200]   It makes it much, much smoother, but that's still tens of thousands of dollars of hardware
[00:10:53.200 --> 00:10:54.680]   that all makes that work.
[00:10:54.680 --> 00:10:57.440]   You know, it's not something that you can just put into every office.
[00:10:57.440 --> 00:10:59.640]   It's better than a classroom, but it's not...
[00:10:59.640 --> 00:11:03.760]   You're hitting on a real sore point, which is why is our conferencing software so abysmally awful?
[00:11:03.760 --> 00:11:04.760]   Oh, I can tell you.
[00:11:04.760 --> 00:11:05.760]   Can I tell you?
[00:11:05.760 --> 00:11:06.760]   Go ahead.
[00:11:06.760 --> 00:11:07.760]   Let's go ahead.
[00:11:07.760 --> 00:11:08.760]   I have an opinion.
[00:11:08.760 --> 00:11:10.760]   It's because we want to make it easy.
[00:11:10.760 --> 00:11:13.360]   So the thing is that we want to make it cheap and easy.
[00:11:13.360 --> 00:11:16.960]   And this is the problem with content in general, but it is...
[00:11:16.960 --> 00:11:18.800]   Let's make it easy for everybody to do it.
[00:11:18.800 --> 00:11:23.560]   And the problem is that as you drive down that ease of use, you limit.
[00:11:23.560 --> 00:11:24.560]   It drives to that.
[00:11:24.560 --> 00:11:26.800]   Keep on limiting what you can actually get done.
[00:11:26.800 --> 00:11:30.920]   And as you make it something that can just go everywhere, then it...
[00:11:30.920 --> 00:11:35.400]   The problem you end up with is that now it can't do anything because it had to work
[00:11:35.400 --> 00:11:37.280]   on every platform and it had to work on it.
[00:11:37.280 --> 00:11:39.880]   The reason mine worked was because it was really hard.
[00:11:39.880 --> 00:11:42.080]   You know, it was really hard to make it.
[00:11:42.080 --> 00:11:44.880]   But when you're actually using it, it's super easy.
[00:11:44.880 --> 00:11:46.120]   But building it was expensive.
[00:11:46.120 --> 00:11:48.920]   I'm having really good luck at the moment with Zoom.
[00:11:48.920 --> 00:11:51.600]   We left Skype behind years ago.
[00:11:51.600 --> 00:11:54.000]   Webex is a crime against humanity.
[00:11:54.000 --> 00:11:57.800]   Microsoft Teams is a load of something.
[00:11:57.800 --> 00:12:00.280]   And we find Zoom not bad.
[00:12:00.280 --> 00:12:03.800]   I wouldn't say it's good, but it's mostly stable and mostly works.
[00:12:03.800 --> 00:12:07.880]   I think the biggest thing I found about Zoom is that it has this habit of defaulting to
[00:12:07.880 --> 00:12:10.320]   the bad microphone and the bad video camera.
[00:12:10.320 --> 00:12:14.840]   When you put a decent camera on top and a decent microphone, it's excellent, actually.
[00:12:14.840 --> 00:12:18.360]   Yeah, we built some overrides for Hangouts that made it much better.
[00:12:18.360 --> 00:12:19.360]   Yeah.
[00:12:19.360 --> 00:12:21.000]   Basically, there used to be an API for Hangouts.
[00:12:21.000 --> 00:12:25.960]   And so we built it in where we could do what we call soft selecting, which led us basically
[00:12:25.960 --> 00:12:27.360]   ignore certain people if we needed to.
[00:12:27.360 --> 00:12:30.840]   Could you build us a camera lock for Zoom, please?
[00:12:30.840 --> 00:12:36.920]   Because the one thing I dislike about Zoom is it's automatic switching.
[00:12:36.920 --> 00:12:39.160]   It makes conversation very jerry.
[00:12:39.160 --> 00:12:40.720]   Yeah, I don't remember what it was.
[00:12:40.720 --> 00:12:43.360]   Now this person is talking now, this person is talking.
[00:12:43.360 --> 00:12:47.920]   I don't remember whether it was, I don't remember what the official external name was,
[00:12:47.920 --> 00:12:50.920]   but there was a thing on pinning or make sticky.
[00:12:50.920 --> 00:12:51.920]   Yeah.
[00:12:51.920 --> 00:12:56.040]   That's what we used to call it for Hangouts, where you could just click on someone's screen
[00:12:56.040 --> 00:12:58.680]   and it would hang, it would at least hang on that for the broadcast.
[00:12:58.680 --> 00:13:02.200]   It still did a free run, but any user could also just click on it and they'll only see
[00:13:02.200 --> 00:13:03.200]   those things.
[00:13:03.200 --> 00:13:07.920]   But again, your point is that Zoom is not suitable for a small group of people, five
[00:13:07.920 --> 00:13:11.520]   to ten people getting together, works pretty well for that.
[00:13:11.520 --> 00:13:15.640]   We use it for live streaming to YouTube a couple of times and it kind of works okay.
[00:13:15.640 --> 00:13:16.640]   Right.
[00:13:16.640 --> 00:13:20.120]   But it still gets into that dumb down to a point where it's, compared to what it could
[00:13:20.120 --> 00:13:21.120]   be, as far as it can be.
[00:13:21.120 --> 00:13:24.740]   I think Zoom is even, I mean, I really like it, but it's, I would say it's even more
[00:13:24.740 --> 00:13:26.160]   dumb down than Skype.
[00:13:26.160 --> 00:13:27.160]   I think it's, I mean--
[00:13:27.160 --> 00:13:28.160]   It's so funny.
[00:13:28.160 --> 00:13:31.640]   These things are dumb down, but yet I'm a very tech savvy person.
[00:13:31.640 --> 00:13:34.200]   I'll build you a computer, but I sometimes can't get Skype to work.
[00:13:34.200 --> 00:13:35.200]   No, that's--
[00:13:35.200 --> 00:13:36.200]   Sense at all.
[00:13:36.200 --> 00:13:37.200]   That's not you, that's Skype.
[00:13:37.200 --> 00:13:38.200]   Don't blame yourself.
[00:13:38.200 --> 00:13:39.200]   Don't blame Microsoft.
[00:13:39.200 --> 00:13:40.200]   That's because it's been dumb down.
[00:13:40.200 --> 00:13:41.200]   Seriously.
[00:13:41.200 --> 00:13:46.880]   That's because you don't have, if something goes wrong, you don't have options to fix it.
[00:13:46.880 --> 00:13:47.880]   Yes.
[00:13:47.880 --> 00:13:48.880]   Like there are many problems we always--
[00:13:48.880 --> 00:13:49.880]   Yeah, like how many seven of them have something my own servers?
[00:13:49.880 --> 00:13:50.880]   I'll make my own servers.
[00:13:50.880 --> 00:13:51.880]   I'll send you guys a link.
[00:13:51.880 --> 00:13:54.240]   And then the problem you get into is the latency, right?
[00:13:54.240 --> 00:13:58.800]   Like it's all this low latency, you know, we, I mean, the best solutions that we've seen
[00:13:58.800 --> 00:14:02.840]   have been private solutions as you, as you said, which are people building on top of
[00:14:02.840 --> 00:14:04.400]   WebRTC.
[00:14:04.400 --> 00:14:05.400]   And that is--
[00:14:05.400 --> 00:14:06.400]   Yeah.
[00:14:06.400 --> 00:14:09.720]   So people will build a custom solution for letting people do it within a company or for
[00:14:09.720 --> 00:14:10.720]   broadcasters.
[00:14:10.720 --> 00:14:11.720]   Yeah.
[00:14:11.720 --> 00:14:14.600]   And they're sitting on top of WebRTC, and that has been super successful for a lot of
[00:14:14.600 --> 00:14:15.600]   them.
[00:14:15.600 --> 00:14:16.600]   Yeah.
[00:14:16.600 --> 00:14:20.120]   But that's not something that right now is a scalable, it's not what everybody's doing.
[00:14:20.120 --> 00:14:21.520]   I think there's a couple of things too.
[00:14:21.520 --> 00:14:25.800]   One of the things that we find is we get people come on our shows and they'll use the rubbish
[00:14:25.800 --> 00:14:29.080]   camera that comes inside of their Dell, you know, the five cent camera that came out
[00:14:29.080 --> 00:14:30.080]   of the factory.
[00:14:30.080 --> 00:14:31.080]   Yeah.
[00:14:31.080 --> 00:14:33.560]   And then they'll yell at the screen and there's a microphone underneath the keyboard and expect
[00:14:33.560 --> 00:14:35.280]   that to work correctly.
[00:14:35.280 --> 00:14:36.280]   Right.
[00:14:36.280 --> 00:14:37.280]   But they won't consider--
[00:14:37.280 --> 00:14:40.960]   I just-- the eyesight camera on the iMac right now, I mean, it's definitely not the best,
[00:14:40.960 --> 00:14:43.280]   but as long as you have like decent lighting, you can still get--
[00:14:43.280 --> 00:14:47.760]   This is where I was just going to say straight after that is, why are not people taking responsibility
[00:14:47.760 --> 00:14:52.640]   for themselves and thinking, I've got to have a space in my study, which has got a background
[00:14:52.640 --> 00:14:55.080]   that's pretty-- like this is just a background behind me, right?
[00:14:55.080 --> 00:14:56.520]   And there's some nice lights here.
[00:14:56.520 --> 00:14:59.800]   You know, my home studio, which you've seen a couple of times when I've been fortunate
[00:14:59.800 --> 00:15:03.480]   to be on the show before, all I've got is a couple of lights that shine on my face.
[00:15:03.480 --> 00:15:04.480]   Right.
[00:15:04.480 --> 00:15:08.000]   And a bit of a backdrop there that doesn't look like I've just, you know--
[00:15:08.000 --> 00:15:09.000]   Right.
[00:15:09.000 --> 00:15:10.000]   I mean, we had a kit.
[00:15:10.000 --> 00:15:13.280]   I don't know how we got into this from cities, but we'll keep on quiet.
[00:15:13.280 --> 00:15:14.280]   Yeah.
[00:15:14.280 --> 00:15:15.280]   So anyway, but--
[00:15:15.280 --> 00:15:16.280]   Crisis.
[00:15:16.280 --> 00:15:20.760]   We had a used to have a kit, because we did about 1,200 hangouts for Google.
[00:15:20.760 --> 00:15:26.680]   And we did-- we had this kit that we would send out that was just an IFB, and it was
[00:15:26.680 --> 00:15:27.680]   an Ego light.
[00:15:27.680 --> 00:15:28.680]   You know, there's something--
[00:15:28.680 --> 00:15:29.680]   Yeah, yeah, a little--
[00:15:29.680 --> 00:15:32.680]   Ego light with a C-- Logitech C920.
[00:15:32.680 --> 00:15:33.680]   Yep.
[00:15:33.680 --> 00:15:34.680]   And a little tripod for it.
[00:15:34.680 --> 00:15:36.600]   And a little tripod for this.
[00:15:36.600 --> 00:15:37.600]   And that was it.
[00:15:37.600 --> 00:15:42.360]   And the thing is, is it was literally tripled the quality of the persons, you know, look,
[00:15:42.360 --> 00:15:45.320]   and it was just like-- and we'd send it to them with a return address and a little video
[00:15:45.320 --> 00:15:46.320]   on how to put it together.
[00:15:46.320 --> 00:15:47.320]   This is what we did.
[00:15:47.320 --> 00:15:48.320]   And it just worked.
[00:15:48.320 --> 00:15:49.320]   We're doing that.
[00:15:49.320 --> 00:15:50.320]   I just did that.
[00:15:50.320 --> 00:15:53.080]   I did some live-- I did some video for a client recently, same sort of thing, made them go
[00:15:53.080 --> 00:15:55.240]   out and buy a Logitech C922.
[00:15:55.240 --> 00:15:56.240]   Yep.
[00:15:56.240 --> 00:15:58.320]   Made them by a decent $50 microphone.
[00:15:58.320 --> 00:15:59.320]   Right.
[00:15:59.320 --> 00:16:02.000]   And boom, everything was-- and then taught them how to put the lights in front of their
[00:16:02.000 --> 00:16:03.840]   face instead of buying the ads.
[00:16:03.840 --> 00:16:04.840]   And it was fun.
[00:16:04.840 --> 00:16:05.840]   Crazy stuff.
[00:16:05.840 --> 00:16:06.840]   Crazy stuff.
[00:16:06.840 --> 00:16:07.840]   It's not right over the top of their head.
[00:16:07.840 --> 00:16:08.840]   But I mean, that's a learned experience.
[00:16:08.840 --> 00:16:10.960]   People who work from home have to learn that.
[00:16:10.960 --> 00:16:12.520]   And the people aren't used to thinking for themselves.
[00:16:12.520 --> 00:16:14.720]   They're used to going into an office where that's done for them.
[00:16:14.720 --> 00:16:16.920]   And usually not done for them very well.
[00:16:16.920 --> 00:16:20.760]   I mean, the IT team is usually available-- is usually the ones managing that.
[00:16:20.760 --> 00:16:24.720]   And they're not-- I mean, I don't know offense to the IT teams, but they're not camera people.
[00:16:24.720 --> 00:16:27.080]   And so it's kind of a goofy little problem.
[00:16:27.080 --> 00:16:29.640]   Well, not just-- I got a question for you.
[00:16:29.640 --> 00:16:34.240]   So is there a way-- these come-- you know, Apple and all these folks are spending billions
[00:16:34.240 --> 00:16:37.840]   of dollars on cities?
[00:16:37.840 --> 00:16:40.680]   What could they be doing with that money that would actually make a difference as opposed
[00:16:40.680 --> 00:16:42.160]   to just building more of the same?
[00:16:42.160 --> 00:16:43.880]   Do you have any thoughts there?
[00:16:43.880 --> 00:16:47.600]   For me, just even in my neighborhood, I've moved to LA in 2007.
[00:16:47.600 --> 00:16:51.480]   And just seeing the changes in the homeless population just increased, where I'm afraid
[00:16:51.480 --> 00:16:54.880]   to even walk my dog now in my own neighborhood.
[00:16:54.880 --> 00:16:59.040]   And it's hard because I'm completely sympathetic for this because I knew these people are in
[00:16:59.040 --> 00:17:01.480]   terrible places to be in this situation.
[00:17:01.480 --> 00:17:05.560]   But it's like, how do I feel safe in my own town?
[00:17:05.560 --> 00:17:08.640]   And I think a lot of it, unfortunately, comes down to mental health.
[00:17:08.640 --> 00:17:12.160]   So it's like, how is that something that needs to be taken to a place?
[00:17:12.160 --> 00:17:16.640]   And a lot of these people don't want to go to the shelters because they are not able
[00:17:16.640 --> 00:17:20.840]   to-- either they have to be clean or they're unsafe.
[00:17:20.840 --> 00:17:22.680]   So they can't take their families there.
[00:17:22.680 --> 00:17:27.000]   So there's-- I mean, I don't have an answer, but it's just-- I just wish that there was
[00:17:27.000 --> 00:17:31.960]   something that we could do to just further that because they do need help, but there's
[00:17:31.960 --> 00:17:33.440]   not really a place for them to go.
[00:17:33.440 --> 00:17:35.880]   If only tech companies paid taxes, we'd have mental health.
[00:17:35.880 --> 00:17:37.240]   So I agree with you, Justine.
[00:17:37.240 --> 00:17:40.520]   I think the other thing that's happening here is this $4.5 billion they're giving that
[00:17:40.520 --> 00:17:42.400]   is not a gift.
[00:17:42.400 --> 00:17:46.440]   They're trying to make it into a virtual signal and say, like, what they're actually doing
[00:17:46.440 --> 00:17:49.840]   is investing it in a fund and they're trying to make money out of it.
[00:17:49.840 --> 00:17:52.240]   So they're not actually giving it or anything.
[00:17:52.240 --> 00:17:56.320]   All they're doing is putting $4.5 billion into an investment fund that will build properties
[00:17:56.320 --> 00:17:59.400]   that they will take profits from in a few years time.
[00:17:59.400 --> 00:18:00.400]   So it's not even--
[00:18:00.400 --> 00:18:01.400]   Yeah, I think it's even like--
[00:18:01.400 --> 00:18:02.400]   It's not even helping.
[00:18:02.400 --> 00:18:03.400]   It's not even helping.
[00:18:03.400 --> 00:18:04.400]   It's worth--
[00:18:04.400 --> 00:18:07.720]   Yeah, like Google, I think I'm not sure 100% of-- but this is what I've heard like
[00:18:07.720 --> 00:18:11.200]   as far as like, they've bought up a bunch of properties there.
[00:18:11.200 --> 00:18:16.360]   So it's like the housing market in Play Vista in Los Angeles has just quadrupled over the
[00:18:16.360 --> 00:18:20.520]   past year because Google put their offices in and now they own a bunch of those properties.
[00:18:20.520 --> 00:18:25.560]   So even that for just people who were looking at buying just a home for their families,
[00:18:25.560 --> 00:18:27.600]   it's unattainable at this point.
[00:18:27.600 --> 00:18:28.600]   Yeah.
[00:18:28.600 --> 00:18:35.280]   Yeah, and I think that-- and I think that there is-- I'm not clear that the current cities
[00:18:35.280 --> 00:18:36.280]   can be fixed.
[00:18:36.280 --> 00:18:37.680]   We talked about the Sun Mac break the last way.
[00:18:37.680 --> 00:18:42.280]   I don't think that-- I think that there is a argument that it's not changing the cities,
[00:18:42.280 --> 00:18:43.520]   it's not that these cities will go away.
[00:18:43.520 --> 00:18:44.520]   Stanford's just going to go anywhere.
[00:18:44.520 --> 00:18:46.480]   LA's not going to go anywhere.
[00:18:46.480 --> 00:18:51.680]   But I think that if we think about reorganizing for the population growth that we have, you
[00:18:51.680 --> 00:18:55.560]   know, the projected population growth that we're probably going to have, continuing to
[00:18:55.560 --> 00:19:00.080]   grow cities the way that they're being grown, where they're largely subservient to cars,
[00:19:00.080 --> 00:19:06.040]   where they're largely single family houses or all that selling this, is--
[00:19:06.040 --> 00:19:08.680]   that's not sustainable and it's not scalable.
[00:19:08.680 --> 00:19:09.680]   Yeah.
[00:19:09.680 --> 00:19:13.240]   And I think that there's-- and I think that a lot of the tech companies are thinking about
[00:19:13.240 --> 00:19:14.240]   this.
[00:19:14.240 --> 00:19:15.240]   I think that this is-- we're starting to see this.
[00:19:15.240 --> 00:19:20.160]   I'm wondering when a company like Amazon decides to do city as a service.
[00:19:20.160 --> 00:19:24.120]   Well, the challenge here is that I see this is $4.5 billion that they should have paid
[00:19:24.120 --> 00:19:25.280]   in taxes.
[00:19:25.280 --> 00:19:27.520]   And then the government would have it and then it would be able to say--
[00:19:27.520 --> 00:19:29.400]   Because the government would do that so well, wouldn't it?
[00:19:29.400 --> 00:19:30.880]   It generally does it better, right?
[00:19:30.880 --> 00:19:31.880]   That is--
[00:19:31.880 --> 00:19:34.640]   Because it doesn't have a profit-- yeah, it gets a 25% edge because it doesn't have to
[00:19:34.640 --> 00:19:35.640]   do it profitably.
[00:19:35.640 --> 00:19:36.640]   Right?
[00:19:36.640 --> 00:19:37.880]   Well, it's an interesting thing--
[00:19:37.880 --> 00:19:38.880]   Hang on, hang on.
[00:19:38.880 --> 00:19:43.960]   I've worked on plenty of-- have you ever worked for a big company?
[00:19:43.960 --> 00:19:44.960]   Yeah.
[00:19:44.960 --> 00:19:45.960]   Those people are incompetent.
[00:19:45.960 --> 00:19:50.000]   I mean, governments have their problems, but I tell you what, your average big corporation
[00:19:50.000 --> 00:19:54.360]   is a bunch of idiots in suits, as opposed to idiots in cheap clothing.
[00:19:54.360 --> 00:19:56.480]   That's the only difference between a government and a corporation.
[00:19:56.480 --> 00:19:58.400]   And a government doesn't have to make a profit.
[00:19:58.400 --> 00:20:03.000]   They can make one 20% of mistakes and bad decisions and still be on target.
[00:20:03.000 --> 00:20:05.000]   But that would be assuming it was 20%.
[00:20:05.000 --> 00:20:06.000]   Generally, it is.
[00:20:06.000 --> 00:20:07.000]   It's a problem.
[00:20:07.000 --> 00:20:08.000]   It's a problem.
[00:20:08.000 --> 00:20:11.040]   We shouldn't deviate on a tech show into the modes of government.
[00:20:11.040 --> 00:20:13.040]   But that's where all the houses are.
[00:20:13.040 --> 00:20:14.040]   That's where all the houses.
[00:20:14.040 --> 00:20:18.840]   I mean, there are many things that the government could do with that money.
[00:20:18.840 --> 00:20:21.440]   They could improve mental health.
[00:20:21.440 --> 00:20:26.320]   But the one thing they absolutely could not do is build houses.
[00:20:26.320 --> 00:20:31.960]   All government does in the way of housing is say if you can build a house.
[00:20:31.960 --> 00:20:36.040]   No, what they were actually doing in the original plans for this particular estate, one of
[00:20:36.040 --> 00:20:39.480]   the ones that's got two billion dollars worth of funding, 50% of it was designated as low
[00:20:39.480 --> 00:20:43.280]   cost housing and the developer would have to give it away at below cost.
[00:20:43.280 --> 00:20:45.560]   But they could make it up in the other part, right?
[00:20:45.560 --> 00:20:48.960]   But now that the big companies are throwing in 4.5 billion, they're going to get the planning
[00:20:48.960 --> 00:20:49.960]   rights to it.
[00:20:49.960 --> 00:20:53.080]   They'll change it all to high end housing and there'll be nothing left at the low end.
[00:20:53.080 --> 00:20:54.080]   And that's the problem.
[00:20:54.080 --> 00:20:57.000]   Because the government doesn't have a profit motive, it was going to be able to do it for
[00:20:57.000 --> 00:20:58.400]   the good of everybody.
[00:20:58.400 --> 00:21:02.360]   This investment, which must produce a return to Apple and Google and whoever's putting
[00:21:02.360 --> 00:21:06.240]   the money into it, must be high end housing and it's going to displace people and it's
[00:21:06.240 --> 00:21:08.040]   going to make the problem worse.
[00:21:08.040 --> 00:21:09.520]   I see.
[00:21:09.520 --> 00:21:20.760]   However, I mean, it will at least do a little of what Mr. Lindsey wants to happen and transform
[00:21:20.760 --> 00:21:26.920]   the city into more of a more densely populated place.
[00:21:26.920 --> 00:21:33.760]   The plans that Google has for San Jose, the housing that Facebook is building, I don't
[00:21:33.760 --> 00:21:37.360]   know, Apple hasn't shared their plans for what they want to do.
[00:21:37.360 --> 00:21:44.280]   But they're trying to at least build housing near where they are.
[00:21:44.280 --> 00:21:52.360]   And I think that people in suburbs don't have to deal with, then their housing does
[00:21:52.360 --> 00:21:54.360]   not get taken over by Google.
[00:21:54.360 --> 00:21:58.880]   I think that when I was this housing, there was a specific two employees of these companies.
[00:21:58.880 --> 00:22:01.680]   So like, it is not.
[00:22:01.680 --> 00:22:03.800]   For Facebook, it is for Google.
[00:22:03.800 --> 00:22:05.800]   It is partially, but not entirely.
[00:22:05.800 --> 00:22:07.720]   Got our Facebook line in their pockets again.
[00:22:07.720 --> 00:22:08.720]   No questions.
[00:22:08.720 --> 00:22:11.920]   Well, what Facebook is basically doing is building dorms.
[00:22:11.920 --> 00:22:12.920]   Yeah, building.
[00:22:12.920 --> 00:22:13.920]   They're trying to build.
[00:22:13.920 --> 00:22:17.480]   They're doing the because Facebook doesn't want anybody not inside of the camp, inside
[00:22:17.480 --> 00:22:19.360]   of the kindergarten, kissing me.
[00:22:19.360 --> 00:22:20.840]   Anybody goes to work for Facebook.
[00:22:20.840 --> 00:22:24.320]   It's like a kindergarten and all the little nerds get inside there inside the bubble.
[00:22:24.320 --> 00:22:28.640]   But again, I think that there is a argument for these companies.
[00:22:28.640 --> 00:22:34.320]   And I think that a lot of them are trying to figure it out, to get out of the urban areas
[00:22:34.320 --> 00:22:40.280]   and to build large urban structures that are not inside of these and not.
[00:22:40.280 --> 00:22:41.280]   It's called taxes.
[00:22:41.280 --> 00:22:44.680]   If you page a taxes, the government would have the money to build these infrastructures.
[00:22:44.680 --> 00:22:49.920]   If there are less, even if Facebook employees on the roads, then I'm happier.
[00:22:49.920 --> 00:22:56.800]   If the Facebook people just have to walk to work, that's solving several problems.
[00:22:56.800 --> 00:23:01.640]   Regardless of whether we think what people should do or shouldn't do, the reality is
[00:23:01.640 --> 00:23:05.880]   that at some point, I think that a lot of the pressure for on San Jose and San Francisco
[00:23:05.880 --> 00:23:07.440]   and so on and so forth is going to go down.
[00:23:07.440 --> 00:23:10.440]   And the reason it's going to go down is because these companies are going to figure out.
[00:23:10.440 --> 00:23:12.240]   But here's what these companies are going to do.
[00:23:12.240 --> 00:23:14.160]   They're going to figure out how to move to Kansas.
[00:23:14.160 --> 00:23:15.160]   And they're going to build big.
[00:23:15.160 --> 00:23:17.720]   They're going to buy hundreds or thousands of acres.
[00:23:17.720 --> 00:23:20.280]   And they're going to build it.
[00:23:20.280 --> 00:23:22.640]   Now you're talking about a science fiction dystopian.
[00:23:22.640 --> 00:23:23.640]   No, they're testing it.
[00:23:23.640 --> 00:23:24.640]   It's exactly what they're talking about.
[00:23:24.640 --> 00:23:26.560]   They are testing it in Toronto right now.
[00:23:26.560 --> 00:23:29.960]   If Google is building its own neighborhood, at least.
[00:23:29.960 --> 00:23:35.920]   This is them quietly trying to figure this out because for them, it's not so much a
[00:23:35.920 --> 00:23:39.160]   making profit off of other people renting that space.
[00:23:39.160 --> 00:23:44.000]   It is a function of lowering their overall costs because the premium that they pay to
[00:23:44.000 --> 00:23:49.120]   bring people into this state at this point is so high that it would be much better for
[00:23:49.120 --> 00:23:52.520]   them to be able to have a lot more.
[00:23:52.520 --> 00:23:54.360]   And the bottom, you know, the--
[00:23:54.360 --> 00:23:56.640]   So here's my favorite question to ask tech employees.
[00:23:56.640 --> 00:23:57.640]   Sure.
[00:23:57.640 --> 00:24:00.640]   Would you like to come and work in the UK where you'd have complete health care for you and
[00:24:00.640 --> 00:24:02.800]   your entire family no matter who you work for?
[00:24:02.800 --> 00:24:04.800]   The answer is always yes.
[00:24:04.800 --> 00:24:05.800]   Right.
[00:24:05.800 --> 00:24:06.800]   I don't know.
[00:24:06.800 --> 00:24:10.200]   So if you're a smart employee for these companies, you should be working in the European HQs
[00:24:10.200 --> 00:24:15.360]   where there's full cradle to death, health care, and social cover.
[00:24:15.360 --> 00:24:18.960]   Well, that's not the feedback that I got from some level.
[00:24:18.960 --> 00:24:23.960]   If I was Apple and Facebook, I would be building in a place that where leaning into social
[00:24:23.960 --> 00:24:24.960]   services makes sense.
[00:24:24.960 --> 00:24:26.720]   I wouldn't be building here.
[00:24:26.720 --> 00:24:31.240]   I think that there's a big country between the coasts that there's a pretty big opportunity
[00:24:31.240 --> 00:24:32.240]   for it.
[00:24:32.240 --> 00:24:34.360]   And, you know, and I'm not necessarily-- it's not that I don't think--
[00:24:34.360 --> 00:24:38.120]   You don't have to be based in the country where all your revenue comes from.
[00:24:38.120 --> 00:24:42.040]   No, it's just the question of whether people want to move out of the country.
[00:24:42.040 --> 00:24:44.400]   We're not based in Ireland.
[00:24:44.400 --> 00:24:48.120]   I don't want to move.
[00:24:48.120 --> 00:24:50.400]   I just know how much I'm paying in Los Angeles.
[00:24:50.400 --> 00:24:55.680]   If I were to move back home to Pittsburgh, I could have an entire ridiculous studio for
[00:24:55.680 --> 00:24:57.880]   what I'm paying just here.
[00:24:57.880 --> 00:24:59.920]   And I mean, it really does come down to it.
[00:24:59.920 --> 00:25:01.120]   It's like, do you want to move?
[00:25:01.120 --> 00:25:03.400]   And I mean, I don't really want to move back home.
[00:25:03.400 --> 00:25:04.400]   I like it here.
[00:25:04.400 --> 00:25:05.400]   I like, you know, the--
[00:25:05.400 --> 00:25:06.400]   I try.
[00:25:06.400 --> 00:25:07.400]   It's really cold.
[00:25:07.400 --> 00:25:08.400]   Yeah.
[00:25:08.400 --> 00:25:09.400]   I tried.
[00:25:09.400 --> 00:25:10.880]   I tried to persuade my wife to move to Pittsburgh.
[00:25:10.880 --> 00:25:13.240]   We actually moved for a year.
[00:25:13.240 --> 00:25:15.640]   And it turned out to be like the coldest winner in 20 years.
[00:25:15.640 --> 00:25:17.120]   And that was a hard sell.
[00:25:17.120 --> 00:25:19.120]   Oh, and just the California girls.
[00:25:19.120 --> 00:25:21.120]   She was like, mmm, no.
[00:25:21.120 --> 00:25:24.760]   And just for the person in the chat room, he's saying I would have to pay more taxes
[00:25:24.760 --> 00:25:26.760]   if I was in Europe or the UK.
[00:25:26.760 --> 00:25:28.240]   The answer is no, actually.
[00:25:28.240 --> 00:25:31.040]   I actually pay less tax in the UK than you do here.
[00:25:31.040 --> 00:25:32.880]   But you brought up the healthcare.
[00:25:32.880 --> 00:25:34.600]   I mean, that's such a huge point.
[00:25:34.600 --> 00:25:38.400]   I mean, just even now, it's like even my parents, you know, they hadn't used their insurance
[00:25:38.400 --> 00:25:39.400]   for years.
[00:25:39.400 --> 00:25:42.640]   And now that they finally have to use it, they switched off the old insurance.
[00:25:42.640 --> 00:25:44.480]   It's like such an-- it's an incredible hassle.
[00:25:44.480 --> 00:25:45.480]   Yes.
[00:25:45.480 --> 00:25:49.040]   And it's just really unfortunate that that's, you know, that what we are in right now.
[00:25:49.040 --> 00:25:52.640]   But will the tech solve that?
[00:25:52.640 --> 00:25:55.560]   Maybe we need just better conferencing than everything that we solve.
[00:25:55.560 --> 00:25:58.200]   If we had better conferencing, all of this.
[00:25:58.200 --> 00:25:59.600]   It would be moot.
[00:25:59.600 --> 00:26:00.600]   Because then you would--
[00:26:00.600 --> 00:26:04.320]   I mean, you know, and I-- we'll move on to the next thing in a second here.
[00:26:04.320 --> 00:26:11.680]   But the-- my uncle invented some medical stuff that did pretty well.
[00:26:11.680 --> 00:26:15.880]   And I was talking to him, this is when the first single-payer conversation was happening
[00:26:15.880 --> 00:26:17.200]   in the '90s.
[00:26:17.200 --> 00:26:22.640]   And I asked him, like, what is the-- how would you fix the healthcare system?
[00:26:22.640 --> 00:26:26.080]   And he goes, oh, we just have to realize his opinion was, and he builds tools that keep
[00:26:26.080 --> 00:26:27.920]   people alive that people die.
[00:26:27.920 --> 00:26:29.880]   And he goes, the problem we're going to get into.
[00:26:29.880 --> 00:26:32.800]   And he just predicted this 20 years ahead is that he said, you're going to spend all
[00:26:32.800 --> 00:26:36.720]   of your insurance money in the last six weeks or the last six months of your life.
[00:26:36.720 --> 00:26:39.400]   Everything you put into the system is going to get used up at the end, which means that
[00:26:39.400 --> 00:26:43.000]   doesn't-- the insurance process doesn't really work because you're just going to burn it
[00:26:43.000 --> 00:26:44.000]   all up.
[00:26:44.000 --> 00:26:46.200]   And so he says, at some point, we're going to have to start making really hard decisions
[00:26:46.200 --> 00:26:51.360]   because our technology-- he was a technology company-- technology is going to get to a
[00:26:51.360 --> 00:26:53.520]   point where we can keep people alive forever.
[00:26:53.520 --> 00:26:54.520]   That's--
[00:26:54.520 --> 00:26:55.520]   And we don't want to make that decision.
[00:26:55.520 --> 00:26:56.520]   We don't want to be the one to pull the problem.
[00:26:56.520 --> 00:26:57.520]   That is the US.
[00:26:57.520 --> 00:26:58.520]   And that is the United States problem.
[00:26:58.520 --> 00:26:59.520]   That is not necessarily a problem.
[00:26:59.520 --> 00:27:03.360]   In Europe, for example, they actually have commissions which study the cost of medicine
[00:27:03.360 --> 00:27:07.000]   versus the value of life or the quality of life.
[00:27:07.000 --> 00:27:08.000]   And different--
[00:27:08.000 --> 00:27:09.000]   I think Americans are ready for that.
[00:27:09.000 --> 00:27:10.240]   Well, I think that's the problem.
[00:27:10.240 --> 00:27:14.440]   I think that you can have that-- and you need that to make a single pair work.
[00:27:14.440 --> 00:27:15.440]   And I'm not clear--
[00:27:15.440 --> 00:27:18.680]   You have to have a community insurance system to make it work.
[00:27:18.680 --> 00:27:22.080]   You have to have a community insurance for health care.
[00:27:22.080 --> 00:27:25.200]   Now whether that's a commercial community health care or a government sponsored one
[00:27:25.200 --> 00:27:26.200]   doesn't really matter.
[00:27:26.200 --> 00:27:27.920]   The answer is a community health care system.
[00:27:27.920 --> 00:27:32.160]   I think Pete Billigic gets it completely right where he says Medicare for those who wants
[00:27:32.160 --> 00:27:33.160]   it.
[00:27:33.160 --> 00:27:34.160]   I think that makes a lot of sense.
[00:27:34.160 --> 00:27:35.160]   And that makes sense.
[00:27:35.160 --> 00:27:38.640]   So that is if you want health care and you can't find it anywhere else, there's a Medicare
[00:27:38.640 --> 00:27:39.640]   system.
[00:27:39.640 --> 00:27:40.640]   There's people want it.
[00:27:40.640 --> 00:27:41.640]   I think it's an error.
[00:27:41.640 --> 00:27:42.640]   And if you don't want it, that's OK.
[00:27:42.640 --> 00:27:45.800]   And I want to say, to be clear, I would prefer a single pair health care.
[00:27:45.800 --> 00:27:47.800]   That's what I would prefer.
[00:27:47.800 --> 00:27:53.000]   I just don't think that it's-- I think that a-- I don't think that's going to work anytime
[00:27:53.000 --> 00:27:54.000]   soon.
[00:27:54.000 --> 00:27:55.000]   It works in other countries.
[00:27:55.000 --> 00:27:56.000]   It does, but it doesn't.
[00:27:56.000 --> 00:28:00.680]   I think that getting a country the size of the US to transform itself in the current
[00:28:00.680 --> 00:28:02.800]   political climate is not like it happened.
[00:28:02.800 --> 00:28:06.600]   But if you ever want to study a community health care, which is both a combination of
[00:28:06.600 --> 00:28:10.960]   public and private medicine, that is government funded as well as private practice where you
[00:28:10.960 --> 00:28:13.440]   can choose which one you want, go and study the Australian system.
[00:28:13.440 --> 00:28:18.240]   It's a fascinating study and a great success story too, as far as I'm concerned.
[00:28:18.240 --> 00:28:19.240]   As far as I believe.
[00:28:19.240 --> 00:28:20.240]   Absolutely.
[00:28:20.240 --> 00:28:25.360]   Speaking of medicine, we have an interesting story of how medicine is going to be delivered
[00:28:25.360 --> 00:28:26.360]   in the future.
[00:28:26.360 --> 00:28:27.360]   I was just about to--
[00:28:27.360 --> 00:28:28.360]   This is crazy.
[00:28:28.360 --> 00:28:29.360]   It's crazy.
[00:28:29.360 --> 00:28:34.400]   So, Justine, do you see your drugs being-- your prescription drugs, not your drug drugs.
[00:28:34.400 --> 00:28:36.840]   It is California, marijuana is legal.
[00:28:36.840 --> 00:28:41.400]   I mean, you don't mean delivery, marijuana is like delivering a high from high.
[00:28:41.400 --> 00:28:43.560]   On high, it'd be great.
[00:28:43.560 --> 00:28:48.480]   But prescription drugs, do you see this something that you would use as having your prescription
[00:28:48.480 --> 00:28:49.480]   drugs delivered to your house?
[00:28:49.480 --> 00:28:50.480]   What?
[00:28:50.480 --> 00:28:53.800]   I mean, this article specifically, it was talking about people who aren't able to go
[00:28:53.800 --> 00:28:55.840]   to the store and haven't delivered.
[00:28:55.840 --> 00:28:56.840]   But I'm not sure.
[00:28:56.840 --> 00:28:59.600]   I mean, don't they have just regular delivery systems?
[00:28:59.600 --> 00:29:00.800]   Do they have to have the drones?
[00:29:00.800 --> 00:29:01.800]   I also feel like--
[00:29:01.800 --> 00:29:03.200]   I think a lot of it has to do with expense.
[00:29:03.200 --> 00:29:05.360]   Yeah, I guess that's a good point too.
[00:29:05.360 --> 00:29:10.320]   This was specifically talking about UPS and CVS partnering together.
[00:29:10.320 --> 00:29:13.760]   I thought it was very interesting having a drone delivering your drugs, but I also feel
[00:29:13.760 --> 00:29:17.480]   like you could just catch that drone very easily.
[00:29:17.480 --> 00:29:20.800]   I feel like if there's people out there that are trying to get these drugs that are flying
[00:29:20.800 --> 00:29:23.600]   around the sky, they're going to figure it out.
[00:29:23.600 --> 00:29:24.600]   So I don't know.
[00:29:24.600 --> 00:29:27.600]   I think that I was looking at it.
[00:29:27.600 --> 00:29:29.840]   Instead, it drops it from 20 feet.
[00:29:29.840 --> 00:29:31.320]   I was like, I'm three to the hour.
[00:29:31.320 --> 00:29:32.680]   I was like 20 feet.
[00:29:32.680 --> 00:29:33.680]   I'm just waiting for it.
[00:29:33.680 --> 00:29:35.600]   I guess they decided it's a little box.
[00:29:35.600 --> 00:29:37.000]   It's not very heavy.
[00:29:37.000 --> 00:29:40.800]   And it probably won't hurt anybody if it hits him in the head.
[00:29:40.800 --> 00:29:44.400]   But that was kind of my, I don't know how that's going to work.
[00:29:44.400 --> 00:29:45.800]   The door step, where did it drop?
[00:29:45.800 --> 00:29:46.800]   You can't really land it.
[00:29:46.800 --> 00:29:48.040]   I mean, I understand that you can't really--
[00:29:48.040 --> 00:29:49.040]   Yeah.
[00:29:49.040 --> 00:29:52.400]   You don't want to be trying to land the drone because that's really where the 20 feet, as
[00:29:52.400 --> 00:29:55.000]   you said, you could get ahold of the drone.
[00:29:55.000 --> 00:29:56.840]   I mean, the question is, is it worth it?
[00:29:56.840 --> 00:30:01.320]   Is it worth trying to steal something from a drone that you don't know what's in it?
[00:30:01.320 --> 00:30:02.320]   I think--
[00:30:02.320 --> 00:30:07.840]   You know, that's like, you don't know whether that box is worth it to get you go to jail.
[00:30:07.840 --> 00:30:09.600]   They steal packages all the time.
[00:30:09.600 --> 00:30:12.200]   So it's like, I think one day somebody stole something.
[00:30:12.200 --> 00:30:15.040]   It was just like a bunch of sandbags without the sand in them.
[00:30:15.040 --> 00:30:17.840]   I was like, where did my sandbags go off of my doorstep?
[00:30:17.840 --> 00:30:20.600]   I'm like, they're going to be really disappointed because that's not a good steal.
[00:30:20.600 --> 00:30:26.120]   What I'm amazed by is that nobody has done a show where it's just constantly catching
[00:30:26.120 --> 00:30:30.680]   people using-- like, I'm always surprised that we don't have a show that is like-- and
[00:30:30.680 --> 00:30:31.840]   there's part of me that wants to do it.
[00:30:31.840 --> 00:30:34.000]   My wife has told me I'm not allowed to.
[00:30:34.000 --> 00:30:38.480]   You know, but I really want to do it when we put cameras in it and we do something where
[00:30:38.480 --> 00:30:39.480]   we-- you know, like--
[00:30:39.480 --> 00:30:40.480]   Yeah.
[00:30:40.480 --> 00:30:41.480]   And people like--
[00:30:41.480 --> 00:30:42.480]   Somebody did it once.
[00:30:42.480 --> 00:30:43.480]   But it was right in the edge of the wall.
[00:30:43.480 --> 00:30:44.480]   I'm afraid that also did that, too.
[00:30:44.480 --> 00:30:49.760]   They created a whole Amazon package which had a camera and then it would put out some
[00:30:49.760 --> 00:30:52.400]   fat gas and then it would eject tinsel.
[00:30:52.400 --> 00:30:53.400]   It's on YouTube somewhere.
[00:30:53.400 --> 00:30:56.520]   It is, but it turned out that the person's stealing it wasn't really a-- wasn't really
[00:30:56.520 --> 00:30:57.520]   a perk.
[00:30:57.520 --> 00:30:59.320]   A couple of them were done for just to-- yeah.
[00:30:59.320 --> 00:31:04.200]   Anyway, I think the interesting part about the drones and everything here is that it's
[00:31:04.200 --> 00:31:07.560]   an interesting test of an idea and it comes back to this idea of trialling out the idea
[00:31:07.560 --> 00:31:08.560]   to see what works.
[00:31:08.560 --> 00:31:10.280]   Can you drop a parcel?
[00:31:10.280 --> 00:31:13.120]   I just wish these companies would go and do it without trying to make a media circus
[00:31:13.120 --> 00:31:17.800]   out of it and lean us in a direction of something that's pointless, like, for this.
[00:31:17.800 --> 00:31:22.400]   But what I did see the other day was a hospital that straddled two sides of a motorway and
[00:31:22.400 --> 00:31:27.080]   they were sending the pathology samples from one side to the other using a drone.
[00:31:27.080 --> 00:31:28.080]   So I literally--
[00:31:28.080 --> 00:31:29.720]   What could possibly go wrong?
[00:31:29.720 --> 00:31:32.960]   Well, the point is this is actually working for them because for them to drive between
[00:31:32.960 --> 00:31:34.360]   the two took 45 minutes.
[00:31:34.360 --> 00:31:37.120]   But it takes five minutes for a drone because they don't have to go out.
[00:31:37.120 --> 00:31:40.600]   Well, what caused me to go wrong was taking vials of blood and flying it over the highway.
[00:31:40.600 --> 00:31:41.600]   I mean, I don't know.
[00:31:41.600 --> 00:31:42.600]   Well, good.
[00:31:42.600 --> 00:31:43.600]   What?
[00:31:43.600 --> 00:31:45.600]   But apparently it's made a massive difference because now they're talking about several zombie
[00:31:45.600 --> 00:31:46.600]   movies of phones.
[00:31:46.600 --> 00:31:47.600]   That's a good, honest statement.
[00:31:47.600 --> 00:31:49.320]   Well, you don't want to move.
[00:31:49.320 --> 00:31:51.760]   What are the clearances, though, that you have to go through?
[00:31:51.760 --> 00:31:54.800]   How does the FFA determine who can fly where?
[00:31:54.800 --> 00:31:56.600]   Are they all pretty well?
[00:31:56.600 --> 00:31:57.600]   That's all.
[00:31:57.600 --> 00:32:00.800]   When I see a drone flying, even though I know that they probably can't see me, I still
[00:32:00.800 --> 00:32:02.880]   get a little like, oh, OK, there's a drone.
[00:32:02.880 --> 00:32:03.880]   What is this?
[00:32:03.880 --> 00:32:08.480]   So I just don't understand, like, who's going to say that this is OK and it's not OK.
[00:32:08.480 --> 00:32:11.040]   How am I going to know that's a good drone and not just me out flying?
[00:32:11.040 --> 00:32:12.520]   The FFA stuff is pretty well worked out.
[00:32:12.520 --> 00:32:13.680]   The FFA stuff's worked out.
[00:32:13.680 --> 00:32:17.240]   The medical stuff is as long as the pathologist is willing to sign off on it, so having the
[00:32:17.240 --> 00:32:19.200]   chain of medical custody.
[00:32:19.200 --> 00:32:22.600]   If you can put it, there's not much difference between a drone and a car.
[00:32:22.600 --> 00:32:26.760]   If you can keep your sample, if you can cut the transport time between taking the sample
[00:32:26.760 --> 00:32:30.640]   and getting into the pathology lab from, they were talking about an hour because by the
[00:32:30.640 --> 00:32:35.400]   time they took the sample, got it downstairs, put it in a car, the person drove the car
[00:32:35.400 --> 00:32:40.400]   out of the pathology around the car park onto the motorway, crossed the other side and went
[00:32:40.400 --> 00:32:43.000]   and apparently the drone's doing it in five to 10 minutes.
[00:32:43.000 --> 00:32:44.000]   It's a pre-programmed.
[00:32:44.000 --> 00:32:45.920]   You know, they have no bang suction tubes.
[00:32:45.920 --> 00:32:46.920]   It would be like a minute.
[00:32:46.920 --> 00:32:47.920]   Yeah.
[00:32:47.920 --> 00:32:48.920]   Just be like, you know, like a little thing.
[00:32:48.920 --> 00:32:51.000]   I've got to say, yes, it is.
[00:32:51.000 --> 00:32:52.760]   We reinvented the old suction tubes.
[00:32:52.760 --> 00:32:54.240]   You know, we're seeing a lot more.
[00:32:54.240 --> 00:32:58.160]   All that being said, though, I'm super into the drone delivery, so I'm definitely interested
[00:32:58.160 --> 00:32:59.160]   in it.
[00:32:59.160 --> 00:33:01.960]   Rwanda's actually cutting edge in that area.
[00:33:01.960 --> 00:33:02.960]   I think that they're moving.
[00:33:02.960 --> 00:33:05.320]   They're actually moving points of blood.
[00:33:05.320 --> 00:33:08.120]   You know, they're working with it, but they, I think they're doing a couple different things
[00:33:08.120 --> 00:33:09.120]   there.
[00:33:09.120 --> 00:33:10.120]   And they were difficult.
[00:33:10.120 --> 00:33:12.120]   I brought a drone to Rwanda.
[00:33:12.120 --> 00:33:13.400]   It's been a lot of time and customs.
[00:33:13.400 --> 00:33:17.200]   And so, you know, they weren't so excited about it, but now they're starting to get
[00:33:17.200 --> 00:33:18.760]   it figured out.
[00:33:18.760 --> 00:33:24.960]   And Africa is a good example of a place where it really works because the roadways at night
[00:33:24.960 --> 00:33:29.960]   are dangerous, not because of crime, but because of just drivers, you know, trucks drive
[00:33:29.960 --> 00:33:31.520]   down the middle of the road oftentimes.
[00:33:31.520 --> 00:33:32.880]   There's no streetlights.
[00:33:32.880 --> 00:33:41.560]   And so the, so getting from one rural area to another becomes something that becomes much
[00:33:41.560 --> 00:33:42.560]   more useful.
[00:33:42.560 --> 00:33:43.560]   Yes.
[00:33:43.560 --> 00:33:44.560]   There's so much more.
[00:33:44.560 --> 00:33:49.200]   And it's so much easier too, because there's nothing else in the air, in the air space.
[00:33:49.200 --> 00:33:51.840]   And again, it just comes down to China custody because they have to monitor the temperature
[00:33:51.840 --> 00:33:55.600]   of the parcel in flight to make sure the blood doesn't exceed a certain temperature.
[00:33:55.600 --> 00:33:57.000]   But that's all solvable.
[00:33:57.000 --> 00:33:59.120]   That's not something we can't easily solve.
[00:33:59.120 --> 00:34:00.120]   Right.
[00:34:00.120 --> 00:34:04.440]   And so do we think that this is going to be something that becomes how we get our packages
[00:34:04.440 --> 00:34:05.920]   from Amazon, for instance?
[00:34:05.920 --> 00:34:10.160]   It won't in Europe because everybody lives in highly packed, dense housing.
[00:34:10.160 --> 00:34:12.640]   And there's nowhere for them to land or to drop.
[00:34:12.640 --> 00:34:17.720]   Like my house opens onto the street and my back garden is basically the size of this
[00:34:17.720 --> 00:34:18.720]   table.
[00:34:18.720 --> 00:34:19.720]   Right.
[00:34:19.720 --> 00:34:22.400]   And you drone delivery unless it can land in my back garden exactly.
[00:34:22.400 --> 00:34:24.520]   I'm very, very precisely that it's not going to work.
[00:34:24.520 --> 00:34:27.320]   So it may work in a limited number of circumstances.
[00:34:27.320 --> 00:34:31.840]   This is what I'm saying most of this is pointless because it's only going to work for a certain
[00:34:31.840 --> 00:34:32.840]   small number of years.
[00:34:32.840 --> 00:34:36.480]   But in some ways, in some ways, the places where it works, it is the place that it makes
[00:34:36.480 --> 00:34:40.200]   the most sense because these areas that are you're sending your sending prescriptions
[00:34:40.200 --> 00:34:42.400]   to an area that is difficult to reach.
[00:34:42.400 --> 00:34:44.560]   This is why it shouldn't be a headline article.
[00:34:44.560 --> 00:34:48.800]   It should just be just being done until something provable is there.
[00:34:48.800 --> 00:34:51.880]   But these companies always want to go out with a media storm and get people's attention.
[00:34:51.880 --> 00:34:57.280]   And it's like, how are you going to do drone deliveries to like apartment complex?
[00:34:57.280 --> 00:35:00.320]   And then I know how many Amazon packages I get.
[00:35:00.320 --> 00:35:04.960]   So I would have a whole fleet of drones over my house just dropping every 24 seconds.
[00:35:04.960 --> 00:35:08.960]   So I mean, especially like the airspace like in Los Angeles, I mean, it would just be so
[00:35:08.960 --> 00:35:12.400]   incredibly crowded and then you're going to have to worry about like noise and then what
[00:35:12.400 --> 00:35:14.000]   happens if the drone crashes.
[00:35:14.000 --> 00:35:16.400]   So I don't think it's entirely ready for that.
[00:35:16.400 --> 00:35:19.160]   But in remote areas and things like that, I think it's incredible.
[00:35:19.160 --> 00:35:22.400]   But you're also going to have to deal with like, you know, flight times.
[00:35:22.400 --> 00:35:25.680]   But it's not going to work for sparsely populated.
[00:35:25.680 --> 00:35:27.280]   The drone has to travel so far.
[00:35:27.280 --> 00:35:28.240]   It becomes less cost-
[00:35:28.240 --> 00:35:29.240]   It's figuring something's fault.
[00:35:29.240 --> 00:35:31.360]   It's problems for suburbia, basically.
[00:35:31.360 --> 00:35:36.320]   It's all, I mean, LA is a very good test case for it because LA is essentially one large
[00:35:36.320 --> 00:35:37.320]   suburban area.
[00:35:37.320 --> 00:35:39.560]   Drones can go a long way within a battery.
[00:35:39.560 --> 00:35:40.560]   Yeah.
[00:35:40.560 --> 00:35:41.560]   I mean, it's just a matter.
[00:35:41.560 --> 00:35:42.560]   It's just a weight.
[00:35:42.560 --> 00:35:43.560]   It's a weight process.
[00:35:43.560 --> 00:35:44.560]   Yeah.
[00:35:44.560 --> 00:35:46.960]   You know, we've put drums up for a long time.
[00:35:46.960 --> 00:35:52.600]   So anyway, so it's just, you know, so they can, they can, they can go up, you know, custom
[00:35:52.600 --> 00:35:57.960]   drones can, you can put more battery power into them and, and they, they can go a long
[00:35:57.960 --> 00:35:58.960]   way.
[00:35:58.960 --> 00:36:01.960]   You know, I mean, the, the real restriction for most of that is actually, what?
[00:36:01.960 --> 00:36:06.640]   But then it would be such a bigger drone and that's just, you know, taking up more, more,
[00:36:06.640 --> 00:36:07.640]   that's true.
[00:36:07.640 --> 00:36:10.600]   But it's just more airspace, I feel like, that people might be kind of like, uh, there's
[00:36:10.600 --> 00:36:11.880]   like a drone flying over my house.
[00:36:11.880 --> 00:36:12.880]   It's kind of loud.
[00:36:12.880 --> 00:36:13.880]   Yeah.
[00:36:13.880 --> 00:36:16.760]   I think there's a lot of things that, it's determining factors.
[00:36:16.760 --> 00:36:17.760]   Yeah.
[00:36:17.760 --> 00:36:22.280]   No, I, I think that, I mean, in the people might think that it's louder, but a lot of
[00:36:22.280 --> 00:36:26.480]   that has to do with the construction of the propellers and, you know, and the way the
[00:36:26.480 --> 00:36:27.480]   engines work.
[00:36:27.480 --> 00:36:28.480]   You can definitely make them quiet.
[00:36:28.480 --> 00:36:30.080]   And UPS trucks are not quiet.
[00:36:30.080 --> 00:36:31.080]   Hm?
[00:36:31.080 --> 00:36:32.080]   UPS trucks are not quiet.
[00:36:32.080 --> 00:36:38.720]   I mean, there are the, the amount, especially since, uh, and especially since Amazon has
[00:36:38.720 --> 00:36:45.880]   gone to being their own delivery service, the amount of, uh, delivery traffic in United
[00:36:45.880 --> 00:36:48.040]   States is just insane.
[00:36:48.040 --> 00:36:56.760]   Like the amount of gas wasted delivering packages every day is, is just, it is overwhelming.
[00:36:56.760 --> 00:36:59.280]   Uh, that's only until we move to electric.
[00:36:59.280 --> 00:37:07.440]   Well, if, and in moving to electric, moving to tiny, tiny electric vehicles like drones
[00:37:07.440 --> 00:37:10.360]   is that's, that's a solution.
[00:37:10.360 --> 00:37:13.280]   Yeah, I just wish that Amazon could decide where they're going to leave my package would
[00:37:13.280 --> 00:37:14.280]   be.
[00:37:14.280 --> 00:37:15.280]   Yeah.
[00:37:15.280 --> 00:37:16.280]   I'd be super excited.
[00:37:16.280 --> 00:37:19.760]   Of the, we can have the whole drone thing, but if they could just leave the packages in
[00:37:19.760 --> 00:37:21.960]   one certain place, I have my house.
[00:37:21.960 --> 00:37:23.800]   There's like four different places that I have to check.
[00:37:23.800 --> 00:37:27.560]   You know, I have to go to my iPhone and look and see, okay, they've delivered it somewhere
[00:37:27.560 --> 00:37:30.400]   and now I got to go wander around the house and find it.
[00:37:30.400 --> 00:37:31.400]   Just sign up for the.
[00:37:31.400 --> 00:37:32.400]   The bushes.
[00:37:32.400 --> 00:37:33.400]   Sorry.
[00:37:33.400 --> 00:37:34.400]   What'd you say, Justine?
[00:37:34.400 --> 00:37:36.000]   I said it's in the bushes.
[00:37:36.000 --> 00:37:39.040]   I've found packages there quite often or in my neighbor's house.
[00:37:39.040 --> 00:37:42.200]   I was like, like, you'll send a photo proof of where it is.
[00:37:42.200 --> 00:37:44.960]   I'm like, okay, well now I got to go dig over here for it.
[00:37:44.960 --> 00:37:45.960]   Yeah.
[00:37:45.960 --> 00:37:47.200]   I'm just going to go to the pool that they do at least do that.
[00:37:47.200 --> 00:37:49.400]   So it's, you've got that proof of delivery.
[00:37:49.400 --> 00:37:50.400]   Yeah.
[00:37:50.400 --> 00:37:54.440]   I think that there have been some where they take the picture and then they take the package.
[00:37:54.440 --> 00:37:58.360]   You know, they've had some issues with, you know, like they, you know, they're not very
[00:37:58.360 --> 00:38:00.920]   many isolated issues that made it onto social media.
[00:38:00.920 --> 00:38:05.920]   But I've also gotten very, very close up pictures of the packages, which doesn't help.
[00:38:05.920 --> 00:38:06.920]   Right.
[00:38:06.920 --> 00:38:07.920]   Yes.
[00:38:07.920 --> 00:38:08.920]   There's a package there, but there's a box.
[00:38:08.920 --> 00:38:11.920]   To be honest, when if you're delivering a hundred packages a day, you might get a little
[00:38:11.920 --> 00:38:13.480]   casual about your photography skills.
[00:38:13.480 --> 00:38:17.960]   My whole thing is I'm fine with the package being wherever it's going to be as long as
[00:38:17.960 --> 00:38:19.360]   you decide where that is.
[00:38:19.360 --> 00:38:22.560]   You know, and it doesn't, you know, I feel like I should put signs up that just have
[00:38:22.560 --> 00:38:26.720]   little Amazon arrows, like go here, but then I'm afraid then people would come and take
[00:38:26.720 --> 00:38:27.720]   my packages.
[00:38:27.720 --> 00:38:31.360]   So it's a very complicated situation here with delivery.
[00:38:31.360 --> 00:38:37.400]   Now Google had, you know, they came out with cardboard a couple of years ago, which I think
[00:38:37.400 --> 00:38:38.400]   is brilliant.
[00:38:38.400 --> 00:38:39.400]   I'll just say it right out.
[00:38:39.400 --> 00:38:42.680]   Cardboard, I think, was a brilliant idea.
[00:38:42.680 --> 00:38:43.680]   But it didn't work.
[00:38:43.680 --> 00:38:46.600]   It's like, well, it didn't work that.
[00:38:46.600 --> 00:38:51.840]   And being Google, they've decided to, they dream VR obviously got dropped.
[00:38:51.840 --> 00:38:54.480]   And what happened?
[00:38:54.480 --> 00:38:55.880]   What happened with this?
[00:38:55.880 --> 00:38:58.480]   Did you use, Justine, did you use cardboard much?
[00:38:58.480 --> 00:39:00.520]   I mean, I thought cardboard was cool.
[00:39:00.520 --> 00:39:05.080]   I'm actually working on a series of three videos right now that are 180 videos, and we're
[00:39:05.080 --> 00:39:06.080]   shooting them stereoscopically.
[00:39:06.080 --> 00:39:07.080]   So it'll be 3D.
[00:39:07.080 --> 00:39:10.000]   So if you have a headset, you can watch it, but you could also view it on YouTube.
[00:39:10.000 --> 00:39:13.600]   And one of the interesting things with Google too is they found that a lot of people were
[00:39:13.600 --> 00:39:17.160]   watching YouTube videos with a headset, just regular YouTube videos.
[00:39:17.160 --> 00:39:22.080]   So I feel like creating 180 content, I think is something that I'm looking more into doing
[00:39:22.080 --> 00:39:26.840]   in like, you know, the next year, just because you kind of do have that interactive experience.
[00:39:26.840 --> 00:39:30.680]   But with VR and 360, I personally get motion sickness.
[00:39:30.680 --> 00:39:34.000]   I want to kind of sit and watch content, not like me looking around.
[00:39:34.000 --> 00:39:38.360]   And it's so difficult to even start creating 360 content that's engaging and doesn't make
[00:39:38.360 --> 00:39:39.360]   people sick.
[00:39:39.360 --> 00:39:43.000]   So as far as cardboard and 180 content, like I'm definitely super excited about it.
[00:39:43.000 --> 00:39:45.360]   What are you using for 180 what cameras?
[00:39:45.360 --> 00:39:47.520]   The reason with the Zcams.
[00:39:47.520 --> 00:39:51.960]   And then I also just for myself personally, I use like the Insta360 cameras a lot just
[00:39:51.960 --> 00:39:55.560]   for, you know, little like easy things for social.
[00:39:55.560 --> 00:39:58.760]   But no, I'm pretty excited about it because it looks really good.
[00:39:58.760 --> 00:40:04.440]   And it's just sort of a fun kind of thing, but I'm not a big fan of VR right now.
[00:40:04.440 --> 00:40:06.720]   Like it's just, I feel like it's still too early.
[00:40:06.720 --> 00:40:08.560]   Like the headsets are heavy and big.
[00:40:08.560 --> 00:40:14.840]   But with like the Oculus Quest and the Oculus Go, like that's on the way to what we need.
[00:40:14.840 --> 00:40:19.480]   We need that standalone stuff without having cords connecting to computers and things like
[00:40:19.480 --> 00:40:20.480]   that.
[00:40:20.480 --> 00:40:21.840]   So I'm excited about that.
[00:40:21.840 --> 00:40:26.160]   I think that the challenge with the going smaller is that we're moving by moving away
[00:40:26.160 --> 00:40:29.680]   from the computer, we end up with less power.
[00:40:29.680 --> 00:40:35.880]   And so one of the things that is problematic, I'm working on some VR stuff that has a lot
[00:40:35.880 --> 00:40:37.880]   of polygons.
[00:40:37.880 --> 00:40:39.040]   And so I mean, I just did that.
[00:40:39.040 --> 00:40:44.040]   I have to decimate and decimate is getting rid of the polygons.
[00:40:44.040 --> 00:40:48.160]   The first pass at part of the project I'm working on right now is 343 million polygons.
[00:40:48.160 --> 00:40:50.120]   And I was like, it's not going to work in a headset.
[00:40:50.120 --> 00:40:55.440]   So we're going to figure it all out and get it down to something more manageable.
[00:40:55.440 --> 00:40:57.640]   The problem that I run into is that I want to build it.
[00:40:57.640 --> 00:41:03.280]   There's part of me that just wants to build a for Oculus, the full headset, so that I can
[00:41:03.280 --> 00:41:07.880]   keep my polygon count and my texture resolutions up much higher than what I want to put on
[00:41:07.880 --> 00:41:08.880]   a Quest.
[00:41:08.880 --> 00:41:13.000]   I think that the thing that I found really interesting about the cardboard was less of
[00:41:13.000 --> 00:41:16.600]   a long experience and more of a casual experience.
[00:41:16.600 --> 00:41:21.280]   And I think that their expeditions was a great way to deal with that, which is I mean,
[00:41:21.280 --> 00:41:26.240]   the expeditions was kind of like you're in a classroom, you're going to talk about some
[00:41:26.240 --> 00:41:27.840]   certain location.
[00:41:27.840 --> 00:41:30.680]   And then we're going to throw you into it for a minute.
[00:41:30.680 --> 00:41:34.720]   Not for a long time, but it's something that's casual that you can kind of put up and look
[00:41:34.720 --> 00:41:35.720]   at.
[00:41:35.720 --> 00:41:40.480]   And I always thought that there were a lot of use cases for that process, which I'm glad
[00:41:40.480 --> 00:41:43.680]   that what they've done here, by the way, is that they're open sourcing it.
[00:41:43.680 --> 00:41:47.560]   So they're going to make these APIs make it available so that it's easy for you to still
[00:41:47.560 --> 00:41:51.800]   offer developers to keep on developing these processes and building these out.
[00:41:51.800 --> 00:41:55.560]   Now, there's a lot of, this is, I think that they're mostly just not leaving people who
[00:41:55.560 --> 00:41:59.940]   have already done development out in the cold, which is good because Google's not always
[00:41:59.940 --> 00:42:03.280]   great at that.
[00:42:03.280 --> 00:42:08.440]   It's the problem that Google has is it's hard to get as you start to quit things, because
[00:42:08.440 --> 00:42:09.440]   they're not working.
[00:42:09.440 --> 00:42:12.200]   Well, I think Google's part of the business, it's building up a reputation for being a
[00:42:12.200 --> 00:42:16.800]   quitter in a failure, the more things that they build and fail at, they get their reputation
[00:42:16.800 --> 00:42:22.680]   suffers and they don't seem to care so much because 90% of the revenue comes out of displaying
[00:42:22.680 --> 00:42:23.680]   ads.
[00:42:23.680 --> 00:42:24.680]   So that's one thing.
[00:42:24.680 --> 00:42:27.680]   I think at this particular point in time, my whole sense of VR is that it's got failure
[00:42:27.680 --> 00:42:28.960]   written all over it.
[00:42:28.960 --> 00:42:35.000]   And I suspect the real signal for me is that we've seen so many VR companies go under.
[00:42:35.000 --> 00:42:39.320]   An Oculus really hasn't come back, reached any of the promise.
[00:42:39.320 --> 00:42:43.320]   More important is that Apple's moved completely away from VR and they're going to this augmented
[00:42:43.320 --> 00:42:44.320]   reality.
[00:42:44.320 --> 00:42:50.040]   We've got some topics we might get to later on about AR and whether you can have an
[00:42:50.040 --> 00:42:54.840]   interesting debate around things like the new Apple AirPods Pro as augmented reality
[00:42:54.840 --> 00:42:59.640]   because they're modifying the sound that you hear around you and the Apple Watch is
[00:42:59.640 --> 00:43:02.440]   sort of a version of augmented reality rather than a visual thing.
[00:43:02.440 --> 00:43:07.320]   So I think one of the challenges that people are failing to understand is that VR, virtual
[00:43:07.320 --> 00:43:11.760]   reality is only visual at this point in time, but there's so many other, there's five sensors
[00:43:11.760 --> 00:43:15.400]   that nobody seems to be thinking about the rest of those.
[00:43:15.400 --> 00:43:20.600]   And there's a key technology inflection that has to happen for VR to work, CPU, graphics
[00:43:20.600 --> 00:43:26.600]   processing, power, battery reduction, localized power consumption, that sort of stuff.
[00:43:26.600 --> 00:43:28.920]   And there's no signs that that is on the horizon.
[00:43:28.920 --> 00:43:35.840]   Well, and I think that actually, you know, one of my problems with Oculus in general was
[00:43:35.840 --> 00:43:37.360]   my glasses.
[00:43:37.360 --> 00:43:42.320]   And I felt like, you know, Samsung figured out that if you just put like a little wheel
[00:43:42.320 --> 00:43:46.160]   at the top, you can take my glasses off, I can throw a gear on and I can sit there and
[00:43:46.160 --> 00:43:49.200]   scroll it and get everything into focus, right?
[00:43:49.200 --> 00:43:53.400]   But I can't, you know, I couldn't do that with Oculus and I didn't want to go buy extra
[00:43:53.400 --> 00:43:54.960]   lenses, I didn't want to do anything else.
[00:43:54.960 --> 00:43:57.200]   I just wanted to have my little wheel.
[00:43:57.200 --> 00:44:00.480]   And without that little wheel, I was left with this having to put my glasses under my
[00:44:00.480 --> 00:44:02.120]   glasses get pushed at a certain angle.
[00:44:02.120 --> 00:44:04.960]   So there's this whole process that you put the glasses on.
[00:44:04.960 --> 00:44:08.280]   And now you have to figure out how to turn, you know, like you have to move them inside
[00:44:08.280 --> 00:44:09.800]   in the Oculus to get them.
[00:44:09.800 --> 00:44:12.320]   This is what I mean, the technology is just so immature.
[00:44:12.320 --> 00:44:17.520]   But the worst part was, is that I was like, how many people are, how many people in the
[00:44:17.520 --> 00:44:19.760]   computer business wear glasses?
[00:44:19.760 --> 00:44:21.520]   Well, Sony, Sony figured that out.
[00:44:21.520 --> 00:44:22.520]   At least 50%.
[00:44:22.520 --> 00:44:23.520]   Exactly.
[00:44:23.520 --> 00:44:28.520]   And so many figured that out by, by designing a headset that you could wear with glasses.
[00:44:28.520 --> 00:44:30.480]   Like the Sony Play-Von is, is.
[00:44:30.480 --> 00:44:32.640]   But I think finally, I don't want to.
[00:44:32.640 --> 00:44:42.920]   I think my problem is, is I didn't want to, I didn't want to wear my glasses underneath
[00:44:42.920 --> 00:44:43.920]   it.
[00:44:43.920 --> 00:44:46.880]   I just didn't want to, I just wanted to put it on and just move, move my little scroll.
[00:44:46.880 --> 00:44:50.320]   The problem was I knew that it could be better because I had a Samsung gear.
[00:44:50.320 --> 00:44:54.640]   Because I had that, I was like, you're ruining this for everybody.
[00:44:54.640 --> 00:44:59.360]   That's really hard to develop a system that can correct.
[00:44:59.360 --> 00:45:00.360]   But Samsung did it.
[00:45:00.360 --> 00:45:01.360]   Especially my vision.
[00:45:01.360 --> 00:45:02.360]   I don't put it on my vision.
[00:45:02.360 --> 00:45:06.800]   I'm really, I'm really not interested in a visual reality, a visual virtual reality.
[00:45:06.800 --> 00:45:08.400]   I want to see an audio virtual reality.
[00:45:08.400 --> 00:45:09.720]   I want to see something that's tactile.
[00:45:09.720 --> 00:45:11.760]   I want to see something that's much more immersive.
[00:45:11.760 --> 00:45:15.160]   I don't want something that just lets me watch TV because I don't watch TV.
[00:45:15.160 --> 00:45:18.200]   Well, I think that fundamentally one of the problems that we get into is that, is that
[00:45:18.200 --> 00:45:22.080]   the people who develop this stuff only know that one area.
[00:45:22.080 --> 00:45:25.200]   So they're VR specialists or they're audio specialists or they're video specialists.
[00:45:25.200 --> 00:45:29.440]   And so they think about each one of these things as a silo, as opposed to, I want to
[00:45:29.440 --> 00:45:31.960]   learn and I want a little bit of all of it.
[00:45:31.960 --> 00:45:35.680]   I mean, Justine, do you see that as a, as a, as a limiter for that process?
[00:45:35.680 --> 00:45:38.840]   Now, well, it's interesting because I just got a set of Razer headphones.
[00:45:38.840 --> 00:45:43.220]   So they actually have haptic feedback and they have a chair as well that also has haptic
[00:45:43.220 --> 00:45:44.220]   feedback.
[00:45:44.220 --> 00:45:47.720]   So, you know, when you have this connected to your PC or these headphones specifically
[00:45:47.720 --> 00:45:52.920]   work with Xbox One, you feel like the vibration and then you can feel like if you're playing
[00:45:52.920 --> 00:45:56.440]   a first person shooter, if you're like shot in a specific location, like you can actually
[00:45:56.440 --> 00:45:57.440]   feel that.
[00:45:57.440 --> 00:46:01.200]   So I think that is sort of taking that next step into 4D.
[00:46:01.200 --> 00:46:04.360]   But again, you know, I loved the vibe because the quality of it was great.
[00:46:04.360 --> 00:46:06.440]   But again, you had to be connected to a computer.
[00:46:06.440 --> 00:46:10.520]   So that's why having the quest in the go, like that kind of stuff for me, like I want
[00:46:10.520 --> 00:46:14.840]   to be able to take it with me when I'm traveling and just sort of have that, you know, something
[00:46:14.840 --> 00:46:17.240]   that is easy to use again.
[00:46:17.240 --> 00:46:19.800]   I think that's the barrier to entry for a lot of people.
[00:46:19.800 --> 00:46:20.800]   Yeah.
[00:46:20.800 --> 00:46:24.080]   And I think that the ease of use is a real problem because it is always like a setup.
[00:46:24.080 --> 00:46:29.160]   And even when I get my son has a birthday party coming up and he's going to have Oculus
[00:46:29.160 --> 00:46:31.920]   running and I always think it was like, oh, this is a setup.
[00:46:31.920 --> 00:46:34.880]   No, like I gotta make sure that everything's working.
[00:46:34.880 --> 00:46:38.520]   And it's not, you know, and when it was always just, if I left the computer only running
[00:46:38.520 --> 00:46:41.800]   Oculus, I had a computer for a while, it was just dedicated to Oculus because we were doing
[00:46:41.800 --> 00:46:45.000]   a lot of development for it.
[00:46:45.000 --> 00:46:48.240]   And so it was easy because then you just throw it on and it works.
[00:46:48.240 --> 00:46:50.080]   But if my PC is doing, I mean it's a PC.
[00:46:50.080 --> 00:46:54.560]   So if it's doing anything else, you know, I'm going to have to figure out why it's now
[00:46:54.560 --> 00:46:55.560]   no longer.
[00:46:55.560 --> 00:46:59.160]   What update the biggest problem I had is that I didn't have a strong opinion about PC's.
[00:46:59.160 --> 00:47:00.160]   I mean, I did.
[00:47:00.160 --> 00:47:02.480]   But I have a lot of development.
[00:47:02.480 --> 00:47:06.560]   I have Linux machines and I have PC machines and I have lots of other things that I'm using
[00:47:06.560 --> 00:47:07.560]   them for different things.
[00:47:07.560 --> 00:47:11.160]   I have a PC that I'm doing a lot of photogrammetry on because my Mac is in powerful enough to
[00:47:11.160 --> 00:47:12.160]   do it.
[00:47:12.160 --> 00:47:15.480]   I mean, fundamentally, you know, and so I spent a lot of time there.
[00:47:15.480 --> 00:47:20.200]   But with Oculus, it was like this constant issue of every time there was an update, it
[00:47:20.200 --> 00:47:21.200]   no longer worked.
[00:47:21.200 --> 00:47:22.200]   It's like, oh my gosh.
[00:47:22.200 --> 00:47:23.200]   This is what I mean.
[00:47:23.200 --> 00:47:27.200]   Of course, now we got this with Apple with the last update to the OS.
[00:47:27.200 --> 00:47:29.880]   I haven't even put Catalina on because I'm just kind of like, I don't know what will
[00:47:29.880 --> 00:47:30.880]   break yet.
[00:47:30.880 --> 00:47:32.480]   I'm just going to give them like six months to figure that out.
[00:47:32.480 --> 00:47:33.480]   Yeah, I just.
[00:47:33.480 --> 00:47:36.440]   Yeah, I put it on my other machines, but not my main one because I'm also worried like
[00:47:36.440 --> 00:47:38.160]   is it not going to connect to the server?
[00:47:38.160 --> 00:47:42.640]   But I mean, the augmented reality, I think, is still my favorite.
[00:47:42.640 --> 00:47:46.120]   Like I know when Microsoft was working on HoloLens, like I thought that was going to
[00:47:46.120 --> 00:47:47.320]   be incredible.
[00:47:47.320 --> 00:47:52.240]   And I just, I love still being in my world, but yet, you know, having it, I mean, obviously
[00:47:52.240 --> 00:47:56.440]   augmented, but just having sort of, you know, taken out of that, I think is really great.
[00:47:56.440 --> 00:47:59.840]   So I'm excited to see all the future stuff that Apple is coming out with.
[00:47:59.840 --> 00:48:03.280]   And I mean, I know that there's always been rumors of Apple headsets.
[00:48:03.280 --> 00:48:08.040]   So I feel like when Apple finally does take the plunge and do that or announce it or release
[00:48:08.040 --> 00:48:10.920]   it, then obviously that's again, when it will become.
[00:48:10.920 --> 00:48:12.840]   I think the important is common for the masses.
[00:48:12.840 --> 00:48:13.840]   Yeah.
[00:48:13.840 --> 00:48:20.920]   The stuff I've played with with Magic Leap, their AR system is that is definitely where
[00:48:20.920 --> 00:48:23.440]   it is, where things are going.
[00:48:23.440 --> 00:48:30.720]   It's a it's it's as powerful as as the Oculus buys that you can see through it.
[00:48:30.720 --> 00:48:35.720]   So you can have a mixed VR, a our experience that's much more immersive.
[00:48:35.720 --> 00:48:36.720]   That's cool.
[00:48:36.720 --> 00:48:37.720]   In my opinion.
[00:48:37.720 --> 00:48:42.920]   Yeah, we'll be here in five years and you'll be telling me how great AR and VR, how great
[00:48:42.920 --> 00:48:46.880]   VR is and it'll still be incompetent and the vendors will still be promising everything
[00:48:46.880 --> 00:48:47.880]   and it'll never have.
[00:48:47.880 --> 00:48:48.880]   I think it will.
[00:48:48.880 --> 00:48:49.880]   I promise you.
[00:48:49.880 --> 00:48:55.080]   The issue is is that the issue is neither Facebook or Google or Microsoft is competent
[00:48:55.080 --> 00:48:58.120]   at delivering a product on that sort of complexity successfully.
[00:48:58.120 --> 00:49:02.280]   If you look back over the last 20 years, those companies couldn't even deliver a decent operating
[00:49:02.280 --> 00:49:03.280]   system.
[00:49:03.280 --> 00:49:04.280]   Look at Android, look at Windows.
[00:49:04.280 --> 00:49:05.760]   I think we saw something like for instance for me.
[00:49:05.760 --> 00:49:08.560]   There's no way those companies are ever going to deliver anything that people are actually
[00:49:08.560 --> 00:49:09.560]   going to consume.
[00:49:09.560 --> 00:49:14.800]   For me, I think that Robo Recall was the this could actually this was my moment where this
[00:49:14.800 --> 00:49:15.800]   could actually work.
[00:49:15.800 --> 00:49:17.640]   I was I don't know.
[00:49:17.640 --> 00:49:19.240]   Justin, did you play Robo Recall very much?
[00:49:19.240 --> 00:49:20.240]   I did it.
[00:49:20.240 --> 00:49:21.240]   No.
[00:49:21.240 --> 00:49:22.240]   Oh my gosh.
[00:49:22.240 --> 00:49:26.160]   So for me, for an Oculus, Robo Recall was, oh my gosh, this could actually work.
[00:49:26.160 --> 00:49:31.080]   You could actually turn this into a business because I felt like it was so immersive.
[00:49:31.080 --> 00:49:38.120]   It was fluid, it didn't have the frame rate issues.
[00:49:38.120 --> 00:49:44.240]   As a special effects person had a little bit of aliasing, but in general, it was very good.
[00:49:44.240 --> 00:49:50.640]   I was like, this is really the future, but it's one app.
[00:49:50.640 --> 00:49:53.320]   It's done.
[00:49:53.320 --> 00:50:00.520]   I think that I think a lot of people haven't figured out a way to do that again.
[00:50:00.520 --> 00:50:03.400]   I'm sure there's a bunch of people that are now.
[00:50:03.400 --> 00:50:09.400]   That app pushes the boundaries of what Oculus is capable of.
[00:50:09.400 --> 00:50:13.480]   That's why phone based VR has failed.
[00:50:13.480 --> 00:50:15.800]   It's not powerful enough to do anything more than a gimmick.
[00:50:15.800 --> 00:50:18.120]   Yeah, and I think that it doesn't matter.
[00:50:18.120 --> 00:50:19.560]   Any of this is nothing to do with it.
[00:50:19.560 --> 00:50:23.400]   None of the companies that are doing VR are competent at delivering a consumer grade product
[00:50:23.400 --> 00:50:25.480]   that people can buy.
[00:50:25.480 --> 00:50:30.040]   Google, Facebook, Microsoft, any of the virtual reality companies out there are fundamentally
[00:50:30.040 --> 00:50:32.520]   incompetent rich in the consumer market.
[00:50:32.520 --> 00:50:34.360]   Google is good at making ads.
[00:50:34.360 --> 00:50:36.960]   Microsoft wants to build a public cloud.
[00:50:36.960 --> 00:50:40.760]   Facebook wants to rip people off to display them banner ads with targeted marketing.
[00:50:40.760 --> 00:50:42.200]   None of that is virtual reality.
[00:50:42.200 --> 00:50:43.880]   The HoloLens is pretty cool.
[00:50:43.880 --> 00:50:45.280]   I mean, it's a team with it.
[00:50:45.280 --> 00:50:48.120]   It doesn't matter how cool the technology is.
[00:50:48.120 --> 00:50:49.120]   We have to look at live weather.
[00:50:49.120 --> 00:50:52.800]   The lesson of the last 20 years is it doesn't matter how cool your technology is.
[00:50:52.800 --> 00:50:55.320]   It has to be focused on quality and who the buyer is.
[00:50:55.320 --> 00:50:57.880]   Nothing in the VR market is focused on those things.
[00:50:57.880 --> 00:51:01.400]   And it immediately HoloLens is more of an AR solution than a VR solution.
[00:51:01.400 --> 00:51:02.400]   But it is...
[00:51:02.400 --> 00:51:03.400]   It did try HoloLens a thing.
[00:51:03.400 --> 00:51:06.720]   It was like two or three years ago at E3.
[00:51:06.720 --> 00:51:07.720]   It was pretty awesome.
[00:51:07.720 --> 00:51:10.120]   You went through this amazing demo.
[00:51:10.120 --> 00:51:12.760]   I'm a huge believer and fan of AR.
[00:51:12.760 --> 00:51:14.520]   I think over VR.
[00:51:14.520 --> 00:51:17.200]   So I'm excited to see what the future holds for it.
[00:51:17.200 --> 00:51:21.120]   I think creating an AR is going to be really interesting, especially me as a creator doing
[00:51:21.120 --> 00:51:22.920]   my own things like that.
[00:51:22.920 --> 00:51:24.320]   It's going to be really fun.
[00:51:24.320 --> 00:51:25.320]   Yeah.
[00:51:25.320 --> 00:51:28.400]   The tools, which we'll talk about a little later in the show, the tools are becoming
[00:51:28.400 --> 00:51:31.480]   a lot more fluid to allow you to do that.
[00:51:31.480 --> 00:51:36.960]   And I think that Adobe and Apple and Unreal and Unity are all making it easier for us to
[00:51:36.960 --> 00:51:37.960]   do that.
[00:51:37.960 --> 00:51:41.880]   Now we're going to have to slow us down here because we're about to...
[00:51:41.880 --> 00:51:45.920]   We're going to talk about the FBI and face tracking in a second.
[00:51:45.920 --> 00:51:48.880]   But first, Leo's got a couple words for us.
[00:51:48.880 --> 00:51:51.640]   Hello, just let me interrupt for a second.
[00:51:51.640 --> 00:51:53.800]   I want to talk a little bit about ZipRecruiter.
[00:51:53.800 --> 00:51:54.800]   I am an expert.
[00:51:54.800 --> 00:51:56.600]   We use it at Twit.
[00:51:56.600 --> 00:51:59.400]   We hired one of our most recent interns.
[00:51:59.400 --> 00:52:02.560]   We've hired a number of people through ZipRecruiter.
[00:52:02.560 --> 00:52:05.800]   Hiring is a hard thing to do.
[00:52:05.800 --> 00:52:07.040]   You're down a person.
[00:52:07.040 --> 00:52:09.560]   You need a person.
[00:52:09.560 --> 00:52:13.560]   You're afraid you're going to need a lot of phone calls and you're a lot of mail in
[00:52:13.560 --> 00:52:14.880]   your inbox and all that stuff.
[00:52:14.880 --> 00:52:20.640]   I know pushing that button on posting a job is always a little trepidation involved.
[00:52:20.640 --> 00:52:21.640]   Not with ZipRecruiter.
[00:52:21.640 --> 00:52:26.600]   First of all, when you post once, just once to ZipRecruiter, that post goes to more than
[00:52:26.600 --> 00:52:30.840]   a hundred job boards plus social networks like Twitter and Facebook.
[00:52:30.840 --> 00:52:32.360]   It goes to everywhere.
[00:52:32.360 --> 00:52:35.000]   You're reaching out to the most possible candidates.
[00:52:35.000 --> 00:52:38.240]   Now don't let that scare you because they don't call you.
[00:52:38.240 --> 00:52:39.600]   They don't email you.
[00:52:39.600 --> 00:52:42.360]   Every applicant goes right into the ZipRecruiter interface.
[00:52:42.360 --> 00:52:44.800]   They format it, make it easy to read.
[00:52:44.800 --> 00:52:47.360]   They'll look the same so you can scan them quickly.
[00:52:47.360 --> 00:52:49.240]   They have screening questions.
[00:52:49.240 --> 00:52:50.600]   Yes, no, true, false.
[00:52:50.600 --> 00:52:56.560]   You have an essay question so you can eliminate candidates that don't work very quickly.
[00:52:56.560 --> 00:53:00.200]   They also rank the incoming applicants.
[00:53:00.200 --> 00:53:02.800]   You're never going to miss the best possible candidates.
[00:53:02.800 --> 00:53:04.680]   Don't worry about getting a lot of applications.
[00:53:04.680 --> 00:53:06.600]   That's the whole point.
[00:53:06.600 --> 00:53:10.440]   You want to comb through all of the possibilities to get that perfect person.
[00:53:10.440 --> 00:53:11.600]   It's so important.
[00:53:11.600 --> 00:53:14.040]   They do one other thing that I think is really important.
[00:53:14.040 --> 00:53:18.320]   Actually, maybe you saw the TV ad.
[00:53:18.320 --> 00:53:20.560]   Normally hiring takes a long time.
[00:53:20.560 --> 00:53:21.560]   That's not good.
[00:53:21.560 --> 00:53:23.440]   You need to hire somebody often.
[00:53:23.440 --> 00:53:26.600]   The TV ad had that guy from Cafe Alturo.
[00:53:26.600 --> 00:53:27.600]   Alturo?
[00:53:27.600 --> 00:53:30.640]   Yeah, he's the COO Dylan Miskowitz.
[00:53:30.640 --> 00:53:32.080]   He needed a director of coffee.
[00:53:32.080 --> 00:53:36.540]   He had been advertising the job for some time on other boards but was having trouble finding
[00:53:36.540 --> 00:53:37.680]   qualified applicants.
[00:53:37.680 --> 00:53:41.760]   He switched over to ZipRecruiter and that's when the magic begins.
[00:53:41.760 --> 00:53:44.480]   ZipRecruiter doesn't just depend on candidates finding you.
[00:53:44.480 --> 00:53:48.800]   It actually finds candidates for you.
[00:53:48.800 --> 00:53:52.360]   This technology identifies people with the right experience that invites them to apply
[00:53:52.360 --> 00:53:54.480]   to your job.
[00:53:54.480 --> 00:53:56.760]   That means you get qualified candidates and you get them fast.
[00:53:56.760 --> 00:53:59.160]   Our experience has been really fast.
[00:53:59.160 --> 00:54:00.880]   Dylan posted his job on ZipRecruiter.
[00:54:00.880 --> 00:54:01.880]   He was impressed.
[00:54:01.880 --> 00:54:04.640]   He said how quickly he had great candidate supply.
[00:54:04.640 --> 00:54:10.560]   He used that candidate rating feature that brings the top ones to the top.
[00:54:10.560 --> 00:54:14.440]   He was able to focus on the ones that matched his real tight criteria.
[00:54:14.440 --> 00:54:16.840]   You know what?
[00:54:16.840 --> 00:54:19.640]   Dylan found his new director of coffee in just a few days.
[00:54:19.640 --> 00:54:20.880]   Yeah, sorry.
[00:54:20.880 --> 00:54:21.880]   He's hired him.
[00:54:21.880 --> 00:54:24.240]   I wanted to apply myself.
[00:54:24.240 --> 00:54:28.280]   With results like that, it's no one or four out of five employers who post on ZipRecruiter
[00:54:28.280 --> 00:54:31.240]   get a quality candidate within the first day.
[00:54:31.240 --> 00:54:33.960]   We did within the first hour.
[00:54:33.960 --> 00:54:36.000]   It was mind-boggling.
[00:54:36.000 --> 00:54:39.440]   See why ZipRecruiter is effective for businesses of all sizes.
[00:54:39.440 --> 00:54:41.240]   Try it free right now.
[00:54:41.240 --> 00:54:49.440]   ZipRecruiter.com/twit.
[00:54:49.440 --> 00:54:53.800]   Z-I-P-R-E-C-R-U-I-T-E-R.
[00:54:53.800 --> 00:54:56.000]   ZipRecruiter.com/twit.
[00:54:56.000 --> 00:54:57.000]   ZipRecruiter.
[00:54:57.000 --> 00:54:59.760]   It is easily the smartest way to hire.
[00:54:59.760 --> 00:55:02.040]   You're going to love it.
[00:55:02.040 --> 00:55:04.040]   Now back to Twit.
[00:55:04.040 --> 00:55:07.000]   And so now we're shifting gears just a little bit.
[00:55:07.000 --> 00:55:11.320]   We have a report that the FBI now is tracking.
[00:55:11.320 --> 00:55:16.520]   There are our faces and the ACLU is understandably a little concerned.
[00:55:16.520 --> 00:55:21.960]   And so really this is looking at the overall process of the FBI and probably many other.
[00:55:21.960 --> 00:55:24.600]   I mean, they're focused on the FBI right now.
[00:55:24.600 --> 00:55:32.520]   But it is really looking at, you know, where does this end?
[00:55:32.520 --> 00:55:34.000]   Where is it going?
[00:55:34.000 --> 00:55:35.000]   What are they using it for?
[00:55:35.000 --> 00:55:38.120]   For us now most of this has not been very transparent.
[00:55:38.120 --> 00:55:47.120]   So I guess the question for you is how do we weigh liberty versus security?
[00:55:47.120 --> 00:55:50.480]   I think the challenge here is do we trust our institutions?
[00:55:50.480 --> 00:55:54.720]   So at the end of the day we have to believe that the Secret Services have our best interests
[00:55:54.720 --> 00:55:56.400]   at heart.
[00:55:56.400 --> 00:56:01.680]   And we have historically entrusted, and in the UK we have the same problem with GCHQ
[00:56:01.680 --> 00:56:03.040]   and the government doing the same thing.
[00:56:03.040 --> 00:56:07.520]   There's so many cameras in London and in the high streets it's just like they're just
[00:56:07.520 --> 00:56:09.200]   ubiquitous everywhere.
[00:56:09.200 --> 00:56:12.800]   The question is if we give the government the ability to draw that data together like
[00:56:12.800 --> 00:56:14.640]   Facebook does.
[00:56:14.640 --> 00:56:19.960]   The thing that Facebook does wrong or the thing that Facebook does that is creepy and
[00:56:19.960 --> 00:56:24.160]   non-intuitive is it because it has so much data it can find things that nobody else can.
[00:56:24.160 --> 00:56:26.640]   It's got so much power because of that.
[00:56:26.640 --> 00:56:32.040]   If we allow governments to do this, the potential for misuse or the ability of governments
[00:56:32.040 --> 00:56:37.000]   or whoever is currently in politics to use this to say if I look at these faces I can
[00:56:37.000 --> 00:56:40.920]   say that that person is in that place and therefore they belong to this voter group
[00:56:40.920 --> 00:56:45.000]   so I can target them or I can set up a gerrymander on the basis of it.
[00:56:45.000 --> 00:56:48.400]   The question here isn't whether the FBI is tracking our faces.
[00:56:48.400 --> 00:56:50.680]   The question is do we trust our institutions?
[00:56:50.680 --> 00:56:54.720]   And I think the fact that we don't trust them indicates that society doesn't trust
[00:56:54.720 --> 00:56:59.080]   our Secret Services to work in our best interests.
[00:56:59.080 --> 00:57:04.360]   So whether they're tracking our faces or our emails or capturing all the data on the transatlantic
[00:57:04.360 --> 00:57:09.560]   cables doesn't really matter what the actual process is.
[00:57:09.560 --> 00:57:12.840]   The issue here is do we trust our governments to work in our best interest?
[00:57:12.840 --> 00:57:19.040]   Yeah and I think that the hard part is is that you're weighing the process of...as someone
[00:57:19.040 --> 00:57:26.160]   who works all over the world, the comfort that we live in here is unique.
[00:57:26.160 --> 00:57:30.520]   You know like in some Western countries and so on and so forth but generally Western
[00:57:30.520 --> 00:57:34.920]   countries that have a lot of intelligence we get to live without big walls.
[00:57:34.920 --> 00:57:36.880]   We don't have glass across those walls.
[00:57:36.880 --> 00:57:41.080]   We don't have full-time security at everybody's house and I work in places where that's
[00:57:41.080 --> 00:57:42.080]   the norm.
[00:57:42.080 --> 00:57:43.080]   Yep.
[00:57:43.080 --> 00:57:44.080]   You know that you have...
[00:57:44.080 --> 00:57:47.560]   So I think yeah I've worked in places like Papua New Guinea and Fiji and Kenya and other
[00:57:47.560 --> 00:57:48.560]   places like Brazil.
[00:57:48.560 --> 00:57:54.480]   So everyone lives in compounds because you don't have that security.
[00:57:54.480 --> 00:57:57.080]   And so we have that security.
[00:57:57.080 --> 00:58:04.120]   What our countries as an aggregate, these Western countries that spend a lot of money
[00:58:04.120 --> 00:58:08.480]   on intelligence, a lot of that is happening invisibly for us.
[00:58:08.480 --> 00:58:14.520]   And we just have to be clear that when we stop doing that there's a cost on the other
[00:58:14.520 --> 00:58:15.520]   end of security.
[00:58:15.520 --> 00:58:19.320]   We're that metadata collection and I'm not saying...
[00:58:19.320 --> 00:58:23.920]   I'm very concerned about giving up security for instance on a phone.
[00:58:23.920 --> 00:58:29.120]   I think that a lot of these viruses right now, the one of cries and so on and so forth,
[00:58:29.120 --> 00:58:30.120]   those are...
[00:58:30.120 --> 00:58:31.120]   It's our code.
[00:58:31.120 --> 00:58:32.960]   You know that we couldn't keep secret.
[00:58:32.960 --> 00:58:33.960]   Yes.
[00:58:33.960 --> 00:58:38.000]   So the concern I have is less of distrust for the organizations and more of their ability
[00:58:38.000 --> 00:58:43.000]   to control the data that they have is more of the issue because I think that there are
[00:58:43.000 --> 00:58:45.960]   a lot of good people doing a lot of things that we don't want to think about or know
[00:58:45.960 --> 00:58:49.320]   about that has our country.
[00:58:49.320 --> 00:58:50.320]   And we have to understand...
[00:58:50.320 --> 00:58:51.320]   Well that's...
[00:58:51.320 --> 00:58:53.360]   It's easy for us to say that we want to have...
[00:58:53.360 --> 00:58:55.920]   It's easy for us to say we want to be...
[00:58:55.920 --> 00:59:00.120]   We don't want to have surveillance but we don't even know what that surveillance is
[00:59:00.120 --> 00:59:01.120]   doing.
[00:59:01.120 --> 00:59:03.240]   So you're making a trade off there between social safety.
[00:59:03.240 --> 00:59:07.760]   So that is in general society we have an issue where we trust our neighbor.
[00:59:07.760 --> 00:59:09.760]   We trust the people in our community around us.
[00:59:09.760 --> 00:59:12.320]   We don't have to worry about that.
[00:59:12.320 --> 00:59:17.280]   But in the countries that you know you and I have been to, you and my family with me,
[00:59:17.280 --> 00:59:20.840]   those social trusts or those social boundaries are different and therefore you have to enact
[00:59:20.840 --> 00:59:22.320]   physical defenses.
[00:59:22.320 --> 00:59:26.040]   So that's different from government.
[00:59:26.040 --> 00:59:30.920]   I don't think you can make a draw a line between high level secret services tracking
[00:59:30.920 --> 00:59:35.760]   the entire population to what's happening socially in a small group of people.
[00:59:35.760 --> 00:59:40.160]   But I do agree that there's no trust in certain countries and that's what you end up with.
[00:59:40.160 --> 00:59:44.000]   If you don't trust the society that you live in, if you don't trust each other, you end
[00:59:44.000 --> 00:59:47.840]   up with compounds living behind walls with security guards and that sort of stuff.
[00:59:47.840 --> 00:59:51.640]   Justine are you concerned about face tracking in public?
[00:59:51.640 --> 00:59:55.680]   I mean, that's I feel like a lease of my concerns at this point.
[00:59:55.680 --> 00:59:59.400]   There's just, I feel like the whole privacy issue, like anytime you post anything online
[00:59:59.400 --> 01:00:05.800]   and especially the amount of content that I have posted, I'm voluntarily giving this
[01:00:05.800 --> 01:00:09.400]   information out and I think as I've been doing this longer and longer, I've been posting
[01:00:09.400 --> 01:00:10.720]   less and less.
[01:00:10.720 --> 01:00:17.120]   But just the whole deep fakes thing, there's enough photos and audio clips of me that anyone
[01:00:17.120 --> 01:00:19.000]   can make me say or do whatever I want.
[01:00:19.000 --> 01:00:22.360]   So that for me is kind of concerning.
[01:00:22.360 --> 01:00:28.080]   I think the FBI obviously is, they have way more power than I think that we would ever
[01:00:28.080 --> 01:00:31.040]   imagine and I think if anybody wants to do something like they're going to figure out
[01:00:31.040 --> 01:00:32.840]   a way to do it no matter what.
[01:00:32.840 --> 01:00:38.040]   Whether you're in the FBI, whether you work for a phone company and you're able to access
[01:00:38.040 --> 01:00:41.440]   someone's records and then take their phone number and then be able to change all of their
[01:00:41.440 --> 01:00:42.440]   passwords.
[01:00:42.440 --> 01:00:45.960]   So there are so many things that I think that a lot of people don't even realize that
[01:00:45.960 --> 01:00:50.240]   they're giving up on a daily basis, from going into the grocery stores to shopping,
[01:00:50.240 --> 01:00:53.960]   all of those cameras, everyone is tracking you somehow.
[01:00:53.960 --> 01:00:59.280]   And what's interesting with a lot of the stores now is they are tracking you as a person,
[01:00:59.280 --> 01:01:05.400]   your age, race, gender, your shopping habits, where you go in the supermarket, what you
[01:01:05.400 --> 01:01:08.280]   end up purchasing and no one ever thinks twice about that.
[01:01:08.280 --> 01:01:13.520]   And like, is there a way that we can say that we don't want to do that?
[01:01:13.520 --> 01:01:15.720]   I mean, how do you opt out of something like that?
[01:01:15.720 --> 01:01:22.720]   Well, I have to admit that I used to be very, you know, there was one time in Colorado that
[01:01:22.720 --> 01:01:26.240]   they started, they rolled out and taken your thumbprint when you got your driver's license.
[01:01:26.240 --> 01:01:29.640]   And I was so angry about that that I actually burned my thumbprints off before I went in
[01:01:29.640 --> 01:01:31.160]   to flatten them.
[01:01:31.160 --> 01:01:34.320]   And I was like, I'm not giving them my thumbprint and I bought everything in cash.
[01:01:34.320 --> 01:01:37.040]   And I was very, you know, if I had a tin foil hat, I would have worn it.
[01:01:37.040 --> 01:01:39.320]   You know, I was like, they're not going to get any of my information.
[01:01:39.320 --> 01:01:43.560]   And after doing as much work as I have in a variety of different locations, I just gave
[01:01:43.560 --> 01:01:44.560]   up.
[01:01:44.560 --> 01:01:48.240]   So the key is just to live a boring life and not do anything weird because it's just,
[01:01:48.240 --> 01:01:54.480]   you know, it, you know, there's all this tracking, you know, that happens and it's so,
[01:01:54.480 --> 01:02:00.760]   and this, it's so, you know, what else says, I guess, I am concerned about, you know, and
[01:02:00.760 --> 01:02:05.400]   I'm mostly concerned because we're seeing where that can really go wrong in China, in
[01:02:05.400 --> 01:02:09.480]   my opinion, where they're using it as the social credit and they're paying attention
[01:02:09.480 --> 01:02:14.200]   to an enormous amount of things about people that, and actually controlling their lives
[01:02:14.200 --> 01:02:15.200]   with it.
[01:02:15.200 --> 01:02:18.400]   And so I think that we get into the situation where we can say it's easy for us to say
[01:02:18.400 --> 01:02:20.000]   that our government would never do that.
[01:02:20.000 --> 01:02:21.000]   But do we know?
[01:02:21.000 --> 01:02:24.440]   Well, the flip side of that is to a lesser or greater extent we actually have it here.
[01:02:24.440 --> 01:02:26.000]   It's called a credit score.
[01:02:26.000 --> 01:02:29.960]   And you're actually in the Western world, your credit score defines what you can and
[01:02:29.960 --> 01:02:30.960]   can't do.
[01:02:30.960 --> 01:02:34.080]   You're restricted as to how much you can buy your, you know, what sort of car loan you
[01:02:34.080 --> 01:02:35.080]   can get that type of stuff.
[01:02:35.080 --> 01:02:36.960]   So there's aspects of that in our life.
[01:02:36.960 --> 01:02:37.960]   It's just different.
[01:02:37.960 --> 01:02:38.960]   So sometimes try not to.
[01:02:38.960 --> 01:02:39.960]   The rudimentary.
[01:02:39.960 --> 01:02:40.960]   Yeah.
[01:02:40.960 --> 01:02:42.960]   It's very rudimentary compared to, you know, compared to.
[01:02:42.960 --> 01:02:43.960]   It's also what they said.
[01:02:43.960 --> 01:02:48.640]   The story that we hear through the media is very much, I just want to be concerned here
[01:02:48.640 --> 01:02:52.800]   that the reality on the ground that the day to day of what the Chinese government's doing
[01:02:52.800 --> 01:02:55.480]   for monitoring is about the same as what a credit score is in this country.
[01:02:55.480 --> 01:02:56.480]   So it's not quite.
[01:02:56.480 --> 01:02:57.480]   More aggressive, I think.
[01:02:57.480 --> 01:03:01.360]   But the point I will go back to is the, everything that you've said is at the end of
[01:03:01.360 --> 01:03:04.280]   the day you have to have trust in your institutions.
[01:03:04.280 --> 01:03:09.000]   And this is where Google and Facebook and Amazon are making a mistake is we are losing
[01:03:09.000 --> 01:03:13.520]   our ability to trust them to act in the best interest of us as people.
[01:03:13.520 --> 01:03:20.200]   When they go sharing that data, when they go giving away that information or being creepily
[01:03:20.200 --> 01:03:23.160]   stalking us around the place, what they're actually doing is creating a breach of trust
[01:03:23.160 --> 01:03:26.600]   between you and I and breaching the trust contract that we have.
[01:03:26.600 --> 01:03:28.360]   We have to be able to trust them.
[01:03:28.360 --> 01:03:32.560]   And when they continually breach that contract, we actually end up in a situation where society
[01:03:32.560 --> 01:03:33.640]   begins to break down.
[01:03:33.640 --> 01:03:36.720]   And that's the problem with Facebook and Google is we can't trust them.
[01:03:36.720 --> 01:03:37.720]   Why?
[01:03:37.720 --> 01:03:42.120]   And then going into that knowing that you can't trust them also sets a precedent as well.
[01:03:42.120 --> 01:03:44.520]   So it's like, maybe I won't share as much information.
[01:03:44.520 --> 01:03:48.760]   But at some point, you just kind of realize that this is what it is.
[01:03:48.760 --> 01:03:49.760]   And I think something now-
[01:03:49.760 --> 01:03:52.840]   That's my point is, but the answer is if you go into the situation, not trusting him,
[01:03:52.840 --> 01:03:57.400]   it's like when you go to buy a used car from a guy on the corner of the road and he's going,
[01:03:57.400 --> 01:03:58.640]   oh mate, runs brilliant.
[01:03:58.640 --> 01:04:00.000]   You definitely want to get in this.
[01:04:00.000 --> 01:04:01.000]   It's engines great.
[01:04:01.000 --> 01:04:04.280]   Just got the tires, you know, like, but your hackles are up and you know that this guy's
[01:04:04.280 --> 01:04:07.120]   probably going to try and foist a lemon on you.
[01:04:07.120 --> 01:04:09.920]   And you're in a situation where it's a hostile business transaction.
[01:04:09.920 --> 01:04:13.880]   But when you go to the supermarket to buy milk for your children, you've got to be able
[01:04:13.880 --> 01:04:16.560]   to trust that the milk is clean and safe.
[01:04:16.560 --> 01:04:20.520]   That has been through the cold chain all the way through so that milk comes out is healthy
[01:04:20.520 --> 01:04:21.520]   and fit to eat.
[01:04:21.520 --> 01:04:23.440]   There's a completely different level of trust about that.
[01:04:23.440 --> 01:04:26.960]   That person buying that milk know that they're being tracked now that they've bought the milk.
[01:04:26.960 --> 01:04:30.520]   Now that person is now facial recognition that now they know that they bought that milk
[01:04:30.520 --> 01:04:32.680]   that they also bought the specific type of Cheerios.
[01:04:32.680 --> 01:04:36.320]   So now they're going to be starting to get Facebook ads for that specific type of thing.
[01:04:36.320 --> 01:04:38.240]   And I don't care what anybody says.
[01:04:38.240 --> 01:04:43.040]   Like there is 100% someone is listening somewhere because I will talk about something, me and
[01:04:43.040 --> 01:04:44.280]   a bunch of my friends.
[01:04:44.280 --> 01:04:46.440]   And I will get an ad for that thing.
[01:04:46.440 --> 01:04:48.360]   And it is the most obscure things.
[01:04:48.360 --> 01:04:52.640]   We will even test this out and start talking about the most insane things that you will
[01:04:52.640 --> 01:04:53.640]   think.
[01:04:53.640 --> 01:04:56.200]   And the next day, there's an ad for something related to that.
[01:04:56.200 --> 01:04:57.200]   Instagram.
[01:04:57.200 --> 01:04:59.120]   Instagram retracted down on my wife's phone.
[01:04:59.120 --> 01:05:00.520]   It was Instagram.
[01:05:00.520 --> 01:05:03.720]   As long as she's running Instagram or it's running in the background, that's how they find
[01:05:03.720 --> 01:05:04.720]   it.
[01:05:04.720 --> 01:05:07.880]   It's fascinating but also terrifying at the same time.
[01:05:07.880 --> 01:05:09.320]   But the point is that comes back.
[01:05:09.320 --> 01:05:10.320]   If you...
[01:05:10.320 --> 01:05:11.320]   But beyond beyond beyond...
[01:05:11.320 --> 01:05:15.520]   The secret service is whether it's GCHQ or MI5 or MI6 in the UK or any of the five eyes
[01:05:15.520 --> 01:05:16.520]   countries.
[01:05:16.520 --> 01:05:19.280]   My problem is that I need to trust them.
[01:05:19.280 --> 01:05:22.680]   I can't stop them from collecting secret information and building up databases.
[01:05:22.680 --> 01:05:24.960]   In fact, I want them to for terrorists.
[01:05:24.960 --> 01:05:26.880]   The question is, do you trust them or not?
[01:05:26.880 --> 01:05:27.880]   And that's the problem.
[01:05:27.880 --> 01:05:32.560]   Again, I think my problem is less about do I trust them to gather the information and
[01:05:32.560 --> 01:05:34.080]   to even use it in our best interest.
[01:05:34.080 --> 01:05:37.720]   My concern is their ability to control it.
[01:05:37.720 --> 01:05:38.880]   And because they can't...
[01:05:38.880 --> 01:05:39.880]   We can argue that the...
[01:05:39.880 --> 01:05:45.120]   And for me, the fundamental trust that is broken there, as my kids would refer to the
[01:05:45.120 --> 01:05:54.720]   circle of trust, that is broken there, is that we lost what we could consider some of the
[01:05:54.720 --> 01:06:03.120]   most important between Snowden and the information that was lost, that a lot of our worms and
[01:06:03.120 --> 01:06:05.160]   so on and so forth getting lost.
[01:06:05.160 --> 01:06:09.520]   That's some of the most important information that that agency has and they lost it.
[01:06:09.520 --> 01:06:12.760]   They can't even control that data and our data doesn't matter to them nearly as much
[01:06:12.760 --> 01:06:13.760]   as that data.
[01:06:13.760 --> 01:06:16.920]   So when you have important data that you can't keep control of, it's even what worries me
[01:06:16.920 --> 01:06:17.920]   is that...
[01:06:17.920 --> 01:06:21.800]   The second part of what Snowden talked about is the abuse that data, right?
[01:06:21.800 --> 01:06:22.800]   Exactly.
[01:06:22.800 --> 01:06:26.320]   That data's out there and you have individuals who are unaccountable that are just wandering
[01:06:26.320 --> 01:06:30.360]   around and looking at people in the same way that...
[01:06:30.360 --> 01:06:37.360]   And the problem is that it's less about the agencies for me and more about individual
[01:06:37.360 --> 01:06:40.640]   control and I think that that's where they have to prove it.
[01:06:40.640 --> 01:06:46.120]   And I think that there's parts of the ACL thing that I think are a little bit of hyperbole.
[01:06:46.120 --> 01:06:48.280]   But I think that also...
[01:06:48.280 --> 01:06:51.160]   We probably do need to talk a little bit about how it's being used.
[01:06:51.160 --> 01:06:52.160]   Yeah.
[01:06:52.160 --> 01:06:54.520]   Well, there was part of the lesson from Snowden as we saw them abuse it.
[01:06:54.520 --> 01:06:57.800]   The facial information has been being used for a long time.
[01:06:57.800 --> 01:07:00.480]   We're talking about it right now, but...
[01:07:00.480 --> 01:07:02.720]   Google's been asking you facial information for...
[01:07:02.720 --> 01:07:05.280]   Because of all the photos people have uploaded to Google Photos.
[01:07:05.280 --> 01:07:07.480]   I don't know what the government's been doing this for decades.
[01:07:07.480 --> 01:07:12.200]   Definitely the second part of your statement is what we have to focus on.
[01:07:12.200 --> 01:07:16.200]   I mean, the ACLU is fighting a rear guard action here.
[01:07:16.200 --> 01:07:22.360]   The privacy is something that would be nice if we still had.
[01:07:22.360 --> 01:07:30.760]   That every breach of the NSA, every breach of Equifax, every breach of Target has taught
[01:07:30.760 --> 01:07:37.520]   us that all of our data is up for grabs at all times.
[01:07:37.520 --> 01:07:38.520]   Yeah.
[01:07:38.520 --> 01:07:40.520]   Keep in mind that Russian and China leak data like was needed.
[01:07:40.520 --> 01:07:47.360]   We have to figure out how to live in a privacy-free society at some point.
[01:07:47.360 --> 01:07:52.280]   And then some of the other valid issues that are coming up is that the facial tracking
[01:07:52.280 --> 01:07:54.000]   is much more...
[01:07:54.000 --> 01:07:57.720]   For a variety of reasons, it's much more accurate on lighter skin than darker skin.
[01:07:57.720 --> 01:08:04.040]   So if you have darker skin, it has a lot harder time being accurate.
[01:08:04.040 --> 01:08:05.040]   And so...
[01:08:05.040 --> 01:08:06.040]   That's the algorithms.
[01:08:06.040 --> 01:08:07.800]   That'll be the algorithms.
[01:08:07.800 --> 01:08:11.800]   Initially, the algorithms are being trained on databases that are available and notated
[01:08:11.800 --> 01:08:13.800]   and a lot of them don't include diverse face-to-face...
[01:08:13.800 --> 01:08:16.960]   Well, I think that it's a mixture of algorithms, but I think it's also contrast.
[01:08:16.960 --> 01:08:17.960]   Yeah.
[01:08:17.960 --> 01:08:18.960]   It is contrast.
[01:08:18.960 --> 01:08:19.960]   It is contrast.
[01:08:19.960 --> 01:08:22.960]   The contrast issue is a real issue for the computer because...
[01:08:22.960 --> 01:08:24.960]   Okay, the iPhone 11 has fixed that.
[01:08:24.960 --> 01:08:26.520]   The iPhone 11 has fixed that.
[01:08:26.520 --> 01:08:28.520]   It's going to come up with a really great iPhone.
[01:08:28.520 --> 01:08:29.520]   The security cameras don't do that.
[01:08:29.520 --> 01:08:30.520]   No, they're still cheap.
[01:08:30.520 --> 01:08:31.520]   Not yet.
[01:08:31.520 --> 01:08:32.520]   But yeah, that's all cheap.
[01:08:32.520 --> 01:08:39.160]   Well, that's one reason why I'm glad San Francisco and California and other cities have banned law
[01:08:39.160 --> 01:08:45.960]   enforcement from using facial recognition for three years is that it's not quite...
[01:08:45.960 --> 01:08:46.960]   It's not quite there yet.
[01:08:46.960 --> 01:08:51.680]   It allows society some time to catch up and adapt and people to get comfortable and also
[01:08:51.680 --> 01:08:56.040]   gives the governments themselves time to put in mechanisms so that we can trust them.
[01:08:56.040 --> 01:08:57.040]   Hopefully.
[01:08:57.040 --> 01:08:58.040]   Yeah.
[01:08:58.040 --> 01:09:03.280]   So the Apple Apple on the other end has revamped their privacy site headlines every day.
[01:09:03.280 --> 01:09:05.520]   Apps designed for your privacy.
[01:09:05.520 --> 01:09:08.760]   Justine, is this a winning formula for Apple?
[01:09:08.760 --> 01:09:13.760]   I mean, I think for me to, like, using different email addresses for things is always a high
[01:09:13.760 --> 01:09:14.760]   priority.
[01:09:14.760 --> 01:09:16.760]   Or using the sign in with Apple.
[01:09:16.760 --> 01:09:20.240]   Like, I'm really excited for people to start implementing that because you'll know exactly
[01:09:20.240 --> 01:09:22.960]   where a breach or something has happened.
[01:09:22.960 --> 01:09:23.960]   But they did...
[01:09:23.960 --> 01:09:26.240]   I'm not sure if you guys saw the video that they played.
[01:09:26.240 --> 01:09:27.800]   It was like the new commercial about the privacy.
[01:09:27.800 --> 01:09:28.800]   But it was really...
[01:09:28.800 --> 01:09:31.120]   I mean, I thought it was kind of a touching video.
[01:09:31.120 --> 01:09:35.000]   Just showed how much of your information really is out there.
[01:09:35.000 --> 01:09:39.440]   And I think when you stop and think how much stuff is on your phone, it's shocking.
[01:09:39.440 --> 01:09:43.440]   So I think for Apple to kind of step up and sort of make this move and show how important
[01:09:43.440 --> 01:09:47.680]   this is and really make an entire commercial and video dedicated to it.
[01:09:47.680 --> 01:09:51.160]   I think it's a pretty bubble move.
[01:09:51.160 --> 01:09:53.600]   I sense that this feels like a very slow move.
[01:09:53.600 --> 01:09:54.600]   It's very...
[01:09:54.600 --> 01:09:57.000]   They're not scaring anyone, but we're adding...
[01:09:57.000 --> 01:10:01.120]   They just keep on tightening these little bolts very slowly.
[01:10:01.120 --> 01:10:04.440]   So it's kind of like when you put on a tire and you keep on going around and you just
[01:10:04.440 --> 01:10:07.120]   keep on tightening these bolts very, very slowly.
[01:10:07.120 --> 01:10:08.640]   In a certain way.
[01:10:08.640 --> 01:10:12.640]   But they're not just going, "Okay, we're going to turn the security all the way on."
[01:10:12.640 --> 01:10:15.440]   Because there's a lot of places that they could go.
[01:10:15.440 --> 01:10:17.480]   And I think that...
[01:10:17.480 --> 01:10:21.680]   And I think that they're not tightening it so much that people go crazy.
[01:10:21.680 --> 01:10:24.880]   But when you look at that trajectory, it feels like they could go...
[01:10:24.880 --> 01:10:25.880]   They could tighten this a lot.
[01:10:25.880 --> 01:10:30.480]   For instance, I think that the email is good.
[01:10:30.480 --> 01:10:36.400]   I think basically allowing developers to have an anonymized relationship with their users,
[01:10:36.400 --> 01:10:37.480]   where it's fixed.
[01:10:37.480 --> 01:10:41.040]   I know that I'm talking to that person, a person.
[01:10:41.040 --> 01:10:42.440]   But I don't know who they are.
[01:10:42.440 --> 01:10:46.440]   And that anonymizing of the data is incredibly valuable.
[01:10:46.440 --> 01:10:49.760]   Because you can do a lot of things that people won't trust you to do otherwise.
[01:10:49.760 --> 01:10:50.760]   And I think that that...
[01:10:50.760 --> 01:10:52.960]   And it does seem like they're going to make it harder and harder.
[01:10:52.960 --> 01:10:57.480]   Yeah, as I said, they're kind of boiling a security frog.
[01:10:57.480 --> 01:10:58.640]   This comes back to my point.
[01:10:58.640 --> 01:11:00.480]   People trust Apple to get this right.
[01:11:00.480 --> 01:11:06.480]   So when it comes to this privacy and keeping your data secure and respecting you as an
[01:11:06.480 --> 01:11:11.160]   individual and that sort of stuff, then Apple is building that trust that other institutions
[01:11:11.160 --> 01:11:12.160]   are.
[01:11:12.160 --> 01:11:13.160]   And it's very interesting.
[01:11:13.160 --> 01:11:17.160]   I think if Apple actually ratcheted it up to maximum, like you said, it'd be interesting
[01:11:17.160 --> 01:11:21.280]   to see if they would actually provoke Facebook, Google and others into a reaction.
[01:11:21.280 --> 01:11:26.600]   So if Apple became so private that the secret services weren't able to track people, or
[01:11:26.600 --> 01:11:31.360]   that Facebook started to lose valuable analytics data, or that Google wasn't able to do targeted
[01:11:31.360 --> 01:11:34.160]   advertising, they would provoke a reaction from those institutions.
[01:11:34.160 --> 01:11:37.000]   Well, I think the concern is that it probably reacts from the government.
[01:11:37.000 --> 01:11:38.000]   Like less about the...
[01:11:38.000 --> 01:11:39.000]   No, no, you have to...
[01:11:39.000 --> 01:11:40.000]   You have to provoke Facebook.
[01:11:40.000 --> 01:11:41.000]   But it's not just the government.
[01:11:41.000 --> 01:11:43.920]   You can't just keep blaming the government for everything.
[01:11:43.920 --> 01:11:45.920]   Jesus, Americans have to chop down.
[01:11:45.920 --> 01:11:46.920]   No, no, no, no.
[01:11:46.920 --> 01:11:48.200]   It's business and government, right?
[01:11:48.200 --> 01:11:49.200]   And society.
[01:11:49.200 --> 01:11:50.960]   You have three, you have four states, right?
[01:11:50.960 --> 01:11:55.360]   And you have society, you have the business community, and you have the government.
[01:11:55.360 --> 01:12:01.320]   The organization most trying to stop Apple from going down the security path is the FBI,
[01:12:01.320 --> 01:12:02.320]   not Google or Facebook.
[01:12:02.320 --> 01:12:05.320]   Google and Facebook aren't comfortable with it, but the ones that are talking about it
[01:12:05.320 --> 01:12:09.800]   in Washington all the time, and the ones that are passing laws in Australia are security.
[01:12:09.800 --> 01:12:12.520]   You know, like our government agencies, that's the problem.
[01:12:12.520 --> 01:12:16.040]   But the governments are talking about it in public, but Google and Facebook are making
[01:12:16.040 --> 01:12:20.000]   moves behind the scenes to bypass the privacy that Apple's putting in place constantly.
[01:12:20.000 --> 01:12:21.000]   But that's a whack-a-mole.
[01:12:21.000 --> 01:12:26.760]   But I think the whack-a-mole is also saying that they are going to encrypt WhatsApp end-to-end
[01:12:26.760 --> 01:12:28.760]   and make...
[01:12:28.760 --> 01:12:34.920]   I mean, Zuckerberg is making all sorts of at least statements about how privacy is the
[01:12:34.920 --> 01:12:35.920]   future.
[01:12:35.920 --> 01:12:38.320]   Or you can just see what we're saying there.
[01:12:38.320 --> 01:12:41.480]   I mean, of course, Zuckerberg is going to say that.
[01:12:41.480 --> 01:12:42.480]   Exactly.
[01:12:42.480 --> 01:12:43.480]   It's Facebook.
[01:12:43.480 --> 01:12:44.960]   I was going to say that too.
[01:12:44.960 --> 01:12:45.960]   Yeah.
[01:12:45.960 --> 01:12:49.360]   But I mean, for a lot of normal consumers, people like my parents and my mom, they don't
[01:12:49.360 --> 01:12:50.360]   want to have to be worrying.
[01:12:50.360 --> 01:12:54.920]   Like, I go home and I make sure that I have Face ID, I have all of their things secured
[01:12:54.920 --> 01:12:59.400]   and locked, because that's not something that a normal everyday person is going to be concerned
[01:12:59.400 --> 01:13:00.400]   about, but it is.
[01:13:00.400 --> 01:13:02.040]   Like, what if you lose your phone?
[01:13:02.040 --> 01:13:03.600]   And you didn't have a passcode on?
[01:13:03.600 --> 01:13:04.600]   Like, why not?
[01:13:04.600 --> 01:13:06.240]   Like, those simple things.
[01:13:06.240 --> 01:13:07.920]   Like, everyone should be doing.
[01:13:07.920 --> 01:13:11.680]   And you know, for Apple to kind of make this video that is widely available to like everyone,
[01:13:11.680 --> 01:13:13.000]   I think is a good move.
[01:13:13.000 --> 01:13:17.080]   And it just makes normal everyday consumers a little bit more aware that privacy is a
[01:13:17.080 --> 01:13:18.160]   huge issue.
[01:13:18.160 --> 01:13:20.920]   You have so much information on that phone, be careful.
[01:13:20.920 --> 01:13:23.480]   No, I was talking to my mom.
[01:13:23.480 --> 01:13:24.720]   My mother has a PC.
[01:13:24.720 --> 01:13:26.440]   She's very committed to it.
[01:13:26.440 --> 01:13:30.560]   And she's got all these viruses and then she's got this stuff popping up all the time.
[01:13:30.560 --> 01:13:31.800]   And I'm like, "What are you doing with it?"
[01:13:31.800 --> 01:13:33.400]   "Well, I'm doing email and I'm doing this."
[01:13:33.400 --> 01:13:34.400]   "I'm just getting an iPad."
[01:13:34.400 --> 01:13:36.720]   "This wall will just go away."
[01:13:36.720 --> 01:13:38.320]   You know, like, it's a closed system.
[01:13:38.320 --> 01:13:39.320]   And the same problem with my brother.
[01:13:39.320 --> 01:13:40.320]   He just couldn't cope with it.
[01:13:40.320 --> 01:13:41.320]   I have.
[01:13:41.320 --> 01:13:42.320]   I gave him an iPad and it was all solved.
[01:13:42.320 --> 01:13:43.320]   I have PCs.
[01:13:43.320 --> 01:13:44.320]   I have Linux.
[01:13:44.320 --> 01:13:45.320]   I have Androids.
[01:13:45.320 --> 01:13:47.880]   I have, you know, I have all this stuff and I use them all every day.
[01:13:47.880 --> 01:13:51.120]   But I know what I shouldn't be doing with those things.
[01:13:51.120 --> 01:13:55.320]   You know, and it's kind of like, you know, they're powerful and they're valuable, but
[01:13:55.320 --> 01:13:58.960]   for my mom, you know, like, it's kind of like she just needs an iPad.
[01:13:58.960 --> 01:13:59.960]   You know?
[01:13:59.960 --> 01:14:03.520]   And that comes down to, so for me, same thing.
[01:14:03.520 --> 01:14:06.960]   All of my family uses phones because I know that the privacy and generally the security
[01:14:06.960 --> 01:14:07.960]   is good.
[01:14:07.960 --> 01:14:10.000]   So I come back to my trust point.
[01:14:10.000 --> 01:14:11.200]   I trust Apple to get it mostly.
[01:14:11.200 --> 01:14:13.440]   If you don't use password as the password.
[01:14:13.440 --> 01:14:14.440]   Yeah.
[01:14:14.440 --> 01:14:21.360]   You know, like, and the best advice I got was, you know, I have, you know, my phone is, you
[01:14:21.360 --> 01:14:23.320]   know, get away from the four digit or six digit.
[01:14:23.320 --> 01:14:25.440]   This is our little PSA here for a second.
[01:14:25.440 --> 01:14:29.760]   It's think of a phrase that you remember from your childhood that no one would know and use
[01:14:29.760 --> 01:14:32.160]   that phrase and don't ever say it out loud.
[01:14:32.160 --> 01:14:33.160]   Yeah.
[01:14:33.160 --> 01:14:35.160]   And you might blink up the street.
[01:14:35.160 --> 01:14:36.160]   Or whatever.
[01:14:36.160 --> 01:14:39.000]   But just just it doesn't have to have any special letters.
[01:14:39.000 --> 01:14:40.760]   No, it's just a long phrase.
[01:14:40.760 --> 01:14:43.240]   Like my my phrase is 26.
[01:14:43.240 --> 01:14:44.440]   I'm not going to tell my phrase.
[01:14:44.440 --> 01:14:45.440]   My phrase is.
[01:14:45.440 --> 01:14:46.440]   It's a shushy.
[01:14:46.440 --> 01:14:49.880]   I'm going to say my phrase is right.
[01:14:49.880 --> 01:14:50.880]   Went for the marks.
[01:14:50.880 --> 01:14:52.600]   No one's ever going to guess right.
[01:14:52.600 --> 01:14:54.080]   The market is great, isn't it?
[01:14:54.080 --> 01:14:55.480]   No.
[01:14:55.480 --> 01:14:59.720]   It is, but it's 26 characters long, you know, and it's not the alphabet in case you're wondering.
[01:14:59.720 --> 01:15:01.080]   It just happens to be 26 characters.
[01:15:01.080 --> 01:15:04.760]   The point, the only time I get upset is like my battery goes out and then I know I'm like,
[01:15:04.760 --> 01:15:06.360]   oh my gosh, I have to type this.
[01:15:06.360 --> 01:15:08.280]   You know, like, you know, it's.
[01:15:08.280 --> 01:15:11.680]   But it's a phrase that I'm always going to remember and it's always going to be there.
[01:15:11.680 --> 01:15:14.080]   And no one, it's 26 characters.
[01:15:14.080 --> 01:15:15.080]   No one.
[01:15:15.080 --> 01:15:18.880]   Mine is my favorite one is to use a when I'm creating a password to get into my password
[01:15:18.880 --> 01:15:23.240]   manager is to use a phrase where it is really outrageous.
[01:15:23.240 --> 01:15:27.960]   Something that you could never say out loud because you'd be in instant trouble.
[01:15:27.960 --> 01:15:32.400]   And so when you're sitting there, going to yourself, I use my, the example of riding
[01:15:32.400 --> 01:15:36.720]   my bike up the street, you know, and be tea.
[01:15:36.720 --> 01:15:40.600]   And what you do is you use swear words or really bad words and then you'll never say
[01:15:40.600 --> 01:15:41.600]   it out loud.
[01:15:41.600 --> 01:15:42.600]   Yeah, there we go.
[01:15:42.600 --> 01:15:44.680]   Oh my gosh, you're giving away all the secrets.
[01:15:44.680 --> 01:15:45.680]   Yeah.
[01:15:45.680 --> 01:15:46.680]   Yeah.
[01:15:46.680 --> 01:15:47.680]   But those are the, but that's hard too.
[01:15:47.680 --> 01:15:49.840]   But a lot of these security questions is like, where were you born?
[01:15:49.840 --> 01:15:52.280]   Well, I can Google it and I can figure out where you were born.
[01:15:52.280 --> 01:15:53.360]   What was your mother's maiden name?
[01:15:53.360 --> 01:15:54.720]   Well, everyone knows who my mom is.
[01:15:54.720 --> 01:15:55.720]   So let's look it up.
[01:15:55.720 --> 01:16:00.040]   So these questions are almost too simple that the fact that like I can't actually use any
[01:16:00.040 --> 01:16:03.720]   of those or they ask, or they ask, they ask ones that are harder, but then I can't remember
[01:16:03.720 --> 01:16:05.920]   what they are because I can't remember what I said.
[01:16:05.920 --> 01:16:07.720]   And so they're like, who's your favorite?
[01:16:07.720 --> 01:16:08.720]   This what's your favorite?
[01:16:08.720 --> 01:16:13.840]   You should take those as secondary passwords.
[01:16:13.840 --> 01:16:16.040]   I don't, I don't answer those questions.
[01:16:16.040 --> 01:16:18.680]   I have, I have secondary passwords for those questions.
[01:16:18.680 --> 01:16:21.680]   Well, I mean, you were even talking about, I mean, one of the sponsors of the show was
[01:16:21.680 --> 01:16:22.680]   LastPass.
[01:16:22.680 --> 01:16:25.360]   I've been using LastPass for a long time as well and they've sponsored a bunch of my
[01:16:25.360 --> 01:16:29.800]   videos and it's great because I will store, you know, information in there that I wouldn't
[01:16:29.800 --> 01:16:32.240]   store in like my notepad or anything like that.
[01:16:32.240 --> 01:16:36.240]   And just to have all of those passwords, every single account has a different password.
[01:16:36.240 --> 01:16:38.040]   And it's, it really is.
[01:16:38.040 --> 01:16:39.040]   It's such a process.
[01:16:39.040 --> 01:16:42.760]   And the only issue I have with LastPass is mostly that if it's not on the web, it just
[01:16:42.760 --> 01:16:43.760]   gets more complicated.
[01:16:43.760 --> 01:16:44.760]   I never get to it.
[01:16:44.760 --> 01:16:48.600]   You know, so if it's, so I hate apps, pop up in one of password because I'm just like
[01:16:48.600 --> 01:16:49.600]   getting, it's getting better.
[01:16:49.600 --> 01:16:50.600]   It's getting better.
[01:16:50.600 --> 01:16:53.440]   My favorite one is when it says what's your favorite name and I always use the word
[01:16:53.440 --> 01:16:57.080]   spankalicious, which is, which gives me a little smile.
[01:16:57.080 --> 01:17:01.440]   I have a pet name that is not a pet that I use that is my pet name.
[01:17:01.440 --> 01:17:04.840]   You know, like, you know, like that is a different and different.
[01:17:04.840 --> 01:17:05.840]   Oh, wow.
[01:17:05.840 --> 01:17:06.840]   Yeah.
[01:17:06.840 --> 01:17:09.760]   Well, no, it's like, it's like you have to have, it's not that I have a pet that I actually
[01:17:09.760 --> 01:17:10.760]   use for it.
[01:17:10.760 --> 01:17:12.800]   It's just that I have a generic pet name.
[01:17:12.800 --> 01:17:16.840]   I like to make up just crazy words like snuggle or flunk or grunkle or something and just
[01:17:16.840 --> 01:17:19.440]   type that in there and then record that in my password manager.
[01:17:19.440 --> 01:17:20.440]   You'll never remember.
[01:17:20.440 --> 01:17:23.280]   Yeah, but I've recorded in the password manager and whatever, you know.
[01:17:23.280 --> 01:17:27.720]   So you can go and have a go at cracking my accounts, but my don't bother looking up
[01:17:27.720 --> 01:17:30.320]   my first pet or something like that because it won't help you.
[01:17:30.320 --> 01:17:31.480]   Yeah, yeah, exactly.
[01:17:31.480 --> 01:17:36.040]   So speaking of we're going to continue down the security path here just for one more
[01:17:36.040 --> 01:17:41.080]   passes that we now have and this gets back into the trust of your organization to to
[01:17:41.080 --> 01:17:45.440]   former Twitter employees charged with spying for Saudi Arabia by digging into the accounts
[01:17:45.440 --> 01:17:47.400]   of the kingdom critics.
[01:17:47.400 --> 01:17:50.960]   So so these are two different folks that got brought in and they're basically they worked
[01:17:50.960 --> 01:17:57.240]   for Twitter and then they use their access at Twitter to start figuring out who is complaining
[01:17:57.240 --> 01:17:59.040]   about the about the kingdom.
[01:17:59.040 --> 01:18:01.960]   And this is a you know, obviously this is what we worry about.
[01:18:01.960 --> 01:18:05.640]   Like this gets past past the whole, am I worried that Twitter is doing political ads
[01:18:05.640 --> 01:18:06.640]   or anything else?
[01:18:06.640 --> 01:18:11.400]   It's more of am I worried that an average person of Twitter has access to now and it
[01:18:11.400 --> 01:18:17.280]   matters less to me because for the most part, I don't put anything online that like I would
[01:18:17.280 --> 01:18:20.720]   not use Twitter to have a conversation that was personal.
[01:18:20.720 --> 01:18:24.040]   And if I thought I was going to say something dangerous, I would go through an enormous
[01:18:24.040 --> 01:18:28.000]   number of hoops to put it on Twitter where you have to, you know, you get through three
[01:18:28.000 --> 01:18:31.120]   VPNs and do a whole bunch of things if I thought my life was in danger.
[01:18:31.120 --> 01:18:36.480]   So I don't trust I don't trust Twitter to do that anyway, but people do and they they
[01:18:36.480 --> 01:18:39.560]   are this is an important political tool.
[01:18:39.560 --> 01:18:43.840]   So the challenge here is that when a lot of these tech companies are very immature in
[01:18:43.840 --> 01:18:48.360]   their terms of their data security and they also did very little to validate the people
[01:18:48.360 --> 01:18:54.080]   that worked for them and have various discussions with people in Silicon Valley over time.
[01:18:54.080 --> 01:19:00.120]   And if you worked for any one of the major technology companies, once you're an employee
[01:19:00.120 --> 01:19:03.240]   for a while back there, everybody had access to all the data.
[01:19:03.240 --> 01:19:07.160]   You could see anybody's user and you know, you these stories that we're hearing about
[01:19:07.160 --> 01:19:11.080]   somebody inside the organization was snooping on potential girlfriends or looking for bikini
[01:19:11.080 --> 01:19:12.640]   pictures and that sort of stuff.
[01:19:12.640 --> 01:19:16.080]   That's because these companies didn't have internal data controls.
[01:19:16.080 --> 01:19:19.800]   And if you read between the lines here, these people were actually accessing accounts in
[01:19:19.800 --> 01:19:20.800]   2015.
[01:19:20.800 --> 01:19:25.800]   Now, what the technology companies are now saying and Twitter in this case particularly
[01:19:25.800 --> 01:19:28.920]   and Facebook has now subsequently implemented is data control.
[01:19:28.920 --> 01:19:34.480]   So if you're an employee and you shouldn't be looking at this data, now you can't.
[01:19:34.480 --> 01:19:38.800]   And this is a testament to just how badly organized.
[01:19:38.800 --> 01:19:43.920]   My understanding is is not only can you, if you can, you need to know that someone is
[01:19:43.920 --> 01:19:46.960]   going to call you and ask you why you looked at that account.
[01:19:46.960 --> 01:19:50.040]   Like, at this point, yes, they didn't have any sort of logging tie into some random
[01:19:50.040 --> 01:19:51.040]   person's.
[01:19:51.040 --> 01:19:52.280]   They didn't used to have any sort of logging on what you looked at.
[01:19:52.280 --> 01:19:53.280]   It is.
[01:19:53.280 --> 01:19:54.960]   They didn't check if you had privileges.
[01:19:54.960 --> 01:19:57.920]   If you were just anyone in the system had to look at anything, they could go and look
[01:19:57.920 --> 01:19:58.920]   up.
[01:19:58.920 --> 01:20:02.240]   But at this point, there's a lot in most of these organizations in the last couple of
[01:20:02.240 --> 01:20:04.080]   years, 2019, they expanded.
[01:20:04.080 --> 01:20:06.000]   Incredible, incredible amount of oversight.
[01:20:06.000 --> 01:20:09.960]   And that's what they're complaining and bitching and whining about because that costs the money.
[01:20:09.960 --> 01:20:13.840]   Every time they have to put these data controls in place, it restricts the abilities of the
[01:20:13.840 --> 01:20:18.160]   employees to move fast, to innovate and bring new products to market.
[01:20:18.160 --> 01:20:21.800]   Backups get harder, security controls get harder because when you do a backup, you have
[01:20:21.800 --> 01:20:22.800]   to encrypt the backup.
[01:20:22.800 --> 01:20:25.880]   A lot of their backups weren't even encrypted five years ago.
[01:20:25.880 --> 01:20:31.600]   So I'm a little okay with this in the sense that this was 2015 and Twitter's now gone
[01:20:31.600 --> 01:20:34.080]   on to restrict and apply data controls.
[01:20:34.080 --> 01:20:37.040]   So they've closed the door after the horse has bolted.
[01:20:37.040 --> 01:20:42.640]   But welcome to Silicon Valley where the kids play with their toys and don't care who gets
[01:20:42.640 --> 01:20:43.640]   hurt.
[01:20:43.640 --> 01:20:47.480]   And maybe we'll wait and see if it was done in 2018.
[01:20:47.480 --> 01:20:50.480]   I mean, when we say that, I just want to make sure that we're clear that it's welcome
[01:20:50.480 --> 01:20:51.480]   to every new business.
[01:20:51.480 --> 01:20:56.000]   I mean, whether it was the railroads, whether it was in industry, it was always, you know,
[01:20:56.000 --> 01:20:59.040]   people were moving fast and fast and furious for a couple of decades.
[01:20:59.040 --> 01:21:00.040]   And then it all kind of happened.
[01:21:00.040 --> 01:21:01.040]   Yeah.
[01:21:01.040 --> 01:21:03.440]   But if your whole business is information, those data controls should have been there
[01:21:03.440 --> 01:21:04.440]   from the start.
[01:21:04.440 --> 01:21:08.000]   They should have been introduced way earlier than it's hard to.
[01:21:08.000 --> 01:21:09.840]   When you're trying to figure it out, you don't even know.
[01:21:09.840 --> 01:21:10.840]   They're just kids.
[01:21:10.840 --> 01:21:14.280]   Look at like the people in charge of Google and Twitter and Facebook or just high school
[01:21:14.280 --> 01:21:19.120]   kids that managed to get old without having to take adult responsibilities or fools.
[01:21:19.120 --> 01:21:20.120]   And then what happened?
[01:21:20.120 --> 01:21:22.640]   I don't think they were in high school when they started Twitter.
[01:21:22.640 --> 01:21:25.440]   They sure act like it now.
[01:21:25.440 --> 01:21:27.600]   So, you know, I don't know.
[01:21:27.600 --> 01:21:28.600]   I'm sorry.
[01:21:28.600 --> 01:21:29.760]   We didn't get it right.
[01:21:29.760 --> 01:21:31.120]   We'll try harder tomorrow.
[01:21:31.120 --> 01:21:34.000]   Just like a 15 year old has been caught running between holes.
[01:21:34.000 --> 01:21:35.000]   Because the adults were on PG&E.
[01:21:35.000 --> 01:21:36.000]   See, we're here.
[01:21:36.000 --> 01:21:40.120]   I'm here in Northern California and I had my power turned off for four days because
[01:21:40.120 --> 01:21:44.160]   people didn't make any of the right decisions, both in the government and in the company.
[01:21:44.160 --> 01:21:45.160]   And those were adults.
[01:21:45.160 --> 01:21:48.640]   So, I'm not, so I think that the, that goes around.
[01:21:48.640 --> 01:21:49.640]   What we say, Justine?
[01:21:49.640 --> 01:21:50.640]   No, I just think it's a lot.
[01:21:50.640 --> 01:21:53.920]   It's really crazy because a lot of these things, you know, never, I think in anyone's
[01:21:53.920 --> 01:21:57.200]   bought a stream, would they ever expect that Twitter became what it is today?
[01:21:57.200 --> 01:22:01.080]   So obviously you start building this infrastructure and you're not planning for it.
[01:22:01.080 --> 01:22:02.960]   To be what it is now.
[01:22:02.960 --> 01:22:07.000]   And so I think, you know, the fact that it didn't take them that long, I mean, they probably
[01:22:07.000 --> 01:22:08.500]   should have done that sooner.
[01:22:08.500 --> 01:22:11.640]   But I think it's just hard when you're thrown into something and you're like, what do we
[01:22:11.640 --> 01:22:12.640]   do now?
[01:22:12.640 --> 01:22:16.560]   And for a lot of these startups, it's like, you know, I, I, there was a great interview.
[01:22:16.560 --> 01:22:19.920]   Now I can't think of what there was a, there's a podcast or something where they're inter,
[01:22:19.920 --> 01:22:24.320]   and I can, it might be NPR or something, but the interview entrepreneurs, you know, so
[01:22:24.320 --> 01:22:28.520]   they've entered and they were interviewing the, the guys that started Instagram.
[01:22:28.520 --> 01:22:32.320]   And they were just saying, you know, it was kind of like, well, things weren't working.
[01:22:32.320 --> 01:22:35.640]   And, and then we threw together this little thing on a server and then the server was
[01:22:35.640 --> 01:22:36.760]   so popular at craft.
[01:22:36.760 --> 01:22:42.520]   And then, and the problem is, is that once you have something that, that in a startup,
[01:22:42.520 --> 01:22:47.360]   once you have something that takes off, there is a, you're now trying to, you're no longer
[01:22:47.360 --> 01:22:49.400]   fixing a stationary train.
[01:22:49.400 --> 01:22:52.960]   You are fixing a train that is going faster than you even know how to steer it.
[01:22:52.960 --> 01:22:53.960]   Yeah.
[01:22:53.960 --> 01:22:57.040]   And so, but, but we have to, but it's easy for us to say when we don't do it, but the problem
[01:22:57.040 --> 01:23:00.920]   is is that when you're doing it, you're in the middle of it's moving really fast and
[01:23:00.920 --> 01:23:03.080]   you have to figure out how to do it without stopping it.
[01:23:03.080 --> 01:23:05.520]   Yeah, but they got billions of dollars.
[01:23:05.520 --> 01:23:10.000]   These kids got billions of dollars in profits and they didn't do anything.
[01:23:10.000 --> 01:23:11.000]   But not initially.
[01:23:11.000 --> 01:23:12.000]   They never did.
[01:23:12.000 --> 01:23:13.000]   Yes, they did.
[01:23:13.000 --> 01:23:17.600]   In 2015, Twitter was rolling in cash and they did nothing.
[01:23:17.600 --> 01:23:21.000]   All they did was trouser all that money and congratulated themselves without clever
[01:23:21.000 --> 01:23:24.400]   they were, but without doing any of the disciplined hard work that you need to do.
[01:23:24.400 --> 01:23:26.760]   And Twitter, it will be hard for you to know that.
[01:23:26.760 --> 01:23:29.400]   Because there's a lot of work that gets done in a lot of these companies where there's
[01:23:29.400 --> 01:23:30.720]   a lot of concern about this stuff.
[01:23:30.720 --> 01:23:34.760]   There's a lot of, you know, it's not that it's easy to say from the outside, oh, well,
[01:23:34.760 --> 01:23:36.880]   they're not doing anything, but they're all working on it.
[01:23:36.880 --> 01:23:41.960]   And they have been all working on it for a long time, you know, and, and I, badly, you
[01:23:41.960 --> 01:23:42.960]   can't keep accusing.
[01:23:42.960 --> 01:23:46.240]   It's just, I'm not, it's a, you've got to stop making excuses.
[01:23:46.240 --> 01:23:51.840]   A lot of these problems are problems that you, you have no idea you're going to face
[01:23:51.840 --> 01:23:53.440]   until you've faced them.
[01:23:53.440 --> 01:23:57.080]   No, it was entirely predictable, entirely predictable.
[01:23:57.080 --> 01:24:03.000]   If your data is not in secured and segmented and need to know this is going to happen,
[01:24:03.000 --> 01:24:07.080]   entirely predictable, the executive team in charge of all of these companies, Facebook,
[01:24:07.080 --> 01:24:10.960]   Google, Twitter, failed to implement perfectly reasonable controls.
[01:24:10.960 --> 01:24:12.440]   There's no one predicted that.
[01:24:12.440 --> 01:24:14.000]   I think that's a really nice sign.
[01:24:14.000 --> 01:24:15.000]   Everybody predicted that.
[01:24:15.000 --> 01:24:18.000]   We've been saying it in the IT industry for 10 years.
[01:24:18.000 --> 01:24:25.080]   Just, just the fact that, that there is information on Twitter valuable enough for governments
[01:24:25.080 --> 01:24:30.840]   to have spies to look at is, is, is, I said this on this show two years ago, Karsten,
[01:24:30.840 --> 01:24:34.160]   when I was here, I said the problem with these companies is that internally they have zero
[01:24:34.160 --> 01:24:35.640]   internal controls.
[01:24:35.640 --> 01:24:40.360]   They are not validating or doing any background checks on the employees that work for them.
[01:24:40.360 --> 01:24:43.840]   And once you're inside the company with a badge, you get full access to all the data.
[01:24:43.840 --> 01:24:44.840]   This was entirely predictable.
[01:24:44.840 --> 01:24:47.960]   But the problem is, is we have data breaches from people who have spent all their time
[01:24:47.960 --> 01:24:48.960]   doing this.
[01:24:48.960 --> 01:24:53.760]   The question is, is whether it's going to, we would think that our credit scores, you
[01:24:53.760 --> 01:24:57.320]   know, companies that manage our credit scores would have some control over the data.
[01:24:57.320 --> 01:25:00.200]   They have adults, they're probably working there, but they still can't keep control
[01:25:00.200 --> 01:25:01.200]   of it.
[01:25:01.200 --> 01:25:05.360]   So the thing is, is that the issue is, is that assuming that they'd be able to actually
[01:25:05.360 --> 01:25:12.800]   fix this, is, is I think, it would be difficult, you know, in that area.
[01:25:12.800 --> 01:25:22.760]   And again, I, what I will say is, is that the, the data control, you know, they are, I've
[01:25:22.760 --> 01:25:27.200]   been in a situation where I, you know, I've, I've built up online forums, I've built up
[01:25:27.200 --> 01:25:28.580]   all those things.
[01:25:28.580 --> 01:25:34.960]   And the level of work when you're getting, especially when you're getting started, the,
[01:25:34.960 --> 01:25:38.640]   you are, yes, you can't fix everything.
[01:25:38.640 --> 01:25:40.800]   And then the problem is you have a whole bunch of code.
[01:25:40.800 --> 01:25:41.800]   You have it.
[01:25:41.800 --> 01:25:44.480]   And you understand what you're saying, but you also didn't have billions of dollars in
[01:25:44.480 --> 01:25:46.160]   profits coming through the door every year.
[01:25:46.160 --> 01:25:48.600]   But that didn't happen until all that code was already written.
[01:25:48.600 --> 01:25:49.600]   This is in 2015.
[01:25:49.600 --> 01:25:52.200]   They should have been implementing this since 2000.
[01:25:52.200 --> 01:25:57.240]   11 years, 11 years since they started, 11 years of code of millions of lines a year.
[01:25:57.240 --> 01:25:58.240]   Doesn't matter.
[01:25:58.240 --> 01:26:01.840]   They had the money, they had the capabilities people were telling them it's a problem.
[01:26:01.840 --> 01:26:05.960]   I've been doing enterprise IT infrastructure and working inside of people's organizations
[01:26:05.960 --> 01:26:06.960]   for 30 years.
[01:26:06.960 --> 01:26:07.960]   There's a bunch of social networks.
[01:26:07.960 --> 01:26:11.000]   There was a bunch of social networks that thought that that was important.
[01:26:11.000 --> 01:26:12.000]   And you know what happened?
[01:26:12.000 --> 01:26:13.800]   They didn't succeed because they moved too slowly.
[01:26:13.800 --> 01:26:17.560]   And so the thing is, is that the problem is, is that these ones got bigger because they
[01:26:17.560 --> 01:26:20.680]   moved fast enough to stay in front of the wave and set it behind it.
[01:26:20.680 --> 01:26:23.520]   Now the cost is now that they have to go back and try to tie it all in.
[01:26:23.520 --> 01:26:24.760]   So don't excuse them for being incompetent.
[01:26:24.760 --> 01:26:27.440]   They chose to be incompetent to put their users in risk.
[01:26:27.440 --> 01:26:28.720]   I wouldn't say they chose to be incompetent.
[01:26:28.720 --> 01:26:30.320]   I think they chose to move fast.
[01:26:30.320 --> 01:26:31.320]   You know, and I think-
[01:26:31.320 --> 01:26:33.680]   I think if they could have made this an issue and fix it at the beginning, like they would
[01:26:33.680 --> 01:26:34.680]   have.
[01:26:34.680 --> 01:26:37.960]   I mean, I'm just saying from the beginning, like I was on Twitter in 2006, it was not what
[01:26:37.960 --> 01:26:38.960]   it is now.
[01:26:38.960 --> 01:26:41.080]   I was a 103rd person to join Instagram.
[01:26:41.080 --> 01:26:45.120]   I was even on bourbon, which was like the thing that was before Instagram.
[01:26:45.120 --> 01:26:49.280]   And no one ever initially at these times ever expected it to be what it is.
[01:26:49.280 --> 01:26:53.240]   I'm not disregarding what you're saying that yes, these things need to be implemented.
[01:26:53.240 --> 01:26:56.800]   And I think now knowing this going forward, people starting companies and starting these
[01:26:56.800 --> 01:26:58.680]   types of apps with these things in mind.
[01:26:58.680 --> 01:27:01.480]   Yes, it should 100% be implemented from the beginning.
[01:27:01.480 --> 01:27:04.680]   But I just think initially this was such a whole new thing that we were doing.
[01:27:04.680 --> 01:27:06.200]   I'm not saying it should have been implemented from the beginning.
[01:27:06.200 --> 01:27:08.880]   I'm saying by 2015, this should have been well under control.
[01:27:08.880 --> 01:27:14.480]   It's just when you have at that point hundreds of millions of lines of code written by a
[01:27:14.480 --> 01:27:20.000]   lot of different people pulling that out is like grabbing on.
[01:27:20.000 --> 01:27:28.800]   And it's not written by, it's not written by guys that are trying to build in a structure.
[01:27:28.800 --> 01:27:30.000]   They're trying to fix something today.
[01:27:30.000 --> 01:27:32.360]   And so there's not a lot of commenting.
[01:27:32.360 --> 01:27:34.240]   There's not a lot of process.
[01:27:34.240 --> 01:27:38.160]   So when we say that it's always should just go back in there and fix it, it's the same
[01:27:38.160 --> 01:27:42.840]   problem with, I'm just going to go back to it because it's very near and dear to my
[01:27:42.840 --> 01:27:48.200]   heart given the fact that I lost power for four days because these idiots didn't put
[01:27:48.200 --> 01:27:49.280]   the power under the ground.
[01:27:49.280 --> 01:27:54.400]   Well, it cost them, they saved half a million dollars a mile to not put it under ground
[01:27:54.400 --> 01:27:55.920]   over the last 30 years.
[01:27:55.920 --> 01:28:00.040]   And now they could have for the amount that's going to cost them that mistake.
[01:28:00.040 --> 01:28:03.360]   They could have put it under 60,000 out of the 82,000 miles.
[01:28:03.360 --> 01:28:07.480]   And so the thing is, and again, when we talk about these kids and they're being irresponsible,
[01:28:07.480 --> 01:28:08.480]   this is a big company.
[01:28:08.480 --> 01:28:09.480]   This is of old people.
[01:28:09.480 --> 01:28:10.480]   I've worked for the government.
[01:28:10.480 --> 01:28:11.480]   And it's managed by the government.
[01:28:11.480 --> 01:28:12.480]   I've worked for the government departments.
[01:28:12.480 --> 01:28:13.480]   I've worked for the law.
[01:28:13.480 --> 01:28:15.480]   All these companies make mistakes.
[01:28:15.480 --> 01:28:17.480]   I've worked for the government law departments.
[01:28:17.480 --> 01:28:19.120]   I've worked for universities.
[01:28:19.120 --> 01:28:20.680]   I've worked for banking institutions.
[01:28:20.680 --> 01:28:22.800]   I've worked for online gaming companies.
[01:28:22.800 --> 01:28:25.920]   And I've worked for them when they're nascent and I've worked for them when they're mature.
[01:28:25.920 --> 01:28:30.320]   And there's a certain point at your cycle where you take data security seriously, neither
[01:28:30.320 --> 01:28:35.360]   Facebook, neither Google, neither Twitter took this seriously until far too late in the
[01:28:35.360 --> 01:28:36.360]   cycle.
[01:28:36.360 --> 01:28:38.120]   And they got behind on it.
[01:28:38.120 --> 01:28:40.880]   And the thing is, is there they are closing up.
[01:28:40.880 --> 01:28:41.880]   That's fine.
[01:28:41.880 --> 01:28:43.160]   I have no problem with the being behind.
[01:28:43.160 --> 01:28:44.760]   Let's just not make excuses for them.
[01:28:44.760 --> 01:28:47.600]   No, I'm just saying that we have to be real about how to work.
[01:28:47.600 --> 01:28:48.600]   They are confident.
[01:28:48.600 --> 01:28:49.600]   They made a mistake.
[01:28:49.600 --> 01:28:51.240]   They may be fixed it by now.
[01:28:51.240 --> 01:28:54.560]   But don't give them a pass and say, oh, you guys made lots of money.
[01:28:54.560 --> 01:28:56.600]   I'm not giving anybody a pass.
[01:28:56.600 --> 01:29:00.200]   I'm just saying that everybody blows it.
[01:29:00.200 --> 01:29:01.200]   I work with all.
[01:29:01.200 --> 01:29:02.200]   I work.
[01:29:02.200 --> 01:29:05.800]   And in full disclosure, I have worked with all of these companies.
[01:29:05.800 --> 01:29:10.800]   You know, and the thing is, is that in the end of it when you realize it, when you get
[01:29:10.800 --> 01:29:14.200]   into the middle of all of these things, whether it's governments or corporations or small
[01:29:14.200 --> 01:29:17.960]   companies or whatever, you realize that nobody really knows what they're doing.
[01:29:17.960 --> 01:29:20.400]   They're all just trying to figure it out.
[01:29:20.400 --> 01:29:23.920]   And some of them are making better decisions than others.
[01:29:23.920 --> 01:29:27.040]   And there's good decisions and bad decisions.
[01:29:27.040 --> 01:29:35.320]   But as far as we're going down the Twitter route, and yet again, it is time for Leo to
[01:29:35.320 --> 01:29:38.280]   share some kind words with us.
[01:29:38.280 --> 01:29:42.560]   This week at Tech brought to you this week by Wasabi Hot Cloud Storage.
[01:29:42.560 --> 01:29:45.520]   My buddies, Jeff Flowers and David Friend.
[01:29:45.520 --> 01:29:51.440]   They were a carbonite when they patented a process for writing to hard drives sequentially
[01:29:51.440 --> 01:29:53.920]   as opposed to in blocks.
[01:29:53.920 --> 01:29:55.920]   That made a big difference.
[01:29:55.920 --> 01:29:58.360]   In fact, it's why Wasabi, which is their new startup.
[01:29:58.360 --> 01:30:04.440]   It's enterprise class cloud storage, hot cloud storage, is 80% cheaper and six times
[01:30:04.440 --> 01:30:06.080]   faster than S3.
[01:30:06.080 --> 01:30:07.600]   It's this patented technology.
[01:30:07.600 --> 01:30:08.600]   Only they have it.
[01:30:08.600 --> 01:30:10.200]   It also is more durable.
[01:30:10.200 --> 01:30:12.220]   11 nines of durability.
[01:30:12.220 --> 01:30:13.920]   That's as high as you can get.
[01:30:13.920 --> 01:30:17.920]   9 9 9 11 nines of durability.
[01:30:17.920 --> 01:30:21.840]   They do something else I think is so cool, especially in this day and age of ransomware.
[01:30:21.840 --> 01:30:24.640]   You can designate some of or all of your storage as immutable.
[01:30:24.640 --> 01:30:25.880]   It can't be changed.
[01:30:25.880 --> 01:30:29.120]   Not by ransomware, not by fumble fingered employees.
[01:30:29.120 --> 01:30:30.760]   That's awesome.
[01:30:30.760 --> 01:30:32.220]   Redundant data centers too.
[01:30:32.220 --> 01:30:34.320]   Your data is never at risk.
[01:30:34.320 --> 01:30:39.960]   They do regular integrity checks to make sure your data has not been modified in any way.
[01:30:39.960 --> 01:30:42.960]   It's the best way to put your data in the cloud.
[01:30:42.960 --> 01:30:43.960]   Everybody's doing it.
[01:30:43.960 --> 01:30:46.040]   They're all moving to the cloud.
[01:30:46.040 --> 01:30:47.960]   But you don't have to do what everybody else is doing.
[01:30:47.960 --> 01:30:50.080]   You don't have to follow the herd.
[01:30:50.080 --> 01:30:54.400]   I know Google, Microsoft, Amazon, everybody follows the herd.
[01:30:54.400 --> 01:30:56.240]   You don't have to.
[01:30:56.240 --> 01:30:57.240]   You don't have to.
[01:30:57.240 --> 01:31:00.200]   You can save money, get better performance.
[01:31:00.200 --> 01:31:03.540]   You don't have to tell them your secret is wasabi.
[01:31:03.540 --> 01:31:08.700]   By the way, just as secure and I would say in most cases more secure than on-premises
[01:31:08.700 --> 01:31:13.460]   storage, it's HIPAA compliant, it's FINRA compliant, it's CJIS compliant.
[01:31:13.460 --> 01:31:18.860]   Look, just all you got to do is tell the boss, "Okay, I know you want the big three, but
[01:31:18.860 --> 01:31:24.260]   let me just tell you, I found one that's 80% cheaper and up to six times faster than
[01:31:24.260 --> 01:31:25.460]   the better known brands.
[01:31:25.460 --> 01:31:27.420]   It's wasabi."
[01:31:27.420 --> 01:31:31.080]   Calculate the savings for yourself and start a free trial.
[01:31:31.080 --> 01:31:34.400]   Unlimited storage for a month so you can really bang on it.
[01:31:34.400 --> 01:31:39.560]   Go to wasabi.com, W-A-S-A-B-I.com.
[01:31:39.560 --> 01:31:42.600]   Click the free trial link, put the code in Twit and then you'll get unlimited free storage
[01:31:42.600 --> 01:31:44.480]   for a month.
[01:31:44.480 --> 01:31:49.000]   Join the movement and migrate your data to the cloud with confidence wasabi.com.
[01:31:49.000 --> 01:31:51.440]   You got to use the offer code to it.
[01:31:51.440 --> 01:31:53.960]   We thank wasabi so much for their support.
[01:31:53.960 --> 01:31:56.520]   Now back to you.
[01:31:56.520 --> 01:31:58.420]   I have an important question for you.
[01:31:58.420 --> 01:31:59.420]   Yes.
[01:31:59.420 --> 01:32:00.420]   How do you like the new place?
[01:32:00.420 --> 01:32:01.420]   Facebook logo.
[01:32:01.420 --> 01:32:04.860]   Oh, gosh.
[01:32:04.860 --> 01:32:05.860]   It's fine.
[01:32:05.860 --> 01:32:06.860]   I mean, like, whatever.
[01:32:06.860 --> 01:32:11.460]   I think at this point, I mean, it was kind of just a weird move that they're just like,
[01:32:11.460 --> 01:32:12.460]   "All right, see what we're doing."
[01:32:12.460 --> 01:32:16.100]   Isn't this basically like the alphabet, the kind of the alphabet Google thing is that
[01:32:16.100 --> 01:32:17.100]   you're trying to--
[01:32:17.100 --> 01:32:21.860]   It's just extremely simple, but I mean, I think making all of their products kind of
[01:32:21.860 --> 01:32:23.700]   look the same, I get it.
[01:32:23.700 --> 01:32:28.080]   But the one thing that I never liked about Facebook is how many times am I going to have
[01:32:28.080 --> 01:32:31.720]   to download another app to do the same exact thing when I could just do it all in one app?
[01:32:31.720 --> 01:32:32.880]   I need the messages app.
[01:32:32.880 --> 01:32:37.600]   I need like the app to control my actual profile page.
[01:32:37.600 --> 01:32:41.840]   So I think just integrating everything into one app would be amazing.
[01:32:41.840 --> 01:32:43.680]   But the logo is fine.
[01:32:43.680 --> 01:32:45.960]   Like if that's what you decided to go with.
[01:32:45.960 --> 01:32:50.120]   I think that they should have called it the Facebook.
[01:32:50.120 --> 01:32:54.780]   You're going to go all the caps.
[01:32:54.780 --> 01:32:56.260]   You might as well go all the way.
[01:32:56.260 --> 01:32:58.600]   But I mean, like go back to their beginning.
[01:32:58.600 --> 01:33:03.060]   So the big holding company is the Facebook, and then you have Facebook.
[01:33:03.060 --> 01:33:05.460]   See, I just think that would be perfect.
[01:33:05.460 --> 01:33:06.460]   Yeah.
[01:33:06.460 --> 01:33:12.380]   But it is-- I have to admit that I like the different apps because, for instance, I don't
[01:33:12.380 --> 01:33:15.340]   necessarily want to go on Facebook all the time, but I have a lot of friends that are
[01:33:15.340 --> 01:33:16.340]   a messenger.
[01:33:16.340 --> 01:33:17.940]   And so there's a lot of back and forth.
[01:33:17.940 --> 01:33:22.260]   And so I don't really want messenger-- when they split messenger out, I was like, I cannot
[01:33:22.260 --> 01:33:24.160]   believe they're doing that.
[01:33:24.160 --> 01:33:27.160]   But now I'm totally like I'm really glad that I don't have to.
[01:33:27.160 --> 01:33:36.120]   Because I think for me, a lot of times Facebook, I feel a little-- I feel that Facebook's a
[01:33:36.120 --> 01:33:37.120]   little heavy.
[01:33:37.120 --> 01:33:40.320]   You get lost in doing something else instead of just making steady messages.
[01:33:40.320 --> 01:33:41.680]   They're just talking to somebody, right?
[01:33:41.680 --> 01:33:42.680]   Yeah.
[01:33:42.680 --> 01:33:43.680]   It's interesting.
[01:33:43.680 --> 01:33:47.680]   I was listening to a professor of marketing, Professor Galloway, who's quite well known
[01:33:47.680 --> 01:33:49.280]   in the podcasting community.
[01:33:49.280 --> 01:33:55.200]   And he points out that the whole idea of Instagram by Facebook and WeChat by Facebook--
[01:33:55.200 --> 01:33:57.360]   not WeChat-- what's the messenger called?
[01:33:57.360 --> 01:33:58.360]   What's that?
[01:33:58.360 --> 01:33:59.360]   What's that?
[01:33:59.360 --> 01:34:03.680]   By Facebook and Facebook by Facebook is really an interesting branding decision.
[01:34:03.680 --> 01:34:07.720]   And his point was with it, is how quickly can you destroy your company?
[01:34:07.720 --> 01:34:13.640]   Because the company that sits behind BMW cars also makes mini cars.
[01:34:13.640 --> 01:34:17.320]   So if now of a sudden you had Mini Cooper by BMW.
[01:34:17.320 --> 01:34:20.560]   That just destroys the whole branding exercise of BMW.
[01:34:20.560 --> 01:34:21.560]   Right?
[01:34:21.560 --> 01:34:22.560]   I think that--
[01:34:22.560 --> 01:34:25.240]   I think it's a-- and he's making a point that it's a terrible mistake.
[01:34:25.240 --> 01:34:26.880]   I don't think you want to connect all the apps.
[01:34:26.880 --> 01:34:30.680]   I think you want the apps to be all their own little world and people who feel like they're
[01:34:30.680 --> 01:34:32.960]   using WhatsApp to just feel like they're using WhatsApp.
[01:34:32.960 --> 01:34:35.640]   Unless you're afraid the government's going to break you up.
[01:34:35.640 --> 01:34:40.320]   Well, in which case you have to tie everything together as quickly as possible to make sure
[01:34:40.320 --> 01:34:41.320]   that--
[01:34:41.320 --> 01:34:42.320]   Which worked great for Microsoft.
[01:34:42.320 --> 01:34:43.320]   Yeah.
[01:34:43.320 --> 01:34:44.320]   That's exactly right.
[01:34:44.320 --> 01:34:46.880]   And it's just going to make it that much harder for Facebook to unpick it later and there'll
[01:34:46.880 --> 01:34:50.240]   be so much more painful and it'll probably destroy them like it did Microsoft.
[01:34:50.240 --> 01:34:51.240]   Which is a very helpful--
[01:34:51.240 --> 01:34:54.000]   So on the Instagram, they broke out into their messages.
[01:34:54.000 --> 01:34:55.720]   I think it's called like threads or something.
[01:34:55.720 --> 01:34:59.960]   So they broke out a separate thing for setting messages to like close friends.
[01:34:59.960 --> 01:35:01.520]   So I thought that was kind of interesting.
[01:35:01.520 --> 01:35:05.120]   But again, I'm just going to use the main app, I feel like.
[01:35:05.120 --> 01:35:06.120]   Yeah.
[01:35:06.120 --> 01:35:10.000]   I have to admit that I think I like it.
[01:35:10.000 --> 01:35:11.080]   I like it being on its own.
[01:35:11.080 --> 01:35:12.880]   I don't really message anybody on Instagram.
[01:35:12.880 --> 01:35:15.360]   So I don't think about-- I mean, maybe I'm too old for that.
[01:35:15.360 --> 01:35:16.360]   But I--
[01:35:16.360 --> 01:35:17.360]   I don't think about it anymore.
[01:35:17.360 --> 01:35:20.920]   So I think it's like-- I feel like we've all sort of moved to Instagram.
[01:35:20.920 --> 01:35:21.920]   Right.
[01:35:21.920 --> 01:35:22.920]   I just take--
[01:35:22.920 --> 01:35:23.920]   Instagram is like my--
[01:35:23.920 --> 01:35:27.440]   My Instagram for me is I'm traveling.
[01:35:27.440 --> 01:35:28.440]   Let me take some pictures for you.
[01:35:28.440 --> 01:35:29.440]   [LAUGHTER]
[01:35:29.440 --> 01:35:34.680]   I can-- you see like there'll be this like long desert of no photos and then it just pops
[01:35:34.680 --> 01:35:36.960]   up like here's a bunch of pictures of me in India or something like that.
[01:35:36.960 --> 01:35:38.560]   I don't have an Instagram account.
[01:35:38.560 --> 01:35:41.640]   Oh, I have-- the first thing I do every time I do social network comes out.
[01:35:41.640 --> 01:35:43.320]   I'm like, I got to get my name.
[01:35:43.320 --> 01:35:44.320]   So I always like register.
[01:35:44.320 --> 01:35:48.560]   So I was like-- when I went to start using Instagram, it was like years after it started.
[01:35:48.560 --> 01:35:50.280]   And I was like, somebody has my name.
[01:35:50.280 --> 01:35:51.280]   How did that happen?
[01:35:51.280 --> 01:35:52.280]   And then I realized that I had my--
[01:35:52.280 --> 01:35:53.280]   Yeah.
[01:35:53.280 --> 01:35:54.280]   No, I just gave up on Instagram.
[01:35:54.280 --> 01:35:55.360]   I couldn't make it work.
[01:35:55.360 --> 01:35:57.320]   And it was just too much of a time suck.
[01:35:57.320 --> 01:36:03.320]   And then I realized that most of my-- the work that I do is in IT infrastructure.
[01:36:03.320 --> 01:36:09.520]   So the service, data centers, WANs, infrastructure software and that sort of stuff.
[01:36:09.520 --> 01:36:12.000]   And I just realized that none of the nerds are on Instagram.
[01:36:12.000 --> 01:36:13.200]   None of the nerds are on Facebook.
[01:36:13.200 --> 01:36:16.000]   They're all on Twitter and LinkedIn and Slack groups.
[01:36:16.000 --> 01:36:17.000]   Right.
[01:36:17.000 --> 01:36:18.480]   So I don't care.
[01:36:18.480 --> 01:36:19.480]   Right.
[01:36:19.480 --> 01:36:25.200]   Facebook, of course, is still going to allow political ads and allow the politicians to
[01:36:25.200 --> 01:36:27.200]   lie.
[01:36:27.200 --> 01:36:29.960]   Is that something that we're concerned about?
[01:36:29.960 --> 01:36:30.960]   About them line?
[01:36:30.960 --> 01:36:35.160]   I mean, I'm more concerned for the people that are actually on Facebook and that are
[01:36:35.160 --> 01:36:38.120]   falling for these traps because I mean, I know me personally.
[01:36:38.120 --> 01:36:40.720]   I'm not really-- I don't use Facebook as much anymore.
[01:36:40.720 --> 01:36:44.840]   But I still use it to post updates like on my Facebook page and things like that.
[01:36:44.840 --> 01:36:46.840]   But it's hard because you'll see these ads.
[01:36:46.840 --> 01:36:51.040]   And it is something that you are so fully believing is real.
[01:36:51.040 --> 01:36:55.640]   And the fake news aspect, whatever you want to-- however you want to take that.
[01:36:55.640 --> 01:36:57.240]   I mean, most of it is fake.
[01:36:57.240 --> 01:37:02.440]   These ads that you're seeing, I have found myself in all of these fake ads holding up
[01:37:02.440 --> 01:37:03.440]   a product.
[01:37:03.440 --> 01:37:06.880]   They'll Photoshop out the phone that I have, which was like an iPhone or something and
[01:37:06.880 --> 01:37:08.280]   put in something fake.
[01:37:08.280 --> 01:37:14.040]   There's been all these ads that are running of me promoting a fake little NES system,
[01:37:14.040 --> 01:37:15.640]   but I'm actually showing the real one.
[01:37:15.640 --> 01:37:19.000]   So it's almost impossible to even stop that.
[01:37:19.000 --> 01:37:24.560]   And as soon as you report to Facebook, another company will then make a new fake page and
[01:37:24.560 --> 01:37:25.920]   start running the same ad.
[01:37:25.920 --> 01:37:28.680]   So it is an issue, even just for me.
[01:37:28.680 --> 01:37:34.960]   So I can't even imagine on the big scale of how this is just affecting people, especially
[01:37:34.960 --> 01:37:35.960]   the political nature.
[01:37:35.960 --> 01:37:39.560]   I think for me, it comes back to this issue we had further up the show where we talked
[01:37:39.560 --> 01:37:40.560]   about trust.
[01:37:40.560 --> 01:37:45.400]   If I can't trust Facebook to show me genuine content, and more importantly, if they're
[01:37:45.400 --> 01:37:51.920]   showing you content that they know to be false, then you can't trust Facebook as an institution
[01:37:51.920 --> 01:37:53.400]   and where does that lead.
[01:37:53.400 --> 01:37:58.240]   And I think logically that ultimately it undermines-- now Facebook is thinking that
[01:37:58.240 --> 01:38:03.480]   if you let that person show a false ad, that's not Facebook that gets the blame as the person
[01:38:03.480 --> 01:38:05.120]   showing the false ad.
[01:38:05.120 --> 01:38:08.560]   But I think the lesson is that from society is that that's not how it works.
[01:38:08.560 --> 01:38:11.520]   It's the platform that they blame or the platform that they trust.
[01:38:11.520 --> 01:38:14.000]   Well, I don't know if most society blames Facebook for anything.
[01:38:14.000 --> 01:38:15.480]   I don't know if they really think about it.
[01:38:15.480 --> 01:38:16.480]   We're thinking about it.
[01:38:16.480 --> 01:38:17.480]   That's what I mean.
[01:38:17.480 --> 01:38:18.480]   We're talking about it.
[01:38:18.480 --> 01:38:20.080]   I think most societies just like they just see the ads go by and they either believe
[01:38:20.080 --> 01:38:21.080]   or not or--
[01:38:21.080 --> 01:38:23.600]   I want to say, OK, Boomer right about now.
[01:38:23.600 --> 01:38:29.400]   But it's that age group who don't-- they've had 50 or 60 years of just reading newspapers
[01:38:29.400 --> 01:38:35.800]   as a trusted news source where it's been the platform has been controlled and regulated
[01:38:35.800 --> 01:38:37.880]   for not necessarily legally controlled.
[01:38:37.880 --> 01:38:38.880]   But it's also--
[01:38:38.880 --> 01:38:42.960]   And there's a middle group of people that are getting-- that are impacted by these.
[01:38:42.960 --> 01:38:48.040]   I think that there is a younger generation that is probably less-- is more cynical about
[01:38:48.040 --> 01:38:49.040]   what's coming through.
[01:38:49.040 --> 01:38:53.400]   And I think that from-- I guess from my perspective, the question is, should you believe anything
[01:38:53.400 --> 01:38:54.400]   that you see?
[01:38:54.400 --> 01:38:59.160]   You know, like whether it's on the news or whether it's on Facebook or anything else.
[01:38:59.160 --> 01:39:05.960]   Well, I spent the last 20 years both in front and behind the press.
[01:39:05.960 --> 01:39:09.600]   And I need to see it from a couple of different angles before I'm going to believe anything
[01:39:09.600 --> 01:39:12.920]   that I see because everything has gotten agenda to it.
[01:39:12.920 --> 01:39:15.440]   We're trying people to trust the news.
[01:39:15.440 --> 01:39:16.440]   And then we've seen--
[01:39:16.440 --> 01:39:17.440]   Which is a horrible idea.
[01:39:17.440 --> 01:39:18.440]   The TV news.
[01:39:18.440 --> 01:39:19.440]   And the history of the world.
[01:39:19.440 --> 01:39:21.440]   Well, historically, the news was--
[01:39:21.440 --> 01:39:22.440]   Always wrong.
[01:39:22.440 --> 01:39:25.600]   --trustable to a large place or a greater degree.
[01:39:25.600 --> 01:39:28.960]   And then we saw Murdoch's weaponized and monetized.
[01:39:28.960 --> 01:39:30.920]   The press was never trustable.
[01:39:30.920 --> 01:39:32.240]   Like, let's be clear.
[01:39:32.240 --> 01:39:33.440]   I'm not saying that they're lying.
[01:39:33.440 --> 01:39:36.080]   I'm not following up on some kind of Trumpism.
[01:39:36.080 --> 01:39:38.120]   You know, and like, that is craziness.
[01:39:38.120 --> 01:39:42.640]   But what I'm saying is that it was never trustworthy because there was people manipulating the
[01:39:42.640 --> 01:39:43.640]   person talking about it.
[01:39:43.640 --> 01:39:46.680]   There's the person that's self with their own viewpoint.
[01:39:46.680 --> 01:39:47.680]   There's this--
[01:39:47.680 --> 01:39:48.680]   I was in--
[01:39:48.680 --> 01:39:49.680]   There was nothing malicious or deliberate.
[01:39:49.680 --> 01:39:51.400]   Oh, yeah, it was.
[01:39:51.400 --> 01:39:52.400]   There was manipulation.
[01:39:52.400 --> 01:39:53.400]   But it was generally--
[01:39:53.400 --> 01:39:54.400]   Oh, yeah, absolutely.
[01:39:54.400 --> 01:39:56.360]   --was faced to differ with you.
[01:39:56.360 --> 01:39:57.760]   Generally, it was balanced.
[01:39:57.760 --> 01:39:58.760]   Like, it wasn't awful, right?
[01:39:58.760 --> 01:39:59.760]   Like, it is now.
[01:39:59.760 --> 01:40:00.760]   Oh, it was completely awful.
[01:40:00.760 --> 01:40:01.760]   Compared to what it is now.
[01:40:01.760 --> 01:40:02.760]   Like, the weaponization of the media.
[01:40:02.760 --> 01:40:03.760]   Hurts.
[01:40:03.760 --> 01:40:05.760]   Like, they were so concerned about Hurts because he would change--
[01:40:05.760 --> 01:40:06.760]   Yeah.
[01:40:06.760 --> 01:40:08.920]   --he would push all these headlines and do all these other things.
[01:40:08.920 --> 01:40:14.560]   The reason that we have all these laws about how much media you can have is because people
[01:40:14.560 --> 01:40:17.360]   were getting a lot of media and then lying with it.
[01:40:17.360 --> 01:40:20.480]   You know, so let's be clear that this is not-- there's nothing.
[01:40:20.480 --> 01:40:21.480]   This is nothing new.
[01:40:21.480 --> 01:40:25.200]   And you have people saying-- I mean, like, if you think the press is crazy now, go back
[01:40:25.200 --> 01:40:28.560]   and look at the headlines around like the late 1850s and these news reports.
[01:40:28.560 --> 01:40:29.560]   Oh, yeah.
[01:40:29.560 --> 01:40:30.560]   It's just crazy.
[01:40:30.560 --> 01:40:33.280]   You know, so the thing is, there's nothing new about this.
[01:40:33.280 --> 01:40:38.040]   You know, and so-- and just-- Justine, are you concerned about this?
[01:40:38.040 --> 01:40:43.000]   I mean, I'm concerned just for the nature of, you know, it is something that is being advertised
[01:40:43.000 --> 01:40:44.000]   to people.
[01:40:44.000 --> 01:40:46.680]   And you believe what you see when you watch the news and when you watch Facebook.
[01:40:46.680 --> 01:40:48.840]   Do you believe what's showing up there?
[01:40:48.840 --> 01:40:51.520]   Well, like you said, I'll definitely go and look at separate sources.
[01:40:51.520 --> 01:40:56.200]   I will start searching on Twitter and then I will look-- and it's crazy because you will
[01:40:56.200 --> 01:40:59.560]   just put these news articles next to each other and each one is different.
[01:40:59.560 --> 01:41:03.280]   Like, the headline definitely skews to whatever that political belief is.
[01:41:03.280 --> 01:41:06.960]   So it's really hard and it's even hard to have your own opinions because everyone has
[01:41:06.960 --> 01:41:09.000]   so many differing opinions.
[01:41:09.000 --> 01:41:13.960]   And this content that you're reading, it's being skewed towards what your beliefs are
[01:41:13.960 --> 01:41:18.920]   or something, you know, that it's like a trigger point because obviously Facebook knows everything.
[01:41:18.920 --> 01:41:23.400]   So if it knows or it's overheard me say something that I didn't like, it knows how to target
[01:41:23.400 --> 01:41:24.400]   that.
[01:41:24.400 --> 01:41:27.560]   The problem is that now the data is getting so good.
[01:41:27.560 --> 01:41:31.800]   I mean, the, you know, like TikTok is a good example of that for me is that TikTok will
[01:41:31.800 --> 01:41:34.600]   show me videos that I want to see but I don't want to admit that I want to see.
[01:41:34.600 --> 01:41:38.400]   You know, like, I'm like, no, of course, I don't care about that video.
[01:41:38.400 --> 01:41:39.400]   The peanut butter of the game.
[01:41:39.400 --> 01:41:40.400]   I might watch that for another minute.
[01:41:40.400 --> 01:41:43.640]   You know, like, you know, like, for another 10 seconds or whatever.
[01:41:43.640 --> 01:41:47.480]   I'm just going to, for educational purposes, watch this one, another, another 10 seconds.
[01:41:47.480 --> 01:41:52.040]   And so, but it's, it's figured it out because it's watching me every second that I'm watching
[01:41:52.040 --> 01:41:53.040]   that video.
[01:41:53.040 --> 01:41:55.040]   It's making a decision about whether I like it or not.
[01:41:55.040 --> 01:41:59.200]   I think the interesting thing about the political ads ultimately is that Facebook's getting paid
[01:41:59.200 --> 01:42:00.200]   to lie.
[01:42:00.200 --> 01:42:04.400]   And when people realize that it gets really just tasteful.
[01:42:04.400 --> 01:42:08.200]   It's one thing for people because you and me to get onto Facebook and say, you know,
[01:42:08.200 --> 01:42:13.400]   because broadcast ads that lie are different because I just want to make sure we're all
[01:42:13.400 --> 01:42:19.080]   clear that for Facebook, the political ads are some small percentage of their income.
[01:42:19.080 --> 01:42:20.720]   You know, that's not, it's not a big part of it.
[01:42:20.720 --> 01:42:24.200]   I can give up the ad revenue and not wouldn't even have to restate their financial results.
[01:42:24.200 --> 01:42:25.200]   It's so insignificant.
[01:42:25.200 --> 01:42:30.760]   So, so it's a tiny little number for them, but I can tell you for broadcasters, the election
[01:42:30.760 --> 01:42:35.800]   season is when they upgrade all their upgrade their studio, upgrade by all the new cameras,
[01:42:35.800 --> 01:42:39.440]   by all the, like, like there's just money coming in from heaven.
[01:42:39.440 --> 01:42:43.280]   It is like, it is like this, this snow of money that comes into these broadcasters.
[01:42:43.280 --> 01:42:48.920]   And especially when it's like Trump has been this massive boom for the broadcasters because
[01:42:48.920 --> 01:42:51.560]   now they have, it's, it's snowing money every day.
[01:42:51.560 --> 01:42:54.000]   You know, like, like it's not not just around the elections.
[01:42:54.000 --> 01:42:55.000]   It's just been crazy.
[01:42:55.000 --> 01:42:56.000]   I remember the number.
[01:42:56.000 --> 01:42:59.960]   And so the thing is, is that it's, it is when we talk about Facebook's getting paid
[01:42:59.960 --> 01:43:05.320]   to lie, I mean, there's a lot of ads, you know, we can, we can cover a lot of ads in
[01:43:05.320 --> 01:43:09.240]   the past 20 or 30 years where the broadcasters were getting paid to lie.
[01:43:09.240 --> 01:43:11.120]   I mean, those ads are there.
[01:43:11.120 --> 01:43:14.920]   And, and, and I'm not saying that that's, I mean, I think that I, I, I, and what I will
[01:43:14.920 --> 01:43:17.920]   say, I don't know what the answer is.
[01:43:17.920 --> 01:43:20.440]   No, you know, like, like, because, you know, I'm not going to say that they should just
[01:43:20.440 --> 01:43:23.040]   stop doing the ads, like Twitter, because the reality is,
[01:43:23.040 --> 01:43:24.560]   Well, Twitter didn't stop doing the ads.
[01:43:24.560 --> 01:43:26.880]   It said we're going to stop accepting paid ads.
[01:43:26.880 --> 01:43:33.000]   So if a person, if a political put, if somebody standing in politics wants to get onto Twitter
[01:43:33.000 --> 01:43:38.600]   and make lies, then they do that as a person, but they can't pay to get that targeted and
[01:43:38.600 --> 01:43:39.600]   accelerate.
[01:43:39.600 --> 01:43:45.040]   And the problem is, is that for a incumbent, that's great.
[01:43:45.040 --> 01:43:46.040]   Yes.
[01:43:46.040 --> 01:43:49.360]   Because, because you already have a million followers or you already have half a million
[01:43:49.360 --> 01:43:50.360]   followers.
[01:43:50.360 --> 01:43:54.200]   And now you have this startup that's going to try to, you know, compete with you and they
[01:43:54.200 --> 01:43:56.000]   have to now they, and the problem is.
[01:43:56.000 --> 01:43:57.000]   Yeah, you're right.
[01:43:57.000 --> 01:44:00.120]   It opens up an opportunity for a new entrant to enter the market, but then it becomes an
[01:44:00.120 --> 01:44:07.600]   arms race where the new entrant needs to earn money to sustain a, a social media campaign.
[01:44:07.600 --> 01:44:11.960]   And the incumbent starts to spend money and there's no winner here.
[01:44:11.960 --> 01:44:15.720]   The voters don't win because they're just spending more and more money on social media
[01:44:15.720 --> 01:44:19.240]   is put out more and more content that is supposed to attract ads.
[01:44:19.240 --> 01:44:21.360]   The only winner there is the social media company.
[01:44:21.360 --> 01:44:22.360]   All right.
[01:44:22.360 --> 01:44:26.480]   And in fact, what you end up with is what you have in politics around the world is as
[01:44:26.480 --> 01:44:30.200]   they spend more and more money on media, they have to raise more and more money.
[01:44:30.200 --> 01:44:34.040]   And the only way that you can move the needle on raising more money is to go to rich people
[01:44:34.040 --> 01:44:39.120]   and wealthy people and as soon as you accept money from wealthy people, you, you get owned.
[01:44:39.120 --> 01:44:40.120]   Right.
[01:44:40.120 --> 01:44:43.400]   It's wealthy people don't give you money for altruistic reasons.
[01:44:43.400 --> 01:44:48.560]   They usually over generally give it to you so that they can own you and get a favor back.
[01:44:48.560 --> 01:44:52.240]   And that is the cycle that's being broken here by Twitter walking away from the money.
[01:44:52.240 --> 01:44:54.680]   It pulls out the accelerated cycle.
[01:44:54.680 --> 01:44:55.680]   Yeah.
[01:44:55.680 --> 01:44:59.000]   I think that, again, the hard part, I understand, you know, again, I don't have, I don't have
[01:44:59.000 --> 01:45:02.200]   an answer for it, but I think that, that, you know, I've worked in a lot of campaigns
[01:45:02.200 --> 01:45:05.720]   where you're just trying to, especially when folks are trying to get off the ground, you
[01:45:05.720 --> 01:45:08.120]   know, how do you get that, that word out at the beginning?
[01:45:08.120 --> 01:45:20.200]   Now, I will say that I think that, um, uh, I think that their earned views is gold.
[01:45:20.200 --> 01:45:22.720]   Like that is what everybody should be trying to figure out how to do.
[01:45:22.720 --> 01:45:29.000]   So I do believe that anybody who's just leaning on advertising, you know, is, is that's a,
[01:45:29.000 --> 01:45:30.360]   you know, kind of a cheap, cheap pie.
[01:45:30.360 --> 01:45:34.920]   Going through an election campaign in the UK and we're watching these 40, 50, 60 year
[01:45:34.920 --> 01:45:40.960]   old political candidates do these off the cuff videos and it's gold.
[01:45:40.960 --> 01:45:45.960]   It's like watching your mom pretend that she's going to be all hip on an Instagram video.
[01:45:45.960 --> 01:45:48.360]   They are just all calling at it.
[01:45:48.360 --> 01:45:50.800]   I mean, well, it was the same in 2018.
[01:45:50.800 --> 01:45:54.600]   I mean, watching the election, watching, uh, political folks, because there, there were
[01:45:54.600 --> 01:45:58.040]   a couple folks that I, we, we reached out to and just said, I'll help, like, I'll just
[01:45:58.040 --> 01:45:59.320]   help you because I want to.
[01:45:59.320 --> 01:46:02.760]   And no, no, no, we got, we got it under control and then you'd watch the videos and you were
[01:46:02.760 --> 01:46:07.320]   like, oh, you're like, like, you know, like just, it doesn't have to be that way.
[01:46:07.320 --> 01:46:10.840]   You know, and some, like some, somebody's holding up a camera recording them and you're like,
[01:46:10.840 --> 01:46:12.080]   look at the background.
[01:46:12.080 --> 01:46:16.920]   It's just, you know, anyway, I'm sure, but it's just hysterical watching these people
[01:46:16.920 --> 01:46:20.800]   make the transition from, you know, they're literally walking down the street door knocking
[01:46:20.800 --> 01:46:23.720]   at old stash and old fashioned politics.
[01:46:23.720 --> 01:46:26.800]   And then they stopped to record a video, which is supposed to like, and you're like,
[01:46:26.800 --> 01:46:28.400]   I'm going like, why are you door knocking?
[01:46:28.400 --> 01:46:29.960]   Why are you not just doing social media?
[01:46:29.960 --> 01:46:31.760]   It just baffles me beyond belief.
[01:46:31.760 --> 01:46:32.760]   Anyway.
[01:46:32.760 --> 01:46:33.760]   Yeah.
[01:46:33.760 --> 01:46:36.560]   I mean, I think that the hard part right now is we got, when we go back to the whole virtual,
[01:46:36.560 --> 01:46:40.680]   you know what, why don't we have people working remotely because the, the, the tools, I, I
[01:46:40.680 --> 01:46:46.000]   will say I will argue that the, the tools that we have right now to stream, um, to get
[01:46:46.000 --> 01:46:49.960]   out and interact with people, having meaningful conversations with a large number of people
[01:46:49.960 --> 01:46:50.960]   are still rudimentary.
[01:46:50.960 --> 01:46:51.960]   Yeah.
[01:46:51.960 --> 01:46:55.440]   You know, like they are, um, people love it and people get excited about it.
[01:46:55.440 --> 01:46:59.400]   And it's the way to scale your campaign and it's a way to scale your brand.
[01:46:59.400 --> 01:47:03.520]   But the tools, the tools that I've used for those things are stuff that we built from scratch.
[01:47:03.520 --> 01:47:08.120]   You know, we're, we didn't have there and they still are not, I figured once we did it,
[01:47:08.120 --> 01:47:11.200]   people would start building them all the time, but they haven't, you know, like, because
[01:47:11.200 --> 01:47:12.200]   they don't understand it.
[01:47:12.200 --> 01:47:16.160]   So here's the other side of this too is when Twitter said to that they're walking away
[01:47:16.160 --> 01:47:22.080]   from three million in revenue by ditching the political ads, basically they also walked
[01:47:22.080 --> 01:47:25.680]   away from having to develop a system that detected political ads and then detected the
[01:47:25.680 --> 01:47:26.840]   truth.
[01:47:26.840 --> 01:47:32.760]   And if you do the mass, $3 million is roughly about three headcount in a machine learning
[01:47:32.760 --> 01:47:33.960]   in Silicon Valley, right?
[01:47:33.960 --> 01:47:37.040]   Because finding people with good math skills and machine learning, I just think that they
[01:47:37.040 --> 01:47:38.040]   just decided they didn't want to do it.
[01:47:38.040 --> 01:47:41.000]   I mean, you know, like it was just, I think that they just looked at it and said, you
[01:47:41.000 --> 01:47:44.840]   know, this is too hot, you know, and I think that like the money that they're making three,
[01:47:44.840 --> 01:47:48.000]   they said 3 million us is what they're taking for political ads.
[01:47:48.000 --> 01:47:50.240]   That's three headcount for Twitter in the machine learning team.
[01:47:50.240 --> 01:47:54.960]   It's not even worth their while gearing up a team to try and detect fake ads because
[01:47:54.960 --> 01:47:56.360]   they can't, they can't win.
[01:47:56.360 --> 01:47:59.960]   No, no, it's justine, do you think that Facebook should allow the ads or do you think they
[01:47:59.960 --> 01:48:01.960]   should just cut them off like everybody else?
[01:48:01.960 --> 01:48:05.320]   I don't think they would cut them off at all because I feel like that would be completely
[01:48:05.320 --> 01:48:09.920]   against everything that they basically stand for now, which is I mean, their whole platform
[01:48:09.920 --> 01:48:12.440]   is built off of that type of promotion.
[01:48:12.440 --> 01:48:16.680]   And it's interesting that Twitter, so they're only saying that they're losing $3 million
[01:48:16.680 --> 01:48:17.680]   by not taking what it was.
[01:48:17.680 --> 01:48:18.680]   I think the number would be much bigger.
[01:48:18.680 --> 01:48:20.680]   That's the number was 3 million.
[01:48:20.680 --> 01:48:22.600]   Yeah, because that's not a lot at all.
[01:48:22.600 --> 01:48:24.680]   And like you were saying, the amount of money that was coming up.
[01:48:24.680 --> 01:48:26.160]   That's the US election only.
[01:48:26.160 --> 01:48:27.160]   Yeah.
[01:48:27.160 --> 01:48:31.520]   Yeah, but the amount of money would have taken them to put those procedures in place to
[01:48:31.520 --> 01:48:34.080]   make sure that the ads were actually legit.
[01:48:34.080 --> 01:48:35.080]   It was real people.
[01:48:35.080 --> 01:48:37.840]   I mean, that would have cost, I would imagine way more than that.
[01:48:37.840 --> 01:48:39.600]   So I mean, I think it's a good deal.
[01:48:39.600 --> 01:48:45.760]   And but they've already given a massive platform to our current president to basically say whatever
[01:48:45.760 --> 01:48:46.920]   he wants.
[01:48:46.920 --> 01:48:48.600]   So he's still there.
[01:48:48.600 --> 01:48:50.600]   He's still saying his piece.
[01:48:50.600 --> 01:48:54.680]   So I think that's already way too much that they've already given him.
[01:48:54.680 --> 01:48:55.680]   Yeah.
[01:48:55.680 --> 01:48:56.680]   Yeah.
[01:48:56.680 --> 01:48:57.680]   Yeah.
[01:48:57.680 --> 01:48:58.680]   Yeah.
[01:48:58.680 --> 01:49:04.480]   And I think that what you're talking about is the fundamental problem is you have incumbents
[01:49:04.480 --> 01:49:09.080]   who already have a large following and how do you build up to where you can compete
[01:49:09.080 --> 01:49:10.080]   with that.
[01:49:10.080 --> 01:49:12.200]   And I do think that there are other solutions.
[01:49:12.200 --> 01:49:16.600]   I think that people who care about this stuff need to become more organized.
[01:49:16.600 --> 01:49:20.840]   I think for the most part, what you see is a lot of disorganization, you know, where,
[01:49:20.840 --> 01:49:25.560]   you know, for instance, if you can, you know, a lot of times what we work on a lot when
[01:49:25.560 --> 01:49:31.520]   we work on campaigns or what we used to, I don't haven't done it for a while, but is
[01:49:31.520 --> 01:49:33.000]   this kind of coordinated effort?
[01:49:33.000 --> 01:49:38.680]   So you're going to have thought leaders and influencers and all these things pushing towards
[01:49:38.680 --> 01:49:39.680]   a new thing.
[01:49:39.680 --> 01:49:43.960]   And again, what you're then doing is getting earned views, which is what you want to try
[01:49:43.960 --> 01:49:44.960]   to try to build up.
[01:49:44.960 --> 01:49:47.320]   You want to be a lot more valuable, you know, in the long run.
[01:49:47.320 --> 01:49:48.320]   More impactful.
[01:49:48.320 --> 01:49:54.880]   And, but the hard part is that I do think that it's, it's a complicated problem.
[01:49:54.880 --> 01:49:59.480]   You know, like I look at it, I'm glad I'm not the guy that has to make this decision.
[01:49:59.480 --> 01:50:00.480]   All right.
[01:50:00.480 --> 01:50:01.480]   So we're going to talk about, right?
[01:50:01.480 --> 01:50:07.320]   We're going to get out of the security conversation, jump into graphics next, but Leo has a couple
[01:50:07.320 --> 01:50:10.120]   words that he needs to share with us.
[01:50:10.120 --> 01:50:14.600]   Our show today brought to you by Capterra, find the right tools to make an informed software
[01:50:14.600 --> 01:50:17.280]   decision for your business.
[01:50:17.280 --> 01:50:24.000]   Capterra is the leading free, free online resource that'll help you find the best software
[01:50:24.000 --> 01:50:25.560]   solution for your business.
[01:50:25.560 --> 01:50:30.320]   If you dream of being more productive, save time and upgrade the way you work with the
[01:50:30.320 --> 01:50:35.480]   right software, explore software, narrow down your favorite options in minutes, use the
[01:50:35.480 --> 01:50:39.840]   software guides, the comparison tools at capterra.com/twit.
[01:50:39.840 --> 01:50:46.880]   Start making your work, be less work and find the right software for your business at capterra.com/twit.
[01:50:46.880 --> 01:50:48.360]   You know what the best part is?
[01:50:48.360 --> 01:50:53.960]   1 million plus reviews of products from real software users.
[01:50:53.960 --> 01:50:57.440]   So you'll get every bit of information you need to make the right choice.
[01:50:57.440 --> 01:50:59.360]   By the way, these reviews, they're all validated.
[01:50:59.360 --> 01:51:01.240]   You can be confident.
[01:51:01.240 --> 01:51:02.240]   Read the reviews.
[01:51:02.240 --> 01:51:07.200]   There's a thousand new reviews every single day at capterra.com/twit.
[01:51:07.200 --> 01:51:09.080]   And if you want to help, you don't have to pay.
[01:51:09.080 --> 01:51:13.840]   There's no, it's free, but you could leave a review, pay it forward a little bit, help
[01:51:13.840 --> 01:51:18.200]   capterra continue to be the leading free online resource for software solutions.
[01:51:18.200 --> 01:51:23.760]   700 specific categories of software, everything from digital workplace software to video management
[01:51:23.760 --> 01:51:24.760]   software.
[01:51:24.760 --> 01:51:30.440]   No matter what kind of programs or apps your business uses, capterra makes it easy to discover
[01:51:30.440 --> 01:51:31.520]   the right one fast.
[01:51:31.520 --> 01:51:33.040]   And you know why?
[01:51:33.040 --> 01:51:36.680]   Because they believe software makes the world a better place, because software can help
[01:51:36.680 --> 01:51:40.160]   every organization become a better version of itself.
[01:51:40.160 --> 01:51:43.840]   Join the millions of people who use capterra every month to find the right tools for your
[01:51:43.840 --> 01:51:44.840]   business.
[01:51:44.840 --> 01:51:46.440]   Did I mention it's free?
[01:51:46.440 --> 01:51:48.520]   Not free me, I'm free.
[01:51:48.520 --> 01:51:50.560]   They'll never ask you for a penny.
[01:51:50.560 --> 01:51:52.360]   Just a review.
[01:51:52.360 --> 01:51:53.640]   And I, so that's me asking.
[01:51:53.640 --> 01:51:54.800]   I think it's a good idea.
[01:51:54.800 --> 01:51:56.560]   Capterra.com/twit.
[01:51:56.560 --> 01:52:00.840]   Try it free today to find the tools you need to make and inform decision for your business.
[01:52:00.840 --> 01:52:03.840]   Capterra.com/twit.
[01:52:03.840 --> 01:52:06.760]   C-A-P-T-E-D-R-A.com/twit.
[01:52:06.760 --> 01:52:11.000]   Capterra is software selection, simplified.
[01:52:11.000 --> 01:52:12.000]   And we love it.
[01:52:12.000 --> 01:52:13.960]   Thank you for your supported Twit, by the way, capterra.
[01:52:13.960 --> 01:52:17.720]   Thank you for supporting Twit by going to capterra.com/twit.
[01:52:17.720 --> 01:52:18.720]   Try it.
[01:52:18.720 --> 01:52:19.720]   It's free.
[01:52:19.720 --> 01:52:20.720]   What do you get the lows?
[01:52:20.720 --> 01:52:22.360]   Now back to the show.
[01:52:22.360 --> 01:52:24.920]   Justine, did you get the new Photoshop for iPad?
[01:52:24.920 --> 01:52:25.920]   I did.
[01:52:25.920 --> 01:52:26.920]   Yeah.
[01:52:26.920 --> 01:52:27.920]   What do you think?
[01:52:27.920 --> 01:52:28.920]   I'm actually really looking forward to this.
[01:52:28.920 --> 01:52:32.080]   I'm reading a bunch of the reviews and everyone said, "But you guys didn't put all of the
[01:52:32.080 --> 01:52:33.240]   features into it."
[01:52:33.240 --> 01:52:39.280]   And they're obviously like, "We can't put all those years of work and code into the iPad
[01:52:39.280 --> 01:52:43.560]   app, but for what it is right now, I am always making thumbnails.
[01:52:43.560 --> 01:52:47.680]   I'm always doing a ton of photo editing and the way that it can sync using the cloud
[01:52:47.680 --> 01:52:48.680]   services.
[01:52:48.680 --> 01:52:53.520]   I can be cutting something out using the Apple Pencil, go and just drop it into my actual
[01:52:53.520 --> 01:52:55.440]   Photoshop on my computer and continue working.
[01:52:55.440 --> 01:53:01.800]   So for me, it's been incredibly seamless and just being able to make simple thumbnails
[01:53:01.800 --> 01:53:04.760]   and then upload them on YouTube when I'm traveling is really great.
[01:53:04.760 --> 01:53:10.480]   So I'm excited about the future of Photoshop and all the Adobe products for mobile.
[01:53:10.480 --> 01:53:14.240]   Because even like Adobe Rush, I'm a huge fan of for editing videos.
[01:53:14.240 --> 01:53:15.240]   It's been great.
[01:53:15.240 --> 01:53:17.880]   And you sparked?
[01:53:17.880 --> 01:53:22.600]   I have used it a little bit, but now I mostly was using Adobe Rush and I'm just waiting
[01:53:22.600 --> 01:53:26.640]   for Final Cut to be able to, or I movie actually to be able to edit vertical video.
[01:53:26.640 --> 01:53:28.880]   It's still shocking that they have not put that in yet.
[01:53:28.880 --> 01:53:29.880]   I am.
[01:53:29.880 --> 01:53:31.240]   It blows my mind.
[01:53:31.240 --> 01:53:34.960]   You know, I was so against it.
[01:53:34.960 --> 01:53:37.880]   Like so against 9x16.
[01:53:37.880 --> 01:53:40.880]   We had clients that would ask us to like, "What do you think of 9x16?"
[01:53:40.880 --> 01:53:41.880]   I was like, "Not that much."
[01:53:41.880 --> 01:53:45.800]   And I was like, "I don't, I hate it."
[01:53:45.800 --> 01:53:51.000]   And here's the worst part is that I did a bunch of consulting for some TikTok stuff.
[01:53:51.000 --> 01:53:52.440]   So I spent a lot of time in TikTok.
[01:53:52.440 --> 01:53:57.000]   And now you get into this thing like, if you're on TikTok and you see a 16x9, you immediately
[01:53:57.000 --> 01:53:58.000]   just go, "Nope.
[01:53:58.000 --> 01:53:59.000]   Nope.
[01:53:59.000 --> 01:54:00.000]   I'm just not even going to."
[01:54:00.000 --> 01:54:01.800]   I don't care what you're saying in a 16x9.
[01:54:01.800 --> 01:54:04.800]   And even one by one, you're like, "I'm here.
[01:54:04.800 --> 01:54:06.880]   You're cross posting this to Instagram, aren't you?"
[01:54:06.880 --> 01:54:09.200]   You know, like, and you kind of like, you look at them sideways.
[01:54:09.200 --> 01:54:11.120]   Like you're not really a Tiktoker.
[01:54:11.120 --> 01:54:14.280]   You know, like, you know, like, you know, like, you know, you're cheating.
[01:54:14.280 --> 01:54:20.960]   And so, so the 9x16 and my frustration is that more tools aren't built around 9x16.
[01:54:20.960 --> 01:54:25.000]   There's people who are probably listening to this show that are probably horrified that
[01:54:25.000 --> 01:54:26.640]   that came out of my mouth.
[01:54:26.640 --> 01:54:29.520]   I was against it for a very long time.
[01:54:29.520 --> 01:54:32.720]   And now I love editing vertical video and it is a challenge.
[01:54:32.720 --> 01:54:36.680]   Like, even now I've like moved my camera back a little bit more like at my desk setup
[01:54:36.680 --> 01:54:41.200]   so that I can still have enough space on each side to edit that piece into a vertical
[01:54:41.200 --> 01:54:43.480]   video so I don't have to reshoot things twice.
[01:54:43.480 --> 01:54:48.520]   I've also sometimes been using my phone or two separate phones and like just attaching
[01:54:48.520 --> 01:54:51.680]   them together and shooting vertical and horizontal at the same time.
[01:54:51.680 --> 01:54:55.320]   So it's been a challenge, but there's another.
[01:54:55.320 --> 01:54:56.320]   You're good?
[01:54:56.320 --> 01:54:57.320]   There's another app.
[01:54:57.320 --> 01:54:58.320]   Have you seen firework at all?
[01:54:58.320 --> 01:55:03.360]   I haven't used it very much, but it's kind of cool because you can hold the camera horizontal
[01:55:03.360 --> 01:55:08.520]   but then also vertical and it kind of gives you sort of a flipped feel of the whole image
[01:55:08.520 --> 01:55:09.840]   in the video.
[01:55:09.840 --> 01:55:12.800]   But I enjoy editing vertical video now a lot.
[01:55:12.800 --> 01:55:17.120]   I think that there's, especially when you're, it's a person talking to a bunch of other
[01:55:17.120 --> 01:55:18.120]   people.
[01:55:18.120 --> 01:55:19.120]   It works really well.
[01:55:19.120 --> 01:55:23.360]   So that there's something that's more personal about the nine by 16 and this took me a long
[01:55:23.360 --> 01:55:30.240]   time to get to is that I think that when it's a person, that's kind of a nice frame.
[01:55:30.240 --> 01:55:31.240]   When it's two people.
[01:55:31.240 --> 01:55:33.000]   There's a real nice corporate.
[01:55:33.000 --> 01:55:34.000]   It's an electric.
[01:55:34.000 --> 01:55:35.000]   And landscape.
[01:55:35.000 --> 01:55:36.000]   Exactly.
[01:55:36.000 --> 01:55:40.000]   And so, so as a portrait, I think it works actually pretty well.
[01:55:40.000 --> 01:55:45.320]   I think that it is as a, when you're trying to have two or three people or trying to show
[01:55:45.320 --> 01:55:46.320]   something wide.
[01:55:46.320 --> 01:55:52.480]   And I'm always surprised that watching landscape quote unquote stuff on something like TikTok,
[01:55:52.480 --> 01:55:57.920]   where they're showing like a big old panorama and it, excuse me, and it works.
[01:55:57.920 --> 01:55:58.920]   You know, so it's an.
[01:55:58.920 --> 01:56:03.440]   Does it mean that TikTok then tends to lean into head to toe shots of people?
[01:56:03.440 --> 01:56:04.440]   No, not head to toe.
[01:56:04.440 --> 01:56:06.240]   Just just just nine by 16.
[01:56:06.240 --> 01:56:07.240]   So it can be there.
[01:56:07.240 --> 01:56:08.240]   Yeah.
[01:56:08.240 --> 01:56:10.840]   But what I'm saying is over their head, I could imagine that if you're shooting, this
[01:56:10.840 --> 01:56:11.840]   is not my area of expertise.
[01:56:11.840 --> 01:56:14.760]   So I'm coming in as an outsider.
[01:56:14.760 --> 01:56:17.880]   If you're shooting vertically, you're going to lean into seeing the person or you're going
[01:56:17.880 --> 01:56:19.520]   to see torso to head.
[01:56:19.520 --> 01:56:22.920]   Whereas if you're shooting 16 right now and you're going to get shoulders and shoulders.
[01:56:22.920 --> 01:56:27.560]   But it allows you, when you're shooting portrait, unless you say torso to head, it's much more
[01:56:27.560 --> 01:56:31.920]   focused on that person because when you shot, if it's one person talking to you, there's
[01:56:31.920 --> 01:56:32.920]   a whole bunch of stuff behind them.
[01:56:32.920 --> 01:56:33.920]   Yeah, that's what I'm saying is.
[01:56:33.920 --> 01:56:36.040]   They have to worry about their background and they worry about a bunch of other things.
[01:56:36.040 --> 01:56:39.440]   So does that focus on vertical then and maybe just needs the right person to ask, does it
[01:56:39.440 --> 01:56:43.400]   make it focus on the person instead of the scene?
[01:56:43.400 --> 01:56:46.840]   It is, I think, a lot more personal, but a lot of that stuff is also shot using the front
[01:56:46.840 --> 01:56:48.640]   facing camera.
[01:56:48.640 --> 01:56:54.080]   And it also provides, I mean, even me as editing a vertical video, how can I fit other things
[01:56:54.080 --> 01:56:55.080]   into this frame?
[01:56:55.080 --> 01:56:58.600]   So if I'm doing an unboxing video, I can put my expression at the top, I can do a split
[01:56:58.600 --> 01:57:00.800]   screen and put the product at the bottom.
[01:57:00.800 --> 01:57:06.480]   So it's just trying to find other interesting ways to take that existing content and re-edit
[01:57:06.480 --> 01:57:08.920]   it into something that's vertical.
[01:57:08.920 --> 01:57:10.600]   It's challenging, but it's also really fun.
[01:57:10.600 --> 01:57:14.200]   I do feel like the vertical video is way more personal.
[01:57:14.200 --> 01:57:15.200]   Yeah.
[01:57:15.200 --> 01:57:19.600]   Yeah, so it's an interesting process that Apple is a little behind on, I think, you know,
[01:57:19.600 --> 01:57:20.600]   as far as--
[01:57:20.600 --> 01:57:21.600]   I'm like, does it make sense?
[01:57:21.600 --> 01:57:23.240]   Like, you guys basically created this monster.
[01:57:23.240 --> 01:57:24.720]   Now give us the tools to edit it.
[01:57:24.720 --> 01:57:27.440]   But yeah, that stuff is something that I've been pushing for.
[01:57:27.440 --> 01:57:33.560]   It's like, you have iMovie, which works incredible, but Adobe Rush is my go-to now for editing
[01:57:33.560 --> 01:57:34.560]   any vertical stuff.
[01:57:34.560 --> 01:57:36.480]   And then I think it's a Luma Touch.
[01:57:36.480 --> 01:57:38.600]   The Luma Fusion is also really great for editing.
[01:57:38.600 --> 01:57:41.120]   It's basically like Final Cut just in a mobile--
[01:57:41.120 --> 01:57:42.120]   Do you like Luma Touch?
[01:57:42.120 --> 01:57:43.120]   I love it.
[01:57:43.120 --> 01:57:44.120]   I do.
[01:57:44.120 --> 01:57:45.120]   Yeah.
[01:57:45.120 --> 01:57:46.120]   I mean, I mostly just use Rush for simple things.
[01:57:46.120 --> 01:57:48.400]   And then I always usually have my computer with me.
[01:57:48.400 --> 01:57:51.200]   So if I actually have to edit something, I just hop in a Final Cut.
[01:57:51.200 --> 01:57:53.760]   And are you using-- are you doing vertical video and Final Cut?
[01:57:53.760 --> 01:57:54.760]   Mm-hmm.
[01:57:54.760 --> 01:57:55.760]   Yeah, I do a lot of vertical video.
[01:57:55.760 --> 01:57:56.760]   How does that work for you?
[01:57:56.760 --> 01:57:58.960]   Does it work well?
[01:57:58.960 --> 01:57:59.960]   It does.
[01:57:59.960 --> 01:58:00.960]   Yeah.
[01:58:00.960 --> 01:58:01.960]   I mean, I just--
[01:58:01.960 --> 01:58:02.960]   Because the guess that Final Cut doesn't really care.
[01:58:02.960 --> 01:58:03.960]   It doesn't.
[01:58:03.960 --> 01:58:08.440]   No, and I'll usually take my existing 16 by 9 project and just copy and paste it into a
[01:58:08.440 --> 01:58:14.000]   vertical format and then just adjust each piece and just make it work.
[01:58:14.000 --> 01:58:16.880]   But yeah, I think I'm not sure.
[01:58:16.880 --> 01:58:18.960]   I don't really use Premiere very often.
[01:58:18.960 --> 01:58:23.040]   But I think they were working on some things that will auto-adjust your previous project
[01:58:23.040 --> 01:58:25.080]   and reformat it into vertical.
[01:58:25.080 --> 01:58:29.160]   So I'm not 100% sure if that's-- I think that's what they announced not too long ago.
[01:58:29.160 --> 01:58:30.160]   I think that's--
[01:58:30.160 --> 01:58:31.160]   Kind of like AI editing.
[01:58:31.160 --> 01:58:36.160]   It's one of the reasons that I got the 6K from the Blackmagic 6K was because if you
[01:58:36.160 --> 01:58:37.960]   shoot 6K, then you can do whatever you want.
[01:58:37.960 --> 01:58:38.960]   You know, like it's not--
[01:58:38.960 --> 01:58:41.120]   You know, I don't have to think about whether it's vertical or not.
[01:58:41.120 --> 01:58:42.120]   It's horizontal.
[01:58:42.120 --> 01:58:43.760]   There's tons of resolution to work inside of there.
[01:58:43.760 --> 01:58:47.240]   So you can kind of move your frame around and just kind of get whatever you-- you know,
[01:58:47.240 --> 01:58:49.040]   kind of use it and repurpose it.
[01:58:49.040 --> 01:58:51.400]   You know, so just throwing more bits at it.
[01:58:51.400 --> 01:58:53.160]   I want to ask you a question, Justine.
[01:58:53.160 --> 01:58:57.560]   I've had a lot of people tell me that they're giving up on Adobe's licensing because the
[01:58:57.560 --> 01:59:02.400]   cost of subscribing to Adobe's product is getting higher and higher and people are turning
[01:59:02.400 --> 01:59:03.400]   away.
[01:59:03.400 --> 01:59:05.680]   There was an article in slash. this week.
[01:59:05.680 --> 01:59:08.880]   And the reviews for the iPad one have just been crushed by people that are upset about
[01:59:08.880 --> 01:59:09.880]   the subscription service.
[01:59:09.880 --> 01:59:10.880]   I mean, like that--
[01:59:10.880 --> 01:59:11.880]   Should go to Pay Extra for the iPad version?
[01:59:11.880 --> 01:59:14.480]   Well, the iPad version, you have to have a subscription.
[01:59:14.480 --> 01:59:16.000]   No, you just have to have a subscription.
[01:59:16.000 --> 01:59:18.720]   You already have to have a Photoshop subscription to use the iPad version.
[01:59:18.720 --> 01:59:19.720]   Is that right, Justine?
[01:59:19.720 --> 01:59:20.720]   I think so.
[01:59:20.720 --> 01:59:21.720]   Yeah, I mean, I have a subscription.
[01:59:21.720 --> 01:59:22.720]   I do too, so I didn't notice it.
[01:59:22.720 --> 01:59:23.720]   I didn't have a problem.
[01:59:23.720 --> 01:59:27.760]   Yeah, I mean, I think-- I just remember growing up, like when I was really young, I
[01:59:27.760 --> 01:59:31.680]   was like, I can't-- like, there's no way my mom is going to pay, you know, thousands
[01:59:31.680 --> 01:59:35.160]   and thousands of dollars for each of this piece of software and then for updates.
[01:59:35.160 --> 01:59:39.800]   So I think, you know, just having that subscription fee, and especially if you are a business,
[01:59:39.800 --> 01:59:42.920]   like you're basically building your entire life off of this product.
[01:59:42.920 --> 01:59:45.080]   So I mean, I think it makes sense.
[01:59:45.080 --> 01:59:49.640]   I'm not sure if they have smaller subscription plans, if you just plan to use Photoshop,
[01:59:49.640 --> 01:59:50.640]   but I have the whole package.
[01:59:50.640 --> 01:59:52.640]   They have a $10--
[01:59:52.640 --> 01:59:57.960]   They have a $10 photography subscription that has light room.
[01:59:57.960 --> 01:59:59.800]   And does that include light room also?
[01:59:59.800 --> 02:00:03.240]   It includes Photoshop, Lightroom, and Photoshop for the iPad.
[02:00:03.240 --> 02:00:06.360]   I think that's actually really good if you think about it.
[02:00:06.360 --> 02:00:09.480]   I mean, that's $10 a month, $120 a year for those apps.
[02:00:09.480 --> 02:00:12.320]   That sounds like three times more than I would pay for it.
[02:00:12.320 --> 02:00:13.320]   Like, I can get--
[02:00:13.320 --> 02:00:15.760]   Well, I think the problem is, is that there are a lot of tools in Photoshop that just
[02:00:15.760 --> 02:00:19.960]   still aren't in Pixelmator or Affinity or, you know, like other ones.
[02:00:19.960 --> 02:00:21.160]   So you think that you want to use them.
[02:00:21.160 --> 02:00:28.080]   And I've been trying to move more of the work, you know, like for instance, we had-- for a
[02:00:28.080 --> 02:00:32.880]   long time, like a lot of our computers would have-- everybody had Pixelmator and then the
[02:00:32.880 --> 02:00:34.880]   people doing graphics had Photoshop.
[02:00:34.880 --> 02:00:35.880]   Yep.
[02:00:35.880 --> 02:00:39.440]   But, you know, so you were able to edit stuff.
[02:00:39.440 --> 02:00:47.840]   And then I use Affinity on some stuff now because for 360 video and for 360 stills,
[02:00:47.840 --> 02:00:54.160]   Affinity has a panoramic view where you can look straight down at your tripod and paint
[02:00:54.160 --> 02:00:57.440]   it out really easily, which is super useful.
[02:00:57.440 --> 02:01:02.000]   So anyway, so that was why I kind of got into that.
[02:01:02.000 --> 02:01:07.360]   And so I love those apps and I think that the hard part is they don't want to just copy
[02:01:07.360 --> 02:01:09.960]   all the things that Photoshop did.
[02:01:09.960 --> 02:01:10.960]   They're doing something else.
[02:01:10.960 --> 02:01:14.560]   But for us, you know, and unfortunately, I mean, I remember when Photoshop added layers.
[02:01:14.560 --> 02:01:18.080]   So you know, like I'm old enough to, you know, like it was a-- been using this for a long
[02:01:18.080 --> 02:01:24.760]   time and it's hard for me to-- like I just can't figure out why, you know, where it is.
[02:01:24.760 --> 02:01:26.560]   I'm not saying that Pixelmator and Affinity doesn't do it.
[02:01:26.560 --> 02:01:28.080]   I just don't know where that thing is.
[02:01:28.080 --> 02:01:29.080]   It's interesting for me to do this.
[02:01:29.080 --> 02:01:33.320]   And they do goofy things with alpha channels and layers that drive me a little crazy.
[02:01:33.320 --> 02:01:36.320]   See, for me, I've looked at buying-- what do you say, Justine?
[02:01:36.320 --> 02:01:39.800]   Well, just like a lot of these apps, I think people don't even realize that they're even
[02:01:39.800 --> 02:01:45.080]   paying for, I mean, just these simple iPhone apps, you have to pay several dollars a month
[02:01:45.080 --> 02:01:46.080]   to unlock.
[02:01:46.080 --> 02:01:47.640]   So this is not something that's that uncommon.
[02:01:47.640 --> 02:01:50.440]   I think maybe people might be overreacting a little bit.
[02:01:50.440 --> 02:01:54.720]   And I mean, I definitely remember this was when I first started using Photoshop as well.
[02:01:54.720 --> 02:01:57.040]   I mean, it was thousands of dollars.
[02:01:57.040 --> 02:02:01.760]   And obviously, I mean, I think they have student pricing for things as well.
[02:02:01.760 --> 02:02:06.600]   But I mean, if this is something that you're using on a daily basis and you're using it
[02:02:06.600 --> 02:02:12.280]   for business, I mean, I think the $10 a month is well spent using a product that actually
[02:02:12.280 --> 02:02:13.480]   does work.
[02:02:13.480 --> 02:02:17.400]   And you have the cloud and everything can just sink well together.
[02:02:17.400 --> 02:02:18.400]   You are taking a risk.
[02:02:18.400 --> 02:02:24.480]   I mean, back in the day when we were spending $600 on a-- or $700 on a copy of Photoshop,
[02:02:24.480 --> 02:02:26.800]   then you were taking a risk that, are you going to use it enough?
[02:02:26.800 --> 02:02:27.800]   You didn't make that work.
[02:02:27.800 --> 02:02:31.560]   And so a lot of us-- I mean, I started, obviously, with an unofficial copy.
[02:02:31.560 --> 02:02:34.400]   It's kind of, you know, how most of us started in the '90s.
[02:02:34.400 --> 02:02:35.400]   What?
[02:02:35.400 --> 02:02:36.400]   I did as well.
[02:02:36.400 --> 02:02:39.480]   And I think every 30 days-- because I was in sixth grade at the time.
[02:02:39.480 --> 02:02:43.400]   So I didn't understand this whole world and my parents didn't really understand it.
[02:02:43.400 --> 02:02:46.560]   So every 30 days, I would reformat my computer.
[02:02:46.560 --> 02:02:48.240]   And back then, we had floppy disks.
[02:02:48.240 --> 02:02:50.720]   So I was trying to copy all of my little files onto here.
[02:02:50.720 --> 02:02:51.720]   I'm in like 11.
[02:02:51.720 --> 02:02:53.360]   I'm like, I don't know what I'm doing.
[02:02:53.360 --> 02:02:58.360]   But every 30 days, I would reformat so I could have fireworks and Photoshop.
[02:02:58.360 --> 02:03:00.160]   And it was-- I don't know.
[02:03:00.160 --> 02:03:03.080]   It wasn't even that hard when I started doing it.
[02:03:03.080 --> 02:03:07.520]   It was just-- you just had to get somebody's disks and usually, you know, or a copy of
[02:03:07.520 --> 02:03:09.440]   their disks and you needed the serial number.
[02:03:09.440 --> 02:03:11.600]   And then you were kind of like, you're in.
[02:03:11.600 --> 02:03:16.880]   You know, like, and it was easy to do that, of course, Photoshop.
[02:03:16.880 --> 02:03:20.080]   I mean, Adobe figured out how to-- and as soon as-- here's the reality.
[02:03:20.080 --> 02:03:22.400]   As soon as I started making money, I bought it.
[02:03:22.400 --> 02:03:25.080]   Because I don't want to get caught with illegal software.
[02:03:25.080 --> 02:03:27.480]   So, you know, by the mid '90s, I was paying for it.
[02:03:27.480 --> 02:03:29.840]   And the great thing about Photoshop is it came with a scanner.
[02:03:29.840 --> 02:03:33.520]   So it came with every scanner that you could buy in the early '90s.
[02:03:33.520 --> 02:03:38.040]   And so that was the big thing was that we just-- you would just buy a scanner.
[02:03:38.040 --> 02:03:39.720]   Buy a scanner and that's where the Photoshop would show up.
[02:03:39.720 --> 02:03:42.080]   And everybody had a legal copy because they bought a scanner.
[02:03:42.080 --> 02:03:43.080]   Yeah, I just--
[02:03:43.080 --> 02:03:44.080]   That's amazing.
[02:03:44.080 --> 02:03:45.080]   I struggle with Adobe.
[02:03:45.080 --> 02:03:50.920]   I just can't get on board because the even starting Photoshop, the whole interface is
[02:03:50.920 --> 02:03:51.920]   baffling to me.
[02:03:51.920 --> 02:03:52.920]   Does that make sense of it?
[02:03:52.920 --> 02:03:54.520]   You can't make sense of the Photoshop?
[02:03:54.520 --> 02:03:55.520]   No.
[02:03:55.520 --> 02:03:56.520]   Well, I think it's hard.
[02:03:56.520 --> 02:04:04.080]   I had a conversation with someone who worked on the original Photoshop.
[02:04:04.080 --> 02:04:06.080]   And his point was strong.
[02:04:06.080 --> 02:04:10.880]   For us, when I started, it was very simple.
[02:04:10.880 --> 02:04:15.520]   It was much, much less than what Pixelmator does or other things like that.
[02:04:15.520 --> 02:04:17.280]   And then they just kept on adding little features.
[02:04:17.280 --> 02:04:20.320]   And so it wasn't baffling to me because they just kept on adding the new things.
[02:04:20.320 --> 02:04:21.320]   Yeah, you've been to it.
[02:04:21.320 --> 02:04:24.120]   I didn't have to learn how to do something from scratch.
[02:04:24.120 --> 02:04:29.800]   And to the point that someone's making online, PS, Photoshop Elements does a much more simplified
[02:04:29.800 --> 02:04:31.960]   version of the experience.
[02:04:31.960 --> 02:04:36.040]   Although for me, as a user that's used it in production for a long time, it's too simplified
[02:04:36.040 --> 02:04:38.960]   and I can't-- I don't feel like I can get everything done.
[02:04:38.960 --> 02:04:43.800]   And so-- but I think that for most people doing photo editing, I think Photoshop is a
[02:04:43.800 --> 02:04:45.600]   little bit of overkill.
[02:04:45.600 --> 02:04:49.760]   I think that most people, a Pixelmator or an Affinity would work great.
[02:04:49.760 --> 02:04:52.400]   And I think if you didn't have that history, I think it would be less.
[02:04:52.400 --> 02:04:57.440]   But for people like us who've been using it just since you were 11, me, since I was 21
[02:04:57.440 --> 02:04:58.840]   or 20 years old, it's just--
[02:04:58.840 --> 02:05:02.360]   There's products that I've been using for decades, which I wouldn't-- I just couldn't
[02:05:02.360 --> 02:05:06.000]   recommend to normal people because the gap is just too large.
[02:05:06.000 --> 02:05:09.560]   But Adobe for me is just getting into-- Adobe is so tough.
[02:05:09.560 --> 02:05:11.960]   It's so expensive.
[02:05:11.960 --> 02:05:13.560]   It's hundreds of dollars a year.
[02:05:13.560 --> 02:05:17.720]   And I'm just going, I would rather go and buy a license for Sketch or one of the other
[02:05:17.720 --> 02:05:19.720]   services that's a fraction of the price and--
[02:05:19.720 --> 02:05:22.280]   It's just a fraction of features too.
[02:05:22.280 --> 02:05:26.560]   I mean, I'm using it every day on a daily basis for hours and hours on end.
[02:05:26.560 --> 02:05:30.720]   So I think it comes down to like, do I need this or do I not need this?
[02:05:30.720 --> 02:05:32.640]   And for me, I definitely obviously need it.
[02:05:32.640 --> 02:05:35.840]   And it's still incredible that Final Cut is $300.
[02:05:35.840 --> 02:05:37.480]   We've bought that once.
[02:05:37.480 --> 02:05:38.480]   Like that's it.
[02:05:38.480 --> 02:05:43.720]   And that's the benchmark for me is that I think that Adobe might be certainly leaning
[02:05:43.720 --> 02:05:47.560]   into its customers by charging so much money.
[02:05:47.560 --> 02:05:48.560]   I just--
[02:05:48.560 --> 02:05:49.560]   I just don't know if they're leaning.
[02:05:49.560 --> 02:05:50.560]   I don't know if they're leaning.
[02:05:50.560 --> 02:05:52.760]   But they have so much stuff.
[02:05:52.760 --> 02:05:55.240]   They have, I mean, premiere after effects.
[02:05:55.240 --> 02:05:57.360]   I mean, you have everything, Illustrator, InDesigns.
[02:05:57.360 --> 02:05:59.360]   It's like, I use that whole suite of things.
[02:05:59.360 --> 02:06:01.320]   And it's all there under subscription.
[02:06:01.320 --> 02:06:05.480]   So that would have cost thousands of dollars back in the day, even now if you were to buy
[02:06:05.480 --> 02:06:06.480]   it also.
[02:06:06.480 --> 02:06:08.760]   The subscription model, I absolutely love it.
[02:06:08.760 --> 02:06:12.560]   And again, if it isn't something that you need, you can just use to stop the subscription.
[02:06:12.560 --> 02:06:13.560]   So that's always--
[02:06:13.560 --> 02:06:14.560]   And it's not professional, it doesn't make sense.
[02:06:14.560 --> 02:06:20.440]   So for a professional to even have the whole suite, you're talking about an hour, maybe
[02:06:20.440 --> 02:06:24.640]   an hour or two of your billable hours, pays for it for that month.
[02:06:24.640 --> 02:06:25.640]   Yeah.
[02:06:25.640 --> 02:06:26.640]   So out of the--
[02:06:26.640 --> 02:06:27.640]   I think it's like $50 a month.
[02:06:27.640 --> 02:06:28.640]   Yeah, $50 a month.
[02:06:28.640 --> 02:06:29.640]   Yeah.
[02:06:29.640 --> 02:06:34.640]   So depending on how much you're making, that's anywhere from 15 minutes to a couple hours.
[02:06:34.640 --> 02:06:39.360]   Is your rent out of 160 hours of time?
[02:06:39.360 --> 02:06:43.080]   So I think that if you're a professional and this is what you're doing all the time, I
[02:06:43.080 --> 02:06:44.080]   think that makes sense.
[02:06:44.080 --> 02:06:45.080]   Yeah.
[02:06:45.080 --> 02:06:49.360]   Adobe also released Arrow, justine, have you played with Arrow at all?
[02:06:49.360 --> 02:06:50.360]   I have not yet.
[02:06:50.360 --> 02:06:51.360]   No.
[02:06:51.360 --> 02:06:52.920]   Yeah, it's something that I'm excited about.
[02:06:52.920 --> 02:06:55.640]   I haven't played with it a ton.
[02:06:55.640 --> 02:06:56.960]   But I'm excited about where it's going.
[02:06:56.960 --> 02:07:01.720]   One of the things I'm really excited about is that it is supporting the new USDZ format,
[02:07:01.720 --> 02:07:05.080]   which is going to be-- or it's going to be supporting the USDZ format.
[02:07:05.080 --> 02:07:11.160]   The USDZ format is a-- I believe it is the universal scene description.
[02:07:11.160 --> 02:07:16.120]   USD was a Pixar format and USDZ is zipped.
[02:07:16.120 --> 02:07:20.840]   It's zipped up so it's a little bit more contained.
[02:07:20.840 --> 02:07:24.120]   But Apple's been really pushing that format forward.
[02:07:24.120 --> 02:07:27.640]   And I'm really excited about seeing USDZ in more places.
[02:07:27.640 --> 02:07:30.720]   I really wish it was in keynote.
[02:07:30.720 --> 02:07:36.480]   But that's my dream is the Apple Office stuff supporting it so that I can drop 3D models
[02:07:36.480 --> 02:07:37.800]   and stuff.
[02:07:37.800 --> 02:07:45.160]   But it means that you have a simple way to basically export models.
[02:07:45.160 --> 02:07:51.800]   And the idea is to get to a point where designers can build AR experiences relatively easily.
[02:07:51.800 --> 02:07:53.920]   I think that this is a good one.
[02:07:53.920 --> 02:07:57.880]   I think that Apple's Reality Creator-- I think it's Reality Creator.
[02:07:57.880 --> 02:07:58.880]   I don't have it right in front of me.
[02:07:58.880 --> 02:08:03.640]   But it's another great one where it's making it a much more graphical interface because
[02:08:03.640 --> 02:08:05.680]   I think that's going to be needed for AR.
[02:08:05.680 --> 02:08:09.640]   It can't be all, like, I'm going to write-- for most of the AR stuff we've done, there's
[02:08:09.640 --> 02:08:13.120]   a lot of lines of code that make it work.
[02:08:13.120 --> 02:08:18.160]   It's not like-- we built a bunch of cool pictures and now we're going to write them.
[02:08:18.160 --> 02:08:20.680]   Somebody's going to write a lot of code to make it work.
[02:08:20.680 --> 02:08:25.560]   I mean, just need to use yourself building AR experiences and stuff like this.
[02:08:25.560 --> 02:08:26.560]   I think so.
[02:08:26.560 --> 02:08:28.400]   I mean, I definitely would love to best with it more.
[02:08:28.400 --> 02:08:32.000]   It's just, you know, right now it's like, OK, how much time do I need to dedicate to
[02:08:32.000 --> 02:08:36.080]   just keeping YouTube going and then, you know, how much time do I dedicate to all of these
[02:08:36.080 --> 02:08:39.280]   experimental things, which may never end up anywhere.
[02:08:39.280 --> 02:08:42.360]   But I always love testing out things like this.
[02:08:42.360 --> 02:08:48.040]   So yeah, I'm definitely interested in the whole future of AR, like especially AR experiences
[02:08:48.040 --> 02:08:49.160]   for other people.
[02:08:49.160 --> 02:08:53.440]   So imagine me sitting on the couch with somebody watching one of my YouTube videos that's
[02:08:53.440 --> 02:08:57.840]   up on the-- on imaginary TV so they could just be holding their phone, watching on an
[02:08:57.840 --> 02:08:59.560]   imaginary AR TV that's there.
[02:08:59.560 --> 02:09:02.160]   And if they could turn to me, I can give them some feedback.
[02:09:02.160 --> 02:09:03.360]   Like, oh, I love this part.
[02:09:03.360 --> 02:09:05.120]   Like, this is-- make sure you pay attention.
[02:09:05.120 --> 02:09:09.240]   So I think there's a lot of really cool things that can be done in the future with that.
[02:09:09.240 --> 02:09:14.600]   Yeah, I'm really focused on education in relationship to it is just that, you know,
[02:09:14.600 --> 02:09:19.480]   or not just-- and when I say education, I don't mean K through 12 or secondary, but
[02:09:19.480 --> 02:09:25.480]   really the idea of, you know, I'm walking through, let's say, a historical location and
[02:09:25.480 --> 02:09:28.560]   being able to pick up my phone and be able to see new data.
[02:09:28.560 --> 02:09:30.960]   You know, like, this is what this was, and this is what this was, or this is what this
[02:09:30.960 --> 02:09:34.480]   used to look like, or this is-- you know, these are all the things that you could be
[02:09:34.480 --> 02:09:40.920]   adding to the-- adding to that experience where as a venue, you know, someone who's
[02:09:40.920 --> 02:09:44.520]   got the venue, whether that's a historical venue or anything else, like for me, like
[02:09:44.520 --> 02:09:49.000]   AR, someone-- I saw something, I guess, that they're doing a bunch of stuff in the Dallas
[02:09:49.000 --> 02:09:51.840]   Cowboys are really way ahead of this, and they have this big thing when the football
[02:09:51.840 --> 02:09:53.400]   players are really huge and everything else.
[02:09:53.400 --> 02:09:55.320]   And I was like, I just wanted to go to the bathroom.
[02:09:55.320 --> 02:09:58.320]   Like, I just want to pick up my phone.
[02:09:58.320 --> 02:10:00.880]   That's number one down here, and I'll have an arrow that's fast.
[02:10:00.880 --> 02:10:03.360]   But number one, picture-- no, I want to pick up the phone, and I want to see an arrow that
[02:10:03.360 --> 02:10:06.800]   goes like this, you know, like that goes down and around, and I go, okay, that's where
[02:10:06.800 --> 02:10:10.680]   I go, you know, or where do I pick up a hot dog, or, you know, like, I-- like, if you just
[02:10:10.680 --> 02:10:14.240]   gave me that, I'd be really happy, you know, you know, about-- because you get to these
[02:10:14.240 --> 02:10:17.320]   huge arenas and you can't figure out which way is up.
[02:10:17.320 --> 02:10:19.640]   Anyway, so, we'll see how that goes.
[02:10:19.640 --> 02:10:24.480]   Now, Microsoft had Ignite, they have-- one of the things that we're looking at here is
[02:10:24.480 --> 02:10:29.760]   their strategy of Azure Arc, Azure Stack Hub, Azure Stack Edge.
[02:10:29.760 --> 02:10:31.520]   Can you tell us a little bit about what all this stuff is?
[02:10:31.520 --> 02:10:32.520]   I can try.
[02:10:32.520 --> 02:10:34.520]   We're going to drop into some consultative babble though.
[02:10:34.520 --> 02:10:38.960]   So we're going to start talking about-- when you start talking about UCSD, I'm sort of
[02:10:38.960 --> 02:10:39.960]   losing it.
[02:10:39.960 --> 02:10:40.960]   But--
[02:10:40.960 --> 02:10:41.960]   USD.
[02:10:41.960 --> 02:10:45.120]   Up until now, Microsoft has been working with Azure Stack on premise so that in your own data
[02:10:45.120 --> 02:10:46.120]   center--
[02:10:46.120 --> 02:10:47.120]   Right.
[02:10:47.120 --> 02:10:49.640]   --and you would have-- and that would be an honor to the Azure Cloud.
[02:10:49.640 --> 02:10:51.380]   And so it's the old Hyper-V.
[02:10:51.380 --> 02:10:55.860]   You've got a group of container-- of virtual machines and on top of it is a controller
[02:10:55.860 --> 02:10:57.280]   that drives a virtual machine.
[02:10:57.280 --> 02:11:02.180]   So it brings your storage and your servers and your networking all together-ish sort of
[02:11:02.180 --> 02:11:03.180]   thing.
[02:11:03.180 --> 02:11:06.180]   And that's your first step down the road to Cloud is to get into virtualization and then
[02:11:06.180 --> 02:11:09.220]   you could take those virtual machines into the Cloud.
[02:11:09.220 --> 02:11:15.220]   The second stage of Cloud infrastructure has been to transition to containers.
[02:11:15.220 --> 02:11:19.220]   And so we've seen the idea of a container where a virtual machine will run containers
[02:11:19.220 --> 02:11:23.620]   inside of that on top of the server and then it becomes where does the control plane for
[02:11:23.620 --> 02:11:25.140]   the container set.
[02:11:25.140 --> 02:11:30.220]   So the announcement that Microsoft is saying is very similar to what Google Anthos has done
[02:11:30.220 --> 02:11:33.780]   and similar to what AWS Outpost has done, which are the competitor products, which is
[02:11:33.780 --> 02:11:38.660]   instead of putting the control plane in your data center, use the one in the Cloud.
[02:11:38.660 --> 02:11:43.060]   And then Azure Stack in the Cloud will then manage all of the containers in the VMs whether
[02:11:43.060 --> 02:11:47.020]   they're in Azure's Cloud, whether they're in your Azure Stack on-prem.
[02:11:47.020 --> 02:11:49.500]   So it becomes very seamless.
[02:11:49.500 --> 02:11:51.060]   It's an attempt to be seamless.
[02:11:51.060 --> 02:11:53.100]   In theory, it becomes seamless.
[02:11:53.100 --> 02:11:55.780]   And what it also does is it becomes Cloud first.
[02:11:55.780 --> 02:12:00.740]   So where the previous generation of Azure Stack was in my data center, lots of servers,
[02:12:00.740 --> 02:12:04.340]   VMs, and then I can start moving those VMs into the Cloud.
[02:12:04.340 --> 02:12:08.740]   But there's a control where it passes out of my domain into Azure's domain.
[02:12:08.740 --> 02:12:12.780]   Now the control stack is in Azure for containers for the VMs.
[02:12:12.780 --> 02:12:18.580]   And it shifts people's thinking away from on-prem to Cloud first, which is good for the Azure
[02:12:18.580 --> 02:12:19.580]   business.
[02:12:19.580 --> 02:12:22.460]   And I think that what's interesting is I know that with AWS we're doing a bunch of stuff
[02:12:22.460 --> 02:12:27.820]   right now where I have this thing I was talking about has 343 million polygons.
[02:12:27.820 --> 02:12:29.740]   Well, I tried to texture it and it crashed.
[02:12:29.740 --> 02:12:31.940]   It didn't crash my computer.
[02:12:31.940 --> 02:12:33.780]   My little iMac was like, "I can't do this.
[02:12:33.780 --> 02:12:35.420]   I'm not going for this.
[02:12:35.420 --> 02:12:36.940]   This is too much."
[02:12:36.940 --> 02:12:41.820]   And so I'm going to, then I put it on my PC and it was still not enough for AM.
[02:12:41.820 --> 02:12:45.060]   So now I'm just getting, but the idea that I was talking to a friend of mine is we'll
[02:12:45.060 --> 02:12:48.060]   just spin up a, so in AWS we're spinning up-
[02:12:48.060 --> 02:12:49.060]   GPU clusters.
[02:12:49.060 --> 02:12:54.180]   I got four GPUs and a 256 megs of RAM with a big, whatever.
[02:12:54.180 --> 02:12:57.300]   I just spin that up and just push everything there and let it cook.
[02:12:57.300 --> 02:13:01.620]   And I'm paying our subscription that we were just talking about, except a little bit more.
[02:13:01.620 --> 02:13:03.900]   So I think it's like $30 or $40 a day or something like that.
[02:13:03.900 --> 02:13:08.540]   But I was able to just create, because I don't need that computer.
[02:13:08.540 --> 02:13:09.540]   That's inexpensive.
[02:13:09.540 --> 02:13:12.860]   You don't want to spend $100,000 or whatever.
[02:13:12.860 --> 02:13:13.860]   That's a lot of computers.
[02:13:13.860 --> 02:13:16.060]   It's like $10,000 or $20,000 or $30,000 computer.
[02:13:16.060 --> 02:13:17.820]   And then you've got to put it somewhere.
[02:13:17.820 --> 02:13:18.820]   You've got a parrot.
[02:13:18.820 --> 02:13:20.460]   It's probably drawing three or four kilowatts.
[02:13:20.460 --> 02:13:21.460]   Exactly.
[02:13:21.460 --> 02:13:22.460]   So instead I just throw it into that.
[02:13:22.460 --> 02:13:25.620]   You know, I'm able to just kind of push it into the cloud and let it do its thing for
[02:13:25.620 --> 02:13:30.180]   the time that I need it and then I'm out.
[02:13:30.180 --> 02:13:32.980]   So now, justine, do you see yourself moving into the cloud?
[02:13:32.980 --> 02:13:35.900]   How much work do you do in the cloud right now?
[02:13:35.900 --> 02:13:40.820]   I mean, I do a lot as far as transferring huge files back and forth for editing.
[02:13:40.820 --> 02:13:45.500]   I mean, we use Frame.io a lot for almost all the editing stuff as far as, you know, making
[02:13:45.500 --> 02:13:48.060]   changes and edits and sharing things with clients.
[02:13:48.060 --> 02:13:50.140]   But I'm interested in like cloud computing.
[02:13:50.140 --> 02:13:54.060]   So what Google's doing with Stadia is pretty fascinating.
[02:13:54.060 --> 02:13:57.980]   Just the fact that you can play all of these crazy massive powerful games, just in the
[02:13:57.980 --> 02:14:00.340]   palm of your hand, is going to be really cool.
[02:14:00.340 --> 02:14:03.780]   So I think for me, cloud computing is going to be really cool.
[02:14:03.780 --> 02:14:07.220]   So that's going to be something that I'm definitely looking forward to checking out.
[02:14:07.220 --> 02:14:11.660]   And I agree with Frame.io, that's pretty much how we, that's how you communicate with everybody.
[02:14:11.660 --> 02:14:14.060]   You know, to tie, you know, tie all that stuff together.
[02:14:14.060 --> 02:14:19.380]   It's a great example of, you know, how cloud as a, as a service, you know, really makes
[02:14:19.380 --> 02:14:21.660]   sense for, you know, for a lot of folks.
[02:14:21.660 --> 02:14:24.580]   It can kind of be able to integrate directly in with Final Cut.
[02:14:24.580 --> 02:14:28.340]   So it's, you know, they're using the integration.
[02:14:28.340 --> 02:14:30.500]   Or Premiere or a variety of things.
[02:14:30.500 --> 02:14:33.620]   Like it does, it does, it covers all the bases there.
[02:14:33.620 --> 02:14:35.900]   So yeah, I think just the cloud is going to be great.
[02:14:35.900 --> 02:14:39.780]   It's just the hard part is, you know, when I'm traveling, you know, the Wi-Fi and hotels
[02:14:39.780 --> 02:14:42.580]   sometimes isn't that great or when I'm visiting my parents.
[02:14:42.580 --> 02:14:47.220]   So it's having that consistency of connection is going to be really, really important.
[02:14:47.220 --> 02:14:51.860]   Well, like that was my trouble with this, this thing that I'm working on is I, you know,
[02:14:51.860 --> 02:14:56.060]   when I was traveling, it was hard to put the files onto the virtual machine because it's,
[02:14:56.060 --> 02:14:57.300]   you know, six gigs of photos.
[02:14:57.300 --> 02:14:58.300]   Yes.
[02:14:58.300 --> 02:15:00.020]   You know, so you're like, there's a start process.
[02:15:00.020 --> 02:15:04.020]   It's transferring six gigs into the cloud as a substantial challenge.
[02:15:04.020 --> 02:15:07.020]   And that problem probably won't ever go away.
[02:15:07.020 --> 02:15:11.860]   So the network infrastructure that's in the world today is not iterating at a pace that
[02:15:11.860 --> 02:15:15.060]   we need to manage big pieces of data moving around.
[02:15:15.060 --> 02:15:16.060]   Networking is particularly.
[02:15:16.060 --> 02:15:17.060]   In short term.
[02:15:17.060 --> 02:15:19.940]   Like, I mean, what I mean by that is if I have to have it done right now, that's a problem.
[02:15:19.940 --> 02:15:25.180]   If I can, you know, the hard part really is making sure that the tools allow me to interrupt
[02:15:25.180 --> 02:15:26.180]   that upload.
[02:15:26.180 --> 02:15:27.180]   Yeah.
[02:15:27.180 --> 02:15:28.180]   And then resume it.
[02:15:28.180 --> 02:15:29.180]   And then resume it.
[02:15:29.180 --> 02:15:31.180]   And then you're like, I'm not going to be able to do that.
[02:15:31.180 --> 02:15:33.180]   And then you're like, I'm not going to be able to do that.
[02:15:33.180 --> 02:15:35.180]   And then you're like, I'm not going to be able to do that.
[02:15:35.180 --> 02:15:37.180]   And then you're like, I'm not going to be able to do that.
[02:15:37.180 --> 02:15:39.180]   And then you're like, I'm not going to be able to do that.
[02:15:39.180 --> 02:15:40.180]   And then you're like, I'm not going to be able to do that.
[02:15:40.180 --> 02:15:41.180]   And then you're like, I'm not going to be able to do that.
[02:15:41.180 --> 02:15:43.180]   And then you're like, I'm not going to be able to do that.
[02:15:43.180 --> 02:15:44.180]   And then you're like, I'm not going to be able to do that.
[02:15:44.180 --> 02:15:46.180]   And then you're like, I'm not going to be able to do that.
[02:15:46.180 --> 02:15:47.180]   And then you're like, I'm not going to be able to do that.
[02:15:47.180 --> 02:15:57.180]   And then you're like, I'm not going to be able to do that.
[02:15:57.180 --> 02:15:59.180]   And then you're like, I'm not going to be able to do that.
[02:15:59.180 --> 02:16:01.180]   And then you're like, I'm not going to be able to do that.
[02:16:01.180 --> 02:16:03.180]   And then you're like, I'm not going to be able to do that.
[02:16:03.180 --> 02:16:04.180]   And then you're like, I'm not going to be able to do that.
[02:16:04.180 --> 02:16:05.180]   And then you're like, I'm not going to be able to do that.
[02:16:05.180 --> 02:16:06.180]   And then you're like, I'm not going to be able to do that.
[02:16:06.180 --> 02:16:07.180]   And then you're like, I'm not going to be able to do that.
[02:16:07.180 --> 02:16:08.180]   And then you're like, I'm not going to be able to do that.
[02:16:08.180 --> 02:16:09.180]   And then you're like, I'm not going to be able to do that.
[02:16:09.180 --> 02:16:10.180]   And then you're like, I'm not going to be able to do that.
[02:16:10.180 --> 02:16:17.180]   And then you're like, I'm not going to be able to do that.
[02:16:17.180 --> 02:16:20.180]   And then you're like, I'm not going to be able to do that.
[02:16:20.180 --> 02:16:23.180]   And then you're like, I'm not going to be able to do that.
[02:16:23.180 --> 02:16:25.180]   And then you're like, I'm not going to be able to do that.
[02:16:25.180 --> 02:16:27.180]   And then you're like, I'm not going to be able to do that.
[02:16:27.180 --> 02:16:29.180]   And then you're like, I'm not going to be able to do that.
[02:16:29.180 --> 02:16:31.180]   And then you're like, I'm not going to be able to do that.
[02:16:31.180 --> 02:16:32.180]   And then you're like, I'm not going to be able to do that.
[02:16:32.180 --> 02:16:33.180]   And then you're like, I'm not going to be able to do that.
[02:16:33.180 --> 02:16:34.180]   And then you're like, I'm not going to be able to do that.
[02:16:34.180 --> 02:16:35.180]   And then you're like, I'm not going to be able to do that.
[02:16:35.180 --> 02:16:43.180]   But it just makes me more excited for the future, like even getting a camera today, I'm like, this is great, but this makes me more excited for what we're going to see next.
[02:16:43.180 --> 02:16:48.180]   I'm the person in the infrastructure who's sitting there going like, we don't have the infrastructure to make this happen.
[02:16:48.180 --> 02:16:56.180]   And I actually kind of think that the other side of that coin is it makes very little sense to announce these products, which are so obviously not fit for consumption.
[02:16:56.180 --> 02:17:00.180]   And then people try them and they get unhappy with them and then they fail.
[02:17:00.180 --> 02:17:01.180]   Would they be better?
[02:17:01.180 --> 02:17:11.180]   It's the same thing with like 5G, you know, 5G, everyone's so hyped about 5G and you're all going to be let down when it's barely even usable or in your area.
[02:17:11.180 --> 02:17:14.180]   Or you do something where it calls 5GE.
[02:17:14.180 --> 02:17:15.180]   Oh, yeah.
[02:17:15.180 --> 02:17:16.180]   What are you doing?
[02:17:16.180 --> 02:17:21.180]   Well, the worst part is is that the worst pieces that it's not just marketing.
[02:17:21.180 --> 02:17:28.180]   You wish it was just marketing, but they are switching something because my performance drops when it goes to 5GE.
[02:17:28.180 --> 02:17:37.180]   And I'm just like, okay, if you were going to do the absolute wrong thing, it is make sure that my experience is worse when you switch to the new brand.
[02:17:37.180 --> 02:17:44.180]   So what I actually have to do is I don't know if you're interested in this, but there's a thing called 4.5G, which is 4G LTE.
[02:17:44.180 --> 02:17:51.180]   And then inside the LTE is a lot thing called LTE Plus or an LTE extra mode, which is sort of broadly named 4.5G.
[02:17:51.180 --> 02:17:58.180]   And it activates a bunch of extra frequencies and signaling rates.
[02:17:58.180 --> 02:18:02.180]   The way that the 3G/4G standards work is the first 3G comes out.
[02:18:02.180 --> 02:18:05.180]   And then there's all these sub-releases that we don't talk about.
[02:18:05.180 --> 02:18:08.180]   And then 4 comes out and it's a major step.
[02:18:08.180 --> 02:18:17.180]   It's actually not a... Well, 5G is a major step because they stop encoding the IP into radio packets.
[02:18:17.180 --> 02:18:19.180]   IP actually becomes native on the network.
[02:18:19.180 --> 02:18:22.180]   So the data flow becomes vastly improved and much better.
[02:18:22.180 --> 02:18:24.180]   So true 5G will be a difference.
[02:18:24.180 --> 02:18:28.180]   What happened with AT&T was they relabeled 4.5G 5G.
[02:18:28.180 --> 02:18:29.180]   Right.
[02:18:29.180 --> 02:18:30.180]   Which they did the last time too.
[02:18:30.180 --> 02:18:33.180]   I mean, they had whatever they called it.
[02:18:33.180 --> 02:18:35.180]   But it was like the AT&T has a...
[02:18:35.180 --> 02:18:36.180]   Habit of jumping.
[02:18:36.180 --> 02:18:39.180]   Habit of like, I want to be first and I don't actually want to put the hardware out there.
[02:18:39.180 --> 02:18:40.180]   Or we're working on it.
[02:18:40.180 --> 02:18:41.180]   So there's no findings.
[02:18:41.180 --> 02:18:42.180]   We're going to get you excited.
[02:18:42.180 --> 02:18:46.180]   There's only like one phone in the country anywhere in the world that can do 5G.
[02:18:46.180 --> 02:18:50.180]   You shouldn't buy it because it only does it on a certain subset of frequencies.
[02:18:50.180 --> 02:18:52.180]   That will be never worked very well.
[02:18:52.180 --> 02:18:53.180]   You'll never get good 5G.
[02:18:53.180 --> 02:18:57.180]   As long as you're willing to take that 5G phone and throw it in the bin in about 6 months when the next generation of 5G...
[02:18:57.180 --> 02:19:03.180]   If you want to be the cool kid on campus that has 5G that gets to say, "I got 5G and it's so fast and everybody's great."
[02:19:03.180 --> 02:19:04.180]   Well, it's perfect.
[02:19:04.180 --> 02:19:05.180]   It's perfect for you.
[02:19:05.180 --> 02:19:06.180]   That's assuming you actually have a 5G tower.
[02:19:06.180 --> 02:19:07.180]   Because you've got to be in the end.
[02:19:07.180 --> 02:19:09.180]   You're going to be standing within 5 feet of the tower.
[02:19:09.180 --> 02:19:10.180]   Exactly.
[02:19:10.180 --> 02:19:13.180]   But it's going to be very impressive in that one little bit.
[02:19:13.180 --> 02:19:16.180]   And you guys meet me at the 5G tower.
[02:19:16.180 --> 02:19:17.180]   We can download some files.
[02:19:17.180 --> 02:19:19.180]   Because you've got to be within like 200 feet of it.
[02:19:19.180 --> 02:19:21.180]   It's going to be...
[02:19:21.180 --> 02:19:22.180]   It's yeah.
[02:19:22.180 --> 02:19:27.180]   But now the 5G though, I mean, I can see the transmitter is getting put up even in like the little town that I live in.
[02:19:27.180 --> 02:19:30.180]   You see the little dots going on all the lights and everything else.
[02:19:30.180 --> 02:19:32.180]   So it won't be just one tower.
[02:19:32.180 --> 02:19:34.180]   It'll be like these little groups of areas where they're going to go.
[02:19:34.180 --> 02:19:37.180]   There's a lot of incentives for the telcos to get into 5G.
[02:19:37.180 --> 02:19:39.180]   Mainly it's to do with the software control of the tower.
[02:19:39.180 --> 02:19:49.180]   So they're shifting away from the legacy idea of hardware, custom hardware, custom specifics to using software defined radios and software defined engines in the tower.
[02:19:49.180 --> 02:19:52.180]   And so that dramatically shifts the way the cost...
[02:19:52.180 --> 02:19:53.180]   Well, doesn't it all...
[02:19:53.180 --> 02:19:56.180]   It also allows them to compete with a terrestrial cable, right?
[02:19:56.180 --> 02:20:02.180]   I mean, like, because you theoretically could be now, you know, like a T-Mobile can be competing with a Comcast.
[02:20:02.180 --> 02:20:08.180]   Because if they can keep that price down, if they can match the same price for that, you know, I now theoretically have a choice.
[02:20:08.180 --> 02:20:13.180]   So you have to have the choice of that 5G distribution over top of instead of using...
[02:20:13.180 --> 02:20:14.180]   Except...
[02:20:14.180 --> 02:20:15.180]   The ones that have had the lock.
[02:20:15.180 --> 02:20:22.180]   Except that substandard is still in the 3GPP forums, and it's probably 3 to 5 years away before it'll be ratified.
[02:20:22.180 --> 02:20:24.180]   And then you have to have the spectrum licenses.
[02:20:24.180 --> 02:20:29.180]   So you have to go out and buy the spectrum licenses from the government that you can run that in.
[02:20:29.180 --> 02:20:33.180]   And then you have to have a base station that you put in on your house that it lets you to do that.
[02:20:33.180 --> 02:20:38.180]   So there's a lot of steps in the middle of that. Yes, it is potentially exciting.
[02:20:38.180 --> 02:20:46.180]   However, the idea that you'll be able to get a gigabit per second is fraught with all sorts of really substantial options.
[02:20:46.180 --> 02:20:51.180]   I think mostly the average person wouldn't notice anything.
[02:20:51.180 --> 02:20:56.180]   If they had a hundred down and 20 up, they'd be like, "No, this is amazing."
[02:20:56.180 --> 02:20:57.180]   You know, like it's not...
[02:20:57.180 --> 02:21:00.180]   You know, until 8K comes out as Justine...
[02:21:00.180 --> 02:21:06.180]   Have you seen it actually any true 8K content on your 8K TV?
[02:21:06.180 --> 02:21:11.180]   They did have some 8K content that was available that I could watch on it, but as far as...
[02:21:11.180 --> 02:21:13.180]   Was it like a butterfly?
[02:21:13.180 --> 02:21:14.180]   It was mostly like nature.
[02:21:14.180 --> 02:21:15.180]   Yeah, yeah.
[02:21:15.180 --> 02:21:17.180]   It looks amazing.
[02:21:17.180 --> 02:21:20.180]   But again, I watch a lot of my content on my phone.
[02:21:20.180 --> 02:21:23.180]   So 8K content for me on my phone is going to be...
[02:21:23.180 --> 02:21:25.180]   It's not that much.
[02:21:25.180 --> 02:21:26.180]   You know, I was like...
[02:21:26.180 --> 02:21:33.180]   But even looking at my analytics and stuff like on YouTube, it's like most people watch content on the phones, at least my audience.
[02:21:33.180 --> 02:21:34.180]   Right.
[02:21:34.180 --> 02:21:40.180]   I was kind of pooing 8K until I was at NAB and they showed the Sony booth.
[02:21:40.180 --> 02:21:46.180]   They should just... I have no idea why Sony doesn't show this at Best Buy and so on and so forth,
[02:21:46.180 --> 02:21:53.180]   but they had this giant LED wall that was 8K HDR, 120 frames a second.
[02:21:53.180 --> 02:21:57.180]   And it literally made me sick.
[02:21:57.180 --> 02:21:58.180]   No, no, no, no.
[02:21:58.180 --> 02:22:06.180]   Because when they move the camera, I realized that my brain could no longer process the difference between reality and what it was looking at.
[02:22:06.180 --> 02:22:09.180]   And so it was like, you're moving the camera, but I'm not moving.
[02:22:09.180 --> 02:22:13.180]   You know, like so my inner ear and my eye suddenly, just the same problem that you have with VR,
[02:22:13.180 --> 02:22:18.180]   except when I was looking at a screen, it only happened when I walked close enough to the screen where it, you know, got my whole periphery.
[02:22:18.180 --> 02:22:22.180]   That it became this problem, but I realized that that is the...
[02:22:22.180 --> 02:22:23.180]   Of course that.
[02:22:23.180 --> 02:22:24.180]   And I think that that is where we settle.
[02:22:24.180 --> 02:22:32.180]   I think that 108K, 120 frames per second HDR is where we'll get to that point and then we're not going to...
[02:22:32.180 --> 02:22:35.180]   Other than crazy things, it won't get any further than that.
[02:22:35.180 --> 02:22:37.180]   Well, like the LG Uber TVs.
[02:22:37.180 --> 02:22:42.180]   So I have like one of those, like in my office and it's so crazy because it's right next to two windows.
[02:22:42.180 --> 02:22:48.180]   So it's in the middle and when you put like a fake window on it, you can't even tell that it's not like it's a TV.
[02:22:48.180 --> 02:22:51.180]   Like it just looks like there's a window in the middle of my window.
[02:22:51.180 --> 02:22:56.180]   So it's like things are getting so realistic that, you know, when people talk about like video games and things like that,
[02:22:56.180 --> 02:23:01.180]   like if you are actually living in these worlds now and it's crazy.
[02:23:01.180 --> 02:23:02.180]   And it'll be interesting.
[02:23:02.180 --> 02:23:07.180]   I really wanted to see... I don't think I'm going to end up getting to see it at one of the Dolby theaters,
[02:23:07.180 --> 02:23:15.180]   but the new Will Smith movie had... They did it in 4K 120 frames per second.
[02:23:15.180 --> 02:23:18.180]   And I really wanted to see it in high frame, right?
[02:23:18.180 --> 02:23:24.180]   But it's not... There's only like 10 theaters in the country that can actually play it.
[02:23:24.180 --> 02:23:32.180]   So yeah, so it's a... Now Microsoft, speaking of movies, Microsoft stored the entire Superman movie on a piece of glass.
[02:23:32.180 --> 02:23:33.180]   Why is that important?
[02:23:33.180 --> 02:23:36.180]   Well, in theory, because it's going to be able to last.
[02:23:36.180 --> 02:23:37.180]   Yeah, I mean, that's the key.
[02:23:37.180 --> 02:23:43.180]   The thing is of course that, you know, we used to talk about CDs being such and such and turns out they only last 30 to 40 years
[02:23:43.180 --> 02:23:45.180]   before the substrate starts to rot.
[02:23:45.180 --> 02:23:48.180]   And we've got the same problem with magnetic tapes.
[02:23:48.180 --> 02:23:49.180]   And drives.
[02:23:49.180 --> 02:23:51.180]   And drives, magnetic drives.
[02:23:51.180 --> 02:23:52.180]   And so we have this problem of storing it.
[02:23:52.180 --> 02:23:57.180]   And in theory, because the difference between theory and reality is often quite substantial,
[02:23:57.180 --> 02:23:59.180]   this should last for quite a while.
[02:23:59.180 --> 02:24:02.180]   In a thousand years, we'll know whether it really lasts for a thousand years.
[02:24:02.180 --> 02:24:03.180]   You know, like that's...
[02:24:03.180 --> 02:24:08.180]   But when you used to buy silver and gold CDs and the silver was the cheap ones that would only last two to three years
[02:24:08.180 --> 02:24:11.180]   and the gold ones were meant to last 10 to 15 and all that sort of stuff.
[02:24:11.180 --> 02:24:12.180]   Right.
[02:24:12.180 --> 02:24:17.180]   I think this is interesting too, because there's obviously here in Los Angeles, you know, fires is a huge concern.
[02:24:17.180 --> 02:24:22.180]   So, you know, I've bought fireproof cabinets before and I'm like, well, if I'm putting my hard drives in here,
[02:24:22.180 --> 02:24:24.180]   that's not going to make that much of a difference.
[02:24:24.180 --> 02:24:27.180]   It's fire resistant, but the heat is still going to melt whatever's inside of it.
[02:24:27.180 --> 02:24:32.180]   So even having something that's stored in glass, obviously that would melt at a much higher temperature.
[02:24:32.180 --> 02:24:36.180]   So I think that's pretty great that, yeah, it will last way longer.
[02:24:36.180 --> 02:24:38.180]   Yeah, I have a...
[02:24:38.180 --> 02:24:42.180]   We've had to think about it because the fires didn't get to our house, but, you know, they start...
[02:24:42.180 --> 02:24:44.180]   last year's fires got within a couple miles.
[02:24:44.180 --> 02:24:48.180]   And so there's been a lot of discussion about that and I will say that I...
[02:24:48.180 --> 02:24:52.180]   It got me thinking about that process of we have a go case.
[02:24:52.180 --> 02:24:55.180]   You know, like when I did a lot of travel, there was always a go bag.
[02:24:55.180 --> 02:24:57.180]   You know, so you had a go bag that was always all my...
[02:24:57.180 --> 02:25:00.180]   Everything I needed for that thing, I had to add like three things and I'd be gone.
[02:25:00.180 --> 02:25:03.180]   And literally when I got home, I would immediately pack that bag.
[02:25:03.180 --> 02:25:07.180]   Like I'd wash all my clothes and pack the bag, you know, but within hours.
[02:25:07.180 --> 02:25:10.180]   So that I just was always always had a bag that was ready to go.
[02:25:10.180 --> 02:25:13.180]   And so I built this...
[02:25:13.180 --> 02:25:20.180]   Or in the process of building out this go case that is basically if there's a fire and we have to leave in 15 minutes,
[02:25:20.180 --> 02:25:22.180]   you just grab that one thing.
[02:25:22.180 --> 02:25:24.180]   And it's got a cap of all that.
[02:25:24.180 --> 02:25:27.180]   But one of the things for photos, for instance, I'm putting...
[02:25:27.180 --> 02:25:32.180]   While I'm uploading them to the cloud and putting them in two different places, I'm also printing them.
[02:25:32.180 --> 02:25:33.180]   You know, on our kind of...
[02:25:33.180 --> 02:25:34.180]   That's a good idea.
[02:25:34.180 --> 02:25:38.180]   You know, just so I have my most important photos, you know, in that.
[02:25:38.180 --> 02:25:43.180]   But I think that all of us have to think about the storage stuff because, you know, I have videos that I no longer have anymore.
[02:25:43.180 --> 02:25:46.180]   Because I left them on a CD and then I pulled them out.
[02:25:46.180 --> 02:25:48.180]   And then the CD is dead.
[02:25:48.180 --> 02:25:53.180]   I think the interesting part here is too, is I wonder how many people are ready to handle cold data.
[02:25:53.180 --> 02:26:01.180]   So people who do video, like I suspect Justine and yourself, is that you are used to storing stuff and then saying I'm done with that locket away.
[02:26:01.180 --> 02:26:02.180]   I'm finished.
[02:26:02.180 --> 02:26:07.180]   But I wonder how many ordinary people would think about this idea of, I copy this to this thing.
[02:26:07.180 --> 02:26:08.180]   And that's it.
[02:26:08.180 --> 02:26:09.180]   It's written once and I'm done with it.
[02:26:09.180 --> 02:26:11.180]   There's cold data idea that I'm storing that forever.
[02:26:11.180 --> 02:26:14.180]   Well, I think that there's a lot of times when you want cold data.
[02:26:14.180 --> 02:26:19.180]   You know, like when we finish it, when we work on a show, and the movie is a perfect example, you just don't want it to change.
[02:26:19.180 --> 02:26:21.180]   Like we've decided that that's it.
[02:26:21.180 --> 02:26:22.180]   That's the edit.
[02:26:22.180 --> 02:26:23.180]   That's the edit.
[02:26:23.180 --> 02:26:27.180]   And it's not like you want all the raw data there, but that final version, you want to have it.
[02:26:27.180 --> 02:26:28.180]   I just want that done.
[02:26:28.180 --> 02:26:31.180]   I just want to put it somewhere.
[02:26:31.180 --> 02:26:36.180]   And I think I like the permanency of cutting CDs back in the day.
[02:26:36.180 --> 02:26:40.180]   Because it was just like, I knew that if I sent it to a client, it was what it was.
[02:26:40.180 --> 02:26:43.180]   It's not like getting changed or moved around or all those other things.
[02:26:43.180 --> 02:26:47.180]   So, Justine, do you think you would store on glass?
[02:26:47.180 --> 02:26:49.180]   I would love to actually.
[02:26:49.180 --> 02:26:50.180]   I'm ready to sign me up.
[02:26:50.180 --> 02:26:52.180]   Just mostly for all of my old things.
[02:26:52.180 --> 02:26:54.180]   Like I want to have all of that old archived footage.
[02:26:54.180 --> 02:26:57.180]   I still have a lot of it just all backed up on a server.
[02:26:57.180 --> 02:27:00.180]   And then I also have the Jellyfish server, which is fairly new.
[02:27:00.180 --> 02:27:02.180]   So that's most of my recent stuff in the past two years.
[02:27:02.180 --> 02:27:08.180]   But even that, it's like you can't trust these drives, no matter how many backups of the backups you have.
[02:27:08.180 --> 02:27:14.180]   So if you do have something that is like that, that is way more permanent, like I'm definitely into that.
[02:27:14.180 --> 02:27:16.180]   I think a lot of people would be too.
[02:27:16.180 --> 02:27:17.180]   Yeah.
[02:27:17.180 --> 02:27:18.180]   So I think it'll be interesting.
[02:27:18.180 --> 02:27:22.180]   So we've got a couple things from Apple and Amazon coming up soon.
[02:27:22.180 --> 02:27:25.180]   But Leo has one more set of final words for us.
[02:27:25.180 --> 02:27:27.180]   Hey, I want to interrupt one more time.
[02:27:27.180 --> 02:27:29.180]   I'm going to come back next week and do the show.
[02:27:29.180 --> 02:27:31.180]   Thank you, though, for filling in.
[02:27:31.180 --> 02:27:33.180]   I really appreciate it.
[02:27:33.180 --> 02:27:35.180]   It's nice for me to take a little time off.
[02:27:35.180 --> 02:27:37.180]   But I will be back next week.
[02:27:37.180 --> 02:27:41.180]   I did want to come and talk about Mint Mobile because I use it and I love it.
[02:27:41.180 --> 02:27:44.180]   And it saves me so much money.
[02:27:44.180 --> 02:27:47.180]   You know how wireless bills are just ridiculous?
[02:27:47.180 --> 02:27:50.180]   If you look at your bill lately, it's like...
[02:27:50.180 --> 02:27:53.180]   It seems like it goes up every month.
[02:27:53.180 --> 02:27:58.180]   And I know you're paying too much, unless you're using Mint Mobile already.
[02:27:58.180 --> 02:28:00.180]   Network coverage is better than ever.
[02:28:00.180 --> 02:28:02.180]   It doesn't matter which carrier you use.
[02:28:02.180 --> 02:28:05.180]   So why pay more for the same service?
[02:28:05.180 --> 02:28:08.180]   Mint Mobile, they're what we call an MVNO.
[02:28:08.180 --> 02:28:10.180]   They resell T-Mobile service.
[02:28:10.180 --> 02:28:13.180]   So if T-Mobile is great in your neck of the woods, don't pay.
[02:28:13.180 --> 02:28:15.180]   What am I paying for T-Mobile?
[02:28:15.180 --> 02:28:17.180]   $70, $80, $90 a month?
[02:28:17.180 --> 02:28:22.180]   Mint Mobile could cut your bill down to $15 a month for the same premium coverage.
[02:28:22.180 --> 02:28:24.180]   It's not too good to be true.
[02:28:24.180 --> 02:28:28.180]   They save money by not having stores by doing all the support online.
[02:28:28.180 --> 02:28:30.180]   But you get the same great cell phone service.
[02:28:30.180 --> 02:28:33.180]   I decided I splurged.
[02:28:33.180 --> 02:28:34.180]   I got to...
[02:28:34.180 --> 02:28:39.180]   I'm paying a whole 25 bucks a month for my cell phone service.
[02:28:39.180 --> 02:28:43.180]   Unlimited text and unlimited talking all over the country.
[02:28:43.180 --> 02:28:48.180]   And 12 gigabytes a month, I never go through all of that, but I thought why not?
[02:28:48.180 --> 02:28:51.180]   The trick is I paid all up upfront for a year.
[02:28:51.180 --> 02:28:57.180]   So it was $300 for the year, but that's a year of all of that, 25 bucks a month.
[02:28:57.180 --> 02:28:58.180]   That's it.
[02:28:58.180 --> 02:29:00.180]   300 bucks a year.
[02:29:00.180 --> 02:29:05.180]   You can get even less, 15 bucks a month with that special three month introductory plan.
[02:29:05.180 --> 02:29:11.180]   You get unlimited nationwide talk, you get unlimited text, you get crazy fast for GLTE.
[02:29:11.180 --> 02:29:12.180]   They just...
[02:29:12.180 --> 02:29:16.180]   They reimagined how wireless should work and they pass those savings on to you.
[02:29:16.180 --> 02:29:20.180]   You get to port the number over if you want to keep your same number.
[02:29:20.180 --> 02:29:21.180]   No problem.
[02:29:21.180 --> 02:29:25.180]   And if you're not 100% satisfied, Mint Mobile has you covered.
[02:29:25.180 --> 02:29:27.180]   Seven day money back guarantee.
[02:29:27.180 --> 02:29:29.180]   I love Mint Mobile.
[02:29:29.180 --> 02:29:32.180]   Now you can get literally $15 a month.
[02:29:32.180 --> 02:29:34.180]   Same exact service you're already getting.
[02:29:34.180 --> 02:29:36.180]   It's their three month introductory plan.
[02:29:36.180 --> 02:29:39.180]   They'll ship you the SIM for free, put in your existing phone.
[02:29:39.180 --> 02:29:41.500]   They have phones for sale, but just go to the website.
[02:29:41.500 --> 02:29:43.180]   You can check to see if your phone will work.
[02:29:43.180 --> 02:29:47.340]   I'm using my Mint Mobile with a very nice one plus seven pro.
[02:29:47.340 --> 02:29:49.340]   It's fabulous.
[02:29:49.340 --> 02:29:54.540]   And it just blows me away that that phone is 25 bucks a month.
[02:29:54.540 --> 02:29:57.660]   And my iPhone is 100 bucks a month.
[02:29:57.660 --> 02:29:59.740]   When it just doesn't seem right.
[02:29:59.740 --> 02:30:01.100]   I'm moving everything to Mint Mobile.
[02:30:01.100 --> 02:30:03.260]   You should do Mint Mobile.com/Twick.
[02:30:03.260 --> 02:30:07.480]   Cut your wireless, build a $15 a month with their three month introductory plan at Mint
[02:30:07.480 --> 02:30:10.480]   Mobile.com/Twick.
[02:30:10.480 --> 02:30:12.480]   M-I-N-T, Mint.
[02:30:12.480 --> 02:30:13.480]   Mint afresh, Mint.
[02:30:13.480 --> 02:30:15.480]   Mint Mobile.com/Twick.
[02:30:15.480 --> 02:30:17.480]   Hey, back to the show.
[02:30:17.480 --> 02:30:18.480]   And I'll be back next week.
[02:30:18.480 --> 02:30:19.480]   See you then.
[02:30:19.480 --> 02:30:23.480]   So Apple has reportedly thrilled.
[02:30:23.480 --> 02:30:24.480]   Thrilled.
[02:30:24.480 --> 02:30:28.480]   With the new Apple TV launch drawing millions of viewers on the debut weekend.
[02:30:28.480 --> 02:30:30.480]   Justine, have you watched any of the shows?
[02:30:30.480 --> 02:30:32.480]   I've watched a lot actually.
[02:30:32.480 --> 02:30:33.480]   What do you think?
[02:30:33.480 --> 02:30:37.360]   The Morning Show is honestly an incredible show.
[02:30:37.360 --> 02:30:38.520]   I actually got a press screener.
[02:30:38.520 --> 02:30:40.240]   So I have seen the whole season.
[02:30:40.240 --> 02:30:41.640]   And I can tell you it's amazing.
[02:30:41.640 --> 02:30:44.040]   And it's so powerful.
[02:30:44.040 --> 02:30:48.480]   The performances by Reese and Steve Carell and Jennifer Anderson were just really amazing.
[02:30:48.480 --> 02:30:49.800]   It was such an honest show.
[02:30:49.800 --> 02:30:53.840]   And it's pretty daring for them to touch on the subjects they touched on, especially
[02:30:53.840 --> 02:30:54.840]   in this climate.
[02:30:54.840 --> 02:30:57.960]   But I think it's a show that needed to be out there.
[02:30:57.960 --> 02:31:00.760]   And the reviews were not very good for it.
[02:31:00.760 --> 02:31:03.960]   And I honestly kind of think that the reason is maybe they were being a little bit too
[02:31:03.960 --> 02:31:04.960]   honest.
[02:31:04.960 --> 02:31:08.360]   And a lot of the people writing those reviews didn't like how honest it was.
[02:31:08.360 --> 02:31:09.360]   And I don't know.
[02:31:09.360 --> 02:31:10.360]   I think it was incredible.
[02:31:10.360 --> 02:31:16.920]   There's a couple other shows that are coming out later on that are, I think, very promising.
[02:31:16.920 --> 02:31:18.080]   The truth be told.
[02:31:18.080 --> 02:31:20.840]   It's like a Octavia Spencer.
[02:31:20.840 --> 02:31:23.680]   And she does a crime podcast, which is amazing.
[02:31:23.680 --> 02:31:27.760]   So she's going through, oh my gosh, I'm blanking on the same.
[02:31:27.760 --> 02:31:30.800]   Aaron Paul from Breaking Bad is also in it.
[02:31:30.800 --> 02:31:32.600]   It's a great show.
[02:31:32.600 --> 02:31:36.640]   They also have the Dickinson show, which is kind of like a CW-ish type of show.
[02:31:36.640 --> 02:31:38.400]   I haven't watched that one yet.
[02:31:38.400 --> 02:31:43.600]   I watched a few episodes of C, probably not my favorite, but The Morning Show by far has
[02:31:43.600 --> 02:31:44.600]   been.
[02:31:44.600 --> 02:31:45.600]   It was so nice.
[02:31:45.600 --> 02:31:46.600]   I loved it.
[02:31:46.600 --> 02:31:47.600]   That's great.
[02:31:47.600 --> 02:31:50.560]   So I haven't seen C yet, which I was excited about C and for all mankind.
[02:31:50.560 --> 02:31:52.040]   And I haven't.
[02:31:52.040 --> 02:31:57.200]   The fundamental problem I had was I was promised that this was going to be a family affair.
[02:31:57.200 --> 02:32:00.520]   And then as soon as I turned them on, they were all like MA14, MA, whatever.
[02:32:00.520 --> 02:32:02.320]   And I'm like, I was shocked.
[02:32:02.320 --> 02:32:03.800]   I was like walking up with kids.
[02:32:03.800 --> 02:32:05.600]   And I was like, I was like, I'm all excited to watch them.
[02:32:05.600 --> 02:32:07.280]   And then I saw all these MA, MA, MA.
[02:32:07.280 --> 02:32:09.120]   And I was like, what the?
[02:32:09.120 --> 02:32:13.400]   So as I was on the opposite side of that, where I really was excited about finally a platform
[02:32:13.400 --> 02:32:16.000]   that is just going to play a bunch of stuff that I can actually watch with my family.
[02:32:16.000 --> 02:32:17.320]   That's what I thought too.
[02:32:17.320 --> 02:32:18.320]   Yeah.
[02:32:18.320 --> 02:32:21.320]   And then even watching C that first episode, I was like, oh my gosh, I hope there's no
[02:32:21.320 --> 02:32:23.280]   children watching this episode.
[02:32:23.280 --> 02:32:27.160]   But even The Morning Show, it definitely, I mean, the language and everything was definitely
[02:32:27.160 --> 02:32:28.480]   way more mature.
[02:32:28.480 --> 02:32:32.200]   But I think it was the Helpsters, which is like the Sesame Street show.
[02:32:32.200 --> 02:32:33.480]   I haven't watched that yet.
[02:32:33.480 --> 02:32:35.920]   But there's also another one, Ghost Rider.
[02:32:35.920 --> 02:32:38.800]   When I was growing up, that was one of my favorite shows.
[02:32:38.800 --> 02:32:41.480]   So I'm glad to see that kind of get a reboot.
[02:32:41.480 --> 02:32:45.120]   But I spent way more time watching Apple TV than I thought I was going to.
[02:32:45.120 --> 02:32:46.120]   I haven't.
[02:32:46.120 --> 02:32:50.360]   Because of that, the vast majority, you know, as when you have a family, the vast majority
[02:32:50.360 --> 02:32:54.480]   of my viewing habits relate to what we all watched together.
[02:32:54.480 --> 02:32:58.280]   So I haven't had as much time to watch through it.
[02:32:58.280 --> 02:33:01.120]   My wife tried to watch C and I think she got through about the first 20 minutes.
[02:33:01.120 --> 02:33:02.600]   She said, I watched 10 minutes and I walked away.
[02:33:02.600 --> 02:33:05.520]   And then I came back and watched in the 20 minutes and she's like, okay, I'm done.
[02:33:05.520 --> 02:33:07.440]   Yeah, I think we did the same thing.
[02:33:07.440 --> 02:33:10.040]   It's just, I think it's just too bad.
[02:33:10.040 --> 02:33:12.520]   We're just too bad at the rumor is they spend like the same amount of money.
[02:33:12.520 --> 02:33:15.240]   I mean, they spent a lot of money on that on that show.
[02:33:15.240 --> 02:33:16.240]   Yeah.
[02:33:16.240 --> 02:33:17.240]   Yeah.
[02:33:17.240 --> 02:33:19.040]   No, I did start watching for all mankind, which is a cool concept.
[02:33:19.040 --> 02:33:23.720]   It's basically like, okay, what if Russia landed on the moon instead of the US, which,
[02:33:23.720 --> 02:33:26.800]   I mean, something that I've definitely never thought about, but I think it's a cool concept.
[02:33:26.800 --> 02:33:29.120]   I think they also renewed that for the second season.
[02:33:29.120 --> 02:33:33.960]   They also renewed C for a second season, which I'm not sure how that's going to go, but whatever.
[02:33:33.960 --> 02:33:36.400]   I mean, Jason Momoa was great.
[02:33:36.400 --> 02:33:37.960]   And the morning show also has a second season.
[02:33:37.960 --> 02:33:39.680]   And I think Dickinson as well.
[02:33:39.680 --> 02:33:40.920]   The -- And it's cool, though.
[02:33:40.920 --> 02:33:44.560]   A lot of people were complaining about like the price, but if you buy an iPhone, like you're
[02:33:44.560 --> 02:33:48.280]   going to get a whole year of this for free or any Apple products.
[02:33:48.280 --> 02:33:52.080]   So I think that's, you know, essentially you're getting a free year of the service anyway.
[02:33:52.080 --> 02:33:57.440]   Now, are you as excited about Disney Plus?
[02:33:57.440 --> 02:34:01.880]   I might be a little more excited, actually, because these were all of my favorite shows.
[02:34:01.880 --> 02:34:06.560]   I mean Star Wars and Marvel and obviously the whole Disney collection.
[02:34:06.560 --> 02:34:08.040]   So I can't wait.
[02:34:08.040 --> 02:34:09.040]   I'm very excited.
[02:34:09.040 --> 02:34:10.040]   Yeah.
[02:34:10.040 --> 02:34:12.120]   And there's going to be way more content as well.
[02:34:12.120 --> 02:34:13.120]   Yeah.
[02:34:13.120 --> 02:34:18.080]   I think that Disney, you know, I will admit that I tweeted some unhappy words about another
[02:34:18.080 --> 02:34:19.760]   subscription service that I didn't want to do.
[02:34:19.760 --> 02:34:23.200]   But as I got closer and as you saw it in more detail, you know, as it got closer and closer
[02:34:23.200 --> 02:34:25.440]   and closer, you're probably going to get it.
[02:34:25.440 --> 02:34:28.760]   Their Twitter bomb was amazing.
[02:34:28.760 --> 02:34:33.040]   It did get a lot of -- A lot of -- I missed this.
[02:34:33.040 --> 02:34:34.040]   What was it?
[02:34:34.040 --> 02:34:39.280]   It was -- It was -- They -- A couple -- Last week or a couple weeks ago, they launched -- They
[02:34:39.280 --> 02:34:49.520]   basically they tweeted out every single thing that will be on their service in order of
[02:34:49.520 --> 02:34:53.800]   when it was released each one as a tweet.
[02:34:53.800 --> 02:34:55.120]   So -- Disney Plus did?
[02:34:55.120 --> 02:34:56.120]   Yes.
[02:34:56.120 --> 02:34:57.720]   So it started -- Oh my gosh.
[02:34:57.720 --> 02:35:09.840]   -- at Snow White and then like four -- four -- It took them hours to tweet through every
[02:35:09.840 --> 02:35:14.840]   single 500 plus things that will be on the show.
[02:35:14.840 --> 02:35:17.080]   It was an amazing event.
[02:35:17.080 --> 02:35:18.440]   I can't believe I missed this.
[02:35:18.440 --> 02:35:25.480]   Well, you go back and -- I was probably watching Apple TV, which is -- I spent a good few days.
[02:35:25.480 --> 02:35:26.480]   So here's the question.
[02:35:26.480 --> 02:35:27.480]   Here's the question.
[02:35:27.480 --> 02:35:29.360]   And Greg, I'm going to come to you with the same question.
[02:35:29.360 --> 02:35:32.760]   But for Justine, eventually we're going to have to make its choice.
[02:35:32.760 --> 02:35:34.120]   You know, like, well, maybe we don't.
[02:35:34.120 --> 02:35:37.120]   I mean, you spend as much money as you spend on cable and you end up with all of them,
[02:35:37.120 --> 02:35:38.120]   right?
[02:35:38.120 --> 02:35:42.640]   But if you're going to choose, let's say, five services, what are the services that you
[02:35:42.640 --> 02:35:43.640]   choose?
[02:35:43.640 --> 02:35:46.760]   I mean, we're talking like music streaming as well.
[02:35:46.760 --> 02:35:52.920]   -- No, just -- just -- I mean, I do watch Netflix, but I also have five people under my account.
[02:35:52.920 --> 02:35:57.640]   So I am now responsible for five other people's accounts, so I can never give it a Netflix.
[02:35:57.640 --> 02:35:59.800]   So probably I would say Netflix.
[02:35:59.800 --> 02:36:03.640]   And then with Disney Plus, do you also get Hulu, correct?
[02:36:03.640 --> 02:36:05.160]   -- I think correct.
[02:36:05.160 --> 02:36:12.960]   They have a service where you can get Disney Plus, Hulu, and ESPN Plus for, I believe,
[02:36:12.960 --> 02:36:13.960]   $15 a month.
[02:36:13.960 --> 02:36:15.880]   -- Oh, so it's like a package deal.
[02:36:15.880 --> 02:36:19.680]   So I mean, I think that's one of the things where you find the best package deals.
[02:36:19.680 --> 02:36:23.200]   So I mean, that's pretty interesting because I also have Hulu.
[02:36:23.200 --> 02:36:26.000]   So if I get Disney Plus, I can also package that in.
[02:36:26.000 --> 02:36:29.560]   I don't -- I think just a lot of people kind of hop services.
[02:36:29.560 --> 02:36:34.280]   They watch a bunch of shows one month on Netflix or for a few months, switch to Hulu, cancel
[02:36:34.280 --> 02:36:36.480]   that and kind of just hop back and forth.
[02:36:36.480 --> 02:36:38.080]   And I think that's an option.
[02:36:38.080 --> 02:36:41.760]   But I wonder if there's a way to package these things in to give you a better, lower price
[02:36:41.760 --> 02:36:43.080]   if you stay longer.
[02:36:43.080 --> 02:36:44.080]   I'm not sure.
[02:36:44.080 --> 02:36:49.200]   Yeah, well, I mean, I'm not smart enough to package it, like going to jump in and out.
[02:36:49.200 --> 02:36:51.280]   I mean, I just have the subscriptions.
[02:36:51.280 --> 02:36:57.360]   For me, I have my wife likes a lot of the competition shows.
[02:36:57.360 --> 02:36:59.600]   So you think you can dance and stuff like that.
[02:36:59.600 --> 02:37:04.160]   So we have Hulu mostly to take care of her wanting to watch those shows.
[02:37:04.160 --> 02:37:06.960]   I watch for broadcast research primarily.
[02:37:06.960 --> 02:37:08.640]   I don't think I'd pay for it otherwise.
[02:37:08.640 --> 02:37:12.920]   But I have YouTube TV because it is the -- if you're researching broadcasters and you're
[02:37:12.920 --> 02:37:16.920]   researching graphics and you're researching stuff like that for me, being able to DVR
[02:37:16.920 --> 02:37:18.440]   just everything, you know, just go down.
[02:37:18.440 --> 02:37:19.960]   I just want to DVR all the shows.
[02:37:19.960 --> 02:37:21.880]   And then I go back and I can, you know, collect them.
[02:37:21.880 --> 02:37:26.000]   I don't know, again, I don't think I watch enough broadcast TV to justify $50 a month
[02:37:26.000 --> 02:37:28.200]   if I didn't do that.
[02:37:28.200 --> 02:37:29.760]   Apple TV I think is a given for me.
[02:37:29.760 --> 02:37:32.440]   Disney is a kind of a given for me.
[02:37:32.440 --> 02:37:35.080]   Netflix is -- I have a hard time.
[02:37:35.080 --> 02:37:36.080]   My wife's funny.
[02:37:36.080 --> 02:37:37.920]   She's like, why are we still paying for Netflix?
[02:37:37.920 --> 02:37:41.760]   She doesn't -- I don't know when the last time she's watched any Netflix.
[02:37:41.760 --> 02:37:48.360]   I think it was the last Jim Gaffigan thing was the last time she saw it.
[02:37:48.360 --> 02:37:51.760]   But -- and then Amazon Prime just comes with your Amazon Prime.
[02:37:51.760 --> 02:37:52.760]   So you don't think about that one.
[02:37:52.760 --> 02:37:54.400]   That one kind of like just comes packaged.
[02:37:54.400 --> 02:37:57.440]   And I guess -- I kind of feel like I wonder if Apple is just going to keep on doing that
[02:37:57.440 --> 02:38:02.560]   where as long as you keep on buying Apple products, you never actually pay for it.
[02:38:02.560 --> 02:38:05.400]   But then they account for it as a subscription.
[02:38:05.400 --> 02:38:07.360]   Because I don't think -- even though they're giving us free subscriptions, I don't think
[02:38:07.360 --> 02:38:08.600]   that's how it's going to be accounted for.
[02:38:08.600 --> 02:38:09.600]   I think that they're going to --
[02:38:09.600 --> 02:38:10.600]   That's true.
[02:38:10.600 --> 02:38:11.600]   I mean, I also have Apple Arcade.
[02:38:11.600 --> 02:38:13.440]   And you paid less for your phone.
[02:38:13.440 --> 02:38:14.440]   What?
[02:38:14.440 --> 02:38:15.440]   Go ahead.
[02:38:15.440 --> 02:38:17.240]   So it's like I also have Apple Arcade and then Apple News and Apple Music.
[02:38:17.240 --> 02:38:18.240]   So this is like Apple Arcade.
[02:38:18.240 --> 02:38:19.240]   How do you like Apple Arcade?
[02:38:19.240 --> 02:38:20.240]   It's cool.
[02:38:20.240 --> 02:38:23.160]   I mean, I think it's fun just mostly because you can download the games and you don't have
[02:38:23.160 --> 02:38:27.600]   to worry about having a connection, which is what you run into with every other game.
[02:38:27.600 --> 02:38:29.920]   And they also have so many like in-app purchases.
[02:38:29.920 --> 02:38:34.120]   So that free game that you purchase, you've just spent $500 on extra credits.
[02:38:34.120 --> 02:38:38.400]   So you know, having just that subscription base to know that I'm not going to be tricked
[02:38:38.400 --> 02:38:41.760]   into having to pay little extras is really great.
[02:38:41.760 --> 02:38:47.440]   My kids are -- especially my son who's sitting right here is a huge fan of Apple Arcade.
[02:38:47.440 --> 02:38:49.520]   He's played it a lot.
[02:38:49.520 --> 02:38:50.520]   It's fun.
[02:38:50.520 --> 02:38:51.680]   Has he played Sneaky Sasquatch?
[02:38:51.680 --> 02:38:53.240]   Because that's me and my sister's favorite.
[02:38:53.240 --> 02:38:54.920]   Oh no, he gave me the no.
[02:38:54.920 --> 02:38:56.720]   He hasn't played the Sneaky Sasquatch.
[02:38:56.720 --> 02:38:57.720]   It's really fun.
[02:38:57.720 --> 02:38:58.720]   Yeah, it's pretty fun.
[02:38:58.720 --> 02:39:00.000]   It plays the golf one a lot.
[02:39:00.000 --> 02:39:01.800]   What's the golf one?
[02:39:01.800 --> 02:39:02.800]   What's the golf?
[02:39:02.800 --> 02:39:03.800]   What's the golf?
[02:39:03.800 --> 02:39:04.800]   What's the golf?
[02:39:04.800 --> 02:39:06.360]   That one's a very popular one in the house.
[02:39:06.360 --> 02:39:08.080]   Mostly just guy -- I just walked by and I see it.
[02:39:08.080 --> 02:39:09.080]   That's all I know.
[02:39:09.080 --> 02:39:10.080]   How about you, Greg?
[02:39:10.080 --> 02:39:12.120]   Well, I get Amazon Prime.
[02:39:12.120 --> 02:39:13.120]   All right.
[02:39:13.120 --> 02:39:16.520]   Just because I don't watch it because there's nothing in it.
[02:39:16.520 --> 02:39:22.080]   In the UK, very different packaging and very different content, right?
[02:39:22.080 --> 02:39:23.760]   Netflix is almost identical to what it is here.
[02:39:23.760 --> 02:39:25.240]   No, it varies quite substantially.
[02:39:25.240 --> 02:39:28.760]   There's a lot of shows that you get here that we don't get in the UK version.
[02:39:28.760 --> 02:39:31.720]   I get Netflix, but I only get it for my wife and my daughters.
[02:39:31.720 --> 02:39:34.120]   Not so much for me.
[02:39:34.120 --> 02:39:40.040]   And then we get free access to the local TV channels in the UK, which are actually quite
[02:39:40.040 --> 02:39:41.040]   good.
[02:39:41.040 --> 02:39:48.240]   Unlike the US, where a lot of the Frito Air stuff is less than excellent, shall we say?
[02:39:48.240 --> 02:39:52.760]   And so most people feel that paying for cable subscriptions or whatever is worthwhile.
[02:39:52.760 --> 02:39:53.760]   So that's it.
[02:39:53.760 --> 02:39:55.400]   I'm not probably not going to pay for anything else.
[02:39:55.400 --> 02:39:57.360]   I wouldn't watch anything that Disney puts out.
[02:39:57.360 --> 02:40:01.200]   I'm kind of done with Marvel and superhero movies.
[02:40:01.200 --> 02:40:02.480]   I don't even know if that's even possible for me.
[02:40:02.480 --> 02:40:03.480]   I just watched --
[02:40:03.480 --> 02:40:04.800]   I know I love it.
[02:40:04.800 --> 02:40:08.880]   I found out that the kids hadn't seen X-Men, so we started down the X-Men path.
[02:40:08.880 --> 02:40:09.880]   You know, like --
[02:40:09.880 --> 02:40:10.880]   That's great.
[02:40:10.880 --> 02:40:11.880]   You haven't seen it yet?
[02:40:11.880 --> 02:40:13.880]   Like, I thought we saw everything and they're like, "We haven't seen it."
[02:40:13.880 --> 02:40:14.880]   I'm like, "Oh, I just did that."
[02:40:14.880 --> 02:40:18.160]   So I'm not the right person to ask is what I'm trying to say.
[02:40:18.160 --> 02:40:19.640]   I don't get a lot of time to watch TV.
[02:40:19.640 --> 02:40:23.800]   I spend a lot of time working and researching and stuff, so.
[02:40:23.800 --> 02:40:25.200]   For me, it's travel.
[02:40:25.200 --> 02:40:26.200]   And then family.
[02:40:26.200 --> 02:40:27.200]   Yeah, exactly.
[02:40:27.200 --> 02:40:28.200]   When I --
[02:40:28.200 --> 02:40:33.440]   I remember there was some quarterly report where Netflix said we don't see any pop-ups
[02:40:33.440 --> 02:40:35.720]   and the possibility that we're going to download -- we're going to let people download the
[02:40:35.720 --> 02:40:36.720]   videos.
[02:40:36.720 --> 02:40:37.720]   I remember that.
[02:40:37.720 --> 02:40:38.720]   That was like four or five years ago.
[02:40:38.720 --> 02:40:40.480]   They were like, "No, never going to happen."
[02:40:40.480 --> 02:40:44.760]   And now 90% of what I watch on Netflix is because I downloaded and I watch it on a plane.
[02:40:44.760 --> 02:40:47.080]   Yeah, see, I just don't watch video at all.
[02:40:47.080 --> 02:40:52.560]   I don't watch -- I do watch occasionally, but it's like -- if I watched a video for two
[02:40:52.560 --> 02:40:56.640]   or three hours a week, that would be big week on TV consumption for me.
[02:40:56.640 --> 02:40:57.640]   Yeah.
[02:40:57.640 --> 02:41:00.680]   I also feel like I have to just to be updated on what people are talking about.
[02:41:00.680 --> 02:41:04.680]   I mean, I love superhero movies, so the whole Marvel universe -- I mean, having that on
[02:41:04.680 --> 02:41:05.680]   Netflix was amazing.
[02:41:05.680 --> 02:41:09.920]   Like, all of the extra seasons that they do shows like Daredevil.
[02:41:09.920 --> 02:41:10.920]   So great.
[02:41:10.920 --> 02:41:11.920]   So like, those types of things.
[02:41:11.920 --> 02:41:15.440]   I love that it's just expanding that universe and going further into it.
[02:41:15.440 --> 02:41:18.560]   So I'm excited for whatever Disney+ does next.
[02:41:18.560 --> 02:41:23.720]   I think that the number one thing I'm interested in for Disney is Mandalorian.
[02:41:23.720 --> 02:41:26.080]   Yes, that's going to be incredible.
[02:41:26.080 --> 02:41:28.560]   Like, can we just like release all of these at the same time?
[02:41:28.560 --> 02:41:32.960]   Because I like that just mass consumption of just doing nothing for a day and making
[02:41:32.960 --> 02:41:34.960]   up for it the next day.
[02:41:34.960 --> 02:41:42.320]   Because it's back to -- I remember when we -- I always stayed behind for a long time,
[02:41:42.320 --> 02:41:47.800]   like 24, and we'd watch three or four of them at a time, you know, at night.
[02:41:47.800 --> 02:41:52.520]   And in a lot of ways, a lot of times it's much easier to keep track of, you know, keep
[02:41:52.520 --> 02:41:53.520]   track of what's happening.
[02:41:53.520 --> 02:41:54.680]   A whole week up.
[02:41:54.680 --> 02:41:58.560]   You know, like, it's -- this whole week apart is just this really hard thing to manage now
[02:41:58.560 --> 02:42:01.800]   because you're used to just watching all the episodes all one after the other.
[02:42:01.800 --> 02:42:03.600]   And so it's -- I liked it better.
[02:42:03.600 --> 02:42:07.600]   I think I like "Enjoyed Game of Thrones" better -- well, I enjoyed better in the early
[02:42:07.600 --> 02:42:09.360]   seasons period.
[02:42:09.360 --> 02:42:12.640]   But anyway, not that I'm bitter about how I did.
[02:42:12.640 --> 02:42:18.440]   Sorry, I didn't -- You didn't see it, so you didn't have to deal with the -- the
[02:42:18.440 --> 02:42:21.280]   horribleness of the last season.
[02:42:21.280 --> 02:42:23.960]   I'm sorry, I'm -- It's a struggle.
[02:42:23.960 --> 02:42:26.040]   Do you feel the same way, Justine?
[02:42:26.040 --> 02:42:30.920]   I mean, so it's weird because I watched a few seasons of Game of Thrones, and then I just
[02:42:30.920 --> 02:42:35.520]   like stopped watching it, and then I watched like the last -- I guess the last season.
[02:42:35.520 --> 02:42:38.120]   So I miss -- No, you missed the seasons in between.
[02:42:38.120 --> 02:42:39.720]   So there's the work that we did -- I know.
[02:42:39.720 --> 02:42:43.760]   The work that we did as viewers for, you know, trying to keep track of all the pieces.
[02:42:43.760 --> 02:42:47.400]   And you got to -- the worst part was, is my wife and I got into this thing in the last
[02:42:47.400 --> 02:42:51.120]   season because we were so excited about the last season that we were watching between
[02:42:51.120 --> 02:42:55.320]   each episode in the last season, we were watching the old ones.
[02:42:55.320 --> 02:42:59.560]   So we were watching Game of Thrones like one or two every night, you know, to get -- to
[02:42:59.560 --> 02:43:02.080]   make sure that we totally understood all the bits and pieces.
[02:43:02.080 --> 02:43:08.040]   I think that made it worse because the bad writing became much much -- it was in technicolor.
[02:43:08.040 --> 02:43:13.520]   You know, like, you know, like of what the -- of the -- of how bad it had gotten.
[02:43:13.520 --> 02:43:19.080]   So anyway, but one thing we didn't list, which I think is partially the fault of that
[02:43:19.080 --> 02:43:20.920]   show, is HBO.
[02:43:20.920 --> 02:43:22.160]   I'm not interested.
[02:43:22.160 --> 02:43:24.800]   Are you -- are you going to subscribe to HBO?
[02:43:24.800 --> 02:43:25.800]   Justine?
[02:43:25.800 --> 02:43:29.600]   I mean, I think I get it because I actually do still have cable for some reason because
[02:43:29.600 --> 02:43:34.080]   it was actually cheaper for me to keep cable than to get rid of cable to keep my internet.
[02:43:34.080 --> 02:43:35.080]   So I just kept it.
[02:43:35.080 --> 02:43:36.680]   So I think I still have HBO Max.
[02:43:36.680 --> 02:43:37.680]   HBO Max.
[02:43:37.680 --> 02:43:41.800]   But you want -- but you're not going to subscribe to the online version for your phone or whatever.
[02:43:41.800 --> 02:43:42.800]   I don't think so.
[02:43:42.800 --> 02:43:45.520]   I mean, I think I still actually can have access to it through my phone.
[02:43:45.520 --> 02:43:47.480]   But I think HBO Max is something specific.
[02:43:47.480 --> 02:43:48.480]   Right, right, right.
[02:43:48.480 --> 02:43:50.880]   Is there a different content than if I have HBO Go?
[02:43:50.880 --> 02:43:51.880]   Yes, yes.
[02:43:51.880 --> 02:43:57.800]   There is content that available to you on HBO Max that will not be available to you on
[02:43:57.800 --> 02:44:01.320]   HBO Go, even though you pay the same amount of money.
[02:44:01.320 --> 02:44:05.440]   I got to draw a line because honestly, like, I don't have time to do all of this watching.
[02:44:05.440 --> 02:44:08.680]   When it's like, I end up getting into that mode of like, all you want to do is watch
[02:44:08.680 --> 02:44:09.680]   content.
[02:44:09.680 --> 02:44:10.680]   But there's just so much.
[02:44:10.680 --> 02:44:13.480]   So it's like, how do you figure out, like, where do you draw the line?
[02:44:13.480 --> 02:44:15.920]   And you're talking about YouTube TV, which is actually really great, too.
[02:44:15.920 --> 02:44:18.040]   I love the DVR feature.
[02:44:18.040 --> 02:44:19.040]   That's my favorite part of the whole thing.
[02:44:19.040 --> 02:44:26.520]   I mean, that's why I have YouTube TV is specifically because of the DVR feature that
[02:44:26.520 --> 02:44:30.200]   I can like, I'm going to be able to go back and probably watch the Stiele game after this
[02:44:30.200 --> 02:44:33.120]   because we missed it because we were doing the show.
[02:44:33.120 --> 02:44:38.960]   So that's a good example.
[02:44:38.960 --> 02:44:43.800]   But I think that HBO really is paying a price for how Game of Thrones turned out.
[02:44:43.800 --> 02:44:44.800]   Like in this rollout.
[02:44:44.800 --> 02:44:45.800]   Yeah.
[02:44:45.800 --> 02:44:51.000]   I think that there's a lot of people that are bummed.
[02:44:51.000 --> 02:44:52.000]   You know about that.
[02:44:52.000 --> 02:44:53.000]   I think it's actually affected.
[02:44:53.000 --> 02:44:55.400]   I know right after Game of Thrones, I canceled HBO.
[02:44:55.400 --> 02:44:58.800]   Like I was just like, wasn't there supposed to be like another Game of Thrones show that
[02:44:58.800 --> 02:45:00.520]   they are key-
[02:45:00.520 --> 02:45:03.520]   There were two, were there three?
[02:45:03.520 --> 02:45:04.520]   I don't know.
[02:45:04.520 --> 02:45:05.520]   I think there was three.
[02:45:05.520 --> 02:45:07.360]   There's three and one has been canceled already.
[02:45:07.360 --> 02:45:08.360]   Okay.
[02:45:08.360 --> 02:45:20.240]   But there's supposed to be two that are still in pre-production, I think.
[02:45:20.240 --> 02:45:21.520]   But they're still trying to work them out.
[02:45:21.520 --> 02:45:24.600]   And I think they have to really figure out how to make sure that they come out well.
[02:45:24.600 --> 02:45:25.600]   Yeah.
[02:45:25.600 --> 02:45:26.600]   I mean, that ended so badly.
[02:45:26.600 --> 02:45:28.800]   And a lot of it had to do with showrunners that didn't work.
[02:45:28.800 --> 02:45:32.400]   I don't think it would have made too much difference how badly it ended.
[02:45:32.400 --> 02:45:34.200]   I think that had an impact.
[02:45:34.200 --> 02:45:39.280]   But I suspect that the show was so bad that more people quit than would have otherwise.
[02:45:39.280 --> 02:45:42.560]   But I suspect a lot of people were only subscribed to HBO for Game of Thrones anyway.
[02:45:42.560 --> 02:45:45.160]   Well, I think there's two things there.
[02:45:45.160 --> 02:45:50.520]   One is that they should have had three more seasons because they tried to pack three seasons
[02:45:50.520 --> 02:45:51.520]   into one.
[02:45:51.520 --> 02:45:53.440]   And I think a lot had to do with the showrunners didn't want to do this any longer because
[02:45:53.440 --> 02:45:54.840]   they didn't know what they were doing.
[02:45:54.840 --> 02:46:01.040]   And I think that if you watch it, they're just the slow trail off since season five, six,
[02:46:01.040 --> 02:46:06.200]   seven, eight, all just slowly fell apart because they just didn't think about it that way.
[02:46:06.200 --> 02:46:08.000]   They didn't, you know, and they're showrunners.
[02:46:08.000 --> 02:46:12.160]   They're not a, you know, Martin, you know, and so, so I think that that was part of the
[02:46:12.160 --> 02:46:13.160]   problem.
[02:46:13.160 --> 02:46:15.080]   And the second problem was they didn't have something to come right after it.
[02:46:15.080 --> 02:46:19.440]   They didn't have another big show, another Game of Thrones that was, you know, this is
[02:46:19.440 --> 02:46:22.160]   something that's what Avengers Endgame felt like to me.
[02:46:22.160 --> 02:46:25.080]   I was watching Avengers Endgame in the back of the plane seat because I didn't see it
[02:46:25.080 --> 02:46:26.080]   when it came out.
[02:46:26.080 --> 02:46:29.280]   And I was watching the actors and the actors just all seemed bored.
[02:46:29.280 --> 02:46:31.480]   And it was just, I was watching.
[02:46:31.480 --> 02:46:33.520]   I thought I was pretty darn good myself.
[02:46:33.520 --> 02:46:37.120]   I was like, there was a couple of times when I had to call somebody who was going through
[02:46:37.120 --> 02:46:41.680]   and I was watching and the actors in the back kind of like going, you know, it was like,
[02:46:41.680 --> 02:46:47.080]   I just was, I found it incredibly tedious by about 90 minutes in going like really is
[02:46:47.080 --> 02:46:48.080]   it not finished yet?
[02:46:48.080 --> 02:46:49.080]   I loved it.
[02:46:49.080 --> 02:46:50.080]   I loved it.
[02:46:50.080 --> 02:46:51.080]   Anyway, so.
[02:46:51.080 --> 02:46:52.080]   Time battle's good.
[02:46:52.080 --> 02:46:55.560]   I thought it was more than a movie.
[02:46:55.560 --> 02:47:04.640]   I thought, well, and I think that this speaks to Disney's power in this area is that MCU
[02:47:04.640 --> 02:47:07.080]   was an incredibly well designed system.
[02:47:07.080 --> 02:47:08.080]   Oh, yes.
[02:47:08.080 --> 02:47:09.080]   No, yes.
[02:47:09.080 --> 02:47:13.440]   You know, a system of individual video, you know, individual movies as well as group movies
[02:47:13.440 --> 02:47:16.840]   and, you know, I, it'll be interesting to see if they can do that again because they
[02:47:16.840 --> 02:47:18.640]   haven't done it very well with Star Wars in my opinion.
[02:47:18.640 --> 02:47:22.200]   I mean, it's, it's, it's done okay, but I think that, you know, I think that they've
[02:47:22.200 --> 02:47:23.720]   had a bunch of missteps in that area.
[02:47:23.720 --> 02:47:26.600]   So it's not like the whole company has a model that works.
[02:47:26.600 --> 02:47:30.320]   It just happened to be that Avengers, you know, they, they were able to figure that
[02:47:30.320 --> 02:47:33.760]   out and I think that they've been able to keep the comic books ruined put characters
[02:47:33.760 --> 02:47:36.440]   together and take them apart and put character together and take them apart.
[02:47:36.440 --> 02:47:41.600]   So they had a template to work off and they could see and so much of the, that whole MCU
[02:47:41.600 --> 02:47:47.800]   thing is predicated on comic book stories and existing, you know, stories, you know,
[02:47:47.800 --> 02:47:51.760]   product that had worked and they just had to respin it and bring it back.
[02:47:51.760 --> 02:47:56.720]   So I think that and, and the audience itself had adapted to that.
[02:47:56.720 --> 02:48:00.640]   They were expecting Spider-Man to appear with Iron Man and then disappear again, right?
[02:48:00.640 --> 02:48:05.840]   So there was that, but I don't know, Avengers Endgame just felt like it was on entirely
[02:48:05.840 --> 02:48:09.000]   predictable train tracks to me and it was just like, but I love that train.
[02:48:09.000 --> 02:48:10.000]   Yeah.
[02:48:10.000 --> 02:48:11.000]   It was great.
[02:48:11.000 --> 02:48:12.160]   It was the closure that we all needed.
[02:48:12.160 --> 02:48:13.160]   Yeah, exactly.
[02:48:13.160 --> 02:48:14.800]   See, they ended well.
[02:48:14.800 --> 02:48:15.800]   That's the whole thing.
[02:48:15.800 --> 02:48:16.800]   They, they, they chose well.
[02:48:16.800 --> 02:48:18.800]   Not that, you know, Game of Thrones chose Port.
[02:48:18.800 --> 02:48:21.400]   I mean, it definitely was very, very long and I watched it.
[02:48:21.400 --> 02:48:23.760]   I made a mistake of going to like the 11 PM showing.
[02:48:23.760 --> 02:48:26.760]   So by the end, I was like, I love this so much, but I'm so tired.
[02:48:26.760 --> 02:48:32.160]   So it was, I was like, oh gosh, it's so long, but I mean, it was, it's great.
[02:48:32.160 --> 02:48:36.080]   It was something that I think, you know, being a fan of the franchise and the characters,
[02:48:36.080 --> 02:48:39.320]   I think it gave everybody, you know, like I said, like the closure that, that everyone
[02:48:39.320 --> 02:48:40.320]   needed.
[02:48:40.320 --> 02:48:41.320]   Yeah, absolutely.
[02:48:41.320 --> 02:48:42.320]   All right.
[02:48:42.320 --> 02:48:44.520]   Well, one last thing to make sure that everyone knows because I think it's important that
[02:48:44.520 --> 02:48:50.560]   people know that this is available Amazon Prime memberships for Veterans Day to celebrate
[02:48:50.560 --> 02:48:51.560]   Veterans Day.
[02:48:51.560 --> 02:48:56.240]   Amazon Prime is discounting Prime subscriptions for Veterans by $40, which I think is a great
[02:48:56.240 --> 02:48:57.240]   move.
[02:48:57.240 --> 02:49:02.760]   I think that every major company should provide Veterans with specific benefits for their,
[02:49:02.760 --> 02:49:03.760]   for their service.
[02:49:03.760 --> 02:49:08.800]   And so I think it's really important that we make sure that Amazon gets the, the,
[02:49:08.800 --> 02:49:11.080]   kudos from that kudos, kudos for that.
[02:49:11.080 --> 02:49:12.720]   You know, I think that that's really great.
[02:49:12.720 --> 02:49:13.720]   Yeah.
[02:49:13.720 --> 02:49:17.520]   And anybody else who thinks they can try and get a free ride, don't, don't screw it up
[02:49:17.520 --> 02:49:18.520]   for everybody else.
[02:49:18.520 --> 02:49:19.520]   Yeah.
[02:49:19.520 --> 02:49:23.160]   Don't, don't, you know, if it just requires you to get up and say I'm a veteran or something,
[02:49:23.160 --> 02:49:24.840]   don't, don't screw it up.
[02:49:24.840 --> 02:49:25.840]   Just, yeah.
[02:49:25.840 --> 02:49:29.040]   But, but definitely I think that more come, you know, and a lot of companies do.
[02:49:29.040 --> 02:49:32.840]   And so I just think it's important that we, that we always make sure that it's clear that
[02:49:32.840 --> 02:49:35.880]   that they're, they're doing something they don't have to do and they're, and they're,
[02:49:35.880 --> 02:49:37.160]   they're making that available.
[02:49:37.160 --> 02:49:40.360]   So, um, so anyway, thanks to Amazon for that.
[02:49:40.360 --> 02:49:42.840]   Justine, where can people find you on the web?
[02:49:42.840 --> 02:49:44.160]   I justine everywhere.
[02:49:44.160 --> 02:49:48.720]   So just come hang out.
[02:49:48.720 --> 02:49:49.720]   She gets there first.
[02:49:49.720 --> 02:49:53.080]   She said that during the show, she registers on all the latest social media platforms and
[02:49:53.080 --> 02:49:54.320]   get this before anybody else.
[02:49:54.320 --> 02:49:55.320]   I know, I know.
[02:49:55.320 --> 02:49:59.320]   It's funny is I was over 10 years ago, I registered the domain vlog university and because I
[02:49:59.320 --> 02:50:02.960]   wanted to do like a little show just talking about like teaching and instructing people
[02:50:02.960 --> 02:50:09.080]   on just making videos, but now 10 years later, we're making an actual conference in Los Angeles.
[02:50:09.080 --> 02:50:12.800]   So it's kind of crazy that something 10 years ago that I thought of, it's now like an actual
[02:50:12.800 --> 02:50:13.800]   real life thing.
[02:50:13.800 --> 02:50:15.480]   So it's, you never know.
[02:50:15.480 --> 02:50:16.480]   When is it?
[02:50:16.480 --> 02:50:21.360]   It's, um, January 31st, February 1st at the Los Angeles Convention Center.
[02:50:21.360 --> 02:50:23.320]   So it's at vloguniversity.com.
[02:50:23.320 --> 02:50:25.680]   Oh, definitely going to check that out.
[02:50:25.680 --> 02:50:26.680]   Very cool.
[02:50:26.680 --> 02:50:30.640]   You have to come teach some lessons because I actually learned from you in the beginning.
[02:50:30.640 --> 02:50:31.640]   So that's how we met.
[02:50:31.640 --> 02:50:32.640]   That's how we met.
[02:50:32.640 --> 02:50:33.640]   It was like, it was amazing.
[02:50:33.640 --> 02:50:35.240]   Come teach some green screen.
[02:50:35.240 --> 02:50:38.320]   Actually, it was funny also because I was the final cut summit and talking to like Mark
[02:50:38.320 --> 02:50:42.920]   Spencer and Steve Martin about being in like the motion book, we recorded green screen
[02:50:42.920 --> 02:50:44.720]   stuff at your studio years ago.
[02:50:44.720 --> 02:50:45.720]   Right.
[02:50:45.720 --> 02:50:47.240]   And it's crazy that that all came back around.
[02:50:47.240 --> 02:50:50.840]   And I also recently did a final cut training with them.
[02:50:50.840 --> 02:50:51.840]   Yeah.
[02:50:51.840 --> 02:50:52.840]   I released the whole tutorial.
[02:50:52.840 --> 02:50:56.120]   So it's a small world, but it's exciting.
[02:50:56.120 --> 02:51:01.640]   Yeah, that's how, that's how just when I was at an, I was at an unconference in Pittsburgh
[02:51:01.640 --> 02:51:08.080]   and I'm from Pittsburgh and so, and I, but it was, Justin was the smartest person in
[02:51:08.080 --> 02:51:09.080]   the class.
[02:51:09.080 --> 02:51:12.200]   She was like, you know, she was the back answering all the, like I was doing a green screen
[02:51:12.200 --> 02:51:18.160]   class and the person that had all the right questions, you know, like, like that was like
[02:51:18.160 --> 02:51:21.040]   obviously thinking about this really hard, not like a little.
[02:51:21.040 --> 02:51:24.320]   And, and so that's how, and then we had to talk afterwards because I was just like, okay,
[02:51:24.320 --> 02:51:25.640]   she really knows what she's talking about.
[02:51:25.640 --> 02:51:29.360]   So anyway, so anyway, it was, it's, it's cool to see us all still doing it in, in some
[02:51:29.360 --> 02:51:30.360]   sort of way.
[02:51:30.360 --> 02:51:31.360]   So it's amazing.
[02:51:31.360 --> 02:51:33.320]   I'd happy to come down and talk about as many things as you'd like me to.
[02:51:33.320 --> 02:51:34.320]   So that was fun.
[02:51:34.320 --> 02:51:35.320]   I wanted to up.
[02:51:35.320 --> 02:51:36.320]   Okay, great.
[02:51:36.320 --> 02:51:37.320]   I was good.
[02:51:37.320 --> 02:51:39.480]   You can find me on Twitter is at a theory of mine.
[02:51:39.480 --> 02:51:41.560]   See what that's it down there on the bottom, right?
[02:51:41.560 --> 02:51:46.000]   And if you're into enterprise IT infrastructure, then we've got a range of podcast channels
[02:51:46.000 --> 02:51:47.200]   that you might be interested into.
[02:51:47.200 --> 02:51:51.240]   If you're not into enterprise IT infrastructure, probably not your bag at all.
[02:51:51.240 --> 02:51:56.720]   So, so if you want to argue about servers and cloud and most importantly data networking
[02:51:56.720 --> 02:52:01.720]   and things like you want to dive in snorkel deep, then we're probably the right place
[02:52:01.720 --> 02:52:02.720]   for you.
[02:52:02.720 --> 02:52:03.720]   Outstanding.
[02:52:03.720 --> 02:52:05.120]   All right, everybody.
[02:52:05.120 --> 02:52:06.120]   This was a marathon.
[02:52:06.120 --> 02:52:08.160]   I thought we could get to three hours, but we didn't quite make it.
[02:52:08.160 --> 02:52:12.280]   Oh, I guess we could, we could, we could, we could just kind of push it around here.
[02:52:12.280 --> 02:52:15.120]   But anyway, thanks for hanging out with us for, for so long.
[02:52:15.120 --> 02:52:18.680]   And we'll see you, I won't see you all next week, but, but someone will because another
[02:52:18.680 --> 02:52:30.560]   Twitter is in the camp.
[02:52:30.560 --> 02:52:46.500]   Thanks for watching.

