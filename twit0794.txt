
[00:00:00.000 --> 00:00:02.660]   It's time for "Dread This Week" in tech.
[00:00:02.660 --> 00:00:05.400]   Cheer Lazar is here.
[00:00:05.400 --> 00:00:08.240]   Brianna Wu is here from The Washington Post.
[00:00:08.240 --> 00:00:09.420]   Heather Kelly is here.
[00:00:09.420 --> 00:00:12.120]   Lots to talk about.
[00:00:12.120 --> 00:00:14.880]   Politics gets gaming.
[00:00:14.880 --> 00:00:17.720]   The iPhone 12 flat edges are cool.
[00:00:17.720 --> 00:00:20.520]   5G, not so much.
[00:00:20.520 --> 00:00:23.360]   We'll also talk about the bot that orders 32,000
[00:00:23.360 --> 00:00:25.720]   McFlurries every hour.
[00:00:25.720 --> 00:00:31.960]   And why is the RIAA taking down GitHub projects?
[00:00:31.960 --> 00:00:33.720]   And should Microsoft let it?
[00:00:33.720 --> 00:00:37.080]   It's all coming up next on Twitch.
[00:00:37.080 --> 00:00:39.840]   This week, a tech comes to you from Twitch's last pass
[00:00:39.840 --> 00:00:40.400]   studios.
[00:00:40.400 --> 00:00:44.360]   You're focused on security, but are your employees last pass
[00:00:44.360 --> 00:00:47.200]   can ensure they are by making access and authentication
[00:00:47.200 --> 00:00:48.080]   seamless?
[00:00:48.080 --> 00:00:50.880]   Whether employees are working in the office or remotely,
[00:00:50.880 --> 00:00:53.840]   visit lasspass.com/twit to learn more.
[00:00:53.840 --> 00:00:56.280]   [MUSIC PLAYING]
[00:00:56.280 --> 00:00:58.080]   Podcasts you love.
[00:00:58.080 --> 00:01:00.640]   From people you trust.
[00:01:00.640 --> 00:01:02.200]   This is Twitch.
[00:01:02.200 --> 00:01:04.960]   [MUSIC PLAYING]
[00:01:04.960 --> 00:01:09.800]   This is Twitch.
[00:01:09.800 --> 00:01:15.520]   This week in tech, episode 794 recorded Sunday, October 25,
[00:01:15.520 --> 00:01:17.000]   2020.
[00:01:17.000 --> 00:01:20.640]   Pulmonary gold disease.
[00:01:20.640 --> 00:01:22.600]   This episode of This Week in Tech
[00:01:22.600 --> 00:01:24.760]   is brought to you by NetSuite.
[00:01:24.760 --> 00:01:29.520]   Get visibility and control over your financials, HR, inventory,
[00:01:29.520 --> 00:01:32.720]   e-commerce, and more with NetSuite by Oracle.
[00:01:32.720 --> 00:01:35.400]   Now is the time to upgrade to the world's number one cloud
[00:01:35.400 --> 00:01:36.160]   business system.
[00:01:36.160 --> 00:01:39.080]   Let NetSuite show you how they could benefit your business
[00:01:39.080 --> 00:01:44.520]   with a free product tour right now at netsuite.com/twit.
[00:01:44.520 --> 00:01:46.760]   And by last pass.
[00:01:46.760 --> 00:01:49.560]   Last pass can help you manage identities and promote good
[00:01:49.560 --> 00:01:53.040]   security behavior while your employees are remote.
[00:01:53.040 --> 00:01:57.240]   Visit lasspass.com/twit to find out how they can help you.
[00:01:57.240 --> 00:01:59.920]   And by ZipRecruiter.
[00:01:59.920 --> 00:02:02.760]   Hiring is challenging, especially with everything else
[00:02:02.760 --> 00:02:04.320]   you have to consider today.
[00:02:04.320 --> 00:02:08.080]   But there's one place where hiring is simple, fast, and smart.
[00:02:08.080 --> 00:02:09.880]   That place is ZipRecruiter.
[00:02:09.880 --> 00:02:15.120]   Try ZipRecruiter for free at ziprecruiter.com/twit.
[00:02:15.120 --> 00:02:18.400]   ZipRecruiter, the smartest way to hire.
[00:02:18.400 --> 00:02:20.720]   And by CashFly.
[00:02:20.720 --> 00:02:24.600]   Give your users the seamless online experience they want.
[00:02:24.600 --> 00:02:28.400]   Power your site or app with CashFly's CDN
[00:02:28.400 --> 00:02:31.280]   and be 30% faster than the competition.
[00:02:31.280 --> 00:02:34.280]   Learn more at twit.cashfly.com.
[00:02:34.280 --> 00:02:42.440]   It's time for Twit.
[00:02:42.440 --> 00:02:45.800]   This week at Tech, the show where we talk about the week's tech
[00:02:45.800 --> 00:02:49.160]   news and we have a fantastic panel for you.
[00:02:49.160 --> 00:02:50.240]   Welcome back.
[00:02:50.240 --> 00:02:56.840]   Shira Lazar from We Are Channel Q, the fabulous QAnon channel.
[00:02:56.840 --> 00:02:57.840]   No.
[00:02:57.840 --> 00:02:58.600]   Sorry.
[00:02:58.600 --> 00:02:59.200]   Wrong.
[00:02:59.200 --> 00:03:00.960]   I got it wrong again.
[00:03:00.960 --> 00:03:02.320]   That's Shira Lazar.
[00:03:02.320 --> 00:03:04.480]   They're cute.
[00:03:04.480 --> 00:03:05.320]   I'm just teasing.
[00:03:05.320 --> 00:03:06.960]   You know that.
[00:03:06.960 --> 00:03:08.440]   It's great to see you.
[00:03:08.440 --> 00:03:09.400]   It's a sound multiple times.
[00:03:09.400 --> 00:03:10.800]   We're on Edge, Leo.
[00:03:10.800 --> 00:03:11.520]   We're all on Edge.
[00:03:11.520 --> 00:03:12.920]   Did you microdose before the show?
[00:03:12.920 --> 00:03:14.440]   I'm just curious.
[00:03:14.440 --> 00:03:17.240]   I have some microdose, but I did not do that today.
[00:03:17.240 --> 00:03:17.520]   OK.
[00:03:17.520 --> 00:03:21.320]   Just checking, trying to get us a read on the whole situation.
[00:03:21.320 --> 00:03:22.480]   [LAUGHTER]
[00:03:22.480 --> 00:03:24.480]   That's not mean.
[00:03:24.480 --> 00:03:27.120]   Well, you never know these days.
[00:03:27.120 --> 00:03:29.040]   Also-- no, please.
[00:03:29.040 --> 00:03:30.680]   I microdose this morning.
[00:03:30.680 --> 00:03:31.960]   It's OK.
[00:03:31.960 --> 00:03:38.360]   Also with us from her new political action committee,
[00:03:38.360 --> 00:03:42.040]   former candidate for Congress, former space cat girl,
[00:03:42.040 --> 00:03:45.560]   now executive director of the Rebellion Pack, Brianna Wu.
[00:03:45.560 --> 00:03:47.040]   Good to see you.
[00:03:47.040 --> 00:03:47.720]   Good to see you.
[00:03:47.720 --> 00:03:50.680]   I will be microdosing afternoon of the term.
[00:03:50.680 --> 00:03:53.760]   I'm just holding off just nine more days.
[00:03:53.760 --> 00:03:56.520]   Yeah, and what you'll be macrodosing on kind of depends
[00:03:56.520 --> 00:03:57.520]   on what happens.
[00:03:57.520 --> 00:03:58.040]   Exactly.
[00:03:58.040 --> 00:03:59.040]   Right.
[00:03:59.040 --> 00:03:59.540]   Right.
[00:03:59.540 --> 00:04:00.560]   It could go either way.
[00:04:00.560 --> 00:04:01.560]   You'd have pray for me.
[00:04:01.560 --> 00:04:04.840]   The heady smell of victory or the agony of defeat.
[00:04:04.840 --> 00:04:07.160]   It could go either way.
[00:04:07.160 --> 00:04:09.600]   We want to welcome somebody brand new to the show.
[00:04:09.600 --> 00:04:12.520]   Really, been trying to get Heather Kelly on for ages,
[00:04:12.520 --> 00:04:13.680]   many years on CNN.
[00:04:13.680 --> 00:04:16.440]   She's now covering tech at The Washington Post.
[00:04:16.440 --> 00:04:17.400]   Welcome.
[00:04:17.400 --> 00:04:19.040]   Heather will be gentle.
[00:04:19.040 --> 00:04:19.800]   Honest.
[00:04:19.800 --> 00:04:21.200]   I promise.
[00:04:21.200 --> 00:04:22.480]   I can't promise the same, but--
[00:04:22.480 --> 00:04:23.280]   Oh, good.
[00:04:23.280 --> 00:04:24.840]   Even better.
[00:04:24.840 --> 00:04:28.280]   I wanted to actually start because Brianna was a game
[00:04:28.280 --> 00:04:30.400]   developer as an expert on game development.
[00:04:30.400 --> 00:04:33.640]   Because a couple of things happened this week
[00:04:33.640 --> 00:04:35.880]   that I thought were fascinating.
[00:04:35.880 --> 00:04:41.680]   Alexandria Ocasio-Cortez, AOC member of Congress from New
[00:04:41.680 --> 00:04:48.360]   York, played a game on Twitch called Among Us.
[00:04:48.360 --> 00:04:49.920]   It's apparently very popular with the kids.
[00:04:49.920 --> 00:04:56.000]   It's got 444,000 streamers watching her play that game.
[00:04:56.000 --> 00:04:58.640]   Is that awesome or what?
[00:04:58.640 --> 00:05:00.200]   It's beyond awesome.
[00:05:00.200 --> 00:05:03.360]   I feel very strongly you've got to meet people where they are.
[00:05:03.360 --> 00:05:05.760]   And this younger generation, they
[00:05:05.760 --> 00:05:09.960]   spend less time watching cable news and more times watching
[00:05:09.960 --> 00:05:11.440]   people play games on Twitch.
[00:05:11.440 --> 00:05:15.040]   So fun fact, I was actually the first congressional candidate
[00:05:15.040 --> 00:05:17.560]   to ever stream on Twitch to fundraise.
[00:05:17.560 --> 00:05:20.360]   And I just think it's absolutely amazing
[00:05:20.360 --> 00:05:23.240]   that she's out there talking to people.
[00:05:23.240 --> 00:05:24.920]   We have to talk at the game itself.
[00:05:24.920 --> 00:05:27.000]   Among Us is so good, Leo.
[00:05:27.000 --> 00:05:29.000]   You would destroy it this game.
[00:05:29.000 --> 00:05:29.600]   So you get--
[00:05:29.600 --> 00:05:31.440]   It's werewolves, basically, right?
[00:05:31.440 --> 00:05:32.000]   It is.
[00:05:32.000 --> 00:05:32.840]   Yeah.
[00:05:32.840 --> 00:05:34.480]   It's voice chatty.
[00:05:34.480 --> 00:05:37.360]   So you get a group of eight people there.
[00:05:37.360 --> 00:05:41.840]   And if you're the imposter, you have to trick them into making
[00:05:41.840 --> 00:05:45.080]   you think you're not the imposter while you sneak up on them
[00:05:45.080 --> 00:05:46.040]   and kill them.
[00:05:46.040 --> 00:05:48.400]   So it's an awesome last.
[00:05:48.400 --> 00:05:49.040]   It's great.
[00:05:49.040 --> 00:05:49.600]   It's great.
[00:05:49.600 --> 00:05:50.120]   I love it.
[00:05:50.120 --> 00:05:52.520]   Well, I discovered this week--
[00:05:52.520 --> 00:05:55.840]   so when the Nintendo Switch came out,
[00:05:55.840 --> 00:06:00.400]   I bought it immediately and played Final Fantasy
[00:06:00.400 --> 00:06:01.880]   for a little while.
[00:06:01.880 --> 00:06:03.800]   Was it Break the Wind or something?
[00:06:03.800 --> 00:06:06.480]   And I played it for a little while.
[00:06:06.480 --> 00:06:09.080]   And then my son, my stepson, who was 17--
[00:06:09.080 --> 00:06:11.200]   he's going to be 18 in about a minute--
[00:06:11.200 --> 00:06:11.840]   took it from me.
[00:06:11.840 --> 00:06:13.280]   And I've never seen it again.
[00:06:13.280 --> 00:06:14.040]   And everyone's smiling.
[00:06:14.040 --> 00:06:15.520]   I'd say, Michael, how's that switch doing?
[00:06:15.520 --> 00:06:16.720]   He said, that's great.
[00:06:16.720 --> 00:06:19.200]   I said, have you ever played Animal Crossing?
[00:06:19.200 --> 00:06:20.080]   He said, yes.
[00:06:20.080 --> 00:06:21.520]   You wouldn't like it.
[00:06:21.520 --> 00:06:25.000]   So finally, you could get him again about--
[00:06:25.000 --> 00:06:26.120]   last week, I looked on Amazon.
[00:06:26.120 --> 00:06:27.440]   Oh my god, I can get a switch again,
[00:06:27.440 --> 00:06:28.800]   because for a while, you couldn't buy one
[00:06:28.800 --> 00:06:29.800]   that we're out of stock.
[00:06:29.800 --> 00:06:32.760]   So I bought one and I immediately put Animal Crossing on it.
[00:06:32.760 --> 00:06:36.040]   And then-- and I've got it right here--
[00:06:36.040 --> 00:06:40.440]   I went to the Biden campaign headquarters.
[00:06:40.440 --> 00:06:42.440]   And this is an island.
[00:06:42.440 --> 00:06:44.560]   The Biden HQ is an island.
[00:06:44.560 --> 00:06:46.320]   It's actually quite a beautiful island.
[00:06:46.320 --> 00:06:48.840]   I'm a little bit jealous.
[00:06:48.840 --> 00:06:51.000]   And you can wander around.
[00:06:51.000 --> 00:06:55.520]   You can buy-- see, I'm wearing a Biden-Harris beanie.
[00:06:55.520 --> 00:07:01.040]   You can't really tell, but I'm also wearing a Kamala tank top.
[00:07:01.040 --> 00:07:03.320]   And-- but the main thing you can do--
[00:07:03.320 --> 00:07:07.080]   and if I could find him, I don't understand quite how this works.
[00:07:07.080 --> 00:07:09.320]   These are canned, I guess.
[00:07:09.320 --> 00:07:10.160]   They're not live.
[00:07:10.160 --> 00:07:13.480]   There's nobody-- I don't think in them live.
[00:07:13.480 --> 00:07:17.120]   Oh, isn't that a cool garden, a red, white, and blue mums
[00:07:17.120 --> 00:07:18.480]   garden?
[00:07:18.480 --> 00:07:22.000]   But somewhere, the candidate is wandering around in here.
[00:07:22.000 --> 00:07:24.840]   And you can get-- I'm going to go over in the rope line.
[00:07:24.840 --> 00:07:27.400]   Maybe he's in the rope line.
[00:07:27.400 --> 00:07:33.720]   And you can pose for selfies with Joe.
[00:07:33.720 --> 00:07:35.280]   He's got his aviator glasses.
[00:07:35.280 --> 00:07:38.240]   I also bought a hat that said no malarkey.
[00:07:38.240 --> 00:07:41.160]   Yeah, he's-- I guess he's taken the--
[00:07:41.160 --> 00:07:41.840]   oh, who's that?
[00:07:41.840 --> 00:07:43.560]   No, that's just a blue mousse.
[00:07:43.560 --> 00:07:48.360]   That's not-- so I thought this was also interesting.
[00:07:48.360 --> 00:07:50.480]   I don't know-- I don't know if there he is.
[00:07:50.480 --> 00:07:51.880]   Hey, Joe!
[00:07:51.880 --> 00:07:55.440]   Let me get my smartphone out so I could--
[00:07:55.440 --> 00:07:57.720]   oh, he always walks away while you're ready to--
[00:07:57.720 --> 00:07:59.040]   let's take a picture.
[00:07:59.040 --> 00:08:00.160]   Zoom in.
[00:08:00.160 --> 00:08:01.200]   Come on.
[00:08:01.200 --> 00:08:02.200]   Come on.
[00:08:02.200 --> 00:08:03.360]   Oh, man.
[00:08:03.360 --> 00:08:04.200]   I'm not really--
[00:08:04.200 --> 00:08:05.040]   He's leaving.
[00:08:05.040 --> 00:08:06.480]   He's going to the beach.
[00:08:06.480 --> 00:08:07.440]   OK, there's a shot.
[00:08:07.440 --> 00:08:09.080]   Me and Joe at the beach.
[00:08:09.080 --> 00:08:10.360]   OK, get the camera back out.
[00:08:10.360 --> 00:08:11.080]   Oh, he's leaving.
[00:08:11.080 --> 00:08:12.000]   Come back, Joe.
[00:08:12.000 --> 00:08:13.280]   Come back.
[00:08:13.280 --> 00:08:16.640]   Do you think this also-- what does this do for a candidate?
[00:08:16.640 --> 00:08:18.440]   Does this also bring-- he's leaving.
[00:08:18.440 --> 00:08:19.800]   He's walking right out of the frame.
[00:08:19.800 --> 00:08:23.880]   I guess I'll get a selfie with a purple mule.
[00:08:23.880 --> 00:08:25.000]   There's my selfie.
[00:08:25.000 --> 00:08:27.880]   That's pathetic.
[00:08:27.880 --> 00:08:28.960]   Is this the same thing?
[00:08:28.960 --> 00:08:30.200]   Is this like Alexandria?
[00:08:30.200 --> 00:08:32.800]   Or I have some pictures I took earlier.
[00:08:32.800 --> 00:08:33.680]   I'll have to go to my--
[00:08:33.680 --> 00:08:35.200]   Be careful, you should one.
[00:08:35.200 --> 00:08:37.640]   No, no, don't worry.
[00:08:37.640 --> 00:08:39.640]   I'm not Captain America.
[00:08:39.640 --> 00:08:41.920]   But I have pictures of him wandering in and out
[00:08:41.920 --> 00:08:43.600]   of the shot also.
[00:08:43.600 --> 00:08:45.920]   He never sticks around, Joe does.
[00:08:45.920 --> 00:08:47.160]   Here I am in the rope line.
[00:08:47.160 --> 00:08:48.040]   There he is.
[00:08:48.040 --> 00:08:49.240]   That's me in the candidate.
[00:08:49.240 --> 00:08:50.640]   Why he's wandering off again.
[00:08:50.640 --> 00:08:53.680]   Yeah, it's a photorealistic representation of both of you.
[00:08:53.680 --> 00:08:54.760]   Yeah.
[00:08:54.760 --> 00:08:59.040]   Hey, as close as I could get with whatever these are called.
[00:08:59.040 --> 00:09:01.360]   Are these weamals or weamals?
[00:09:01.360 --> 00:09:03.440]   That was the Animal Crossing style.
[00:09:03.440 --> 00:09:06.240]   It's not me.
[00:09:06.240 --> 00:09:06.800]   There I am.
[00:09:06.800 --> 00:09:08.640]   And there's always a trash can in the picture.
[00:09:08.640 --> 00:09:11.000]   I don't know why that is.
[00:09:11.000 --> 00:09:15.280]   I think first of all, you have to say the technical level--
[00:09:15.280 --> 00:09:18.400]   this was done by an Animal Crossing pro.
[00:09:18.400 --> 00:09:19.360]   Oh, you can tell.
[00:09:19.360 --> 00:09:19.960]   Yeah, because--
[00:09:19.960 --> 00:09:21.880]   Oh, it's astonishing.
[00:09:21.880 --> 00:09:25.000]   I put probably 100 hours into that game.
[00:09:25.000 --> 00:09:28.920]   And my island just looks like dirt compared to that.
[00:09:28.920 --> 00:09:31.800]   Notice, I did not show my tent.
[00:09:31.800 --> 00:09:34.000]   Right.
[00:09:34.000 --> 00:09:37.480]   So I'm one hand.
[00:09:37.480 --> 00:09:39.120]   I'm kind of unconvinced that anyone
[00:09:39.120 --> 00:09:41.880]   is going to make up their mind about voting.
[00:09:41.880 --> 00:09:43.600]   No, because there's no issues here at all.
[00:09:43.600 --> 00:09:44.040]   At all.
[00:09:44.040 --> 00:09:44.240]   It's not.
[00:09:44.240 --> 00:09:44.880]   Right.
[00:09:44.880 --> 00:09:48.480]   But I also remember a traditional question.
[00:09:48.480 --> 00:09:50.840]   We've asked politicians for a long time.
[00:09:50.840 --> 00:09:53.960]   It's like, who's the person you want to have a beer with more?
[00:09:53.960 --> 00:09:55.560]   And that was famously--
[00:09:55.560 --> 00:09:56.040]   Yeah.
[00:09:56.040 --> 00:09:59.400]   People wanted to have a beer with George Bush more than John
[00:09:59.400 --> 00:10:00.240]   Kerry.
[00:10:00.240 --> 00:10:04.200]   So I think as far as making the Democratic Party
[00:10:04.200 --> 00:10:08.920]   seem more relatable to people, I think this is generally
[00:10:08.920 --> 00:10:09.760]   a smart move.
[00:10:09.760 --> 00:10:13.040]   And I want to see more of it.
[00:10:13.040 --> 00:10:16.080]   In 2016, the Trump campaign was lauded
[00:10:16.080 --> 00:10:18.560]   because they seem to be the only campaign to figure out
[00:10:18.560 --> 00:10:21.200]   how to use Facebook effectively.
[00:10:21.200 --> 00:10:23.160]   And I think a lot of people give credit
[00:10:23.160 --> 00:10:28.960]   to that for his election.
[00:10:28.960 --> 00:10:31.280]   Facebook doesn't seem like Facebook
[00:10:31.280 --> 00:10:34.600]   is the battleground anymore for presidential politics
[00:10:34.600 --> 00:10:37.800]   or any politics.
[00:10:37.800 --> 00:10:39.400]   They made it complicated.
[00:10:39.400 --> 00:10:41.520]   Is it because it's too complicated?
[00:10:41.520 --> 00:10:45.040]   Well, because of all the horrors of 2016
[00:10:45.040 --> 00:10:46.840]   and all the lawsuits and all the cases,
[00:10:46.840 --> 00:10:49.320]   I mean, I think they wanted just to stay away.
[00:10:49.320 --> 00:10:52.520]   And then there was new laws in terms of--
[00:10:52.520 --> 00:10:55.880]   or they're not letting ads run the day of the election
[00:10:55.880 --> 00:10:57.400]   or a week before.
[00:10:57.400 --> 00:10:57.920]   So I don't know.
[00:10:57.920 --> 00:10:59.520]   It just feels like it got complicated.
[00:10:59.520 --> 00:11:01.160]   It wasn't the same game that they were trying to play
[00:11:01.160 --> 00:11:02.280]   in 2016, obviously.
[00:11:02.280 --> 00:11:04.680]   There have been calls for social media
[00:11:04.680 --> 00:11:09.400]   to shut down for the next week.
[00:11:09.400 --> 00:11:10.600]   Just stop.
[00:11:10.600 --> 00:11:12.680]   I don't think Jack Dorsey or Mark Zuckerberg
[00:11:12.680 --> 00:11:16.400]   is going to stop operations.
[00:11:16.400 --> 00:11:20.760]   But that gives you some idea to how much people consider
[00:11:20.760 --> 00:11:26.120]   social media influential, maybe not in a good way, on politics.
[00:11:26.120 --> 00:11:28.760]   I think something that's worth considering
[00:11:28.760 --> 00:11:32.720]   is someone who has a massive ad budget,
[00:11:32.720 --> 00:11:36.760]   and we spend quite a bit of it on Facebook ads.
[00:11:36.760 --> 00:11:38.560]   We can't do it on Twitter anymore,
[00:11:38.560 --> 00:11:40.640]   because Twitter has even IEs.
[00:11:40.640 --> 00:11:42.480]   They've gotten rid of that.
[00:11:42.480 --> 00:11:44.200]   We've looked at doing it on TikTok,
[00:11:44.200 --> 00:11:46.600]   but there's not really an ad model in the same way
[00:11:46.600 --> 00:11:48.760]   it's more content-based over there.
[00:11:48.760 --> 00:11:52.560]   So for someone like us that is literally in the business
[00:11:52.560 --> 00:11:54.240]   of serving out political ads, Facebook--
[00:11:54.240 --> 00:11:55.400]   That's the only place.
[00:11:55.400 --> 00:11:57.280]   It's the only game in town.
[00:11:57.280 --> 00:12:01.200]   So you're basically paying for television, YouTube,
[00:12:01.200 --> 00:12:04.120]   or Facebook, meaning Facebook and Instagram.
[00:12:04.120 --> 00:12:08.360]   So I can say it's very profitable for someone like us.
[00:12:08.360 --> 00:12:10.160]   Is it good for democracy?
[00:12:10.160 --> 00:12:11.440]   I think that's a different question.
[00:12:11.440 --> 00:12:13.000]   Well, it's a very efficient--
[00:12:13.000 --> 00:12:18.000]   Is it harder right now with targeting and with conversions?
[00:12:18.000 --> 00:12:21.680]   Are they making it harder on the political front?
[00:12:21.680 --> 00:12:26.560]   Getting registered to run ads has continually gotten harder,
[00:12:26.560 --> 00:12:29.160]   because I ran for Congress first in 2016.
[00:12:29.160 --> 00:12:30.720]   It was a bar there.
[00:12:30.720 --> 00:12:34.320]   It just keeps getting higher and more difficult
[00:12:34.320 --> 00:12:37.200]   to jump through all Facebook's hoops, which is frustrating
[00:12:37.200 --> 00:12:39.080]   when you're someone that follows the rules.
[00:12:39.080 --> 00:12:41.960]   So we definitely see them cracking down.
[00:12:41.960 --> 00:12:44.080]   Is it having an effect?
[00:12:44.080 --> 00:12:45.840]   I can't really say.
[00:12:45.840 --> 00:12:48.640]   Let me ask Heather this, because we've
[00:12:48.640 --> 00:12:53.560]   talked a lot about the notion that maybe Facebook should
[00:12:53.560 --> 00:12:57.240]   do what Twitter did, which is reject all political ads.
[00:12:57.240 --> 00:12:59.160]   But whenever I mention that, people say,
[00:12:59.160 --> 00:13:02.360]   but here's the problem, is that if you are a candidate
[00:13:02.360 --> 00:13:05.840]   without a strong national presence,
[00:13:05.840 --> 00:13:08.920]   Facebook is actually a tool that can bring many candidates who
[00:13:08.920 --> 00:13:13.360]   would not normally be viable to the attention
[00:13:13.360 --> 00:13:14.680]   of the voting public.
[00:13:14.680 --> 00:13:16.640]   So maybe shutting down political ads
[00:13:16.640 --> 00:13:17.960]   is the wrong thing to do.
[00:13:17.960 --> 00:13:20.560]   Furthermore, if you're savvy enough,
[00:13:20.560 --> 00:13:22.720]   there's plenty of politics on Twitter.
[00:13:22.720 --> 00:13:25.480]   So there's plenty of ways you can create
[00:13:25.480 --> 00:13:27.640]   bot armies and do all sorts of things.
[00:13:27.640 --> 00:13:28.760]   What do you think, Heather?
[00:13:28.760 --> 00:13:30.360]   Is it the right or the wrong thing to do
[00:13:30.360 --> 00:13:32.760]   to shut down political advertising?
[00:13:32.760 --> 00:13:35.920]   I mean, I don't think anybody's ever asked for a full shutdown.
[00:13:35.920 --> 00:13:40.280]   People would like maybe Facebook to be a little harder
[00:13:40.280 --> 00:13:41.320]   to spread, I guess.
[00:13:41.320 --> 00:13:43.400]   Some of the things that Twitter has done
[00:13:43.400 --> 00:13:46.120]   to make things a little more friction.
[00:13:46.120 --> 00:13:47.400]   It's harder to retweet all of a sudden.
[00:13:47.400 --> 00:13:49.120]   They want you to say something with your retweet,
[00:13:49.120 --> 00:13:50.960]   which is way too much pressure.
[00:13:50.960 --> 00:13:52.960]   But so Facebook, they're not taking
[00:13:52.960 --> 00:13:55.360]   any new political ads for the week up to the election,
[00:13:55.360 --> 00:13:59.840]   and then they're stopping political ads after polls close.
[00:13:59.840 --> 00:14:01.200]   That actually seems like a good idea.
[00:14:01.200 --> 00:14:02.760]   A lot of people would like it a little earlier.
[00:14:02.760 --> 00:14:03.520]   I don't know.
[00:14:03.520 --> 00:14:07.240]   When the polls close, it's a very horse out of the barn kind of thing.
[00:14:07.240 --> 00:14:09.160]   Well, maybe not because there's some concern
[00:14:09.160 --> 00:14:14.960]   that if early on in the early voting, one candidate or another
[00:14:14.960 --> 00:14:17.480]   takes a lead, but the full count hasn't come in
[00:14:17.480 --> 00:14:21.480]   because there's so many absentee and mail-in ballots,
[00:14:21.480 --> 00:14:24.440]   that this might be a chance for--
[00:14:24.440 --> 00:14:26.000]   I think people were worried mostly
[00:14:26.000 --> 00:14:30.320]   about the Trump campaign declaring victory inappropriately
[00:14:30.320 --> 00:14:32.680]   and buying up ads on Facebook to do that.
[00:14:32.680 --> 00:14:34.400]   Is that-- I think that's what they're probably
[00:14:34.400 --> 00:14:36.120]   trying to prevent, right?
[00:14:36.120 --> 00:14:37.960]   What do you have ads for after the election?
[00:14:37.960 --> 00:14:39.760]   That's the only thing I could think of.
[00:14:39.760 --> 00:14:41.320]   Well, you just want to sow confusion.
[00:14:41.320 --> 00:14:42.560]   If you're going to have lawsuits,
[00:14:42.560 --> 00:14:45.400]   you want to win over public opinion.
[00:14:45.400 --> 00:14:47.720]   And the reason they're worried is some early research
[00:14:47.720 --> 00:14:50.000]   shows that more Democrats are doing mail-in ballots
[00:14:50.000 --> 00:14:51.760]   than Republicans, and then the mail-in ballots
[00:14:51.760 --> 00:14:53.800]   get counted after the day of ballots.
[00:14:53.800 --> 00:14:55.960]   So on the day of, we could see a red map,
[00:14:55.960 --> 00:14:58.400]   and then the day after it could turn blue or a week after,
[00:14:58.400 --> 00:15:01.080]   because these things they're going to take forever.
[00:15:01.080 --> 00:15:02.600]   And so it's that little in-between time,
[00:15:02.600 --> 00:15:05.920]   when they might be counting on some confusion
[00:15:05.920 --> 00:15:08.000]   if it's not as clear-cut.
[00:15:08.000 --> 00:15:09.240]   What is your take?
[00:15:09.240 --> 00:15:11.280]   I've talked to both these people, but I'm curious
[00:15:11.280 --> 00:15:12.640]   what your take is, Heather, on--
[00:15:12.640 --> 00:15:16.760]   how do you put this?
[00:15:16.760 --> 00:15:19.760]   Facebook's motivation is--
[00:15:19.760 --> 00:15:21.880]   I mean, I don't think Mark Zuckerberg is particularly
[00:15:21.880 --> 00:15:24.120]   political, although you had an article--
[00:15:24.120 --> 00:15:25.960]   or there was an article in the Wall Street Journal
[00:15:25.960 --> 00:15:28.880]   how Mark Zuckerberg learned politics,
[00:15:28.880 --> 00:15:33.000]   and there's a picture of a giant zuck walking down the front.
[00:15:33.000 --> 00:15:34.600]   I'm probably up on the photo shelf.
[00:15:34.600 --> 00:15:36.680]   [LAUGHTER]
[00:15:36.680 --> 00:15:39.480]   The 90-foot-tall Mark Zuckerberg.
[00:15:39.480 --> 00:15:41.000]   It's been fake news.
[00:15:41.000 --> 00:15:42.080]   Talk about fake news.
[00:15:42.080 --> 00:15:50.960]   There is some concern that if Facebook decided
[00:15:50.960 --> 00:15:52.880]   that they liked one candidate better than the other,
[00:15:52.880 --> 00:15:55.240]   or there was an issue that they cared a lot about,
[00:15:55.240 --> 00:15:57.080]   that they could be very manipulative.
[00:15:57.080 --> 00:15:59.440]   And we've seen it happen in other countries--
[00:15:59.440 --> 00:16:04.280]   Myanmar and the Philippines-- where Facebook has been misused
[00:16:04.280 --> 00:16:08.480]   by political figures to spread misinformation.
[00:16:08.480 --> 00:16:10.080]   And they haven't done-- they didn't at the time
[00:16:10.080 --> 00:16:12.880]   do a lot to stop it.
[00:16:12.880 --> 00:16:15.080]   I don't know if you can really ascribe a political leaning
[00:16:15.080 --> 00:16:17.800]   to Facebook, so much as Facebook trying to figure out
[00:16:17.800 --> 00:16:19.640]   the best way to have influence and money.
[00:16:19.640 --> 00:16:22.080]   And then overseas, a lot of times that's
[00:16:22.080 --> 00:16:24.680]   in competence or dropping the ball,
[00:16:24.680 --> 00:16:26.680]   not having people on the ground who speak the language
[00:16:26.680 --> 00:16:28.960]   or spotting what's happening soon enough.
[00:16:28.960 --> 00:16:31.600]   And I like with the issues of conservative bias,
[00:16:31.600 --> 00:16:33.560]   which is going to be fun this week.
[00:16:33.560 --> 00:16:36.280]   I mean, Facebook realized that it didn't want
[00:16:36.280 --> 00:16:38.840]   to alienate conservative users and that it was more
[00:16:38.840 --> 00:16:40.680]   beneficial to it financially, perhaps,
[00:16:40.680 --> 00:16:44.960]   to make sure those voices were more heard.
[00:16:44.960 --> 00:16:48.920]   And then maybe things like Mother Jones were not as heard.
[00:16:48.920 --> 00:16:50.000]   It's Hanlon's razor.
[00:16:50.000 --> 00:16:54.560]   Never ascribe to malice that which is adequately explained
[00:16:54.560 --> 00:16:56.600]   by incompetence.
[00:16:56.600 --> 00:16:57.400]   Or greed.
[00:16:57.400 --> 00:16:58.280]   I don't know whose razor--
[00:16:58.280 --> 00:16:58.800]   Or greed.
[00:16:58.800 --> 00:17:02.360]   [LAUGHTER]
[00:17:02.360 --> 00:17:04.160]   Yeah, I think that's kind of what I've always thought
[00:17:04.160 --> 00:17:06.840]   is that it's not their amoral.
[00:17:06.840 --> 00:17:07.720]   They're amoral.
[00:17:07.720 --> 00:17:11.840]   And most corporations have no moral imperative.
[00:17:11.840 --> 00:17:16.200]   Their job is to return money for the stakeholders.
[00:17:16.200 --> 00:17:18.760]   We love to anthropomorphize corporations.
[00:17:18.760 --> 00:17:19.280]   Right.
[00:17:19.280 --> 00:17:21.440]   They're just giant, massive money-making machines.
[00:17:21.440 --> 00:17:22.360]   That's all they do.
[00:17:22.360 --> 00:17:22.760]   Yeah.
[00:17:22.760 --> 00:17:23.520]   Capitalism.
[00:17:23.520 --> 00:17:24.040]   Yeah.
[00:17:24.040 --> 00:17:27.880]   So having the Republicans has been easier on Facebook,
[00:17:27.880 --> 00:17:31.080]   on antitrust issues, and everything can competition.
[00:17:31.080 --> 00:17:34.520]   So he's actually leaning towards getting
[00:17:34.520 --> 00:17:37.560]   comfy with Trump versus perhaps the Democrats who
[00:17:37.560 --> 00:17:40.960]   have questioned him more like that very viral video of AOC
[00:17:40.960 --> 00:17:41.920]   questioning him.
[00:17:41.920 --> 00:17:42.720]   Right.
[00:17:42.720 --> 00:17:45.880]   There's been a lot of conspiracy theories,
[00:17:45.880 --> 00:17:48.560]   and I hate to give any conspiracy theory any juice,
[00:17:48.560 --> 00:17:52.200]   but that Mark is smart enough to know
[00:17:52.200 --> 00:17:55.280]   where his bread is buttered, and he's going to kiss up
[00:17:55.280 --> 00:17:57.800]   to whoever he needs to to make sure they're
[00:17:57.800 --> 00:17:59.320]   regulated the least.
[00:17:59.320 --> 00:18:01.920]   And I think a lot of people think there was a deal with the devil.
[00:18:01.920 --> 00:18:07.320]   There's Zuckerberg had dinner with Trump a week before.
[00:18:07.320 --> 00:18:09.360]   This happened or that happened.
[00:18:09.360 --> 00:18:11.640]   I don't know how much of that is true.
[00:18:11.640 --> 00:18:14.960]   But I guess any competent CEO is going
[00:18:14.960 --> 00:18:18.960]   to be aware of the political wins and attempt
[00:18:18.960 --> 00:18:20.040]   to navigate them.
[00:18:20.040 --> 00:18:21.560]   Right, Brianna?
[00:18:21.560 --> 00:18:23.480]   Yeah, definitely.
[00:18:23.480 --> 00:18:26.320]   I keep thinking about the Upton Sinclair quote.
[00:18:26.320 --> 00:18:28.840]   You know, it's hard to get a man to understand something,
[00:18:28.840 --> 00:18:32.160]   which is living depends on not understanding it.
[00:18:32.160 --> 00:18:35.520]   With Zuckerberg, I think this is a wider phenomenon tech.
[00:18:35.520 --> 00:18:39.400]   I think there's a base set of assumptions that they hold.
[00:18:39.400 --> 00:18:43.040]   One of them is like the solution to bad speech is more speech
[00:18:43.040 --> 00:18:44.160]   or connect with people.
[00:18:44.160 --> 00:18:46.840]   By the way, on the surface, I love that.
[00:18:46.840 --> 00:18:47.920]   That's right.
[00:18:47.920 --> 00:18:49.240]   That's what we all thought.
[00:18:49.240 --> 00:18:49.800]   Yeah.
[00:18:49.800 --> 00:18:51.040]   We all thought that.
[00:18:51.040 --> 00:18:54.600]   But I think if you start digging down into these beliefs,
[00:18:54.600 --> 00:18:57.640]   you're like, OK, is inherently connecting people
[00:18:57.640 --> 00:19:01.240]   and letting them broadcast, say, QAnon stuff.
[00:19:01.240 --> 00:19:03.600]   We have some objective data today.
[00:19:03.600 --> 00:19:08.640]   Like, is this making our democracy healthier or sicker?
[00:19:08.640 --> 00:19:11.280]   It's really hard for me to think of an example of where
[00:19:11.280 --> 00:19:12.960]   that's making it healthier.
[00:19:12.960 --> 00:19:16.120]   So I think the bias of someone like Zuckerberg
[00:19:16.120 --> 00:19:19.480]   is having a certain set of very popular beliefs
[00:19:19.480 --> 00:19:24.000]   in the tech industry and really leaving those unexamined.
[00:19:24.000 --> 00:19:26.680]   I think that's the real bias, more than right or left.
[00:19:26.680 --> 00:19:28.000]   Yeah.
[00:19:28.000 --> 00:19:30.600]   And not taking accountability or responsibility
[00:19:30.600 --> 00:19:33.960]   when she has hit the fan to do something about it, being like,
[00:19:33.960 --> 00:19:35.840]   well, this wasn't what it was made for.
[00:19:35.840 --> 00:19:36.960]   And you're like, well, it wasn't.
[00:19:36.960 --> 00:19:38.160]   But that's where we are right now.
[00:19:38.160 --> 00:19:40.240]   That is their MO, isn't it?
[00:19:40.240 --> 00:19:45.520]   In fact, it's almost codified in their original motto
[00:19:45.520 --> 00:19:48.520]   to move fast and break things.
[00:19:48.520 --> 00:19:51.400]   So it's easier to ask forgiveness than ask permission.
[00:19:51.400 --> 00:19:52.800]   Just go ahead and do it.
[00:19:52.800 --> 00:19:55.800]   And then we'll apologize afterwards.
[00:19:55.800 --> 00:20:00.200]   And it seems like that's their operating model.
[00:20:00.200 --> 00:20:02.320]   I love that they got rid of that slogan.
[00:20:02.320 --> 00:20:03.600]   They did change it.
[00:20:03.600 --> 00:20:04.600]   Yeah.
[00:20:04.600 --> 00:20:06.400]   It's not as funny anymore.
[00:20:06.400 --> 00:20:10.720]   Do you think they got rid of it because it was in politics
[00:20:10.720 --> 00:20:12.960]   to say that or because they really don't believe it?
[00:20:12.960 --> 00:20:14.720]   I feel like they still do it.
[00:20:14.720 --> 00:20:16.280]   It was-- I forget the exact timing,
[00:20:16.280 --> 00:20:19.440]   but Facebook was in the headlines for literally breaking
[00:20:19.440 --> 00:20:21.840]   some things, democracy, something.
[00:20:21.840 --> 00:20:22.600]   And so they--
[00:20:22.600 --> 00:20:23.800]   Democracy.
[00:20:23.800 --> 00:20:25.480]   They announced like that we're going
[00:20:25.480 --> 00:20:27.600]   to change it to something more--
[00:20:27.600 --> 00:20:28.920]   I don't know, something less catchy
[00:20:28.920 --> 00:20:30.280]   because nobody remembers it from the motto.
[00:20:30.280 --> 00:20:31.640]   Yeah, I don't remember it.
[00:20:31.640 --> 00:20:34.360]   I remember the old one.
[00:20:34.360 --> 00:20:36.200]   That really is the fundamental question
[00:20:36.200 --> 00:20:40.080]   that I'm really trying to get to, which is,
[00:20:40.080 --> 00:20:44.320]   does social media break democracy?
[00:20:44.320 --> 00:20:47.000]   I think it does.
[00:20:47.000 --> 00:20:50.720]   There's a quote by my favorite author, Neil Stevenson,
[00:20:50.720 --> 00:20:53.840]   basically saying social media is the doomsday machine.
[00:20:53.840 --> 00:20:57.840]   I have unfortunately come to believe that that is true.
[00:20:57.840 --> 00:20:58.680]   You've been the victim.
[00:20:58.680 --> 00:21:00.520]   Of course, you were the victim of gamergate.
[00:21:00.520 --> 00:21:03.240]   Social media has been weaponized against you.
[00:21:03.240 --> 00:21:05.360]   It is, but it's wider than that.
[00:21:05.360 --> 00:21:07.880]   I mean, what happened to me during gamergate was, what,
[00:21:07.880 --> 00:21:09.280]   five, six years ago?
[00:21:09.280 --> 00:21:11.080]   Life moves on.
[00:21:11.080 --> 00:21:13.440]   What I see it doing to my country right now,
[00:21:13.440 --> 00:21:17.520]   it's really hard to argue that the discourse in the United
[00:21:17.520 --> 00:21:21.320]   States in the last, especially for years,
[00:21:21.320 --> 00:21:25.480]   has gotten really terrifyingly toxic.
[00:21:25.480 --> 00:21:28.800]   And I'm sure there are other reasons for it.
[00:21:28.800 --> 00:21:32.840]   But it does feel like the algorithms of both Twitter
[00:21:32.840 --> 00:21:35.880]   and Facebook and YouTube--
[00:21:35.880 --> 00:21:38.080]   got to include YouTube in this-- are designed
[00:21:38.080 --> 00:21:41.760]   to move the conversation in a more polarized, more
[00:21:41.760 --> 00:21:43.040]   extreme direction.
[00:21:43.040 --> 00:21:44.640]   They're outrage engines.
[00:21:44.640 --> 00:21:46.000]   Yeah.
[00:21:46.000 --> 00:21:49.640]   I mean, this ties into a lot of my work.
[00:21:49.640 --> 00:21:53.240]   I am of the opinion of issues like Medicare for All.
[00:21:53.240 --> 00:21:55.840]   I think we need to look at universal health care.
[00:21:55.840 --> 00:21:59.320]   But there is a weaponization of a certain portion
[00:21:59.320 --> 00:22:03.120]   of the electorate where it's a grievance engine.
[00:22:03.120 --> 00:22:06.560]   And it tells you that if you don't get this one policy,
[00:22:06.560 --> 00:22:08.360]   then the solution is to set it out
[00:22:08.360 --> 00:22:10.680]   and wait for maximalist policies.
[00:22:10.680 --> 00:22:14.200]   We're seeing that more and more with the left in a way
[00:22:14.200 --> 00:22:16.600]   I've never seen in my whole lifetime.
[00:22:16.600 --> 00:22:20.280]   I am really worried about that conversation.
[00:22:20.280 --> 00:22:23.800]   And yet, I hate the phrase "Overtan Window,"
[00:22:23.800 --> 00:22:26.640]   but it is the right phrase for this.
[00:22:26.640 --> 00:22:32.080]   The "Overtan Window" is the range of policies
[00:22:32.080 --> 00:22:35.280]   that are within the natural discourse.
[00:22:35.280 --> 00:22:39.040]   Like, that's not too far out of range.
[00:22:39.040 --> 00:22:40.920]   It's in the "Overtan Window."
[00:22:40.920 --> 00:22:44.960]   I feel like the "Overtan Window" has been moved and broadened
[00:22:44.960 --> 00:22:49.320]   by the discourse that's happening on social media, yes?
[00:22:49.320 --> 00:22:50.040]   Definitely.
[00:22:50.040 --> 00:22:50.960]   Definitely.
[00:22:50.960 --> 00:22:52.080]   In a good way.
[00:22:52.080 --> 00:22:53.000]   I mean, look at issues like--
[00:22:53.000 --> 00:22:55.280]   So there's benefits, too.
[00:22:55.280 --> 00:22:56.560]   There are benefits.
[00:22:56.560 --> 00:22:59.400]   I mean, if you're moving towards policies you agree with,
[00:22:59.400 --> 00:23:02.200]   I think, unfortunately--
[00:23:02.200 --> 00:23:03.560]   Well, Medicare for All, for instance,
[00:23:03.560 --> 00:23:05.320]   was a non-starter 10 years ago.
[00:23:05.320 --> 00:23:06.200]   Absolutely.
[00:23:06.200 --> 00:23:08.000]   But also, look at the conversation
[00:23:08.000 --> 00:23:09.840]   we're having with white supremacy today.
[00:23:09.840 --> 00:23:11.840]   It was also a non-starter 10 years ago.
[00:23:11.840 --> 00:23:12.280]   You're right.
[00:23:12.280 --> 00:23:12.800]   Right.
[00:23:12.800 --> 00:23:14.920]   I got the Mississippi in the '90s,
[00:23:14.920 --> 00:23:18.680]   and I see more statements justifying what is going on today
[00:23:18.680 --> 00:23:20.520]   than I did there.
[00:23:20.520 --> 00:23:23.360]   And it really terrifies me.
[00:23:23.360 --> 00:23:24.120]   Sorry.
[00:23:24.120 --> 00:23:26.200]   We were trying to say something that's true.
[00:23:26.200 --> 00:23:28.400]   Oh, well, the social dilemma on--
[00:23:28.400 --> 00:23:29.520]   No, that's OK.
[00:23:29.520 --> 00:23:30.480]   Let's talk about that.
[00:23:30.480 --> 00:23:33.640]   The fact is they want to keep you on the platform,
[00:23:33.640 --> 00:23:35.800]   so they're going to feed you what they think you want to hear
[00:23:35.800 --> 00:23:38.400]   more of or know more about.
[00:23:38.400 --> 00:23:40.960]   And so you get into this deep rabbit hole around things
[00:23:40.960 --> 00:23:42.160]   that might not be right.
[00:23:42.160 --> 00:23:45.720]   And even if it's misinformation, it's still something
[00:23:45.720 --> 00:23:47.120]   that will keep you on the platform.
[00:23:47.120 --> 00:23:49.480]   And that's where the ethical nature of it
[00:23:49.480 --> 00:23:52.240]   and world nature of what they're allowing
[00:23:52.240 --> 00:23:55.760]   to be on these platforms comes in.
[00:23:55.760 --> 00:23:58.320]   It also glances over the people actually making
[00:23:58.320 --> 00:24:00.600]   and spreading this information and gaming the systems.
[00:24:00.600 --> 00:24:03.160]   It's not like Facebook put up any misinformation itself.
[00:24:03.160 --> 00:24:03.800]   It's--
[00:24:03.800 --> 00:24:04.300]   No.
[00:24:04.300 --> 00:24:07.600]   It's my least favorite phrase, bad actors.
[00:24:07.600 --> 00:24:10.580]   Yeah, so in fact, some of the people in the chair
[00:24:10.580 --> 00:24:12.600]   are saying it's people, people with a problem.
[00:24:12.600 --> 00:24:17.000]   But the problem is people have been given a tool, a megaphone,
[00:24:17.000 --> 00:24:20.040]   an amplifier they didn't have before.
[00:24:20.040 --> 00:24:22.920]   So I don't think people are worse than they were.
[00:24:22.920 --> 00:24:25.080]   But these networks--
[00:24:25.080 --> 00:24:26.920]   People are always like that thinking these things,
[00:24:26.920 --> 00:24:30.160]   but it empowers them and grows.
[00:24:30.160 --> 00:24:32.120]   It's like the water to the seed, right?
[00:24:32.120 --> 00:24:35.180]   You still-- it's all intertwined to grow this--
[00:24:35.180 --> 00:24:36.180]   So what do we do?
[00:24:36.180 --> 00:24:38.540]   --to keep for anger and frustration?
[00:24:38.540 --> 00:24:39.580]   Do we shut it down?
[00:24:39.580 --> 00:24:42.060]   No.
[00:24:42.060 --> 00:24:43.860]   No, I just think that we need--
[00:24:43.860 --> 00:24:45.380]   I don't know, like regulations.
[00:24:45.380 --> 00:24:47.820]   Like, I think that it was a bit extreme.
[00:24:47.820 --> 00:24:50.700]   The New York Post article about Hunter Biden--
[00:24:50.700 --> 00:24:53.500]   Which was blocked on all social media.
[00:24:53.500 --> 00:24:56.060]   Even Fox, by the way, apparently, was offered the story.
[00:24:56.060 --> 00:24:57.980]   And they said, that smells a little bit.
[00:24:57.980 --> 00:24:59.420]   We're not going to do that.
[00:24:59.420 --> 00:25:01.420]   But the post went ahead with it, Rupert Murdoch,
[00:25:01.420 --> 00:25:03.640]   being what he is, went ahead with it.
[00:25:03.640 --> 00:25:05.640]   And then Twitter blocked it.
[00:25:05.640 --> 00:25:06.880]   You couldn't retweet it.
[00:25:06.880 --> 00:25:09.560]   But you're saying that had the negative impact
[00:25:09.560 --> 00:25:10.600]   on how this spread.
[00:25:10.600 --> 00:25:14.000]   Yeah, if you hold the fire that all these platforms are
[00:25:14.000 --> 00:25:16.540]   starting to censor Black Amir style,
[00:25:16.540 --> 00:25:18.920]   and I think there's a way to be responsible and accountable
[00:25:18.920 --> 00:25:20.720]   and not feeding into that, like, I do
[00:25:20.720 --> 00:25:24.880]   think they could have said this hasn't been verified or this--
[00:25:24.880 --> 00:25:26.600]   I think that's what they ended up doing, didn't they?
[00:25:26.600 --> 00:25:28.360]   Yeah, well, that's like-- and because they
[00:25:28.360 --> 00:25:31.080]   wanted to use this as an example, this became that.
[00:25:31.080 --> 00:25:32.880]   And I just-- I don't think it was the right timing
[00:25:32.880 --> 00:25:34.500]   for that example, because it just
[00:25:34.500 --> 00:25:36.960]   became a story that the left and the media
[00:25:36.960 --> 00:25:38.600]   are continuing to censor this side.
[00:25:38.600 --> 00:25:43.200]   If this happened to Biden, or like they would have--
[00:25:43.200 --> 00:25:45.160]   or if it was the other way around,
[00:25:45.160 --> 00:25:47.400]   then they wouldn't have censored it.
[00:25:47.400 --> 00:25:49.640]   And so I don't know.
[00:25:49.640 --> 00:25:51.080]   I feel like there's some issues there.
[00:25:51.080 --> 00:25:53.040]   But Heather, I'd be interested to hear what happened.
[00:25:53.040 --> 00:25:55.480]   Yeah, I mean, The Washington Post has done such a good job,
[00:25:55.480 --> 00:25:59.640]   I think, of walking the line of covering this stuff.
[00:25:59.640 --> 00:26:00.680]   It's very difficult.
[00:26:00.680 --> 00:26:05.160]   And to not look partisan, but at the same time,
[00:26:05.160 --> 00:26:09.440]   to also not do the two sides reporting,
[00:26:09.440 --> 00:26:11.280]   it's difficult to do.
[00:26:11.280 --> 00:26:13.640]   It's easier because-- I mean, I came from CNN
[00:26:13.640 --> 00:26:14.960]   where there was a much faster pace.
[00:26:14.960 --> 00:26:18.280]   And at Washington Post, there's more incentive to go slow
[00:26:18.280 --> 00:26:18.880]   and get it right.
[00:26:18.880 --> 00:26:20.040]   But what I thought was interesting
[00:26:20.040 --> 00:26:21.520]   with this particular story is it ended up
[00:26:21.520 --> 00:26:24.920]   being a platform story more than it was about--
[00:26:24.920 --> 00:26:25.920]   Yes.
[00:26:25.920 --> 00:26:28.120]   --which was not the intention at all.
[00:26:28.120 --> 00:26:30.280]   And so we're all writing, like, 2000 word thing pieces
[00:26:30.280 --> 00:26:32.760]   about Twitter's policy and Rudy Giuliani is like,
[00:26:32.760 --> 00:26:34.160]   no, that's not the plan.
[00:26:34.160 --> 00:26:37.000]   That wasn't what you were supposed to be focused on.
[00:26:37.000 --> 00:26:37.520]   Yeah.
[00:26:37.520 --> 00:26:38.720]   That's a good point.
[00:26:38.720 --> 00:26:40.960]   Maybe then it actually was a good decision.
[00:26:40.960 --> 00:26:41.960]   Yeah.
[00:26:41.960 --> 00:26:43.760]   But who knows?
[00:26:43.760 --> 00:26:46.760]   It was interesting in the debate on Thursday
[00:26:46.760 --> 00:26:48.720]   to watch the president bring it up
[00:26:48.720 --> 00:26:53.920]   as if everybody had knew the story in almost a shorthand way.
[00:26:53.920 --> 00:26:56.920]   And all the commentators and all the networks said,
[00:26:56.920 --> 00:26:59.720]   yeah, nobody knew what he was talking about.
[00:26:59.720 --> 00:27:02.840]   Because it had been somewhat suppressed.
[00:27:02.840 --> 00:27:06.840]   So maybe it did have a celebratory effect.
[00:27:06.840 --> 00:27:07.720]   I don't know.
[00:27:07.720 --> 00:27:08.640]   I'll tell you a story.
[00:27:08.640 --> 00:27:09.640]   And I read some other commentary that
[00:27:09.640 --> 00:27:12.760]   was along the lines of people aren't
[00:27:12.760 --> 00:27:15.520]   supposed to know the details of the story exactly.
[00:27:15.520 --> 00:27:17.760]   They're just supposed to give this general impression
[00:27:17.760 --> 00:27:20.040]   that wrongdoing happened.
[00:27:20.040 --> 00:27:20.520]   And so they--
[00:27:20.520 --> 00:27:21.520]   That's all it needs.
[00:27:21.520 --> 00:27:23.120]   --like that the confusion.
[00:27:23.120 --> 00:27:23.640]   Yeah.
[00:27:23.640 --> 00:27:25.520]   So we're going to take a different opinion here
[00:27:25.520 --> 00:27:27.520]   because I'm on the show with three journalists.
[00:27:27.520 --> 00:27:29.440]   I'm not a journalist.
[00:27:29.440 --> 00:27:30.840]   And I have a different opinion.
[00:27:30.840 --> 00:27:34.200]   I used to believe this five, 10 years ago.
[00:27:34.200 --> 00:27:36.840]   I would 100% be there with you.
[00:27:36.840 --> 00:27:41.120]   I have come to the conclusion that we can't be information
[00:27:41.120 --> 00:27:42.480]   idealists.
[00:27:42.480 --> 00:27:45.800]   And I think we need to be information realists about the way
[00:27:45.800 --> 00:27:50.240]   misinformation spreads because we can really see this
[00:27:50.240 --> 00:27:53.200]   is pushing our democracy to the brink.
[00:27:53.200 --> 00:27:54.920]   And I think the republic is going
[00:27:54.920 --> 00:27:59.320]   to be just fine if social media companies like Twitter
[00:27:59.320 --> 00:28:03.200]   take a harder line on flat out disinformation.
[00:28:03.200 --> 00:28:05.400]   I think it's going to be just fine.
[00:28:05.400 --> 00:28:06.920]   We knew this was going to happen.
[00:28:06.920 --> 00:28:11.440]   And also the fact that Russian disinformation certainly
[00:28:11.440 --> 00:28:13.440]   seems to be indicated in this.
[00:28:13.440 --> 00:28:16.560]   I also think there's a national security argument for this.
[00:28:16.560 --> 00:28:20.480]   So I have grown increasingly comfortable with this.
[00:28:20.480 --> 00:28:25.360]   What I think we should do is I think the answer is to--
[00:28:25.360 --> 00:28:28.480]   I think Facebook is so large that if you don't like
[00:28:28.480 --> 00:28:32.120]   their policies, it's very hard to go somewhere else.
[00:28:32.120 --> 00:28:36.440]   So I think that breaking up the Facebook monopoly,
[00:28:36.440 --> 00:28:38.760]   and then if you like Twitter's policies
[00:28:38.760 --> 00:28:41.640]   or you like Facebook's policies, you can go there.
[00:28:41.640 --> 00:28:42.920]   You can enjoy that.
[00:28:42.920 --> 00:28:45.960]   Or you can go to something like GAB, which maybe the policies
[00:28:45.960 --> 00:28:47.960]   are a better fit for you.
[00:28:47.960 --> 00:28:51.000]   But I think ultimately, I think that choice is going to be fine.
[00:28:51.000 --> 00:28:52.440]   Yeah.
[00:28:52.440 --> 00:28:54.440]   I want to take a little break, because there is a lot more
[00:28:54.440 --> 00:28:57.040]   in this vein to talk about, including the Department of Justice
[00:28:57.040 --> 00:28:59.560]   going after Google.
[00:28:59.560 --> 00:29:02.200]   We never really did figure out what we should do.
[00:29:02.200 --> 00:29:03.560]   I mean, Brianna, you're the only one
[00:29:03.560 --> 00:29:06.480]   who's had a prescription for how to deal with social media,
[00:29:06.480 --> 00:29:09.680]   which is let them do what they do.
[00:29:09.680 --> 00:29:11.720]   There has been an assault on Section 230,
[00:29:11.720 --> 00:29:14.760]   which protects Twitter, Facebook, and social media,
[00:29:14.760 --> 00:29:19.320]   websites, so that they can do that.
[00:29:19.320 --> 00:29:20.760]   I think we have--
[00:29:20.760 --> 00:29:21.360]   Yeah.
[00:29:21.360 --> 00:29:21.760]   Yeah.
[00:29:21.760 --> 00:29:22.520]   It's stopped.
[00:29:22.520 --> 00:29:23.800]   We have a lot to talk about.
[00:29:23.800 --> 00:29:26.480]   And we are going to get to that in just a second.
[00:29:26.480 --> 00:29:30.800]   But first word of our sponsor, ladies and gentlemen,
[00:29:30.800 --> 00:29:31.640]   I've got a great panel.
[00:29:31.640 --> 00:29:34.120]   I'm really glad to have this group here with us.
[00:29:34.120 --> 00:29:36.440]   Brianna Wu, who knows a little bit about politics,
[00:29:36.440 --> 00:29:40.120]   a lot about games, and a lot about everything.
[00:29:40.120 --> 00:29:44.200]   And if you ever have any questions about Porsche Boxsters,
[00:29:44.200 --> 00:29:45.760]   Porsche Boxsters--
[00:29:45.760 --> 00:29:46.800]   Any Porsche, really.
[00:29:46.800 --> 00:29:48.920]   Any Porsche, really, or powder coating your wheels.
[00:29:48.920 --> 00:29:53.240]   She's the one to go to, executive director of the Rebellion
[00:29:53.240 --> 00:29:54.280]   Pack.
[00:29:54.280 --> 00:29:55.200]   We're going to be gentle.
[00:29:55.200 --> 00:29:57.320]   She's brand new Heather Kelly from The Washington Post,
[00:29:57.320 --> 00:30:00.960]   but thrilled to have her @HeatherKelly on Twitter.
[00:30:00.960 --> 00:30:02.520]   And she likes cheddar cheese.
[00:30:02.520 --> 00:30:03.280]   We know that much.
[00:30:03.280 --> 00:30:05.840]   And sure, Lazar.
[00:30:05.840 --> 00:30:09.440]   We are channelq.com.
[00:30:09.440 --> 00:30:15.040]   And she sure is always making me feel better and relax.
[00:30:15.040 --> 00:30:15.880]   Oh, my God.
[00:30:15.880 --> 00:30:18.440]   Focus on the present.
[00:30:18.440 --> 00:30:19.800]   We all need that.
[00:30:19.800 --> 00:30:22.480]   Are you still doing your mind, body, love thing?
[00:30:22.480 --> 00:30:23.840]   Yeah, peace and side live.
[00:30:23.840 --> 00:30:27.000]   Yeah, we do live Zoom classes daily around mindfulness,
[00:30:27.000 --> 00:30:28.800]   meditation, and movement.
[00:30:28.800 --> 00:30:31.880]   We're working actually with a lot of brands and for-profits,
[00:30:31.880 --> 00:30:36.000]   bringing meditation mindfulness to their teams,
[00:30:36.000 --> 00:30:37.680]   like virtual sessions.
[00:30:37.680 --> 00:30:39.240]   And we work with nonprofits as well.
[00:30:39.240 --> 00:30:40.920]   So every hour we spend with a for-profit,
[00:30:40.920 --> 00:30:42.800]   we give an hour at a nonprofit.
[00:30:42.800 --> 00:30:43.200]   Oh, that's awesome.
[00:30:43.200 --> 00:30:44.360]   Yeah, it's continuing.
[00:30:44.360 --> 00:30:45.120]   Yeah.
[00:30:45.120 --> 00:30:46.040]   Good for you.
[00:30:46.040 --> 00:30:47.720]   We have lots of events.
[00:30:47.720 --> 00:30:49.840]   We're doing a death over dinner, virtual death over dinner
[00:30:49.840 --> 00:30:50.360]   tomorrow night.
[00:30:50.360 --> 00:30:52.400]   If you've heard about that, it's a pretty big--
[00:30:52.400 --> 00:30:56.040]   death over dinner.
[00:30:56.040 --> 00:30:56.480]   Yeah.
[00:30:56.480 --> 00:30:57.760]   Death over dinner.
[00:30:57.760 --> 00:30:59.960]   Women, don't tell me.
[00:30:59.960 --> 00:31:02.480]   Will one of us die at this dinner?
[00:31:02.480 --> 00:31:02.920]   No.
[00:31:02.920 --> 00:31:04.000]   Is it a mystery party?
[00:31:04.000 --> 00:31:05.520]   Not like clue.
[00:31:05.520 --> 00:31:06.720]   OK.
[00:31:06.720 --> 00:31:10.320]   Cheryl is our in the living room.
[00:31:10.320 --> 00:31:11.160]   What?
[00:31:11.160 --> 00:31:12.200]   With the microphone.
[00:31:12.200 --> 00:31:13.960]   With the microphone.
[00:31:13.960 --> 00:31:15.640]   The short-circuited microphone.
[00:31:15.640 --> 00:31:17.240]   That's it.
[00:31:17.240 --> 00:31:19.920]   No, what is death over dinner?
[00:31:19.920 --> 00:31:24.520]   Well, originally it was in real life, which we can't be right
[00:31:24.520 --> 00:31:25.040]   now.
[00:31:25.040 --> 00:31:28.360]   And so this guy Michael Hebb started these.
[00:31:28.360 --> 00:31:30.200]   He's still like a TED talk about and everything,
[00:31:30.200 --> 00:31:33.040]   where you have dinner and you talk about life
[00:31:33.040 --> 00:31:37.840]   and how you would want it being remembered and what
[00:31:37.840 --> 00:31:39.120]   you want on your tombstone.
[00:31:39.120 --> 00:31:42.480]   And it allows you to actually appreciate life more when
[00:31:42.480 --> 00:31:46.920]   you can think and talk about the other side of that.
[00:31:46.920 --> 00:31:47.280]   Can we--
[00:31:47.280 --> 00:31:48.160]   So we're doing that virtually.
[00:31:48.160 --> 00:31:49.840]   Can we do that before we do that?
[00:31:49.840 --> 00:31:51.560]   [LAUGHTER]
[00:31:51.560 --> 00:31:53.920]   It's actually very inspiring and empowering.
[00:31:53.920 --> 00:31:58.240]   I've done death over Zoom, but there was no meal involved.
[00:31:58.240 --> 00:32:00.960]   No, that makes sense, actually, because we pretend
[00:32:00.960 --> 00:32:02.760]   we're not going to die.
[00:32:02.760 --> 00:32:03.760]   And that really is--
[00:32:03.760 --> 00:32:06.920]   that talk about fake news.
[00:32:06.920 --> 00:32:09.440]   That really can distort your perspective on the world.
[00:32:09.440 --> 00:32:10.200]   I'm a little forever.
[00:32:10.200 --> 00:32:11.840]   It's not a problem.
[00:32:11.840 --> 00:32:12.360]   Yeah.
[00:32:12.360 --> 00:32:14.920]   I mean, when you know that it's finite,
[00:32:14.920 --> 00:32:16.880]   you can appreciate it more.
[00:32:16.880 --> 00:32:17.280]   Yeah.
[00:32:17.280 --> 00:32:19.680]   Or get going.
[00:32:19.680 --> 00:32:21.520]   Get off your ass and get to do something.
[00:32:21.520 --> 00:32:23.520]   Yeah.
[00:32:23.520 --> 00:32:23.960]   That's good.
[00:32:23.960 --> 00:32:24.800]   Thank you, Shira.
[00:32:24.800 --> 00:32:26.000]   Death over dinner.
[00:32:26.000 --> 00:32:27.200]   Dodd.
[00:32:27.200 --> 00:32:28.400]   He's inside.live, though.
[00:32:28.400 --> 00:32:28.680]   Go check out.
[00:32:28.680 --> 00:32:30.320]   Can I do a death over dinner?
[00:32:30.320 --> 00:32:31.160]   Like, can I come to dinner?
[00:32:31.160 --> 00:32:31.960]   You join us tomorrow.
[00:32:31.960 --> 00:32:32.520]   It's tomorrow night.
[00:32:32.520 --> 00:32:36.080]   Tomorrow, you're going to talk about death over dinner?
[00:32:36.080 --> 00:32:37.840]   Yeah, it's like an 80% event.
[00:32:37.840 --> 00:32:39.320]   We're doing all virtually over Zoom.
[00:32:39.320 --> 00:32:41.120]   That sounds really interesting.
[00:32:41.120 --> 00:32:42.240]   Yeah.
[00:32:42.240 --> 00:32:44.760]   Can I-- I'll bring the brisket.
[00:32:44.760 --> 00:32:45.280]   Go for it.
[00:32:45.280 --> 00:32:48.520]   If you're going to die, you might as well eat barbecue, right?
[00:32:48.520 --> 00:32:49.080]   Whatever you want.
[00:32:49.080 --> 00:32:50.080]   That's my attitude.
[00:32:50.080 --> 00:32:50.920]   I don't eat meat.
[00:32:50.920 --> 00:32:51.600]   You're a vegan.
[00:32:51.600 --> 00:32:52.120]   I know.
[00:32:52.120 --> 00:32:52.640]   I know.
[00:32:52.640 --> 00:32:53.160]   I know.
[00:32:53.160 --> 00:32:53.680]   Yeah.
[00:32:53.680 --> 00:32:57.080]   Our show today-- that's why I'll eat the brisket all by myself.
[00:32:57.080 --> 00:33:00.080]   Our show today brought to you by NetSuite.
[00:33:00.080 --> 00:33:01.000]   You know about NetSuite.
[00:33:01.000 --> 00:33:02.360]   Oh, I hope you know about NetSuite.
[00:33:02.360 --> 00:33:05.320]   NetSuite gives you visibility and control
[00:33:05.320 --> 00:33:07.120]   over every aspect of your business--
[00:33:07.120 --> 00:33:11.080]   financials, HR, inventory, e-commerce, everything--
[00:33:11.080 --> 00:33:16.320]   and more, everything you need all in one place instantaneously.
[00:33:16.320 --> 00:33:17.960]   It's kind of the holy grail.
[00:33:17.960 --> 00:33:20.240]   You don't have a spread out all over the place.
[00:33:20.240 --> 00:33:22.600]   You may not realize this, but you're using quick books.
[00:33:22.600 --> 00:33:24.040]   You're using spreadsheets.
[00:33:24.040 --> 00:33:25.840]   You got this here, that, there, that.
[00:33:25.840 --> 00:33:27.320]   My wife has a screen.
[00:33:27.320 --> 00:33:30.320]   It's literally wider than her arm spreads
[00:33:30.320 --> 00:33:32.920]   so that she could put all those things on one screen.
[00:33:32.920 --> 00:33:34.000]   That's crazy.
[00:33:34.000 --> 00:33:36.880]   If you're sick of working on multiple platforms,
[00:33:36.880 --> 00:33:39.040]   and you're ready to take your business to the next level,
[00:33:39.040 --> 00:33:39.760]   you better right now.
[00:33:39.760 --> 00:33:42.000]   It's a time to upgrade to NetSuite.
[00:33:42.000 --> 00:33:44.040]   Lisa actually has been saying, I think we need NetSuite.
[00:33:44.040 --> 00:33:47.200]   Running a fast-growing, smaller, medium-sized business
[00:33:47.200 --> 00:33:48.400]   is tough.
[00:33:48.400 --> 00:33:50.160]   I see it every day.
[00:33:50.160 --> 00:33:51.480]   You've got to have a solution that's
[00:33:51.480 --> 00:33:54.640]   evolving to meet your needs.
[00:33:54.640 --> 00:33:58.960]   NetSuite is the world's number one cloud business system.
[00:33:58.960 --> 00:34:00.640]   It gives you cloud-based solutions,
[00:34:00.640 --> 00:34:03.520]   streamlines mission critical business processes,
[00:34:03.520 --> 00:34:07.440]   and reduces IT costs, allowing you to easily scale and future
[00:34:07.440 --> 00:34:10.000]   proof of your business with an agile business platform
[00:34:10.000 --> 00:34:11.360]   that evolves as your needs change.
[00:34:11.360 --> 00:34:12.480]   You'll save time.
[00:34:12.480 --> 00:34:14.200]   You'll save money.
[00:34:14.200 --> 00:34:16.440]   You can close with confidence, accelerate
[00:34:16.440 --> 00:34:20.000]   the financial close, maintain compliance with accounting
[00:34:20.000 --> 00:34:20.920]   standards.
[00:34:20.920 --> 00:34:23.520]   You'll be reporting with accuracy.
[00:34:23.520 --> 00:34:25.400]   I mean, how many times you look at the reports and go,
[00:34:25.400 --> 00:34:26.880]   I wonder how accurate that is.
[00:34:26.880 --> 00:34:30.320]   You need the accurate financial accuracy is everything.
[00:34:30.320 --> 00:34:32.320]   You can even drill down into the underlying details
[00:34:32.320 --> 00:34:34.760]   and understand what's impacting your business.
[00:34:34.760 --> 00:34:35.880]   What does this number mean?
[00:34:35.880 --> 00:34:37.280]   What's this coming from?
[00:34:37.280 --> 00:34:39.640]   Get real-time information to improve your business's
[00:34:39.640 --> 00:34:43.920]   performance with real-time metrics, role-based dashboards.
[00:34:43.920 --> 00:34:45.920]   The whole point of all of this is never
[00:34:45.920 --> 00:34:48.920]   be in the dark about where your money's going,
[00:34:48.920 --> 00:34:50.680]   where your business is going.
[00:34:50.680 --> 00:34:57.520]   And I can guarantee those multiple unconnected systems
[00:34:57.520 --> 00:34:58.720]   are getting in the way.
[00:34:58.720 --> 00:34:59.960]   You need NetSuite.
[00:34:59.960 --> 00:35:02.520]   NetSuite delivers what others can't.
[00:35:02.520 --> 00:35:04.520]   Let NetSuite show you how they'll benefit your business
[00:35:04.520 --> 00:35:08.440]   with a free product tour at netsuite.com/twit.
[00:35:08.440 --> 00:35:12.280]   N-E-T-S-U-I-T-E.com/twit.
[00:35:12.280 --> 00:35:13.800]   NetSuite.com/twit.
[00:35:13.800 --> 00:35:16.080]   Schedule your free product tour right now.
[00:35:16.080 --> 00:35:18.800]   NetSuite.com/twit.
[00:35:18.800 --> 00:35:21.360]   Thank you, NetSuite, for supporting this week in tech.
[00:35:21.360 --> 00:35:24.040]   Thank you for supporting it by using that special address
[00:35:24.040 --> 00:35:25.280]   so they know you saw it here.
[00:35:25.280 --> 00:35:29.920]   NetSuite.com/twit.
[00:35:29.920 --> 00:35:32.000]   Now, there's a lot-- and I'm sure you guys
[00:35:32.000 --> 00:35:34.040]   will have a lot to say, so I'm going to give you a chance.
[00:35:34.040 --> 00:35:37.720]   There's a lot of conversation over the Justice Department.
[00:35:37.720 --> 00:35:41.560]   They finally filed there, as the Wall Street Journal says,
[00:35:41.560 --> 00:35:47.640]   long-awaited antitrust lawsuit against Google.
[00:35:47.640 --> 00:35:52.000]   Quite a bit of conversation about how it's malformed.
[00:35:52.000 --> 00:35:54.600]   It's politically intended.
[00:35:54.600 --> 00:35:58.920]   Maybe there's some merit in it, but it's not the right lawsuit.
[00:35:58.920 --> 00:36:00.880]   But I am going to submit.
[00:36:00.880 --> 00:36:07.480]   I think it has a bracing impact on the minds of corporations
[00:36:07.480 --> 00:36:10.280]   all across this great land of ours,
[00:36:10.280 --> 00:36:14.680]   because it forces you to say, hmm, maybe we should think twice
[00:36:14.680 --> 00:36:18.520]   about that acquisition or that move.
[00:36:18.520 --> 00:36:21.800]   I think you might argue that Apple is holding back
[00:36:21.800 --> 00:36:25.960]   on its location-tracking Apple tags,
[00:36:25.960 --> 00:36:30.000]   because there's been some talk that maybe they're
[00:36:30.000 --> 00:36:33.200]   disadvantaging a tile, the competition,
[00:36:33.200 --> 00:36:36.400]   because even the CEO of Tile has said this in front of Congress,
[00:36:36.400 --> 00:36:39.160]   Apple isn't giving them access, then Apple will have
[00:36:39.160 --> 00:36:41.160]   this built-in advantage.
[00:36:41.160 --> 00:36:44.640]   I think Apple hasn't released air tags, because I think they're
[00:36:44.640 --> 00:36:48.880]   going, well, we don't want to get in trouble right now.
[00:36:48.880 --> 00:36:54.640]   If nothing else, I'll go to our government expert.
[00:36:54.640 --> 00:36:58.920]   If nothing else doesn't a lawsuit like this make people at least
[00:36:58.920 --> 00:37:01.240]   slow down and think about what they're doing,
[00:37:01.240 --> 00:37:04.360]   that it could be risky?
[00:37:04.360 --> 00:37:06.000]   I mean, I absolutely think so.
[00:37:06.000 --> 00:37:07.240]   I think it's a good thing.
[00:37:07.240 --> 00:37:12.480]   I think as the verge and many other legal experts have noted,
[00:37:12.480 --> 00:37:15.880]   this is not the strongest case.
[00:37:15.880 --> 00:37:19.520]   And I think the fact that it really seems to have been brought
[00:37:19.520 --> 00:37:23.400]   forward for political motives really undermines
[00:37:23.400 --> 00:37:25.000]   the public confidence in it.
[00:37:25.000 --> 00:37:29.880]   But does the Justice Department generally enforcing antitrust law
[00:37:29.880 --> 00:37:32.640]   does that have a positive effect for consumers?
[00:37:32.640 --> 00:37:34.040]   I think unquestionably.
[00:37:34.040 --> 00:37:37.720]   And I just want to see them pursue smarter cases.
[00:37:37.720 --> 00:37:43.200]   I really think you cannot overstate just how much the stench
[00:37:43.200 --> 00:37:46.480]   of partisanship gets into cases like this.
[00:37:46.480 --> 00:37:48.920]   It undermines the rule of law.
[00:37:48.920 --> 00:37:50.880]   It undermines public confidence.
[00:37:50.880 --> 00:37:53.120]   It's just so terrible.
[00:37:53.120 --> 00:37:55.800]   And I think that's going to be one of the darkest
[00:37:55.800 --> 00:37:58.600]   legacies of the bar, Justice Department.
[00:37:58.600 --> 00:38:01.000]   You then agree with Karl Bodie writing in Tektok.
[00:38:01.000 --> 00:38:05.960]   Bill Barr's Google antitrust inquiry is a weaponized farce.
[00:38:05.960 --> 00:38:07.000]   Yeah.
[00:38:07.000 --> 00:38:08.400]   That's pretty strong.
[00:38:08.400 --> 00:38:10.720]   Heather, do you agree?
[00:38:10.720 --> 00:38:15.160]   I mean, I think if you read the indictment, a lot of it's stupid.
[00:38:15.160 --> 00:38:17.320]   A lot of it's like--
[00:38:17.320 --> 00:38:19.880]   I think Neil I Patel had a great tweet.
[00:38:19.880 --> 00:38:24.600]   He said, Google harshly stopping carrier bloatware
[00:38:24.600 --> 00:38:28.040]   should be illegal is again not the best argument
[00:38:28.040 --> 00:38:30.960]   for the Department of Justice.
[00:38:30.960 --> 00:38:33.520]   Section 143 of the indictment, Google
[00:38:33.520 --> 00:38:36.920]   was concerned that a major US carrier would ask manufacturers
[00:38:36.920 --> 00:38:39.240]   to install a search widget powered
[00:38:39.240 --> 00:38:44.720]   by the carriers in-house search engine.
[00:38:44.720 --> 00:38:46.200]   Google told this--
[00:38:46.200 --> 00:38:47.760]   I'm going to guess it's Verizon, but it's
[00:38:47.760 --> 00:38:50.440]   going to told this company--
[00:38:50.440 --> 00:38:53.360]   these customization requests will not go far.
[00:38:53.360 --> 00:38:55.360]   If you want Google on your phone,
[00:38:55.360 --> 00:38:58.360]   you better not put your own search widget on there.
[00:38:58.360 --> 00:39:03.160]   That's a lousy antitrust argument.
[00:39:03.160 --> 00:39:07.120]   But is there some merit in this, Heather?
[00:39:07.120 --> 00:39:09.960]   The whole case kind of reminds me of the impeachment,
[00:39:09.960 --> 00:39:11.400]   where they had to pick one topic.
[00:39:11.400 --> 00:39:13.040]   They're like, we're going to pick one thing.
[00:39:13.040 --> 00:39:15.120]   There's a lot of impeachable offenses, hypothetically.
[00:39:15.120 --> 00:39:17.880]   What if we just pick one narrow, easy win?
[00:39:17.880 --> 00:39:20.720]   And this feels like to me that the Justice Department was
[00:39:20.720 --> 00:39:23.120]   on a time crunch that they wanted before the election.
[00:39:23.120 --> 00:39:26.360]   And they wanted to pick whatever part of the case they had,
[00:39:26.360 --> 00:39:28.040]   the most ready to go, the tightest.
[00:39:28.040 --> 00:39:30.720]   There's evidence of that because the staff attorneys in the DOJ,
[00:39:30.720 --> 00:39:32.960]   in fact, apparently said, we can't--
[00:39:32.960 --> 00:39:33.840]   it's too soon.
[00:39:33.840 --> 00:39:35.240]   We're not ready.
[00:39:35.240 --> 00:39:37.080]   And bars went ahead.
[00:39:37.080 --> 00:39:39.160]   Bars department went ahead.
[00:39:39.160 --> 00:39:44.320]   So it seems very, very specific and narrow.
[00:39:44.320 --> 00:39:45.360]   Maybe it's in 3D chess here.
[00:39:45.360 --> 00:39:46.400]   Maybe it's in negotiating.
[00:39:46.400 --> 00:39:49.120]   Like an opening gambit, we'll see if Google will settle this,
[00:39:49.120 --> 00:39:51.920]   if we can get them to settle things,
[00:39:51.920 --> 00:39:54.120]   if they're smaller and piece by piece,
[00:39:54.120 --> 00:39:56.480]   instead of a giant antitrust lawsuit.
[00:39:56.480 --> 00:39:56.960]   I don't know.
[00:39:56.960 --> 00:39:59.440]   It's all contributing to the lawyer industrial complex.
[00:39:59.440 --> 00:40:02.720]   These people are going to be busy with this for years.
[00:40:02.720 --> 00:40:04.200]   Yeah.
[00:40:04.200 --> 00:40:07.320]   So I'm curious, Heather, whether you think that--
[00:40:07.320 --> 00:40:09.960]   and it was probably before your time, but I remember,
[00:40:09.960 --> 00:40:12.960]   1998, when the DOJ went against Microsoft,
[00:40:12.960 --> 00:40:16.400]   and that thing did take almost 10 years to resolve.
[00:40:16.400 --> 00:40:18.400]   But I think there's no question.
[00:40:18.400 --> 00:40:20.560]   Microsoft actually came out of it stronger
[00:40:20.560 --> 00:40:22.440]   because they were chastened.
[00:40:22.440 --> 00:40:26.920]   And they stopped their engulf and devour business practices.
[00:40:26.920 --> 00:40:28.960]   And they actually became a better company for it.
[00:40:28.960 --> 00:40:30.880]   And I think the world was a better place.
[00:40:30.880 --> 00:40:34.120]   In hindsight, that was successful.
[00:40:34.120 --> 00:40:36.840]   I mean, I was alive then, was not paying that question.
[00:40:36.840 --> 00:40:37.360]   Barely.
[00:40:37.360 --> 00:40:39.640]   [LAUGHTER]
[00:40:39.640 --> 00:40:41.000]   I'm sure, I mean, that may be true.
[00:40:41.000 --> 00:40:43.520]   I still think maybe Microsoft wished
[00:40:43.520 --> 00:40:45.360]   that wasn't a thing it had to go through.
[00:40:45.360 --> 00:40:46.360]   I don't know.
[00:40:46.360 --> 00:40:46.840]   Oh, oh, oh, oh.
[00:40:46.840 --> 00:40:47.840]   Thanks, definitely.
[00:40:47.840 --> 00:40:48.600]   Oh, great.
[00:40:48.600 --> 00:40:50.160]   Oh, I'm not saying that.
[00:40:50.160 --> 00:40:54.720]   In fact, somebody quoted Bill Gates.
[00:40:54.720 --> 00:40:57.720]   They said, you'd sit down in the boardroom,
[00:40:57.720 --> 00:40:59.680]   and somebody would say, well, we should do this.
[00:40:59.680 --> 00:41:02.640]   And Bill said, I'm not ever sitting in that chair again.
[00:41:02.640 --> 00:41:05.400]   We are not doing that.
[00:41:05.400 --> 00:41:09.400]   I think that that-- it did have a beneficial effect on Microsoft
[00:41:09.400 --> 00:41:11.360]   in hindsight.
[00:41:11.360 --> 00:41:14.280]   So these things, I think, are not necessarily bad things to do.
[00:41:14.280 --> 00:41:19.720]   But I think, sure, it's also hard to imagine, what do you do
[00:41:19.720 --> 00:41:21.760]   to spank Google?
[00:41:21.760 --> 00:41:23.920]   Do you break them up?
[00:41:23.920 --> 00:41:26.520]   Yeah, I mean, I feel like Facebook needs more of a spanking.
[00:41:26.520 --> 00:41:28.280]   Facebook's going to get its spanking.
[00:41:28.280 --> 00:41:31.200]   If I have anything to do with it.
[00:41:31.200 --> 00:41:33.560]   I mean, yeah, this feels like it's
[00:41:33.560 --> 00:41:35.720]   a distraction from the major issues
[00:41:35.720 --> 00:41:37.680]   that we're dealing with, which is like,
[00:41:37.680 --> 00:41:41.320]   we don't have a pandemic relief, Bill.
[00:41:41.320 --> 00:41:42.160]   Obviously--
[00:41:42.160 --> 00:41:43.560]   Well, that's a good point.
[00:41:43.560 --> 00:41:45.320]   Yeah, like, the Supreme Court nominee.
[00:41:45.320 --> 00:41:47.480]   And then they're like, wow, we throw this in to continue
[00:41:47.480 --> 00:41:51.920]   to show how these platforms are evil.
[00:41:51.920 --> 00:41:54.120]   Like, it's like-- I feel like it's just a whole--
[00:41:54.120 --> 00:41:55.880]   You kind of want to shake some people.
[00:41:55.880 --> 00:41:57.440]   Yeah, it's just like, they want to distract us
[00:41:57.440 --> 00:42:00.320]   to other things which make other things feel evil
[00:42:00.320 --> 00:42:02.960]   when the administration is somewhat evil.
[00:42:02.960 --> 00:42:06.160]   But I mean, I think that there's something to be said.
[00:42:06.160 --> 00:42:07.840]   I mean, I think the one thing that I saw in this
[00:42:07.840 --> 00:42:11.040]   was that they were paying a platform like over $100 million
[00:42:11.040 --> 00:42:11.880]   for exclusivity.
[00:42:11.880 --> 00:42:14.800]   And like, in essence, that cuts out anyone else from--
[00:42:14.800 --> 00:42:16.360]   More than that, they pay Apple--
[00:42:16.360 --> 00:42:20.280]   Apple between $8 and $12 billion a year
[00:42:20.280 --> 00:42:22.760]   to be the default search engine on the iPhone.
[00:42:22.760 --> 00:42:25.120]   Yeah, so how is anyone else going to grow, you could say?
[00:42:25.120 --> 00:42:28.400]   But then it's like, there are companies that get discovered
[00:42:28.400 --> 00:42:34.320]   and users end up making that company a popular platform.
[00:42:34.320 --> 00:42:37.600]   And so if maybe a company like Apple or Smart enough,
[00:42:37.600 --> 00:42:40.200]   they'll say, well, we want to be with the cool kids now,
[00:42:40.200 --> 00:42:41.520]   but probably not if they're getting
[00:42:41.520 --> 00:42:42.920]   made a shit out of money.
[00:42:42.920 --> 00:42:43.360]   Right.
[00:42:43.360 --> 00:42:45.360]   So yeah, I mean, that's an issue.
[00:42:45.360 --> 00:42:47.200]   That's definitely possibly an issue.
[00:42:47.200 --> 00:42:53.280]   Heather, you probably get pitches from people who say,
[00:42:53.280 --> 00:42:56.280]   we are going to be the next Google.
[00:42:56.280 --> 00:42:57.880]   Do you just laugh and crumple them up
[00:42:57.880 --> 00:43:00.160]   and throw them at the track?
[00:43:00.160 --> 00:43:02.840]   I don't get them, but I did learn about one this week.
[00:43:02.840 --> 00:43:06.720]   And I apologize to this company if it's Neva or Neera.
[00:43:06.720 --> 00:43:08.920]   But it was mentioned without naming it in the complaint
[00:43:08.920 --> 00:43:12.120]   because they do like an ad-based search product--
[00:43:12.120 --> 00:43:13.120]   Oh, that is--
[00:43:13.120 --> 00:43:15.080]   --a subscription based product.
[00:43:15.080 --> 00:43:17.840]   But you don't have to have any ads, which obviously
[00:43:17.840 --> 00:43:19.720]   is problematic because if you can't afford
[00:43:19.720 --> 00:43:23.160]   to buy your way out of ads, well, that sucks.
[00:43:23.160 --> 00:43:25.400]   But so yeah, it's an ex-Googleer, I believe.
[00:43:25.400 --> 00:43:26.960]   So there are other companies coming up,
[00:43:26.960 --> 00:43:30.000]   and there's always duck, duck go and Bing.
[00:43:30.000 --> 00:43:31.840]   And I think I've literally named all of them.
[00:43:31.840 --> 00:43:33.320]   Have you heard about Brave?
[00:43:33.320 --> 00:43:34.000]   Did you hear about Brave?
[00:43:34.000 --> 00:43:34.920]   Brave is a browser.
[00:43:34.920 --> 00:43:36.680]   It doesn't have its own search, though.
[00:43:36.680 --> 00:43:37.440]   Yeah.
[00:43:37.440 --> 00:43:38.840]   Doesn't?
[00:43:38.840 --> 00:43:41.280]   I feel like they were trying to get people off--
[00:43:41.280 --> 00:43:41.960]   Well, off of like--
[00:43:41.960 --> 00:43:42.480]   Well, they were.
[00:43:42.480 --> 00:43:44.520]   And actually, part of this complaint
[00:43:44.520 --> 00:43:46.840]   against Google is Chrome, is their browser.
[00:43:46.840 --> 00:43:47.960]   Yeah.
[00:43:47.960 --> 00:43:52.440]   Oddly, Brave and Microsoft's Edge are both based on the open source
[00:43:52.440 --> 00:43:54.960]   Chrome you mentioned that Google uses for Chrome.
[00:43:54.960 --> 00:43:57.280]   I don't know.
[00:43:57.280 --> 00:43:59.480]   One of the things that DOJ implied is maybe they
[00:43:59.480 --> 00:44:03.280]   could get Google to divest Chrome.
[00:44:03.280 --> 00:44:05.960]   Maybe that is a good idea.
[00:44:05.960 --> 00:44:08.560]   Maybe they can get Chrome to stop slowing down my computer
[00:44:08.560 --> 00:44:10.320]   that would be a great idea.
[00:44:10.320 --> 00:44:11.320]   It could start.
[00:44:11.320 --> 00:44:12.120]   The DOJ could put that.
[00:44:12.120 --> 00:44:13.480]   That's a winning election issue, I think.
[00:44:13.480 --> 00:44:14.480]   Yeah.
[00:44:14.480 --> 00:44:14.980]   Yeah.
[00:44:14.980 --> 00:44:19.240]   The last time I was on, you were actually going through the Microsoft
[00:44:19.240 --> 00:44:21.040]   antitrust case from the '90s.
[00:44:21.040 --> 00:44:21.560]   Right.
[00:44:21.560 --> 00:44:24.040]   Yeah, you were looking at what's actually in there.
[00:44:24.040 --> 00:44:26.240]   It's all utterly reasonable stuff,
[00:44:26.240 --> 00:44:27.600]   like before acquisition.
[00:44:27.600 --> 00:44:29.360]   In the consent decree, yeah.
[00:44:29.360 --> 00:44:29.800]   Right.
[00:44:29.800 --> 00:44:30.760]   Absolutely.
[00:44:30.760 --> 00:44:32.840]   So I would--
[00:44:32.840 --> 00:44:36.480]   I personally would be happy with something more in that vein.
[00:44:36.480 --> 00:44:41.480]   I feel like we're so used to these mega mergers.
[00:44:41.480 --> 00:44:44.240]   I feel like we all have a collective--
[00:44:44.240 --> 00:44:48.120]   we're shocked into thinking we don't have any power.
[00:44:48.120 --> 00:44:49.680]   And I don't know.
[00:44:49.680 --> 00:44:52.760]   I think there's a reason Facebook and Google
[00:44:52.760 --> 00:44:57.880]   have put so much effort into their public facing--
[00:44:57.880 --> 00:45:00.440]   their public facing messaging on this,
[00:45:00.440 --> 00:45:04.480]   because they realize this is a big threat to their essentially
[00:45:04.480 --> 00:45:05.800]   duopoly.
[00:45:05.800 --> 00:45:07.760]   So we have power.
[00:45:07.760 --> 00:45:09.920]   I just think it's worth remembering that.
[00:45:09.920 --> 00:45:13.880]   It's also worth remembering that the Department of Justice
[00:45:13.880 --> 00:45:15.720]   has not exactly been aggressively
[00:45:15.720 --> 00:45:19.480]   pursuing antitrust policy.
[00:45:19.480 --> 00:45:21.960]   Avery Gardner tweeted this as you gear up
[00:45:21.960 --> 00:45:24.040]   for the antitrust complaint.
[00:45:24.040 --> 00:45:26.280]   Recall DOJ's own statistics show.
[00:45:26.280 --> 00:45:28.680]   It didn't bring a single--
[00:45:28.680 --> 00:45:33.680]   not one single case for abusive monopoly power.
[00:45:33.680 --> 00:45:36.360]   Since 2010, there's only been one in 2011.
[00:45:36.360 --> 00:45:40.240]   And that was-- I'm trying to remember what that was--
[00:45:40.240 --> 00:45:44.240]   at the AT&T time Warner deal, and that
[00:45:44.240 --> 00:45:45.800]   was more politically motivated.
[00:45:45.800 --> 00:45:51.240]   There hasn't been a lot of antitrust enforcement.
[00:45:51.240 --> 00:45:53.320]   And by the way, this predates Trump.
[00:45:53.320 --> 00:45:56.920]   This goes back to the George W. Bush and Barack Obama.
[00:45:56.920 --> 00:45:59.840]   I mean, the DOJ has been pretty lenient.
[00:45:59.840 --> 00:46:03.520]   They've allowed T-Mobile and Sprint to merge.
[00:46:03.520 --> 00:46:10.320]   They've allowed Comcast to gobble up NBC and universal pictures.
[00:46:10.320 --> 00:46:14.920]   I mean, it's been anything goes for a decade.
[00:46:14.920 --> 00:46:24.080]   According to Techdirt, the one example usually trotted out
[00:46:24.080 --> 00:46:27.920]   to claim otherwise AT&T's lawsuit to stop the AT&T time
[00:46:27.920 --> 00:46:29.760]   Warner merger.
[00:46:29.760 --> 00:46:32.800]   And that really ended up being-- and you might remember this,
[00:46:32.800 --> 00:46:38.640]   together, because this was to piss off CNN for Trump
[00:46:38.640 --> 00:46:40.960]   and helping Rupert Murdoch than any serious concern
[00:46:40.960 --> 00:46:42.360]   about media consolidation.
[00:46:42.360 --> 00:46:43.760]   Murdoch wanted to deal blocked.
[00:46:43.760 --> 00:46:50.320]   Politics is inevitably going to get in any of this stuff.
[00:46:50.320 --> 00:46:52.280]   I would imagine.
[00:46:52.280 --> 00:46:55.400]   You can't say, oh, this should be divorced from politics.
[00:46:55.400 --> 00:46:59.920]   I do wonder about the timing of this one.
[00:46:59.920 --> 00:47:02.040]   Were they hoping that any actual voters
[00:47:02.040 --> 00:47:03.280]   cared about this issue?
[00:47:03.280 --> 00:47:06.480]   It's not going to win your votes.
[00:47:06.480 --> 00:47:07.880]   I don't know if that's true.
[00:47:07.880 --> 00:47:12.840]   I think it rallies up one party.
[00:47:12.840 --> 00:47:13.240]   I think it does.
[00:47:13.240 --> 00:47:15.680]   Well, I've heard from a lot of people
[00:47:15.680 --> 00:47:19.480]   who say, you see, this proves that the social media
[00:47:19.480 --> 00:47:22.960]   and the media and the big tech is all liberal.
[00:47:22.960 --> 00:47:24.840]   Yeah, they snowflake platforms, right?
[00:47:24.840 --> 00:47:25.960]   They do whatever they want.
[00:47:25.960 --> 00:47:27.680]   They need to be regulated.
[00:47:27.680 --> 00:47:29.720]   They're trying to regulate us.
[00:47:29.720 --> 00:47:31.080]   We need to take control of them.
[00:47:31.080 --> 00:47:32.800]   Right.
[00:47:32.800 --> 00:47:33.720]   I don't know.
[00:47:33.720 --> 00:47:36.760]   I think I grew up in Mississippi.
[00:47:36.760 --> 00:47:38.840]   I grew up watching Fox.
[00:47:38.840 --> 00:47:41.680]   And I feel like one of my first jobs
[00:47:41.680 --> 00:47:44.000]   was working for the Republican Party in DC.
[00:47:44.000 --> 00:47:46.920]   So I feel like I really understand that mindset
[00:47:46.920 --> 00:47:50.400]   and the idea that the platforms or the media
[00:47:50.400 --> 00:47:54.600]   is out to get you and won't give you a fair shake.
[00:47:54.600 --> 00:47:58.520]   I can tell you, I was very motivated by that idea.
[00:47:58.520 --> 00:48:02.920]   And I think that if you can come to the conclusion that,
[00:48:02.920 --> 00:48:05.600]   oh, all these systems are against me,
[00:48:05.600 --> 00:48:08.760]   it allows you to kind of not think anything those systems
[00:48:08.760 --> 00:48:12.920]   are telling you are true with coronavirus or other subjects.
[00:48:12.920 --> 00:48:17.240]   So I do think it taps into a grander scheme other than,
[00:48:17.240 --> 00:48:21.120]   oh, I'm going to go vote on this issue.
[00:48:21.120 --> 00:48:24.360]   Although, I mean, those votes are already counted.
[00:48:24.360 --> 00:48:27.560]   I mean, that's in the base of anything
[00:48:27.560 --> 00:48:30.200]   you do to appease to the base is not going to get you more
[00:48:30.200 --> 00:48:32.520]   votes is maybe you'll get them out to vote.
[00:48:32.520 --> 00:48:34.440]   Maybe that's the idea.
[00:48:34.440 --> 00:48:36.960]   Get them angry and get them out there.
[00:48:36.960 --> 00:48:37.320]   Yeah.
[00:48:37.320 --> 00:48:39.200]   Well, the more you harp on those issues,
[00:48:39.200 --> 00:48:42.240]   though, the undecided voters, I think, seem to be like,
[00:48:42.240 --> 00:48:43.400]   well, maybe they're right.
[00:48:43.400 --> 00:48:45.560]   It's like the more you see something and hear something.
[00:48:45.560 --> 00:48:45.880]   Oh, yeah.
[00:48:45.880 --> 00:48:50.200]   It feels like a safe move to make to lean into that side.
[00:48:50.200 --> 00:48:50.440]   Yeah.
[00:48:50.440 --> 00:48:53.520]   If the DOJ says Google's bias, they must be.
[00:48:53.520 --> 00:48:53.920]   Right.
[00:48:53.920 --> 00:48:54.720]   Yeah.
[00:48:54.720 --> 00:48:55.160]   OK.
[00:48:55.160 --> 00:48:57.400]   That's fair.
[00:48:57.400 --> 00:48:58.160]   It did.
[00:48:58.160 --> 00:48:59.240]   It was rushed.
[00:48:59.240 --> 00:49:01.000]   They did want to get it out.
[00:49:01.000 --> 00:49:02.760]   It's not exactly an October surprise,
[00:49:02.760 --> 00:49:06.720]   but they want to get it out before the election, I think.
[00:49:06.720 --> 00:49:09.400]   And don't forget what's happening on Wednesday.
[00:49:09.400 --> 00:49:12.360]   It's the big congressional hearing
[00:49:12.360 --> 00:49:15.240]   on conservative bias in social media
[00:49:15.240 --> 00:49:17.720]   that's going to go on for a hand-as-close amount of forever
[00:49:17.720 --> 00:49:18.640]   time.
[00:49:18.640 --> 00:49:21.200]   And that's going to bring Jack Dorsey, you'll be there, right?
[00:49:21.200 --> 00:49:22.960]   From Twitter.
[00:49:22.960 --> 00:49:23.800]   I believe so.
[00:49:23.800 --> 00:49:28.960]   Yeah, I think a couple of the big tech people will be on--
[00:49:28.960 --> 00:49:33.640]   once again, on stage, testifying in front of Congress.
[00:49:33.640 --> 00:49:34.640]   On Zoom.
[00:49:34.640 --> 00:49:36.160]   I don't think anybody's playing on Zoom.
[00:49:36.160 --> 00:49:38.800]   They'll be from their Hawaiian hideouts or wherever,
[00:49:38.800 --> 00:49:41.360]   trying to look very modest in the background.
[00:49:41.360 --> 00:49:43.000]   The election, I mean, I just also
[00:49:43.000 --> 00:49:45.960]   feel like that doesn't help all of this right now.
[00:49:45.960 --> 00:49:48.400]   Like, bring the top people on social media.
[00:49:48.400 --> 00:49:51.080]   And with that side, so again, social media.
[00:49:51.080 --> 00:49:53.640]   And it's like just feeds into that narrative
[00:49:53.640 --> 00:49:55.200]   that they need to be questions.
[00:49:55.200 --> 00:49:57.280]   Like, you can't believe anything.
[00:49:57.280 --> 00:49:57.780]   Yeah.
[00:49:57.780 --> 00:50:04.360]   Well, I don't know.
[00:50:04.360 --> 00:50:05.840]   I don't know.
[00:50:05.840 --> 00:50:06.800]   I don't know.
[00:50:06.800 --> 00:50:12.440]   I feel like it's hard to imagine what the remedies would be.
[00:50:12.440 --> 00:50:15.760]   Is it just going to go poof after the election,
[00:50:15.760 --> 00:50:18.360]   or is this going to go on for 10 years?
[00:50:18.360 --> 00:50:22.520]   This is a war that's going to keep raging for our entire lives.
[00:50:22.520 --> 00:50:23.360]   It's not going to stop.
[00:50:23.360 --> 00:50:24.360]   Social war.
[00:50:24.360 --> 00:50:25.360]   Yeah.
[00:50:25.360 --> 00:50:26.360]   It's culture war.
[00:50:26.360 --> 00:50:27.360]   Culture war.
[00:50:27.360 --> 00:50:28.360]   Culture war.
[00:50:28.360 --> 00:50:29.360]   Yeah.
[00:50:29.360 --> 00:50:30.360]   Yeah.
[00:50:30.360 --> 00:50:31.360]   OK, well, great.
[00:50:31.360 --> 00:50:32.360]   Yeah.
[00:50:32.360 --> 00:50:33.760]   I just want to talk about the new iPhone.
[00:50:33.760 --> 00:50:34.760]   I'm really doing it.
[00:50:34.760 --> 00:50:35.760]   Yes.
[00:50:35.760 --> 00:50:36.760]   Yes.
[00:50:36.760 --> 00:50:38.760]   Yeah, it's a lighter thing.
[00:50:38.760 --> 00:50:40.960]   Heather, what do you cover tech?
[00:50:40.960 --> 00:50:42.640]   But do you cover everything in tech?
[00:50:42.640 --> 00:50:46.560]   Or what do you cover for The Washington Post?
[00:50:46.560 --> 00:50:48.160]   I mostly cover consumer tech.
[00:50:48.160 --> 00:50:50.360]   I look at trends that affect real people.
[00:50:50.360 --> 00:50:51.360]   Yeah.
[00:50:51.360 --> 00:50:54.440]   I did play a little bit with the iPhone.
[00:50:54.440 --> 00:50:56.760]   I wasn't doing our iPhone review this year for change.
[00:50:56.760 --> 00:50:58.720]   And I like the flat edges.
[00:50:58.720 --> 00:51:00.720]   It's my really important--
[00:51:00.720 --> 00:51:02.360]   I can't wait to take a look at that.
[00:51:02.360 --> 00:51:03.360]   Yeah.
[00:51:03.360 --> 00:51:04.960]   That's pretty much all you can say.
[00:51:04.960 --> 00:51:05.960]   You know, the edges.
[00:51:05.960 --> 00:51:06.960]   They're flat.
[00:51:06.960 --> 00:51:07.960]   I like that.
[00:51:07.960 --> 00:51:13.040]   Well, I talked to some iPhone 3e SE owners a while ago, and they swear that you can pop
[00:51:13.040 --> 00:51:15.600]   up in a beer with the flat edges of the older devices.
[00:51:15.600 --> 00:51:16.600]   Geez, Louise.
[00:51:16.600 --> 00:51:17.600]   Don't.
[00:51:17.600 --> 00:51:18.600]   Don't.
[00:51:18.600 --> 00:51:19.600]   No.
[00:51:19.600 --> 00:51:20.600]   Stop.
[00:51:20.600 --> 00:51:22.000]   But now I'm on live.
[00:51:22.000 --> 00:51:25.160]   Does Jeffrey Fowler get to do the review this year?
[00:51:25.160 --> 00:51:27.160]   He did the review.
[00:51:27.160 --> 00:51:31.480]   He took out like seven iPhones and tested the cameras and everything.
[00:51:31.480 --> 00:51:36.400]   He's also sort of our 5G expert, which is where this phone is.
[00:51:36.400 --> 00:51:37.400]   I pity the man.
[00:51:37.400 --> 00:51:38.400]   I'm the well-manged.
[00:51:38.400 --> 00:51:40.400]   He has a fun job.
[00:51:40.400 --> 00:51:41.400]   He loves it.
[00:51:41.400 --> 00:51:42.400]   Oh, good.
[00:51:42.400 --> 00:51:43.400]   No, I think Jeffrey's great.
[00:51:43.400 --> 00:51:46.840]   5G is the least compelling thing he says about the iPhone 12.
[00:51:46.840 --> 00:51:48.640]   And we've been saying that too.
[00:51:48.640 --> 00:51:50.880]   I think last week I played that picture.
[00:51:50.880 --> 00:51:51.880]   It's lovely, right?
[00:51:51.880 --> 00:51:52.880]   You took that.
[00:51:52.880 --> 00:51:55.680]   So do you like the blue?
[00:51:55.680 --> 00:51:56.680]   I mean, I don't know.
[00:51:56.680 --> 00:51:59.800]   I think this is a, I don't want to make any gender assumptions here.
[00:51:59.800 --> 00:52:02.200]   I feel like men are less likely to put it in a case.
[00:52:02.200 --> 00:52:04.600]   I would never have an iPhone without a case on it.
[00:52:04.600 --> 00:52:06.560]   That's just absolutely lunatic to me.
[00:52:06.560 --> 00:52:08.920]   Is that like not wearing a mask?
[00:52:08.920 --> 00:52:12.880]   I don't wear a mask and I'm not going to put my phone in a case.
[00:52:12.880 --> 00:52:13.880]   Freedom.
[00:52:13.880 --> 00:52:17.120]   Maybe it's because like we have like, I'll have a bag to put my phone in.
[00:52:17.120 --> 00:52:18.120]   Oh.
[00:52:18.120 --> 00:52:20.800]   I'm worried about having to get it into my pocket or a little friction there.
[00:52:20.800 --> 00:52:22.200]   And I think that's, that's more the reason.
[00:52:22.200 --> 00:52:25.320]   I make my daughter put her phone in the case.
[00:52:25.320 --> 00:52:29.720]   I also, I also will not go iPhone naked.
[00:52:29.720 --> 00:52:31.240]   I just don't believe in that.
[00:52:31.240 --> 00:52:32.720]   Got to put it in a case.
[00:52:32.720 --> 00:52:38.840]   That said, I'm so frustrated this time around that I feel like the, the lower cheaper model
[00:52:38.840 --> 00:52:41.640]   got all these cool bright vibrant colors.
[00:52:41.640 --> 00:52:42.640]   Yeah.
[00:52:42.640 --> 00:52:43.640]   Looking at the pro.
[00:52:43.640 --> 00:52:44.640]   We got robbed.
[00:52:44.640 --> 00:52:45.640]   Yeah.
[00:52:45.640 --> 00:52:46.640]   Right.
[00:52:46.640 --> 00:52:50.320]   Whatever graphite, you know, gold.
[00:52:50.320 --> 00:52:55.920]   It's like, it's like they think we're too classy to have the trashy bright colors.
[00:52:55.920 --> 00:52:56.920]   I'm not.
[00:52:56.920 --> 00:52:57.920]   I want to play.
[00:52:57.920 --> 00:52:59.640]   No, I'm trashy, baby.
[00:52:59.640 --> 00:53:02.320]   Here's another picture from a Washington Post photographer, Heather Kelly.
[00:53:02.320 --> 00:53:04.280]   That's beautiful.
[00:53:04.280 --> 00:53:07.280]   There's the difference in the blues between the, on the right, the iPhone 12.
[00:53:07.280 --> 00:53:08.520]   It's even fact you're blue, right?
[00:53:08.520 --> 00:53:09.520]   The cheaper one.
[00:53:09.520 --> 00:53:12.480]   It's like, oh, here's your bright, bright blue versus your palette blue.
[00:53:12.480 --> 00:53:13.720]   You cheap people.
[00:53:13.720 --> 00:53:15.280]   You want bright colors.
[00:53:15.280 --> 00:53:16.280]   Wow.
[00:53:16.280 --> 00:53:19.160]   I never even thought of that.
[00:53:19.160 --> 00:53:21.520]   You've created a class war over iPhone.
[00:53:21.520 --> 00:53:28.200]   So Leo, if you look at the history of like what cars and bright colors, it goes in waves.
[00:53:28.200 --> 00:53:32.880]   This is really interesting where it used to be in the model T was black when it came
[00:53:32.880 --> 00:53:33.880]   up, right?
[00:53:33.880 --> 00:53:34.880]   Yeah.
[00:53:34.880 --> 00:53:37.120]   Henry Ford famously said any color you want as long as it's black.
[00:53:37.120 --> 00:53:38.120]   Black.
[00:53:38.120 --> 00:53:41.560]   And then when we finally started figuring out how to do bright metallic paints, right, they
[00:53:41.560 --> 00:53:47.520]   would actually get fish scales and sacrifice 50,000 fish to your car.
[00:53:47.520 --> 00:53:48.920]   That's how they did that.
[00:53:48.920 --> 00:53:49.920]   Absolutely.
[00:53:49.920 --> 00:53:52.320]   Before they figured out how to do it with aluminum.
[00:53:52.320 --> 00:53:58.640]   So then that was the era that bright colors were associated with wealth that it switched.
[00:53:58.640 --> 00:54:02.280]   Then the nineties it switched back again, really bright colors.
[00:54:02.280 --> 00:54:07.360]   And now we're back to the top selling colors are white, silver and black.
[00:54:07.360 --> 00:54:10.320]   And the bright colors are associated with cheap.
[00:54:10.320 --> 00:54:14.440]   But I just I want to go back to the other like give me vibrates.
[00:54:14.440 --> 00:54:22.040]   You know, I'm embarrassed because I've I ordered the new electric Mustang Machi.
[00:54:22.040 --> 00:54:27.840]   And it comes the one I got comes in three colors, white, black, or what they call it
[00:54:27.840 --> 00:54:31.880]   grabber blue, which is that bright Mustang blue.
[00:54:31.880 --> 00:54:32.880]   That's problematic.
[00:54:32.880 --> 00:54:37.920]   And yeah, my reaction was I am not going to drive a bright blue car.
[00:54:37.920 --> 00:54:41.480]   Under no circumstances.
[00:54:41.480 --> 00:54:43.360]   So I got gray.
[00:54:43.360 --> 00:54:44.360]   Good.
[00:54:44.360 --> 00:54:45.360]   That's subtle.
[00:54:45.360 --> 00:54:46.360]   Really?
[00:54:46.360 --> 00:54:47.360]   Or is it boring?
[00:54:47.360 --> 00:54:48.360]   I know.
[00:54:48.360 --> 00:54:49.360]   You don't want to.
[00:54:49.360 --> 00:54:53.320]   I mean, also is insurance higher if it's brighter the car?
[00:54:53.320 --> 00:54:56.840]   I don't think that there was always, you know, there's always that thought, Oh, if you drive
[00:54:56.840 --> 00:55:00.200]   a red car, you're going to get ticketed for speeding more.
[00:55:00.200 --> 00:55:06.920]   What colors your car, I have a bright red $100,000 Porsche.
[00:55:06.920 --> 00:55:09.320]   I'm getting pulled over a lot more.
[00:55:09.320 --> 00:55:10.320]   Okay.
[00:55:10.320 --> 00:55:17.640]   I have that I have a silver classic, a classic silver boxer, which is more understated.
[00:55:17.640 --> 00:55:20.200]   But that was also the color of the new millennium.
[00:55:20.200 --> 00:55:26.280]   Do you remember that car came out in 2000 and we were all silver like that bright color.
[00:55:26.280 --> 00:55:27.520]   It was just, I don't know.
[00:55:27.520 --> 00:55:29.840]   It looks best in that color, but I don't know.
[00:55:29.840 --> 00:55:31.640]   I want to see your Machi when you get it.
[00:55:31.640 --> 00:55:32.880]   That's really exciting about it.
[00:55:32.880 --> 00:55:35.920]   I just got the email from Ford that there.
[00:55:35.920 --> 00:55:38.040]   You say your car will be made November 23rd.
[00:55:38.040 --> 00:55:39.040]   Oh, wow.
[00:55:39.040 --> 00:55:40.040]   Yeah.
[00:55:40.040 --> 00:55:41.040]   Fancy.
[00:55:41.040 --> 00:55:42.040]   I like electric.
[00:55:42.040 --> 00:55:43.040]   I had a Tesla.
[00:55:43.040 --> 00:55:44.040]   That's electric.
[00:55:44.040 --> 00:55:45.040]   Yeah, it's all electric.
[00:55:45.040 --> 00:55:46.040]   Yeah.
[00:55:46.040 --> 00:55:47.040]   Oh, wow.
[00:55:47.040 --> 00:55:48.040]   It's a four door Mustang.
[00:55:48.040 --> 00:55:49.040]   Yeah.
[00:55:49.040 --> 00:55:50.040]   Oh, I love that.
[00:55:50.040 --> 00:55:51.040]   Oh, yeah.
[00:55:51.040 --> 00:55:52.040]   But it doesn't make that big Mustang sound.
[00:55:52.040 --> 00:55:53.040]   It does.
[00:55:53.040 --> 00:55:54.040]   It has three sounds.
[00:55:54.040 --> 00:55:55.040]   Wow.
[00:55:55.040 --> 00:55:56.040]   That's so funny.
[00:55:56.040 --> 00:55:57.800]   You should say that it actually has three sounds.
[00:55:57.800 --> 00:56:02.840]   One of them is the rumble-throated Mustang sound.
[00:56:02.840 --> 00:56:07.080]   I used to have a Mustang 5.0 GT.
[00:56:07.080 --> 00:56:09.840]   And it goes, "No, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,
[00:56:09.840 --> 00:56:10.840]   no."
[00:56:10.840 --> 00:56:13.160]   And apparently there's a recording that plays in the cabin.
[00:56:13.160 --> 00:56:14.160]   That's hilarious.
[00:56:14.160 --> 00:56:15.880]   You turn on your Mustang.
[00:56:15.880 --> 00:56:17.520]   I can't wait.
[00:56:17.520 --> 00:56:20.640]   But it does that in the Porsche Taycan as well.
[00:56:20.640 --> 00:56:21.640]   Yeah.
[00:56:21.640 --> 00:56:22.640]   Yeah.
[00:56:22.640 --> 00:56:24.440]   So, I mean, how did you decide between those two?
[00:56:24.440 --> 00:56:26.200]   I mean, I personally think the Porsche is a good one.
[00:56:26.200 --> 00:56:27.200]   I can't afford a Taycan.
[00:56:27.200 --> 00:56:28.200]   I'd love a Taycan.
[00:56:28.200 --> 00:56:29.200]   Are you kidding me?
[00:56:29.200 --> 00:56:30.200]   It's beautiful.
[00:56:30.200 --> 00:56:31.200]   They drive really heavy.
[00:56:31.200 --> 00:56:32.760]   I don't know if you've had a chance to do it.
[00:56:32.760 --> 00:56:33.760]   But it's like $130,000.
[00:56:33.760 --> 00:56:35.760]   What do you think I am?
[00:56:35.760 --> 00:56:36.760]   Made of money?
[00:56:36.760 --> 00:56:38.760]   It's a beautiful car.
[00:56:38.760 --> 00:56:39.760]   It's a beautiful car.
[00:56:39.760 --> 00:56:42.000]   No, I do like electric.
[00:56:42.000 --> 00:56:45.360]   I had a Model X for years and I gave that up.
[00:56:45.360 --> 00:56:47.880]   And Lisa's driving a Chevy Bolt.
[00:56:47.880 --> 00:56:51.920]   We have like 50 or 60 solar panels on the house.
[00:56:51.920 --> 00:56:52.920]   So we make our own power.
[00:56:52.920 --> 00:56:53.920]   Wow.
[00:56:53.920 --> 00:56:54.920]   Good for you.
[00:56:54.920 --> 00:56:55.920]   Wow.
[00:56:55.920 --> 00:56:56.920]   That's great.
[00:56:56.920 --> 00:56:58.840]   We've got two of those Tesla batteries.
[00:56:58.840 --> 00:57:04.800]   Because where we are, the PG&E, our electric company, turns off the power just randomly
[00:57:04.800 --> 00:57:10.600]   for them because the power causes fires and fires cause death, destruction, and mayhem.
[00:57:10.600 --> 00:57:15.520]   And so, you know, we've already been told that the power, right, John?
[00:57:15.520 --> 00:57:19.120]   The power might go off again this week.
[00:57:19.120 --> 00:57:20.120]   Not here.
[00:57:20.120 --> 00:57:21.120]   It's going out already.
[00:57:21.120 --> 00:57:23.560]   The reason, this is so annoying.
[00:57:23.560 --> 00:57:29.080]   The reason is our electric company, when given millions of dollars by the state to fix the
[00:57:29.080 --> 00:57:33.320]   power lines, get them out of the trees, cut back the brush and all that stuff, instead
[00:57:33.320 --> 00:57:36.240]   gave the executives bonuses.
[00:57:36.240 --> 00:57:41.760]   And now they're afraid on windy days or dry days or warm days, guess what?
[00:57:41.760 --> 00:57:43.480]   We're in California.
[00:57:43.480 --> 00:57:51.480]   On windy days, dry days or hot days, they turn off the power because they're afraid
[00:57:51.480 --> 00:57:54.400]   it'll spark a wildfire.
[00:57:54.400 --> 00:57:57.000]   So which is just nuts.
[00:57:57.000 --> 00:57:58.160]   Heather, you're in San Francisco.
[00:57:58.160 --> 00:57:59.960]   You don't have to worry about this.
[00:57:59.960 --> 00:58:00.960]   But you got smoked out.
[00:58:00.960 --> 00:58:06.360]   I get to chip in with our fire coverage, being out here for the Washington Post.
[00:58:06.360 --> 00:58:10.360]   But yeah, I mean tonight until tomorrow, it's expected to be one of the worst wind events
[00:58:10.360 --> 00:58:11.360]   of the season yet.
[00:58:11.360 --> 00:58:13.600]   So all of that.
[00:58:13.600 --> 00:58:19.720]   Anyway, that's why I got the batteries because if they turn off the power, we can still flush
[00:58:19.720 --> 00:58:20.720]   the toilets.
[00:58:20.720 --> 00:58:25.720]   No, you need electricity to flush the toilet.
[00:58:25.720 --> 00:58:26.720]   Do you?
[00:58:26.720 --> 00:58:28.080]   No, you need your water.
[00:58:28.080 --> 00:58:29.080]   Our toilets.
[00:58:29.080 --> 00:58:31.680]   Well, okay, so it's two things.
[00:58:31.680 --> 00:58:33.360]   And regret asking.
[00:58:33.360 --> 00:58:35.280]   You're going to really regret this.
[00:58:35.280 --> 00:58:40.200]   But we have a pump because we're on a well and the pump needs electricity.
[00:58:40.200 --> 00:58:43.960]   So if the pump stops for any length of time, no water.
[00:58:43.960 --> 00:58:47.720]   And then we have those fancy Japanese toilets.
[00:58:47.720 --> 00:58:51.800]   If you unplug them, they're just dead pieces of ceramic.
[00:58:51.800 --> 00:58:53.360]   They don't do anything.
[00:58:53.360 --> 00:58:56.240]   They can't clean you the way you're used to being clean.
[00:58:56.240 --> 00:59:02.680]   I can't be clean in the fashion I expect.
[00:59:02.680 --> 00:59:03.680]   But I don't think they even flush.
[00:59:03.680 --> 00:59:06.320]   I think even the flush is electronic.
[00:59:06.320 --> 00:59:07.320]   There's no manual.
[00:59:07.320 --> 00:59:08.320]   Answer me.
[00:59:08.320 --> 00:59:09.320]   Think you're a life Leo.
[00:59:09.320 --> 00:59:11.320]   I think I need to.
[00:59:11.320 --> 00:59:15.640]   Yeah, I'm telling you, I'm not sticking with the manual transmission.
[00:59:15.640 --> 00:59:17.640]   I'm sticking with the manual toilet.
[00:59:17.640 --> 00:59:20.360]   Just keep me old school.
[00:59:20.360 --> 00:59:21.360]   I don't know.
[00:59:21.360 --> 00:59:23.560]   There's no transmission on my electric vehicles.
[00:59:23.560 --> 00:59:24.560]   There you go.
[00:59:24.560 --> 00:59:26.000]   Just push the not the button.
[00:59:26.000 --> 00:59:30.640]   Yeah, what I thought about doing EV West has a kit out there in California.
[00:59:30.640 --> 00:59:34.720]   And the next time I find a reason to go out there when there's not a pandemic, you can
[00:59:34.720 --> 00:59:43.640]   buy a $30,000 kit and they will take a classic car and you can remove the M96 or M97 engine
[00:59:43.640 --> 00:59:46.240]   in it in a Porsche Boxster or Cayman or 911.
[00:59:46.240 --> 00:59:47.240]   Do it.
[00:59:47.240 --> 00:59:51.000]   And put batteries in Panasonic batteries.
[00:59:51.000 --> 00:59:54.200]   You get the manual transmission because that's not removed.
[00:59:54.200 --> 00:59:56.640]   It's a central engine.
[00:59:56.640 --> 01:00:01.560]   And you get all the benefits of an electric, but you still get all the styling and drive
[01:00:01.560 --> 01:00:03.640]   feel of a traditional car.
[01:00:03.640 --> 01:00:07.440]   You know, the car I really want.
[01:00:07.440 --> 01:00:15.240]   Neil Young took a Lincoln with suicide doors.
[01:00:15.240 --> 01:00:21.680]   He calls it his link vault and he electrified it.
[01:00:21.680 --> 01:00:24.080]   And I think you can buy it.
[01:00:24.080 --> 01:00:25.080]   I'm not sure.
[01:00:25.080 --> 01:00:31.920]   But he took a 1959 Lincoln Continental with suicide doors and electrified it.
[01:00:31.920 --> 01:00:37.280]   It probably writes like an electric boat.
[01:00:37.280 --> 01:00:40.720]   But I just that's what I really want.
[01:00:40.720 --> 01:00:41.720]   That's cool.
[01:00:41.720 --> 01:00:43.440]   Wouldn't that be cool?
[01:00:43.440 --> 01:00:48.000]   You saw that they electrified the Jaguar E-Type from the 1967.
[01:00:48.000 --> 01:00:49.560]   That's so expensive.
[01:00:49.560 --> 01:00:52.520]   That's the one actually I would love that with a big long hood.
[01:00:52.520 --> 01:00:55.040]   Yeah, I'll never afford it.
[01:00:55.040 --> 01:00:56.040]   No.
[01:00:56.040 --> 01:00:59.720]   We were going to talk about the iPhone, but somehow we got sidetracked.
[01:00:59.720 --> 01:01:01.560]   No, no, it's not.
[01:01:01.560 --> 01:01:04.000]   I've tried to talk about the iPhone for two weeks in a row now.
[01:01:04.000 --> 01:01:06.480]   I can't get anybody to bite.
[01:01:06.480 --> 01:01:09.320]   Okay, so bottom line, I am skipping this year.
[01:01:09.320 --> 01:01:12.120]   I am skipping this year.
[01:01:12.120 --> 01:01:16.200]   You know, so I ended up buying the iPhone 11 Pro.
[01:01:16.200 --> 01:01:17.720]   That camera is 10 out of 10.
[01:01:17.720 --> 01:01:18.720]   I love it.
[01:01:18.720 --> 01:01:19.720]   I'm not a picture person.
[01:01:19.720 --> 01:01:20.720]   It's the next one.
[01:01:20.720 --> 01:01:21.720]   I'm very happy.
[01:01:21.720 --> 01:01:22.720]   It is great.
[01:01:22.720 --> 01:01:25.280]   I do not regret buying the 11 Pro at all.
[01:01:25.280 --> 01:01:30.760]   But you look at this year 5G, I think there's never been a less compelling year to upgrade
[01:01:30.760 --> 01:01:31.760]   5G.
[01:01:31.760 --> 01:01:32.760]   I'm so annoyed with 5G.
[01:01:32.760 --> 01:01:33.760]   I'm so annoyed.
[01:01:33.760 --> 01:01:36.160]   With all the marketing hype, it's crazy.
[01:01:36.160 --> 01:01:41.240]   Well, Christina has that New York Times podcast with Verizon.
[01:01:41.240 --> 01:01:42.800]   So good on her for a live.
[01:01:42.800 --> 01:01:43.800]   Yeah, we won't say that.
[01:01:43.800 --> 01:01:46.560]   Yeah, she was here last week and she mentioned that.
[01:01:46.560 --> 01:01:47.560]   Yeah.
[01:01:47.560 --> 01:01:51.600]   But 5G, right now, I'm barely leaving my house.
[01:01:51.600 --> 01:01:54.360]   It's not here in Dedham on the outskirts of Boston.
[01:01:54.360 --> 01:01:55.360]   Anywhere.
[01:01:55.360 --> 01:01:57.000]   There's just no point to it.
[01:01:57.000 --> 01:01:59.800]   It's so inconsistent when it does work.
[01:01:59.800 --> 01:02:02.520]   So that's not compelling.
[01:02:02.520 --> 01:02:10.320]   You know, the camera upgrades and the 12 Pro this year, I personally don't find that compelling.
[01:02:10.320 --> 01:02:15.440]   I just, that's why I was so surprised with the show notes for planning this week.
[01:02:15.440 --> 01:02:20.240]   The Apple is expecting the 12 to be one of their best selling phones in a long time.
[01:02:20.240 --> 01:02:25.960]   And I'm just, I'm really stunned because it doesn't look like a year to upgrade to me.
[01:02:25.960 --> 01:02:27.880]   And do people have the money to pay for new phones right now?
[01:02:27.880 --> 01:02:28.880]   Is that a priority?
[01:02:28.880 --> 01:02:29.880]   Right.
[01:02:29.880 --> 01:02:30.880]   Or right.
[01:02:30.880 --> 01:02:31.880]   Yeah.
[01:02:31.880 --> 01:02:35.920]   Well, I think also a lot of people always do people have more expendable cash.
[01:02:35.920 --> 01:02:36.920]   Say again.
[01:02:36.920 --> 01:02:38.800]   Like people have more expendable cash.
[01:02:38.800 --> 01:02:40.200]   The people who have jobs.
[01:02:40.200 --> 01:02:43.200]   I mean, because if you're still, if you're not out of work.
[01:02:43.200 --> 01:02:44.200]   Yeah.
[01:02:44.200 --> 01:02:46.200]   So you've got kind of this, this split.
[01:02:46.200 --> 01:02:47.640]   No, that's actually a good point.
[01:02:47.640 --> 01:02:49.520]   Because we're not going out to eat.
[01:02:49.520 --> 01:02:51.120]   We're not paying for travel.
[01:02:51.120 --> 01:02:52.120]   We're not vacationing.
[01:02:52.120 --> 01:02:54.600]   Yeah, that's a good point.
[01:02:54.600 --> 01:02:55.600]   So maybe.
[01:02:55.600 --> 01:02:56.600]   But also night selfies.
[01:02:56.600 --> 01:02:57.600]   So maybe.
[01:02:57.600 --> 01:03:06.840]   So tell me, tell me, so you obviously, I mean, I know Jeffrey got the review, but you got
[01:03:06.840 --> 01:03:08.640]   to play with the pro, right?
[01:03:08.640 --> 01:03:10.200]   Well, it was daytime.
[01:03:10.200 --> 01:03:15.880]   And so I should actually have taken one is I, I, I love night mode on, I have an 11.
[01:03:15.880 --> 01:03:18.600]   I don't think anybody should upgrade because there's a new phone.
[01:03:18.600 --> 01:03:22.320]   It should always be because your old phone is no longer functional in some way that you
[01:03:22.320 --> 01:03:23.320]   can't pay to fix.
[01:03:23.320 --> 01:03:25.720]   It's silly to be like, Oh, I just want this one new feature.
[01:03:25.720 --> 01:03:28.120]   I got a new phone last year.
[01:03:28.120 --> 01:03:29.120]   It should be like a laptop.
[01:03:29.120 --> 01:03:32.680]   You know, you get a new laptop and your old ones too slow.
[01:03:32.680 --> 01:03:37.800]   That said, everyone gets a new phone just for a new one new feature just to say they
[01:03:37.800 --> 01:03:39.400]   have it.
[01:03:39.400 --> 01:03:40.400]   If you can afford it.
[01:03:40.400 --> 01:03:41.960]   If you can afford it.
[01:03:41.960 --> 01:03:48.640]   Here's Jeffrey's pictures showing the night mode in a evening scene.
[01:03:48.640 --> 01:03:52.400]   This is the iPhone seven and the iPhone 10, the iPhone 11.
[01:03:52.400 --> 01:03:56.640]   And boy, the 12, you know, you can read the sign for one thing.
[01:03:56.640 --> 01:03:59.760]   I mean, this is pretty amazing.
[01:03:59.760 --> 01:04:02.160]   And they, they've, they've expanded it to all the cameras.
[01:04:02.160 --> 01:04:04.960]   It was just on one camera before, but now you can do it in the front facing, all the
[01:04:04.960 --> 01:04:07.720]   back facing telephoto and that, that seems awesome.
[01:04:07.720 --> 01:04:09.640]   I use it at night when I put my kids to sleep.
[01:04:09.640 --> 01:04:12.520]   I can't see in the dark if they're actually asleep and I use night mode.
[01:04:12.520 --> 01:04:14.000]   I think night to make sure they're.
[01:04:14.000 --> 01:04:18.160]   I mean, why are you showing and then Fred light my eyes, mommy?
[01:04:18.160 --> 01:04:19.160]   Please.
[01:04:19.160 --> 01:04:20.640]   You're for kids.
[01:04:20.640 --> 01:04:24.480]   It's low our list of issues.
[01:04:24.480 --> 01:04:28.600]   When I was growing up, I would always see this red light in my eyes.
[01:04:28.600 --> 01:04:30.560]   It doesn't have a red light, does it?
[01:04:30.560 --> 01:04:32.000]   No, it's invisible.
[01:04:32.000 --> 01:04:33.920]   Unless they're lizard children, they can't see it.
[01:04:33.920 --> 01:04:35.160]   So you're, you're safe.
[01:04:35.160 --> 01:04:36.160]   They weren't.
[01:04:36.160 --> 01:04:37.160]   Yeah.
[01:04:37.160 --> 01:04:43.280]   I, I do think the ceramic, the, so I am not a coordinated person.
[01:04:43.280 --> 01:04:46.600]   I dropped my phone like 500 times a day.
[01:04:46.600 --> 01:04:51.680]   I will own it on that person that gets my money back from Apple care every single time I buy
[01:04:51.680 --> 01:04:52.680]   it.
[01:04:52.680 --> 01:04:58.240]   And if it really is four times stronger, that is a very compelling feature to me.
[01:04:58.240 --> 01:05:02.840]   I was just harden in, you know, our friend Joanna Stern's review, the apple wouldn't
[01:05:02.840 --> 01:05:05.280]   let her actually drop test it.
[01:05:05.280 --> 01:05:06.880]   So she's in the middle of the stadium.
[01:05:06.880 --> 01:05:08.120]   They wouldn't let her.
[01:05:08.120 --> 01:05:09.880]   Rose, they wouldn't let her do it.
[01:05:09.880 --> 01:05:12.120]   So she's just throwing the phone around.
[01:05:12.120 --> 01:05:13.480]   That's why you got to buy them.
[01:05:13.480 --> 01:05:14.480]   Yeah.
[01:05:14.480 --> 01:05:17.080]   What are they going to do if she actually broke it?
[01:05:17.080 --> 01:05:18.560]   No more phones for Joanna Stern.
[01:05:18.560 --> 01:05:20.640]   No, that's not going to happen.
[01:05:20.640 --> 01:05:21.640]   You're absolutely not.
[01:05:21.640 --> 01:05:23.640]   She's, she's a rule follower.
[01:05:23.640 --> 01:05:24.640]   She's, she's chaotic.
[01:05:24.640 --> 01:05:25.640]   Good.
[01:05:25.640 --> 01:05:30.680]   I have to tell you though, that's why I'm not invited to Apple.
[01:05:30.680 --> 01:05:33.400]   Apparently I'm not a rule follower.
[01:05:33.400 --> 01:05:34.400]   I don't know.
[01:05:34.400 --> 01:05:38.640]   I think that in MagSafe, I think that is the other really interesting thing this year.
[01:05:38.640 --> 01:05:44.120]   You know, lightning, I think is a, I think most of us that are tech people want to see
[01:05:44.120 --> 01:05:48.280]   us just get rid of lightning, put USB-C on it.
[01:05:48.280 --> 01:05:50.600]   You're not going to get your wish.
[01:05:50.600 --> 01:05:52.880]   It's all ports are going to be gone next year.
[01:05:52.880 --> 01:05:53.880]   I think you're right.
[01:05:53.880 --> 01:05:55.480]   I think we're going to move to a MagSafe feature.
[01:05:55.480 --> 01:05:57.160]   They could have gone to see this year.
[01:05:57.160 --> 01:05:58.880]   And I think they thought, you know, why?
[01:05:58.880 --> 01:06:02.000]   Because we're just going to get rid of all ports and it's just going to be MagSafe.
[01:06:02.000 --> 01:06:03.000]   Yeah.
[01:06:03.000 --> 01:06:04.720]   But like, do we really want another proprietary?
[01:06:04.720 --> 01:06:08.680]   Like at least last year it worked with all the wireless chargers.
[01:06:08.680 --> 01:06:10.840]   And I was like, no, no, only Apple MagSafe.
[01:06:10.840 --> 01:06:12.840]   No, this will still work on a Qi charger.
[01:06:12.840 --> 01:06:14.240]   You can still use a Qi charger.
[01:06:14.240 --> 01:06:15.240]   Yeah, yeah, yeah.
[01:06:15.240 --> 01:06:16.240]   They said that.
[01:06:16.240 --> 01:06:17.240]   It just isn't as good.
[01:06:17.240 --> 01:06:19.960]   Cars need to have those chargers like this.
[01:06:19.960 --> 01:06:26.320]   My Mustang Mach-E has, this is actually the only reason I bought it.
[01:06:26.320 --> 01:06:31.880]   It has two Qi chargers where you put your phones down and it's wireless car play or
[01:06:31.880 --> 01:06:35.160]   Android Auto, so you don't even have to plug it in for the car play.
[01:06:35.160 --> 01:06:37.680]   Just put it down and you're going, man.
[01:06:37.680 --> 01:06:39.840]   Like one for you and one for the passenger?
[01:06:39.840 --> 01:06:40.840]   Yes.
[01:06:40.840 --> 01:06:41.840]   That's cool.
[01:06:41.840 --> 01:06:42.840]   Yes.
[01:06:42.840 --> 01:06:45.040]   Isn't that awesome?
[01:06:45.040 --> 01:06:46.040]   Let's take a little break.
[01:06:46.040 --> 01:06:51.400]   We will come back and talk about more and consequential matters with our fabulous panel.
[01:06:51.400 --> 01:06:55.160]   Cheryl Azhar is here from WeAreChannelQ.com.
[01:06:55.160 --> 01:06:57.760]   She dances just like Elaine and Seinfeld.
[01:06:57.760 --> 01:06:58.760]   Do the thumbs.
[01:06:58.760 --> 01:06:59.760]   Do the thumbs.
[01:06:59.760 --> 01:07:00.760]   Why does that what she does?
[01:07:00.760 --> 01:07:01.760]   Oh my gosh.
[01:07:01.760 --> 01:07:03.080]   That was her dance right there.
[01:07:03.080 --> 01:07:04.080]   You did the Elaine.
[01:07:04.080 --> 01:07:05.080]   Can you realize that?
[01:07:05.080 --> 01:07:06.080]   That's the name.
[01:07:06.080 --> 01:07:07.920]   No, no, I've seen your Instagram videos.
[01:07:07.920 --> 01:07:08.920]   You dance beautifully.
[01:07:08.920 --> 01:07:09.920]   Maybe not.
[01:07:09.920 --> 01:07:10.920]   Maybe I'm being kind.
[01:07:10.920 --> 01:07:19.480]   Also Heather Kelly is here from the Washington Post.
[01:07:19.480 --> 01:07:23.080]   Wonderful to have you for the first time, not the last, I hope.
[01:07:23.080 --> 01:07:25.760]   Where are your children right now?
[01:07:25.760 --> 01:07:26.760]   I thought you had them.
[01:07:26.760 --> 01:07:27.760]   Oh, God.
[01:07:27.760 --> 01:07:32.200]   We've locked them out of the studio.
[01:07:32.200 --> 01:07:34.480]   There's somewhere we don't know.
[01:07:34.480 --> 01:07:38.080]   Also, the wonderful Brianna Wu and her Porsche Boxster.
[01:07:38.080 --> 01:07:39.640]   Oh, no, I'm sorry.
[01:07:39.640 --> 01:07:40.800]   That's a Peloton bike.
[01:07:40.800 --> 01:07:42.280]   That's quite a long time.
[01:07:42.280 --> 01:07:45.400]   I'm going to ask you about Rebellion Pack when we get back because I'm very curious, executive
[01:07:45.400 --> 01:07:48.480]   director at rebellionpack.com.
[01:07:48.480 --> 01:07:50.040]   Are you looking to raise money?
[01:07:50.040 --> 01:07:51.040]   Yes, absolutely.
[01:07:51.040 --> 01:07:54.720]   If you want to help get Trump out of office, go to help the rebellion.com.
[01:07:54.720 --> 01:07:56.880]   What are you going to do next week?
[01:07:56.880 --> 01:07:58.280]   I'm not going to do next week.
[01:07:58.280 --> 01:08:04.680]   We're going to keep money on hand in case the election is contested to basically pull
[01:08:04.680 --> 01:08:07.320]   support there and then we're going to look at 2022.
[01:08:07.320 --> 01:08:08.320]   Yes.
[01:08:08.320 --> 01:08:11.920]   So what if let's assume I'll give you a scenario.
[01:08:11.920 --> 01:08:12.920]   I don't know what's going to happen.
[01:08:12.920 --> 01:08:15.560]   Let's assume Biden wins.
[01:08:15.560 --> 01:08:17.400]   It's not contested November 10.
[01:08:17.400 --> 01:08:18.400]   It's all over.
[01:08:18.400 --> 01:08:19.400]   Then what do you do?
[01:08:19.400 --> 01:08:20.400]   Go home.
[01:08:20.400 --> 01:08:23.520]   No, you know, I still believe in these policies.
[01:08:23.520 --> 01:08:24.520]   I want to argue.
[01:08:24.520 --> 01:08:26.160]   Yeah, I mean, he's not a Medicare for all guys.
[01:08:26.160 --> 01:08:29.520]   So maybe you could still push him to the left, right?
[01:08:29.520 --> 01:08:30.520]   Absolutely.
[01:08:30.520 --> 01:08:33.520]   I think we're not just about Medicare for all.
[01:08:33.520 --> 01:08:39.600]   Rebellion Pack exists to bridge this gap between progressive Democrats and more traditional
[01:08:39.600 --> 01:08:40.600]   Democrats.
[01:08:40.600 --> 01:08:41.840]   We're arguing with each other.
[01:08:41.840 --> 01:08:44.000]   We don't need to be.
[01:08:44.000 --> 01:08:46.320]   We want to have our voice in that conversation.
[01:08:46.320 --> 01:08:48.040]   We want to work it with the system.
[01:08:48.040 --> 01:08:55.160]   So issues like LGBT rights or women's reproductive health care, things like that.
[01:08:55.160 --> 01:09:00.840]   You want to stand there and push the conversation in a direction we agree with within the system.
[01:09:00.840 --> 01:09:02.400]   We're looking for a C at the table.
[01:09:02.400 --> 01:09:08.520]   Well, I just want to announce the formation of my new pack, the Empire Pack.
[01:09:08.520 --> 01:09:13.360]   Our director, Darth Maul, will be glad to meet with you in debate anytime.
[01:09:13.360 --> 01:09:14.360]   Okay.
[01:09:14.360 --> 01:09:15.360]   Rebels.
[01:09:15.360 --> 01:09:16.360]   You rebels you.
[01:09:16.360 --> 01:09:17.360]   Are you sure?
[01:09:17.360 --> 01:09:22.200]   Are you sure they brought to you by the last pass?
[01:09:22.200 --> 01:09:24.600]   You see, here we are in the last pass.
[01:09:24.600 --> 01:09:25.600]   Studios.
[01:09:25.600 --> 01:09:26.680]   We are fans of last pass.
[01:09:26.680 --> 01:09:31.480]   I've been using last pass as my password manager for as long as they've been around.
[01:09:31.480 --> 01:09:34.160]   More than a decade, I think 12 years.
[01:09:34.160 --> 01:09:36.680]   Steve Gibson, I can't believe it's 10 years ago.
[01:09:36.680 --> 01:09:40.400]   We had our security guy, Steve Gibson of security now.
[01:09:40.400 --> 01:09:42.480]   Go under the covers with last pass.
[01:09:42.480 --> 01:09:45.600]   He got Jogus E. Grist, its founder to show them all the code.
[01:09:45.600 --> 01:09:46.760]   He said, this is amazing.
[01:09:46.760 --> 01:09:48.600]   This is exactly what you want.
[01:09:48.600 --> 01:09:51.600]   He's been using it now for a decade.
[01:09:51.600 --> 01:09:54.080]   20,000 businesses use last pass.
[01:09:54.080 --> 01:09:55.880]   25 million users.
[01:09:55.880 --> 01:09:58.960]   It is the award winning number one password manager.
[01:09:58.960 --> 01:09:59.960]   Okay.
[01:09:59.960 --> 01:10:04.920]   Maybe you can give COVID a little credit for the number of businesses using last pass because
[01:10:04.920 --> 01:10:10.680]   when you start sending employees home, they are no longer in the protected environs of
[01:10:10.680 --> 01:10:12.000]   your office.
[01:10:12.000 --> 01:10:15.920]   They are at home with the passwords, the keys to the kingdom to your bank account, your
[01:10:15.920 --> 01:10:19.680]   website, your customer records, everything.
[01:10:19.680 --> 01:10:24.600]   But identity and access management is teetering.
[01:10:24.600 --> 01:10:29.160]   So you've got to make sure you've got something to protect your assets.
[01:10:29.160 --> 01:10:30.960]   And that's what last pass is.
[01:10:30.960 --> 01:10:33.720]   It's been a saving grace to our company.
[01:10:33.720 --> 01:10:37.440]   We use last pass to enable our team to set up, utilize.
[01:10:37.440 --> 01:10:41.800]   And this is important to share strong passwords for their accounts and programs.
[01:10:41.800 --> 01:10:46.480]   If they're at home, you don't want them texting each other passwords or emailing them in clear
[01:10:46.480 --> 01:10:47.480]   text.
[01:10:47.480 --> 01:10:50.200]   If you use last pass, it will send them securely.
[01:10:50.200 --> 01:10:53.920]   This is an important step towards improving data security.
[01:10:53.920 --> 01:10:56.000]   But here's the thing about last pass.
[01:10:56.000 --> 01:10:57.360]   They do something kind of magical.
[01:10:57.360 --> 01:11:00.680]   Usually there's a tradeoff between convenience and security.
[01:11:00.680 --> 01:11:02.760]   You can have one or the other.
[01:11:02.760 --> 01:11:09.200]   Last pass somehow makes it even easier to work from home, makes it even more convenient
[01:11:09.200 --> 01:11:11.440]   for employees in a lot of different ways.
[01:11:11.440 --> 01:11:16.960]   Of course, the last pass vault, auto fills wherever you are, works on Mac, Windows, Linux,
[01:11:16.960 --> 01:11:20.520]   with every browser known to man on your iPhone and your Android phone.
[01:11:20.520 --> 01:11:24.200]   And that auto fill means they don't have to type passwords anymore.
[01:11:24.200 --> 01:11:26.760]   Last pass generates long, strong passwords.
[01:11:26.760 --> 01:11:28.960]   You don't have to remember them anymore.
[01:11:28.960 --> 01:11:29.960]   It is awesome.
[01:11:29.960 --> 01:11:35.320]   And one of the things you always get with last pass is oversight of shadow IT, enforceable
[01:11:35.320 --> 01:11:36.480]   policies.
[01:11:36.480 --> 01:11:42.120]   So your IT department likes last pass too because they know exactly who's using what, when
[01:11:42.120 --> 01:11:43.120]   and where.
[01:11:43.120 --> 01:11:49.600]   Sure, every single person using your precious assets is authorized to do so.
[01:11:49.600 --> 01:11:51.240]   That's what last pass does.
[01:11:51.240 --> 01:11:57.880]   They support not only two factor face or recognition or fingerprint ID.
[01:11:57.880 --> 01:12:02.920]   They also support multi factor, additional contextual factors that help make sure the
[01:12:02.920 --> 01:12:04.880]   right person is using the right resource.
[01:12:04.880 --> 01:12:10.200]   Things like geo location and IP address.
[01:12:10.200 --> 01:12:15.120]   This pass uses a zero security knowledge model as your knowledge, secure, that's what all
[01:12:15.120 --> 01:12:16.280]   the big companies do.
[01:12:16.280 --> 01:12:20.720]   It's the kind of the state of the art and security where you assume there is no secure
[01:12:20.720 --> 01:12:21.960]   perimeter.
[01:12:21.960 --> 01:12:24.760]   Anybody using any resource has to authenticate.
[01:12:24.760 --> 01:12:26.360]   That's what last pass does.
[01:12:26.360 --> 01:12:29.000]   That's because securities are top priority.
[01:12:29.000 --> 01:12:37.320]   AES 256 bit encryption, PBK DF2 to make it hard to brute force salted hashes SHA 256,
[01:12:37.320 --> 01:12:41.800]   all of the buzzwords, all of the security things you know, that's what they do.
[01:12:41.800 --> 01:12:46.240]   Data is encrypted and decrypted only at device level.
[01:12:46.240 --> 01:12:50.720]   Your master password is never transmitted, not the last pass, not to anywhere.
[01:12:50.720 --> 01:12:52.880]   The data in your vault is completely secure.
[01:12:52.880 --> 01:12:57.000]   That's why I use last pass, not just for passwords, but passports, drivers, licenses,
[01:12:57.000 --> 01:12:58.000]   everything.
[01:12:58.000 --> 01:13:02.360]   Last passes one eight awards so far this year alone, PC magazines, editors choice, the
[01:13:02.360 --> 01:13:08.400]   fortress cybersecurity award, business insiders, best overall password manager, and many more
[01:13:08.400 --> 01:13:09.400]   and go on and on.
[01:13:09.400 --> 01:13:14.320]   But look, you don't have to take their word for it or my word, last pass speaks for itself.
[01:13:14.320 --> 01:13:18.960]   This is the time there is last pass for every possible scenario.
[01:13:18.960 --> 01:13:22.040]   Go to last pass dot com slash twit.
[01:13:22.040 --> 01:13:24.520]   It's the first thing I put on any new device.
[01:13:24.520 --> 01:13:31.680]   It's the last thing I ever take off last pass dot com slash twit because stronger security
[01:13:31.680 --> 01:13:33.120]   cannot wait.
[01:13:33.120 --> 01:13:35.200]   Thank you last pass for your support.
[01:13:35.200 --> 01:13:39.240]   He's the burden for yourself and your remote workforce with the cyber security protection
[01:13:39.240 --> 01:13:40.240]   you need.
[01:13:40.240 --> 01:13:43.640]   Last pass dot com slash twit.
[01:13:43.640 --> 01:13:49.960]   We had a very good week this week on Twitter and I'm hoping that our crack team of editors
[01:13:49.960 --> 01:13:53.840]   and producers put together a little mini movie for your enjoyment.
[01:13:53.840 --> 01:13:54.840]   Watch.
[01:13:54.840 --> 01:14:00.280]   I'd like to talk about that the apples down holding Charlie Brown and the penis gang hostage.
[01:14:00.280 --> 01:14:02.080]   Are you saying that you can only watch?
[01:14:02.080 --> 01:14:05.800]   It's the great pumpkin Charlie Brown on Apple TV now.
[01:14:05.800 --> 01:14:08.600]   What's in this frosty the snowman?
[01:14:08.600 --> 01:14:11.240]   Damn you Apple.
[01:14:11.240 --> 01:14:13.960]   Previously on twit.
[01:14:13.960 --> 01:14:14.960]   All about Android.
[01:14:14.960 --> 01:14:18.960]   Yes, this is the LG wing and we're going to do an unboxing.
[01:14:18.960 --> 01:14:23.960]   Yeah, do we know if the swivel is something that has to be powered on to do or?
[01:14:23.960 --> 01:14:26.360]   Oh, okay, we have our answer.
[01:14:26.360 --> 01:14:27.360]   There we go.
[01:14:27.360 --> 01:14:30.360]   I don't know that you ever want to do that.
[01:14:30.360 --> 01:14:31.800]   Hands on photography.
[01:14:31.800 --> 01:14:34.600]   This is the week of Adobe Max 2020.
[01:14:34.600 --> 01:14:41.600]   We got some new updates to the world of Lightroom as well as some updates to the world of Photoshop.
[01:14:41.600 --> 01:14:44.280]   Some pretty daggum slick AI.
[01:14:44.280 --> 01:14:45.480]   Oh my goodness.
[01:14:45.480 --> 01:14:47.040]   It's really good.
[01:14:47.040 --> 01:14:48.040]   Tech news weekly.
[01:14:48.040 --> 01:14:52.880]   Mario Kart Live takes the familiar Mario Kart racing game that I love.
[01:14:52.880 --> 01:14:54.640]   (laughing)
[01:14:54.640 --> 01:14:57.220]   - Ask him to an augmented reality experience.
[01:14:57.220 --> 01:14:59.560]   - You get to make your own tracks, you can do loops
[01:14:59.560 --> 01:15:02.620]   and twirl around or do whatever you want to.
[01:15:02.620 --> 01:15:05.580]   As long as the carts, gates and the arrows
[01:15:05.580 --> 01:15:07.540]   are in the right locations, everything works out
[01:15:07.540 --> 01:15:08.780]   really well.
[01:15:08.780 --> 01:15:09.860]   - This week in Google.
[01:15:09.860 --> 01:15:12.200]   - Say starting today, you can hum, whistle,
[01:15:12.200 --> 01:15:15.400]   or sing a melody to Google to solve your ear worm.
[01:15:15.400 --> 01:15:17.640]   (giggling)
[01:15:17.640 --> 01:15:22.340]   You wish you could fight song?
[01:15:22.340 --> 01:15:24.180]   - It's all the single ladies.
[01:15:24.180 --> 01:15:25.180]   - Oh, I did not.
[01:15:25.180 --> 01:15:26.020]   - I did not.
[01:15:26.020 --> 01:15:26.860]   - You're right.
[01:15:26.860 --> 01:15:28.320]   - You are, you are tone deaf.
[01:15:28.320 --> 01:15:31.020]   I will actually grant you that now.
[01:15:31.020 --> 01:15:32.900]   - Twit, all your favorite podcasts
[01:15:32.900 --> 01:15:35.200]   from the 80s, 90s, and today.
[01:15:35.200 --> 01:15:37.820]   (laughing)
[01:15:37.820 --> 01:15:39.740]   - Jim Gotlay, thank you very much.
[01:15:39.740 --> 01:15:42.640]   Actually, I wanted to ask about Adobe Max
[01:15:42.640 --> 01:15:45.300]   'cause everybody was singing the praises
[01:15:45.300 --> 01:15:48.320]   of Adobe has these new AI filters that let you age.
[01:15:48.320 --> 01:15:50.820]   People make them more beautiful.
[01:15:50.820 --> 01:15:53.180]   I've got three women on the panel today.
[01:15:53.180 --> 01:15:56.940]   I thought I'd ask you 'cause one of the things it can do
[01:15:56.940 --> 01:15:58.500]   is make people smile.
[01:15:58.500 --> 01:16:01.220]   And of course, one of the very first videos
[01:16:01.220 --> 01:16:05.080]   that Adobe puts out is called Make Her Smile.
[01:16:05.080 --> 01:16:08.620]   - No. - Nope.
[01:16:08.620 --> 01:16:09.620]   - Nope. - Nope.
[01:16:09.620 --> 01:16:10.460]   - Nope. - Nope.
[01:16:10.460 --> 01:16:11.300]   - It should be called Make Them Smile.
[01:16:11.300 --> 01:16:12.620]   - Make it smile.
[01:16:12.620 --> 01:16:14.060]   Make someone else smile.
[01:16:14.060 --> 01:16:16.060]   - Make everyone smile, not just,
[01:16:16.060 --> 01:16:18.500]   'cause that continues to fall into the trope.
[01:16:18.500 --> 01:16:19.820]   So like, when we need to smile,
[01:16:19.820 --> 01:16:22.140]   like, we'll explain that because I think
[01:16:22.140 --> 01:16:23.780]   there's people watching who say,
[01:16:23.780 --> 01:16:25.220]   what is Leo talking about?
[01:16:25.220 --> 01:16:30.940]   - Well, I think typically we're told at all ages
[01:16:30.940 --> 01:16:32.220]   that like, come on, just smile,
[01:16:32.220 --> 01:16:34.500]   'cause it means like, be happy.
[01:16:34.500 --> 01:16:36.980]   It's like, that means you're, I don't know.
[01:16:36.980 --> 01:16:39.580]   Like, what would you say other fellow women on this panel?
[01:16:39.580 --> 01:16:43.220]   Like, there's this idea, like you need to do that too.
[01:16:43.220 --> 01:16:45.380]   I don't know, be easy at all.
[01:16:45.380 --> 01:16:46.220]   - It's the complaint. - It was the complaint.
[01:16:46.220 --> 01:16:48.020]   - Like, make other people feel comfortable.
[01:16:48.020 --> 01:16:49.700]   - It was the complaint against Hillary Clinton.
[01:16:49.700 --> 01:16:51.980]   It's a complaint against every woman in politics.
[01:16:51.980 --> 01:16:53.820]   She doesn't smile enough.
[01:16:53.820 --> 01:16:56.220]   - When I move around much more,
[01:16:56.220 --> 01:16:58.060]   he doesn't smile. - When I ran for Congress,
[01:16:58.060 --> 01:17:00.580]   I can't tell you how many DTCs I went to.
[01:17:00.580 --> 01:17:02.580]   And, you know, here on the show,
[01:17:02.580 --> 01:17:04.540]   like, I can show you my whole personality.
[01:17:04.540 --> 01:17:07.260]   I could joke around, but like, my default thing,
[01:17:07.260 --> 01:17:09.260]   'cause it's so hard to be taken seriously
[01:17:09.260 --> 01:17:11.660]   when you're a woman in politics is, you know,
[01:17:11.660 --> 01:17:14.820]   engineer mode, facts, focus, this is what we're doing.
[01:17:14.820 --> 01:17:17.860]   - But that makes you seem serious and not like them.
[01:17:17.860 --> 01:17:21.060]   - And I would have my team sit there and say, like,
[01:17:21.060 --> 01:17:22.780]   they would be like, come on, smile.
[01:17:22.780 --> 01:17:23.940]   We're going into this event.
[01:17:23.940 --> 01:17:26.020]   You need to make sure you're smiling at people.
[01:17:26.020 --> 01:17:29.820]   And it's, I would get home and my cheeks would hurt.
[01:17:29.820 --> 01:17:32.500]   At the end of the day, like, these muscles were broken
[01:17:32.500 --> 01:17:33.340]   from smiling.
[01:17:33.340 --> 01:17:34.180]   It was the worst.
[01:17:34.180 --> 01:17:35.460]   Oh my gosh.
[01:17:35.460 --> 01:17:38.460]   - Heather, does anybody tell you to smile more?
[01:17:38.460 --> 01:17:39.860]   - Nobody's still alive, no.
[01:17:39.860 --> 01:17:41.180]   (laughing)
[01:17:41.180 --> 01:17:42.920]   - Okay, there you have it.
[01:17:42.920 --> 01:17:45.020]   - I mean, the reason-
[01:17:45.020 --> 01:17:46.220]   - I mean, the walking down the street,
[01:17:46.220 --> 01:17:47.980]   like, you know, that's the most annoying thing
[01:17:47.980 --> 01:17:48.820]   when you walk down the street.
[01:17:48.820 --> 01:17:49.660]   - Hey baby!
[01:17:49.660 --> 01:17:50.660]   - You're not having a good day.
[01:17:50.660 --> 01:17:51.780]   - Smile.
[01:17:51.780 --> 01:17:52.620]   - I'm having a great day.
[01:17:52.620 --> 01:17:53.460]   - That's why I'm having a great day.
[01:17:53.460 --> 01:17:54.280]   I just don't care.
[01:17:54.280 --> 01:17:55.980]   - It's the new Wolf Whistle.
[01:17:55.980 --> 01:17:57.280]   - Yeah, exactly.
[01:17:57.280 --> 01:17:59.540]   - Smile, baby.
[01:17:59.540 --> 01:18:04.340]   So that's actually not the only problem with these AI filters.
[01:18:04.340 --> 01:18:09.260]   I feel like Adobe just institutionalized deep fakes.
[01:18:09.260 --> 01:18:10.580]   - Yeah, yeah.
[01:18:10.580 --> 01:18:11.420]   - Right?
[01:18:12.780 --> 01:18:16.260]   - I, you know, I will admit, like,
[01:18:16.260 --> 01:18:18.220]   especially now in the pandemic era,
[01:18:18.220 --> 01:18:20.900]   I grow on Zoom a lot more.
[01:18:20.900 --> 01:18:23.180]   Look, this is a pandemic and most of the time
[01:18:23.180 --> 01:18:27.500]   I'm in yoga pants and, you know, I just am, right?
[01:18:27.500 --> 01:18:29.940]   And there's so much pressure to be
[01:18:29.940 --> 01:18:33.500]   in like physical Zoom calls with people that I can,
[01:18:33.500 --> 01:18:36.980]   I can see some of this technology being like put on makeup
[01:18:36.980 --> 01:18:39.100]   or brush your hair or something like that
[01:18:39.100 --> 01:18:42.140]   because there's so much more work for women
[01:18:42.140 --> 01:18:44.260]   to look professional than there are men.
[01:18:44.260 --> 01:18:48.540]   But overall, it's inevitable it's gonna happen.
[01:18:48.540 --> 01:18:52.340]   I'm glad Adobe is the one doing it, but still scary.
[01:18:52.340 --> 01:18:53.620]   - Yeah.
[01:18:53.620 --> 01:18:57.820]   Katarina Fake, who's of course one of the founders of Flickr,
[01:18:57.820 --> 01:19:02.660]   says, "Ugh, I hate the Photoshop AI filters
[01:19:02.660 --> 01:19:05.340]   and how it's changing people."
[01:19:05.340 --> 01:19:09.420]   She explains it in her article at katarina.net
[01:19:09.420 --> 01:19:14.420]   Social peacocking, showing yourself in a favorable light online.
[01:19:14.420 --> 01:19:18.100]   You know, you see this all the time on Instagram
[01:19:18.100 --> 01:19:21.900]   and influencers, I'm glad to have a phrase for it.
[01:19:21.900 --> 01:19:24.020]   Social peacocking.
[01:19:24.020 --> 01:19:28.260]   And, you know, she doesn't, I think she's kind of got a point
[01:19:28.260 --> 01:19:30.620]   that we're starting to say,
[01:19:30.620 --> 01:19:36.580]   if you're using a photo editor,
[01:19:36.580 --> 01:19:38.900]   it's gotta make everything prettier
[01:19:38.900 --> 01:19:40.580]   or somehow more appealing.
[01:19:40.580 --> 01:19:42.540]   - Like, I'm not appealing enough
[01:19:42.540 --> 01:19:43.860]   so I need to add a filter to it.
[01:19:43.860 --> 01:19:45.180]   - Precisely. - To do more appealing.
[01:19:45.180 --> 01:19:46.540]   - Yeah.
[01:19:46.540 --> 01:19:49.020]   - Yeah, so I mean, it's gonna be a useful tool.
[01:19:49.020 --> 01:19:51.620]   I just worry it's gonna be used.
[01:19:51.620 --> 01:19:53.100]   It's just one more way. - It already is.
[01:19:53.100 --> 01:19:54.660]   - Yeah, one more way.
[01:19:54.660 --> 01:19:56.620]   Yeah, look like your background, so blurry.
[01:19:56.620 --> 01:19:57.460]   Now, is that--
[01:19:57.460 --> 01:19:58.460]   - Oh, do you watch that?
[01:19:58.460 --> 01:19:59.980]   Is this attitude blurry?
[01:19:59.980 --> 01:20:01.300]   What is that?
[01:20:01.300 --> 01:20:02.860]   That's all peacocking.
[01:20:02.860 --> 01:20:03.700]   You know, I was just--
[01:20:03.700 --> 01:20:05.500]   - No, that's the opposite of peacocking.
[01:20:05.500 --> 01:20:07.740]   That's trying to hide the mess.
[01:20:07.740 --> 01:20:09.420]   - I understand.
[01:20:09.420 --> 01:20:11.420]   I understand.
[01:20:11.420 --> 01:20:12.580]   I'm just teasing you.
[01:20:12.580 --> 01:20:18.260]   Yeah, deep fakes are coming.
[01:20:18.260 --> 01:20:19.300]   That's for sure.
[01:20:19.300 --> 01:20:22.940]   My wife has an interesting take on it.
[01:20:22.940 --> 01:20:24.140]   She says, "Good.
[01:20:24.140 --> 01:20:26.700]   "People should stop believing everything they see.
[01:20:26.700 --> 01:20:31.700]   "And if it's widely known that it's easy to do this,
[01:20:31.700 --> 01:20:33.540]   "it will make people think twice.
[01:20:33.540 --> 01:20:35.380]   "You know, we still have that notion.
[01:20:35.380 --> 01:20:36.980]   "Oh, I'm seeing a picture of it."
[01:20:36.980 --> 01:20:38.460]   It's like saying, "I read it on the internet,
[01:20:38.460 --> 01:20:39.900]   "so it must be true."
[01:20:39.900 --> 01:20:44.340]   - Maybe it'll force us to verify things more.
[01:20:44.340 --> 01:20:46.620]   If we know that that's more common,
[01:20:46.620 --> 01:20:50.180]   then we'll have to find multiple copies of that
[01:20:50.180 --> 01:20:52.700]   are from different verified accounts.
[01:20:52.700 --> 01:20:53.580]   You know what I mean?
[01:20:53.580 --> 01:20:55.780]   So it actually, yeah, it could force people
[01:20:55.780 --> 01:20:57.780]   to question things more than they do.
[01:20:57.780 --> 01:21:00.060]   - Imagine what that would do for criminal cases,
[01:21:00.060 --> 01:21:03.460]   for civil lawsuits, for sexual harassment lawsuits.
[01:21:03.460 --> 01:21:08.220]   I see a lot more downside there than upside, personally.
[01:21:08.220 --> 01:21:09.900]   - Well, it's here, it's gonna happen.
[01:21:09.900 --> 01:21:16.780]   There was a telegram group that I think was shut down,
[01:21:16.780 --> 01:21:19.940]   but there was some tool that was being used in the group
[01:21:19.940 --> 01:21:21.780]   that could take a picture of any woman
[01:21:21.780 --> 01:21:25.180]   and generate a nude image of that woman.
[01:21:25.180 --> 01:21:26.020]   - Oh, yeah.
[01:21:26.020 --> 01:21:28.500]   - I know, I know.
[01:21:28.500 --> 01:21:29.540]   - I said around, no, it's horrible.
[01:21:29.540 --> 01:21:31.340]   I mean, it's been around,
[01:21:31.340 --> 01:21:34.820]   and now I guess that it's more in front of our faces,
[01:21:34.820 --> 01:21:37.860]   more out there than at least it's not as underground anymore.
[01:21:37.860 --> 01:21:40.540]   So we know when those things are there,
[01:21:40.540 --> 01:21:42.460]   and then people can--
[01:21:42.460 --> 01:21:43.860]   - That's Lisa's point of view.
[01:21:43.860 --> 01:21:44.700]   - He called out.
[01:21:44.700 --> 01:21:47.700]   - Yeah, it's always been around,
[01:21:47.700 --> 01:21:50.980]   but it's always been kind of under the,
[01:21:50.980 --> 01:21:52.860]   people kind of believed it was real.
[01:21:52.860 --> 01:21:55.540]   So it's good, everybody should know,
[01:21:55.540 --> 01:21:58.340]   there's so much of this, it's fake, it's not real.
[01:22:00.060 --> 01:22:04.740]   - Speaking of not real, it's all over for Quibi.
[01:22:04.740 --> 01:22:06.580]   - Oh, yeah.
[01:22:06.580 --> 01:22:07.900]   (laughing)
[01:22:07.900 --> 01:22:08.900]   - We hardly knew you.
[01:22:08.900 --> 01:22:11.500]   - Quibi, we hardly knew you.
[01:22:11.500 --> 01:22:14.420]   Or as some wag wrote, Quibi calls it quits.
[01:22:14.420 --> 01:22:16.660]   (laughing)
[01:22:16.660 --> 01:22:20.820]   You have something to say about this, Brianna,
[01:22:20.820 --> 01:22:21.660]   I think you do.
[01:22:21.660 --> 01:22:25.460]   - I don't under, Leah, you and I about story businesses.
[01:22:25.460 --> 01:22:27.820]   It is unbelievably hard work.
[01:22:27.820 --> 01:22:30.500]   You have run a streaming business
[01:22:30.500 --> 01:22:32.860]   on the internet for a long time.
[01:22:32.860 --> 01:22:36.540]   I bet it wasn't easy to make this into what it is.
[01:22:36.540 --> 01:22:40.700]   And I'm just perplexed by the number of people
[01:22:40.700 --> 01:22:43.420]   that are gleeful that this failed.
[01:22:43.420 --> 01:22:44.980]   - I have the same reaction.
[01:22:44.980 --> 01:22:46.860]   - Simone is a friend of mine,
[01:22:46.860 --> 01:22:48.780]   she was a producer for Quibi.
[01:22:48.780 --> 01:22:49.620]   - Oh, really?
[01:22:49.620 --> 01:22:50.940]   - Simone is a lovely person.
[01:22:50.940 --> 01:22:53.660]   So it's the best human being I know.
[01:22:53.660 --> 01:22:56.260]   And I mean, some of the shows there,
[01:22:56.260 --> 01:22:58.020]   I'm not gonna say it was for me,
[01:22:58.020 --> 01:23:02.100]   but that Golden Arm Show, that was legit awesome.
[01:23:02.100 --> 01:23:05.100]   That was the happiest moment of this last year.
[01:23:05.100 --> 01:23:09.020]   The Target 24 Jack Bauer Show.
[01:23:09.020 --> 01:23:11.500]   It's not good, but it's not bad.
[01:23:11.500 --> 01:23:16.060]   - The Golden Arm Show featured Mrs. Maisel, right?
[01:23:16.060 --> 01:23:17.940]   Rachel, Brianna Han.
[01:23:17.940 --> 01:23:18.780]   - Is it her?
[01:23:18.780 --> 01:23:19.620]   Oh my gosh.
[01:23:19.620 --> 01:23:20.660]   - Yeah, you didn't know that?
[01:23:20.660 --> 01:23:21.500]   Yeah.
[01:23:21.500 --> 01:23:22.660]   I think I'm right on that.
[01:23:22.660 --> 01:23:25.980]   And she suddenly discovers she has a Golden Arm.
[01:23:25.980 --> 01:23:28.860]   - Oh, you haven't seen this hard clip online.
[01:23:28.860 --> 01:23:29.780]   You've got to play it, right?
[01:23:29.780 --> 01:23:31.140]   - Well, see, this is the problem right there.
[01:23:31.140 --> 01:23:32.980]   You didn't see it on Quibi, did you?
[01:23:32.980 --> 01:23:36.420]   - Right, no, it's a famous shot on Twitter.
[01:23:36.420 --> 01:23:39.580]   Type it, Golden Arm Quibi, it is unbelievable.
[01:23:39.580 --> 01:23:43.460]   So it's this melodrama of a woman that's very vain
[01:23:43.460 --> 01:23:45.300]   and she had loose as her arm.
[01:23:45.300 --> 01:23:48.340]   And she has a Golden Arm put in its place.
[01:23:48.340 --> 01:23:50.020]   And even though it's killing her,
[01:23:50.020 --> 01:23:52.140]   she wants to be buried with her Golden Arm.
[01:23:52.140 --> 01:23:54.260]   It is beautiful, it is wonderful.
[01:23:54.260 --> 01:23:56.100]   Here we go, here's Rachel.
[01:23:56.100 --> 01:23:57.380]   - Oh, God.
[01:23:57.380 --> 01:23:59.700]   - Oh, by the way, here's problem number one.
[01:23:59.700 --> 01:24:00.540]   - Yep.
[01:24:00.540 --> 01:24:02.220]   (laughing)
[01:24:02.220 --> 01:24:03.820]   - You couldn't share it.
[01:24:03.820 --> 01:24:05.740]   - You couldn't share it.
[01:24:05.740 --> 01:24:08.100]   Like, if you wanted to tweet it,
[01:24:08.100 --> 01:24:11.380]   you had to do what this poor Zach Raphael is doing.
[01:24:11.380 --> 01:24:13.620]   You had to shoot a video of your phone.
[01:24:13.620 --> 01:24:17.060]   So she's got a Golden Arm.
[01:24:17.060 --> 01:24:19.860]   - Then of course, when I came, I would go sick.
[01:24:19.860 --> 01:24:22.260]   - The tests have come in.
[01:24:22.260 --> 01:24:23.900]   It is pulmonary gold disease.
[01:24:23.900 --> 01:24:25.900]   - Pulmonary gold disease.
[01:24:25.900 --> 01:24:28.100]   - This is so strange.
[01:24:28.100 --> 01:24:29.900]   - There's very little I can do.
[01:24:29.900 --> 01:24:31.940]   You forgot to take off that prosthetic.
[01:24:31.940 --> 01:24:33.420]   - No.
[01:24:33.420 --> 01:24:35.620]   I can't take off my Golden Arm.
[01:24:35.620 --> 01:24:37.780]   (laughing)
[01:24:37.780 --> 01:24:40.420]   - Sir, whatever she wants.
[01:24:40.420 --> 01:24:41.980]   - Oh, I love him.
[01:24:41.980 --> 01:24:43.860]   - This is as bad as a room.
[01:24:43.860 --> 01:24:46.100]   (laughing)
[01:24:46.100 --> 01:24:49.980]   - She's gonna die 'cause she has a Golden Arm.
[01:24:49.980 --> 01:24:50.820]   - Spoiler.
[01:24:50.820 --> 01:24:53.540]   - Oh, so, okay.
[01:24:53.540 --> 01:24:56.020]   - Wait a minute, wait a minute, I gotta pause it.
[01:24:56.020 --> 01:24:58.300]   So it's not an actual Golden Arm.
[01:24:58.300 --> 01:24:59.140]   It's a prosthetic.
[01:24:59.140 --> 01:25:01.180]   - No, it's an actual Golden Arm.
[01:25:01.180 --> 01:25:03.100]   - She was born with a Golden Arm.
[01:25:03.100 --> 01:25:07.260]   - No, she'd lost her arm in a lumberjack accident.
[01:25:07.260 --> 01:25:10.780]   And she's so vain that her husband cast her one
[01:25:10.780 --> 01:25:13.740]   with 3D software, even though he lives in a barn,
[01:25:13.740 --> 01:25:16.380]   which is confusing, that he smelt her
[01:25:16.380 --> 01:25:18.540]   an arm made out of pure gold.
[01:25:18.540 --> 01:25:19.540]   So.
[01:25:19.540 --> 01:25:20.380]   - That's love.
[01:25:20.380 --> 01:25:21.740]   - There it is.
[01:25:21.740 --> 01:25:22.660]   - Sam Raimi.
[01:25:23.660 --> 01:25:25.820]   - Pretty good guy for a director,
[01:25:25.820 --> 01:25:27.860]   co-wrote it and directed it.
[01:25:27.860 --> 01:25:30.660]   He says, "I wasn't setting out to make a comedy."
[01:25:30.660 --> 01:25:33.860]   (laughing)
[01:25:33.860 --> 01:25:35.660]   My favorite is Titus Burgess,
[01:25:35.660 --> 01:25:37.420]   who is one of my favorite actors
[01:25:37.420 --> 01:25:41.940]   from the Unbreakable Kimmy Schmidt.
[01:25:41.940 --> 01:25:45.100]   It's a show called Dish Mantle.
[01:25:45.100 --> 01:25:49.540]   It was pre-COVID in Conception, I think,
[01:25:49.540 --> 01:25:51.580]   because the idea is that they'd have a chef
[01:25:51.580 --> 01:25:54.580]   make an amazing meal,
[01:25:54.580 --> 01:25:56.140]   then they'd mush it all together
[01:25:56.140 --> 01:26:00.540]   and put it in cannons and shoot it at two chefs
[01:26:00.540 --> 01:26:03.980]   in a special room.
[01:26:03.980 --> 01:26:06.140]   They would get splattered with this meal.
[01:26:06.140 --> 01:26:08.100]   They would then have to taste it,
[01:26:08.100 --> 01:26:10.180]   figure out what it was and make it.
[01:26:10.180 --> 01:26:12.020]   And the chef who gave the closest
[01:26:12.020 --> 01:26:15.060]   to making the original meal got $5,000.
[01:26:15.060 --> 01:26:17.860]   - Someone was definitely stoned when they made this.
[01:26:17.860 --> 01:26:19.860]   - That was micro-dosing in a nut, shelly.
[01:26:19.860 --> 01:26:20.820]   - Chef, they were on something.
[01:26:20.820 --> 01:26:22.020]   They were on one side.
[01:26:22.020 --> 01:26:24.380]   (laughing)
[01:26:24.380 --> 01:26:26.980]   - Quibi's other feature was that you could
[01:26:26.980 --> 01:26:29.180]   turn the phone sideways,
[01:26:29.180 --> 01:26:33.340]   and not only would the picture readjust as every phone does,
[01:26:33.340 --> 01:26:35.020]   you'd get a different angle on the scene.
[01:26:35.020 --> 01:26:38.060]   That the scenes were shot in both aspect ratios,
[01:26:38.060 --> 01:26:40.820]   portrait and landscape, in some cases,
[01:26:40.820 --> 01:26:42.020]   apparently not every show.
[01:26:42.020 --> 01:26:44.180]   And so it would do something interesting.
[01:26:44.180 --> 01:26:45.780]   And then they got sued by a company,
[01:26:45.780 --> 01:26:47.300]   and said, "You know, we invented that.
[01:26:47.300 --> 01:26:48.580]   That was your..."
[01:26:48.580 --> 01:26:50.780]   So that was another thing.
[01:26:50.780 --> 01:26:53.260]   Now here's the thing, you were very kind.
[01:26:53.260 --> 01:26:56.420]   You said, "You know, I've created this vast media empire
[01:26:56.420 --> 01:26:58.060]   over the last 15 years."
[01:26:58.060 --> 01:27:00.540]   Well, I didn't have something that Quibi had.
[01:27:00.540 --> 01:27:05.540]   1.75 billion dollars in venture capital.
[01:27:05.540 --> 01:27:08.420]   And that's what killed him, right Heather?
[01:27:08.420 --> 01:27:09.740]   It's like...
[01:27:09.740 --> 01:27:11.740]   - I mean, that's why, and I don't have an opinion
[01:27:11.740 --> 01:27:13.220]   about Quibi one way or the other having
[01:27:13.220 --> 01:27:14.580]   literally never watched anything,
[01:27:14.580 --> 01:27:17.740]   but the video of somebody's phone showing the Golden Arm show.
[01:27:17.740 --> 01:27:18.980]   - That tells you something right there.
[01:27:18.980 --> 01:27:23.340]   And I think that's like 99% of people who know about Quibi.
[01:27:23.340 --> 01:27:25.820]   I think some of the glee was just not even glee,
[01:27:25.820 --> 01:27:28.580]   but like they, you guys talk about like making a business,
[01:27:28.580 --> 01:27:30.180]   and you said how many years it was.
[01:27:30.180 --> 01:27:32.900]   Like it takes work and scraping by.
[01:27:32.900 --> 01:27:36.460]   And they had such a ridiculous amount of money
[01:27:36.460 --> 01:27:38.020]   and made so many missteps,
[01:27:38.020 --> 01:27:40.740]   and just seemed to not even know some of the executives,
[01:27:40.740 --> 01:27:42.580]   not even know their market that well,
[01:27:42.580 --> 01:27:43.620]   or who they were appealing to,
[01:27:43.620 --> 01:27:45.300]   or how to make things shareable and viral.
[01:27:45.300 --> 01:27:50.060]   And it's just like a head-smacking moment.
[01:27:50.060 --> 01:27:52.060]   More than glee that people are losing their jobs
[01:27:52.060 --> 01:27:55.380]   just astounded that they didn't try harder
[01:27:55.380 --> 01:27:56.780]   or do a little different something.
[01:27:56.780 --> 01:27:57.620]   I don't know.
[01:27:57.620 --> 01:27:59.940]   - It was a typical Hollywood move.
[01:27:59.940 --> 01:28:02.060]   They were trying to do YouTube, right?
[01:28:02.060 --> 01:28:04.700]   We're gonna make 260 plus year old saying,
[01:28:04.700 --> 01:28:06.060]   we know what the kids want.
[01:28:06.060 --> 01:28:10.260]   - I just don't really want to be clear.
[01:28:10.260 --> 01:28:12.380]   I don't think they made smart decisions.
[01:28:12.380 --> 01:28:13.220]   I don't.
[01:28:13.220 --> 01:28:14.060]   - No, no, no.
[01:28:14.060 --> 01:28:14.900]   - But I'm with you.
[01:28:14.900 --> 01:28:16.220]   I feel for the content creators.
[01:28:16.220 --> 01:28:17.060]   I completely agree.
[01:28:17.060 --> 01:28:17.900]   - I do.
[01:28:17.900 --> 01:28:20.820]   I remember when Simone was talking about getting her IMDB
[01:28:20.820 --> 01:28:24.100]   as a producer on an actual show.
[01:28:24.100 --> 01:28:25.860]   That's an exciting moment for her.
[01:28:25.860 --> 01:28:29.060]   Like she went out and she worked very hard on that.
[01:28:29.060 --> 01:28:30.580]   And I just, I don't know.
[01:28:30.580 --> 01:28:33.460]   I know so many people in media that are hurting,
[01:28:33.460 --> 01:28:34.820]   especially at the pandemic,
[01:28:34.820 --> 01:28:36.580]   I just, I'm not gonna be gleeful
[01:28:36.580 --> 01:28:38.780]   as people are losing their jobs.
[01:28:38.780 --> 01:28:39.620]   - No, I'm with you.
[01:28:39.620 --> 01:28:40.460]   - That's me.
[01:28:40.460 --> 01:28:41.980]   - But I imagine how many could have been employed
[01:28:41.980 --> 01:28:42.820]   with that money.
[01:28:42.820 --> 01:28:43.740]   Like how many local papers
[01:28:43.740 --> 01:28:45.580]   did that have made me care?
[01:28:45.580 --> 01:28:46.820]   - It could have been spent better.
[01:28:46.820 --> 01:28:47.660]   - Yeah.
[01:28:47.660 --> 01:28:48.500]   - Yeah.
[01:28:48.500 --> 01:28:49.340]   - Yeah.
[01:28:49.340 --> 01:28:50.340]   I mean, I think it's like when you have two,
[01:28:50.340 --> 01:28:54.700]   as you said, like two older white individuals
[01:28:54.700 --> 01:28:56.700]   that are like, we're gonna like do this new thing
[01:28:56.700 --> 01:28:58.500]   and put over a billion dollars into it.
[01:28:58.500 --> 01:28:59.580]   They're boasting about it.
[01:28:59.580 --> 01:29:03.140]   They're also shooting down every successful platform
[01:29:03.140 --> 01:29:06.220]   who has figured it out, who has spent many years doing it.
[01:29:06.220 --> 01:29:08.980]   It's kind of like your, it's a recipe for disaster.
[01:29:08.980 --> 01:29:10.500]   And then also they're just giving money.
[01:29:10.500 --> 01:29:12.060]   There was also a feeling, I think,
[01:29:12.060 --> 01:29:13.300]   from a lot of creatives
[01:29:13.300 --> 01:29:14.500]   that there was giving money to the people
[01:29:14.500 --> 01:29:15.820]   that already had money.
[01:29:15.820 --> 01:29:20.180]   Whereas I think that there's two Hollywood execs
[01:29:20.180 --> 01:29:21.500]   that are starting something new
[01:29:21.500 --> 01:29:23.500]   and like they're definitely looking at more diversity
[01:29:23.500 --> 01:29:25.300]   in terms of like putting the spotlight
[01:29:25.300 --> 01:29:27.740]   in a more up and coming creators and writers.
[01:29:27.740 --> 01:29:30.580]   Like while having definitely the star power,
[01:29:30.580 --> 01:29:33.860]   but it just felt like they were giving every celebrity
[01:29:33.860 --> 01:29:36.980]   and their like, and their mom money for a show
[01:29:36.980 --> 01:29:38.500]   and they were spending so much money.
[01:29:38.500 --> 01:29:40.780]   Like I knew a lot of people that had shows there
[01:29:40.780 --> 01:29:43.780]   and it's just everyone knew they were just throwing out money.
[01:29:43.780 --> 01:29:48.180]   And so yeah, people are not like excited unfortunately
[01:29:48.180 --> 01:29:52.060]   in this era of kind of like,
[01:29:52.060 --> 01:29:53.820]   I think that people have a chip on their shoulder
[01:29:53.820 --> 01:29:57.460]   and how they would have it to see like something fall, right?
[01:29:57.460 --> 01:29:58.460]   - Yeah.
[01:29:58.460 --> 01:30:00.860]   My first reaction, I actually said this a couple of times,
[01:30:00.860 --> 01:30:03.580]   was it's just the Hollywood model does not work on the internet.
[01:30:03.580 --> 01:30:06.260]   The internet model is more like TikTok and YouTube.
[01:30:06.260 --> 01:30:09.500]   You make a platform that anybody can create content on.
[01:30:09.500 --> 01:30:10.860]   You make it easy for them to do so
[01:30:10.860 --> 01:30:14.060]   and then you use an algorithm to surface the best content.
[01:30:14.060 --> 01:30:16.380]   - They were telling people what they wanted versus like
[01:30:16.380 --> 01:30:17.220]   - Exactly.
[01:30:17.220 --> 01:30:18.060]   - a solution.
[01:30:18.060 --> 01:30:19.940]   And then that was like, I think that assumption
[01:30:19.940 --> 01:30:22.820]   made people not like want to see them fail.
[01:30:22.820 --> 01:30:26.140]   Unfortunately, that said, I also know a lot of people have shows
[01:30:26.140 --> 01:30:28.060]   who are deserving and a lot of people.
[01:30:28.060 --> 01:30:29.460]   Yeah, they were employing a lot of people.
[01:30:29.460 --> 01:30:31.260]   So I even said after they launched
[01:30:31.260 --> 01:30:32.540]   while everyone was making fun of them,
[01:30:32.540 --> 01:30:35.340]   like I feel like I want them to succeed
[01:30:35.340 --> 01:30:38.220]   because it means more people get more jobs, right?
[01:30:38.220 --> 01:30:40.620]   - That's how I've modified my thinking
[01:30:40.620 --> 01:30:42.100]   because over the last few nights,
[01:30:42.100 --> 01:30:43.620]   'cause I do feel bad.
[01:30:43.620 --> 01:30:48.460]   There's a story of a Quibi film crew that was out making a movie
[01:30:48.460 --> 01:30:50.100]   and they were told that Quibi had folded it
[01:30:50.100 --> 01:30:51.980]   and they're desperately trying to continue
[01:30:51.980 --> 01:30:55.140]   so they can at least finish what they were making
[01:30:55.140 --> 01:30:57.140]   and maybe find another market for it.
[01:30:57.140 --> 01:30:59.660]   There are a lot of people be left out in the cold.
[01:30:59.660 --> 01:31:01.700]   So my initial take was, oh, this is Hollywood
[01:31:01.700 --> 01:31:04.300]   versus Silicon Valley and they just don't get it.
[01:31:04.300 --> 01:31:05.540]   But then I thought a little bit about it.
[01:31:05.540 --> 01:31:10.540]   And what it really is, Quibi's doing art,
[01:31:10.540 --> 01:31:16.180]   stuff that's thoughtfully created or we're trying to anyway.
[01:31:16.180 --> 01:31:18.220]   I mean, that's what a movie is in a TV show,
[01:31:18.220 --> 01:31:19.780]   stuff that somebody writes a script
[01:31:19.780 --> 01:31:22.940]   and they bring in a lot of talent and they produce it
[01:31:22.940 --> 01:31:27.180]   and they have a huge number of film crews
[01:31:27.180 --> 01:31:28.580]   and people doing this.
[01:31:28.580 --> 01:31:31.940]   And that was a different kind of creation
[01:31:31.940 --> 01:31:34.780]   and I don't wanna see that kind of creation fail.
[01:31:35.540 --> 01:31:36.980]   We need that.
[01:31:36.980 --> 01:31:38.420]   I think it's important.
[01:31:38.420 --> 01:31:40.300]   I think that's, you know,
[01:31:40.300 --> 01:31:44.020]   but when you think that they put 1.75 billion dollars
[01:31:44.020 --> 01:31:47.420]   into this and frankly, no show on Quibi
[01:31:47.420 --> 01:31:50.940]   got more views than Nathan Apodaca,
[01:31:50.940 --> 01:31:55.940]   this guy on his longboard drinking his crannapal juice
[01:31:55.940 --> 01:32:02.500]   and making a 43 year old song by Fleetwood Mac
[01:32:03.420 --> 01:32:05.020]   again on the top 10.
[01:32:05.020 --> 01:32:08.800]   I mean, this is the opposite of Quibi, right?
[01:32:08.800 --> 01:32:12.700]   - And let's remember also, musically,
[01:32:12.700 --> 01:32:14.740]   that was, you know, before TikTok bought them,
[01:32:14.740 --> 01:32:16.700]   was having a hard time too, right?
[01:32:16.700 --> 01:32:18.980]   - Yeah, but musically had a secret sauce,
[01:32:18.980 --> 01:32:19.980]   which was what we just saw,
[01:32:19.980 --> 01:32:23.740]   which was you were allowed to take real music, right?
[01:32:23.740 --> 01:32:25.100]   And put your video to it.
[01:32:25.100 --> 01:32:25.940]   - Yeah, right.
[01:32:25.940 --> 01:32:26.780]   - If you did that on YouTube,
[01:32:26.780 --> 01:32:28.140]   you'd be taking it down on it and a hard thing.
[01:32:28.140 --> 01:32:29.980]   - You're an active participant in it.
[01:32:29.980 --> 01:32:31.940]   And I think that with Quibi, people are like,
[01:32:31.940 --> 01:32:36.140]   it's a lean back, but it's also for the next generation.
[01:32:36.140 --> 01:32:38.020]   So it was confusing.
[01:32:38.020 --> 01:32:40.180]   And they went too high, like starting at 1 billion,
[01:32:40.180 --> 01:32:41.780]   you can't keep that up.
[01:32:41.780 --> 01:32:42.740]   You're never gonna be able to keep that up
[01:32:42.740 --> 01:32:44.180]   or make your money back in time.
[01:32:44.180 --> 01:32:46.540]   - It's often the kiss of death to get venture funding,
[01:32:46.540 --> 01:32:47.380]   I have to say.
[01:32:47.380 --> 01:32:49.180]   - Unless you're like, Apple,
[01:32:49.180 --> 01:32:50.540]   from Floss Talk of How Many Billions,
[01:32:50.540 --> 01:32:52.100]   they've been spending on their original content.
[01:32:52.100 --> 01:32:54.380]   And I think there's been, this is buys.
[01:32:54.380 --> 01:32:56.460]   I think there's been one good show coming on Apple,
[01:32:56.460 --> 01:32:57.820]   but it's getting better over time.
[01:32:57.820 --> 01:32:59.980]   Like they hung out more than six months
[01:32:59.980 --> 01:33:01.300]   and kept making mediocre videos.
[01:33:01.300 --> 01:33:02.140]   You know why?
[01:33:02.140 --> 01:33:03.180]   - I'm a good team.
[01:33:03.180 --> 01:33:04.780]   - 'Cause this could be a loss leader.
[01:33:04.780 --> 01:33:07.500]   They don't ever have to make money on Apple TV Plus, right?
[01:33:07.500 --> 01:33:08.340]   - Right, both right.
[01:33:08.340 --> 01:33:09.780]   And they're taking their time to figure out what works
[01:33:09.780 --> 01:33:11.260]   versus buying-- - Well, they're finding out
[01:33:11.260 --> 01:33:12.100]   what doesn't work. - I mean,
[01:33:12.100 --> 01:33:14.260]   how many shows, yeah, it doesn't work.
[01:33:14.260 --> 01:33:17.300]   But like spending that much money on that many shows,
[01:33:17.300 --> 01:33:19.660]   there's no room for any errors.
[01:33:19.660 --> 01:33:21.860]   You're not leaving yourself a lot of room for mistakes.
[01:33:21.860 --> 01:33:23.100]   - Yeah, they don't have that many shows.
[01:33:23.100 --> 01:33:24.100]   They don't have a catalog.
[01:33:24.100 --> 01:33:26.220]   They don't have what Netflix has where Netflix
[01:33:26.220 --> 01:33:28.700]   can make 10 bad shows.
[01:33:28.700 --> 01:33:30.620]   And still, there's a catalog.
[01:33:30.620 --> 01:33:32.660]   So you can watch stuff.
[01:33:32.660 --> 01:33:35.340]   - I feel like the really big mistake Quibi made
[01:33:35.340 --> 01:33:37.300]   was market segmentation.
[01:33:37.300 --> 01:33:39.300]   Like look at car stuff.
[01:33:39.300 --> 01:33:42.740]   What's like the most successful YouTube channel for cars?
[01:33:42.740 --> 01:33:43.940]   It's donut media.
[01:33:43.940 --> 01:33:47.180]   It's, you know, dudes sitting around talking out cars,
[01:33:47.180 --> 01:33:50.420]   upgrading their cars, talking about the top 10 best cars.
[01:33:50.420 --> 01:33:51.540]   It's very authentic.
[01:33:51.540 --> 01:33:54.140]   It's hyper segmented to that market.
[01:33:54.140 --> 01:33:56.020]   What was Quibi's car show?
[01:33:56.020 --> 01:33:59.900]   It was Idris Elba driving around doing dumb stunts,
[01:33:59.900 --> 01:34:01.260]   trying to beat a stunt driver.
[01:34:01.260 --> 01:34:03.220]   It was a big spectacle.
[01:34:03.220 --> 01:34:05.780]   But it doesn't appeal to people like me.
[01:34:05.780 --> 01:34:08.140]   Look at, look at TWIT and what you do.
[01:34:08.140 --> 01:34:11.500]   You've got an Android show, you've got a main tech news show.
[01:34:11.500 --> 01:34:14.500]   You're very segmented with your different audiences.
[01:34:14.500 --> 01:34:17.340]   Quibi was trying to dilute that down
[01:34:17.340 --> 01:34:22.340]   and find dumber, broader concepts with celebrities.
[01:34:22.340 --> 01:34:25.100]   - I learned that lesson.
[01:34:25.100 --> 01:34:25.940]   - You know where I learned that lesson?
[01:34:25.940 --> 01:34:26.780]   - Yeah.
[01:34:26.780 --> 01:34:27.620]   - Tech TV.
[01:34:27.620 --> 01:34:30.380]   - Yeah. - Because it was on cable, right?
[01:34:30.380 --> 01:34:34.140]   This is the network that I kind of made my name on a night
[01:34:34.140 --> 01:34:36.020]   from 1998 to 2004.
[01:34:36.020 --> 01:34:39.620]   It was on a cable network.
[01:34:39.620 --> 01:34:41.700]   And I always thought just, you know,
[01:34:41.700 --> 01:34:43.780]   if you were gonna do ESPN, you don't do shows
[01:34:43.780 --> 01:34:44.860]   for people who hate football.
[01:34:44.860 --> 01:34:47.460]   You do shows for people who are really, really, really
[01:34:47.460 --> 01:34:48.780]   into football. - Right.
[01:34:48.780 --> 01:34:52.260]   - And Tech TV, I said, we should go deep.
[01:34:52.260 --> 01:34:54.500]   We should go, we should be, you know,
[01:34:54.500 --> 01:34:56.740]   there's 14 million programmers in the US.
[01:34:56.740 --> 01:34:59.580]   We should be aiming for the most geeky people.
[01:34:59.580 --> 01:35:02.620]   Instead, and this happens, this is not unusual,
[01:35:02.620 --> 01:35:05.700]   that everybody wants to get the big broad audience.
[01:35:05.700 --> 01:35:08.100]   Maybe that's 'cause advertising, I don't know.
[01:35:08.100 --> 01:35:13.100]   But, so they put on thunderbirds and,
[01:35:13.100 --> 01:35:16.780]   what was that cop show they put on bad, you know, bad cop back?
[01:35:16.780 --> 01:35:20.420]   They, because they wanted to get a bigger audience.
[01:35:20.420 --> 01:35:22.580]   Well, no geek's gonna watch that.
[01:35:22.580 --> 01:35:25.500]   And no general audience's gonna watch the geek show,
[01:35:25.500 --> 01:35:28.180]   so you just killed yourself and in fact, they did.
[01:35:28.180 --> 01:35:29.180]   - Yeah.
[01:35:29.180 --> 01:35:30.180]   - They're coming back though.
[01:35:30.180 --> 01:35:31.940]   Tech TV, I heard there's gonna be--
[01:35:31.940 --> 01:35:32.940]   - Yeah, good luck on that.
[01:35:32.940 --> 01:35:33.780]   - A relaunch.
[01:35:33.780 --> 01:35:35.180]   - I'm not tech TV.
[01:35:35.180 --> 01:35:36.700]   G4.
[01:35:36.700 --> 01:35:37.540]   - G4, I mean-- - G4.
[01:35:37.540 --> 01:35:38.980]   - Yeah, well that was-- - G4.
[01:35:38.980 --> 01:35:41.260]   - So, Tech TV got bought by Comcast,
[01:35:41.260 --> 01:35:43.020]   merged into G4 for a while.
[01:35:43.020 --> 01:35:45.620]   It was G4 Tech TV, then they got rid of the Tech TV part.
[01:35:45.620 --> 01:35:49.020]   It was G4, which was about guns, gaming, dumb balls.
[01:35:49.020 --> 01:35:51.340]   - Yes, points for 2021 reboot.
[01:35:51.340 --> 01:35:52.940]   Video game network unplugged.
[01:35:52.940 --> 01:35:54.300]   - They did a tweet.
[01:35:54.300 --> 01:35:55.220]   That's all they've done.
[01:35:55.220 --> 01:35:56.060]   - As a tweet.
[01:35:56.060 --> 01:35:59.180]   - A tweet that made headlines.
[01:35:59.180 --> 01:36:04.180]   - Can I say, I am gonna restart the screen savers in 2025?
[01:36:04.180 --> 01:36:07.540]   You know, I mean, come on.
[01:36:07.540 --> 01:36:08.540]   We'll see.
[01:36:08.540 --> 01:36:10.340]   I don't think there's an audience for G4.
[01:36:10.340 --> 01:36:13.740]   - I don't know, there's a lot of nostalgia around it,
[01:36:13.740 --> 01:36:16.900]   but you know, and when you have NBC Universal,
[01:36:16.900 --> 01:36:18.420]   if they do it right this time,
[01:36:18.420 --> 01:36:20.540]   maybe they can figure it out, but who knows?
[01:36:20.540 --> 01:36:23.300]   - Yeah, I wish them well, good luck.
[01:36:24.220 --> 01:36:26.580]   - What's that Olivia Munn been doing ever since, right?
[01:36:26.580 --> 01:36:27.420]   I mean. - What do you mean?
[01:36:27.420 --> 01:36:28.860]   She's an act, she's a big actress.
[01:36:28.860 --> 01:36:30.660]   - I'm being facetious.
[01:36:30.660 --> 01:36:32.460]   (laughing)
[01:36:32.460 --> 01:36:34.780]   - She will defend Olivia, okay.
[01:36:34.780 --> 01:36:36.020]   - I'm sorry. - I'm sorry.
[01:36:36.020 --> 01:36:36.860]   - Yeah.
[01:36:36.860 --> 01:36:38.900]   - She was so good at magic, Mike.
[01:36:38.900 --> 01:36:40.260]   - I even liked Predator.
[01:36:40.260 --> 01:36:42.860]   Like, what's the topic of fan I am?
[01:36:42.860 --> 01:36:46.220]   - All right, let's take a break.
[01:36:46.220 --> 01:36:50.780]   Now that I'm getting bit by our panel,
[01:36:52.780 --> 01:36:56.340]   Brianna Wu, Heather Kelly, Cheryl Azar.
[01:36:56.340 --> 01:36:57.620]   I'm getting what I deserve.
[01:36:57.620 --> 01:36:59.580]   That's all I can say.
[01:36:59.580 --> 01:37:00.940]   We will have more in just a moment
[01:37:00.940 --> 01:37:03.580]   I showed today brought to you by Zippur Cruder.
[01:37:03.580 --> 01:37:05.100]   Did we use Zippur Cruder?
[01:37:05.100 --> 01:37:06.740]   This is how we hire.
[01:37:06.740 --> 01:37:08.340]   So I could say this with authorities,
[01:37:08.340 --> 01:37:10.780]   Zippur Cruder is the best way to hire.
[01:37:10.780 --> 01:37:13.020]   If you're business, if you are lucky enough
[01:37:13.020 --> 01:37:15.180]   that your business is looking to hire people,
[01:37:15.180 --> 01:37:19.740]   God bless you, thank you, the world needs you,
[01:37:19.740 --> 01:37:22.380]   and you might be saying, now, how do I find somebody?
[01:37:22.380 --> 01:37:23.940]   There's so many people looking for work.
[01:37:23.940 --> 01:37:27.060]   Where do there's a needle in that haystack,
[01:37:27.060 --> 01:37:28.020]   but how do I find it?
[01:37:28.020 --> 01:37:30.700]   That's Zippur Cruder.
[01:37:30.700 --> 01:37:34.700]   It's hard to fill these jobs,
[01:37:34.700 --> 01:37:39.700]   but Zippur Cruder makes hiring faster, easier, and smarter.
[01:37:39.700 --> 01:37:42.860]   So you're spreading your net, you're casting your net
[01:37:42.860 --> 01:37:44.340]   as wide as possible.
[01:37:44.340 --> 01:37:47.820]   And then Zippur Cruder does something really interesting.
[01:37:47.820 --> 01:37:50.260]   They look at your posting,
[01:37:50.260 --> 01:37:54.220]   and they match you up to some of the resumes they have on file,
[01:37:54.220 --> 01:37:56.060]   and they invite the people who match best
[01:37:56.060 --> 01:37:57.580]   to apply to your job.
[01:37:57.580 --> 01:38:01.540]   That's why when you post a job on Zippur Cruder,
[01:38:01.540 --> 01:38:04.980]   you are gonna get qualified candidates fast.
[01:38:04.980 --> 01:38:07.100]   In my case, we'd post at breakfast,
[01:38:07.100 --> 01:38:09.900]   we'd have two or three qualified candidates by lunch.
[01:38:09.900 --> 01:38:12.220]   Four out of five employers report,
[01:38:12.220 --> 01:38:14.500]   they get a quality candidate on Zippur Cruder
[01:38:14.500 --> 01:38:16.740]   within the first day.
[01:38:16.740 --> 01:38:19.820]   And by the way, these applicants don't flow
[01:38:19.820 --> 01:38:22.180]   into your e-mail or your phone.
[01:38:22.180 --> 01:38:23.740]   They go into the Zippur Cruder interface,
[01:38:23.740 --> 01:38:27.700]   the resumes are formatted, so it's easy to scan them.
[01:38:27.700 --> 01:38:29.700]   You can have your own screening questions,
[01:38:29.700 --> 01:38:32.540]   true, false, multiple choice, essay,
[01:38:32.540 --> 01:38:34.580]   so you can screen out the candidates
[01:38:34.580 --> 01:38:36.100]   that don't fit your needs,
[01:38:36.100 --> 01:38:39.340]   rank the rest and hire the right one fast.
[01:38:39.340 --> 01:38:41.700]   It really works.
[01:38:41.700 --> 01:38:44.660]   The world is changing, you've gotta be flexible,
[01:38:44.660 --> 01:38:46.340]   but if you are hiring,
[01:38:46.340 --> 01:38:49.740]   can I tell you zippurcruder.com/twit,
[01:38:49.740 --> 01:38:51.620]   you can always count on Zippur Cruder
[01:38:51.620 --> 01:38:54.100]   to make hiring faster and easier.
[01:38:54.100 --> 01:38:56.020]   And now's a good time to see for yourself
[01:38:56.020 --> 01:38:58.500]   'cause you could try Zippur Cruder free
[01:38:58.500 --> 01:39:00.340]   at zippurcruder.com/twit.
[01:39:00.340 --> 01:39:02.180]   That's zippurcruder.com/twit.
[01:39:02.180 --> 01:39:05.740]   Dot com/twit.
[01:39:05.740 --> 01:39:10.260]   Don't suffer, let's Zippur Cruder take the hiring drudgery
[01:39:10.260 --> 01:39:11.820]   off your plate, they make it easy,
[01:39:11.820 --> 01:39:13.580]   go to zippurcruder.com/twit,
[01:39:13.580 --> 01:39:15.420]   and I can say that's some of our best employees
[01:39:15.420 --> 01:39:17.900]   that found on Zippur Cruder.
[01:39:17.900 --> 01:39:20.860]   Zippur Cruder is the smartest way to hire.
[01:39:20.860 --> 01:39:23.420]   Thank you, Zippur Cruder for supporting.
[01:39:23.420 --> 01:39:26.260]   This week in tech.
[01:39:26.260 --> 01:39:32.820]   Now the FCC says, oh yeah,
[01:39:32.820 --> 01:39:36.100]   first they said last year during the net neutrality thing,
[01:39:36.100 --> 01:39:38.820]   oh, we can't regulate the internet.
[01:39:38.820 --> 01:39:40.300]   Now they're saying, damn straight,
[01:39:40.300 --> 01:39:42.500]   we can regulate the internet.
[01:39:42.500 --> 01:39:45.380]   In fact, we're gonna get rid of that section
[01:39:45.380 --> 01:39:50.380]   to 30 thing that's protecting all those social networks.
[01:39:50.380 --> 01:39:56.140]   They even got the FCC's general counsel
[01:39:56.140 --> 01:40:00.420]   to write a kind of confusing legal memo.
[01:40:00.420 --> 01:40:03.460]   It had lots of highfalutin references
[01:40:03.460 --> 01:40:06.740]   to previous court decisions to somehow imply
[01:40:06.740 --> 01:40:09.300]   that somehow magically the FCC,
[01:40:09.300 --> 01:40:11.340]   now they can regulate the internet.
[01:40:12.660 --> 01:40:15.260]   Any thoughts on, Brianna,
[01:40:15.260 --> 01:40:18.980]   can you explain section 230 or is that?
[01:40:18.980 --> 01:40:23.060]   Sure, section 230 is basically the part of,
[01:40:23.060 --> 01:40:26.780]   it basically indemnifies corporations like Facebook
[01:40:26.780 --> 01:40:31.740]   or Google or let's say a Twitch outroom against,
[01:40:31.740 --> 01:40:33.720]   like you're basically not responsible
[01:40:33.720 --> 01:40:36.540]   for what users are posting there.
[01:40:36.540 --> 01:40:39.220]   I wouldn't have a chatroom if it weren't for section 230.
[01:40:39.220 --> 01:40:41.820]   I wouldn't have a comments section on YouTube.
[01:40:41.820 --> 01:40:44.300]   I wouldn't have a forum.
[01:40:44.300 --> 01:40:45.740]   It's too risky.
[01:40:45.740 --> 01:40:50.420]   Yep, so it indemnifies providers for user content basically.
[01:40:50.420 --> 01:40:51.540]   It's pretty short and sweet.
[01:40:51.540 --> 01:40:53.580]   In fact, short enough, I can read it to you right now.
[01:40:53.580 --> 01:40:57.380]   It part of the Communications Decency Act of 1996.
[01:40:57.380 --> 01:41:01.980]   No provider or user of an interactive computer service
[01:41:01.980 --> 01:41:04.300]   shall be treated as the publisher or speaker
[01:41:04.300 --> 01:41:08.460]   of any information provided by another
[01:41:08.460 --> 01:41:11.540]   information content provider.
[01:41:11.540 --> 01:41:14.020]   In other words, you're not a publisher
[01:41:14.020 --> 01:41:16.420]   like the Washington Post is a publisher.
[01:41:16.420 --> 01:41:18.260]   I'm not a publisher in our chatroom
[01:41:18.260 --> 01:41:21.220]   and I'm not held to the same requirements
[01:41:21.220 --> 01:41:22.660]   as a publisher is.
[01:41:22.660 --> 01:41:27.660]   For instance, I can without any risk,
[01:41:27.660 --> 01:41:30.620]   remove hate speech from my chatroom.
[01:41:30.620 --> 01:41:34.860]   I can't be sued for hate speech in my chatroom.
[01:41:34.860 --> 01:41:37.460]   So I have privileges in both directions.
[01:41:39.260 --> 01:41:42.580]   Some people say these are the 26 words
[01:41:42.580 --> 01:41:43.380]   that created the internet.
[01:41:43.380 --> 01:41:45.780]   In fact, there's a book with that title.
[01:41:45.780 --> 01:41:47.900]   I don't know what we would do with that.
[01:41:47.900 --> 01:41:51.700]   I do want to say, and sometimes on this show,
[01:41:51.700 --> 01:41:53.060]   you play devil's advocate.
[01:41:53.060 --> 01:41:54.460]   So I'm going to play it here.
[01:41:54.460 --> 01:41:56.860]   A good friend of mine is Kerry Goldberg.
[01:41:56.860 --> 01:41:59.140]   She's a lawyer.
[01:41:59.140 --> 01:42:02.140]   She's been very critical about section 230
[01:42:02.140 --> 01:42:04.580]   because she's had to adjudicate a lot
[01:42:04.580 --> 01:42:09.580]   of the situations where it's really, really gone wrong.
[01:42:09.580 --> 01:42:15.620]   The example she starts her book with is with Grindr.
[01:42:15.620 --> 01:42:18.660]   There was someone on Grindr that created a false profile
[01:42:18.660 --> 01:42:23.660]   of basically a gay man and harassed him for years
[01:42:23.660 --> 01:42:26.580]   with people showing up to his apartment
[01:42:26.580 --> 01:42:30.100]   for basically sexual relations.
[01:42:30.100 --> 01:42:33.020]   And he tried everything he could to work with Grindr
[01:42:33.020 --> 01:42:34.780]   and get them to take it down
[01:42:34.780 --> 01:42:37.140]   and to take these repeated fake profiles down
[01:42:37.140 --> 01:42:38.820]   and they just would not do it.
[01:42:38.820 --> 01:42:42.180]   And what Kerry has found in her work
[01:42:42.180 --> 01:42:45.260]   is that there's really no civil recourse
[01:42:45.260 --> 01:42:46.700]   for a situation like that.
[01:42:46.700 --> 01:42:50.940]   I myself did not have a civil recourse during gamergate.
[01:42:50.940 --> 01:42:55.940]   I'm not saying we throw section 230 away because of that,
[01:42:55.940 --> 01:43:01.660]   but I have begun to become increasingly open-minded
[01:43:01.660 --> 01:43:05.900]   to the thought that perhaps we could widen it
[01:43:05.900 --> 01:43:09.220]   in a way that might address those very reasonable concerns.
[01:43:09.220 --> 01:43:12.340]   - That's a good point.
[01:43:12.340 --> 01:43:13.740]   I hadn't really thought about that.
[01:43:13.740 --> 01:43:17.340]   I mean, normally what section 230 is used for
[01:43:17.340 --> 01:43:20.140]   is to let somebody like Grindr pull that account down
[01:43:20.140 --> 01:43:22.260]   without liability, right?
[01:43:22.260 --> 01:43:27.980]   But if they decide not to, where is the recourse?
[01:43:27.980 --> 01:43:32.100]   And you're saying that you can't sue them over that.
[01:43:32.100 --> 01:43:35.460]   - She has found it nearly impossible to bring lawsuits
[01:43:35.460 --> 01:43:40.860]   forward with issues like revenge porn or cyber stalking
[01:43:40.860 --> 01:43:43.940]   or basically organized harassment.
[01:43:43.940 --> 01:43:46.700]   Like Kerry is the lawyer you call
[01:43:46.700 --> 01:43:48.580]   if you're in a situation like that.
[01:43:48.580 --> 01:43:52.820]   And again, I hope your listeners and viewers
[01:43:52.820 --> 01:43:55.060]   don't think I'm advocating gang rev 230.
[01:43:55.060 --> 01:43:58.300]   I'm not, I'm just wondering if there's a way
[01:43:58.300 --> 01:44:00.140]   to make everyone happy here.
[01:44:00.140 --> 01:44:00.980]   - Yeah.
[01:44:00.980 --> 01:44:02.820]   Anybody have--
[01:44:02.820 --> 01:44:04.780]   - That's where the community comes into play.
[01:44:04.780 --> 01:44:07.260]   I think when there's something wrong like that
[01:44:07.260 --> 01:44:10.820]   and someone's abusing the platforms,
[01:44:10.820 --> 01:44:13.780]   like I mean, right now on Instagram, you flag people
[01:44:13.780 --> 01:44:17.780]   or if they're a catfishing or if they're harassment.
[01:44:17.780 --> 01:44:20.940]   I mean, the platforms do something about it, it seems,
[01:44:20.940 --> 01:44:22.460]   most of the time.
[01:44:22.460 --> 01:44:24.740]   But yet sometimes, I mean,
[01:44:24.740 --> 01:44:26.420]   for my, but like, yeah,
[01:44:26.420 --> 01:44:28.580]   I mean, I think that everyone has a different experience
[01:44:28.580 --> 01:44:30.460]   with that and then it's also very biased.
[01:44:30.460 --> 01:44:31.940]   There's no like one way to do it
[01:44:31.940 --> 01:44:33.740]   because it depends how high profile you are,
[01:44:33.740 --> 01:44:35.060]   how much accessibility you have.
[01:44:35.060 --> 01:44:37.540]   Do you know an exec at that platform to help you do it,
[01:44:37.540 --> 01:44:38.380]   right?
[01:44:38.380 --> 01:44:40.460]   And then that person can then fight against it.
[01:44:40.460 --> 01:44:43.380]   So I do think there needs to be some rules and regulations
[01:44:43.380 --> 01:44:47.340]   around that including on dating apps
[01:44:47.340 --> 01:44:48.820]   where it could get dangerous.
[01:44:48.820 --> 01:44:49.660]   - Yeah, I mean, that's terrible.
[01:44:49.660 --> 01:44:50.980]   - That's not supposed to be using this,
[01:44:50.980 --> 01:44:53.620]   if they're using this against people,
[01:44:53.620 --> 01:44:56.100]   then yeah, there's an issue there to definitely broaden it
[01:44:56.100 --> 01:44:59.580]   or create a new, seems like regulation around that
[01:44:59.580 --> 01:45:00.860]   for these platforms.
[01:45:00.860 --> 01:45:02.300]   - Really good point.
[01:45:02.300 --> 01:45:03.460]   I had not thought about that.
[01:45:03.460 --> 01:45:06.700]   - They're all very like smart and nuanced takes on 230,
[01:45:06.700 --> 01:45:09.020]   which is not the current public discourse around it.
[01:45:09.020 --> 01:45:11.060]   Like it's being used as something that Trump can,
[01:45:11.060 --> 01:45:14.260]   can literally say 230, how about that at campaign rallies?
[01:45:14.260 --> 01:45:15.420]   - Right. - Around of applause.
[01:45:15.420 --> 01:45:16.260]   - Right.
[01:45:16.260 --> 01:45:18.980]   - Although Joe Biden has also said
[01:45:18.980 --> 01:45:20.500]   in an interview with the New York Times,
[01:45:20.500 --> 01:45:22.860]   yeah, I think we should repeal 230.
[01:45:22.860 --> 01:45:26.060]   I think somebody, I think Jeff Jarvis told me on Wednesday
[01:45:26.060 --> 01:45:30.260]   that calmer heads have apparently talked him off that ledge.
[01:45:30.260 --> 01:45:33.420]   But maybe we do need to address it somehow.
[01:45:33.420 --> 01:45:36.300]   I thought it was kind of beautiful in its elegance,
[01:45:36.300 --> 01:45:37.860]   but it does have a consequence
[01:45:37.860 --> 01:45:39.100]   that I hadn't really considered.
[01:45:39.100 --> 01:45:41.740]   So thank you, Brianna, for sharing that.
[01:45:41.740 --> 01:45:44.900]   I mean, clearly we need protection of some kind,
[01:45:44.900 --> 01:45:48.860]   but too much protection allows bad behavior.
[01:45:48.860 --> 01:45:52.300]   - There's gotta be a way to open up grinder,
[01:45:52.300 --> 01:45:57.020]   to civil consequences in a situation like that, right?
[01:45:57.020 --> 01:46:01.900]   Because she can't, I mean,
[01:46:01.900 --> 01:46:04.620]   Kerry was unable to sue the person themselves
[01:46:04.620 --> 01:46:06.100]   because they had no money
[01:46:06.100 --> 01:46:08.980]   and they were just continuing to participate in this.
[01:46:08.980 --> 01:46:12.020]   And it's not a crime to start a profile.
[01:46:12.020 --> 01:46:14.620]   So it's really a situation.
[01:46:14.620 --> 01:46:16.940]   It's like a lot of online harassment things.
[01:46:16.940 --> 01:46:21.100]   It's just not adjudicated very well, which are as prudent.
[01:46:21.100 --> 01:46:24.580]   So this is why I ran for Congress.
[01:46:24.580 --> 01:46:26.220]   I thought it was a Florida policy.
[01:46:26.220 --> 01:46:28.740]   - Yeah, well, and you know,
[01:46:28.740 --> 01:46:31.700]   I hate to say it, but you're an expert on online abuse.
[01:46:31.700 --> 01:46:35.540]   So I actually wanna hear what you have to say about it
[01:46:35.540 --> 01:46:38.660]   because you've been the victim of it.
[01:46:38.660 --> 01:46:40.700]   Although anybody online, especially a woman,
[01:46:40.700 --> 01:46:44.500]   but anybody online these days is subject to that.
[01:46:44.500 --> 01:46:47.460]   And I don't know what the right answer is.
[01:46:47.460 --> 01:46:50.380]   I think you assume that the platforms will do a good job,
[01:46:50.380 --> 01:46:52.700]   but, and maybe the platforms would feel like,
[01:46:52.700 --> 01:46:55.340]   well, we can't do anything at all without 230.
[01:46:55.340 --> 01:46:59.260]   But I don't know what the, that's an interesting one.
[01:46:59.260 --> 01:47:00.940]   Now we gotta think about that.
[01:47:00.940 --> 01:47:03.140]   Too bad you didn't get into Congress, Brianna.
[01:47:03.140 --> 01:47:04.900]   - I know, I know. - Damn it.
[01:47:04.900 --> 01:47:08.060]   - Yeah, it's unfortunate to rely on the community
[01:47:08.060 --> 01:47:11.020]   to drag a platform down in order to protect individuals.
[01:47:11.020 --> 01:47:12.380]   The law should be able to do that.
[01:47:12.380 --> 01:47:13.900]   - Yeah, there's gotta be a better way.
[01:47:13.900 --> 01:47:17.580]   Okay, okay, you've made me rethink this whole thing.
[01:47:17.580 --> 01:47:18.820]   (laughing)
[01:47:18.820 --> 01:47:20.660]   - Kerry's book is great, you should read it.
[01:47:20.660 --> 01:47:22.220]   - What's the name of it?
[01:47:22.220 --> 01:47:23.380]   - Nobody's victim.
[01:47:23.380 --> 01:47:25.980]   - Nobody's victim, is it about you?
[01:47:25.980 --> 01:47:28.620]   - Nah, I think I may be in it, I don't know.
[01:47:28.620 --> 01:47:33.620]   - Okay, fighting psychos, stalkers, perves, and trolls.
[01:47:33.620 --> 01:47:37.460]   Is that it?
[01:47:37.460 --> 01:47:39.860]   - That's it, right there.
[01:47:39.860 --> 01:47:43.180]   - Right there, Kerry Goldberg, I will read it.
[01:47:43.180 --> 01:47:47.340]   Does she make some recommendations?
[01:47:47.340 --> 01:47:49.060]   - Yeah, she has very strong opinion.
[01:47:49.060 --> 01:47:52.420]   She has a hard opinion on 230.
[01:47:52.420 --> 01:47:54.580]   She agrees with repealing it.
[01:47:54.580 --> 01:47:56.500]   I'm not willing to go that far,
[01:47:56.500 --> 01:48:00.060]   but I think sometimes it's helpful to understand
[01:48:00.060 --> 01:48:02.100]   where someone is coming from.
[01:48:02.100 --> 01:48:06.460]   - Well, I just added it to my audible listens.
[01:48:06.460 --> 01:48:08.460]   I happen to have a credit lying around.
[01:48:08.460 --> 01:48:09.420]   (laughing)
[01:48:09.420 --> 01:48:10.260]   So there you go.
[01:48:10.260 --> 01:48:12.860]   (laughing)
[01:48:12.860 --> 01:48:16.060]   Yeah, that's how fast I can buy a book, look at that.
[01:48:16.060 --> 01:48:17.420]   No, I need to read this,
[01:48:17.420 --> 01:48:21.460]   'cause I like to fight stalkers, perves, trolls,
[01:48:21.460 --> 01:48:22.780]   and psychos too.
[01:48:22.780 --> 01:48:24.140]   We all need to.
[01:48:24.140 --> 01:48:25.540]   - You're a superhero.
[01:48:25.540 --> 01:48:26.380]   (laughing)
[01:48:26.380 --> 01:48:28.300]   That's what you're doing when you're not honest.
[01:48:28.300 --> 01:48:29.300]   - What's your superpower?
[01:48:29.300 --> 01:48:33.620]   Oh, fighting stalkers, perves, trolls, you know, the usual.
[01:48:33.620 --> 01:48:42.140]   We chat, apparently we'll live to chat again.
[01:48:43.340 --> 01:48:48.140]   A US judge, the judge who originally issued
[01:48:48.140 --> 01:48:51.460]   a preliminary injunction blocking the order
[01:48:51.460 --> 01:48:54.020]   from the Commerce Department that would have put
[01:48:54.020 --> 01:48:56.780]   WeChat out of business in the US on September 20th,
[01:48:56.780 --> 01:49:01.780]   Judge Laurel Biehler made her injunction permanent,
[01:49:01.780 --> 01:49:05.220]   at least until there's a trial.
[01:49:05.220 --> 01:49:07.820]   The Justice Department asked her to reverse the decision.
[01:49:07.820 --> 01:49:09.380]   She's now rejected it.
[01:49:09.380 --> 01:49:11.020]   In her decision, she said,
[01:49:11.020 --> 01:49:13.980]   "The record does not support the conclusion
[01:49:13.980 --> 01:49:16.300]   that does not support the conclusion
[01:49:16.300 --> 01:49:19.100]   that the government has narrowly tailored
[01:49:19.100 --> 01:49:20.900]   the prohibited transactions
[01:49:20.900 --> 01:49:24.340]   to protect its national security interests.
[01:49:24.340 --> 01:49:26.420]   The evidence supports the conclusion
[01:49:26.420 --> 01:49:29.380]   that the restrictions burden substantially more speech
[01:49:29.380 --> 01:49:32.500]   than is necessary to further the government's legitimate
[01:49:32.500 --> 01:49:33.340]   interests."
[01:49:33.340 --> 01:49:34.340]   In other words, she says,
[01:49:34.340 --> 01:49:39.900]   "It's just too much to ban WeChat given your problems with it.
[01:49:39.900 --> 01:49:44.340]   WeChat is the Chinese chat client
[01:49:44.340 --> 01:49:45.940]   that's used mostly primarily in China,
[01:49:45.940 --> 01:49:50.460]   but also used by China as expats in the United States
[01:49:50.460 --> 01:49:54.780]   to communicate with friends and family back home.
[01:49:54.780 --> 01:49:57.460]   But for instance, Disney uses WeChat
[01:49:57.460 --> 01:50:00.340]   because WeChat's more than a chat platform.
[01:50:00.340 --> 01:50:03.540]   It's a commerce platform.
[01:50:03.540 --> 01:50:07.220]   Disney uses WeChat for payments for passes,
[01:50:07.220 --> 01:50:08.660]   concessions and other purchases
[01:50:08.660 --> 01:50:11.220]   at Hong Kong and Shanghai Disneyland.
[01:50:11.220 --> 01:50:14.900]   Apple believes that if WeChat were blocked in the US,
[01:50:14.900 --> 01:50:19.980]   it would cause iPhone shipments to dip by as much as 30%
[01:50:19.980 --> 01:50:22.060]   because without WeChat and on iPhone,
[01:50:22.060 --> 01:50:24.500]   no one's going to buy it in China.
[01:50:24.500 --> 01:50:29.500]   So I think that those briefs convinced the judge
[01:50:29.500 --> 01:50:32.660]   that the harm would be greater than the solution.
[01:50:32.660 --> 01:50:36.900]   Now, the DOJ says they are going to appeal it
[01:50:36.900 --> 01:50:38.620]   to the Ninth Circuit Court of Appeals.
[01:50:38.620 --> 01:50:43.860]   So it's not over, but WeChat will live for now.
[01:50:43.860 --> 01:50:45.580]   What's going on with TikTok?
[01:50:45.580 --> 01:50:46.420]   Anything?
[01:50:46.420 --> 01:50:47.860]   (laughs)
[01:50:47.860 --> 01:50:51.860]   Is there any, it's so hard to follow this stuff.
[01:50:51.860 --> 01:50:55.300]   I haven't heard anything about TikTok lately.
[01:50:55.300 --> 01:50:57.580]   It's certainly still active, right?
[01:50:57.580 --> 01:50:58.860]   - Yep. - Yep.
[01:50:58.860 --> 01:51:01.780]   - Not taken down yet, not dead yet.
[01:51:01.780 --> 01:51:06.500]   - Yeah, I was, my one experience of WeChat,
[01:51:06.500 --> 01:51:08.860]   this is such a funny story that, yeah,
[01:51:08.860 --> 01:51:11.780]   Frank is Chinese, so he has a lot of relatives
[01:51:11.780 --> 01:51:14.020]   that are natively from China.
[01:51:14.020 --> 01:51:17.220]   And I was buying a song on iTunes
[01:51:17.220 --> 01:51:20.380]   and Frank's niece looks at me and she's like,
[01:51:20.380 --> 01:51:22.100]   "You're paying money for music?
[01:51:22.100 --> 01:51:23.860]   "Why would you do that?"
[01:51:23.860 --> 01:51:27.180]   And she goes on to WeChat and just downloads him for free.
[01:51:27.180 --> 01:51:28.020]   - Oh, great.
[01:51:28.020 --> 01:51:31.380]   - That second on there, it was such a, it was--
[01:51:31.380 --> 01:51:33.420]   - Don't tell them that, they'll ban it.
[01:51:33.420 --> 01:51:34.420]   - I know.
[01:51:35.620 --> 01:51:37.820]   - I think people that don't,
[01:51:37.820 --> 01:51:40.740]   I think a lot of Americans aren't aware of just how,
[01:51:40.740 --> 01:51:42.060]   I don't wanna say monolithic,
[01:51:42.060 --> 01:51:44.900]   but it's more powerful than Facebook, I think.
[01:51:44.900 --> 01:51:46.500]   - It is, yeah. - So, yeah.
[01:51:46.500 --> 01:51:48.020]   - Yeah, so, does Frank,
[01:51:48.020 --> 01:51:50.140]   what does Frank's point of view on this?
[01:51:50.140 --> 01:51:52.340]   - He doesn't like technology at all.
[01:51:52.340 --> 01:51:54.180]   - Okay, so he doesn't care.
[01:51:54.180 --> 01:51:56.060]   - It's all my headache, he hates it.
[01:51:56.060 --> 01:51:57.540]   - But he uses it.
[01:51:57.540 --> 01:51:59.660]   - He does and I fix it for him.
[01:51:59.660 --> 01:52:01.940]   - And if it were to go away,
[01:52:01.940 --> 01:52:03.580]   have you ever asked him if he were to go away,
[01:52:03.580 --> 01:52:05.140]   what would you, he'd be happy?
[01:52:05.140 --> 01:52:08.620]   - I think he would, he was comfortable at the 1980s level.
[01:52:08.620 --> 01:52:10.780]   - He says, I'll just phone him, I'll just call him.
[01:52:10.780 --> 01:52:12.100]   - Yeah.
[01:52:12.100 --> 01:52:15.540]   - I've gotta telegraph, I don't need anything more.
[01:52:15.540 --> 01:52:16.380]   - Yeah.
[01:52:16.380 --> 01:52:17.460]   - You can call on WeChat though.
[01:52:17.460 --> 01:52:18.300]   - Yeah, that's true.
[01:52:18.300 --> 01:52:19.140]   Oh, you can do any?
[01:52:19.140 --> 01:52:19.980]   I mean, honestly.
[01:52:19.980 --> 01:52:21.780]   - Yeah, it's like a better version of WhatsApp,
[01:52:21.780 --> 01:52:24.380]   but also like your wallet.
[01:52:24.380 --> 01:52:26.780]   - Somebody in our chat room says,
[01:52:26.780 --> 01:52:30.820]   "I have a WeChat account, I watch the new Moline for free."
[01:52:30.820 --> 01:52:31.660]   - Oh, nice.
[01:52:31.660 --> 01:52:32.500]   - Yes.
[01:52:32.500 --> 01:52:34.420]   - Oh, Disney's going, "Now!"
[01:52:34.420 --> 01:52:36.660]   Maybe that wasn't a good idea.
[01:52:36.660 --> 01:52:41.340]   - Ah, okay.
[01:52:41.340 --> 01:52:44.340]   The government's asserting it has the authority
[01:52:44.340 --> 01:52:46.100]   just to ban an outright, so,
[01:52:46.100 --> 01:52:50.060]   you know, that's what the judge stopped, we shall see.
[01:52:50.060 --> 01:52:51.540]   It's gonna be up to the district court now,
[01:52:51.540 --> 01:52:54.620]   and then eventually the Supreme Court, I would guess.
[01:52:54.620 --> 01:52:56.620]   Point of the day, they really, they just wanna shut down.
[01:52:56.620 --> 01:52:57.780]   - So politicized, like it's not--
[01:52:57.780 --> 01:53:00.220]   - It is, 'cause it's hard to imagine,
[01:53:00.220 --> 01:53:04.140]   you know, what is the threat to American security
[01:53:04.140 --> 01:53:06.500]   from WeChat and TikTok?
[01:53:06.500 --> 01:53:10.740]   - They're just trying to drag every Chinese company
[01:53:10.740 --> 01:53:12.540]   that's starting to move into the US.
[01:53:12.540 --> 01:53:13.380]   Yeah.
[01:53:13.380 --> 01:53:14.220]   - I agree.
[01:53:14.220 --> 01:53:16.500]   - They wanna hit him where they think it hurts.
[01:53:16.500 --> 01:53:18.300]   - Is it to protect Facebook?
[01:53:18.300 --> 01:53:24.180]   - I do think that there's an assumption
[01:53:24.180 --> 01:53:26.540]   that American technology companies are good
[01:53:26.540 --> 01:53:28.980]   and Chinese technology companies are awful.
[01:53:28.980 --> 01:53:29.820]   - Right, right.
[01:53:29.820 --> 01:53:31.500]   - That is coloring their thinking.
[01:53:31.500 --> 01:53:32.340]   - That's too bad.
[01:53:32.340 --> 01:53:33.180]   - Yeah.
[01:53:33.180 --> 01:53:34.020]   - Yeah.
[01:53:34.020 --> 01:53:39.020]   Does Frank face any Asian sentiment or any Chinese sentiment?
[01:53:39.020 --> 01:53:40.700]   - Absolutely, really.
[01:53:40.700 --> 01:53:44.540]   - It's, you know, it's not helping when people are calling it
[01:53:44.540 --> 01:53:47.540]   the president is calling it the China--
[01:53:47.540 --> 01:53:51.260]   - Yeah, the Congress flu, China virus, yeah.
[01:53:51.260 --> 01:53:52.780]   - He's definitely faced that.
[01:53:52.780 --> 01:53:53.860]   - Yeah.
[01:53:53.860 --> 01:53:56.220]   You know, virus is no, no national boundaries,
[01:53:56.220 --> 01:53:57.300]   I just discovered that.
[01:53:57.300 --> 01:53:59.380]   (laughs)
[01:53:59.380 --> 01:54:02.700]   The RIAA, is that it again?
[01:54:02.700 --> 01:54:05.260]   Well, I thought we would heard the last of them 10 years ago
[01:54:05.260 --> 01:54:08.380]   when they stopped suing people for stealing music.
[01:54:08.380 --> 01:54:12.420]   They have taken down 18, count 'em, 18,
[01:54:12.420 --> 01:54:17.420]   GitHub projects used for downloading YouTube videos.
[01:54:17.420 --> 01:54:22.180]   The main target was the YouTube DL project,
[01:54:22.180 --> 01:54:26.460]   which is a Python library used by many YouTube video ripping
[01:54:26.460 --> 01:54:27.420]   tools and services.
[01:54:27.420 --> 01:54:30.260]   You may say, why would the recording industry association
[01:54:30.260 --> 01:54:33.580]   of America care if I download a YouTube video?
[01:54:33.580 --> 01:54:37.220]   Well, they say the clear purpose of YouTube
[01:54:37.220 --> 01:54:41.180]   downloaders is to circumvent the technological protection
[01:54:41.180 --> 01:54:44.380]   measures used by authorized streaming services such as
[01:54:44.380 --> 01:54:47.820]   YouTube to allow users to reproduce and distribute music
[01:54:47.820 --> 01:54:50.900]   videos and sound recordings without authorization.
[01:54:50.900 --> 01:54:53.740]   You should go after WeChat RIAA, please.
[01:54:53.740 --> 01:54:59.060]   - I think this story really brings forward some uncomfortable
[01:54:59.060 --> 01:55:02.020]   questions about Microsoft stewardship over GitHub.
[01:55:02.020 --> 01:55:03.620]   - They didn't even, there was, they didn't put it out
[01:55:03.620 --> 01:55:04.460]   for common or anything.
[01:55:04.460 --> 01:55:06.300]   They said, okay, sure.
[01:55:06.300 --> 01:55:07.460]   - Exactly.
[01:55:07.460 --> 01:55:10.820]   It's very, you know, I was very, I think most people
[01:55:10.820 --> 01:55:15.020]   at Microsoft were very happy to see them acquire GitHub.
[01:55:15.020 --> 01:55:17.780]   And I think overall Microsoft has been a very strong
[01:55:17.780 --> 01:55:19.340]   steward for open source.
[01:55:19.340 --> 01:55:23.460]   In fact, at Rebellion, we modeled our code of conduct
[01:55:23.460 --> 01:55:26.740]   directly off the Microsoft open source code of conduct
[01:55:26.740 --> 01:55:28.500]   'cause it was so good.
[01:55:28.500 --> 01:55:33.500]   But if they're just gonna roll over like this with a legal
[01:55:33.500 --> 01:55:38.500]   threat for something that there's clearly fair use to be
[01:55:38.500 --> 01:55:42.860]   with YouTube downloading, we use it at Rebellion all the time
[01:55:42.860 --> 01:55:44.220]   for political ads.
[01:55:44.220 --> 01:55:47.900]   I just, I think it really raises some questions.
[01:55:47.900 --> 01:55:50.620]   - I encourage people to use YouTube downloaders for our
[01:55:50.620 --> 01:55:51.940]   shows.
[01:55:51.940 --> 01:55:54.420]   If they, honestly, if we're on YouTube, if you want a
[01:55:54.420 --> 01:55:58.340]   smaller version of our show than the HD version we put out,
[01:55:58.340 --> 01:56:00.620]   I say go to YouTube and download it.
[01:56:00.620 --> 01:56:02.620]   That's not infringing.
[01:56:02.620 --> 01:56:03.460]   - Yeah.
[01:56:03.460 --> 01:56:07.260]   - According to John Bergmaer, who is the legal director
[01:56:07.260 --> 01:56:10.700]   of public knowledge, he said, this is not a DMC request.
[01:56:10.700 --> 01:56:13.260]   There is no assertion that YouTube downloader is an
[01:56:13.260 --> 01:56:15.300]   infringing work.
[01:56:15.300 --> 01:56:18.260]   The claim is it's illegal per se.
[01:56:18.260 --> 01:56:20.940]   It's not.
[01:56:20.940 --> 01:56:23.620]   That's like saying, bit torn is illegal per se
[01:56:23.620 --> 01:56:26.580]   because in some cases it's used illegally.
[01:56:26.580 --> 01:56:27.580]   - Yeah.
[01:56:27.580 --> 01:56:29.340]   - If you're making an assumption, then that's the only way
[01:56:29.340 --> 01:56:30.540]   that it's used.
[01:56:30.540 --> 01:56:33.220]   - And the fact that Microsoft didn't defend it is very
[01:56:33.220 --> 01:56:34.060]   disappointing.
[01:56:34.060 --> 01:56:36.900]   - Yeah, it doesn't protect those.
[01:56:36.900 --> 01:56:39.380]   And it sets a precedent that, yeah, what's happening
[01:56:39.380 --> 01:56:40.460]   is illegal.
[01:56:40.460 --> 01:56:41.300]   - Right.
[01:56:41.300 --> 01:56:42.140]   - Right.
[01:56:42.140 --> 01:56:44.460]   You know, I think that, you know, there are ways to
[01:56:44.460 --> 01:56:47.220]   monetize or like there's technology and then still
[01:56:47.220 --> 01:56:52.220]   networks and collectives that will find the content that
[01:56:52.220 --> 01:56:56.140]   you have or that's been used on someone else's channels
[01:56:56.140 --> 01:56:58.620]   and then just monetize that for you.
[01:56:58.620 --> 01:57:01.220]   Like I think that is better than necessarily doing
[01:57:01.220 --> 01:57:02.060]   takedowns.
[01:57:02.060 --> 01:57:02.900]   - Right.
[01:57:02.900 --> 01:57:05.340]   Well, that's in fact one of the choices you have
[01:57:05.340 --> 01:57:07.900]   with YouTube's content ID system.
[01:57:07.900 --> 01:57:09.860]   There are a number of things you can do if you say
[01:57:09.860 --> 01:57:11.060]   that's infringing content.
[01:57:11.060 --> 01:57:12.540]   We get taken that all the time.
[01:57:12.540 --> 01:57:16.060]   In fact, the fact that I played Nathan Apodaca's TikTok
[01:57:16.060 --> 01:57:18.980]   that had the music from "Flat with Max Dream" behind it
[01:57:18.980 --> 01:57:21.060]   means that this show almost certainly get taken down
[01:57:21.060 --> 01:57:24.140]   on YouTube, which is why our editors will probably
[01:57:24.140 --> 01:57:25.180]   just take it out.
[01:57:26.180 --> 01:57:28.900]   Which pisses the hell out of me because it's fair use.
[01:57:28.900 --> 01:57:30.980]   It was a news story.
[01:57:30.980 --> 01:57:32.420]   It's completely legal use.
[01:57:32.420 --> 01:57:34.660]   And by the way, nobody's not gonna buy dreams
[01:57:34.660 --> 01:57:37.060]   'cause they heard me play it on this show.
[01:57:37.060 --> 01:57:38.780]   In fact, quite the opposite.
[01:57:38.780 --> 01:57:41.180]   - You're stealing the, yeah, you're really mean to that.
[01:57:41.180 --> 01:57:42.780]   - Quite the opposite.
[01:57:42.780 --> 01:57:47.780]   This is, I mean, that TikTok video is prima facie evidence
[01:57:47.780 --> 01:57:49.540]   that it sells records.
[01:57:49.540 --> 01:57:51.580]   It doesn't stop record sales.
[01:57:51.580 --> 01:57:55.260]   It makes a 43 year old song ahead again.
[01:57:55.260 --> 01:57:57.740]   - They're selective, right?
[01:57:57.740 --> 01:58:00.980]   With what they wanna to work for them and with them.
[01:58:00.980 --> 01:58:02.900]   That's where, it's like that great area
[01:58:02.900 --> 01:58:03.980]   and makes it really difficult.
[01:58:03.980 --> 01:58:05.220]   - Well, you do get the choice.
[01:58:05.220 --> 01:58:07.460]   So we get taken that all the time.
[01:58:07.460 --> 01:58:09.300]   I get taken that for crazy things.
[01:58:09.300 --> 01:58:10.140]   But you have a choice.
[01:58:10.140 --> 01:58:13.140]   When you set the content ID, you can do like,
[01:58:13.140 --> 01:58:15.900]   remember when National Geographic accidentally said,
[01:58:15.900 --> 01:58:18.940]   any videos with a space launch should be taken down,
[01:58:18.940 --> 01:58:21.500]   even though they didn't own them.
[01:58:21.500 --> 01:58:24.300]   And our videos and a lot of YouTubers videos
[01:58:24.300 --> 01:58:28.140]   that had a pictures of the Crew Dragon launch
[01:58:28.140 --> 01:58:31.940]   got taken down because National Geographic said we own it,
[01:58:31.940 --> 01:58:32.860]   but they don't.
[01:58:32.860 --> 01:58:35.380]   Or you can say monetize it.
[01:58:35.380 --> 01:58:37.180]   That's one of the switches, put an ad on it.
[01:58:37.180 --> 01:58:38.780]   Or, I mean, there's a variety,
[01:58:38.780 --> 01:58:42.100]   or you could say put a link to the song download on it.
[01:58:42.100 --> 01:58:43.860]   There's a lot of things you can do.
[01:58:43.860 --> 01:58:47.460]   But you can never break the chain.
[01:58:48.660 --> 01:58:49.900]   (laughing)
[01:58:49.900 --> 01:58:53.380]   - We had a big kerfluffle this week
[01:58:53.380 --> 01:58:54.900]   in the game industry.
[01:58:54.900 --> 01:58:58.540]   A Stadia developer put out.
[01:58:58.540 --> 01:58:59.380]   - Can you put a pin in that?
[01:58:59.380 --> 01:59:00.300]   I wanna talk about that one.
[01:59:00.300 --> 01:59:01.620]   - Go for it, go for it.
[01:59:01.620 --> 01:59:02.860]   - I wanted to bring that up with you.
[01:59:02.860 --> 01:59:04.780]   I'm so glad you mentioned that.
[01:59:04.780 --> 01:59:06.180]   Let's talk about it in just a second.
[01:59:06.180 --> 01:59:08.460]   But first, a quick word from our sponsor.
[01:59:08.460 --> 01:59:11.300]   If you're watching or listening to our shows,
[01:59:11.300 --> 01:59:14.260]   almost certainly it's brought to you by Cashfly.
[01:59:14.260 --> 01:59:16.980]   In fact, you may remember for years, I said bandwidth
[01:59:16.980 --> 01:59:19.780]   for the Twit podcast is brought to you by Cashfly
[01:59:19.780 --> 01:59:22.140]   at C-A-C-H-E-F-L-Y.com.
[01:59:22.140 --> 01:59:25.620]   That's our CDN, our content delivery network.
[01:59:25.620 --> 01:59:27.300]   We've used it for years.
[01:59:27.300 --> 01:59:30.260]   It has been a lifesaver for us.
[01:59:30.260 --> 01:59:33.300]   They've been innovating content delivery since 1999.
[01:59:33.300 --> 01:59:36.620]   We've been using them at least 10 years.
[01:59:36.620 --> 01:59:38.500]   And one of the things we've been using,
[01:59:38.500 --> 01:59:39.940]   this wasn't even, this was just something
[01:59:39.940 --> 01:59:42.900]   they let us do, but now you can do it too.
[01:59:42.900 --> 01:59:45.140]   They call it their storage optimization system.
[01:59:45.140 --> 01:59:46.940]   One of the real expenses of a,
[01:59:46.940 --> 01:59:49.380]   so you have to understand how a content delivery network works.
[01:59:49.380 --> 01:59:52.340]   They have servers all, as you can see, all over the world.
[01:59:52.340 --> 01:59:54.940]   And they put your content on all those servers,
[01:59:54.940 --> 01:59:58.020]   so it's close to your customers, your downloaders,
[01:59:58.020 --> 02:00:01.340]   your listeners, and they get it faster that way.
[02:00:01.340 --> 02:00:05.340]   But if one of those servers doesn't have the content,
[02:00:05.340 --> 02:00:08.900]   that's called a CashMiss, it has to go out
[02:00:08.900 --> 02:00:11.380]   and get it from the original source and download it.
[02:00:11.380 --> 02:00:12.900]   And that can end up costing you a lot of money.
[02:00:12.900 --> 02:00:16.100]   If you store your stuff on Amazon's S3, for instance,
[02:00:16.100 --> 02:00:19.260]   you might have noticed that even though you're on a CDN,
[02:00:19.260 --> 02:00:20.940]   your S3 bills are through the roof,
[02:00:20.940 --> 02:00:22.660]   that's 'cause of all the CashMisses.
[02:00:22.660 --> 02:00:25.660]   We've never had that problem because CashFly
[02:00:25.660 --> 02:00:29.500]   lets us store our content on CashFly's servers.
[02:00:29.500 --> 02:00:33.460]   Now you can too, with our storage optimization system.
[02:00:33.460 --> 02:00:35.380]   It lets you keep the data and content
[02:00:35.380 --> 02:00:38.940]   closer to your customers without traffic over
[02:00:38.940 --> 02:00:42.780]   the public internet slowing you down and costing you money.
[02:00:42.780 --> 02:00:46.020]   You could save thousands a month by shielding your origin.
[02:00:46.020 --> 02:00:48.260]   No CashMisses.
[02:00:48.260 --> 02:00:50.620]   That means a lot of things, not only saves you money,
[02:00:50.620 --> 02:00:53.420]   but it means no more buffering, no more slowdowns,
[02:00:53.420 --> 02:00:56.300]   your download speeds will be drastically improved,
[02:00:56.300 --> 02:01:00.140]   and your data transfer out fees significantly reduced.
[02:01:00.140 --> 02:01:02.020]   Because with CashFly's SOS,
[02:01:02.020 --> 02:01:04.900]   you get a 100% CashHit ratio.
[02:01:04.900 --> 02:01:06.740]   All you have to do is decide how much storage you need,
[02:01:06.740 --> 02:01:07.860]   they'll take care of the rest.
[02:01:07.860 --> 02:01:11.380]   And by the way, CashFly is always getting better.
[02:01:11.380 --> 02:01:12.740]   They're rapidly expanding,
[02:01:12.740 --> 02:01:16.020]   they added just new POPS, six new POPS points of presence.
[02:01:16.020 --> 02:01:19.060]   Those are the servers I was talking about in South America.
[02:01:19.060 --> 02:01:22.140]   They are now serving 10 times the amount of traffic
[02:01:22.140 --> 02:01:24.380]   in Latin America over last year.
[02:01:24.380 --> 02:01:25.340]   They've not only maintained,
[02:01:25.340 --> 02:01:27.740]   but drastically improved their performance in the region.
[02:01:27.740 --> 02:01:30.020]   While taking on a much higher traffic load,
[02:01:30.020 --> 02:01:31.740]   that's why I love CashFly.
[02:01:31.740 --> 02:01:34.300]   Doesn't matter where your users are, Latin America,
[02:01:34.300 --> 02:01:38.020]   North America, the Caribbean, Europe, the Middle East,
[02:01:38.020 --> 02:01:42.420]   Asia Pacific, your content is delivered locally
[02:01:42.420 --> 02:01:44.540]   to your listeners, your users,
[02:01:44.540 --> 02:01:46.900]   even in hard to reach regions.
[02:01:46.900 --> 02:01:50.060]   You can expect consistency and performance everywhere
[02:01:50.060 --> 02:01:53.540]   in the world, reliable throughput and scalability.
[02:01:53.540 --> 02:01:55.900]   That's what makes CashFly as much as five times faster
[02:01:55.900 --> 02:01:57.180]   than other CDNs.
[02:01:57.180 --> 02:02:00.500]   And of course, SOS is backed by CashFly's 100%
[02:02:00.500 --> 02:02:01.900]   uptime SLA guarantee,
[02:02:01.900 --> 02:02:04.420]   and it's industry leading global performance.
[02:02:04.420 --> 02:02:07.220]   So whether it's video streaming, podcasting,
[02:02:07.220 --> 02:02:09.820]   digital downloads, CashFly can do it.
[02:02:09.820 --> 02:02:11.420]   By the way, they've partnered,
[02:02:11.420 --> 02:02:12.380]   they're a good company too.
[02:02:12.380 --> 02:02:13.300]   I really love these guys.
[02:02:13.300 --> 02:02:15.500]   They've partnered with World Central Kitchen.
[02:02:15.500 --> 02:02:17.460]   They've donated now over $50,000.
[02:02:17.460 --> 02:02:20.020]   They're gold to serve 300,000 warm meals
[02:02:20.020 --> 02:02:21.220]   to those who are struggling.
[02:02:21.220 --> 02:02:23.820]   They're good people, and it's a great company.
[02:02:23.820 --> 02:02:26.220]   And if you serve content over the internet,
[02:02:26.220 --> 02:02:28.420]   I want you to find out how CashFly can help.
[02:02:28.420 --> 02:02:31.180]   They're giving away a complimentary detail analysis
[02:02:31.180 --> 02:02:34.020]   of your current CDN bill and usage trends.
[02:02:34.020 --> 02:02:36.900]   You may be paying, overpaying by as much as 20%,
[02:02:36.900 --> 02:02:40.020]   plus not getting the service you deserve,
[02:02:40.020 --> 02:02:42.940]   go to twit.cash fly.com and find out.
[02:02:42.940 --> 02:02:47.020]   twit.cash fly.com.
[02:02:47.020 --> 02:02:49.420]   Thank you, CashFly, for making this possible.
[02:02:49.420 --> 02:02:50.580]   We really appreciate it.
[02:02:50.580 --> 02:02:54.220]   twit.cash fly.com.
[02:02:54.220 --> 02:02:57.580]   I should add Roblox is another really interesting gaming
[02:02:57.580 --> 02:02:59.340]   phenomenon we started talking about,
[02:02:59.340 --> 02:03:03.780]   the show about among us and animal crossing.
[02:03:03.780 --> 02:03:06.940]   Roblox is, I mean, with the young people,
[02:03:06.940 --> 02:03:08.180]   it's kind of amazing.
[02:03:09.420 --> 02:03:12.860]   But technically, not impressive game,
[02:03:12.860 --> 02:03:14.940]   but they get that content,
[02:03:14.940 --> 02:03:16.660]   and it's just one of those things
[02:03:16.660 --> 02:03:20.220]   where they caught an audience in turnout content,
[02:03:20.220 --> 02:03:23.540]   and they're making literally billions of dollars.
[02:03:23.540 --> 02:03:24.380]   Yeah.
[02:03:24.380 --> 02:03:26.500]   So tell us about the Stadia.
[02:03:26.500 --> 02:03:29.340]   Oh my God, this was, you know,
[02:03:29.340 --> 02:03:32.220]   like most times when you've read about gamers in the news,
[02:03:32.220 --> 02:03:37.220]   it's like, oh no, they went after some sexist scandal
[02:03:37.220 --> 02:03:38.780]   or something like this.
[02:03:38.780 --> 02:03:40.860]   This is actually heartwarming,
[02:03:40.860 --> 02:03:45.020]   that some developer for Stadia decides to go on Twitter
[02:03:45.020 --> 02:03:46.980]   and start popping off, and he's like,
[02:03:46.980 --> 02:03:51.500]   you know what, I think streamers need to actually
[02:03:51.500 --> 02:03:55.940]   start paying the companies for the games they're streaming.
[02:03:55.940 --> 02:03:57.780]   I think they need to pay money.
[02:03:57.780 --> 02:03:59.180]   You mean streamers on Twitch,
[02:03:59.180 --> 02:04:02.140]   like if I'm streaming a Minecraft session,
[02:04:02.140 --> 02:04:03.900]   I should pay Mojang.
[02:04:03.900 --> 02:04:06.100]   You should be cutting down the check exactly.
[02:04:06.100 --> 02:04:08.740]   Just like I pay for the music that I'm playing in the back.
[02:04:08.740 --> 02:04:10.980]   Or Activision, right?
[02:04:10.980 --> 02:04:14.900]   And I got to tell you, a gaming community is usually toxic,
[02:04:14.900 --> 02:04:19.900]   but feminist gamers, gay gamers, right-wing gamers,
[02:04:19.900 --> 02:04:24.220]   game journalists, all of us came together in a glorious song
[02:04:24.220 --> 02:04:27.620]   and went after the Twitter main character of the day
[02:04:27.620 --> 02:04:30.380]   and really, really critiqued this person
[02:04:30.380 --> 02:04:32.820]   to the point where floundering Stadia,
[02:04:32.820 --> 02:04:35.820]   he actually took it out of his bio,
[02:04:35.820 --> 02:04:38.580]   the fact that he was a Stadia developer.
[02:04:38.580 --> 02:04:41.700]   Because Stadia doesn't need any more problems.
[02:04:41.700 --> 02:04:44.740]   - Why did he think they should pay?
[02:04:44.740 --> 02:04:46.460]   He wanted to get paid.
[02:04:46.460 --> 02:04:48.860]   - I guess he's a game developer.
[02:04:48.860 --> 02:04:50.540]   I'm a game developer.
[02:04:50.540 --> 02:04:52.900]   You shouldn't be paying to stream games.
[02:04:52.900 --> 02:04:54.740]   Like if anything, they should be paying you
[02:04:54.740 --> 02:04:56.580]   because you're advertising.
[02:04:56.580 --> 02:04:59.700]   You know, among us, the game the AOC played,
[02:04:59.700 --> 02:05:03.420]   when it came out in 2018, it was a complete failure.
[02:05:03.420 --> 02:05:04.740]   Nobody played it.
[02:05:04.740 --> 02:05:07.620]   And then a makeup YouTuber
[02:05:07.620 --> 02:05:11.980]   started streaming it to millions of people on a whim
[02:05:11.980 --> 02:05:14.500]   and it exploded in popularity.
[02:05:14.500 --> 02:05:16.180]   - They should pay her.
[02:05:16.180 --> 02:05:18.940]   - Right, well it was a him, but yeah.
[02:05:18.940 --> 02:05:21.180]   - I'm sorry, I assumed that a makeup streamer
[02:05:21.180 --> 02:05:23.020]   on Twitch is a gal, but okay.
[02:05:23.020 --> 02:05:24.100]   - It's a brave new world.
[02:05:24.100 --> 02:05:25.580]   - It's a whole new world.
[02:05:25.580 --> 02:05:26.580]   - Yeah, come on.
[02:05:26.580 --> 02:05:30.140]   - I'm sorry, I apologize.
[02:05:30.140 --> 02:05:30.980]   - It is.
[02:05:30.980 --> 02:05:32.820]   - Actually, I do my own makeup.
[02:05:32.820 --> 02:05:35.340]   Not now, but on TV, I always did my own makeup.
[02:05:35.340 --> 02:05:36.980]   I'm very good with a contour brush.
[02:05:36.980 --> 02:05:39.260]   I don't knock that.
[02:05:39.260 --> 02:05:40.100]   - There we go.
[02:05:40.100 --> 02:05:44.500]   No, it's, I mean, streamers are how games are advertised today.
[02:05:44.500 --> 02:05:46.700]   So it was just absolutely ridiculous.
[02:05:46.700 --> 02:05:49.380]   - He, it was, we might as well say,
[02:05:49.380 --> 02:05:51.220]   Alex Hutchinson of Bang Bang,
[02:05:51.220 --> 02:05:54.860]   Bang Bang Click of the Montreal studio.
[02:05:54.860 --> 02:05:55.700]   - My hometown.
[02:05:55.700 --> 02:05:56.540]   - Yeah, more.
[02:05:56.540 --> 02:05:58.780]   (laughs)
[02:05:58.780 --> 02:06:01.380]   - Yeah, I think that's okay.
[02:06:01.380 --> 02:06:03.380]   You know what, this is where social media,
[02:06:03.380 --> 02:06:05.340]   evened it out, he had an idea.
[02:06:05.340 --> 02:06:07.180]   He posted a tweets term.
[02:06:07.180 --> 02:06:09.540]   I don't understand why people who wanna,
[02:06:09.540 --> 02:06:11.500]   they get a freaking blog.
[02:06:11.500 --> 02:06:14.680]   Why are you making me read 25 tweets?
[02:06:14.680 --> 02:06:16.500]   Anyway.
[02:06:16.500 --> 02:06:17.740]   - Too much work to have a blog.
[02:06:17.740 --> 02:06:19.220]   - Is that it?
[02:06:19.220 --> 02:06:21.700]   - Yes, pretty much, or too lazy.
[02:06:21.700 --> 02:06:23.620]   - Writing is hard.
[02:06:23.620 --> 02:06:24.660]   - But you're still writing it,
[02:06:24.660 --> 02:06:26.900]   you're just spreading it out over--
[02:06:26.900 --> 02:06:28.060]   - No, it's social.
[02:06:28.060 --> 02:06:30.180]   It's like something that easily can get picked up
[02:06:30.180 --> 02:06:31.460]   and reacted to.
[02:06:31.460 --> 02:06:32.820]   - Yeah, exactly.
[02:06:33.740 --> 02:06:37.300]   - Okay, anyway, it was probably the right thing to do
[02:06:37.300 --> 02:06:39.980]   because it got the conversation rolling, where else?
[02:06:39.980 --> 02:06:43.220]   But Twitter and Google eventually said,
[02:06:43.220 --> 02:06:45.460]   "We don't think this.
[02:06:45.460 --> 02:06:48.420]   Pay no attention, Alex."
[02:06:48.420 --> 02:06:53.580]   It does not reflect the views of Stadia, YouTube, or Google.
[02:06:53.580 --> 02:06:54.420]   No.
[02:06:54.420 --> 02:06:56.660]   - I just think it's funny.
[02:06:56.660 --> 02:06:59.740]   You've got like, maybe, maybe if you're being generous,
[02:06:59.740 --> 02:07:03.620]   a few thousand young people, they've figured out a way
[02:07:03.620 --> 02:07:05.780]   to pay their rent streaming games.
[02:07:05.780 --> 02:07:07.420]   And the conversation like,
[02:07:07.420 --> 02:07:11.380]   yeah, have you thought about $5 billion a year Activision?
[02:07:11.380 --> 02:07:13.380]   Have you thought of maybe you're stealing something
[02:07:13.380 --> 02:07:14.300]   from them?
[02:07:14.300 --> 02:07:15.940]   It's just a ridiculous statement.
[02:07:15.940 --> 02:07:18.300]   - Well, you know where you're stealing it from.
[02:07:18.300 --> 02:07:21.020]   And I used to know these guys back in the day.
[02:07:21.020 --> 02:07:24.860]   There was a pretty good gig to write those $25 books
[02:07:24.860 --> 02:07:27.460]   on how to play, how to beat a game, right?
[02:07:27.460 --> 02:07:29.340]   That was a booming market.
[02:07:29.340 --> 02:07:30.500]   You don't need that anymore.
[02:07:30.500 --> 02:07:33.580]   Just get a YouTube video or watch a Twitch streamer.
[02:07:33.580 --> 02:07:34.620]   - I've missed those books.
[02:07:34.620 --> 02:07:35.620]   That's were great.
[02:07:35.620 --> 02:07:36.460]   - Really?
[02:07:36.460 --> 02:07:37.300]   - I have a bunch of, oh yeah.
[02:07:37.300 --> 02:07:38.140]   - Should we bring them back?
[02:07:38.140 --> 02:07:38.980]   You have them right there?
[02:07:38.980 --> 02:07:41.180]   - I have a whole ton of them right there, yeah.
[02:07:41.180 --> 02:07:43.100]   - And they were, the production was nice
[02:07:43.100 --> 02:07:46.180]   'cause you have the, it's all the game and everything.
[02:07:46.180 --> 02:07:47.580]   - Yeah, all the art.
[02:07:47.580 --> 02:07:48.380]   - All the art.
[02:07:48.380 --> 02:07:50.740]   Okay, so he was wrong.
[02:07:50.740 --> 02:07:54.420]   Which is it?
[02:07:54.420 --> 02:07:59.420]   What is it gonna be Xbox, sex, or PlayStation 5?
[02:08:02.580 --> 02:08:03.500]   - I got both.
[02:08:03.500 --> 02:08:04.780]   I don't have an opinion.
[02:08:04.780 --> 02:08:05.740]   - Why should one?
[02:08:05.740 --> 02:08:06.580]   Why should one?
[02:08:06.580 --> 02:08:08.220]   - Maybe Xbox is called six or sex.
[02:08:08.220 --> 02:08:10.820]   - Series X, but I abbreviated it to sex.
[02:08:10.820 --> 02:08:11.980]   Because sex is better.
[02:08:11.980 --> 02:08:14.460]   - I was like so confused, sorry.
[02:08:14.460 --> 02:08:15.300]   I mean, I don't know if it was--
[02:08:15.300 --> 02:08:17.340]   - Is it Xbox, sex, or PlayStation sex?
[02:08:17.340 --> 02:08:18.820]   Which is it?
[02:08:18.820 --> 02:08:21.940]   No, it's the Xbox Series X.
[02:08:21.940 --> 02:08:23.460]   - Terrible name, by the way.
[02:08:23.460 --> 02:08:24.580]   Terrible name.
[02:08:24.580 --> 02:08:26.620]   - In fact, we already know it's a terrible name
[02:08:26.620 --> 02:08:29.340]   'cause there's more than a few fathers, not me,
[02:08:29.340 --> 02:08:32.420]   but more than a few fathers who bought a Xbox
[02:08:32.420 --> 02:08:36.300]   One X thinking it was the Series X.
[02:08:36.300 --> 02:08:38.220]   And they're gonna have some
[02:08:38.220 --> 02:08:40.620]   greatest point of children Christmas day
[02:08:40.620 --> 02:08:43.620]   when they hop in and say, "Dad, you bought me the old one?"
[02:08:43.620 --> 02:08:45.880]   (laughing)
[02:08:45.880 --> 02:08:48.540]   Which is it, Heather?
[02:08:48.540 --> 02:08:50.760]   PlayStation 5 or Series X?
[02:08:50.760 --> 02:08:52.620]   You couldn't care.
[02:08:52.620 --> 02:08:54.420]   - I mean, if I had time to play any games,
[02:08:54.420 --> 02:08:57.620]   I would know, but I haven't played games in my 10 years.
[02:08:57.620 --> 02:08:59.060]   - Are your kids really little?
[02:09:00.260 --> 02:09:01.820]   - I mean, the oldest one is six.
[02:09:01.820 --> 02:09:04.620]   You can play one game on the Nintendo Switch,
[02:09:04.620 --> 02:09:06.820]   which is why I've never played a game on there.
[02:09:06.820 --> 02:09:08.820]   - Yeah, he'll never give it up.
[02:09:08.820 --> 02:09:10.220]   Take it from me.
[02:09:10.220 --> 02:09:12.620]   Kids 18 now, I still haven't seen the Switch.
[02:09:12.620 --> 02:09:14.900]   - Like when would it do it anyway?
[02:09:14.900 --> 02:09:17.180]   You wake up, you work, you cry a little, you go to bed.
[02:09:17.180 --> 02:09:20.700]   - That's it, that's life in the COVID era.
[02:09:20.700 --> 02:09:23.580]   - If you like Breaking Bad,
[02:09:23.580 --> 02:09:26.380]   if you like Breaking Bad or Better Call Soul,
[02:09:26.380 --> 02:09:28.220]   - I do. - Gustavo Fring.
[02:09:28.220 --> 02:09:30.060]   - Oh, I love him. - He's a new villain
[02:09:30.060 --> 02:09:33.180]   in Far Cry 6, which is gonna be one of the big releases
[02:09:33.180 --> 02:09:36.300]   for PlayStation and Xbox, this generation.
[02:09:36.300 --> 02:09:38.660]   And I think it's gonna be an amazing game.
[02:09:38.660 --> 02:09:40.580]   I'm really psyched for that.
[02:09:40.580 --> 02:09:41.580]   - You're not all about, though.
[02:09:41.580 --> 02:09:44.300]   What is it, Cyberpunk 2077?
[02:09:44.300 --> 02:09:47.500]   - I'm gonna play that too, but, you know, Far Cry,
[02:09:47.500 --> 02:09:49.980]   that's my jam, that's my emotional life.
[02:09:49.980 --> 02:09:51.260]   - Far Cry is beautiful.
[02:09:51.260 --> 02:09:52.660]   - Yeah, oh, I love that game.
[02:09:52.660 --> 02:09:54.380]   - I mean, I haven't played the most recent ones,
[02:09:54.380 --> 02:09:56.380]   but it's like you're on a tropical island,
[02:09:56.380 --> 02:10:00.220]   and it's pretty, and oh, the graphics are gorgeous.
[02:10:00.220 --> 02:10:02.100]   You don't have to actually play a game,
[02:10:02.100 --> 02:10:03.900]   just wander around.
[02:10:03.900 --> 02:10:06.220]   It's an open space, I love it.
[02:10:06.220 --> 02:10:11.820]   Okay, I'm sorry, I'm going to go to the fantastic.
[02:10:11.820 --> 02:10:15.860]   Hey, good news, Edward Snowden's gonna get to stay in Russia.
[02:10:15.860 --> 02:10:21.020]   He doesn't look too happy about it, actually, he looks kind of--
[02:10:21.020 --> 02:10:22.660]   (laughing)
[02:10:22.660 --> 02:10:23.700]   - Pretend you're happy.
[02:10:23.700 --> 02:10:25.540]   - Looks good at home.
[02:10:25.540 --> 02:10:30.060]   He just got permanent residency in the--
[02:10:30.060 --> 02:10:33.020]   I wanna say the Soviet Union, that just--
[02:10:33.020 --> 02:10:33.860]   - Oh, wow.
[02:10:33.860 --> 02:10:35.700]   - But look how happy he is.
[02:10:35.700 --> 02:10:38.980]   Now I get to have potato soup every day.
[02:10:38.980 --> 02:10:42.180]   Just doesn't seem happy about it.
[02:10:42.180 --> 02:10:45.420]   - Oh, I wish we could find a way to just pardon him
[02:10:45.420 --> 02:10:46.700]   and bring him home.
[02:10:46.700 --> 02:10:49.580]   - Well, then you should cast your vote for President Trump.
[02:10:49.580 --> 02:10:52.340]   - I'm not gonna be doing that.
[02:10:52.340 --> 02:10:54.060]   - You're not a single issue voter, huh?
[02:10:54.060 --> 02:10:55.140]   - I am not.
[02:10:55.140 --> 02:10:56.580]   - I don't know if he was serious.
[02:10:56.580 --> 02:10:58.100]   He said he was thinking about it.
[02:10:58.100 --> 02:10:59.580]   He was thinking about it.
[02:10:59.580 --> 02:11:03.420]   I think, you know what, if Obama did it,
[02:11:03.420 --> 02:11:05.580]   he's thinking about undoing it.
[02:11:05.580 --> 02:11:06.820]   That's really the real.
[02:11:06.820 --> 02:11:07.980]   - Yeah. - Yeah.
[02:11:07.980 --> 02:11:10.100]   I'm just looking at everything he did.
[02:11:10.100 --> 02:11:13.100]   He said it in August and nothing's happened, so.
[02:11:13.100 --> 02:11:19.540]   All right, that was my big bang story to wrap things up.
[02:11:19.540 --> 02:11:23.220]   Can I leave anything out?
[02:11:23.220 --> 02:11:25.300]   Oh, I did leave this out.
[02:11:25.300 --> 02:11:30.300]   There is a bot that orders $18,752 worth of max Sundays
[02:11:30.300 --> 02:11:37.980]   every half hour to see if they're broken
[02:11:37.980 --> 02:11:40.700]   the McFlurry machines.
[02:11:40.700 --> 02:11:43.020]   And you, and what?
[02:11:43.020 --> 02:11:46.620]   You go to mikbroken, mcbroken.com.
[02:11:46.620 --> 02:11:48.380]   You can see that because I guess,
[02:11:48.380 --> 02:11:51.580]   I didn't know this not being a McFlurry lover,
[02:11:51.580 --> 02:11:54.420]   that McFlurry machines break a lot.
[02:11:54.420 --> 02:11:55.260]   - Yeah, thank you.
[02:11:55.260 --> 02:11:56.380]   - So, you see?
[02:11:56.380 --> 02:11:59.300]   So before you head out, you might wanna know
[02:11:59.300 --> 02:12:03.860]   that the McFlurry machine in Roanert Park on Redwood Drive
[02:12:03.860 --> 02:12:05.060]   is still broken.
[02:12:05.060 --> 02:12:06.420]   It's been broken all day.
[02:12:06.420 --> 02:12:07.780]   I've been checking.
[02:12:07.780 --> 02:12:08.620]   - Any sense?
[02:12:08.620 --> 02:12:11.020]   - Yeah, but good news, the McFlurry machine
[02:12:11.020 --> 02:12:13.980]   just down the road in Petaluma is working.
[02:12:13.980 --> 02:12:16.420]   This, apparently this guy wrote a bot.
[02:12:16.420 --> 02:12:18.500]   - It's amazing.
[02:12:18.500 --> 02:12:20.460]   - To order McFlurry's,
[02:12:21.300 --> 02:12:25.180]   like I don't know how you can order them and not buy them.
[02:12:25.180 --> 02:12:30.420]   But apparently you can order online and,
[02:12:30.420 --> 02:12:34.300]   oh, if it's broken, you can't order it.
[02:12:34.300 --> 02:12:36.900]   Rasheek Zahi decided it's better to know
[02:12:36.900 --> 02:12:39.660]   if the ice cream machine is broken before you go.
[02:12:39.660 --> 02:12:43.860]   Thus was born McFlurry, which maps out all the McDonald's
[02:12:43.860 --> 02:12:47.020]   near you with a simple color-coded dot system.
[02:12:47.020 --> 02:12:50.100]   I reversed, so here's how he did it.
[02:12:50.100 --> 02:12:51.980]   Now this you gotta admire this guy.
[02:12:51.980 --> 02:12:54.340]   This is Kate Cox writing in ours, Technica.
[02:12:54.340 --> 02:12:59.340]   He says, "I reverse engineered McDonald's internal ordering API
[02:12:59.340 --> 02:13:05.420]   "and I'm currently placing an order worth $18,752 every minute
[02:13:05.420 --> 02:13:07.100]   "at every McDonald's in the US
[02:13:07.100 --> 02:13:10.380]   "to figure out which locations have a broken machine."
[02:13:10.380 --> 02:13:13.060]   Now I don't know, I hope these McFlurry machines
[02:13:13.060 --> 02:13:18.260]   aren't spinning up to make unconsumed McFlurry's
[02:13:18.260 --> 02:13:19.180]   all over the country.
[02:13:19.180 --> 02:13:21.260]   That seems like I'm a flurry waste.
[02:13:21.260 --> 02:13:24.220]   He's actually from Germany.
[02:13:24.220 --> 02:13:28.180]   - I hope this means that McFlurry machines
[02:13:28.180 --> 02:13:29.660]   are connected to the internet,
[02:13:29.660 --> 02:13:32.220]   meaning that could potentially be Skynet.
[02:13:32.220 --> 02:13:33.860]   That could be where it all starts.
[02:13:33.860 --> 02:13:36.500]   (laughs)
[02:13:36.500 --> 02:13:38.540]   - He adds them to the cart every 30 minutes,
[02:13:38.540 --> 02:13:41.060]   but he doesn't, I guess, check out.
[02:13:41.060 --> 02:13:44.580]   And if it says, "No, I can't add it to the cart,"
[02:13:44.580 --> 02:13:48.060]   this is not apparently the first time a customer
[02:13:48.060 --> 02:13:50.300]   just tried to develop a technological workaround
[02:13:50.300 --> 02:13:52.500]   to McDonald's corporate failings.
[02:13:52.500 --> 02:13:57.500]   In 2017, Raina McCloud created an app to track
[02:13:57.500 --> 02:14:00.140]   if the McDonald's ice cream machines were working.
[02:14:00.140 --> 02:14:04.340]   - Are they, McDonald's has more failings than that.
[02:14:04.340 --> 02:14:06.020]   - You think it's just those two?
[02:14:06.020 --> 02:14:08.620]   It's just those two anyway.
[02:14:08.620 --> 02:14:11.780]   Never, just want you to know, you never have to suffer
[02:14:11.780 --> 02:14:15.780]   a wasted trip to Mickey D's ever again.
[02:14:15.780 --> 02:14:20.780]   Check McBroken.com to see if the ice cream machine
[02:14:20.780 --> 02:14:23.100]   in your neighborhood is broken.
[02:14:23.100 --> 02:14:25.860]   I don't know about you, but I'm loving it.
[02:14:25.860 --> 02:14:29.700]   That ends the show.
[02:14:29.700 --> 02:14:34.100]   Shira, you wonderful person, you plug away.
[02:14:34.100 --> 02:14:36.180]   Tell us everything you're, by the way,
[02:14:36.180 --> 02:14:41.180]   I see a, geez, that the new Siri mini behind you.
[02:14:41.180 --> 02:14:44.140]   - No, this is essential oils.
[02:14:44.140 --> 02:14:46.860]   - Oh yeah, that looks a lot like an essential oils machine
[02:14:46.860 --> 02:14:47.980]   actually, yeah.
[02:14:47.980 --> 02:14:48.820]   - Young living.
[02:14:48.820 --> 02:14:50.060]   - Young living.
[02:14:50.060 --> 02:14:53.740]   - Anyway, yes, you can listen to me weekdays on channel Q.
[02:14:53.740 --> 02:14:56.580]   We stream live on the radio.com app and on the radio,
[02:14:56.580 --> 02:14:59.260]   but to make it easier, just go to radio.com apps
[02:14:59.260 --> 02:15:01.420]   or channel Q or we are channel Q.com.
[02:15:01.420 --> 02:15:03.460]   My show is called Let's Go There,
[02:15:03.460 --> 02:15:05.740]   four to seven PM Pacific, seven to 10 PM Pacific.
[02:15:05.740 --> 02:15:09.020]   - Do you actually go through every single show?
[02:15:09.020 --> 02:15:11.500]   - No, we were recording right now during COVID,
[02:15:11.500 --> 02:15:14.100]   just from our home, but typically we do go to this,
[02:15:14.100 --> 02:15:17.620]   same station, like we're on the same floor
[02:15:17.620 --> 02:15:19.140]   as a lot of big LA.
[02:15:19.140 --> 02:15:20.540]   - So when you say let's go there,
[02:15:20.540 --> 02:15:23.060]   you mean just let's go to the station and do the show now.
[02:15:23.060 --> 02:15:24.460]   - If my show's called, let's go there.
[02:15:24.460 --> 02:15:27.460]   - Yeah, but I'm saying, is that what you mean?
[02:15:27.460 --> 02:15:28.620]   Let's just go to the show.
[02:15:28.620 --> 02:15:30.700]   - Because you're after a new and drive show, get it?
[02:15:30.700 --> 02:15:32.580]   - Oh, let's go there.
[02:15:32.580 --> 02:15:33.420]   - Let's go there.
[02:15:33.420 --> 02:15:34.500]   - I thought I meant you would have--
[02:15:34.500 --> 02:15:35.980]   - We go there on topics.
[02:15:35.980 --> 02:15:37.180]   - Heavy topics.
[02:15:37.180 --> 02:15:38.020]   - From the non-current events.
[02:15:38.020 --> 02:15:38.860]   - Heavy discussions.
[02:15:38.860 --> 02:15:39.700]   - The top culture.
[02:15:39.700 --> 02:15:41.100]   - Yeah, about things nobody wants to talk about
[02:15:41.100 --> 02:15:43.140]   what you are gonna go there.
[02:15:43.140 --> 02:15:44.940]   - Of course, exactly.
[02:15:44.940 --> 02:15:47.380]   And then, peace inside live,
[02:15:47.380 --> 02:15:49.820]   wanna get some mindfulness meditation movement,
[02:15:49.820 --> 02:15:53.540]   need some community, are you feeling lonely?
[02:15:53.540 --> 02:15:55.500]   Do you want some inner peace and inner happiness?
[02:15:55.500 --> 02:15:57.660]   Go to peaceinside.live.
[02:15:57.660 --> 02:15:59.980]   We have a donation based Zoom classes daily
[02:15:59.980 --> 02:16:02.060]   with really cool facilitators.
[02:16:02.060 --> 02:16:03.140]   You might learn something.
[02:16:03.140 --> 02:16:06.180]   - It's cool, it's meditation, it's yoga,
[02:16:06.180 --> 02:16:09.100]   it's Tibetan bells, it's all that stuff.
[02:16:09.100 --> 02:16:09.940]   - It's all that stuff.
[02:16:09.940 --> 02:16:10.780]   - That's the work you do.
[02:16:10.780 --> 02:16:11.620]   - Yep.
[02:16:11.620 --> 02:16:13.180]   - What are our classes to see our classes to see you?
[02:16:13.180 --> 02:16:14.340]   - Nice.
[02:16:14.340 --> 02:16:15.180]   - Anyway.
[02:16:15.180 --> 02:16:16.900]   - Sheer is wonderful to see you.
[02:16:16.900 --> 02:16:17.740]   - Appreciated.
[02:16:17.740 --> 02:16:20.900]   - Your Instagram is keeping me centered and on track.
[02:16:20.900 --> 02:16:21.820]   - Oh, wow.
[02:16:21.820 --> 02:16:23.820]   - Yeah, I look at it and I go, yeah, I feel good.
[02:16:23.820 --> 02:16:24.660]   I feel good, I'm okay.
[02:16:24.660 --> 02:16:26.380]   - I'm good, that's what I'm doing.
[02:16:26.380 --> 02:16:27.220]   - That's what you're doing.
[02:16:27.220 --> 02:16:28.420]   - Instagram, then.
[02:16:28.420 --> 02:16:29.260]   - You're good.
[02:16:29.260 --> 02:16:30.860]   - Yeah, you're good, no, that's awesome.
[02:16:30.860 --> 02:16:31.700]   Thank you.
[02:16:31.700 --> 02:16:34.860]   Thank you so much, Heather, for being here.
[02:16:34.860 --> 02:16:36.860]   I hope it wasn't too awful.
[02:16:36.860 --> 02:16:39.700]   - No, it was good, I'm glad to be here.
[02:16:39.700 --> 02:16:41.020]   - Yeah, you don't have to say that, it's okay.
[02:16:41.020 --> 02:16:45.180]   Heather Kelly covers tech for the Washington Post.
[02:16:45.180 --> 02:16:47.500]   Really, we appreciate it.
[02:16:47.500 --> 02:16:50.340]   And I'm glad the kids are, I think they're safe.
[02:16:50.340 --> 02:16:53.140]   Johnny, you still have them in the kitchen.
[02:16:53.140 --> 02:16:53.980]   - They're fine.
[02:16:53.980 --> 02:16:55.380]   - Yeah, we gave them chips.
[02:16:55.380 --> 02:16:56.220]   - See them.
[02:16:56.220 --> 02:16:57.060]   - Yeah.
[02:16:57.060 --> 02:16:57.900]   - That's okay.
[02:16:57.900 --> 02:16:59.060]   - That'll be great.
[02:16:59.060 --> 02:17:00.540]   - How many kids is there?
[02:17:00.540 --> 02:17:02.380]   - Like eight.
[02:17:02.380 --> 02:17:03.380]   - Yeah. - Nine, two?
[02:17:03.380 --> 02:17:05.100]   - Nine, two, 100.
[02:17:05.100 --> 02:17:08.460]   Anyway, thank you Heather, it's really nice to meet you.
[02:17:08.460 --> 02:17:10.540]   Thank you for being here.
[02:17:10.540 --> 02:17:11.740]   Oh, do you wanna plug anything?
[02:17:11.740 --> 02:17:14.060]   I should offer you that chance.
[02:17:14.060 --> 02:17:16.460]   - I mean, I love that these ladies have so much going on
[02:17:16.460 --> 02:17:18.060]   'cause I don't, I just do one thing.
[02:17:18.060 --> 02:17:21.740]   - Oh, you do, you just have like a really good full-time job, so.
[02:17:21.740 --> 02:17:22.580]   - Yeah, that's the problem.
[02:17:22.580 --> 02:17:25.260]   - Yeah, I do the full-time job and then I stop
[02:17:25.260 --> 02:17:26.300]   and then I do it again.
[02:17:26.300 --> 02:17:27.140]   - That's awesome.
[02:17:27.140 --> 02:17:29.940]   - I have no hobbies, no side projects, no hopes, no dreams.
[02:17:29.940 --> 02:17:31.500]   Just.
[02:17:31.500 --> 02:17:33.420]   - You got two kids, believe me.
[02:17:33.420 --> 02:17:34.260]   - I love it.
[02:17:34.260 --> 02:17:35.100]   - Everything else.
[02:17:35.100 --> 02:17:37.460]   - Yeah, you have a family, I'm single and I'm childless.
[02:17:37.460 --> 02:17:40.060]   - Yeah, then you have time, that's who has time.
[02:17:41.020 --> 02:17:43.300]   - Yeah, if you got kids, you don't got time.
[02:17:43.300 --> 02:17:44.260]   You got kids.
[02:17:44.260 --> 02:17:47.820]   Do they like McFlurries 'cause I know,
[02:17:47.820 --> 02:17:49.340]   I know where you can get one.
[02:17:49.340 --> 02:17:51.260]   - They don't know they exist yet.
[02:17:51.260 --> 02:17:54.100]   - That's good, don't let them know that, that's bad.
[02:17:54.100 --> 02:17:54.940]   As soon as they know.
[02:17:54.940 --> 02:17:56.260]   - They're so good, I don't even know what's in there,
[02:17:56.260 --> 02:17:57.380]   but they're fantastic.
[02:17:57.380 --> 02:17:58.860]   (laughs)
[02:17:58.860 --> 02:18:00.620]   - That's good, you don't wanna know.
[02:18:00.620 --> 02:18:04.780]   And thank you so much, once again, Brianna Wu.
[02:18:04.780 --> 02:18:07.660]   I'm finally, we can hear about Rebellion Pack.
[02:18:07.660 --> 02:18:09.620]   I'm so excited. - Yes.
[02:18:09.620 --> 02:18:11.380]   - Do you want money?
[02:18:11.380 --> 02:18:14.820]   - We're super packed, we're trying to win this election.
[02:18:14.820 --> 02:18:16.380]   Of course we want money.
[02:18:16.380 --> 02:18:19.060]   If you wanna support, look, I wanna tell you what we're doing.
[02:18:19.060 --> 02:18:22.980]   We are, right now we're doing a huge ad buy in Florida.
[02:18:22.980 --> 02:18:25.100]   Florida, the way we're looking at it
[02:18:25.100 --> 02:18:28.300]   has 52% chance to go for Biden.
[02:18:28.300 --> 02:18:30.060]   So we're looking at that, we're saying
[02:18:30.060 --> 02:18:32.220]   that is worth our ad dollars.
[02:18:32.220 --> 02:18:34.140]   So we're putting a really big ad buy there.
[02:18:34.140 --> 02:18:36.980]   - So why did you buy an ad in Nebraska then?
[02:18:36.980 --> 02:18:38.820]   - Well, because of Canada, we like a lot,
[02:18:38.820 --> 02:18:41.940]   Kerry Easton is there. - Ah, a local care, okay.
[02:18:41.940 --> 02:18:45.700]   - Well, she's has a 48% chance
[02:18:45.700 --> 02:18:49.020]   of beating a Republican incumbent,
[02:18:49.020 --> 02:18:50.900]   who's there with a 52% chance.
[02:18:50.900 --> 02:18:53.820]   This is someone who vetoed COVID relief.
[02:18:53.820 --> 02:18:55.820]   And I take that personally.
[02:18:55.820 --> 02:18:57.540]   I think we should be doing more on that.
[02:18:57.540 --> 02:19:00.300]   So, but yeah, if we win Nebraska,
[02:19:00.300 --> 02:19:03.220]   we also get that electoral vote, won't hurt.
[02:19:03.220 --> 02:19:04.460]   We're looking at Michigan.
[02:19:04.460 --> 02:19:07.380]   So, we are, I'm an engineer.
[02:19:07.380 --> 02:19:10.140]   We look at these swing states and we put ads
[02:19:10.140 --> 02:19:12.100]   in places where it makes sense.
[02:19:12.100 --> 02:19:13.380]   - Smart. - Yep.
[02:19:13.380 --> 02:19:14.260]   - We love this idea.
[02:19:14.260 --> 02:19:16.260]   Was this your idea to form this?
[02:19:16.260 --> 02:19:17.820]   I know you were talking about it
[02:19:17.820 --> 02:19:21.100]   after your campaign talking about a PAC.
[02:19:21.100 --> 02:19:25.580]   - So a friend of mine, I was gonna start a technology PAC
[02:19:25.580 --> 02:19:29.580]   after I didn't win, well, after COVID.
[02:19:29.580 --> 02:19:31.660]   - You didn't lose, you withdraw that right.
[02:19:31.660 --> 02:19:33.060]   - Yeah. - Which were because of COVID
[02:19:33.060 --> 02:19:35.060]   and I concluded you can't win.
[02:19:35.060 --> 02:19:37.540]   - If you can't hold events or knock on doors,
[02:19:37.540 --> 02:19:39.660]   if you're a challenger.
[02:19:39.660 --> 02:19:41.700]   I wanted to start a PAC PAC
[02:19:41.700 --> 02:19:44.020]   and then a friend of mine came to me.
[02:19:44.020 --> 02:19:47.060]   They raised about 1.3 million.
[02:19:47.060 --> 02:19:49.540]   I raised close to a million.
[02:19:49.540 --> 02:19:51.980]   And we said if we combine our forces,
[02:19:51.980 --> 02:19:54.540]   we can really help win this election.
[02:19:54.540 --> 02:19:57.700]   So, I was looking at much better paid jobs
[02:19:57.700 --> 02:19:59.260]   in engineering at the time,
[02:19:59.260 --> 02:20:03.260]   but I decided I wanted to do what I could for this election.
[02:20:03.260 --> 02:20:04.620]   God wasn't done with me yet.
[02:20:04.620 --> 02:20:06.100]   So, that's why I did this. - Good, we're glad.
[02:20:06.100 --> 02:20:09.780]   And I was reading the code of conduct on your ethics page
[02:20:09.780 --> 02:20:11.420]   and I really like it.
[02:20:11.420 --> 02:20:13.180]   I think I'm gonna-- - We took that seriously.
[02:20:13.180 --> 02:20:14.860]   - Yeah. - I think you put a lot of effort
[02:20:14.860 --> 02:20:16.300]   into it and I'm gonna steal it. - I sure did.
[02:20:16.300 --> 02:20:17.780]   - I think it's really good. - I sure did.
[02:20:17.780 --> 02:20:19.820]   If I could plug one more thing,
[02:20:19.820 --> 02:20:23.140]   we have the opposite mindfulness classes on Zoom.
[02:20:23.140 --> 02:20:26.980]   It's Rocket, it's Relay FM's worst show.
[02:20:26.980 --> 02:20:27.820]   - What? - Many--
[02:20:27.820 --> 02:20:29.060]   - Is that your tag line?
[02:20:29.060 --> 02:20:31.820]   - We are the best worst show on Relay.
[02:20:31.820 --> 02:20:34.180]   Many of the hosts that you love here on Twitch
[02:20:34.180 --> 02:20:35.220]   are over on my show. - All of them.
[02:20:35.220 --> 02:20:38.220]   - I think Christina Warren and Simone de Rushmore
[02:20:38.220 --> 02:20:39.060]   are both there. - Yeah.
[02:20:39.060 --> 02:20:40.620]   - So, please come watch us there.
[02:20:40.620 --> 02:20:41.460]   It's a good time. - I love Christina.
[02:20:41.460 --> 02:20:43.620]   - Say what? - Christina's the best.
[02:20:43.620 --> 02:20:44.780]   - We all love her. - Yeah.
[02:20:44.780 --> 02:20:45.620]   - Yeah. - Girl.
[02:20:45.620 --> 02:20:47.980]   She was on last week. - Ridiculous time.
[02:20:47.980 --> 02:20:48.820]   - Yeah.
[02:20:48.820 --> 02:20:50.980]   And Simone was on a couple of weeks before that.
[02:20:50.980 --> 02:20:51.980]   - Yeah. - Rocket?
[02:20:51.980 --> 02:20:53.580]   - They're cannibalizing the whole rocket team.
[02:20:53.580 --> 02:20:54.420]   - No, we're not.
[02:20:54.420 --> 02:20:55.420]   We're sharing.
[02:20:55.420 --> 02:20:56.860]   It's sharing.
[02:20:56.860 --> 02:20:59.540]   It's not cannibalizing unless it's a McFlurry.
[02:20:59.540 --> 02:21:02.260]   Relay.fm/--
[02:21:02.260 --> 02:21:03.060]   No, there's no--
[02:21:03.060 --> 02:21:04.980]   No, I don't want McDonald's assuming.
[02:21:04.980 --> 02:21:07.860]   There's no people in McFlurry as far as we know.
[02:21:07.860 --> 02:21:10.740]   Relay.fm/rocket.
[02:21:10.740 --> 02:21:14.380]   Accelerated Geek Conversation and it really is good.
[02:21:14.380 --> 02:21:17.900]   Thank you everybody for being here for this week in tech.
[02:21:17.900 --> 02:21:21.340]   We do this show every week, hence the name,
[02:21:21.340 --> 02:21:23.620]   of a Sunday afternoon evening,
[02:21:23.620 --> 02:21:27.900]   about 230 Pacific, 530 Eastern, 2130 UTC.
[02:21:27.900 --> 02:21:32.980]   Actually, next week, it will be at 2030 UTC
[02:21:32.980 --> 02:21:37.980]   because we're gonna fall spring back forward.
[02:21:37.980 --> 02:21:40.940]   And so whatever that is, we're gonna do it
[02:21:40.940 --> 02:21:44.060]   and we will be at 2030 UTC.
[02:21:44.060 --> 02:21:46.620]   So just a little word of warning.
[02:21:46.620 --> 02:21:48.180]   But it'll still be weirdly enough
[02:21:48.180 --> 02:21:51.020]   230 Pacific, 530 Eastern.
[02:21:51.020 --> 02:21:53.900]   And if you wanna watch it live,
[02:21:53.900 --> 02:21:56.660]   there are live streams of audio and video available,
[02:21:56.660 --> 02:22:00.060]   variety of them at twit.tv/live.
[02:22:00.060 --> 02:22:03.860]   People watch live often like to chat live in our chat room
[02:22:03.860 --> 02:22:08.860]   as an IRC chat room, old school, very IRC.twit.tv.
[02:22:08.860 --> 02:22:13.820]   You also can get on-demand versions
[02:22:13.820 --> 02:22:17.540]   of everything we do at our website, twit.tv.
[02:22:17.540 --> 02:22:20.620]   This show included, there's also a YouTube channel
[02:22:20.620 --> 02:22:22.540]   devoted to this week in tech.
[02:22:22.540 --> 02:22:24.300]   And actually the best thing to do,
[02:22:24.300 --> 02:22:26.740]   probably we get a podcast app that you like
[02:22:26.740 --> 02:22:31.380]   and subscribe to us, where everywhere you want us to be.
[02:22:31.380 --> 02:22:33.340]   And if you subscribe, then you can download it
[02:22:33.340 --> 02:22:35.580]   and automatically, it's available.
[02:22:35.580 --> 02:22:37.380]   You don't have to worry about it.
[02:22:37.380 --> 02:22:38.620]   Thank you everybody for being here.
[02:22:38.620 --> 02:22:39.860]   Thanks to our wonderful panel.
[02:22:39.860 --> 02:22:40.860]   We'll see you next time.
[02:22:40.860 --> 02:22:41.780]   Another twit.
[02:22:41.780 --> 02:22:43.300]   - This is amazing.
[02:22:43.300 --> 02:22:45.880]   (upbeat music)
[02:22:45.880 --> 02:22:52.280]   You're on the twe, do on the tweet, alright. Do on the tweet baby, do on the tweet.
[02:22:52.280 --> 02:22:53.280]   Do a look to it.
[02:22:53.280 --> 02:22:55.360]   you

