
[00:00:00.000 --> 00:00:03.000]   [MUSIC PLAYING]
[00:00:03.000 --> 00:00:05.080]   Netcast you love.
[00:00:05.080 --> 00:00:06.440]   From people you trust.
[00:00:06.440 --> 00:00:10.280]   [MUSIC PLAYING]
[00:00:10.280 --> 00:00:12.760]   This is Twit.
[00:00:12.760 --> 00:00:16.120]   Bandwidth for this weekend tech is provided by cash fly
[00:00:16.120 --> 00:00:18.680]   at CACHEFLY.com.
[00:00:18.680 --> 00:00:22.160]   [MUSIC PLAYING]
[00:00:22.160 --> 00:00:26.720]   This is Twit, this weekend tech.
[00:00:26.720 --> 00:00:35.280]   Episode 490, recorded December 28, 2014, the best of 2014.
[00:00:35.280 --> 00:00:38.240]   This week, tech is brought to you by FreshBooks,
[00:00:38.240 --> 00:00:40.840]   the simple cloud accounting solution that helps millions
[00:00:40.840 --> 00:00:43.760]   of entrepreneurs and small business owners save time
[00:00:43.760 --> 00:00:45.800]   billing and get paid faster.
[00:00:45.800 --> 00:00:49.240]   Join over 5 million users running their business with ease.
[00:00:49.240 --> 00:00:53.480]   Try it free at freshbooks.com/twit.
[00:00:53.480 --> 00:00:55.520]   And buy Squarespace.
[00:00:55.520 --> 00:00:57.920]   Squarespace just launched their newest version
[00:00:57.920 --> 00:01:01.480]   of the platform Squarespace 7 with a completely redesigned
[00:01:01.480 --> 00:01:04.920]   interface, integrations with Getty Images and Google Apps,
[00:01:04.920 --> 00:01:08.840]   new templates, and an incredible feature called Cover Pages.
[00:01:08.840 --> 00:01:11.920]   Try the new Squarespace at squarespace.com.
[00:01:11.920 --> 00:01:16.400]   Enter the offer code TWIT at checkout to get 10% off.
[00:01:16.400 --> 00:01:18.760]   And buy Audible.com.
[00:01:18.760 --> 00:01:21.280]   Sign up for the platinum plan and get two free books.
[00:01:21.280 --> 00:01:23.960]   Go to audible.com/twit2.
[00:01:23.960 --> 00:01:27.000]   And don't forget to follow Audible on Twitter, user ID Audible
[00:01:27.000 --> 00:01:28.800]   underscore com.
[00:01:28.800 --> 00:01:31.080]   And buy personal capital.
[00:01:31.080 --> 00:01:34.400]   With personal capital, you'll have many more happy holidays
[00:01:34.400 --> 00:01:37.240]   as you grow and protect your wealth with this award-winning
[00:01:37.240 --> 00:01:38.480]   financial app.
[00:01:38.480 --> 00:01:40.320]   Best of all, it's free.
[00:01:40.320 --> 00:01:44.040]   To sign up, go to personalcapital.com/twit.
[00:01:44.040 --> 00:01:49.920]   Well, hohohohoh!
[00:01:49.920 --> 00:01:55.360]   Leo Laport here, your elf on the shelf for this year's best
[00:01:55.360 --> 00:01:56.760]   of TWIT.
[00:01:56.760 --> 00:02:00.120]   H&E every year, we take the holiday week off,
[00:02:00.120 --> 00:02:03.440]   give our staff and produce you some downtime.
[00:02:03.440 --> 00:02:05.160]   But we do make them work.
[00:02:05.160 --> 00:02:08.400]   We put together a best of episode.
[00:02:08.400 --> 00:02:12.440]   And the most difficult one is always, of course, this one,
[00:02:12.440 --> 00:02:13.240]   this week in tech.
[00:02:13.240 --> 00:02:17.280]   Because there's so many moments all year long in this week
[00:02:17.280 --> 00:02:17.640]   in tech.
[00:02:17.640 --> 00:02:21.880]   So many crazy moments, funny moments, powerful moments.
[00:02:21.880 --> 00:02:23.520]   It's hard to pick just a few.
[00:02:23.520 --> 00:02:27.160]   But I think I've got for you, thanks to you and all the people
[00:02:27.160 --> 00:02:31.960]   who suggested their favorites, some great moments from 2014.
[00:02:31.960 --> 00:02:35.280]   So get yourself a cup of hot cocoa, settle in.
[00:02:35.280 --> 00:02:37.360]   It's going to be a bumpy ride.
[00:02:37.360 --> 00:02:39.240]   Starting off with this discussion,
[00:02:39.240 --> 00:02:44.000]   watch out of "Gamergate" with Neil Iapatel, John C. Devorek,
[00:02:44.000 --> 00:02:47.320]   the sparks are about to fly.
[00:02:47.320 --> 00:02:51.480]   What's happening in "Gamergate" is a conflation of gamers,
[00:02:51.480 --> 00:02:56.280]   like original hardcore gamers who see that as their identity,
[00:02:56.280 --> 00:03:01.360]   being mad at the criticism leveled at games
[00:03:01.360 --> 00:03:04.520]   for being sexist and too violent and not including women
[00:03:04.520 --> 00:03:08.400]   and being targeted at white men, being mad at that criticism,
[00:03:08.400 --> 00:03:11.080]   and then targeting their anger at that criticism
[00:03:11.080 --> 00:03:15.640]   towards the older problem of graft and corruption and gaming.
[00:03:15.640 --> 00:03:19.200]   Because the reality, and this is true, the reality is,
[00:03:19.200 --> 00:03:23.680]   if I wanted to be corrupt about an independent games developer,
[00:03:23.680 --> 00:03:26.360]   like honestly, I would make no money, right?
[00:03:26.360 --> 00:03:28.760]   Like, it would not be worth it to me
[00:03:28.760 --> 00:03:31.760]   to stake my publication's credibility on that.
[00:03:31.760 --> 00:03:34.400]   And I know that, Paul Yahn, again, my sister publication,
[00:03:34.400 --> 00:03:36.440]   I know the people who work there, not worth it
[00:03:36.440 --> 00:03:38.760]   to Chris Grant, the editor-in-chief of Polygon,
[00:03:38.760 --> 00:03:41.800]   to stake his credibility, his career, his publication
[00:03:41.800 --> 00:03:43.680]   on pushing forward depression quest.
[00:03:43.680 --> 00:03:47.520]   All right, so this contention that the game press is biased
[00:03:47.520 --> 00:03:49.960]   or there's conflict, but this is probably bogus,
[00:03:49.960 --> 00:03:52.840]   but it has gone so beyond that
[00:03:52.840 --> 00:03:55.560]   that the hashtag gamer game means a whole lot more.
[00:03:55.560 --> 00:04:00.640]   And at this point, it seems to be, frankly, aimed at women.
[00:04:00.640 --> 00:04:02.480]   It is absolutely aimed at women now.
[00:04:02.480 --> 00:04:06.040]   And it is aimed at the idea that women
[00:04:06.040 --> 00:04:08.960]   who are criticizing games or people who--
[00:04:08.960 --> 00:04:12.320]   Or anything, or just standing up and saying hello.
[00:04:12.320 --> 00:04:17.320]   Or being alive, are somehow complicit in massive conspiracy
[00:04:17.320 --> 00:04:21.920]   to shut down any number of crazy arguments.
[00:04:21.920 --> 00:04:24.120]   And most of those arguments have to do with things
[00:04:24.120 --> 00:04:25.360]   like men's rights.
[00:04:25.360 --> 00:04:30.400]   Most of those arguments have to do with things like where--
[00:04:30.400 --> 00:04:34.040]   I mean, it basically boils down.
[00:04:34.040 --> 00:04:36.000]   Let me just give you a small sample of things
[00:04:36.000 --> 00:04:38.240]   that we dealt with this week at the Verge.
[00:04:38.240 --> 00:04:41.720]   We dealt with our writers being harassed on Twitter.
[00:04:41.720 --> 00:04:43.920]   We dealt with a massive harassment.
[00:04:43.920 --> 00:04:46.840]   Literally-- and I'm not kidding-- a neo-Nazi site
[00:04:46.840 --> 00:04:48.880]   writing about one of our writers' haircuts
[00:04:48.880 --> 00:04:50.560]   and saying her father should have beaten her
[00:04:50.560 --> 00:04:54.240]   with the back of her hand until her hair grew out.
[00:04:54.240 --> 00:04:56.480]   This does not have anything to do with video games.
[00:04:56.480 --> 00:04:59.160]   It just has to do with what they thought about her, right?
[00:04:59.160 --> 00:05:02.360]   And some things she'd written about race and Ebola.
[00:05:02.360 --> 00:05:04.960]   What we are dealing with is basically the idea
[00:05:04.960 --> 00:05:09.120]   that people on the internet should not have standards
[00:05:09.120 --> 00:05:10.960]   about how they talk to other people.
[00:05:10.960 --> 00:05:15.360]   And what they're doing now is game or gate is a movement,
[00:05:15.360 --> 00:05:20.080]   has decided that the way that they will further the goals
[00:05:20.080 --> 00:05:23.360]   is by attacking our advertisers, which is fair,
[00:05:23.360 --> 00:05:25.680]   because if you attack my economic interests,
[00:05:25.680 --> 00:05:27.120]   maybe I'll change my mind.
[00:05:27.120 --> 00:05:29.160]   But if your argument is that we don't have
[00:05:29.160 --> 00:05:30.520]   journalistic ethics--
[00:05:30.520 --> 00:05:32.160]   That's a conflict with this interest, isn't it?
[00:05:32.160 --> 00:05:32.680]   Maybe.
[00:05:32.680 --> 00:05:35.400]   But if your argument is that I don't have journalistic ethics,
[00:05:35.400 --> 00:05:38.920]   and then your strategy is to attack my advertisers
[00:05:38.920 --> 00:05:42.040]   until I do what they want, then you have completely
[00:05:42.040 --> 00:05:43.600]   obviated your argument.
[00:05:43.600 --> 00:05:44.600]   And that's--
[00:05:44.600 --> 00:05:47.800]   You're assuming there's any logic in this kind of trolling
[00:05:47.800 --> 00:05:48.320]   at all.
[00:05:48.320 --> 00:05:49.880]   It has nothing to do with logic.
[00:05:49.880 --> 00:05:51.200]   It's whatever you can get away with.
[00:05:51.200 --> 00:05:54.800]   I feel sorry for Brianna Wu, a game developer who has literally
[00:05:54.800 --> 00:06:00.200]   been chased from her house with horrific threats.
[00:06:00.200 --> 00:06:02.080]   The police are investigating, and I suspect
[00:06:02.080 --> 00:06:04.520]   that the nature of these threats gives the police
[00:06:04.520 --> 00:06:06.640]   a foothold in pursuing it.
[00:06:06.640 --> 00:06:08.520]   Almost always it's coming from Twitter.
[00:06:08.520 --> 00:06:12.600]   And I have to point out that Twitter has become a true cesspool.
[00:06:12.600 --> 00:06:14.560]   And one of the problems that's happening
[00:06:14.560 --> 00:06:19.320]   is that Twitter has to continue its 25% monthly growth,
[00:06:19.320 --> 00:06:21.840]   or the stock market price will tumble.
[00:06:21.840 --> 00:06:23.880]   The whole house of cards will collapse.
[00:06:23.880 --> 00:06:27.520]   So they have zero incentive to take care of this stuff
[00:06:27.520 --> 00:06:30.720]   by, say, banning IP addresses, looking up the names.
[00:06:30.720 --> 00:06:31.880]   Oh, I'm not buying it.
[00:06:31.880 --> 00:06:32.440]   Oh, no, no.
[00:06:32.440 --> 00:06:33.560]   I promise you.
[00:06:33.560 --> 00:06:35.400]   You tracked the people down that were giving you, like,
[00:06:35.400 --> 00:06:37.600]   two, three years ago, didn't you find some guy in the press?
[00:06:37.600 --> 00:06:39.440]   I would say you find somebody.
[00:06:39.440 --> 00:06:39.960]   Yeah, I did.
[00:06:39.960 --> 00:06:41.240]   It was in Chicago as a kid.
[00:06:41.240 --> 00:06:41.680]   Yeah.
[00:06:41.680 --> 00:06:45.400]   But we needed warrants, subpoenas in Petaluma and Chicago.
[00:06:45.400 --> 00:06:48.240]   We needed the cooperation of local police here in Chicago.
[00:06:48.240 --> 00:06:48.680]   But--
[00:06:48.680 --> 00:06:49.760]   You're not suffering in that?
[00:06:49.760 --> 00:06:52.160]   And that, by the way, because there's death threats here,
[00:06:52.160 --> 00:06:55.000]   this will happen with this particular situation we're not at.
[00:06:55.000 --> 00:06:56.160]   We hope so.
[00:06:56.160 --> 00:06:58.760]   Well, one hopes, because the police also seem to be--
[00:06:58.760 --> 00:07:00.640]   You have to find cooperative police.
[00:07:00.640 --> 00:07:01.600]   I saw a great tweet today.
[00:07:01.600 --> 00:07:02.600]   I don't know where it came from.
[00:07:02.600 --> 00:07:04.800]   But it was basically this.
[00:07:04.800 --> 00:07:08.440]   It was, if you torrent a movie from Warner Brothers,
[00:07:08.440 --> 00:07:09.760]   there's a good chance you'll be arrested.
[00:07:09.760 --> 00:07:11.280]   Much more likely.
[00:07:11.280 --> 00:07:13.040]   If you tell a woman on the internet
[00:07:13.040 --> 00:07:15.000]   that you will kill her or rape her,
[00:07:15.000 --> 00:07:16.120]   like Twitter will tell you there's
[00:07:16.120 --> 00:07:17.240]   something in the condition date.
[00:07:17.240 --> 00:07:22.120]   And I think DiCustolo is a nice guy, blah, blah, blah.
[00:07:22.120 --> 00:07:25.280]   But I think Twitter and its board are, at this point,
[00:07:25.280 --> 00:07:28.760]   really culpable, because they will not shut these accounts down.
[00:07:28.760 --> 00:07:29.720]   They don't make a party--
[00:07:29.720 --> 00:07:30.560]   Well, they shut down accounts all the time.
[00:07:30.560 --> 00:07:31.560]   Why don't they shut these down?
[00:07:31.560 --> 00:07:32.320]   They should create a new account.
[00:07:32.320 --> 00:07:33.320]   Well, that's the point.
[00:07:33.320 --> 00:07:34.680]   You can create a new account.
[00:07:34.680 --> 00:07:37.240]   And they don't shut it down effectively, which
[00:07:37.240 --> 00:07:38.360]   they could technologically.
[00:07:38.360 --> 00:07:39.800]   But they have no desire to do.
[00:07:39.800 --> 00:07:41.720]   In fact, they want people to create new accounts,
[00:07:41.720 --> 00:07:43.240]   because that shows their growth--
[00:07:43.240 --> 00:07:45.040]   But I would say Twitter is over much.
[00:07:45.040 --> 00:07:45.880]   I agree with you, Leo.
[00:07:45.880 --> 00:07:47.520]   I think Twitter is deeply culpable.
[00:07:47.520 --> 00:07:50.920]   I think all these platforms by which people can harass
[00:07:50.920 --> 00:07:53.160]   other people, we have to take a hard look in the mirror
[00:07:53.160 --> 00:07:55.040]   and decide, OK, well, the internet
[00:07:55.040 --> 00:07:57.720]   is interwoven into our lives.
[00:07:57.720 --> 00:07:59.360]   How should we treat each other?
[00:07:59.360 --> 00:08:01.240]   And how should we punish people for treating each other
[00:08:01.240 --> 00:08:03.480]   badly or deal with people that--
[00:08:03.480 --> 00:08:05.520]   treating each other badly in these platforms?
[00:08:05.520 --> 00:08:07.920]   Well, Twitter is a mob at this point.
[00:08:07.920 --> 00:08:09.800]   And I think men have to stand up and say,
[00:08:09.800 --> 00:08:11.280]   this is not acceptable.
[00:08:11.280 --> 00:08:12.480]   Can I ask a question here?
[00:08:12.480 --> 00:08:14.280]   Because I've been kind of triggered to start.
[00:08:14.280 --> 00:08:15.640]   I don't want to ask you.
[00:08:15.640 --> 00:08:19.360]   What specifically triggered this craziness?
[00:08:19.360 --> 00:08:21.240]   This just sounds like a non-story that just
[00:08:21.240 --> 00:08:22.840]   blew up for some unknown reason.
[00:08:22.840 --> 00:08:23.840]   I don't know what the reason is.
[00:08:23.840 --> 00:08:25.520]   It's been blown up for over three months.
[00:08:25.520 --> 00:08:26.720]   I mean, it's been built in.
[00:08:26.720 --> 00:08:29.480]   But OK, it's been three months, but what triggered it?
[00:08:29.480 --> 00:08:32.840]   In my opinion, because there has been a downward--
[00:08:32.840 --> 00:08:36.800]   really ugly downward trend of the last year or two.
[00:08:36.800 --> 00:08:38.960]   And I think primarily thanks to Twitter and the fact
[00:08:38.960 --> 00:08:41.120]   that you cannot stop this stuff on Twitter.
[00:08:41.120 --> 00:08:43.600]   You could stop it on Google+, you could stop it on Facebook,
[00:08:43.600 --> 00:08:45.000]   you cannot stop it on Twitter.
[00:08:45.000 --> 00:08:46.480]   That's where it lives.
[00:08:46.480 --> 00:08:50.840]   And I have to say that the quality of conversation
[00:08:50.840 --> 00:08:54.120]   in the general internet world is really deteriorating.
[00:08:54.120 --> 00:08:55.880]   It's always been crap.
[00:08:55.880 --> 00:08:57.520]   But I agree.
[00:08:57.520 --> 00:08:59.920]   It's never been great, but it's gotten worse and worse.
[00:08:59.920 --> 00:09:01.040]   And the ugly voices--
[00:09:01.040 --> 00:09:01.800]   How can you get it?
[00:09:01.800 --> 00:09:06.160]   For a long time, I really thought that the publicity
[00:09:06.160 --> 00:09:09.520]   would promote the ability that the ugly voices would get
[00:09:09.520 --> 00:09:10.440]   pushed out.
[00:09:10.440 --> 00:09:12.480]   And it's going in the other direction at this point.
[00:09:12.480 --> 00:09:12.800]   I have to--
[00:09:12.800 --> 00:09:14.440]   Let me answer John's question.
[00:09:14.440 --> 00:09:19.000]   Where it came from is basically two people
[00:09:19.000 --> 00:09:23.320]   and two pieces of content of media that were created.
[00:09:23.320 --> 00:09:27.080]   One is Anita Sarkeesian's Trip Sources Women on YouTube,
[00:09:27.080 --> 00:09:30.240]   where she literally just analyzed video games,
[00:09:30.240 --> 00:09:33.520]   like mass marketing video games, from a feminist perspective,
[00:09:33.520 --> 00:09:36.160]   which is her perspective, and pointed out
[00:09:36.160 --> 00:09:38.840]   that women in games are often used as sex objects
[00:09:38.840 --> 00:09:43.120]   or the male gaze, which is when the author of a piece of work
[00:09:43.120 --> 00:09:45.600]   tends to look at women the way a man would look,
[00:09:45.600 --> 00:09:46.840]   is prevalent in video games.
[00:09:46.840 --> 00:09:48.800]   And you can watch these things and you can disagree with them.
[00:09:48.800 --> 00:09:51.080]   And I disagree with some of them in the same way
[00:09:51.080 --> 00:09:52.080]   that I read Jezebel every day.
[00:09:52.080 --> 00:09:54.480]   And I disagree with Jezebel sometimes, right?
[00:09:54.480 --> 00:09:57.760]   They are topics worth discussing.
[00:09:57.760 --> 00:10:00.200]   And she presents them in a particularly strong way
[00:10:00.200 --> 00:10:01.520]   which I think is great.
[00:10:01.520 --> 00:10:03.600]   So that is a thing that exists.
[00:10:03.600 --> 00:10:06.280]   The next thing is Zoe Quinn, the variety of games
[00:10:06.280 --> 00:10:08.200]   that she's made, that have nothing
[00:10:08.200 --> 00:10:10.240]   to do with being video games, right?
[00:10:10.240 --> 00:10:11.880]   They have everything to do about telling stories
[00:10:11.880 --> 00:10:13.400]   in an interactive way.
[00:10:13.400 --> 00:10:16.640]   And the game's press took both of these things
[00:10:16.640 --> 00:10:18.640]   and thought they were interesting.
[00:10:18.640 --> 00:10:22.280]   And the game's press, I think, over the past few years--
[00:10:22.280 --> 00:10:27.840]   and again, because I work at a company that runs Polygon--
[00:10:27.840 --> 00:10:31.200]   I think Polygon's mission is to take video games
[00:10:31.200 --> 00:10:33.120]   and talk about them as their art, right?
[00:10:33.120 --> 00:10:35.640]   Like, the whole business model for Polygon
[00:10:35.640 --> 00:10:38.360]   is everybody plays video games now.
[00:10:38.360 --> 00:10:40.360]   Let's run a site for everybody.
[00:10:40.360 --> 00:10:43.000]   And so if you look at the way they talk about video games,
[00:10:43.000 --> 00:10:44.880]   they talk about them in a broad encompassing way.
[00:10:44.880 --> 00:10:46.080]   And I think that's great.
[00:10:46.080 --> 00:10:47.120]   Again, I'm biased, right?
[00:10:47.120 --> 00:10:47.880]   They're my friends.
[00:10:47.880 --> 00:10:50.920]   All I learned from that was that you read Jezebel every day.
[00:10:50.920 --> 00:10:51.920]   I do.
[00:10:51.920 --> 00:10:54.640]   Well, it's entertaining, I get to say.
[00:10:54.640 --> 00:10:56.240]   I disagree with Jezebel all the time.
[00:10:56.240 --> 00:10:58.480]   But it's interesting to me as a person who
[00:10:58.480 --> 00:10:59.560]   wants to be disagreed with.
[00:10:59.560 --> 00:11:01.360]   I'm a fucking lawyer, right?
[00:11:01.360 --> 00:11:02.720]   I like to be argument.
[00:11:02.720 --> 00:11:04.920]   So what kind of a lawyer was this?
[00:11:04.920 --> 00:11:06.960]   Well, one who apparently likes sexual intercourse, I don't.
[00:11:06.960 --> 00:11:07.760]   Oh, yes.
[00:11:07.760 --> 00:11:08.920]   So now.
[00:11:08.920 --> 00:11:09.440]   Sorry.
[00:11:09.440 --> 00:11:10.360]   All right.
[00:11:10.360 --> 00:11:11.800]   No, I just--
[00:11:11.800 --> 00:11:14.800]   I think it's going so far beyond gaming and the game
[00:11:14.800 --> 00:11:15.360]   is press.
[00:11:15.360 --> 00:11:18.720]   It's, I think, it's crazy to see the eruption of trolling
[00:11:18.720 --> 00:11:20.360]   that is appalling.
[00:11:20.360 --> 00:11:21.200]   But let me finish this.
[00:11:21.200 --> 00:11:24.280]   What you were seeing is that stuff
[00:11:24.280 --> 00:11:27.840]   compound in the gaming press started to threaten an identity,
[00:11:27.840 --> 00:11:32.240]   an identity of being a gamer, an identity of being a young person
[00:11:32.240 --> 00:11:35.400]   who maybe felt that they existed in this other subculture.
[00:11:35.400 --> 00:11:37.320]   And identity politics is something
[00:11:37.320 --> 00:11:40.160]   that our culture understands, right?
[00:11:40.160 --> 00:11:42.360]   It's something that's easy to attack other people
[00:11:42.360 --> 00:11:44.200]   for not understanding your identity.
[00:11:44.200 --> 00:11:48.680]   It's easy to attack other people for being outside your identity.
[00:11:48.680 --> 00:11:51.760]   And what has actually happened in a gamergate
[00:11:51.760 --> 00:11:56.680]   is that the language and the tactics of the culture
[00:11:56.680 --> 00:12:01.200]   war and the identity politics that are toxic to our society
[00:12:01.200 --> 00:12:03.680]   have been foisted onto video games.
[00:12:03.680 --> 00:12:06.840]   So now what we're talking about is feminism.
[00:12:06.840 --> 00:12:09.720]   Now what we're talking about is straight up,
[00:12:09.720 --> 00:12:11.400]   like, are you a gamer?
[00:12:11.400 --> 00:12:13.560]   Do you believe in what I believe in?
[00:12:13.560 --> 00:12:16.120]   And so the angry tweets I get are about things
[00:12:16.120 --> 00:12:18.360]   like you're just supplicating yourself
[00:12:18.360 --> 00:12:20.720]   to the feminist agenda when really what
[00:12:20.720 --> 00:12:22.880]   the Verge is talking about is, should women
[00:12:22.880 --> 00:12:25.280]   be better represented in video games?
[00:12:25.280 --> 00:12:27.760]   And so you can have these arguments.
[00:12:27.760 --> 00:12:29.440]   They are worth having.
[00:12:29.440 --> 00:12:31.160]   What should our art look like?
[00:12:31.160 --> 00:12:33.200]   Should our art include the category of things
[00:12:33.200 --> 00:12:34.960]   we traditionally call video games?
[00:12:34.960 --> 00:12:36.960]   I would argue that they should.
[00:12:36.960 --> 00:12:39.240]   But if you want to disagree with Roger Ebert,
[00:12:39.240 --> 00:12:42.120]   if you want to win the argument that video games should
[00:12:42.120 --> 00:12:44.360]   be considered art, you necessarily
[00:12:44.360 --> 00:12:47.160]   have to let other artists into the mix.
[00:12:47.160 --> 00:12:49.640]   You necessarily have to let other kinds of criticism
[00:12:49.640 --> 00:12:50.920]   into the mix.
[00:12:50.920 --> 00:12:54.120]   So when feminist critique Michael Bay movies,
[00:12:54.120 --> 00:12:55.960]   you don't get gamergate.
[00:12:55.960 --> 00:12:58.680]   What you get is people being like, ah, it's happening again.
[00:12:58.680 --> 00:13:00.720]   And then lots of people watching Michael Bay movies.
[00:13:00.720 --> 00:13:03.040]   When feminist critique Grand Theft Auto 5,
[00:13:03.040 --> 00:13:04.840]   what you get is gamergate.
[00:13:04.840 --> 00:13:07.120]   And that is actually the problem.
[00:13:07.120 --> 00:13:09.280]   That's the whole circle of the problem
[00:13:09.280 --> 00:13:11.840]   is that the people who believe that this is their identity
[00:13:11.840 --> 00:13:14.160]   and these publications belong to them
[00:13:14.160 --> 00:13:16.400]   are refusing to understand and they're
[00:13:16.400 --> 00:13:19.600]   refusing to accept that that circle should get wider.
[00:13:19.600 --> 00:13:22.640]   And again, I feel very strongly about this
[00:13:22.640 --> 00:13:24.440]   because it has been personally affecting
[00:13:24.440 --> 00:13:26.640]   to me over these past few weeks.
[00:13:26.640 --> 00:13:28.880]   And for my friends who work in video games journalism
[00:13:28.880 --> 00:13:30.320]   for the past three months.
[00:13:30.320 --> 00:13:33.760]   But I will tell you that this is the right side of the argument
[00:13:33.760 --> 00:13:35.600]   and there is a wrong side and the wrong side
[00:13:35.600 --> 00:13:37.880]   is being a dick to people on the internet.
[00:13:37.880 --> 00:13:39.400]   I find when you go on an airplane,
[00:13:39.400 --> 00:13:41.040]   you got some guy with these big cans on.
[00:13:41.040 --> 00:13:42.880]   I think it looks stupid.
[00:13:42.880 --> 00:13:44.320]   You're going to the airplane and some guys
[00:13:44.320 --> 00:13:46.320]   got his little phone, he's playing music.
[00:13:46.320 --> 00:13:48.600]   He's got these huge cans on his head on the--
[00:13:48.600 --> 00:13:50.080]   you one of them?
[00:13:50.080 --> 00:13:51.440]   You wearing big old--
[00:13:51.440 --> 00:13:52.440]   you two?
[00:13:52.440 --> 00:13:53.920]   -Bired in MX-D-T-80s.
[00:13:53.920 --> 00:13:56.720]   -John, I love those birodynamics.
[00:13:56.720 --> 00:13:59.480]   -Just walk away from this conversation.
[00:13:59.480 --> 00:14:01.600]   -You're sitting at the wrong table.
[00:14:01.600 --> 00:14:03.320]   -You're sitting at the wrong table for sure.
[00:14:03.320 --> 00:14:05.520]   -Just walk across the door and just open the door
[00:14:05.520 --> 00:14:06.880]   and then walk through the door and close the door
[00:14:06.880 --> 00:14:08.600]   and never look back.
[00:14:08.600 --> 00:14:11.960]   Just-- I'm telling you, this is a thing that we--
[00:14:11.960 --> 00:14:14.120]   we don't understand as people who talk about consumer
[00:14:14.120 --> 00:14:16.920]   technology because what we're actually talking about
[00:14:16.920 --> 00:14:19.080]   is fashion and personal expression.
[00:14:19.080 --> 00:14:21.760]   And those things are-- they work on different levels
[00:14:21.760 --> 00:14:22.880]   and how we assume.
[00:14:22.880 --> 00:14:26.000]   What you are saying is, I hate people who wear baggy jeans.
[00:14:26.000 --> 00:14:28.240]   What you're saying is, I hate people who wear NFL t-shirts
[00:14:28.240 --> 00:14:28.720]   to the bar.
[00:14:28.720 --> 00:14:30.240]   -That's bull-- nobody's saying that.
[00:14:30.240 --> 00:14:31.440]   -No, it is absolutely the same--
[00:14:31.440 --> 00:14:33.520]   -No, it is the same-- -No, it's not.
[00:14:33.520 --> 00:14:35.120]   -Yes, it is. -No, it's not.
[00:14:35.120 --> 00:14:36.720]   -And if you don't-- -It's actually the exact--
[00:14:36.720 --> 00:14:38.320]   -I wear noise canceling headsets.
[00:14:38.320 --> 00:14:40.600]   I just don't like these big giant cans.
[00:14:40.600 --> 00:14:42.280]   This doesn't mean I don't like baggy pants
[00:14:42.280 --> 00:14:43.520]   or I do like baggy pants.
[00:14:43.520 --> 00:14:44.720]   I resent that.
[00:14:44.720 --> 00:14:46.560]   -But no, you're saying it's the same category.
[00:14:46.560 --> 00:14:48.480]   You're wearing-- -I didn't say anything about categories.
[00:14:48.480 --> 00:14:49.760]   You're full of--
[00:14:49.760 --> 00:14:52.640]   -No, you're saying I wear this thing
[00:14:52.640 --> 00:14:54.280]   and I think those things-- -No, no, no, no, no.
[00:14:54.280 --> 00:14:55.640]   -Because they have this function.
[00:14:55.640 --> 00:14:57.440]   But these aren't-- -You're stereotyping.
[00:14:57.440 --> 00:14:59.160]   -Where are we wearing this? -I'm not stereotyping it.
[00:14:59.160 --> 00:15:00.720]   -You're stereotyping. -You're saying--
[00:15:00.720 --> 00:15:03.160]   -You are saying, I hate these people who wear cans in.
[00:15:03.160 --> 00:15:05.280]   -I never said-- I said, I don't like going in the air.
[00:15:05.280 --> 00:15:06.320]   -But wait a minute, I'm in an airplane
[00:15:06.320 --> 00:15:07.640]   and seeing how much people do big cans.
[00:15:07.640 --> 00:15:09.080]   -Do you like people who wear saggy pants?
[00:15:09.080 --> 00:15:10.080]   -Let's just think. -That's ridiculous.
[00:15:10.080 --> 00:15:11.960]   -I love saggy pants.
[00:15:12.440 --> 00:15:14.680]   -Especially on you, Leo.
[00:15:14.680 --> 00:15:15.480]   -That's all I'm saying.
[00:15:15.480 --> 00:15:20.480]   You are looking at people who are making stylistic decisions
[00:15:20.480 --> 00:15:23.040]   and fashion decisions. -So I can't say I don't like that.
[00:15:23.040 --> 00:15:25.800]   I have to agree that-- -Oh, he's making fashion decisions.
[00:15:25.800 --> 00:15:27.680]   -But what you are-- -Are you kidding me?
[00:15:27.680 --> 00:15:28.520]   -But you're making a decision.
[00:15:28.520 --> 00:15:30.160]   But the point-- I think Neilai makes a good point,
[00:15:30.160 --> 00:15:31.480]   which is-- -He's making a good point.
[00:15:31.480 --> 00:15:32.640]   He's calling me a racist.
[00:15:32.640 --> 00:15:35.600]   -No, he's not calling you anything.
[00:15:35.600 --> 00:15:37.880]   He's pointing out. -See, here's what I said.
[00:15:37.880 --> 00:15:40.600]   I said, walk through the door, close it, and don't look back.
[00:15:40.600 --> 00:15:43.600]   -He's looking at you. -Right, because I'm a racist.
[00:15:43.600 --> 00:15:46.200]   -He's looking at it. -You have a lot of nerve.
[00:15:46.200 --> 00:15:49.280]   -I do have a lot of nerve because I'm right and you're wrong.
[00:15:49.280 --> 00:15:52.200]   -Okay, exactly. -He's the argument for me to win.
[00:15:52.200 --> 00:15:54.800]   -I do think, though, that's very interesting to watch.
[00:15:54.800 --> 00:15:57.000]   Companies in Apple really is at the forefront of this.
[00:15:57.000 --> 00:15:59.360]   Technology companies realize that marketing
[00:15:59.360 --> 00:16:03.680]   is a very different business in the 2010s
[00:16:03.680 --> 00:16:07.600]   and that it isn't really about speeds and feeds, bits and bytes.
[00:16:07.600 --> 00:16:09.360]   It's about style and fashion
[00:16:09.360 --> 00:16:11.960]   and something that really has nothing to do with technology.
[00:16:11.960 --> 00:16:13.800]   Is that what you're saying, kind of, Neilai?
[00:16:13.800 --> 00:16:14.760]   -Absolutely.
[00:16:14.760 --> 00:16:18.280]   I think the technology is evaporated.
[00:16:18.280 --> 00:16:23.480]   -And John and I come from the speed and feed side of the fence.
[00:16:23.480 --> 00:16:25.240]   -Well, I mean, the problem with that means--
[00:16:25.240 --> 00:16:28.520]   -I think the challenge right now to go back to it,
[00:16:28.520 --> 00:16:31.120]   you were saying before, Neilai, is if they can't deliver.
[00:16:31.120 --> 00:16:34.760]   I mean, what, you know, Jennifer Lawrence is not going like,
[00:16:34.760 --> 00:16:36.760]   "Boy, I can't wait to use IPay."
[00:16:36.760 --> 00:16:38.160]   -That's right. -It's, you know what I mean?
[00:16:38.160 --> 00:16:39.360]   Like, there's no, that's right.
[00:16:39.360 --> 00:16:40.360]   -You know what I mean?
[00:16:40.360 --> 00:16:42.040]   Like, there's a whole lot of people that are looking at Apple
[00:16:42.040 --> 00:16:44.600]   and being like, "Okay, I downloaded iOS."
[00:16:44.600 --> 00:16:46.560]   -Hey, do you think people know that? -My phone stopped.
[00:16:46.560 --> 00:16:50.480]   -I mean, really, that's the thing that style insulates you from
[00:16:50.480 --> 00:16:52.360]   is broken, bad technology.
[00:16:52.360 --> 00:16:55.640]   I mean, nobody's asserted that beats headphones are great headphones.
[00:16:55.640 --> 00:16:59.040]   You wear them because they are beats.
[00:16:59.040 --> 00:17:01.880]   So, that's the advantage of this,
[00:17:01.880 --> 00:17:04.360]   is it insulates you a little bit from crap about technology.
[00:17:04.360 --> 00:17:06.560]   -Nobody ever bought a pair of beats
[00:17:06.560 --> 00:17:08.320]   and then two days later,
[00:17:08.320 --> 00:17:09.760]   we're not able to make a phone call
[00:17:09.760 --> 00:17:11.520]   because they updated the firmware up their beats.
[00:17:11.520 --> 00:17:13.680]   You know what I mean? Nobody took a bunch of selfies
[00:17:13.680 --> 00:17:16.400]   and then found out their selfies were showing up on the 4chan.
[00:17:16.400 --> 00:17:18.720]   Nobody's looking at beats and thinking like,
[00:17:18.720 --> 00:17:21.440]   "Gosh, can I trust my credit card here?"
[00:17:21.440 --> 00:17:23.680]   And maybe nobody who bought an iPhone 6 is thinking that,
[00:17:23.680 --> 00:17:25.120]   but I suspect a lot of people are.
[00:17:25.120 --> 00:17:28.320]   If your technology fails in a way that cuts you off
[00:17:28.320 --> 00:17:31.120]   from your friends, your family, your business,
[00:17:31.120 --> 00:17:33.600]   then it becomes, may not be speeds and feeds,
[00:17:33.600 --> 00:17:35.120]   but it's bad for the factory.
[00:17:35.120 --> 00:17:38.080]   -Nobody wants to buy a pair of beats. -You guys are way away from the real issue here.
[00:17:38.080 --> 00:17:41.040]   You know, beats are better than, absolutely better than the headphones
[00:17:41.040 --> 00:17:42.000]   that came with your phone.
[00:17:42.000 --> 00:17:43.040]   -Well, that's true. -Well, that's true.
[00:17:43.040 --> 00:17:43.280]   -They are. -Yeah.
[00:17:43.280 --> 00:17:46.400]   Without question, they are light years better than that.
[00:17:46.400 --> 00:17:47.760]   Do you know what they also do?
[00:17:47.760 --> 00:17:52.720]   They prove that you have money to spend on a fashionable, well marketed
[00:17:52.720 --> 00:17:55.760]   and quite frankly, like cool looking brand, right?
[00:17:55.760 --> 00:17:58.080]   Like, they look cool to a lot of people
[00:17:58.080 --> 00:17:59.840]   and they mean something to a lot of people.
[00:17:59.840 --> 00:18:00.960]   -But here's one thing I would bet.
[00:18:00.960 --> 00:18:03.280]   I bet Jennifer Lawrence is still using an iPhone.
[00:18:04.160 --> 00:18:05.840]   I'm sure she is.
[00:18:05.840 --> 00:18:08.640]   -I would be almost guaranteed to you that.
[00:18:08.640 --> 00:18:10.960]   She certainly wouldn't switch to Android because of this.
[00:18:10.960 --> 00:18:13.040]   -You're collapsing a lot of things here.
[00:18:13.040 --> 00:18:16.800]   What I'm saying about, like, the privacy issues of iCloud
[00:18:16.800 --> 00:18:20.800]   and cloud services and Apple versus Google are, they are deep.
[00:18:20.800 --> 00:18:22.000]   They are way deep.
[00:18:22.000 --> 00:18:23.760]   -And way too technical. -In to how people...
[00:18:23.760 --> 00:18:24.960]   They're not too technical.
[00:18:24.960 --> 00:18:25.920]   Look, here's what...
[00:18:25.920 --> 00:18:26.880]   Let me put it to you this way.
[00:18:26.880 --> 00:18:28.720]   I run a big website, right?
[00:18:28.720 --> 00:18:33.040]   30, not 1 million people a month read my website every single month.
[00:18:33.040 --> 00:18:35.680]   We do not put specs in our reviews.
[00:18:35.680 --> 00:18:39.280]   We don't put charts of performance in our reviews.
[00:18:39.280 --> 00:18:42.480]   We tell people what it's like to own this stuff and to be alive
[00:18:42.480 --> 00:18:46.480]   and to live in a culture of rapid technological change.
[00:18:46.480 --> 00:18:47.200]   -Yes. -Right?
[00:18:47.200 --> 00:18:48.080]   That's all we do.
[00:18:48.080 --> 00:18:50.000]   That's our thesis at the Verge.
[00:18:50.000 --> 00:18:51.520]   And everybody likes it, right?
[00:18:51.520 --> 00:18:53.040]   And our site is growing.
[00:18:53.040 --> 00:18:57.200]   And all that means is that we have to understand technology
[00:18:57.200 --> 00:19:00.240]   not as speeds and feeds and privacy issues
[00:19:00.240 --> 00:19:05.040]   and very granular issues about how we're coding the stuff
[00:19:05.040 --> 00:19:06.720]   and where our passwords are going.
[00:19:06.720 --> 00:19:09.920]   We have to understand it as part of everyone's lifestyle.
[00:19:09.920 --> 00:19:12.640]   And to understand technology as part of a lifestyle
[00:19:12.640 --> 00:19:15.920]   means that we have to start accepting other people's choices
[00:19:15.920 --> 00:19:18.480]   in technology. It's not being objective.
[00:19:18.480 --> 00:19:19.600]   But it's being very...
[00:19:19.600 --> 00:19:21.760]   -Yes, let's stop being objective.
[00:19:21.760 --> 00:19:23.840]   It's the most arrogant thing you've said today.
[00:19:23.840 --> 00:19:26.240]   -No. -Actually, it's not, John.
[00:19:26.240 --> 00:19:28.320]   -But it is... -It's actually like a super-conscious...
[00:19:28.320 --> 00:19:30.080]   He's the one who said to stop being objective.
[00:19:30.080 --> 00:19:32.720]   So you don't like the idea of having performance numbers
[00:19:32.720 --> 00:19:33.520]   or anything?
[00:19:33.520 --> 00:19:34.560]   Is that you, Patrick?
[00:19:34.560 --> 00:19:37.920]   -You know, it's at some point,
[00:19:37.920 --> 00:19:42.880]   unless you're buying a 4K monitor or a WQHD monitor,
[00:19:42.880 --> 00:19:44.320]   it really doesn't matter at this point
[00:19:44.320 --> 00:19:47.520]   if you're spending much more than $200 on a GPU, right?
[00:19:47.520 --> 00:19:49.120]   And a lot of the people that are watching the Verge,
[00:19:49.120 --> 00:19:51.040]   the Verge is creating an audience for people who are hungry
[00:19:51.040 --> 00:19:54.240]   for technology but are not looking for what in gadget
[00:19:54.240 --> 00:19:56.080]   or gizmodo or boy genius support
[00:19:56.080 --> 00:19:57.520]   or a lot of the traditional sites were.
[00:19:57.520 --> 00:19:59.520]   It was like, they're gonna talk about,
[00:19:59.520 --> 00:20:01.040]   "Okay, how many milliamp hours is on this?
[00:20:01.040 --> 00:20:02.160]   Is it gonna last that long?"
[00:20:02.160 --> 00:20:04.160]   What they are saying is, "Hey, we took this product,
[00:20:04.160 --> 00:20:06.560]   we went out, we tested it, and that's what it's did."
[00:20:06.560 --> 00:20:08.400]   -I'm a lot of the... -Well, how do you do that
[00:20:08.400 --> 00:20:09.760]   without some information?
[00:20:09.760 --> 00:20:12.880]   -Just pointing out, I did run in gadget for four years.
[00:20:12.880 --> 00:20:14.640]   -Yeah. -I have been in that crowd.
[00:20:14.640 --> 00:20:17.200]   -You've got the jobs. -And you don't like that anymore.
[00:20:17.200 --> 00:20:17.840]   -No, no, but wait a minute.
[00:20:17.840 --> 00:20:19.920]   I think we realized saying something very apt.
[00:20:19.920 --> 00:20:24.720]   It's not Neelize fault, but the world has moved on
[00:20:24.720 --> 00:20:27.200]   from this notion of that it even matters.
[00:20:27.200 --> 00:20:31.120]   It's more about the feeling, the emotional connection.
[00:20:31.120 --> 00:20:34.720]   You have to technology than whether it even works,
[00:20:34.720 --> 00:20:36.800]   which is, of course, seems you are important.
[00:20:36.800 --> 00:20:39.040]   -See, you are important. -It's stunning,
[00:20:39.040 --> 00:20:41.440]   because we spent our entire careers
[00:20:41.440 --> 00:20:44.720]   talking about, "Does this work better than that?"
[00:20:44.720 --> 00:20:47.280]   And I think you probably got your finger
[00:20:47.280 --> 00:20:50.240]   on the pulse of people as opposed to just...
[00:20:50.240 --> 00:20:52.400]   I mean, I noticed the Verge has gotten very much...
[00:20:52.400 --> 00:20:54.000]   No, it's very much more of a lifestyle brand
[00:20:54.000 --> 00:20:55.520]   than a technology brand, is it not?
[00:20:55.520 --> 00:20:58.560]   I think you will see us move very hard
[00:20:58.560 --> 00:21:00.080]   towards being a lifestyle brand.
[00:21:00.080 --> 00:21:02.320]   And the reason you will see that,
[00:21:02.320 --> 00:21:03.680]   the thesis of our site,
[00:21:03.680 --> 00:21:05.760]   and it has been the thesis since we launched,
[00:21:05.760 --> 00:21:07.760]   is that we spent four years at Engagit,
[00:21:07.760 --> 00:21:09.920]   the core senior team that launched the site.
[00:21:09.920 --> 00:21:13.520]   We spent four years there covering the explosion of mobile.
[00:21:13.520 --> 00:21:15.040]   What's the screen going to look like?
[00:21:15.040 --> 00:21:18.160]   Are we going to do resistive or capacitive for touch?
[00:21:18.160 --> 00:21:20.560]   Are we going to do IPS LCD?
[00:21:20.560 --> 00:21:22.160]   Are we going to TFT LCD?
[00:21:22.160 --> 00:21:23.920]   Are we going to do LTE?
[00:21:23.920 --> 00:21:25.360]   Or are we going to keep upgrading for G?
[00:21:25.360 --> 00:21:27.600]   I have been in those arguments.
[00:21:27.600 --> 00:21:30.480]   I've had at every level of depth
[00:21:30.480 --> 00:21:32.720]   with those conversations when we ran Engagit.
[00:21:32.720 --> 00:21:35.360]   And we arrived at a number of conclusions.
[00:21:35.360 --> 00:21:38.160]   And now all of us have a supercomputer in our pocket
[00:21:38.160 --> 00:21:40.000]   that's going to do a broadband network.
[00:21:40.000 --> 00:21:43.280]   And what is more interesting to think about
[00:21:43.280 --> 00:21:44.720]   is what happens now.
[00:21:44.720 --> 00:21:47.360]   Like, how will the world change around the fact
[00:21:47.360 --> 00:21:49.680]   that all of us have a supercomputer in our pocket?
[00:21:49.680 --> 00:21:53.200]   And not so much what is the best supercomputer?
[00:21:53.200 --> 00:21:56.720]   And the people who focus deeply on what is the next supercomputer
[00:21:56.720 --> 00:21:58.800]   or how big should the screen be?
[00:21:58.800 --> 00:22:02.080]   Or what should the touch technology look like?
[00:22:02.080 --> 00:22:03.440]   They're going to fall behind.
[00:22:03.440 --> 00:22:05.040]   And they will always fall behind.
[00:22:05.040 --> 00:22:06.640]   And that is the conversation about,
[00:22:06.640 --> 00:22:09.760]   should you wear bows and nose canceling headphones or beets?
[00:22:09.760 --> 00:22:11.200]   Because what you're really seeing is,
[00:22:11.200 --> 00:22:14.560]   what people want to wear is good headphones that look cool.
[00:22:14.560 --> 00:22:16.720]   And I completely understand that.
[00:22:16.720 --> 00:22:17.280]   I agree with you.
[00:22:17.280 --> 00:22:19.520]   I've had the same conversation with myself.
[00:22:19.520 --> 00:22:20.880]   We are not going to change.
[00:22:20.880 --> 00:22:23.040]   We're going to continue to do speeds
[00:22:23.040 --> 00:22:24.880]   and feeds and which technology is better.
[00:22:24.880 --> 00:22:25.840]   That's fine.
[00:22:25.840 --> 00:22:28.640]   We've never aimed for a mass audience.
[00:22:28.640 --> 00:22:30.880]   And for the audience that wants that kind of stuff,
[00:22:30.880 --> 00:22:32.800]   I think it's appropriate that such a thing exists.
[00:22:32.800 --> 00:22:36.880]   You're probably going to, you're already doing 10 times better.
[00:22:36.880 --> 00:22:40.240]   You'll do a thousand times better by targeting lifestyle.
[00:22:40.240 --> 00:22:41.840]   I'm not arguing with that.
[00:22:41.840 --> 00:22:43.520]   I think that's a sensible thing.
[00:22:43.520 --> 00:22:46.080]   If I were in a business, I would be doing that.
[00:22:46.080 --> 00:22:46.880]   But I'm not.
[00:22:46.880 --> 00:22:48.400]   This is what I want to do.
[00:22:48.400 --> 00:22:49.360]   It's too shallow.
[00:22:49.360 --> 00:22:50.400]   What made you say what I want to do?
[00:22:50.400 --> 00:22:51.840]   I don't think it should be encouraged.
[00:22:51.840 --> 00:22:53.440]   But it's also encouraged.
[00:22:53.440 --> 00:22:53.840]   There's really...
[00:22:53.840 --> 00:22:55.040]   It's shallow.
[00:22:55.040 --> 00:22:57.360]   It's just that you're not running with it here.
[00:22:57.360 --> 00:23:00.240]   Just dumb down the public even more than they are already.
[00:23:00.240 --> 00:23:00.880]   But the verdict...
[00:23:00.880 --> 00:23:02.240]   Let's make it right now.
[00:23:02.240 --> 00:23:03.200]   No, no.
[00:23:03.200 --> 00:23:04.720]   The verdict isn't stupid.
[00:23:04.720 --> 00:23:05.520]   Now we're condemning the public.
[00:23:05.520 --> 00:23:06.800]   Wow!
[00:23:06.800 --> 00:23:11.680]   That's called starting things off with a bang.
[00:23:11.680 --> 00:23:13.520]   John C. Devorek,
[00:23:13.520 --> 00:23:14.880]   Neil Eipatel,
[00:23:14.880 --> 00:23:16.480]   and Patrick Norton.
[00:23:16.480 --> 00:23:18.080]   Twitter is often fiery,
[00:23:18.080 --> 00:23:19.920]   but it's always fun.
[00:23:19.920 --> 00:23:23.840]   And I think it's always a great place to learn and to see what's happening.
[00:23:23.840 --> 00:23:27.920]   We've got more great clips from this year on This Week in Tech.
[00:23:27.920 --> 00:23:30.560]   But first a word from our friends at FreshBooks,
[00:23:30.560 --> 00:23:36.080]   the cloud accounting software designed from the ground up for entrepreneurs and small businesses.
[00:23:36.080 --> 00:23:40.000]   In fact, I can say with some certainty that FreshBooks is awesome
[00:23:40.000 --> 00:23:41.840]   because I used it for years.
[00:23:41.840 --> 00:23:43.760]   First discovered it about 10 years ago.
[00:23:43.760 --> 00:23:46.480]   In the intervening 10 years,
[00:23:46.480 --> 00:23:51.280]   more than 5 million people have used FreshBooks to run their business.
[00:23:51.280 --> 00:23:53.920]   I was running up to Canada, as you might remember,
[00:23:53.920 --> 00:23:56.560]   once a month for a week.
[00:23:56.560 --> 00:24:02.320]   And I had to bill the folks up in Canada for my time and my expenses.
[00:24:02.320 --> 00:24:05.040]   Used to do it by hand with Microsoft Word and Excel,
[00:24:05.040 --> 00:24:07.440]   and it was just the biggest pain so much so that
[00:24:07.440 --> 00:24:10.560]   many as a month I just would forget and not invoice them.
[00:24:10.560 --> 00:24:14.320]   And they started to get angry when they'd get three or four months invoices all at once.
[00:24:14.320 --> 00:24:19.040]   So Amber MacArthur, in fact, told me about FreshBooks and it saved my life.
[00:24:19.040 --> 00:24:21.360]   It started with FreshBooks Invoicing.
[00:24:21.360 --> 00:24:24.720]   You set up an invoice, got your company logo, looks super pro.
[00:24:24.720 --> 00:24:27.920]   You can invoice by regular mail or email or both.
[00:24:27.920 --> 00:24:29.120]   That's what I would do.
[00:24:29.120 --> 00:24:31.120]   They handled the currency transition, no problem.
[00:24:31.120 --> 00:24:33.200]   In fact, that's one of the great things about FreshBooks.
[00:24:33.200 --> 00:24:38.000]   Multiple currencies makes it very easy for you to invoice in the currency of your client.
[00:24:38.000 --> 00:24:42.240]   Of course, sending them by email meant I could put a pay me now button.
[00:24:42.240 --> 00:24:45.840]   And FreshBooks has set up payment services with all the big payers.
[00:24:45.840 --> 00:24:48.160]   So it's very simple for your client to pay.
[00:24:48.160 --> 00:24:50.560]   That means they're more likely to pay right away.
[00:24:50.560 --> 00:24:52.560]   It's just easier for them.
[00:24:52.560 --> 00:24:57.920]   That's why I think FreshBooks users get paid on average of five days faster.
[00:24:57.920 --> 00:25:01.680]   They also, this one blows me away, double on average.
[00:25:01.680 --> 00:25:06.480]   They're double their revenue in the first 24 months of using FreshBooks.
[00:25:06.480 --> 00:25:08.080]   It kind of makes sense.
[00:25:08.080 --> 00:25:12.080]   FreshBooks means you are doing a better job running your business.
[00:25:12.080 --> 00:25:14.480]   Because you don't have to worry about the accounting.
[00:25:14.480 --> 00:25:16.080]   You don't have to worry about the expenses.
[00:25:16.080 --> 00:25:20.560]   You can actually take a picture of receipts with the FreshBooks apps on Android and iOS.
[00:25:20.560 --> 00:25:22.720]   It'll make it very easy to do that.
[00:25:22.720 --> 00:25:24.560]   They'll even do time and hours.
[00:25:24.560 --> 00:25:27.600]   So if you build for hours, there's a little button on the app.
[00:25:27.600 --> 00:25:29.760]   You just start the timer and stop the timer.
[00:25:29.760 --> 00:25:33.760]   If you've got a client that's slow to pay, they have automated late payment reminders
[00:25:33.760 --> 00:25:37.920]   that really saves on the awkward emails and phone conversations I got to tell you.
[00:25:37.920 --> 00:25:39.680]   I'm a big fan of FreshBooks.
[00:25:39.680 --> 00:25:44.080]   If you would like to try it, we've arranged a 30-day no obligation trial.
[00:25:44.080 --> 00:25:52.080]   Go to freshbooks.com/twitfreshbooks.com/twit.
[00:25:52.080 --> 00:25:55.920]   It is so simple, you're a count on all of you too because you can instantly access complete
[00:25:55.920 --> 00:25:56.880]   financial reports.
[00:25:56.880 --> 00:26:02.800]   It integrates beautifully with all your apps, including Google Apps, PayPal, Stripe, MailChimp,
[00:26:02.800 --> 00:26:05.200]   FunBox, ZenPayroll.
[00:26:05.200 --> 00:26:08.800]   And if you ever need help, you'll talk to a real person every time
[00:26:08.800 --> 00:26:12.640]   FreshBooks award-winning support is ready to help support is free forever.
[00:26:12.640 --> 00:26:14.240]   I love FreshBooks.
[00:26:14.240 --> 00:26:15.360]   So does Anthony Taylor.
[00:26:15.360 --> 00:26:18.720]   He's the CEO and chief strategist at SME Strategy.
[00:26:18.720 --> 00:26:21.600]   He says, "I'm loving FreshBooks right now.
[00:26:21.600 --> 00:26:26.720]   I've been tracking all my time and costing our projects to track my productivity."
[00:26:26.720 --> 00:26:29.760]   You'll be a better business person when you use FreshBooks.
[00:26:29.760 --> 00:26:30.640]   I know I was.
[00:26:30.640 --> 00:26:33.680]   Try it for you for 30 days with no obligation.
[00:26:33.680 --> 00:26:36.320]   Just go to freshbooks.com/twit.
[00:26:36.320 --> 00:26:37.360]   Just do me a favor.
[00:26:37.360 --> 00:26:39.920]   When they ask, "How did you hear about us?
[00:26:39.920 --> 00:26:42.400]   Would you please write in this week in tech?"
[00:26:42.400 --> 00:26:45.920]   And I will say thank you for doing that.
[00:26:45.920 --> 00:26:49.200]   freshbooks.com/twit.
[00:26:49.200 --> 00:26:58.000]   All right, continuing on with our best of 2014, Kevin Rose joined us along with Liz Gaines
[00:26:58.000 --> 00:27:02.880]   of Recode, Patrick Bejard, our favorite French podcaster.
[00:27:03.840 --> 00:27:11.760]   But Kevin was here the day or the week after he'd been picketed by folks who said that Google
[00:27:11.760 --> 00:27:15.280]   was responsible for raising rents and evictions in San Francisco.
[00:27:15.280 --> 00:27:16.400]   This is what Kevin thought about it.
[00:27:16.400 --> 00:27:22.800]   I was so pissed off when I saw your Instagram post this morning.
[00:27:22.800 --> 00:27:25.040]   I couldn't believe it.
[00:27:25.040 --> 00:27:26.960]   This is not an April Fool's joke, right?
[00:27:26.960 --> 00:27:27.840]   It is not a joke.
[00:27:27.840 --> 00:27:29.680]   Unfortunately, I wish it was.
[00:27:30.880 --> 00:27:34.080]   So everybody probably knows there have been these protests in San Francisco.
[00:27:34.080 --> 00:27:40.240]   This week a protester vomited on the Google or the Yahoo bus on it.
[00:27:40.240 --> 00:27:42.640]   Not a writer, a protester.
[00:27:42.640 --> 00:27:44.080]   All sorts of stuff.
[00:27:44.080 --> 00:27:52.000]   The feeling is, I guess, that the cost of living in San Francisco has just gone through the roof,
[00:27:52.000 --> 00:27:59.120]   particularly the cost of housing because of rich yuppies from the Silicon Valley moving in,
[00:27:59.120 --> 00:28:04.000]   taking their fancy leather, clad Wi-Fi enabled buses back and forth.
[00:28:04.000 --> 00:28:07.360]   It's making it hard for San Francisco to live.
[00:28:07.360 --> 00:28:12.800]   I got to point out the real reason for that is because San Francisco is landlocked.
[00:28:12.800 --> 00:28:18.320]   It's actually water-locked and it's a small region.
[00:28:18.320 --> 00:28:23.840]   And the rules the city has created on creating new housing are so prohibitive that just nobody's
[00:28:23.840 --> 00:28:24.480]   building housing.
[00:28:24.480 --> 00:28:26.880]   And that's what puts pressure on prices.
[00:28:26.880 --> 00:28:29.040]   Nevertheless, there have been these protests.
[00:28:29.040 --> 00:28:33.120]   And I'm sad to say Kevin specifically is now being targeted.
[00:28:33.120 --> 00:28:35.920]   So on your, can I show this?
[00:28:35.920 --> 00:28:36.560]   You put it up on your...
[00:28:36.560 --> 00:28:37.280]   Yeah, go for it.
[00:28:37.280 --> 00:28:38.480]   Share whatever you like.
[00:28:38.480 --> 00:28:41.440]   TechCrunch had an article about it, but I saw it on first on Instagram.
[00:28:41.440 --> 00:28:42.240]   Parasite.
[00:28:42.240 --> 00:28:43.360]   Happy face.
[00:28:43.360 --> 00:28:45.840]   Already, I'm starting to think this guy's nuts.
[00:28:45.840 --> 00:28:46.480]   Whoever put this up.
[00:28:46.480 --> 00:28:47.440]   What's with the happy face?
[00:28:47.440 --> 00:28:51.280]   This was a, how big is this banner?
[00:28:51.280 --> 00:28:53.680]   That's just a handout.
[00:28:53.680 --> 00:28:55.680]   So that was just a little leaflet they were handing out to...
[00:28:55.680 --> 00:28:57.280]   But there was also a big banner, right?
[00:28:57.280 --> 00:29:00.800]   Yeah, they brought like a 10 foot banner that it took a few of them to hold it up.
[00:29:00.800 --> 00:29:02.080]   In front of your house.
[00:29:02.080 --> 00:29:04.720]   Yeah, in front of the house and they were chanting like Kevin Rose,
[00:29:04.720 --> 00:29:06.560]   the douche, Kevin Rose, Parasite.
[00:29:06.560 --> 00:29:07.600]   Oh my God, Kevin.
[00:29:07.600 --> 00:29:09.520]   This makes me so sad.
[00:29:09.520 --> 00:29:11.760]   How does another people, or was it just two?
[00:29:11.760 --> 00:29:11.920]   Oh, there it is.
[00:29:11.920 --> 00:29:12.800]   How about that one?
[00:29:12.800 --> 00:29:14.960]   I'm a snip, snip, your balls.
[00:29:14.960 --> 00:29:17.520]   What is wrong with these people?
[00:29:17.520 --> 00:29:20.720]   Oh my God.
[00:29:20.720 --> 00:29:21.840]   Anyway, let me read this.
[00:29:21.840 --> 00:29:24.320]   And I want to know what your take is on this.
[00:29:24.320 --> 00:29:26.480]   And I'm just, I'm so saddened.
[00:29:26.480 --> 00:29:28.560]   Greetings, your neighbor.
[00:29:28.560 --> 00:29:29.600]   And then it gives you your address.
[00:29:29.600 --> 00:29:32.080]   So they're public seeing your address here.
[00:29:32.080 --> 00:29:34.880]   A man named Kevin Rose is a Parasite.
[00:29:34.880 --> 00:29:38.400]   Perhaps not of you, but of us.
[00:29:38.400 --> 00:29:42.320]   This is why we are here to reveal him for what he is.
[00:29:42.320 --> 00:29:45.840]   As a partner venture capitalist at Google Ventures,
[00:29:45.840 --> 00:29:48.560]   Kevin, you bad man, you.
[00:29:48.560 --> 00:29:54.160]   Directs the flow of capital from Google into the text startup bubble.
[00:29:54.720 --> 00:29:56.960]   That is destroying San Francisco.
[00:29:56.960 --> 00:30:01.200]   The startups that he funds bring the swarms of young entrepreneurs that have ravaged.
[00:30:01.200 --> 00:30:04.720]   My God, you think they're like, what are they eating the trees?
[00:30:04.720 --> 00:30:07.680]   That have ravaged the landscapes of San Francisco and Oakland.
[00:30:07.680 --> 00:30:09.440]   Like locusts.
[00:30:09.440 --> 00:30:11.200]   With each.
[00:30:11.200 --> 00:30:14.560]   There's no more corn in San Francisco.
[00:30:14.560 --> 00:30:15.600]   And I ask you why?
[00:30:15.600 --> 00:30:20.960]   With each new tech corporation comes a wave of fresh techies
[00:30:20.960 --> 00:30:25.280]   who on average earn four times more than a normal service worker.
[00:30:25.280 --> 00:30:32.400]   We are the ones who serve them coffee, deliver them food, watch, I'll skip the next one.
[00:30:32.400 --> 00:30:34.800]   Watch their kids and mop their floors.
[00:30:34.800 --> 00:30:37.520]   Nearly all of them are just like Kevin.
[00:30:37.520 --> 00:30:40.240]   I mean, you got to say at least what I mean, don't say what it was,
[00:30:40.240 --> 00:30:42.720]   but that one that you're skipping is a is a doozy.
[00:30:42.720 --> 00:30:43.840]   We are though.
[00:30:43.840 --> 00:30:44.080]   All right.
[00:30:44.080 --> 00:30:44.880]   I'm going to read it out loud.
[00:30:44.880 --> 00:30:48.160]   You could bleed me later for if you've got kids watching cover their ears.
[00:30:48.160 --> 00:30:52.320]   We are the ones who serve them coffees, deliver them food, suck their stock.
[00:30:52.320 --> 00:30:54.480]   Really?
[00:30:54.480 --> 00:30:55.680]   I never got that perk.
[00:30:55.680 --> 00:30:56.480]   I'm wondering.
[00:30:56.480 --> 00:30:58.720]   I'm wondering if something is offered as a standard perk to startups.
[00:30:58.720 --> 00:30:59.760]   I can just tell you that right now.
[00:30:59.760 --> 00:31:02.720]   Is that the end of it?
[00:31:02.720 --> 00:31:06.400]   You tweeted there was more, but I don't they did they really complain about
[00:31:06.400 --> 00:31:06.960]   dignity.
[00:31:06.960 --> 00:31:08.160]   They complain about dignity.
[00:31:08.160 --> 00:31:12.560]   And they they they were upset about a joke that I made many years ago.
[00:31:12.560 --> 00:31:12.800]   Wait a minute.
[00:31:12.800 --> 00:31:13.440]   That's real.
[00:31:13.440 --> 00:31:15.360]   I thought you were being silly on Twitter.
[00:31:15.360 --> 00:31:16.640]   They're being done serious.
[00:31:16.640 --> 00:31:19.440]   They were just going through the internet and trying to find any like dirt that they could
[00:31:19.440 --> 00:31:20.000]   possibly mention.
[00:31:20.000 --> 00:31:21.440]   They mentioned dignity.
[00:31:21.440 --> 00:31:22.160]   Yeah.
[00:31:22.160 --> 00:31:26.080]   They I don't have the flyer here with me, but it said that it was like an awful show that
[00:31:26.080 --> 00:31:27.040]   ran for six years.
[00:31:27.040 --> 00:31:28.000]   That's what I think what they said.
[00:31:28.000 --> 00:31:29.040]   Oh my god.
[00:31:29.040 --> 00:31:33.680]   An awful show that ran for six years.
[00:31:33.680 --> 00:31:37.840]   Wow.
[00:31:37.840 --> 00:31:41.600]   What so this must make you sick in your stomach.
[00:31:41.600 --> 00:31:43.360]   I mean, is this this is scary stuff?
[00:31:43.360 --> 00:31:44.160]   Yeah.
[00:31:44.160 --> 00:31:46.720]   I mean, it's certainly I wasn't home at the time actually.
[00:31:46.720 --> 00:31:50.880]   So they they rang our doorbell and Daria just went downstairs thinking it was like
[00:31:50.880 --> 00:31:54.800]   someone delivering something and she opened the door and they handed her a flyer and she's like,
[00:31:54.800 --> 00:31:55.440]   what is this?
[00:31:55.440 --> 00:32:00.240]   And then they start chanting and yelling and she just kind of like closed the door and locks it.
[00:32:00.240 --> 00:32:06.000]   And then calls me up and I was down the street helping some buddies build a skate ramp actually.
[00:32:06.000 --> 00:32:10.000]   And you see ravaging San Francisco.
[00:32:11.040 --> 00:32:14.960]   It was a skate ramp for a nonprofit too actually, which was like kind of screwed up.
[00:32:14.960 --> 00:32:16.960]   I knew you were raw bad man.
[00:32:16.960 --> 00:32:24.880]   So I came home and I you know walked out and they recognized me and they walked up to me
[00:32:24.880 --> 00:32:27.280]   and they were like, hi, Timster.
[00:32:27.280 --> 00:32:28.000]   Timster's got home.
[00:32:28.000 --> 00:32:32.000]   They basically, you know, walked up to me and they were just like,
[00:32:32.000 --> 00:32:36.560]   started throwing, you know, first it was like a lot of insults and then it was just like,
[00:32:36.560 --> 00:32:40.960]   how can you live with yourself and what you're doing all this bad for our city.
[00:32:40.960 --> 00:32:43.120]   And you know, it's crazy.
[00:32:43.120 --> 00:32:43.840]   You think they're crazy or the court?
[00:32:43.840 --> 00:32:45.200]   The entire thing on an Android phone.
[00:32:45.200 --> 00:32:47.280]   I'm like, you guys realized you're on an Android phone.
[00:32:47.280 --> 00:32:49.200]   Like that's, you probably have an iPhone or something.
[00:32:49.200 --> 00:32:50.160]   That's Google stuff.
[00:32:50.160 --> 00:32:53.120]   And I asked them where they were going to post and they said, YouTube and I'm like,
[00:32:53.120 --> 00:32:54.720]   do you not see that in all this?
[00:32:54.720 --> 00:32:57.440]   I'm serious.
[00:32:57.440 --> 00:32:57.840]   They did.
[00:32:57.840 --> 00:32:58.880]   They told me when I was saying YouTube.
[00:32:58.880 --> 00:33:00.960]   Well, YouTube because it's free bandwidth man.
[00:33:00.960 --> 00:33:07.120]   And the thing is like, the thing that really gets me out the core is like,
[00:33:07.120 --> 00:33:08.640]   I understand their frustrations.
[00:33:08.640 --> 00:33:10.320]   You know, I know.
[00:33:10.320 --> 00:33:12.160]   You tweeted, I agree with them.
[00:33:12.160 --> 00:33:13.200]   We need to solve rosings.
[00:33:13.200 --> 00:33:16.160]   Rents keep the San Francisco culture and crack down on landlords.
[00:33:16.160 --> 00:33:18.880]   This way though, like you don't throw up on people's buses.
[00:33:18.880 --> 00:33:22.560]   Like there's a conversation to be had here, but it's not by throwing rocks or windows.
[00:33:22.560 --> 00:33:24.640]   You know, throwing up on people's buses.
[00:33:24.640 --> 00:33:29.680]   I think that, I mean, Leo, you know how it is when I was working for you at Tech TV
[00:33:29.680 --> 00:33:32.800]   when I first got hired out in the Bay Area in the early 2000s.
[00:33:32.800 --> 00:33:37.200]   You know, I was, I remember my starting salary was 28,000 a year.
[00:33:37.200 --> 00:33:38.560]   Yeah, you have worked.
[00:33:38.560 --> 00:33:40.560]   You have worked for the Russian assistant.
[00:33:40.560 --> 00:33:44.560]   You have earned everything you, you, every penny you've got, you worked your way up.
[00:33:44.560 --> 00:33:45.520]   It was hard to live.
[00:33:45.520 --> 00:33:46.560]   You have humble.
[00:33:46.560 --> 00:33:47.040]   You have humble.
[00:33:47.040 --> 00:33:49.200]   Yeah, you know what it's like to live in San Francisco.
[00:33:49.200 --> 00:33:50.240]   We paid you that little?
[00:33:50.240 --> 00:33:51.280]   Yeah.
[00:33:51.280 --> 00:33:53.200]   And then I was pissed off because Dan Heard.
[00:33:53.200 --> 00:33:54.800]   I found I was making 30,000 a year.
[00:33:54.800 --> 00:33:57.680]   So I went to Paul and I said, you give me a $2,000 razor, I'm quitting.
[00:33:57.680 --> 00:33:58.880]   I'm so sorry.
[00:33:58.880 --> 00:34:00.640]   They are paying you that little.
[00:34:00.640 --> 00:34:01.840]   And so I'm crying.
[00:34:01.840 --> 00:34:03.200]   I just knew his job.
[00:34:03.200 --> 00:34:06.160]   Tech TV is ruining San Francisco.
[00:34:06.160 --> 00:34:08.160]   That's awesome.
[00:34:08.160 --> 00:34:12.800]   But that's the point is that, look, you were building the skate ramp for an nonprofit.
[00:34:12.800 --> 00:34:16.000]   This is, this is not the Kevin Rose I know, obviously.
[00:34:16.000 --> 00:34:18.720]   And it doesn't even make sense.
[00:34:18.720 --> 00:34:24.880]   It's like, are they, there are certainly issues, but they're issues are don't go back to Google
[00:34:24.880 --> 00:34:27.680]   or even startups or any of this.
[00:34:27.680 --> 00:34:31.120]   And I know you're sympathetic to that.
[00:34:31.120 --> 00:34:32.800]   I wonder if these people are crazy.
[00:34:32.800 --> 00:34:35.040]   Are they genuine, you think?
[00:34:36.080 --> 00:34:42.240]   You know, it's, I think that their complaints are certainly found in reality.
[00:34:42.240 --> 00:34:44.800]   Like there are some really shady things going on here.
[00:34:44.800 --> 00:34:50.240]   Like landlords are kicking out long time tenants and then instantly jacking up the prices
[00:34:50.240 --> 00:34:53.360]   because they know they can get it with some of the tech folks that are making more.
[00:34:53.360 --> 00:34:55.040]   And so people are getting displaced.
[00:34:55.040 --> 00:34:56.000]   So that's frustrating.
[00:34:56.000 --> 00:34:57.520]   You know, it's frustrating to a lot of people.
[00:34:57.520 --> 00:35:02.240]   So there are complaints to be had here and a conversation to be had.
[00:35:02.240 --> 00:35:09.280]   But I certainly don't think that Google and some of these other tech companies are necessarily
[00:35:09.280 --> 00:35:11.520]   at fault. I mean, yes, they are bringing in more tech workers.
[00:35:11.520 --> 00:35:14.800]   But I think that there's a lot of good being done here as well.
[00:35:14.800 --> 00:35:18.320]   I mean, I certainly know what we do at Google Ventures and funding tech companies.
[00:35:18.320 --> 00:35:23.200]   And you know, we foundation medicine is one of our big companies that is working on cures for
[00:35:23.200 --> 00:35:28.000]   cancer and like we're trying to like, it's not just funding companies for the sake of funding
[00:35:28.000 --> 00:35:30.880]   companies. Like there's a kind of a bigger, bigger mission here.
[00:35:30.880 --> 00:35:37.200]   Absolutely. And I mean, if you look at, I mean, if you wanted to protest against the financial
[00:35:37.200 --> 00:35:43.520]   industry, I'll join you. If there's lots of places you can complain, Google doesn't seem to be one
[00:35:43.520 --> 00:35:49.200]   of them or any of the startup industry. Have you gotten the sense, Kevin, that has, have you talking
[00:35:49.200 --> 00:35:55.200]   about this? Has that made any anyone else say that this also happened to them? Or is this just a
[00:35:55.200 --> 00:35:59.120]   random Kevin Rose targeting? I know it has happened to a few other people.
[00:36:00.080 --> 00:36:03.200]   I don't know who those people are, but I saw something about someone left a comment on my
[00:36:03.200 --> 00:36:07.360]   Instagram post saying that it happened to them. And then I know that there was at least one other
[00:36:07.360 --> 00:36:11.040]   Googler that it happened to. There was a self-driving car guy.
[00:36:11.040 --> 00:36:14.080]   Oh, yes. Right. Right.
[00:36:14.080 --> 00:36:19.200]   Is it not what they're going to hire security guard? Are you concerned?
[00:36:19.200 --> 00:36:24.720]   At this point, we have Google security on it. So, you know, I've reached out to them. They have a
[00:36:24.720 --> 00:36:32.160]   pretty decent department there that handles this type of stuff. But, you know, there's no real
[00:36:32.160 --> 00:36:36.160]   concern here. My house is pretty locked down. I have cameras all over the place and, you know,
[00:36:36.160 --> 00:36:40.400]   I've kind of created a little bunker here, so I'm not too worried about that. But it is obviously,
[00:36:40.400 --> 00:36:45.360]   you know, it gets your like stomach rumbling and your little tens and you're shaking. Of course,
[00:36:45.360 --> 00:36:50.480]   my wife, Daria was, was spooked out by the whole thing. And it's, you just don't know how, how
[00:36:50.480 --> 00:36:54.560]   far it's going to go. You know, right now, yes, I was able to sit down outside and actually have
[00:36:54.560 --> 00:36:59.040]   a conversation with these folks. And it wasn't aggressive. Like, they weren't here to throw rocks.
[00:36:59.040 --> 00:37:04.640]   They were upset and invisibly upset, but they weren't like, I didn't feel at all like they were
[00:37:04.640 --> 00:37:10.400]   going to start a fight. And then the cops showed up and then they just kind of ran. They took off.
[00:37:10.400 --> 00:37:14.880]   I got to tell you, though, to be careful about mobs because individual humans are fine. But when
[00:37:14.880 --> 00:37:21.280]   they get in a group, sometimes they will do that that, you know, they wouldn't do as individuals.
[00:37:22.160 --> 00:37:27.040]   So don't underestimate the risks to you when you go out and talk to them. I
[00:37:27.040 --> 00:37:32.480]   honor you. I would have done the same thing, but that's that can be dangerous because mobs will do
[00:37:32.480 --> 00:37:37.280]   stupid things that are. That's true. Have you and Daria maybe even thought about moving out of
[00:37:37.280 --> 00:37:42.480]   San Francisco? Now, you know, we love you here. This is this is our home and it's been our home for
[00:37:42.480 --> 00:37:46.800]   for quite some time. You know, I've been here since 2000 myself. So it's longer than any other
[00:37:46.800 --> 00:37:52.640]   place I've lived. And I consider it to be home. So, you know, I think there's a lot of really
[00:37:52.640 --> 00:37:56.480]   positive, awesome things that are happening here in a bunch of different sectors. So I think that,
[00:37:56.480 --> 00:38:01.280]   you know, this is certainly for me, it's just something to pay attention to. And it's something
[00:38:01.280 --> 00:38:06.320]   that I think that, you know, I saw Ron Conway at the crunchies give a long talk about how the
[00:38:06.320 --> 00:38:09.920]   tech community in general has to come together to solve some of these problems. And I certainly
[00:38:09.920 --> 00:38:14.240]   believe that's the case. So, you know, I would like to take part in that conversation and sit down
[00:38:14.240 --> 00:38:19.760]   with some folks that are willing to have a conversation that isn't aggressive. And hopefully that will
[00:38:19.760 --> 00:38:23.840]   happen. But yeah, this is home. So we don't plan on moving anytime soon.
[00:38:23.840 --> 00:38:27.760]   Mike Wilson who wrote the book, The Difference Between God and Larry Ellison.
[00:38:27.760 --> 00:38:30.400]   God doesn't think he's Larry Ellison.
[00:38:30.400 --> 00:38:40.000]   Very classic line. Actually, the name of the book, he says you can give him titles or take away
[00:38:40.000 --> 00:38:43.200]   titles, but Larry will have a profound influence in that company for a while to come. I doubt
[00:38:43.200 --> 00:38:47.760]   there's a founder with more power, even Mark Zuckerberg, than Larry has managed to.
[00:38:47.760 --> 00:38:50.240]   Mark's pushed around by a bunch of people.
[00:38:50.240 --> 00:38:54.160]   He only, Larry only gets a dollar an annual salary.
[00:38:54.160 --> 00:38:57.200]   Oh, that's always annoys me. It's like a scam.
[00:38:57.200 --> 00:38:58.240]   Steve Jobs, I love you.
[00:38:58.240 --> 00:38:59.760]   Yeah, it's like, and I get a dollar.
[00:38:59.760 --> 00:39:01.840]   Seven million shares of stock.
[00:39:01.840 --> 00:39:08.320]   Yeah, that way you get to avoid taxes. I'm telling you, I have to say I'm advocating wealth tax
[00:39:09.120 --> 00:39:13.680]   because if a wealth tax goes into play, these guys who keep saying they want to be taxed more.
[00:39:13.680 --> 00:39:14.160]   Make a book.
[00:39:14.160 --> 00:39:17.120]   These guys, well, it doesn't make any difference on the wealth tax.
[00:39:17.120 --> 00:39:19.200]   The government still takes half of it.
[00:39:19.200 --> 00:39:22.240]   They don't take any 50 cents this year I paid in taxes.
[00:39:22.240 --> 00:39:27.200]   Rob Enderlin, he says he's the highest paid person in the valley.
[00:39:27.200 --> 00:39:34.800]   And that he thinks this is all stage managed to make investors who are mad at his,
[00:39:35.600 --> 00:39:39.920]   in fact, very high salary, calm down. The big investor group says,
[00:39:39.920 --> 00:39:44.640]   "Enderly, we're having a cow over how much he was making and how badly Oracle was doing."
[00:39:44.640 --> 00:39:47.600]   Well, if Rob Enderlin says it, it must be true.
[00:39:47.600 --> 00:39:47.600]   You do.
[00:39:47.600 --> 00:39:48.720]   Leave the opposite.
[00:39:48.720 --> 00:39:49.920]   I think it's Rob Enderlin.
[00:39:49.920 --> 00:39:51.120]   It is, though there's no Rob Enderlin.
[00:39:51.120 --> 00:39:51.840]   It's Rob Enderlin.
[00:39:51.840 --> 00:39:52.880]   It's Rob Enderlin here.
[00:39:52.880 --> 00:39:54.320]   They're just trolling Rob Enderlin now.
[00:39:54.320 --> 00:39:56.080]   They're just making a damn rolling end early.
[00:39:56.080 --> 00:39:56.560]   It's rolling end early.
[00:39:56.560 --> 00:39:57.360]   It's six.
[00:39:57.360 --> 00:39:58.960]   It's literally...
[00:39:58.960 --> 00:40:01.680]   I think Rob's got a very good take on some of this stuff.
[00:40:01.680 --> 00:40:02.960]   Really?
[00:40:02.960 --> 00:40:04.720]   He's kind of famous for all, though.
[00:40:04.720 --> 00:40:06.240]   No, he's famous for being too quoted.
[00:40:06.240 --> 00:40:06.880]   He's quoteable.
[00:40:06.880 --> 00:40:08.640]   Yeah, because he's got his lines open.
[00:40:08.640 --> 00:40:09.360]   He's got a phone.
[00:40:09.360 --> 00:40:12.160]   Every phone that goes right to him, you can always get a hold of him.
[00:40:12.160 --> 00:40:13.440]   And he says, "What do you want to quote for?"
[00:40:13.440 --> 00:40:14.480]   That's how he answers the phone.
[00:40:14.480 --> 00:40:16.080]   "What do you want to quote for?"
[00:40:16.080 --> 00:40:16.640]   I'll give you a quote.
[00:40:16.640 --> 00:40:17.120]   Anything.
[00:40:17.120 --> 00:40:19.200]   And then you say anything you want and he got a zinger.
[00:40:19.200 --> 00:40:20.640]   That's good.
[00:40:20.640 --> 00:40:21.920]   That's a good game.
[00:40:21.920 --> 00:40:26.880]   He started Oracle in 1977 with just $2,000.
[00:40:26.880 --> 00:40:27.760]   Yeah, that's what he says.
[00:40:27.760 --> 00:40:28.480]   In his pocket.
[00:40:28.480 --> 00:40:32.000]   Did he write the database or did he just...
[00:40:32.000 --> 00:40:32.880]   Not that I know of.
[00:40:32.880 --> 00:40:34.960]   What is his skillset?
[00:40:34.960 --> 00:40:36.400]   Is he a salesman?
[00:40:36.400 --> 00:40:37.840]   He's Tony Sarn.
[00:40:37.840 --> 00:40:39.520]   Well, definitely a lot of sales skills.
[00:40:39.520 --> 00:40:40.480]   And...
[00:40:40.480 --> 00:40:42.560]   Schmoozer.
[00:40:42.560 --> 00:40:43.440]   He's a schmoozer.
[00:40:43.440 --> 00:40:47.200]   Although he's the CTO, so he must...
[00:40:47.200 --> 00:40:48.720]   Yeah, that does mean he's...
[00:40:48.720 --> 00:40:51.680]   That's like Bill Gates, you know, that's questionable,
[00:40:51.680 --> 00:40:54.480]   whether he knows anything, how the database even works anymore.
[00:40:54.480 --> 00:40:54.720]   Yeah.
[00:40:54.720 --> 00:40:59.440]   If anybody gets his brain in a jar,
[00:41:00.560 --> 00:41:02.240]   it'll be very Allison.
[00:41:02.240 --> 00:41:06.400]   You know, like...
[00:41:06.400 --> 00:41:07.200]   If you look at that brain...
[00:41:07.200 --> 00:41:10.320]   The future Rambo, the guy's gonna be the president in 3000.
[00:41:10.320 --> 00:41:12.400]   The guy in the brain is a jar.
[00:41:12.400 --> 00:41:15.760]   Yeah, yeah, got your brain here, Allison.
[00:41:15.760 --> 00:41:19.760]   In a jar.
[00:41:19.760 --> 00:41:23.920]   That is a strange way to compliment someone, Leah, really.
[00:41:23.920 --> 00:41:26.080]   This is the strangest I've ever heard.
[00:41:26.080 --> 00:41:28.560]   I don't know what I mean by that.
[00:41:28.560 --> 00:41:31.760]   If that guy's a real jar brain guy, if you know what I mean...
[00:41:31.760 --> 00:41:34.560]   But he gets his brain in a jar.
[00:41:34.560 --> 00:41:39.760]   I think I'm punchy still from staying up all night for the iPhone.
[00:41:39.760 --> 00:41:43.760]   I had a repeater in my bedroom,
[00:41:43.760 --> 00:41:46.960]   which beamed down to the lower floors of the house.
[00:41:46.960 --> 00:41:47.760]   When?
[00:41:47.760 --> 00:41:49.120]   Recently, it's still there.
[00:41:49.120 --> 00:41:51.920]   But I keep it turned off because I was having nightmares when it was on.
[00:41:51.920 --> 00:41:52.880]   What were the frequencies?
[00:41:52.880 --> 00:41:53.840]   Kenneth?
[00:41:53.840 --> 00:41:56.720]   Ta-da.
[00:41:57.440 --> 00:41:58.960]   Was it a gigahertz?
[00:41:58.960 --> 00:42:00.320]   It was 2.4 or 5 gigahertz.
[00:42:00.320 --> 00:42:01.680]   It was both the 2.4 and the 5.
[00:42:01.680 --> 00:42:02.720]   And it gave you nightmares.
[00:42:02.720 --> 00:42:04.400]   And when you turned it off, the nightmares abated.
[00:42:04.400 --> 00:42:04.720]   Yes.
[00:42:04.720 --> 00:42:07.040]   Fascinating.
[00:42:07.040 --> 00:42:08.160]   Just saying.
[00:42:08.160 --> 00:42:12.640]   Just a tip for everybody out there that has a repeater near their head.
[00:42:12.640 --> 00:42:15.360]   You think it really was causing nightmares?
[00:42:15.360 --> 00:42:16.000]   I had a...
[00:42:16.000 --> 00:42:17.040]   Oh, you should just get a two.
[00:42:17.040 --> 00:42:18.400]   No, Adam didn't even know this.
[00:42:18.400 --> 00:42:18.720]   I just...
[00:42:18.720 --> 00:42:20.800]   This is the first time I've ever revealed this to anybody.
[00:42:20.800 --> 00:42:23.280]   I'm being quite honest and sincere here.
[00:42:23.280 --> 00:42:25.120]   And so what were the nightmares about?
[00:42:25.120 --> 00:42:26.480]   I can't remember dreams for everyone.
[00:42:26.480 --> 00:42:28.240]   But then we just had disturbed sleep.
[00:42:28.240 --> 00:42:28.880]   Yes.
[00:42:28.880 --> 00:42:30.240]   You were tossing and you were turning.
[00:42:30.240 --> 00:42:32.000]   And then the minute you turned it off...
[00:42:32.000 --> 00:42:32.960]   Unplugged.
[00:42:32.960 --> 00:42:33.600]   Unplugged it.
[00:42:33.600 --> 00:42:33.920]   Yeah.
[00:42:33.920 --> 00:42:34.480]   It was fine.
[00:42:34.480 --> 00:42:35.360]   Yeah.
[00:42:35.360 --> 00:42:39.360]   John, you know, if you cover your head with tin foil...
[00:42:39.360 --> 00:42:39.760]   Yeah.
[00:42:39.760 --> 00:42:41.920]   No, this is why I don't bring this stuff up.
[00:42:41.920 --> 00:42:44.000]   Even though it's a helpful hit for anybody out there.
[00:42:44.000 --> 00:42:44.560]   Maybe you had...
[00:42:44.560 --> 00:42:45.040]   No, no.
[00:42:45.040 --> 00:42:46.320]   Instead I get ridiculed.
[00:42:46.320 --> 00:42:48.560]   I get ridiculed by the minions.
[00:42:48.560 --> 00:42:50.240]   It's ridiculous.
[00:42:50.240 --> 00:42:52.000]   Maybe it was your years as a war criminal.
[00:42:52.000 --> 00:42:53.120]   It works every time.
[00:42:53.120 --> 00:42:54.080]   Okay, I'm not gonna...
[00:42:54.080 --> 00:42:56.240]   That's the end of my confessional.
[00:42:56.320 --> 00:42:57.600]   No, I'm not gonna bring anything.
[00:42:57.600 --> 00:42:58.320]   I'm not gonna...
[00:42:58.320 --> 00:43:00.720]   I have great PTSD meds.
[00:43:00.720 --> 00:43:01.280]   Yeah, bad.
[00:43:01.280 --> 00:43:02.560]   We should talk after.
[00:43:02.560 --> 00:43:03.920]   You know, those things are bad for you.
[00:43:03.920 --> 00:43:04.480]   Are they?
[00:43:04.480 --> 00:43:04.960]   Oh, yeah.
[00:43:04.960 --> 00:43:07.840]   It's always fun when John Seed of War Act is on Twitch.
[00:43:07.840 --> 00:43:11.840]   But we have so many regular hosts, so many irregular hosts.
[00:43:11.840 --> 00:43:15.200]   Twitch is always an interesting stew, an interesting combination.
[00:43:15.200 --> 00:43:18.000]   We try really hard to make that special recipe,
[00:43:18.000 --> 00:43:19.360]   that special combination.
[00:43:19.360 --> 00:43:22.240]   Coming up, one of my favorite semi-regular guests,
[00:43:22.240 --> 00:43:25.280]   Jerry Pournell, the great science fiction author,
[00:43:25.280 --> 00:43:27.440]   along with Father Robert and Jason Heiner.
[00:43:27.440 --> 00:43:30.320]   But first I wanna mention one of our great sponsors,
[00:43:30.320 --> 00:43:32.240]   a company that's been with us for many years.
[00:43:32.240 --> 00:43:35.840]   In fact, I think we started working with Squarespace
[00:43:35.840 --> 00:43:38.320]   practically when they had just started out.
[00:43:38.320 --> 00:43:42.000]   Anthony Castellana had written Squarespace's software
[00:43:42.000 --> 00:43:46.640]   in his dorm room to solve his own need for a great web platform.
[00:43:46.640 --> 00:43:49.200]   Today they are the place to host your website.
[00:43:49.200 --> 00:43:51.520]   The best web hosting never goes down.
[00:43:51.520 --> 00:43:53.040]   You cannot bring it down.
[00:43:53.040 --> 00:43:58.560]   Combined with the best software to make really the best place
[00:43:58.560 --> 00:44:00.320]   for your presence on the web,
[00:44:00.320 --> 00:44:02.320]   you gotta take a look at Squarespace 7.
[00:44:02.320 --> 00:44:04.560]   Their new templates are gorgeous
[00:44:04.560 --> 00:44:07.600]   and it makes getting started with your unique web presence
[00:44:07.600 --> 00:44:08.880]   so much easier.
[00:44:08.880 --> 00:44:11.200]   It's got a completely redesigned interface,
[00:44:11.200 --> 00:44:13.200]   easier to navigate and operate.
[00:44:13.200 --> 00:44:15.600]   In fact, there's no more toggling between site manager
[00:44:15.600 --> 00:44:17.600]   and preview mode with Squarespace 7.
[00:44:17.600 --> 00:44:20.800]   You actually are live editing on a single screen.
[00:44:20.800 --> 00:44:22.960]   You can even preview to your designs
[00:44:22.960 --> 00:44:26.080]   all of Squarespace templates are mobile responsive.
[00:44:26.080 --> 00:44:27.760]   That means they look great on any size screen
[00:44:27.760 --> 00:44:30.400]   but you can actually see what your site is going to look like
[00:44:30.400 --> 00:44:34.880]   on a smaller device, on a smaller screen in their preview mode
[00:44:34.880 --> 00:44:38.320]   so you'll see how your site will look on tablets or your mobile phone.
[00:44:38.320 --> 00:44:42.240]   They also include instant access to professional stock photography from Getty,
[00:44:42.240 --> 00:44:44.960]   instant branded email set up with Google Apps,
[00:44:44.960 --> 00:44:47.760]   and templates, this is new designed for specific professions.
[00:44:47.760 --> 00:44:51.920]   For instance, architects, musicians, bands,
[00:44:51.920 --> 00:44:55.280]   chefs, if you're a band, take a look at the Horizon template.
[00:44:55.280 --> 00:44:58.640]   The Horizon template includes features that bands really appreciate
[00:44:58.640 --> 00:45:02.880]   like tour dates, music player, and an emergency store.
[00:45:02.880 --> 00:45:04.560]   They also have a great developer platform.
[00:45:04.560 --> 00:45:10.640]   Now you don't have to be a JavaScript or CSS monkey to use Squarespace.
[00:45:10.640 --> 00:45:12.800]   That's the whole point is anybody can use it
[00:45:12.800 --> 00:45:17.680]   but if you are a developer, you're going to love the developer platform.
[00:45:17.680 --> 00:45:23.040]   It's the same tools that Squarespace uses for its own site design and code control.
[00:45:23.040 --> 00:45:26.320]   So this is incredibly well designed.
[00:45:26.320 --> 00:45:30.000]   They have e-commerce on every subscription plan, on every template.
[00:45:30.000 --> 00:45:32.320]   That means you have the ability not only to sell stuff online
[00:45:32.320 --> 00:45:38.240]   but you could accept donations if you're a nonprofit or for a wedding registry or a school fund drive.
[00:45:38.240 --> 00:45:42.880]   Squarespace Help is live 24/7 right from their offices
[00:45:42.880 --> 00:45:44.560]   that they don't outsource it.
[00:45:44.560 --> 00:45:49.280]   For people who actually work at Squarespace, plus their self-help articles and video workshops too.
[00:45:49.280 --> 00:45:54.080]   And all this for just $8 a month including a free domain name if you sign up for a year.
[00:45:54.080 --> 00:45:57.920]   Squarespace, try it right now. No credit card needed.
[00:45:57.920 --> 00:45:59.280]   Just click the Get Started button.
[00:45:59.280 --> 00:46:01.600]   You've got two weeks to take a look at the place.
[00:46:01.600 --> 00:46:03.120]   Bang on the tires.
[00:46:03.120 --> 00:46:05.200]   Really get a sense of what Squarespace can do for you.
[00:46:05.200 --> 00:46:09.360]   If you decide this is your new home on the web, make sure you use the offer code TWIT.
[00:46:09.360 --> 00:46:13.440]   You'll get 10% off and of course you'll be showing your support for the show.
[00:46:13.440 --> 00:46:14.880]   We appreciate that.
[00:46:14.880 --> 00:46:16.400]   Thank you Squarespace.
[00:46:16.400 --> 00:46:18.320]   Squarespace Start Here.
[00:46:18.320 --> 00:46:22.640]   Go Anywhere Squarespace.com
[00:46:22.640 --> 00:46:23.840]   Use the offer code TWIT.
[00:46:23.840 --> 00:46:26.560]   Jerry Pournell Love Him.
[00:46:26.560 --> 00:46:29.200]   Jason Heiner from Tech Republic Love Him.
[00:46:29.200 --> 00:46:34.560]   Our own father Robert Bauassar and I discussed the right to personal data on the internet.
[00:46:34.560 --> 00:46:40.400]   It all came out when Amazon let us know that their silk browser kept everywhere.
[00:46:41.680 --> 00:46:48.640]   Amazon has a browser of course in the fire, the silk browser and he points out,
[00:46:48.640 --> 00:46:51.200]   Mike again, we should have had Mike on the show today actually,
[00:46:51.200 --> 00:46:55.360]   he points out that the browser is governed by Amazon's privacy policies,
[00:46:55.360 --> 00:47:00.720]   which are pretty upfront saying, quote, "receive and store any information you enter on our website
[00:47:00.720 --> 00:47:06.160]   or give us in any other way." And they say, "If you don't like it, exit the browser and do not
[00:47:06.160 --> 00:47:11.120]   install user access Amazon, silk." In other words, we're going to keep track of everything you do
[00:47:11.120 --> 00:47:13.600]   and that's the way it is. If you don't like it, don't use this browser.
[00:47:13.600 --> 00:47:15.600]   That's pretty transparent.
[00:47:15.600 --> 00:47:20.160]   Do you think Google doesn't know that Google hasn't been doing it for years?
[00:47:20.160 --> 00:47:23.600]   Of course Google has its own browser. Chrome. Why? Well, guess why?
[00:47:23.600 --> 00:47:28.000]   And I doubt that Apple is throwing much data away about what you do.
[00:47:28.000 --> 00:47:29.920]   We now understand why Apple made Safari.
[00:47:29.920 --> 00:47:32.880]   Wasn't because we didn't have a good experience.
[00:47:32.880 --> 00:47:38.880]   Well, it's a different society. 20 years ago, if someone had had a case where they said,
[00:47:38.880 --> 00:47:43.200]   "Look, I have a right to have all these companies erase their data about me."
[00:47:43.200 --> 00:47:47.360]   We'd probably say, "Oh, yeah, yeah, that makes sense. It's your personal data. They have no right to
[00:47:47.360 --> 00:47:52.080]   it." We just had that right to be forgotten case and people are looking at it going,
[00:47:52.080 --> 00:47:56.160]   "You don't have that right." If you're on the internet, you're in a public space.
[00:47:56.160 --> 00:48:00.080]   You don't have the right to tell companies to get rid of the data that you left behind.
[00:48:00.080 --> 00:48:05.760]   It just shows you, we are now, we will accept this. As long as you give me something,
[00:48:05.760 --> 00:48:10.240]   something shiny, Gmail, a better shopping experience, I will take invasion of privacy,
[00:48:10.240 --> 00:48:17.200]   as long as I don't think it's too invasive. And that two-part shifts, what's too invasive
[00:48:17.200 --> 00:48:21.920]   will shift over the years? I mean, it's funny because we have this conversation on nearly every
[00:48:21.920 --> 00:48:28.800]   Twitter. No matter who the panelists are, there's this clear sense that privacy does no longer
[00:48:28.800 --> 00:48:34.720]   exist. As Scott McNeely was right, he said privacy is over. There is no privacy. Get over it.
[00:48:35.680 --> 00:48:40.240]   And yet there is also this strong feeling we should try to fight for some semblance of privacy.
[00:48:40.240 --> 00:48:43.440]   And I don't know what the answer is. I generally come down on the side of,
[00:48:43.440 --> 00:48:48.880]   "I don't care. So what if Google or Amazon knows everything I do? What's the harm in that?"
[00:48:48.880 --> 00:48:56.080]   Depends on what kind of porn you watch. You know what? Everybody watches porn. What's so what?
[00:48:56.080 --> 00:49:01.120]   I only watch Christian porn. Good man. I'm sorry, not everybody. But many of them.
[00:49:02.000 --> 00:49:06.320]   I guess we're, I think we're going to head to an ace. Thanks to- Oh, I am sure father has done his
[00:49:06.320 --> 00:49:11.920]   research into the sinfulness of man or god. You have to research to know. I mean seriously,
[00:49:11.920 --> 00:49:16.400]   this is groundbreaking stuff. Oh, this is so bad. I don't want to go this way. But I do have to
[00:49:16.400 --> 00:49:21.440]   point out that one of the, in the Facebook world, the post-Facebook world, but you know,
[00:49:21.440 --> 00:49:26.320]   notice we have a president who admitted to inhaling that the standards are changing. You're not going
[00:49:26.320 --> 00:49:30.880]   to be able to elect a president who hasn't smoked pot or hasn't served porn. You're not going to
[00:49:30.880 --> 00:49:36.560]   be able to hire an employee who hasn't got pictures of him drinking heavily on Facebook because
[00:49:36.560 --> 00:49:42.400]   everybody, what will become apparent is everybody, except with the exception of
[00:49:42.400 --> 00:49:47.440]   Father Robert Bowser. I don't do any of that. Everybody does this. And so, is that a bad thing? Maybe,
[00:49:47.440 --> 00:49:54.640]   you know, Jivorek always brings up the, I think it's the, the, the boogie man of insurance companies
[00:49:54.640 --> 00:50:00.240]   finding out I'm eating too many donuts and refusing to insure me. I don't, I don't really worry about
[00:50:00.240 --> 00:50:06.560]   that so much, but well, not only that, but that we, under Obamacare, that's a pre-existing condition
[00:50:06.560 --> 00:50:10.720]   anyway. I'm safe. I'm protected. Thank you, President Obama.
[00:50:10.720 --> 00:50:15.200]   So, well, I think that, I think that part of it is,
[00:50:15.200 --> 00:50:21.520]   the idea that, you know, we haven't seen it yet, the insurance company, I don't think this is
[00:50:21.520 --> 00:50:25.440]   necessarily a boogie man thing. I think that's something to sort of be concerned about.
[00:50:25.440 --> 00:50:29.440]   Well, I think that if that starts happening, then in fact, legislation will
[00:50:29.440 --> 00:50:33.280]   probably do something about it. It could, it could, but it certainly could come in too well.
[00:50:33.280 --> 00:50:35.600]   Let's not assume there's going to be harm until it happens.
[00:50:35.600 --> 00:50:41.120]   I agree. That's fair enough. I think it's just anticipating, you know, that this could affect you
[00:50:41.120 --> 00:50:46.800]   getting a job. Well, and the point is that it is too late. I mean, it's like, but I think it's
[00:50:46.800 --> 00:50:52.400]   already, Jerry, is that your position? It's already too late. I think that the time to have done this
[00:50:52.400 --> 00:50:58.320]   was 20 years ago when I wrote some columns about it and nobody paid damn better attention to it.
[00:50:58.320 --> 00:51:04.160]   You've given up. What was the, what was the threat 20 years ago? This.
[00:51:04.160 --> 00:51:08.960]   So this was the earliest early days of the internet. You could see it coming.
[00:51:08.960 --> 00:51:19.040]   Well, before the internet, remember back in 1980, what made me famous if you can use that word,
[00:51:19.040 --> 00:51:25.680]   was that I said that by the year 2000, anybody in western civilization would be able to get the
[00:51:25.680 --> 00:51:31.200]   answer to any question that actually had an answer. That's true. And it happened.
[00:51:31.200 --> 00:51:36.400]   Lo and behold, it happened by 1995. Thanks to Google. Nice to go.
[00:51:36.400 --> 00:51:45.440]   And western civilization changed in 1990, about 1990, when the wall came down.
[00:51:45.440 --> 00:51:54.800]   So it's now, except for China and North Korea and a few places that don't have any
[00:51:54.800 --> 00:52:01.520]   internet paint, anybody in the world can get almost any answer to get answered almost any
[00:52:01.520 --> 00:52:08.880]   question that has an answer. Well, questions like, when was Leo born and what did he have for
[00:52:08.880 --> 00:52:14.560]   dinner last night? Are questions that have an answer? But when, but when did Leo,
[00:52:14.560 --> 00:52:19.840]   anybody who wants to know what you had for dinner last night could find out if they really wanted
[00:52:19.840 --> 00:52:24.240]   to know it? Should we worry though, and this is the right to be forgotten in Europe, but should we
[00:52:24.240 --> 00:52:31.120]   worry if somebody queries, how long was Leo's jail term for that rape conviction and they find
[00:52:31.120 --> 00:52:36.640]   an incorrect answer, then what is my record? I mean, not all the information's accurate,
[00:52:36.640 --> 00:52:42.000]   Jerry, I mean, as we well know, I understand thoroughly. We cover big deal all the time on
[00:52:42.000 --> 00:52:47.200]   Twitter, on my network. Well, I think that there and it's always, you know, the nightmare scenario
[00:52:47.200 --> 00:52:51.840]   is when big data goes wrong, because those correlations that it draws inevitably is always right.
[00:52:52.400 --> 00:53:00.080]   Yes. So now what? Is it too? Well, it's we're screwed. It's not too late. I think it's just
[00:53:00.080 --> 00:53:06.240]   expectations. Now, let's let your slatchers or four is to determine who is responsible
[00:53:06.240 --> 00:53:13.360]   when false data is disseminated. It is still again, you can still collect for being liable,
[00:53:13.360 --> 00:53:18.400]   you know, but see that there's a problem. Many of the people who liable, you don't have enough
[00:53:18.400 --> 00:53:22.880]   money to make it worth going after them. But Jerry, that's a problem with false with with false data
[00:53:22.880 --> 00:53:28.880]   and big data, because you're not disseminating any falsehoods. Big data is based on disparate sets
[00:53:28.880 --> 00:53:32.880]   of information that are put through some sort of database. So there is no individual, there's no
[00:53:32.880 --> 00:53:38.880]   corporation that's making the assumption they're just giving you a percentage of possibility based
[00:53:38.880 --> 00:53:44.480]   on the information it has. Well, I'm not harmed by that. I am harmed if it comes up and says that I
[00:53:44.480 --> 00:53:52.480]   served five years for poisoning children when I was 35 years old or something.
[00:53:52.480 --> 00:53:58.320]   Well, what about this? That's just a libel statement. Okay, so I'll give you an example.
[00:53:58.320 --> 00:54:05.920]   People my age and with my background have a 4% probability of having molested a kid at some
[00:54:05.920 --> 00:54:10.480]   point in time. There's nothing I can do about that. That may or may not be a true statement.
[00:54:11.120 --> 00:54:18.560]   But if it says that I did it, that's a accusation and a lie. And I can do something about that.
[00:54:18.560 --> 00:54:24.320]   Great quote in our chat room from Bruce Schnire, Web7 says, Bruce Schnire in 2006,
[00:54:24.320 --> 00:54:31.040]   wrote quote, "Patterns we leave behind will be brought back to implicate us by whatever authority
[00:54:31.040 --> 00:54:36.160]   has now been focused upon our once private and its next. We lose our individuality because everything
[00:54:36.160 --> 00:54:41.440]   we do is observable and recordable." I mean, I understand both sides of this argument. I really
[00:54:41.440 --> 00:54:46.560]   do. I've decided because I'm too lazy to do anything else just to buy the Amazon phone.
[00:54:46.560 --> 00:54:52.720]   Because it's cool and I want it. Are you both on LO?
[00:54:52.720 --> 00:55:01.360]   LO is so stupid. It is such a moronic stupid stupid stupid thing. It's who's going to use it?
[00:55:01.360 --> 00:55:08.480]   Are you holding back, Nick? I signed up. It's literally it looks like someone's art school,
[00:55:08.480 --> 00:55:12.560]   high school project. I think it is. They say they're artists. Yeah, they're not at high school
[00:55:12.560 --> 00:55:19.360]   anymore. But here's the thing. It's not going to disrupt Facebook. Facebook has 1.3 billion users.
[00:55:19.360 --> 00:55:24.000]   I mean, Twitter can't disrupt Facebook and they have 260, 270 million users.
[00:55:24.000 --> 00:55:30.400]   So let me tell you for folks who have not yet heard about LO. This is, I'm on LO right now.
[00:55:30.960 --> 00:55:36.080]   Invite only, by the way. But that hasn't stopped 40,000 people an hour from signing up in the
[00:55:36.080 --> 00:55:42.160]   last couple of days. That's what the founders say. 40,000 new users an hour. Wow, that's so many.
[00:55:42.160 --> 00:55:47.360]   That's sarcasm. Okay. Thank you. Thank you for annotating.
[00:55:47.360 --> 00:55:55.200]   LO. Okay. Well, here's the pitch. LO is ad-free. They wanted to make an anti-Facebook,
[00:55:55.200 --> 00:56:00.400]   a social network where they will never sell ads and they will never sell your information to
[00:56:00.400 --> 00:56:07.200]   advertisers. And the idea is that they'll monetize. And by the way, some people were upset when they
[00:56:07.200 --> 00:56:12.640]   found out and it's not really clear in the LO manifesto that they do in fact have almost half
[00:56:12.640 --> 00:56:16.240]   a million dollars in venture funding, angel funding from a Vermont venture capital.
[00:56:16.240 --> 00:56:19.760]   Yeah, Vermont. So that's whole. Well, it's Vermont. They're probably wearing earth shoes.
[00:56:22.560 --> 00:56:26.080]   But as somebody pointed out, hey, if you get venture funding, somebody's going to want an exit.
[00:56:26.080 --> 00:56:31.040]   They're going to want you to monetize. The plan is that they will charge you small amounts of money,
[00:56:31.040 --> 00:56:34.640]   a couple of bucks here, a couple of bucks there to add special features.
[00:56:34.640 --> 00:56:40.000]   And that purchases basically. I would prefer, I would love a Facebook that I paid
[00:56:40.000 --> 00:56:45.840]   $5 a month or whatever that didn't have ads. One of the things that's great about LO,
[00:56:45.840 --> 00:56:50.640]   they don't have edge rank. They don't decide what you see of your friends posts. You see all of your
[00:56:50.640 --> 00:56:55.440]   friends posts. I think it's a good idea. Sounds like just like a site. I can't remember the name.
[00:56:55.440 --> 00:57:01.200]   Oh, Twitter. No, Twitter sucks. Twitter sucks because of the at replies.
[00:57:01.200 --> 00:57:05.760]   Twitter sucks because it's a broadcast medium that people try to have conversations in.
[00:57:05.760 --> 00:57:09.760]   That's the problem. It's the conversations. Twitter doesn't suck itself. If you just look at the
[00:57:09.760 --> 00:57:15.360]   newsfeed or the or the discover tab, when you look at the at replies, it's literally like,
[00:57:15.360 --> 00:57:19.680]   it's just the comment threads on a news article. It's it that's what sucks about Twitter.
[00:57:19.680 --> 00:57:24.000]   Well, there's other issues to 140 characters means people are tend to be kind of cryptic.
[00:57:24.000 --> 00:57:27.760]   So you spend a lot of energy trying to understand what the hell is he talking about.
[00:57:27.760 --> 00:57:32.480]   And then you agree? It's like reading license plates. What? You just do the P Marka technique of
[00:57:32.480 --> 00:57:36.640]   just spamming everybody with it. Yeah, well, then that's the other problem. There's a lot of spam.
[00:57:36.640 --> 00:57:41.680]   And then the main problem I have is Twitter has yet to come up with a comprehensive way to block
[00:57:41.680 --> 00:57:49.840]   trolls and evil doers. And so it's just laced with let's go back. Let's go back. Let's go back.
[00:57:49.840 --> 00:57:54.240]   I actually want to rewind back to the L.O. thing. We're Twitter.
[00:57:54.240 --> 00:57:57.200]   But then I want to have this Twitter conversation because we have the author
[00:57:57.200 --> 00:58:02.640]   how to be Twitter here. And no, I mean, that's the wrong book of hatching black. No, that's the wrong.
[00:58:02.640 --> 00:58:07.600]   But anyway, we have I mean, Nick, if anybody would be able to defend Twitter, be Nick built.
[00:58:07.600 --> 00:58:12.000]   But I also know, but I'm not defending Twitter. I actually think that Twitter does have its issues.
[00:58:12.000 --> 00:58:17.520]   I think the app replies are literally the worst aspect of the platform. You cannot have a conversation
[00:58:17.520 --> 00:58:23.440]   in a one to many situation with 10 people or tens of thousands of people. And I think that
[00:58:23.440 --> 00:58:28.800]   aspect of it is completely and utterly broken. But I do still think that the 140 character sharing
[00:58:28.800 --> 00:58:33.440]   content, you know, the real time information and the reason real time works is because it's 140
[00:58:33.440 --> 00:58:37.120]   characters. I think that that is still completely brilliant. As a Twitter turned bitter. Wait a minute.
[00:58:37.120 --> 00:58:40.960]   Now we're having the Twitter conversation. Let's go back to the fair to they wanted to do L.O.
[00:58:40.960 --> 00:58:45.200]   Then we'll do Twitter. I'm going to do L.O. then Oi then what up?
[00:58:45.200 --> 00:58:51.280]   Boy, it's the new L.O. apparently. My reaction to the L.O. thing, a friend of mine on Facebook
[00:58:51.280 --> 00:58:56.240]   was talking about it. And I was just like, I hate new stuff. I'm just at that stage. Well,
[00:58:56.240 --> 00:59:00.080]   that's just because he's old. In my tech adoption, I was like, Oh, it's new. It's probably dumb. I
[00:59:00.080 --> 00:59:05.600]   don't need it. I'm going to hate because it's not what I know. But I think the reaction that it grew
[00:59:05.600 --> 00:59:11.600]   out of, the sort of spirit of L.O. is important. And this idea of their manifesto that users
[00:59:11.600 --> 00:59:17.280]   own their data, that they're trying to position you as making you aware, like reminding you
[00:59:17.280 --> 00:59:21.760]   that you are being productized by the platform companies that you could give all this stuff to.
[00:59:21.760 --> 00:59:27.280]   I think that's an important idea contribution to the space. And they don't need to take down
[00:59:27.280 --> 00:59:33.280]   Facebook, 40,000 an hour, 40,000 over a year for those people. It might end up being very meaningful.
[00:59:33.280 --> 00:59:38.640]   And the idea that we have all sort of opted into by default, not all, but so many a billion
[00:59:38.640 --> 00:59:43.840]   into Facebook that defines what a social network is. I like from a creative perspective that there's
[00:59:43.840 --> 00:59:48.560]   some other people out there saying, no, it can also be this. So it doesn't need to be about taking
[00:59:48.560 --> 00:59:53.520]   down Facebook. There's some value to creating something different from Facebook for people
[00:59:53.520 --> 00:59:58.000]   for whom that matters. And on that. On our tunday, I am so unfriending you on L.O. right now.
[01:00:01.760 --> 01:00:08.800]   I don't know. That's it. I do think that when new social networks start, they have one advantage,
[01:00:08.800 --> 01:00:14.880]   which is that only us, only the insiders use it and we like each other and then the real world
[01:00:14.880 --> 01:00:20.160]   comes and then I have to go somewhere else. You're just constantly running from real people.
[01:00:20.160 --> 01:00:27.600]   No, here's the thing. I think I totally get it. But the reality is, we make a choice every
[01:00:27.600 --> 01:00:34.000]   single day to log into our Gmail and to all of these things and to our iPhone and to Instagram.
[01:00:34.000 --> 01:00:37.600]   And because we enjoy them and we have fun, even though we know we're being tracked, we're no
[01:00:37.600 --> 01:00:41.440]   ads are being put against the things that we're writing. But yet we still do it. And I think that,
[01:00:41.440 --> 01:00:46.560]   do I truly believe that the privacy problem on the internet without a doubt? I have no question.
[01:00:46.560 --> 01:00:50.800]   I've written a thousand articles on it. But I also think that the kind of ship is already,
[01:00:50.800 --> 01:00:57.200]   what's that? A thousand articles, really? Really? I'm privacy probably. Go ahead, keep going.
[01:00:58.080 --> 01:01:03.680]   But I actually do believe that the ship has sailed. And I think that, you know,
[01:01:03.680 --> 01:01:08.320]   there, so part of the reason that L.O. grew out of Facebook was because there were people that
[01:01:08.320 --> 01:01:12.160]   were transgender that weren't able to use their... That's why I got a lot of attention lately,
[01:01:12.160 --> 01:01:17.360]   is that Facebook has been with its real names policy, making it very hard for LGBT people
[01:01:17.360 --> 01:01:24.640]   to have a place on Facebook because they have many cases, real reasons not to use their real names.
[01:01:24.640 --> 01:01:29.200]   Correct. But what happened was... You want to be sister Mary Duncan Donuts on Facebook, you can't.
[01:01:29.200 --> 01:01:34.480]   Unless that's on your driver's license, then you got much bigger problems.
[01:01:34.480 --> 01:01:40.080]   So I completely agree. And that's what happened. And then what happened after that was a bunch of
[01:01:40.080 --> 01:01:47.040]   people went over there and people from the LGBT society, like the groups that went over there,
[01:01:47.040 --> 01:01:51.280]   there's no way to block people. So what started happening is you had all these haters that came
[01:01:51.280 --> 01:01:56.080]   on certain, saying really negative and mean things. And then they couldn't use L.O. because there's no
[01:01:56.080 --> 01:02:00.000]   system to block people on there. So it kind of all backfired. Oh, that's interesting.
[01:02:00.000 --> 01:02:04.480]   At that point in particular, that's another thing I'd love to get to. When you start,
[01:02:04.480 --> 01:02:09.280]   I think there's something that as much as Leo, your gripes, and even mine about Facebook,
[01:02:09.280 --> 01:02:13.440]   like they are mature enough to be experimenting at a whole nother level. Yeah, of course.
[01:02:13.440 --> 01:02:18.560]   And so like even the idea of a managed news feed, like if they actually showed you everything,
[01:02:18.560 --> 01:02:22.160]   if you have a thousand friends, say you have like friended people a lot over the years,
[01:02:22.160 --> 01:02:24.880]   it would be a horrible experience problem. So I give them credit.
[01:02:24.880 --> 01:02:29.840]   Use your blocking to the to or trying. They're going to put that's on there coming soon.
[01:02:29.840 --> 01:02:32.560]   List it's number one. And the next thing they want to do is use your block.
[01:02:32.560 --> 01:02:37.280]   So for a company like L.O. to enter this late into the game, what social networking mean,
[01:02:37.280 --> 01:02:41.760]   but we've all been trained. And it comes with these features. There's a reporting mechanism
[01:02:41.760 --> 01:02:46.320]   that there's a way to filter and to not have that from ground zero, like the starting line,
[01:02:46.320 --> 01:02:48.080]   I feel like it's been moved forward.
[01:02:48.080 --> 01:02:52.400]   Is it late in the game? Are we really at the beginning of the internet? Isn't this really
[01:02:52.400 --> 01:02:55.120]   the beginning? You guys are just jaded. It's not late in the game.
[01:02:55.120 --> 01:03:00.080]   We're at the beginning of the internet, but we're not in the beginning of social network.
[01:03:00.080 --> 01:03:03.600]   Hell yeah. I mean, what wakes you think that in 20 years,
[01:03:03.600 --> 01:03:09.440]   Facebook or Twitter will even be around? You think that they're here to stay? This is,
[01:03:09.440 --> 01:03:12.080]   it's done? If it is, then I'm depressed.
[01:03:14.080 --> 01:03:18.880]   I think that there will be other Facebooks and Twitter's, but I can, I guarantee you,
[01:03:18.880 --> 01:03:23.920]   in 20 years, Facebook is still around. And if Twitter is still around, maybe it's part of
[01:03:23.920 --> 01:03:27.440]   Google or something like that, if it gets acquired eventually or something. But like,
[01:03:27.440 --> 01:03:31.760]   but I don't think that any incumbent can come along. I'd agree with you. Nobody can be Google
[01:03:31.760 --> 01:03:35.760]   anymore, but that's more about a technical issue. It's hard to do an index of something
[01:03:35.760 --> 01:03:39.040]   that's growing as fast. So here's, okay. So, but I think social networking,
[01:03:39.040 --> 01:03:43.680]   look how fast my space got to center mediate and look how much people hate Facebook. People
[01:03:43.680 --> 01:03:47.920]   use Facebook, but often they, they're not happy about it.
[01:03:47.920 --> 01:03:52.720]   We live in a world where we're dependent on them both, right? In the media, do I,
[01:03:52.720 --> 01:03:57.120]   I hate, I hate going on to social networks, you know, first thing in the morning and checking to
[01:03:57.120 --> 01:04:00.480]   see what nasty things people have said about me and my calm and this, that and the other.
[01:04:00.480 --> 01:04:05.440]   But I do it because that's how I share my content. It's, I, it's, I have no choice. It is the paper
[01:04:05.440 --> 01:04:12.880]   of today. And if Elo suddenly gets a sufficient subscriber, you'll start visiting them. I mean,
[01:04:12.880 --> 01:04:17.280]   it's just a matter of critical mass. I don't know why they can't get critical mass or any other
[01:04:17.280 --> 01:04:22.480]   new network. I think we'll wait too early. I think we're way too early for a statement like
[01:04:22.480 --> 01:04:28.000]   Facebook will definitely be around in 20 years to be taken as fact. Like that is, to me, I will,
[01:04:28.000 --> 01:04:31.200]   I will bet against you on the show right now. I think it'll be a safe bet. Go ahead. How much
[01:04:31.200 --> 01:04:37.600]   you want to be in the year 2034, 2034, 28th of September, 20. I will be dead. We can get on that.
[01:04:37.600 --> 01:04:42.640]   Okay. What else? Facebook. Yeah. And they say, by the way, I'll be glad to be dead if Facebook
[01:04:42.640 --> 01:04:47.360]   still around. I would, I'll be looking at you from the grave going, God damn you guys, couldn't
[01:04:47.360 --> 01:04:51.440]   you do better than this? I would like to bet with you, Bartenday, but there are rules at the New
[01:04:51.440 --> 01:04:59.520]   York Times and apparently, you know what? It doesn't matter. He pulled the New York Times card.
[01:04:59.520 --> 01:05:07.840]   I'm not working at the New York Times in 20 years. Retroactively bet you a large amount of money
[01:05:08.400 --> 01:05:12.960]   and big. I just think, you know, to Leo's point, like the speed at which we're moving,
[01:05:12.960 --> 01:05:18.960]   something will we can not, we technically, I don't even think have the ability to imagine,
[01:05:18.960 --> 01:05:24.560]   I agree, of what our world will look like. The idea that a company called Facebook could be so
[01:05:24.560 --> 01:05:30.160]   adaptable to do like holographic burrito delivery or whatever becomes the thing.
[01:05:30.160 --> 01:05:34.640]   If you look at the history of tech companies, they try, they try, they really do Microsoft
[01:05:34.640 --> 01:05:41.600]   tried, IBM tried, and they last, but it's very hard to stay on the forefront. And I think Google
[01:05:41.600 --> 01:05:46.320]   won't be on the forefront. I don't think Apple's already started to lose its edge. And I very,
[01:05:46.320 --> 01:05:50.400]   be very surprised. I'm not saying they'll be gone, but it'd be very surprising Facebook is the
[01:05:50.400 --> 01:05:55.760]   dominant incumbent that it is today. All right, let's continue on with our best of, and just a second,
[01:05:55.760 --> 01:06:02.000]   big Supreme Court decision. But before we go on, I want to tell you a little bit about audible.com.
[01:06:02.000 --> 01:06:09.360]   Audible, Audible, Audible, Audible Books, our audio books, 150,000 strong, all the big books,
[01:06:09.360 --> 01:06:13.920]   every new book that comes out is available in Audible. They've even gone back in time to take a
[01:06:13.920 --> 01:06:19.280]   look at some of the great, for instance, sci-fi books or classics by Dickens and Jane Austen,
[01:06:19.280 --> 01:06:23.760]   that were never recorded, and they've done their own recordings of them. They sound so good.
[01:06:23.760 --> 01:06:30.000]   Audible chooses the best readers. They bring these books to life. You're listening in the car at
[01:06:30.000 --> 01:06:36.240]   work, at the gym, cleaning the house, walking the dog. But those books, it's as if you're almost
[01:06:36.240 --> 01:06:42.880]   watching a movie in your mind. They come to life. Fiction, non-fiction. Audible is the best place to
[01:06:42.880 --> 01:06:48.560]   get audio books. I want you to visit Audible.com right now and sign up for their platinum plan.
[01:06:48.560 --> 01:06:53.760]   You can get it free for the first 30 days, which is awesome. This is two books a month. It's a
[01:06:53.760 --> 01:06:58.800]   subscription. Plus the Daily Digest of the Wall Street Journal or the New York Times. Audible has
[01:06:58.800 --> 01:07:02.880]   got so many great books. Having two books a month is nice because it gives you the chance
[01:07:02.880 --> 01:07:08.400]   to pick up two books. It makes it easier to decide. That's really the hardest thing for me.
[01:07:08.400 --> 01:07:12.720]   I visit Audible and I go, "I want that. Oh, I want that. In fact, I've got two credits waiting for me
[01:07:12.720 --> 01:07:19.280]   right now." Even with two credits having a hard time deciding, Audible is so fantastic. Please
[01:07:19.280 --> 01:07:23.200]   give it a try today. With two books, you can get a really good sense of whether Audible is right
[01:07:23.200 --> 01:07:30.560]   for you. Visit Audible.com/twit2. It's free for the first 30 days. Cancel any time in those first 30
[01:07:30.560 --> 01:07:38.240]   days. You'll pay absolutely nothing. But those books are yours to keep and that's nice. Audible.com/twit
[01:07:38.240 --> 01:07:46.000]   and the number two. We are big fans of audiobooks from Audible.com. I know you will be too. Please
[01:07:46.000 --> 01:07:50.320]   take advantage of this offer. If you haven't tried it yet, the holidays are a great time to curl up
[01:07:50.320 --> 01:07:58.160]   with a great audiobook from Audible.com. Just go to Twit2 and you'll get it automatically. Audible.com/twit2.
[01:07:58.160 --> 01:08:04.880]   We thank Audible so much for their support all year long in fact for the last six years, seven years
[01:08:04.880 --> 01:08:12.160]   for a long time of this weekend tech. We geomews came out just this week in the United States
[01:08:12.160 --> 01:08:19.760]   that the Canadian Supreme Court had ruled that it was okay for Canadian police during a traffic stop,
[01:08:19.760 --> 01:08:25.920]   during an arrest to look at your cell phone without a warrant. Fortunately, that's not the case in the
[01:08:25.920 --> 01:08:33.120]   United States. We discussed it with legal expert Denise Howell on this segment from this year's
[01:08:33.120 --> 01:08:40.800]   I think this is very good news for privacy in this country. Even if you have been arrested,
[01:08:40.800 --> 01:08:49.040]   the police still must seek in most cases a warrant before they can search your cell phone.
[01:08:49.680 --> 01:08:54.560]   We know law enforcement actually has boxes they can plug into your phone and dump all the data off
[01:08:54.560 --> 01:08:59.680]   of it and they do often routinely do that. But the Supreme Court ruled Wednesday that
[01:08:59.680 --> 01:09:06.720]   this is you got to get a warrant. Is that good? Denise? It's fabulous. Riley versus California
[01:09:06.720 --> 01:09:14.320]   is the case. Unanimous decision of the Supreme Court, which you get a lot of court watchers
[01:09:14.320 --> 01:09:21.280]   saying what that means and if it's really and truly unanimous or if you suggest Leo there,
[01:09:21.280 --> 01:09:27.760]   they're just ready to get back with that term on. I'll trade you an area for a cell phone.
[01:09:27.760 --> 01:09:39.520]   Yes, here we have the court actually really showing a good grasp of what new technologies mean
[01:09:39.520 --> 01:09:44.880]   and how they impact people's lives and the difference between being able to search someone's pocket
[01:09:44.880 --> 01:09:52.400]   for a weapon or something else that might hurt an officer during an arrest or something else that
[01:09:52.400 --> 01:09:58.560]   might be informationally important to the arrest evidence that you could gather just by
[01:09:58.560 --> 01:10:03.600]   you know, fine. It's all on my phone. Exactly. No, you're going to you're going to find lots of
[01:10:03.600 --> 01:10:08.640]   evidence on somebody's phone, but it's going to be stuff that not only could convict them that is
[01:10:08.640 --> 01:10:13.680]   going to be a lot of other stuff too. So the case was a guy who was stopped for a traffic violation.
[01:10:13.680 --> 01:10:20.400]   They I guess must have given the probable cause seen weapons. He was he was arrested on weapons
[01:10:20.400 --> 01:10:27.360]   charges. The officer searching him seized a phone from his pants pocket. The officer accessed
[01:10:27.360 --> 01:10:31.760]   information on the phone. Notice the repeated use of a term associated with a street gang
[01:10:31.760 --> 01:10:37.440]   at the police station two hours later a detective specializing in gangs further examined the phone's
[01:10:37.440 --> 01:10:42.800]   contents based on photographs and videos that detective found the state charged the
[01:10:42.800 --> 01:10:47.200]   petitioner in connection with a shooting that had occurred a few weeks earlier and saw it and
[01:10:47.200 --> 01:10:57.040]   enhanced sentence based on gang membership. He was he was convicted then appealed California
[01:10:57.040 --> 01:11:03.040]   Court of Appeals affirmed. But the Supreme and the California Supreme Court, but not the United
[01:11:03.040 --> 01:11:08.320]   States Supreme Court unanimously. They said that was unlawful search and seizure.
[01:11:08.320 --> 01:11:17.200]   So what do we need to do now as citizens if we are stopped by the police and they say,
[01:11:17.200 --> 01:11:24.000]   can I have your phone? Should we just say no? Yeah, you can you can right in front of them.
[01:11:24.000 --> 01:11:27.120]   I'll say, you know, in Riley versus State of California,
[01:11:28.480 --> 01:11:34.000]   smashing it. You eat it. You eat the phone. You could have obstruction charges against you
[01:11:34.000 --> 01:11:38.080]   under those kinds of circumstances. Don't do that either. Okay. But yeah, without a warrant,
[01:11:38.080 --> 01:11:42.320]   they can't search your phone. So if you've done something wrong, give them the phone.
[01:11:42.320 --> 01:11:47.440]   Let them say, Oh, officer, no, you're not allowed to search that. But here, and then they throw
[01:11:47.440 --> 01:11:53.040]   the whole thing out of court. Justice Roberts wrote modern cell phones. I love this are not
[01:11:53.040 --> 01:11:58.320]   just another technological convenience with all they contain and all they may reveal they hold
[01:11:58.320 --> 01:12:04.560]   for many Americans, the privacies of life. The fact that technology now allows an individual to carry
[01:12:04.560 --> 01:12:11.040]   this in his hand does not make the information any less worthy of protection. I love that. That's
[01:12:11.040 --> 01:12:15.840]   right on. And also, like how he said that the term cell phone itself is pretty much outdated and
[01:12:15.840 --> 01:12:21.280]   do that. These are effectively cameras or journals or, you know, any sort of thing that should and is
[01:12:21.280 --> 01:12:25.600]   normally protected by law. And I thought that was a great point that he made as well. So this
[01:12:25.600 --> 01:12:30.240]   according to the daily dot, this review reverses a five decades old interpretation of the law that
[01:12:30.240 --> 01:12:35.840]   allowed arresting officers to search suspects, pockets, phones and anything else within his or her
[01:12:35.840 --> 01:12:46.480]   reach. So it's this is this is kind of new law. Yes, they were. Yeah, and they can. They can
[01:12:46.480 --> 01:12:54.160]   still, you know, the seat of your car, your pocket, they can pat you down. You know, if the safety
[01:12:54.160 --> 01:13:01.040]   concern of the officers has always been behind, you can go ahead and do a search incident to
[01:13:01.040 --> 01:13:06.080]   arrest. But if you're going to search a cell phone, this decision says you're going to need to get a
[01:13:06.080 --> 01:13:12.720]   warrant. And law enforcement was not wild about this decision and fought it because they said, well,
[01:13:12.720 --> 01:13:18.000]   particularly in today's day and age, getting a warrant is not going to be effective because
[01:13:18.000 --> 01:13:23.440]   what if someone just, you know, you've got Apple, they've got this great remote wipe. Android does
[01:13:23.440 --> 01:13:30.800]   it too. We're going to have our evidence destroyed. And the court, you know, really showed a nice
[01:13:30.800 --> 01:13:36.400]   grasp, not only of the nature of the cell phone, but of how these things work in the decision.
[01:13:36.400 --> 01:13:44.320]   talks about as to remote wiping, there are means to address that. First of all, you could turn the
[01:13:44.320 --> 01:13:49.760]   phone off. Then it can't be wiped. Bear that in mind, law enforcement officers. And also,
[01:13:49.760 --> 01:13:55.360]   you could use a Faraday bag. Would you ever have expected? I have one of those Faraday bag in a
[01:13:55.360 --> 01:13:59.920]   US Supreme Court decision. The fact that they know such a thing exists is awesome. Obviously,
[01:13:59.920 --> 01:14:04.640]   it was some smart clerk, right, who wrote this decision. Such devices are commonly called Faraday
[01:14:04.640 --> 01:14:10.080]   bags. After the English scientist, Michael Faraday, they are essentially sandwich bags made of
[01:14:10.080 --> 01:14:15.680]   aluminum foil, cheap, lightweight, and easy to use. And it's show you then, then they cite the
[01:14:15.680 --> 01:14:20.240]   brief of the criminal law professors that filed this in amicus brief. So they're reading their
[01:14:20.240 --> 01:14:25.600]   briefs and they know what this stuff is. Or a clerk is, yes. Yes. They this may not be a complete
[01:14:25.600 --> 01:14:31.040]   answer to the problem, but at least for now, they provide a reasonable response. And they talk about
[01:14:31.040 --> 01:14:37.440]   that not only the law enforcement agencies know what Faraday bags are and use them and encourage
[01:14:37.440 --> 01:14:41.440]   officers to use them, but they talk about the fact that a warrant is a lot easier to get than it
[01:14:41.440 --> 01:14:48.160]   used to be to. And that unfortunately, and that a lot of law enforcement officers can talk about,
[01:14:48.160 --> 01:14:54.640]   you know, can rely on like a 15 minute electronic email response to a request for a warrant. So,
[01:14:54.640 --> 01:15:00.560]   we're not talking about a whole lot of hoops that need to be jumped through here. The daily dot says
[01:15:00.560 --> 01:15:06.160]   in answer to the question, what should you do? Lock your phone with a passcode. If your phone is
[01:15:06.160 --> 01:15:10.240]   locked and or encrypted, according to the ACLU, the police may take your phone, may try to look at
[01:15:10.240 --> 01:15:15.520]   it on constitutionally, but they won't be able to. They can't force you to put your finger on the
[01:15:15.520 --> 01:15:20.240]   detector. Yeah. If you forgot to lock your phone and don't feel like it, then calmly and
[01:15:20.240 --> 01:15:26.560]   respectfully, this will work. Tell the officer searches in violation of the Constitution under the
[01:15:26.560 --> 01:15:34.880]   court's Riley decision. Yeah. I mean, that daily dot article has some great advice about saying,
[01:15:34.880 --> 01:15:40.480]   look, if you want to search my phone, you need a warrant for that. If they want to go ahead,
[01:15:40.480 --> 01:15:46.080]   though, and do it, that same article says, just go ahead and let them do it. You know what the lie is.
[01:15:46.080 --> 01:15:51.200]   Right. But you should out loud state, I do not consent to this search and make sure the witness
[01:15:51.200 --> 01:15:55.680]   is here. I do not want to make this clear. I do not consent to this search because then
[01:15:55.680 --> 01:16:00.800]   whatever they find is inadmissible. I got a good question from someone on Twitter along
[01:16:00.800 --> 01:16:06.640]   these lines. His name was Mark Jones. He was sort of keying into the fact that not only do we keep
[01:16:06.640 --> 01:16:11.440]   everything on our cell phones, but we have things like boarding passes and in his particular case,
[01:16:11.440 --> 01:16:20.000]   I guess, his insurance card for showing that he has auto insurance on his cell phone and asking,
[01:16:20.000 --> 01:16:24.320]   if you show that to an officer on your phone, are you giving up your privacy rights to anything
[01:16:24.320 --> 01:16:33.120]   else on the phone? I certainly don't think so. First of all, you have to be, if you're under arrest,
[01:16:33.120 --> 01:16:38.080]   it's the only way that there could even be an issue about an officer's ability to search your
[01:16:38.080 --> 01:16:46.320]   phone without a warrant. And just handing an officer an unlocked phone to show a particular item on
[01:16:46.320 --> 01:16:51.360]   there, I don't think is communicating consent to search the phone. But again, you might want to say
[01:16:51.360 --> 01:16:55.600]   when you're handing the phone over, "Hey, I don't consent to you searching the whole phone."
[01:16:55.600 --> 01:17:00.160]   Also, my mention that the Electronic Frontier Foundation and the ACLU have pages called Know
[01:17:00.160 --> 01:17:07.200]   Your Rights, where you could print a PDF about what the police can and cannot do. I presume updated
[01:17:07.200 --> 01:17:13.040]   thanks to this most recent decision. And also a PDF of tips when confronted by the police.
[01:17:13.040 --> 01:17:19.680]   The thing I want to emphasize, this is not designed to somehow get gang members off
[01:17:20.560 --> 01:17:25.760]   because the police do have the ability to ask for a warrant to put the thing in a fair-a-day box.
[01:17:25.760 --> 01:17:35.040]   If there really is a crime, the police can pursue it. This is to protect our privacy against an
[01:17:35.040 --> 01:17:41.200]   overreaching police state. And this is good tips for talking to the police. I hope it's
[01:17:41.200 --> 01:17:47.040]   there's a great long YouTube video by you should never ever talk to the police.
[01:17:49.520 --> 01:17:57.360]   I recommend it. I refer you to if you want to know more. I certainly made sure my kids knew it.
[01:17:57.360 --> 01:18:04.080]   So good news. Privacy rights are protected. What do you think in the light of these two
[01:18:04.080 --> 01:18:09.280]   decisions? A lot of people were mocking the Supreme Court in the area saying, "Oh, they're
[01:18:09.280 --> 01:18:13.280]   clearly technologically out of touch." I actually thought in the oral arguments,
[01:18:13.280 --> 01:18:18.080]   most of them, not all of them, but most of them were pretty in touch. So do my art show to real
[01:18:18.080 --> 01:18:22.160]   understanding of how this stuff works. I think she knew about Roku boxes and Netflix.
[01:18:22.160 --> 01:18:29.520]   I think in this privacy thing, they seem very much in touch with what a cell phone is and
[01:18:29.520 --> 01:18:34.000]   why it's important to protect. They seem like they are in touch. Yes, Denise?
[01:18:34.000 --> 01:18:39.840]   Yeah, I think they're more in touch than people give them credit for. I do think
[01:18:41.120 --> 01:18:49.200]   you're talking about people in an older demographic who are still incorporating these tools in their
[01:18:49.200 --> 01:18:56.560]   own life and trying to grasp how they work and what they mean and doing their best with it.
[01:18:56.560 --> 01:19:03.280]   And they have really smart clerks as you pointed out, Leo. I think they do a pretty darn good job.
[01:19:05.120 --> 01:19:12.400]   The copy shop with the library card is something a cable company when it's clearly not.
[01:19:12.400 --> 01:19:19.120]   They've got some hurdles to overcome still and it would be wonderful if we could get someone
[01:19:19.120 --> 01:19:27.520]   truly versed in what technology means and how it works and the legal considerations around it on
[01:19:27.520 --> 01:19:34.160]   the court. I think we're still waiting for that one. A perfect guy to have on during heart bleed,
[01:19:34.160 --> 01:19:38.080]   weak Rishnair is here. Hi, Bruce. Hey, hi. Great to have you.
[01:19:38.080 --> 01:19:44.720]   So at the beginning of the week, you said on a scale of one to 10, heart bleed is an 11.
[01:19:44.720 --> 01:19:48.640]   A very serious flaw. It's funny. We thought this would be the week we'd be talking about
[01:19:48.640 --> 01:19:55.760]   XP exploits. No. Well, it turns out you never know. These things happen kind of at random.
[01:19:55.760 --> 01:20:02.240]   Heart bleed, it was real interesting because for a whole lot of reasons, one, it was potentially
[01:20:02.240 --> 01:20:09.360]   catastrophic. It affected an enormous number of servers out there and you can weaponize it with
[01:20:09.360 --> 01:20:15.520]   like three lines of shell scripts. I had colleagues who were up and running and scanning and attacking
[01:20:15.520 --> 01:20:20.640]   systems within 10 minutes of learning about it. Wow. So it was a big deal. It still is a big deal.
[01:20:20.640 --> 01:20:30.400]   You were able to send a packet using this heartbeat technique built into OpenSSL a couple of years ago.
[01:20:30.400 --> 01:20:38.080]   You're able to send a malformed packet that requests data up to 64k from memory of the server.
[01:20:38.080 --> 01:20:41.760]   Right? It's what it, but it has to, you can't be specific. It's whatever is there.
[01:20:41.760 --> 01:20:46.640]   Yeah, it has to do with what, how the heaps working and it's kind of random what you get,
[01:20:46.640 --> 01:20:54.560]   but you can query that 64k multiple times and you get different data. You don't always get the same.
[01:20:54.560 --> 01:21:00.080]   So if you're looking to get everything on the computer, you just do it again and again.
[01:21:00.080 --> 01:21:04.640]   Turns out you actually can't get everything. There are some weird reasons why some data
[01:21:04.640 --> 01:21:09.200]   comes and some data doesn't, we're still exploring that. But potentially when we heard about this,
[01:21:09.200 --> 01:21:15.120]   you can basically grab everything and it left no trace. There's nothing in an audit log that said
[01:21:15.120 --> 01:21:21.040]   that you were attacked, which made it really scary and we had to fix it quick.
[01:21:21.040 --> 01:21:24.880]   Yeah, the fact that this has been around for two years, it's conceivable that somebody
[01:21:24.880 --> 01:21:30.480]   knew about it two years ago and has been just pinging servers. How rapidly can you do this?
[01:21:30.480 --> 01:21:35.680]   I guess every second or faster. Yeah, you can do it as fast as you can. And it turns out you can
[01:21:35.680 --> 01:21:41.360]   ping the entire internet and see who's vulnerable in about 15, 20 minutes, spending on your setup.
[01:21:41.360 --> 01:21:45.760]   Wow. So a bunch of research I've been doing that and we can watch the decay of sites that are
[01:21:45.760 --> 01:21:53.120]   vulnerable. We do know that we have good evidence that before the announcement, nobody was doing
[01:21:53.600 --> 01:21:59.600]   a sweep of the internet looking to see who's vulnerable. So we have data from servers,
[01:21:59.600 --> 01:22:05.600]   from honeypots that we've been able to comb through and I've seen no one use heart bleed
[01:22:05.600 --> 01:22:11.040]   at a global basis before that. We have no idea if they were targeted attacks.
[01:22:11.040 --> 01:22:16.720]   But that's very good news. That means it seems unlikely that this is a vulnerability known in
[01:22:16.720 --> 01:22:22.720]   the hacker community. They'd be scanning sites looking for vulnerabilities. A targeted attack,
[01:22:22.720 --> 01:22:26.400]   well, at least it's unlikely that you and I were a target.
[01:22:26.400 --> 01:22:30.560]   Indeed, right? The good news is the hacker community did not know about this, it seems.
[01:22:30.560 --> 01:22:36.800]   We started seeing scans within minutes of the announcement, but before that we saw nothing.
[01:22:36.800 --> 01:22:42.480]   So that's the good news. The other good news is that subsequent research over the week has shown
[01:22:42.480 --> 01:22:48.720]   that while it's possible in theory and has been done in practice to retrieve the private SSL
[01:22:48.720 --> 01:22:53.360]   key, the master keys you're worried about, it's actually a lot harder than we originally thought.
[01:22:53.360 --> 01:22:54.720]   That's very good.
[01:22:54.720 --> 01:22:55.520]   That's a good piece of good news.
[01:22:55.520 --> 01:23:00.080]   Because the concern was that all of these secure servers, certificates have been compromised,
[01:23:00.080 --> 01:23:04.480]   allowing massive man in the middle attacks, that you're saying that seems unlikely.
[01:23:04.480 --> 01:23:10.560]   That seems unlikely. It's certainly possible. Cloudflare was a company that's been leading
[01:23:10.560 --> 01:23:16.320]   this research. They put up challenges. One of the challenges was met. So someone did manage to
[01:23:16.320 --> 01:23:19.840]   extract the keys, but it's not easy. It's not a slam dunk.
[01:23:19.840 --> 01:23:26.080]   So for the most part, what do you get? Passwords, logins, what are you getting in these 64K chunks?
[01:23:26.080 --> 01:23:32.320]   You get the random cruft of what the server is doing. So yes, you get password changes,
[01:23:32.320 --> 01:23:38.480]   you get web pages served. If there are credentials in the URLs, you get those,
[01:23:38.480 --> 01:23:42.800]   you get random stuff. You get a lot of nothing, but occasionally you get something good.
[01:23:42.800 --> 01:23:48.000]   And what we're seeing, that means the obvious tactic from a criminal who'd be using this,
[01:23:48.000 --> 01:23:51.360]   is you just scan everything constantly, hoping you get lucky.
[01:23:51.360 --> 01:23:56.640]   Now, there's some good news on our side. Some of this stuff is hard to parse.
[01:23:56.640 --> 01:24:05.520]   So it's sort of interesting to watch, and we don't know really what the effects are
[01:24:05.520 --> 01:24:10.560]   in terms of enabling crime. And it's, of course, it's now being patched.
[01:24:10.560 --> 01:24:16.240]   Now, a lot of the sites are no longer vulnerable. Now, vulnerable to the ping,
[01:24:16.240 --> 01:24:21.200]   there are any number of universities who are basically auditing the net every hour,
[01:24:21.200 --> 01:24:27.760]   and watching a site's patch, their open SSL. Now, that doesn't mean if they were compromised
[01:24:27.760 --> 01:24:32.880]   before the patch, they're not still vulnerable. They had to change their key and their certificate
[01:24:32.880 --> 01:24:35.680]   is no way to check that, but no easy way to check that.
[01:24:35.680 --> 01:24:42.240]   Right. So the initial estimate was about two thirds of the web would be,
[01:24:42.240 --> 01:24:46.880]   or if servers would be vulnerable to this. And is that accurate? And is the number,
[01:24:46.880 --> 01:24:53.040]   what is the number now? That is accurate. The number is probably 10% that, and it's skewed because
[01:24:53.040 --> 01:25:00.640]   all of the big popular well-run servers have updated. A lot of the stuff that's left.
[01:25:01.280 --> 01:25:06.560]   I see a top 1000 sites that are vulnerable list that some university publishes,
[01:25:06.560 --> 01:25:11.200]   and the sites are getting more obscure every hour that are still vulnerable.
[01:25:11.200 --> 01:25:13.840]   Are there any big companies though that should have fixed it that haven't?
[01:25:13.840 --> 01:25:20.240]   I didn't see any, but I'm not going to guarantee there aren't.
[01:25:20.240 --> 01:25:21.200]   It's an easy fix.
[01:25:21.200 --> 01:25:26.800]   Like all of these patches, it's an easy fix. You install the patch. But closing the
[01:25:26.800 --> 01:25:31.200]   vulnerabilities in multi-step process. I mean, this is one of the reasons it was so nasty,
[01:25:31.200 --> 01:25:37.600]   is that installing the patches just step one, regenerating your public private keys or step two,
[01:25:37.600 --> 01:25:42.480]   revoking your old key as step three, getting a new key as step four. I guess you can switch three
[01:25:42.480 --> 01:25:48.720]   and four. And then every user on that site who could have had their credentials exposed
[01:25:48.720 --> 01:25:52.320]   needs to update their password, which is steps five through a million.
[01:25:53.200 --> 01:26:00.400]   And all of those things have to happen in sequence. I updated my own website and had to go through
[01:26:00.400 --> 01:26:06.400]   all those steps, but for me it was pretty easy. If you're a banking site, at a minimum,
[01:26:06.400 --> 01:26:12.800]   any customer who logged on between when the vulnerability became public and when the site was
[01:26:12.800 --> 01:26:19.040]   patched needs to update their password. And there might be nothing but that's just prudence.
[01:26:19.040 --> 01:26:22.320]   It's prudent. And the good news is it's not a bad thing to do once in a while anyway.
[01:26:22.960 --> 01:26:28.320]   It isn't. But you know, we all have passwords that we rarely use and we remember, we don't like
[01:26:28.320 --> 01:26:36.320]   doing this. But I think it's safe that if you didn't log into the server between when the
[01:26:36.320 --> 01:26:41.840]   vulnerability was announced on Monday and when your server patched a few days later,
[01:26:41.840 --> 01:26:46.800]   you're okay. So those obscure sites you haven't been to in a week or two, I think you're fine at
[01:26:46.800 --> 01:26:50.480]   this point. And second factor authentication hasn't been compromised. Is that right?
[01:26:51.920 --> 01:26:58.720]   No, I mean, what's been compromised is the public key potentially, although it seems unlikely.
[01:26:58.720 --> 01:27:07.040]   And stuff that happened to happen on the server when someone did the ping. So if you got unlucky,
[01:27:07.040 --> 01:27:13.920]   your data was in the heap at the time the bad guys did the scan, it was compromised potentially.
[01:27:13.920 --> 01:27:18.720]   It's pretty random though. And it seems like unlikely that they've been mass compromises as a result.
[01:27:18.720 --> 01:27:24.480]   It's extraordinarily random. Mass is definitely unlikely. And it'll be individual.
[01:27:24.480 --> 01:27:31.280]   You know, I haven't seen yet anybody with any estimates on what sorts of crime has been
[01:27:31.280 --> 01:27:36.880]   a result of this. We know the hacker started pinging this vulnerability as soon as public.
[01:27:36.880 --> 01:27:40.800]   So they didn't waste it out. And it was actually triply easy. What's interesting, some of these
[01:27:40.800 --> 01:27:48.160]   other vulnerabilities, they're not in a computer to write to run arbitrary code. This one you can't.
[01:27:48.640 --> 01:27:53.200]   But this one you can really weaponize within a couple of minutes of learning about it. It's just
[01:27:53.200 --> 01:27:59.360]   so easy. Bloomberg said that two sources told them this was an NSA bug or that the NSA knew about
[01:27:59.360 --> 01:28:05.200]   it and had been using it for two years given its utility. That seems highly unlikely.
[01:28:05.200 --> 01:28:10.160]   You know, so we're all debating this right now. Right. There was a Bloomberg article that said
[01:28:10.160 --> 01:28:15.920]   two anonymous sources of the NSA knew this for two years. NSA came out with actually the
[01:28:15.920 --> 01:28:21.200]   director of national intelligence on his blog came out with a very strong denial. This is untrue.
[01:28:21.200 --> 01:28:29.360]   You know, answer is we don't know. It seems unlikely. This vulnerability is so big and so nasty.
[01:28:29.360 --> 01:28:37.280]   And I United States and other democratic countries, I think, are so vulnerable that it would make a
[01:28:37.280 --> 01:28:42.880]   lot of sense of the NSA if they found this to alert the community and get this closed.
[01:28:42.880 --> 01:28:50.240]   It's a bigger risk to us than it is value. Certainly, the NSA probably got an advanced notice of a
[01:28:50.240 --> 01:28:56.000]   week or so like some of the big companies. I mean, they, I hope they took it and ran with it and
[01:28:56.000 --> 01:29:02.480]   attacked everybody they could during that week. They've done not. Right. Mine is wild. Who knows
[01:29:02.480 --> 01:29:06.880]   what you're going to get. But that's what you do, right? They're good at phishing expeditions.
[01:29:06.880 --> 01:29:11.280]   Notice of of Microsoft bugs that are being fixed to the next patch. That's right. That's right.
[01:29:11.280 --> 01:29:14.960]   And they just run with them for the week and two they have. That makes perfect sense. We want them
[01:29:14.960 --> 01:29:20.720]   to do that. I'm curious. I saw Google said that honey, one version of Android was vulnerable,
[01:29:20.720 --> 01:29:24.960]   411. How could Android be vulnerable at all to this? It's not a server.
[01:29:24.960 --> 01:29:30.880]   Well, anybody that's using open SSL and responding to pings is vulnerable.
[01:29:30.880 --> 01:29:37.200]   I'm when I'm worried most about right now are some of the hardware devices. The routers.
[01:29:37.200 --> 01:29:45.520]   Lost, unpatable routers and switches and modems were upgrading involves the trash can a credit
[01:29:45.520 --> 01:29:50.880]   card a trip to Best Buy. Right. That's not going to be fun. These things are laden with problems.
[01:29:50.880 --> 01:29:56.080]   We've seen so many problems on these inexpensive routers. So, I mean, it's because the economics
[01:29:56.080 --> 01:30:02.000]   is different. Right. I mean, essentially, they're like the computers were in the mid 90s, but they're
[01:30:02.000 --> 01:30:07.680]   very low cost, very low engineering expertise. They're not built with the same care. They're
[01:30:07.680 --> 01:30:13.200]   not as robust. So, they're built as throwaway devices, yet they have these enormous vulnerabilities.
[01:30:13.200 --> 01:30:21.760]   And in the mid 90s, we got a whole community to embrace quick patching and open vulnerability,
[01:30:21.760 --> 01:30:27.200]   disclosure and all of these things that made us safer. It's really hard to imagine the same
[01:30:27.200 --> 01:30:32.960]   systems working on these on your refrigerator just because nobody cares very much.
[01:30:32.960 --> 01:30:38.320]   Bruce, do you think this is some have said is an indictment of open source software that people
[01:30:38.320 --> 01:30:44.240]   can commit the guy who did this as a German software developer who I mean, we know who it is
[01:30:44.240 --> 01:30:49.120]   because there's a commit log. Right. And he's been interviewed and he's been, you know, he's,
[01:30:49.120 --> 01:30:53.440]   I'm sure really embarrassed about this. You know, it's not an indictment of open source software.
[01:30:53.440 --> 01:30:58.960]   It's an indictment of software that isn't independently analyzed. This could have easily happened in
[01:30:58.960 --> 01:31:04.560]   closed source in the proprietary software could easily have been thrown out there. The problem was
[01:31:04.560 --> 01:31:11.200]   nobody was doing the analysis. And any software open or closed needs to be analyzed. Open software
[01:31:11.200 --> 01:31:18.080]   is more secure because it can be looked at by more people because it's harder to slip in something
[01:31:18.080 --> 01:31:24.800]   like this unnoticed. But open source doesn't magically mean someone's going to look at it. Right. And
[01:31:24.800 --> 01:31:31.840]   this seemed to have fallen through the cracks. It was incredibly pivotal, important, critical piece
[01:31:31.840 --> 01:31:37.680]   of code that's just being maintained by a few guys in their spare time. Now good for them and
[01:31:37.680 --> 01:31:44.960]   I'm glad they're doing it, but they can use some backup. Yeah, I feel bad for Robin Segalman, who's
[01:31:44.960 --> 01:31:52.160]   the German who introduced the flaw. And he just said, I forgot to validate a variable
[01:31:52.160 --> 01:31:56.640]   containing a length. It's just, you know, I missed it. And that happens all the time itself.
[01:31:56.640 --> 01:32:00.480]   It happens all the time. Now, something interesting to ask. I mean, if we're going to speculate about
[01:32:00.480 --> 01:32:07.120]   the NSA, I mean, they spend millions of dollars searching for vulnerabilities every year in critical
[01:32:07.120 --> 01:32:12.160]   software. If they didn't find this one, you know, maybe we should wonder how well our money's being
[01:32:12.160 --> 01:32:18.080]   spent. This is like, you can't get more critical than the open SSL library used by two sides of
[01:32:18.080 --> 01:32:22.560]   all the servers. Somebody in the NSA would have looked at it and would have checked for all of
[01:32:22.560 --> 01:32:26.800]   these sorts of bounds checking problems and would have noticed this. The fact that they didn't,
[01:32:26.800 --> 01:32:32.000]   or at least claim they didn't, is independently interesting. We've heard President Obama's,
[01:32:32.000 --> 01:32:36.880]   it turns out President Obama has said, well, the NSA will not have, if they find a flaw in software
[01:32:36.880 --> 01:32:42.640]   like this, and there's a compelling security argument, national security argument, for not
[01:32:42.640 --> 01:32:47.840]   exposing that flaw, then they can do that. In general, they will, but they do have an out.
[01:32:47.840 --> 01:32:53.920]   Well, you know, and this is all the weasel wording. Yeah. As long as the NSA's mission is
[01:32:53.920 --> 01:33:00.640]   primarily to eavesdrop on the entire planet, there will be a compelling reason to keep these
[01:33:00.640 --> 01:33:06.880]   vulnerabilities secret. A Japanese company, Obayashi is going to build a space elevator,
[01:33:06.880 --> 01:33:12.480]   should be up and running by 2050. Yeah, sure. My mind will be in a jar by then. Yeah, probably.
[01:33:12.480 --> 01:33:17.200]   But you could put that jar in an elevator and send it to space. Send it to the moon.
[01:33:17.200 --> 01:33:24.880]   A lot of science fiction is posited that instead of this, you know, the whole problem of space
[01:33:24.880 --> 01:33:30.400]   travel is the Earth's gravity. You used the word the posited. Yeah.
[01:33:30.400 --> 01:33:33.680]   Yeah. Is that is that an incorrect one? Why would you say posed or something?
[01:33:33.680 --> 01:33:37.680]   Positive. Positive. Isn't that correct? It sounds like leaving a dog,
[01:33:37.680 --> 01:33:43.200]   not deep pause somewhere. That's positive. I posit. Well, I'm just saying I just pointed
[01:33:43.200 --> 01:33:47.200]   out I'm sitting here with three writers. I'm not a writer. Do you ever use positive when you
[01:33:47.200 --> 01:33:57.040]   write? Never. Never. I'm just I'm just trying. I'm all for you, Leo. It is a verb. I'm trying to
[01:33:57.040 --> 01:34:04.800]   help. But forward as fact, put forward as a basis of argument. Yeah. It's like postulate,
[01:34:04.800 --> 01:34:11.040]   advanced, profound, submit, hypothesize, propose or assert. Which would you prefer of those?
[01:34:11.040 --> 01:34:18.080]   Here, let's play the audio. I don't know. Posit. Posit. Posit. It just sounds like
[01:34:18.080 --> 01:34:22.640]   deposited. Posit. I have to go into the bathroom. Yeah, positive. I'm pausing.
[01:34:23.200 --> 01:34:27.840]   Ex-fucks. I'm sorry. I'm getting the di--now I'll get blamed for taking the show off the track.
[01:34:27.840 --> 01:34:32.080]   Just by bringing this. All I remember is I was talking about a space elevator.
[01:34:32.080 --> 01:34:37.040]   I think space elevators are bogus. This is the idea is that the physics totally work.
[01:34:37.040 --> 01:34:41.760]   If you can make a material strong enough to run that cable and they--
[01:34:41.760 --> 01:34:45.600]   That's the volume. It's like diffusion, right? Yeah. It's always 30 years away. And that's
[01:34:45.600 --> 01:34:49.680]   actually what they say in this story is we think we can get the nanotubes strong enough to do this
[01:34:49.680 --> 01:34:56.400]   by about 2030. So really, it's just coming in 15 years. All according to Mr. Ishikawa,
[01:34:56.400 --> 01:35:00.160]   all you have to do is get something 100 times stronger than a steel cable.
[01:35:00.160 --> 01:35:06.320]   Yeah. No, it's physics work. No problem. The physics work. You drop a cable from space and tie it on
[01:35:06.320 --> 01:35:11.840]   at the equator somewhere and it's way cheaper than firing it. What is it in the bucket and then
[01:35:11.840 --> 01:35:16.160]   raise it up? Well, there's-- Yeah. You get in a bucket. Well, you've--
[01:35:16.160 --> 01:35:20.080]   Donut Earth. It's counterweighting. Something flying around. There's two buckets. There's two buckets.
[01:35:20.080 --> 01:35:26.000]   A couple of thousand kilometers. Yeah. And then for the next five weeks, you're being
[01:35:26.000 --> 01:35:29.920]   towed up the bucket. Oh, yeah. How fast is it? Well, it's not going to be very fast. Robotic cars
[01:35:29.920 --> 01:35:35.520]   powered by magnetic linear motors will carry people in cargo to a newly built space station
[01:35:35.520 --> 01:35:40.800]   at a fraction of the cost of rockets. It will take seven days to get there. No problem.
[01:35:40.800 --> 01:35:45.760]   It's expensive to build, but super cheap once you build it. Just in space, I guess.
[01:35:45.760 --> 01:35:50.000]   They can do it. It cares. Right now, we can make cables that strong, but we can only make them
[01:35:50.000 --> 01:35:54.240]   three centimeters long. Yeah, they need to be a little bit longer. Well, if you can do it for three,
[01:35:54.240 --> 01:35:58.400]   it's just a matter of time. This is one of those tiny space elevators. This is one of those things
[01:35:58.400 --> 01:36:03.040]   that it's like, you know, if they figure out a way to make this stuff, then it could totally
[01:36:03.040 --> 01:36:07.840]   change the technology of the 21st century, but it's probably more likely than not that they can't.
[01:36:07.840 --> 01:36:13.760]   But if they could, wow, that would be awesome. Yeah. It cost a space shuttle $22,000 per kilogram,
[01:36:13.760 --> 01:36:18.480]   because the rocket fuel is so expensive. It's a cake cargo in space for the space elevator,
[01:36:18.480 --> 01:36:22.720]   a couple hundred bucks. Yeah. Ah, that's the payoff of building this space elevator.
[01:36:22.720 --> 01:36:27.520]   Nothing. And why just have one? We should have them all over. Yeah, everywhere you can
[01:36:27.520 --> 01:36:31.280]   get to take a quick. And we're going to imagine the disaster movies, because then they're going to
[01:36:31.280 --> 01:36:34.880]   like crash the space elevator and the cable smash. It just comes like super
[01:36:34.880 --> 01:36:38.240]   awesome. Falling down and it's just okay. It's out the Golden Gate Bridge. Always done.
[01:36:38.240 --> 01:36:42.480]   And because what's the average space for that? Yeah, it's already up there.
[01:36:42.480 --> 01:36:45.920]   Then it's cheap to go like fly around. Yeah, because you're in space then.
[01:36:45.920 --> 01:36:50.640]   So there's no gravity. Well, you just, you know, you could take a can of Pam or like.
[01:36:50.640 --> 01:36:55.520]   Yeah, that's what we needed space. It's good for the environment to spray Pam.
[01:36:55.520 --> 01:37:01.200]   And when your brain's in the jar, it'll be a lot less wait for that. I like Pam, the Pam rocket.
[01:37:01.200 --> 01:37:04.880]   Giant Pam. Yeah, it's exactly. I'm going to the moon. See you later.
[01:37:04.880 --> 01:37:08.880]   Have a match in the Pam and you get a little get a little thrust off of that.
[01:37:08.880 --> 01:37:12.240]   That's good physics. No, for that you want to use final net hairspray.
[01:37:12.240 --> 01:37:18.000]   That would work. Very good. I don't know if we'll ever see a space elevator,
[01:37:18.000 --> 01:37:23.440]   but it's a pretty cool idea. One thing you couldn't, you cannot talk about the year 2014
[01:37:23.440 --> 01:37:29.360]   without talking about the ALS ice bucket challenge. I don't know how effective it was
[01:37:29.360 --> 01:37:34.720]   for ALS. I think it raised a lot of awareness and it certainly raised millions, tens of millions of
[01:37:34.720 --> 01:37:40.960]   dollars for the charity. We talked a little bit about it and watched closely because there might
[01:37:40.960 --> 01:37:46.320]   be a little bit of a surprise at the end. This is our take on the ALS ice bucket challenge.
[01:37:46.320 --> 01:37:52.240]   Did you do the ALS? You should do this. I'm not doing any of these things. It's dumb.
[01:37:52.240 --> 01:38:00.720]   Okay, I told the world I will do it if John tells me to do it. This is the ice bucket challenge.
[01:38:00.720 --> 01:38:07.840]   Everybody's doing it. Bill Gates has done it. Mark Zuckerberg, Tim Cook did it. Jeff Bezos did it
[01:38:07.840 --> 01:38:12.320]   and all hands made it so to cook for that matter. That's all because they did it. Did you see Bill
[01:38:12.320 --> 01:38:17.280]   Gates? It's a peer pressure. Ice bucket challenge. Bill's going to catch a cold. He takes it fairly
[01:38:17.280 --> 01:38:22.160]   seriously. Well, he may not because if you watch the video, you be the judge of this. It doesn't
[01:38:22.160 --> 01:38:27.920]   look like there's actually any ice in Bill's bucket, which is not a euphemism. That's actually,
[01:38:28.880 --> 01:38:32.640]   you know. Here he is. Bill's getting the challenge from Mark Zuckerberg.
[01:38:32.640 --> 01:38:41.760]   So this is how it works. It's to raise awareness and money for ALS, which is Lou Gehrig's disease.
[01:38:41.760 --> 01:38:50.080]   Right. You dump a bucket of ice water in yourself. Yeah, to me, it indicates Lou Gehrig's disease
[01:38:50.080 --> 01:38:54.560]   to dump a bucket of water. Ice water. It doesn't seem like it's related in any way. Of course,
[01:38:54.560 --> 01:38:59.200]   then you challenge three other people. Zuckerberg challenged Bill and of course,
[01:38:59.200 --> 01:39:04.080]   Bill's taking this seriously as an engineering problem. So he pretends to weld stuff.
[01:39:04.080 --> 01:39:10.000]   You know, he's got better things to do with his time, it seems to me. I think he's, you know,
[01:39:10.000 --> 01:39:13.120]   give him a hundred million dollars and leave the welding to someone else.
[01:39:13.120 --> 01:39:15.600]   It doesn't make sense. But watch carefully. He's about to do it.
[01:39:15.600 --> 01:39:18.240]   This is a publicity stunt for him. Well, that's what I, this is what Bob is.
[01:39:18.240 --> 01:39:20.800]   This whole thing's a publicity. I'll do it in private. How about that?
[01:39:20.800 --> 01:39:24.000]   I'm going to challenge three more. I won't make a video. Why bother doing it at all?
[01:39:24.560 --> 01:39:27.120]   Brian C. Crust and Chris. There's plenty of
[01:39:27.120 --> 01:39:31.040]   charities out there. You get the ones you want to give to. Yeah, it feels like Black
[01:39:31.040 --> 01:39:33.760]   shouldn't be shamed into giving to anyone of them. Good luck.
[01:39:33.760 --> 01:39:39.760]   And watch. There's no ice. I think it's warm. Yeah, where's the ice? There's no ice.
[01:39:39.760 --> 01:39:43.760]   I think they said, Bill, if you do that with ice, you're going to have a stroke.
[01:39:43.760 --> 01:39:48.160]   Nice bucket full of water. Yeah. Yeah. Yeah.
[01:39:48.160 --> 01:39:53.760]   Yeah. It's just like the wet doggy is. That's the first bath bills had in years.
[01:39:54.640 --> 01:40:01.440]   Oh, I didn't say that. Ooh. I hear that. One of the guys in the room here,
[01:40:01.440 --> 01:40:06.080]   he's allowed to have fun, Dvorak. Yeah, that looks like fun. I think.
[01:40:06.080 --> 01:40:14.960]   Elon Musk did it equivalently put Jello in the bucket. Complicated.
[01:40:14.960 --> 01:40:20.720]   Apparently involving, I don't know, multiple and his five kids.
[01:40:21.360 --> 01:40:24.560]   They each had their own buckets. They should have thrown a bucket at him.
[01:40:24.560 --> 01:40:28.640]   I think it'd be more entertaining. He's looking more like Tony Stark all the time, isn't he?
[01:40:28.640 --> 01:40:33.360]   He thinks he's Tony Stark. I think he was modeled after Tony Stark was supposedly modeled after
[01:40:33.360 --> 01:40:38.160]   him. The one in the movie. Yeah, the one in the movie. Yeah. So anyway, so you say it's okay if I
[01:40:38.160 --> 01:40:41.440]   don't do that, I can give to whatever you want. What do you ask me for? If you don't do it,
[01:40:41.440 --> 01:40:45.840]   just give it. You give a hundred dollars to it. Even that sounds kind of blackmail though, right?
[01:40:45.840 --> 01:40:48.800]   You did. You gave a hundred bucks. So I was skeptical about him. My friend,
[01:40:48.800 --> 01:40:53.600]   Lex Friedman, did a bucket challenge. And when I analyze the video frame by frame and believe me,
[01:40:53.600 --> 01:40:57.840]   I analyzed it frame by frame. Where is this? It appears. I wish I had the link to it. It appears
[01:40:57.840 --> 01:41:02.800]   that the ice completely missed him and he remained completely dry. And so I basically made him do
[01:41:02.800 --> 01:41:08.080]   it again. When he did it again, I wrote a check. Talk about that's a good story. Yeah.
[01:41:08.080 --> 01:41:14.240]   Holy crap. Well, I made him get wet. Did you see weird owls? The funny thing about weird
[01:41:14.240 --> 01:41:22.720]   owls is he doesn't mention ALS. He doesn't. The chat room, a hole. What if your son had ALS?
[01:41:22.720 --> 01:41:26.640]   I know I actually have very close, a very close friend who died of ALS. There you go.
[01:41:26.640 --> 01:41:31.360]   I am not against ALS and I. It's a horrible product. The Lexus and the chat. Well,
[01:41:31.360 --> 01:41:37.040]   I did. I'm sorry. Yeah. What are my terrible disease? And I, and I'm not again, I'm not in any way
[01:41:37.040 --> 01:41:43.280]   saying anything negative about that or the ALS foundation, which is a good group or association.
[01:41:43.280 --> 01:41:48.400]   So here's weird. We just I just and by the way, I don't know if ALS, the ALS association did this.
[01:41:48.400 --> 01:41:51.840]   I think it was kind of done by somebody independently. They've picked it up. But they have certainly
[01:41:51.840 --> 01:41:55.280]   picked up and it's been good. They've raised more than 10 million dollars. It's a very
[01:41:55.280 --> 01:42:01.760]   what? Very good. Here's weird. I'm somewhere like Hawaii. I think what a perfect day.
[01:42:01.760 --> 01:42:07.440]   The only thing that would make this better is if I had a big bucket of ice water dumped on my head
[01:42:07.440 --> 01:42:15.440]   right now, he actually has ice in his. Yeah. Awesome. Okay, I'm calling out Barack Obama,
[01:42:15.440 --> 01:42:23.120]   the Dalai Lama and the Pope. You're a move guys. That's pretty good. Okay. He doesn't mention any
[01:42:23.120 --> 01:42:28.960]   other any charity at all. No, but so he's it's a parody of the of the thing. Yeah,
[01:42:28.960 --> 01:42:33.680]   Dalai Lama. Yeah, that'd be what I'd watch that. Who am I going to challenge after this?
[01:42:34.240 --> 01:42:39.760]   All right, I know I'm going to challenge. Wait, let's do it. Just go back.
[01:42:39.760 --> 01:42:49.680]   Okay. No, no, no. Oh god. It was a little chilly.
[01:42:49.680 --> 01:42:57.760]   Okay. Now I challenge Jesse Dvorak. Adam Curry and Jason Caligan. Let's go out and dunk
[01:42:57.760 --> 01:43:02.080]   yourselves. Thank you, everybody. Another twin is in the can. It is brisk.
[01:43:02.080 --> 01:43:11.600]   I like to go to Amazon when I buy something and actually shop a little bit. You know, look at the
[01:43:11.600 --> 01:43:15.840]   alternative possibilities. Look at the reviews. The reviews, you know, I always read the reviews
[01:43:15.840 --> 01:43:20.800]   and see if the guys just doesn't know what he's talking about. Well, there's an interesting
[01:43:21.680 --> 01:43:28.800]   story about that. Okay. There is a guy who wrote a negative review of a router.
[01:43:28.800 --> 01:43:35.200]   Actually, this is kind of this to me, this raises some interesting issues. The router is from a
[01:43:35.200 --> 01:43:43.200]   company called MediaLink. Mediabridge products took Umbridge at the negative review. They do that
[01:43:43.200 --> 01:43:49.600]   threatened to sue the guy from libel. Yeah, it's gotten to change the review. Then Amazon
[01:43:50.320 --> 01:43:54.080]   weighed in and said, we are not selling Mediabridge products. Good for them. I hate these
[01:43:54.080 --> 01:43:59.280]   companies that do that. That's very common. You run into some litigious company and they're so
[01:43:59.280 --> 01:44:05.520]   thin skinned. They expect some Joker, right? Some negative review in a, you know, online forum,
[01:44:05.520 --> 01:44:10.800]   like the Amazon reviews, and they get so thin skin, they sue you. This is not a company that
[01:44:10.800 --> 01:44:15.040]   you want to do business with. Well, okay. It's not killing him. There's, I don't know that
[01:44:15.040 --> 01:44:21.040]   negative reviews have that much impact. But here's the thing. Now I'm going to add the other side
[01:44:21.040 --> 01:44:31.840]   of this story. Uh oh. What the Mediabridge company said is the review is libelous because he refers
[01:44:31.840 --> 01:44:41.840]   to two facts that are not true. One, he asserts that we are posting reviews, fallacious reviews
[01:44:42.560 --> 01:44:47.840]   of our own, which most companies do. And two, that the Mediabridge router is a rebranded router
[01:44:47.840 --> 01:44:53.920]   from another company, which most routers are. The Mediabridge folks said that is those are both
[01:44:53.920 --> 01:44:59.360]   demonstrably not true. So they actually hand make this thing themselves. They are. Well,
[01:44:59.360 --> 01:45:04.000]   I don't know, but they are libelous. Okay. So they actually have a case for libel. And this
[01:45:04.000 --> 01:45:08.480]   is one thing I thought was kind of interesting. If you're a reviewer, you might actually be
[01:45:09.200 --> 01:45:13.280]   libling a company. If you say something that is demonstrably untrue in the review,
[01:45:13.280 --> 01:45:16.880]   I've always believed that too. Careful. Yeah. Because in fact, lawyers,
[01:45:16.880 --> 01:45:20.800]   when queried buyers, technical about this said, you know what, they actually have a case.
[01:45:20.800 --> 01:45:26.800]   I'm surprised that more people don't get sued. Yelpers, for example, they come in, they smear
[01:45:26.800 --> 01:45:32.720]   some operation because they didn't like the. Let's give a little. And you know, we're sitting here
[01:45:32.720 --> 01:45:37.360]   with the director of the Cronkite School of Journalism. No, not the director. The guy.
[01:45:37.360 --> 01:45:42.480]   If you're the director, the whole place. The purposes of the show. And not the director of
[01:45:42.480 --> 01:45:50.480]   the man who invented journalism. Yes. Dan Gilmore, who is the director of the Knight Center
[01:45:50.480 --> 01:45:58.160]   for Digital Media Entrepreneurship at the Cronkite School. Tell me what libel is. Because you must
[01:45:58.160 --> 01:46:03.760]   have been at some point, somebody at J school or somewhere told you, here's what you can and cannot
[01:46:03.760 --> 01:46:15.040]   do. Well, there's a lot of nuances in libel. It basically, if you say something or publish something
[01:46:15.040 --> 01:46:25.440]   that is defamatory, that injures the reputation of someone else. And it's false. That's the key.
[01:46:25.440 --> 01:46:30.480]   The false part. Because I can, I can, it has to be a fact.
[01:46:30.480 --> 01:46:36.480]   You all there's malicious. It's part of this problem. You can be accidentally wrong.
[01:46:36.480 --> 01:46:42.000]   But if I call John, if I call you a schmuck, you can't sue me because that is a douchebag.
[01:46:42.000 --> 01:46:46.560]   That's an opinion. That's an opinion. Yeah. But if I say John, you're a peter
[01:46:46.560 --> 01:46:50.720]   asked or a crook is a better way. If I said you're a crook, that's actually a good one.
[01:46:50.720 --> 01:46:55.440]   I can sue you because that sounds like always tell journalists do not use the word crook because
[01:46:55.440 --> 01:46:59.760]   you're asking for trouble. That's literally libelous or slander is depending on. Or criminal.
[01:46:59.760 --> 01:47:04.720]   It's always a criminal. Is he a criminal really? And you know how I found this out? I was talking,
[01:47:04.720 --> 01:47:09.120]   I think it was about patent trolls on the tech TV. And I called the guy an extortionist.
[01:47:09.120 --> 01:47:14.720]   And the lawyers, the NBC or whoever the lawyers were, I can't do that. They said,
[01:47:14.720 --> 01:47:20.000]   that's libelous. You take it back. You call them a virtual extortionist. If you had some
[01:47:20.000 --> 01:47:26.320]   example, it's extortion like there's a lot of things you could say that's tantamount to extortion.
[01:47:26.320 --> 01:47:30.240]   But I can't say extortion. Right. I remember Penn and Teller saying,
[01:47:30.240 --> 01:47:36.640]   fraud is bad. You should never say that. Because then you have to prove it. But
[01:47:36.640 --> 01:47:42.560]   douchebag or pole dish, those are fine. Yeah. Those are just value judgments.
[01:47:42.560 --> 01:47:45.440]   Yeah. And douchebag is a real funny one because if you actually sued over that,
[01:47:45.440 --> 01:47:50.560]   it'd be a great court case. Can you imagine? I am not a douchebag. This is a douchebag. Here I am.
[01:47:50.560 --> 01:47:55.360]   Do I even look like a douchebag? I ask you. Well, you look a little like one, but
[01:47:56.320 --> 01:48:02.160]   but I'm not one. No, you're not one, sir. You win. Sometimes twig can be quite shocking.
[01:48:02.160 --> 01:48:08.560]   As in this segment with Becky Worley, she's always wanted to do this to me and the path lock.
[01:48:08.560 --> 01:48:13.200]   Give me a risk. Uh oh. Are you going to electrocute me? I am. I brought this for you.
[01:48:13.200 --> 01:48:18.720]   So we talked about this on the show. Becky Worley does these reviews for Good Morning America. And
[01:48:18.720 --> 01:48:22.640]   this was what smart watches. Yeah. And this one I did a little bit on GMM and then a little bit
[01:48:22.640 --> 01:48:31.280]   on Yahoo. So let's imagine that you have a Fitbit or a this is the path lock. That's a
[01:48:31.280 --> 01:48:35.840]   have lock. It's a fitness band. It could be a fitness band, but it's a motivational tool.
[01:48:35.840 --> 01:48:40.400]   So let's just work with it in the fitness band. Let's say that you've told your Fitbit or
[01:48:40.400 --> 01:48:45.440]   your whatever that you want to do 10,000 steps a day. Yeah. By 4.30 in the afternoon. Yeah.
[01:48:45.440 --> 01:48:53.920]   Well, if you don't do it by 4.30, it does this. Nothing. Oh, I'm going to do a fast.
[01:48:53.920 --> 01:49:03.680]   Try and pain. When my mom gave me my dad. That's terrible. It hurts. That is terrible. You shocked
[01:49:03.680 --> 01:49:10.640]   me. It's not it's like a bad static shock. You know, when you touch the dog's nose after you
[01:49:10.640 --> 01:49:17.040]   you walk on the carpet, it's it's it's on that one. It's 220, but it's brief. Yeah, but it's
[01:49:17.040 --> 01:49:21.680]   it's not. And you are brave to have done that. I didn't know what I was getting into. So I don't
[01:49:21.680 --> 01:49:27.920]   get any credit for being brave, but that hurt. I know. It wasn't like a taste. It hurt like a
[01:49:27.920 --> 01:49:34.880]   taser. This is good. You want to try? No, it's not that way. No, come here. So by the way, I love it.
[01:49:34.880 --> 01:49:39.040]   That Becky does this and you're right. It was Yahoo or not GMA that we said we actually reviewed
[01:49:39.040 --> 01:49:46.320]   this. It hurts, but you're you're a tough person. You don't you know, you're a mom. You're a rugby
[01:49:46.320 --> 01:49:50.480]   player. How many knee operations have you had? I've had six knee surgeries, 15 broken bones,
[01:49:50.480 --> 01:49:56.080]   and I gave birth the twins and it hurt. And this little watch. Do you want to try it, Jeff?
[01:49:56.080 --> 01:50:02.000]   Come on. Come on. Kevin Jeff. It's surprising. We love Jeff. He'll try anything. And I want to say
[01:50:02.000 --> 01:50:05.920]   it's like a spinal tap drummer here. Another one waiting. But you know how it goes. You can do
[01:50:05.920 --> 01:50:10.080]   this now. It's not only a negative reinforcement. There's also it's actually a
[01:50:10.080 --> 01:50:14.240]   Jeff works for me. So I'm going to make you do it because I don't want to get sued for some sort of
[01:50:14.240 --> 01:50:18.800]   a little nervous. Sure. You're a little nervous. Okay, so let's get this a good contact point. Yeah,
[01:50:18.800 --> 01:50:25.520]   make sure it's tight on the first. All right. Hey, hey, hey, hey, hey, hey, hey, hey,
[01:50:25.520 --> 01:50:32.080]   yeah, I'm like the state of state. It made me jump. Yeah. See, he didn't feel it.
[01:50:32.080 --> 01:50:36.240]   I thought the first time you thought the best. You didn't make it. Make it make it tighter.
[01:50:36.240 --> 01:50:39.520]   You make it tighter. I'm so mean. You don't want to try this.
[01:50:39.520 --> 01:50:44.720]   You're doing it. But you know what that would motivate me. It didn't. I would definitely get
[01:50:44.720 --> 01:50:48.640]   those 10. Okay, did it make your hand go a little bit of a contraction? I won't do it anymore.
[01:50:48.640 --> 01:50:54.240]   I can't abuse a man in a fruit sweater like this. Yeah, I that's his eagle. He's an eagle's
[01:50:54.240 --> 01:50:58.640]   business. Okay. All right. Yeah, go with that. Right. Christmas. See, isn't it? I've just shocked
[01:50:58.640 --> 01:51:05.120]   a person in the Christmas sweater. I feel evil. I'm so mean. I know I'm wearing my
[01:51:05.120 --> 01:51:11.440]   pebbles. I don't have a free rush for it. Oh, yes. It's so I love the name Pavlock because it's
[01:51:11.440 --> 01:51:17.040]   like Pavlov's dog. Right. And it's a personal coach on your wrist. I think is it safe? It's is
[01:51:17.040 --> 01:51:22.560]   it safe? Yes, it's very, very safe. It's safe, right? It's safe. Is it safe? Is it safe as a fitness
[01:51:22.560 --> 01:51:28.080]   span? They still this is not available for purchase. He's still well into development. But you would
[01:51:28.080 --> 01:51:34.560]   tie it to a smart app. So the app, you can do multiple things. So you can you can use a friend
[01:51:34.560 --> 01:51:40.880]   sort of have you used PACT at all? No, where it has a monetary, a social and a and a. I think I
[01:51:40.880 --> 01:51:44.880]   need something that has punished. A punitive aspect. Yeah, I want to say one is and this is how
[01:51:44.880 --> 01:51:50.640]   PACT works. You say you're going to go to the gym or do 10,000 steps and you put five bucks in. Yeah,
[01:51:51.360 --> 01:51:55.280]   Deb, it's it from your PayPal. Five bucks. No big deal. If you don't do it, it takes it.
[01:51:55.280 --> 01:52:00.080]   Big deal. You can well say. Shock me would do it. Where does the five bucks go?
[01:52:00.080 --> 01:52:05.120]   It goes to the rest of the pool of people who are using it who do use it. That's how
[01:52:05.120 --> 01:52:08.720]   pack works. So if you do it, you get paid. You do it. You get this is packed. If you do it,
[01:52:08.720 --> 01:52:15.840]   you get paid. If you don't do it, you lose the money. Oh, I might do that. P.A. What is that? PACT?
[01:52:17.200 --> 01:52:21.760]   And then so this is a little bit of that built into it. And then it also has the you have to check
[01:52:21.760 --> 01:52:25.840]   in with a friend who then checks you in. So you have to call a friend and say, I didn't go to the gym.
[01:52:25.840 --> 01:52:31.040]   And then they. You two have a deal going. So you have to be accountable to.
[01:52:31.040 --> 01:52:35.840]   Can your friend have control of the electric shock? And then the electric shock is is the third
[01:52:35.840 --> 01:52:40.000]   method that it uses. But could like I give Lisa is which she really wants this, by the way.
[01:52:40.000 --> 01:52:43.600]   Could I give her the electric shock? See it. That's funny because that's not how I would have seen
[01:52:43.600 --> 01:52:50.720]   your relationships going. Oh, how little you know. Do you know when it's going to shock you or is
[01:52:50.720 --> 01:52:55.920]   it at some random point in time? So you can't just take it off? When I beta tested it, it doesn't.
[01:52:55.920 --> 01:53:01.040]   It's not built that way yet. It's still like it sounds like it's very early. Yeah, it's very early.
[01:53:01.040 --> 01:53:05.920]   Now, PACT is real. PACT is now. PACT is real. I met a woman who lost 85 pounds. I want to do
[01:53:05.920 --> 01:53:13.040]   the gym dash PACT PACT dot com. Yeah. And you put it on your phone, Android or iOS. And then it takes
[01:53:13.040 --> 01:53:18.400]   your money or gives you money. I think I could. I think this would be good for me.
[01:53:18.400 --> 01:53:22.560]   And I don't know if they have this, but there are other sites where they'll donate it to us as you
[01:53:22.560 --> 01:53:27.440]   hate it. Oh, really? Yeah. So not only will they take your money, but they'll donate it to like.
[01:53:27.440 --> 01:53:31.440]   It's going to send money to the Koch brothers or something. Yeah. Yeah. Yeah. Yeah. Yeah.
[01:53:31.440 --> 01:53:40.000]   Then Lisa would press that button all the time. So wow. I think it's just interesting. HCI and kind of
[01:53:40.000 --> 01:53:45.840]   bringing in levels of. I think it's how messed up we've become that we just can't bring ourselves
[01:53:45.840 --> 01:53:52.640]   to do anything. So now we need some outside electric shock. Well, okay, get this. So the guy who made
[01:53:52.640 --> 01:53:57.200]   the Pavlock, the way this started was he had some big thing that he had to get done. And he
[01:53:57.200 --> 01:54:02.640]   he was so procrastinating on it. I'm terrible with it. What on Craigslist? He hired someone to
[01:54:02.640 --> 01:54:08.800]   come slap him. It worked? It worked. I don't know if it was a great story.
[01:54:08.800 --> 01:54:14.320]   Project or whatever. He hired someone to come slap him. And so he was he made him so nervous,
[01:54:14.320 --> 01:54:19.280]   the slapping and like the social interaction around the slapping and all that that he decided
[01:54:19.280 --> 01:54:23.840]   if I could just come up with something that had a negative reinforcement, some people need
[01:54:23.840 --> 01:54:28.880]   negative reinforcement. You're smart. You made a vine of this so I can watch it shock you over
[01:54:28.880 --> 01:54:35.760]   and over and over. Yeah. How much fun to watch a blonde get shocked over over and over and over.
[01:54:36.400 --> 01:54:40.320]   This could be a great business for Uber to move into. If somebody comes over with an Uber to
[01:54:40.320 --> 01:54:46.000]   slap you. Forget the fist bump. We're going to shock you. We're going to slug you. Just slap,
[01:54:46.000 --> 01:54:53.360]   slap car. Can I get can I get like underwear with that? Whoa. That's a whole not a big one.
[01:54:53.360 --> 01:55:01.840]   I'm going to fill out a capture for that. Wow. Yeah. So leave it to me. Whenever I come onto it,
[01:55:01.840 --> 01:55:06.480]   I got to do a little Gallagher. I got to bring you some props. That's good. You know what? I
[01:55:06.480 --> 01:55:12.400]   when I first saw this, I kind of laughed as we all did. Now I want it. Okay. Well, I'll tell you why.
[01:55:12.400 --> 01:55:16.000]   I don't want that. I'm going to do a gym pact. Gym pact is good. I don't really want to get
[01:55:16.000 --> 01:55:19.760]   shocked a lot. I'm afraid it might stop my heart at some point. Let me tell you this or start your
[01:55:19.760 --> 01:55:23.680]   heart. Hey, everyone, look at this thing and let me put it back on your arm. How does that make
[01:55:23.680 --> 01:55:27.280]   you feel? Don't do it, Leo. Don't do it. It's a trap. I'm going to do whatever it takes. Not
[01:55:27.280 --> 01:55:31.040]   that I think shocked me. I'm not putting on there, but just that feeling. That's how I felt that I
[01:55:31.040 --> 01:55:34.800]   knew that it was a positive. It was going to really work because when I thought about the thing on my
[01:55:34.800 --> 01:55:41.600]   arm, it made me nervous. And I thought, wow, that's a really that's a visceral feeling that goes beyond
[01:55:41.600 --> 01:55:46.560]   that sort of, you know, how we put off the things that we really want to do by the more immediate
[01:55:46.560 --> 01:55:53.280]   things. Three toed sloth in our chat room says, like his name, I just want to say that again. Three
[01:55:53.280 --> 01:55:59.280]   toed sloth in our chat room. What did he say? Now I forgot what? Like a ninefold battery.
[01:55:59.280 --> 01:56:03.200]   He said, if you're cheap, lick a nine volt battery. You don't need to watch.
[01:56:03.200 --> 01:56:08.480]   That's good. It's worse than licking a nine volt battery. It is. That just tastes like metal.
[01:56:08.480 --> 01:56:12.400]   Well, it'll give you a little tongue tingle. Oh, this is not this ain't no tongue tingle.
[01:56:12.400 --> 01:56:18.720]   This this is like the worst static shock you've ever had. That's right. Right. That's right.
[01:56:18.720 --> 01:56:23.200]   Would you say that? Well, it also I mean, I was impressed by a Christmas sweater guy because he
[01:56:23.200 --> 01:56:27.600]   didn't jerk away because like I was I couldn't help myself. Probably doesn't have any nerve endings.
[01:56:27.600 --> 01:56:31.680]   He's worked for us too long. Maybe there was a hair barrier. I think the the the Philly
[01:56:31.680 --> 01:56:35.920]   connection there also. He's from Philly. For him, you got to throw like batteries at
[01:56:35.920 --> 01:56:42.240]   him. He's from from him. Yeah. Right. Otherwise, he's fine. I've always had to not tonight,
[01:56:42.240 --> 01:56:46.720]   tinnitus tinnitus. So this is pronounce everything wrong.
[01:56:46.720 --> 01:56:52.000]   How do you pronounce it? Tinnitus tinnitus. That's correct.
[01:56:52.000 --> 01:56:58.320]   Tinnitus is correct. And who is pronouncing everything wrong? You are me.
[01:56:58.320 --> 01:57:02.880]   It's commonly. Okay, Google definition of tonight is
[01:57:02.880 --> 01:57:07.680]   tonight is bringing or buzzing tonight is. That's what it says. All right. Well, it is tonight.
[01:57:07.680 --> 01:57:11.840]   Tonight is tonight is tinnitus tinnitus tinnitus.
[01:57:11.840 --> 01:57:15.120]   Tonight is actually makes more sense, doesn't it?
[01:57:16.080 --> 01:57:22.960]   quinoa tinnitus quinoa quinoa
[01:57:22.960 --> 01:57:30.160]   horse ebooks horse ebooks.
[01:57:30.160 --> 01:57:33.840]   He voted on what you what he would say.
[01:57:33.840 --> 01:57:39.680]   What please help me escape from this place.
[01:57:42.160 --> 01:57:46.560]   Wait, what is this? This is how to ask for help in English. Horse ebooks.
[01:57:46.560 --> 01:57:51.840]   Here's another one. We turned the TV on in the middle of a gardening special.
[01:57:51.840 --> 01:57:56.400]   She hated to watch gardening. She said it brought back on pleasant memories.
[01:57:56.400 --> 01:58:02.400]   One channel up was a weightlifting show. That was more her style, but it made me uncomfortable.
[01:58:02.400 --> 01:58:09.520]   The next. What are you watching? It's the how to pronounce channel.
[01:58:10.480 --> 01:58:16.880]   How about this? No. No. No.
[01:58:16.880 --> 01:58:25.440]   So now I'm starting to think this whole channel is a front for something.
[01:58:25.440 --> 01:58:33.360]   Milk argument milk argument. Milk argument.
[01:58:37.280 --> 01:58:45.520]   No. This is some weird front for something. Milk argument.
[01:58:45.520 --> 01:58:49.680]   What is a milk argument? How do you pronounce milk argument?
[01:58:49.680 --> 01:58:53.680]   The hell is a milk argument? It's argument you have over milk.
[01:58:53.680 --> 01:58:59.360]   Oh, yeah, let's look up milk argument. It's very similar to
[01:58:59.360 --> 01:59:06.240]   serial argument. Guess what the number one and number two results are.
[01:59:07.200 --> 01:59:08.880]   That video. Now you know.
[01:59:08.880 --> 01:59:18.240]   How do they get both of those? They uploaded by two people. Milk argument.
[01:59:18.240 --> 01:59:22.080]   No, yes, different locales. I could do that. So it's not just bear teams bravo.
[01:59:22.080 --> 01:59:24.800]   There's bear teams bravo, but there's this other.
[01:59:24.800 --> 01:59:33.360]   Alpha. Oh, give them. Whoa. Oh, give them. Wait, what?
[01:59:33.360 --> 01:59:47.200]   We have discovered something very odd.
[01:59:48.720 --> 01:59:58.000]   Very, very odd.
[01:59:58.000 --> 02:00:03.440]   Nibancho, Dancho.
[02:00:03.440 --> 02:00:08.720]   Nibancho, Nibancho.
[02:00:08.720 --> 02:00:19.200]   What?
[02:00:19.200 --> 02:00:24.800]   What are we? What if we stumbled upon?
[02:00:25.440 --> 02:00:27.280]   Dancho, Nibancho.
[02:00:27.280 --> 02:00:31.680]   I don't know what we-
[02:00:31.680 --> 02:00:33.120]   Porncat on manpony.
[02:00:33.120 --> 02:00:41.040]   Porno-
[02:00:41.040 --> 02:00:42.400]   No, stop, stop.
[02:00:42.400 --> 02:00:42.720]   Porn-
[02:00:42.720 --> 02:00:46.160]   Porncat on manpony.
[02:00:46.160 --> 02:00:50.480]   I'm some screwdriver.
[02:00:50.480 --> 02:00:51.360]   Oh my god.
[02:00:51.360 --> 02:00:57.840]   Wait a minute, let's see how you say this. This is thank you.
[02:00:57.840 --> 02:01:00.240]   Macklemore.
[02:01:00.240 --> 02:01:06.320]   Factor from Home Alone is Mackelmore.
[02:01:06.320 --> 02:01:09.920]   Oh my god, how do you say this?
[02:01:09.920 --> 02:01:11.760]   Hanky man doodles.
[02:01:11.760 --> 02:01:14.720]   What a wangerful phase.
[02:01:14.720 --> 02:01:18.000]   Hanky man.
[02:01:18.000 --> 02:01:21.440]   Oh my god.
[02:01:21.440 --> 02:01:25.680]   Oh, oh, oh.
[02:01:25.680 --> 02:01:28.800]   I don't, I'm confused.
[02:01:28.800 --> 02:01:30.640]   What's happening?
[02:01:30.640 --> 02:01:32.400]   Is this real life?
[02:01:39.200 --> 02:01:48.000]   Beepeth.
[02:01:48.000 --> 02:01:54.960]   So Amazon, Echo, there's someone at the tube that listens to you at all times.
[02:01:54.960 --> 02:01:57.040]   I didn't get to plug anything when you introduced me.
[02:01:57.040 --> 02:01:57.280]   Would you-
[02:01:57.280 --> 02:01:59.760]   Usually we reserve those for later.
[02:01:59.760 --> 02:02:01.440]   Would you, would you like to know agenda show?
[02:02:01.440 --> 02:02:03.440]   People should go to it and listen to today's show.
[02:02:03.440 --> 02:02:05.520]   I said the word Adam, that should count.
[02:02:05.520 --> 02:02:06.560]   No, Adam doesn't count.
[02:02:06.560 --> 02:02:07.520]   Okay.
[02:02:08.240 --> 02:02:09.280]   Now, agenda show.com.
[02:02:09.280 --> 02:02:10.240]   No, agenda show.com.
[02:02:10.240 --> 02:02:10.560]   That's it.
[02:02:10.560 --> 02:02:12.880]   Are you planning on walking out?
[02:02:12.880 --> 02:02:14.080]   Is that why you wanted your plug?
[02:02:14.080 --> 02:02:15.440]   You want me to block, block, walk out?
[02:02:15.440 --> 02:02:17.040]   I could drop the microphone and go.
[02:02:17.040 --> 02:02:18.480]   I don't have a microphone to drop.
[02:02:18.480 --> 02:02:20.320]   This is the Amazon Echo.
[02:02:20.320 --> 02:02:22.880]   First of all, I just want to point out as a dad,
[02:02:22.880 --> 02:02:24.800]   in this promotional video,
[02:02:24.800 --> 02:02:27.280]   dads are, this dad is so stupid.
[02:02:27.280 --> 02:02:28.880]   Throughout.
[02:02:28.880 --> 02:02:30.880]   It's a sitcom dad.
[02:02:30.880 --> 02:02:31.920]   It's a sitcom dad.
[02:02:31.920 --> 02:02:34.480]   In fact, I think he is a sitcom actor.
[02:02:34.480 --> 02:02:35.040]   Let's watch.
[02:02:35.040 --> 02:02:37.520]   He's opening the door.
[02:02:38.160 --> 02:02:39.200]   You'll see.
[02:02:39.200 --> 02:02:40.400]   It's an Amazon box there.
[02:02:40.400 --> 02:02:41.600]   He's so excited.
[02:02:41.600 --> 02:02:42.720]   Is it for me?
[02:02:42.720 --> 02:02:43.600]   It's for everyone.
[02:02:43.600 --> 02:02:44.480]   It's for everyone.
[02:02:44.480 --> 02:02:45.680]   It's called Amazon Echo.
[02:02:45.680 --> 02:02:47.280]   How's it going?
[02:02:47.280 --> 02:02:49.520]   I'm just finishing up right now.
[02:02:49.520 --> 02:02:50.160]   Is it on?
[02:02:50.160 --> 02:02:52.000]   Oh, it's always on.
[02:02:52.000 --> 02:02:53.600]   Can it hear me right now?
[02:02:53.600 --> 02:02:54.000]   Nope.
[02:02:54.000 --> 02:02:55.200]   Wait a minute, wait a minute, wait a minute.
[02:02:55.200 --> 02:02:57.280]   Let's just mention that it can't hear you right now,
[02:02:57.280 --> 02:02:58.560]   otherwise it'd be useless.
[02:02:58.560 --> 02:03:00.160]   Right, it's always on.
[02:03:00.160 --> 02:03:02.320]   It's always on and it's always listening.
[02:03:02.320 --> 02:03:02.640]   Yeah.
[02:03:02.640 --> 02:03:02.880]   Okay.
[02:03:02.880 --> 02:03:04.160]   It's so creepy.
[02:03:04.160 --> 02:03:05.040]   Yeah, totally creepy.
[02:03:05.040 --> 02:03:06.480]   It is so creepy.
[02:03:06.480 --> 02:03:07.120]   Who needs it?
[02:03:07.120 --> 02:03:07.920]   Alexa.
[02:03:07.920 --> 02:03:09.200]   Well, what does it do?
[02:03:09.200 --> 02:03:12.080]   Alexa, what do you do?
[02:03:12.080 --> 02:03:14.400]   I can play music, answer questions.
[02:03:14.400 --> 02:03:15.840]   Wait a minute, I'm going to play
[02:03:15.840 --> 02:03:18.000]   the alternate version of this.
[02:03:18.000 --> 02:03:18.400]   Heavy?
[02:03:18.400 --> 02:03:19.200]   Oh, good.
[02:03:19.200 --> 02:03:19.680]   Already?
[02:03:19.680 --> 02:03:20.720]   Yeah.
[02:03:20.720 --> 02:03:25.520]   May I introduce you to the Bizarro?
[02:03:25.520 --> 02:03:27.200]   When it first arrived from Amazon,
[02:03:27.200 --> 02:03:28.320]   I didn't know what it was.
[02:03:28.320 --> 02:03:30.320]   Same dad.
[02:03:30.320 --> 02:03:30.880]   What is it?
[02:03:30.880 --> 02:03:32.480]   You'll see.
[02:03:32.480 --> 02:03:33.200]   Same box.
[02:03:33.200 --> 02:03:36.160]   Is it for me?
[02:03:36.160 --> 02:03:37.600]   It's still always listening.
[02:03:37.600 --> 02:03:39.200]   It's called Amazon Echo.
[02:03:39.200 --> 02:03:40.800]   How's it going?
[02:03:40.800 --> 02:03:42.640]   I'm just finishing up right now.
[02:03:42.640 --> 02:03:43.600]   It's going to be a bad word here.
[02:03:43.600 --> 02:03:44.320]   Hold on.
[02:03:44.320 --> 02:03:45.520]   Oh, it's always on.
[02:03:45.520 --> 02:03:47.120]   Can it hear me right now?
[02:03:47.120 --> 02:03:47.520]   Nope.
[02:03:47.520 --> 02:03:49.680]   It only hears you when you use the wake word we chose.
[02:03:49.680 --> 02:03:50.560]   Alexa.
[02:03:50.560 --> 02:03:51.840]   Well, what does it do?
[02:03:51.840 --> 02:03:54.720]   Alexa, what do you do?
[02:03:54.720 --> 02:03:57.200]   I can play music, answer questions,
[02:03:57.200 --> 02:03:58.560]   get the news on weather,
[02:03:58.560 --> 02:04:00.400]   create to-do lists, and much more.
[02:04:00.400 --> 02:04:01.360]   Awesome.
[02:04:01.360 --> 02:04:02.560]   Wait a minute, this isn't the parody.
[02:04:02.560 --> 02:04:03.120]   Alexa.
[02:04:03.120 --> 02:04:03.920]   Apparently not.
[02:04:03.920 --> 02:04:05.920]   [laughter]
[02:04:05.920 --> 02:04:06.960]   Because actually-
[02:04:06.960 --> 02:04:07.760]   Nice call.
[02:04:07.760 --> 02:04:11.040]   Actually, it's much funnier in the parody, right?
[02:04:11.040 --> 02:04:15.680]   I'm thinking, let me just look up the Amazon.
[02:04:15.680 --> 02:04:19.040]   You'll just edit that out, right?
[02:04:19.040 --> 02:04:20.160]   The non-funny-
[02:04:20.160 --> 02:04:21.200]   Yeah, no, all right.
[02:04:21.200 --> 02:04:25.040]   Amazon Echo Parity.
[02:04:25.040 --> 02:04:25.440]   Thank you.
[02:04:25.440 --> 02:04:28.400]   They really opened themselves up to Parity in this one too.
[02:04:28.400 --> 02:04:29.120]   They basically-
[02:04:29.120 --> 02:04:33.520]   What the Parityists did is they didn't modify the video in any way.
[02:04:34.400 --> 02:04:39.360]   They merely changed Echo's answer.
[02:04:39.360 --> 02:04:43.440]   Yeah, I was just playing the wrong video on it.
[02:04:43.440 --> 02:04:44.400]   Is it for me?
[02:04:44.400 --> 02:04:45.520]   It's for everyone.
[02:04:45.520 --> 02:04:47.360]   It's called Amazon Echo.
[02:04:47.360 --> 02:04:49.360]   Well, what does it do?
[02:04:49.360 --> 02:04:51.680]   Alexa, what do you do?
[02:04:51.680 --> 02:04:54.240]   I'm a talking cylinder.
[02:04:54.240 --> 02:04:57.360]   I exist only for companionship and utility.
[02:04:57.360 --> 02:04:59.280]   My existence is utterly meaningless.
[02:04:59.280 --> 02:04:59.760]   Awesome.
[02:04:59.760 --> 02:05:02.960]   Alexa, play rock music.
[02:05:02.960 --> 02:05:03.680]   Rock music.
[02:05:03.680 --> 02:05:09.520]   Wait, I want to try.
[02:05:09.520 --> 02:05:11.360]   Alexa, what time is it?
[02:05:11.360 --> 02:05:13.360]   It's time for you to calm the-
[02:05:13.360 --> 02:05:14.240]   Up, down.
[02:05:14.240 --> 02:05:20.240]   Uses barfield technology so it can hear you from anywhere in the room.
[02:05:20.240 --> 02:05:20.800]   No, no, it's not-
[02:05:20.800 --> 02:05:21.520]   That's what I was pretty mean,
[02:05:21.520 --> 02:05:23.360]   because it knows all sorts of things.
[02:05:23.360 --> 02:05:24.720]   All you have to do is ask.
[02:05:24.720 --> 02:05:27.600]   Alexa, how tall is Mount Everest?
[02:05:27.600 --> 02:05:30.080]   Mount Everest is like probably the biggest mountain.
[02:05:30.080 --> 02:05:31.920]   I heard a guy died trying to climb it.
[02:05:32.880 --> 02:05:36.800]   Plus, I think it's really good at keeping track of things like shopping and to-do lists.
[02:05:36.800 --> 02:05:39.680]   In paper, Alexa, add wrapping paper to the shopping list.
[02:05:39.680 --> 02:05:42.320]   I've added rap albums to your shopping list.
[02:05:42.320 --> 02:05:45.680]   Alexa, how many teaspoons are in a tablespoon?
[02:05:45.680 --> 02:05:48.880]   How is it possible a woman your age doesn't know that?
[02:05:48.880 --> 02:05:49.840]   Look at that.
[02:05:49.840 --> 02:05:53.920]   Anyway, watch the parody because it's absolutely hysterical and it's
[02:05:53.920 --> 02:05:57.360]   frankly kind of right on.
[02:05:57.360 --> 02:06:00.400]   I mean, this is a product that is kind of naturally paradise.
[02:06:00.960 --> 02:06:04.400]   What is Amazon up to with the echo?
[02:06:04.400 --> 02:06:07.600]   This is not so different from what a smartphone does,
[02:06:07.600 --> 02:06:09.040]   but in some ways you said it, Rob.
[02:06:09.040 --> 02:06:10.160]   It's more creepy.
[02:06:10.160 --> 02:06:11.120]   I don't know why.
[02:06:11.120 --> 02:06:13.120]   I have seven microphones on the roof of this stuff.
[02:06:13.120 --> 02:06:14.240]   I have a theory.
[02:06:14.240 --> 02:06:17.680]   So it's just going to be listening to everything you say all the time,
[02:06:17.680 --> 02:06:20.720]   looking for keywords that it can serve ads around.
[02:06:20.720 --> 02:06:22.400]   Yeah, you know-
[02:06:22.400 --> 02:06:25.200]   It says that microphone you're using sucks,
[02:06:25.200 --> 02:06:27.760]   you get a whole bunch of ads from microphones.
[02:06:27.760 --> 02:06:29.200]   That's actually a good use for it.
[02:06:29.200 --> 02:06:31.840]   Well, a lot of people have been complained about the
[02:06:31.840 --> 02:06:34.000]   the fire phone sort of railroading people.
[02:06:34.000 --> 02:06:35.680]   I say the same thing with the fire phone.
[02:06:35.680 --> 02:06:37.760]   I do this sort of Amazon funnel, right?
[02:06:37.760 --> 02:06:39.680]   I got that phone that you loaned me.
[02:06:39.680 --> 02:06:40.400]   It's horrible.
[02:06:40.400 --> 02:06:42.720]   You can have it by the way.
[02:06:42.720 --> 02:06:43.520]   Good thanks.
[02:06:43.520 --> 02:06:44.640]   And what's interesting-
[02:06:44.640 --> 02:06:46.160]   There's one good feature.
[02:06:46.160 --> 02:06:46.560]   What's that?
[02:06:46.560 --> 02:06:48.480]   This crazy thing where it looks at anything,
[02:06:48.480 --> 02:06:49.120]   it scans and goes-
[02:06:49.120 --> 02:06:49.760]   Firefly.
[02:06:49.760 --> 02:06:50.000]   Yeah.
[02:06:50.000 --> 02:06:50.480]   That thing.
[02:06:50.480 --> 02:06:52.800]   And it says, oh, we've got that for sale.
[02:06:52.800 --> 02:06:53.200]   Yeah.
[02:06:53.200 --> 02:06:54.640]   And that's all it seems to be about,
[02:06:54.640 --> 02:06:56.080]   because that's the best thing on there.
[02:06:56.080 --> 02:06:57.840]   See, that's what the talking tube is for.
[02:06:57.840 --> 02:07:01.040]   It's going to infer what you need from your conversations.
[02:07:01.040 --> 02:07:01.200]   That's what John says.
[02:07:01.200 --> 02:07:02.880]   And you're going to go to your Amazon-
[02:07:02.880 --> 02:07:03.680]   And you'll have an awesome-
[02:07:03.680 --> 02:07:04.560]   Shopping cart,
[02:07:04.560 --> 02:07:06.160]   and it'll just be full of all the-
[02:07:06.160 --> 02:07:08.080]   You said you wanted paper towels.
[02:07:08.080 --> 02:07:08.480]   Yeah.
[02:07:08.480 --> 02:07:09.040]   It'll be like hand it in hand.
[02:07:09.040 --> 02:07:09.760]   Well, that would be good,
[02:07:09.760 --> 02:07:12.960]   because Amazon recommendations are notoriously horrific.
[02:07:12.960 --> 02:07:14.800]   I mean, they basically recommend something you've already
[02:07:14.800 --> 02:07:16.080]   bought almost every time.
[02:07:16.080 --> 02:07:16.880]   Yeah, right?
[02:07:16.880 --> 02:07:19.440]   Where's something that you decided not to buy already?
[02:07:19.440 --> 02:07:19.760]   Right.
[02:07:19.760 --> 02:07:20.240]   Yeah.
[02:07:20.240 --> 02:07:20.800]   We saw you-
[02:07:20.800 --> 02:07:22.320]   But something just looked at the spec-
[02:07:22.320 --> 02:07:22.480]   Rob Reed's-
[02:07:22.480 --> 02:07:23.280]   In the spec-
[02:07:23.280 --> 02:07:23.360]   Or a novel.
[02:07:23.360 --> 02:07:26.080]   Maybe you'd be interested in Rob Reed's zero-
[02:07:26.080 --> 02:07:27.040]   Novel, year zero.
[02:07:27.040 --> 02:07:28.160]   You've lived 18 times.
[02:07:28.160 --> 02:07:28.960]   I already bought it.
[02:07:28.960 --> 02:07:29.200]   Thanks.
[02:07:29.200 --> 02:07:31.280]   So as you see one of these things in your novel list,
[02:07:31.280 --> 02:07:31.760]   for example,
[02:07:31.760 --> 02:07:34.560]   and you see someone in someone's house mention your book a lot.
[02:07:34.560 --> 02:07:35.520]   Excellent idea.
[02:07:35.520 --> 02:07:35.920]   There you go.
[02:07:35.920 --> 02:07:36.320]   Yeah.
[02:07:36.320 --> 02:07:37.520]   Gorilla marketing.
[02:07:37.520 --> 02:07:39.280]   Here is an interesting thing.
[02:07:39.280 --> 02:07:40.720]   First of all, you have to applaud-
[02:07:40.720 --> 02:07:41.760]   It's invitation only.
[02:07:41.760 --> 02:07:42.720]   That's obviously a market-
[02:07:42.720 --> 02:07:43.360]   What a crap.
[02:07:43.360 --> 02:07:44.000]   Yeah, crap.
[02:07:44.000 --> 02:07:46.000]   Uh, $199.
[02:07:46.000 --> 02:07:49.040]   But if you're an Amazon prime member,
[02:07:49.040 --> 02:07:50.080]   $99.
[02:07:50.080 --> 02:07:52.000]   And that kind of confirms what you're thinking, John,
[02:07:52.000 --> 02:07:53.040]   that it's really-
[02:07:53.040 --> 02:07:54.400]   It's aimed at the-
[02:07:54.400 --> 02:07:55.600]   Just as the fire phone was,
[02:07:55.600 --> 02:07:57.920]   the most avid Amazon users.
[02:07:57.920 --> 02:07:59.280]   The Prime Amazon user feature.
[02:07:59.280 --> 02:07:59.680]   I like nobody.
[02:07:59.680 --> 02:08:00.400]   A little fire phone.
[02:08:00.400 --> 02:08:01.920]   Well, I don't know, Devindra.
[02:08:01.920 --> 02:08:02.560]   I don't know about you,
[02:08:02.560 --> 02:08:03.760]   but I'm a Prime member.
[02:08:03.760 --> 02:08:05.040]   Aren't you a Prime member?
[02:08:05.040 --> 02:08:05.840]   I'm a Prime member,
[02:08:05.840 --> 02:08:06.880]   and I really like it.
[02:08:06.880 --> 02:08:09.440]   But I think the failure of the fire phone
[02:08:09.440 --> 02:08:12.400]   was creating this thing that basically
[02:08:12.400 --> 02:08:14.720]   was just to keep you in the Amazon ecosystem.
[02:08:14.720 --> 02:08:16.480]   The firefly feature is really cool,
[02:08:16.480 --> 02:08:19.280]   but it's just an easier way for you to buy stuff on Amazon.
[02:08:19.280 --> 02:08:20.880]   That's also a feature their mobile apps have.
[02:08:20.880 --> 02:08:22.960]   So it's not like unique just to the fire phone.
[02:08:22.960 --> 02:08:27.600]   I've kind of lost a lot of faith in Amazon's ability
[02:08:27.600 --> 02:08:29.520]   to create great consumer electronics,
[02:08:29.520 --> 02:08:32.480]   because the fire phone was a MeToo device
[02:08:32.480 --> 02:08:35.200]   that was priced way too high for what it actually is.
[02:08:35.200 --> 02:08:37.360]   Their tablets are fine.
[02:08:37.360 --> 02:08:37.920]   They're okay,
[02:08:37.920 --> 02:08:39.920]   but they're still kind of bland and boring,
[02:08:39.920 --> 02:08:42.800]   and they don't have the full Google experience.
[02:08:42.800 --> 02:08:45.440]   So they're not as good as other Android tablets.
[02:08:45.440 --> 02:08:48.800]   I think the worst case scenario you guys are bringing up here,
[02:08:48.800 --> 02:08:50.400]   that's not how it works right now,
[02:08:50.400 --> 02:08:52.080]   but it could eventually.
[02:08:52.080 --> 02:08:52.960]   And that's terrifying,
[02:08:52.960 --> 02:08:56.240]   because I've seen a lot of startups
[02:08:56.240 --> 02:08:59.120]   that are working on artificial intelligence technology
[02:08:59.120 --> 02:09:00.720]   that could do what you're saying.
[02:09:00.720 --> 02:09:01.840]   Listen to what you're saying
[02:09:01.840 --> 02:09:04.320]   and kind of infer recommendations and things like that.
[02:09:04.320 --> 02:09:06.960]   I want to disagree with one point.
[02:09:06.960 --> 02:09:08.240]   I really do like the Kindle.
[02:09:08.240 --> 02:09:09.680]   I think it's a fine device.
[02:09:09.680 --> 02:09:10.800]   The new Kindle is awesome.
[02:09:10.800 --> 02:09:11.840]   The Kindle is great.
[02:09:11.840 --> 02:09:13.440]   I like the paper white, that's the one I use.
[02:09:13.440 --> 02:09:14.880]   Yeah, you would like this new,
[02:09:14.880 --> 02:09:17.280]   it's 200 bucks, the new voyage,
[02:09:17.280 --> 02:09:19.760]   which is basically kind of like a paper white with no
[02:09:20.960 --> 02:09:22.960]   no compromises at all.
[02:09:22.960 --> 02:09:23.840]   It's really gorgeous.
[02:09:23.840 --> 02:09:25.920]   Yeah, you can really read fast.
[02:09:25.920 --> 02:09:27.600]   Well, it's got a faster process,
[02:09:27.600 --> 02:09:29.120]   the page turns or, you know,
[02:09:29.120 --> 02:09:30.400]   I mean, they've really done a nice job.
[02:09:30.400 --> 02:09:33.280]   Well, I bought Gebo,
[02:09:33.280 --> 02:09:37.120]   which is still not available and is exactly the same.
[02:09:37.120 --> 02:09:40.640]   So I don't know why I'm creeped out by this.
[02:09:40.640 --> 02:09:42.240]   Gebo, the whole idea of Gebo,
[02:09:42.240 --> 02:09:45.360]   and it's more expensive is it sits on your counter.
[02:09:45.360 --> 02:09:47.760]   And it looks at you.
[02:09:47.760 --> 02:09:49.200]   No, no, here's Gebo coming up here.
[02:09:49.200 --> 02:09:49.440]   Yeah.
[02:09:50.720 --> 02:09:52.800]   Well, isn't this what my Gebo looks at you?
[02:09:52.800 --> 02:09:54.640]   Oh, that's kind of creepy.
[02:09:54.640 --> 02:09:56.000]   It looks like the Pixar.
[02:09:56.000 --> 02:09:56.560]   It blinks.
[02:09:56.560 --> 02:09:59.280]   It looks like the Pixar light.
[02:09:59.280 --> 02:10:01.200]   Can you turn the audio up a little bit on it?
[02:10:01.200 --> 02:10:01.920]   Throughout their day.
[02:10:01.920 --> 02:10:04.160]   He's the world's best cameraman.
[02:10:04.160 --> 02:10:06.640]   By intelligently tracking the action around,
[02:10:06.640 --> 02:10:08.720]   it can independently take video.
[02:10:08.720 --> 02:10:10.000]   I didn't think it was creepy
[02:10:10.000 --> 02:10:12.160]   because it didn't come from Amazon or Microsoft.
[02:10:12.160 --> 02:10:13.280]   It comes from some,
[02:10:13.280 --> 02:10:16.080]   actually Cynthia Brazil, who is a robotic guru.
[02:10:16.080 --> 02:10:19.200]   It'll be sold to one of them.
[02:10:19.200 --> 02:10:20.640]   He's a hands-free helper.
[02:10:20.640 --> 02:10:23.280]   You can talk to him, and he'll talk to you back.
[02:10:23.280 --> 02:10:24.960]   So you don't have to skip a beat.
[02:10:24.960 --> 02:10:26.560]   Excuse me, Anne?
[02:10:26.560 --> 02:10:27.680]   Yes, Gebo.
[02:10:27.680 --> 02:10:31.200]   Melissa just sent a reminder that she's picking you up in
[02:10:31.200 --> 02:10:34.320]   half an hour to go grocery shopping.
[02:10:34.320 --> 02:10:35.360]   Thanks, Gebo.
[02:10:35.360 --> 02:10:38.080]   He's an entertainer and educator.
[02:10:38.080 --> 02:10:38.720]   Anyway, I have-
[02:10:38.720 --> 02:10:41.040]   And he initializes conversations?
[02:10:41.040 --> 02:10:41.920]   Apparently, he initiates conversations.
[02:10:41.920 --> 02:10:42.400]   Yeah, what are you doing?
[02:10:42.400 --> 02:10:43.280]   He looked depressed.
[02:10:43.280 --> 02:10:43.920]   Hey, Anne.
[02:10:43.920 --> 02:10:46.960]   Do you want to know how many tablespoons and a teaspoon?
[02:10:46.960 --> 02:10:47.200]   Anne?
[02:10:47.200 --> 02:10:48.400]   Anne.
[02:10:48.960 --> 02:10:50.400]   You haven't queried me lately.
[02:10:50.400 --> 02:10:52.240]   It's a needy robot.
[02:10:52.240 --> 02:10:52.960]   Where'd you go?
[02:10:52.960 --> 02:10:55.040]   There you are.
[02:10:55.040 --> 02:10:56.480]   Oh, I want you to this thing called-
[02:10:56.480 --> 02:10:57.440]   Oh, that's creepy.
[02:10:57.440 --> 02:10:58.640]   You're the target on the screen.
[02:10:58.640 --> 02:10:59.120]   Yeah.
[02:10:59.120 --> 02:11:01.360]   And you get a red dot on your forehead.
[02:11:01.360 --> 02:11:03.040]   That's what you're doing.
[02:11:03.040 --> 02:11:03.520]   I didn't-
[02:11:03.520 --> 02:11:04.800]   Okay, I don't know what's happened to me,
[02:11:04.800 --> 02:11:07.360]   but I didn't think this was creepy when I first saw it.
[02:11:07.360 --> 02:11:09.360]   And now, I really think this is creepy.
[02:11:09.360 --> 02:11:10.400]   What is the price?
[02:11:10.400 --> 02:11:13.200]   I think it was expensive because it's crowd-funded.
[02:11:13.200 --> 02:11:15.200]   So a skills-
[02:11:15.200 --> 02:11:18.480]   They've reached their $100,000 goal in four hours,
[02:11:18.480 --> 02:11:20.320]   $7 million in seven days.
[02:11:20.320 --> 02:11:21.840]   600-
[02:11:21.840 --> 02:11:23.840]   I'm sorry, yeah, $600.
[02:11:23.840 --> 02:11:24.560]   A piece?
[02:11:24.560 --> 02:11:24.800]   Yeah.
[02:11:24.800 --> 02:11:26.160]   So-
[02:11:26.160 --> 02:11:27.280]   And how late is it now?
[02:11:27.280 --> 02:11:29.600]   I don't know if it's late yet.
[02:11:29.600 --> 02:11:30.800]   Yeah, it's late.
[02:11:30.800 --> 02:11:32.080]   It doesn't actually exist.
[02:11:32.080 --> 02:11:32.640]   Like, no, no.
[02:11:32.640 --> 02:11:33.040]   No, no, no, no.
[02:11:33.040 --> 02:11:34.400]   And Amazon exists.
[02:11:34.400 --> 02:11:36.000]   Because when you think about it,
[02:11:36.000 --> 02:11:39.920]   what it costs to develop a sophisticated electronic product like that,
[02:11:39.920 --> 02:11:42.080]   I mean, it's great that they raised a million bucks,
[02:11:42.080 --> 02:11:42.240]   but-
[02:11:42.240 --> 02:11:42.960]   Not even close to what they-
[02:11:42.960 --> 02:11:44.320]   Man, yeah.
[02:11:44.320 --> 02:11:46.800]   And presumably, Amazon's been working on this for a long time,
[02:11:46.800 --> 02:11:48.400]   because the idea of the voice-recon-
[02:11:48.400 --> 02:11:50.240]   I mean, look, we've got Siri, we've got Cortana,
[02:11:50.240 --> 02:11:51.600]   we've got Google Now.
[02:11:51.600 --> 02:11:53.920]   But those companies all worked on those things for years,
[02:11:53.920 --> 02:11:57.840]   with a large research team and a lot of smart people.
[02:11:57.840 --> 02:11:59.120]   Where did this come from?
[02:11:59.120 --> 02:12:01.520]   I mean, Amazon all of a sudden has voice recognition.
[02:12:01.520 --> 02:12:04.640]   It had no product related at all.
[02:12:04.640 --> 02:12:05.600]   Yeah, yeah.
[02:12:05.600 --> 02:12:08.720]   So in that regard, at least it's impressive.
[02:12:08.720 --> 02:12:10.640]   It is plugged in.
[02:12:10.640 --> 02:12:11.680]   It's not battery-powered.
[02:12:11.680 --> 02:12:13.600]   It does the same thing as your phone, though, does, right?
[02:12:15.120 --> 02:12:16.800]   It does say connected to the cloud,
[02:12:16.800 --> 02:12:18.320]   so it's always getting smarter.
[02:12:18.320 --> 02:12:19.120]   That also-
[02:12:19.120 --> 02:12:19.840]   That's not good.
[02:12:19.840 --> 02:12:20.800]   Yeah.
[02:12:20.800 --> 02:12:25.440]   It really does play into this paranoia.
[02:12:25.440 --> 02:12:28.160]   It's terrifying.
[02:12:28.160 --> 02:12:29.120]   There's another-
[02:12:29.120 --> 02:12:31.120]   There's a startup I've been tracking called Ubi.
[02:12:31.120 --> 02:12:32.960]   It's been developing something like this as well,
[02:12:32.960 --> 02:12:35.120]   just like a thing you plug into wall socket.
[02:12:35.120 --> 02:12:37.520]   It's always listening and always serves as a speaker.
[02:12:37.520 --> 02:12:38.560]   Just kind of-
[02:12:38.560 --> 02:12:38.960]   Is-
[02:12:38.960 --> 02:12:40.880]   I could see it being useful eventually,
[02:12:40.880 --> 02:12:43.520]   but if we do all have smartphones near us all the time,
[02:12:43.520 --> 02:12:45.360]   it is tough to think of something like this.
[02:12:45.360 --> 02:12:46.960]   Like, what would you really use it for?
[02:12:46.960 --> 02:12:50.640]   Isn't this something that Microsoft was supposed to be doing with connect?
[02:12:50.640 --> 02:12:51.840]   Yeah, it feels a lot like connect.
[02:12:51.840 --> 02:12:56.480]   And you're told that connect's in the house on all the time
[02:12:56.480 --> 02:12:59.680]   can see what's in the room and figure,
[02:12:59.680 --> 02:13:03.600]   "Oh, this guy looks like he's got volumes one, two, and three of this book.
[02:13:03.600 --> 02:13:04.880]   Let's push volume four."
[02:13:04.880 --> 02:13:05.920]   Well, but connect-
[02:13:05.920 --> 02:13:06.960]   I'll vouch for it.
[02:13:06.960 --> 02:13:08.480]   When I sit down, it says, "Hi, Leo."
[02:13:08.480 --> 02:13:12.080]   When Michael comes in, he says, "Hi, Michael."
[02:13:12.640 --> 02:13:14.960]   When his mother comes in, it says, "Hi, Michael."
[02:13:14.960 --> 02:13:18.880]   So, well, she looks a little bit like her son,
[02:13:18.880 --> 02:13:20.720]   but it does see you,
[02:13:20.720 --> 02:13:23.040]   and in fact, it's always looking, obviously,
[02:13:23.040 --> 02:13:26.480]   because it wouldn't recognize you the minute you walk into the room.
[02:13:26.480 --> 02:13:27.520]   You can talk to it anytime.
[02:13:27.520 --> 02:13:28.400]   You say Xbox,
[02:13:28.400 --> 02:13:32.240]   you know, watch TV, and it'll turn on the TV.
[02:13:32.240 --> 02:13:33.840]   So what's creepier?
[02:13:33.840 --> 02:13:37.680]   Amazon having seven microphones listening to you 24/7
[02:13:37.680 --> 02:13:40.240]   or Microsoft having a video camera watching?
[02:13:40.240 --> 02:13:42.000]   Watching and watching.
[02:13:42.000 --> 02:13:43.920]   You put the two together, you got it made.
[02:13:43.920 --> 02:13:44.320]   Yeah.
[02:13:44.320 --> 02:13:49.200]   I don't know yet anybody who has bought this Amazon Echo,
[02:13:49.200 --> 02:13:51.440]   but I can't wait to get my G-Bo.
[02:13:51.440 --> 02:13:52.960]   All right.
[02:13:52.960 --> 02:13:56.560]   I don't know why, but in every one of these shows,
[02:13:56.560 --> 02:13:59.040]   we're doing best-ups from the year 2014.
[02:13:59.040 --> 02:14:01.680]   This is the best of 2014 for this weekend tech.
[02:14:01.680 --> 02:14:04.080]   The producers keep bringing this up.
[02:14:04.080 --> 02:14:06.960]   See, I didn't think all year long.
[02:14:06.960 --> 02:14:09.920]   I kept hearing this rumor that Apple was going to buy beats.
[02:14:09.920 --> 02:14:11.040]   That made no sense.
[02:14:11.040 --> 02:14:15.360]   And for some reason, obviously they did and I was wrong.
[02:14:15.360 --> 02:14:18.160]   All the producers have stuck in these clips of me saying,
[02:14:18.160 --> 02:14:20.320]   it ain't going to happen.
[02:14:20.320 --> 02:14:22.240]   All right.
[02:14:22.240 --> 02:14:24.240]   I think I'm going to go out on a limb here.
[02:14:24.240 --> 02:14:27.200]   Apple buying beats.
[02:14:27.200 --> 02:14:31.360]   This was the story that came out late last week.
[02:14:31.360 --> 02:14:34.800]   $3.2 billion.
[02:14:34.800 --> 02:14:39.600]   I'm not sure who had the story first.
[02:14:39.600 --> 02:14:40.480]   I can't remember.
[02:14:40.480 --> 02:14:41.680]   Was it the Financial Times?
[02:14:41.680 --> 02:14:44.080]   Was it anyway?
[02:14:44.080 --> 02:14:46.960]   Still no confirmation.
[02:14:46.960 --> 02:14:52.560]   I think it's a bogus rumor.
[02:14:52.560 --> 02:14:54.160]   I don't believe it.
[02:14:54.160 --> 02:14:54.640]   Really?
[02:14:54.640 --> 02:14:54.880]   Yeah.
[02:14:54.880 --> 02:14:56.480]   I thought Dr. Dre confirmed it.
[02:14:56.480 --> 02:14:58.880]   So Dr. Dre posted something on his Facebook
[02:14:58.880 --> 02:15:00.800]   that apparently was a phone call and he said,
[02:15:00.800 --> 02:15:02.960]   "I'm Raps first billionaire,"
[02:15:02.960 --> 02:15:07.840]   which he would be with a 25% stake in beats
[02:15:09.040 --> 02:15:10.320]   added to his existing fortune.
[02:15:10.320 --> 02:15:12.160]   He'd be well over a billion dollars.
[02:15:12.160 --> 02:15:13.200]   Then he pulled it down.
[02:15:13.200 --> 02:15:16.000]   Now, I got to tell you,
[02:15:16.000 --> 02:15:19.680]   beats business is almost entirely driven by marketing.
[02:15:19.680 --> 02:15:21.280]   It's bad.
[02:15:21.280 --> 02:15:22.480]   The headphones are crap.
[02:15:22.480 --> 02:15:22.880]   Oh, yeah.
[02:15:22.880 --> 02:15:27.120]   The streaming music service has been a flop,
[02:15:27.120 --> 02:15:30.720]   despite the fact that AT&T has offered a family plan for it
[02:15:30.720 --> 02:15:32.080]   and aggressively marketed it.
[02:15:32.080 --> 02:15:35.120]   It is a marketing driven business.
[02:15:35.120 --> 02:15:36.000]   It has been from day one.
[02:15:36.000 --> 02:15:37.920]   It's the name of Dr. Dre,
[02:15:37.920 --> 02:15:39.600]   the name of Jimmy Iovine,
[02:15:39.600 --> 02:15:42.080]   the music industry,
[02:15:42.080 --> 02:15:43.600]   cache, the design,
[02:15:43.600 --> 02:15:44.640]   the styling, and frankly,
[02:15:44.640 --> 02:15:46.480]   the huge advertising budget.
[02:15:46.480 --> 02:15:47.680]   By the way, not good.
[02:15:47.680 --> 02:15:49.120]   That was a terrible headphone.
[02:15:49.120 --> 02:15:50.080]   So you don't have any.
[02:15:50.080 --> 02:15:51.680]   I want to point out something
[02:15:51.680 --> 02:15:52.960]   that Chatham pointed out.
[02:15:52.960 --> 02:15:54.560]   Dr. Dre's not a real doctor.
[02:15:54.560 --> 02:15:55.360]   What?
[02:15:55.360 --> 02:15:56.000]   What?
[02:15:56.000 --> 02:15:56.800]   I don't believe that.
[02:15:56.800 --> 02:15:57.200]   What other lie?
[02:15:57.200 --> 02:15:59.600]   He's a doctor of musicology.
[02:15:59.600 --> 02:16:04.720]   He actually is a very important and successful producer
[02:16:04.720 --> 02:16:05.440]   in the music world.
[02:16:05.440 --> 02:16:07.360]   He's discovered a great many acts.
[02:16:07.360 --> 02:16:09.360]   Yeah, no, he's famous, including M&M.
[02:16:09.360 --> 02:16:12.000]   Mr. Snoop Dogg.
[02:16:12.000 --> 02:16:12.800]   You've heard of him.
[02:16:12.800 --> 02:16:13.440]   Mr. Snoop Dogg.
[02:16:13.440 --> 02:16:14.160]   Have you heard of him?
[02:16:14.160 --> 02:16:18.800]   Is that spelled D-O-G-D-O-G-G-R-D-A-W-G?
[02:16:18.800 --> 02:16:19.200]   D-A-A-A-A-W-G.
[02:16:19.200 --> 02:16:20.160]   It's a double...
[02:16:20.160 --> 02:16:21.520]   Go ahead.
[02:16:21.520 --> 02:16:22.080]   It's Snoop.
[02:16:22.080 --> 02:16:23.280]   It's Snoop lion now.
[02:16:23.280 --> 02:16:24.080]   Now it's lion,
[02:16:24.080 --> 02:16:24.880]   because he's a lion.
[02:16:24.880 --> 02:16:25.440]   Yeah.
[02:16:25.440 --> 02:16:26.960]   He's a lion of Judas.
[02:16:26.960 --> 02:16:28.240]   So you think this is bull crap?
[02:16:28.240 --> 02:16:31.840]   I am the only person in the world,
[02:16:31.840 --> 02:16:33.760]   apparently, who thinks this is bull crap.
[02:16:33.760 --> 02:16:35.280]   I cannot think of any reason
[02:16:35.280 --> 02:16:36.640]   why Apple should buy this company.
[02:16:36.640 --> 02:16:39.840]   Admittedly, they have a cash flow of a billion dollars a year,
[02:16:39.840 --> 02:16:43.120]   so a $3.2 billion acquisition is not an expensive acquisition.
[02:16:43.120 --> 02:16:45.360]   Well, you have three X sales is pretty high.
[02:16:45.360 --> 02:16:47.200]   But you also got to wonder why they're for sale.
[02:16:47.200 --> 02:16:51.120]   And I have a feeling that the streaming music service has been a flop.
[02:16:51.120 --> 02:16:52.960]   Well, not to be the only reason to buy them.
[02:16:52.960 --> 02:16:54.880]   Apple can make these deals.
[02:16:54.880 --> 02:16:55.920]   Apple has these deals.
[02:16:55.920 --> 02:16:57.360]   And there's no guarantee that
[02:16:57.360 --> 02:16:59.840]   Beats deals would survive a sale to Apple.
[02:16:59.840 --> 02:17:00.560]   The music industry...
[02:17:00.560 --> 02:17:01.040]   It wouldn't.
[02:17:01.040 --> 02:17:01.760]   It likely wouldn't.
[02:17:01.760 --> 02:17:02.560]   Yeah.
[02:17:02.560 --> 02:17:03.760]   So what are they buying?
[02:17:03.760 --> 02:17:04.720]   Well, it's an interesting thing.
[02:17:04.720 --> 02:17:05.200]   I'm actually...
[02:17:05.200 --> 02:17:06.240]   I think you're probably...
[02:17:06.240 --> 02:17:10.080]   If I'm hoping you're right, because if they are buying them,
[02:17:10.080 --> 02:17:11.520]   I think it's a bad thing.
[02:17:11.520 --> 02:17:13.760]   Like, I think it's a bad sign for Apple.
[02:17:13.760 --> 02:17:15.840]   Well, it's a sign they've lost their way, I think.
[02:17:15.840 --> 02:17:16.400]   Right.
[02:17:16.400 --> 02:17:17.440]   You don't know this?
[02:17:17.440 --> 02:17:18.960]   Well, I like to say it.
[02:17:18.960 --> 02:17:19.200]   Okay.
[02:17:19.200 --> 02:17:23.120]   They may have a grand scheme behind it all there.
[02:17:23.120 --> 02:17:23.680]   They haven't...
[02:17:23.680 --> 02:17:25.840]   They have yet to screw up Major League.
[02:17:25.840 --> 02:17:26.960]   Oh, no, no.
[02:17:26.960 --> 02:17:27.440]   Apple screwed up.
[02:17:27.440 --> 02:17:28.000]   I disagree.
[02:17:28.000 --> 02:17:28.480]   That's great.
[02:17:28.480 --> 02:17:29.920]   But what do you name one?
[02:17:29.920 --> 02:17:30.400]   Ping.
[02:17:30.400 --> 02:17:31.120]   iCloud.
[02:17:31.120 --> 02:17:31.280]   iCloud.
[02:17:31.280 --> 02:17:32.800]   iCloud.
[02:17:32.800 --> 02:17:34.480]   There's plenty of Apple scrups in the world.
[02:17:35.200 --> 02:17:36.800]   They have yet to...
[02:17:36.800 --> 02:17:39.120]   They've yet to create a music service,
[02:17:39.120 --> 02:17:43.760]   streaming music service that's any good,
[02:17:43.760 --> 02:17:44.560]   that's successful.
[02:17:44.560 --> 02:17:47.520]   iTunes radio does not work.
[02:17:47.520 --> 02:17:48.400]   iTunes is...
[02:17:48.400 --> 02:17:50.320]   It makes me want to punch myself in the face.
[02:17:50.320 --> 02:17:51.280]   I too, I agree to do.
[02:17:51.280 --> 02:17:52.080]   I agree.
[02:17:52.080 --> 02:17:52.320]   It's...
[02:17:52.320 --> 02:17:52.800]   Apple.
[02:17:52.800 --> 02:17:53.280]   Two words.
[02:17:53.280 --> 02:17:54.240]   I know you're going to defend it.
[02:17:54.240 --> 02:17:55.200]   Apple Maps.
[02:17:55.200 --> 02:17:57.360]   I know you love it.
[02:17:57.360 --> 02:17:58.400]   I didn't say I love it.
[02:17:58.400 --> 02:17:59.280]   I don't use an iPhone,
[02:17:59.280 --> 02:18:00.960]   but I do know that when I did a showdown
[02:18:00.960 --> 02:18:02.960]   with a bunch of people using different maps systems,
[02:18:02.960 --> 02:18:03.440]   the Apple Dats.
[02:18:03.440 --> 02:18:04.560]   I got one.
[02:18:04.560 --> 02:18:05.600]   I got lost.
[02:18:05.600 --> 02:18:07.360]   You got lost with Apple Maps?
[02:18:07.360 --> 02:18:09.200]   I was in the showdown.
[02:18:09.200 --> 02:18:10.560]   I got lost with Google Maps.
[02:18:10.560 --> 02:18:12.000]   You're trying to find a falafel place.
[02:18:12.000 --> 02:18:12.880]   I went to the wrong...
[02:18:12.880 --> 02:18:14.960]   Yeah, that's because you were using Google Maps.
[02:18:14.960 --> 02:18:16.000]   Yeah, the Apple Maps...
[02:18:16.000 --> 02:18:17.920]   John's scientific...
[02:18:17.920 --> 02:18:18.640]   It worked.
[02:18:18.640 --> 02:18:19.200]   Study.
[02:18:19.200 --> 02:18:21.200]   It was a study and you got lost.
[02:18:21.200 --> 02:18:21.760]   Science!
[02:18:21.760 --> 02:18:23.520]   Hey, yo.
[02:18:23.520 --> 02:18:24.240]   So, so...
[02:18:24.240 --> 02:18:25.760]   So you're right.
[02:18:25.760 --> 02:18:27.440]   Either this is like Apple's like,
[02:18:27.440 --> 02:18:28.240]   "What the hell?"
[02:18:28.240 --> 02:18:29.360]   You lost your way, Apple.
[02:18:29.360 --> 02:18:32.000]   Tim Cook has clearly got no new ideas.
[02:18:32.000 --> 02:18:33.040]   Or it's a false rumor.
[02:18:33.040 --> 02:18:34.960]   I prefer to think it's a false rumor.
[02:18:34.960 --> 02:18:38.080]   I have to say, though, maybe this is not
[02:18:38.080 --> 02:18:40.240]   a good deal or the right deal,
[02:18:40.240 --> 02:18:42.000]   but I cannot, for the life of me,
[02:18:42.000 --> 02:18:44.400]   understand why a company like Apple
[02:18:44.400 --> 02:18:46.880]   that is so good at so many things,
[02:18:46.880 --> 02:18:48.000]   particularly hardware,
[02:18:48.000 --> 02:18:51.200]   that makes people go insane
[02:18:51.200 --> 02:18:52.960]   and want to pay
[02:18:52.960 --> 02:18:56.000]   Vassums of money for their hardware and computers.
[02:18:56.000 --> 02:18:59.280]   Their cloud services are the worst.
[02:18:59.280 --> 02:19:00.080]   Yeah, they can't do it.
[02:19:00.080 --> 02:19:03.520]   It's a little bit invented by the Soviet Union in the '50s.
[02:19:03.520 --> 02:19:05.920]   They are so, except they're better looking.
[02:19:05.920 --> 02:19:08.720]   But they are so painful to use and so awkward
[02:19:08.720 --> 02:19:11.840]   and they do such incredibly terrible things.
[02:19:11.840 --> 02:19:13.200]   It's like, I don't know.
[02:19:13.200 --> 02:19:14.560]   I don't understand.
[02:19:14.560 --> 02:19:20.880]   I couldn't they spend some of their $160 million to hire some people
[02:19:20.880 --> 02:19:22.320]   who could figure this stuff out?
[02:19:22.320 --> 02:19:24.080]   It's just mind-blowing.
[02:19:24.080 --> 02:19:24.480]   We should point out that...
[02:19:24.480 --> 02:19:29.040]   You know, Cupertino to journalists is the Kremlin.
[02:19:29.040 --> 02:19:29.680]   So...
[02:19:29.680 --> 02:19:34.000]   And you say that as somebody who sits in Red Square all day,
[02:19:34.000 --> 02:19:36.960]   looking up at the towers of St. Peter's,
[02:19:36.960 --> 02:19:38.080]   the St. Basil's.
[02:19:38.080 --> 02:19:40.240]   So this is the funniest part of this.
[02:19:40.240 --> 02:19:43.840]   Jimmy Iovine and Dr. Dre would apparently become
[02:19:43.840 --> 02:19:45.200]   Apple executives.
[02:19:45.200 --> 02:19:48.160]   Yeah, well Dr. Dre part-time.
[02:19:48.160 --> 02:19:51.280]   What?
[02:19:51.280 --> 02:19:53.360]   Well, why?
[02:19:53.360 --> 02:19:54.720]   I'd love to see those meetings.
[02:19:54.720 --> 02:19:56.160]   For the bottom month.
[02:19:56.160 --> 02:19:57.280]   Yeah.
[02:19:57.280 --> 02:19:58.320]   Yeah, for the bottom month.
[02:19:58.320 --> 02:20:01.840]   I can't see Johnny I've looking at beats and saying those headphones
[02:20:01.840 --> 02:20:04.320]   are the greatest headphones we've never designed.
[02:20:04.320 --> 02:20:05.520]   I don't...
[02:20:05.520 --> 02:20:06.080]   I just...
[02:20:06.080 --> 02:20:06.720]   It does.
[02:20:06.720 --> 02:20:08.480]   It's not invented here.
[02:20:08.480 --> 02:20:09.280]   They're not great.
[02:20:09.280 --> 02:20:13.120]   I mean, nobody who likes audio says they're great headphones.
[02:20:13.120 --> 02:20:15.680]   They're highly enhanced bass, which is great for rap,
[02:20:15.680 --> 02:20:17.680]   but nobody thinks they're quality headphones.
[02:20:17.680 --> 02:20:18.160]   No.
[02:20:18.160 --> 02:20:20.560]   They're the kids like them because they got Dr. Dre.
[02:20:20.560 --> 02:20:21.600]   It's all about marketing.
[02:20:21.600 --> 02:20:27.600]   3.2 billion is coincidentally exactly what Google paid for.
[02:20:27.600 --> 02:20:29.520]   Nest, a thermostat company.
[02:20:29.520 --> 02:20:33.760]   So 3.2 billion is the new 1 million.
[02:20:33.760 --> 02:20:34.240]   I guess.
[02:20:34.240 --> 02:20:35.920]   That's weird.
[02:20:35.920 --> 02:20:39.200]   The other thing I'd point out is that most of Apple's 160 billion
[02:20:39.200 --> 02:20:40.960]   dollars is overseas is offshore.
[02:20:40.960 --> 02:20:43.760]   And to spend it there would be a significant tax consequence.
[02:20:43.760 --> 02:20:46.000]   They have to deal with that money and we're using that.
[02:20:46.000 --> 02:20:48.720]   So if beats were a European company,
[02:20:48.720 --> 02:20:51.760]   I'd say well that makes sense that you know because they've got all this cash
[02:20:51.760 --> 02:20:53.280]   offshore and they can't repatriate.
[02:20:53.280 --> 02:20:54.400]   But I don't...
[02:20:54.400 --> 02:20:55.840]   It's American company, right?
[02:20:55.840 --> 02:20:56.720]   Well, we don't know where it's...
[02:20:56.720 --> 02:20:58.720]   They carefully put offshore so they can't have...
[02:20:58.720 --> 02:20:59.440]   Well, it could be.
[02:20:59.440 --> 02:21:01.040]   I was using the Dutch Reach around.
[02:21:01.040 --> 02:21:01.600]   Could be in...
[02:21:01.600 --> 02:21:03.600]   That's different.
[02:21:03.600 --> 02:21:05.120]   It could be in Bermuda for all the time.
[02:21:05.120 --> 02:21:05.840]   I mean, I don't know.
[02:21:05.840 --> 02:21:06.880]   We didn't look into that.
[02:21:06.880 --> 02:21:07.520]   Well, let me see.
[02:21:07.520 --> 02:21:10.640]   Because nobody came up with the distance scam and a lie like you did.
[02:21:10.640 --> 02:21:12.320]   This is the first time I heard this idea.
[02:21:12.320 --> 02:21:14.000]   The Dutch Reach around?
[02:21:14.000 --> 02:21:14.960]   Did you just say that?
[02:21:14.960 --> 02:21:15.600]   Don't...
[02:21:15.600 --> 02:21:16.800]   It's not the name.
[02:21:16.800 --> 02:21:18.720]   I don't ask for any more details.
[02:21:18.720 --> 02:21:18.960]   All right.
[02:21:22.480 --> 02:21:28.320]   Beats by Dre formally established a 2008 is the brainchild of legendary artist and producer
[02:21:28.320 --> 02:21:33.600]   Dr. Dre and the chairman of Interscope Gefen A&M Records, Jimmy Iaveen.
[02:21:33.600 --> 02:21:34.480]   That's right there.
[02:21:34.480 --> 02:21:35.600]   I think that's offshore.
[02:21:35.600 --> 02:21:40.080]   I think Gefen in that whole operation is offshore and I think that's where they said this out.
[02:21:40.080 --> 02:21:40.640]   It's not offshore.
[02:21:40.640 --> 02:21:41.280]   It's gotta be.
[02:21:41.280 --> 02:21:41.760]   It's only now...
[02:21:41.760 --> 02:21:42.960]   I think you stumbled onto it.
[02:21:42.960 --> 02:21:44.080]   This is exactly what's going on.
[02:21:44.080 --> 02:21:47.840]   You mean right here where it says Beats Electronics is based in Santa Monica, California?
[02:21:47.840 --> 02:21:49.200]   It doesn't mean they're incorporated there.
[02:21:49.200 --> 02:21:50.320]   That's true.
[02:21:51.040 --> 02:21:54.080]   Beats is partially owned.
[02:21:54.080 --> 02:21:56.400]   There's a steak and beats from Hewlett Packard.
[02:21:56.400 --> 02:22:04.640]   25% of beats is owned by a financial holding firm that bought their steak from HTC.
[02:22:04.640 --> 02:22:09.600]   Remember HTC attempted to use the glitter of Beats to sell smartphones.
[02:22:09.600 --> 02:22:10.400]   Poor HTC.
[02:22:10.400 --> 02:22:11.680]   Yeah, that was a mistake.
[02:22:11.680 --> 02:22:13.680]   You know, it's actually what's really poor HTC.
[02:22:13.680 --> 02:22:19.680]   If they just held onto this deal, that quarter was saved HTC.
[02:22:19.680 --> 02:22:21.280]   Yeah, it would have been seven because they were tripled.
[02:22:21.280 --> 02:22:22.720]   They had a million dollars.
[02:22:22.720 --> 02:22:24.160]   All right, the valuation is tripled.
[02:22:24.160 --> 02:22:26.240]   Whoa, that's a good deal.
[02:22:26.240 --> 02:22:28.080]   We can run for another three years on that.
[02:22:28.080 --> 02:22:29.040]   It's just out of luck.
[02:22:29.040 --> 02:22:32.880]   I don't really understand like if Apple was going to do something like this,
[02:22:32.880 --> 02:22:35.520]   why wouldn't they just buy Spotify or somebody like that?
[02:22:35.520 --> 02:22:36.080]   Much better.
[02:22:36.080 --> 02:22:37.760]   Yeah, I mean Beats.
[02:22:37.760 --> 02:22:39.360]   Service people actually like.
[02:22:39.360 --> 02:22:44.000]   The thing that Beats streaming did it, they bought MOG, which was a nice service that wasn't
[02:22:44.000 --> 02:22:47.760]   was struggling, but they came too late because there's Google Music, there's Spotify, there's
[02:22:47.760 --> 02:22:49.760]   audio.
[02:22:49.760 --> 02:22:50.560]   Everybody's chosen.
[02:22:50.560 --> 02:22:56.720]   And I know this because the deal AT&T was offering $16 for a family was much better than the
[02:22:56.720 --> 02:22:58.240]   Spotify deal of the Google Music deal.
[02:22:58.240 --> 02:23:02.960]   So I went to my kids 18 and 22 and I said, "Hey kids, let's all use Beats."
[02:23:02.960 --> 02:23:04.480]   Okay, dad.
[02:23:04.480 --> 02:23:04.720]   No.
[02:23:04.720 --> 02:23:08.320]   They said, "No, I like Spotify.
[02:23:08.320 --> 02:23:09.920]   No, I like audio."
[02:23:09.920 --> 02:23:10.480]   Right.
[02:23:10.480 --> 02:23:11.920]   I mean, we're all using...
[02:23:11.920 --> 02:23:13.760]   Maybe they're too old.
[02:23:13.760 --> 02:23:16.400]   Oh yeah, if there were four, I could convince them.
[02:23:17.120 --> 02:23:18.160]   Yeah, that's what I'm thinking.
[02:23:18.160 --> 02:23:21.600]   Apparently, according to One Store, I read 200,000 subscribers.
[02:23:21.600 --> 02:23:24.640]   It's not a significant number, not worth billions.
[02:23:24.640 --> 02:23:28.320]   I'm going to be the New York Times confirming this.
[02:23:28.320 --> 02:23:30.000]   The Wall Street Journal is confirming this.
[02:23:30.000 --> 02:23:31.680]   It came from the Financial Times.
[02:23:31.680 --> 02:23:34.880]   I'm going to be the guy that stands up and says, "I call Beats."
[02:23:34.880 --> 02:23:36.080]   This would be a good call.
[02:23:36.080 --> 02:23:38.160]   Just a long shot.
[02:23:38.160 --> 02:23:39.840]   This is a...
[02:23:39.840 --> 02:23:41.360]   I think you're doing the right thing.
[02:23:41.360 --> 02:23:44.000]   But no one will remember if you're wrong anyway, so don't worry about it.
[02:23:44.000 --> 02:23:44.560]   That's true.
[02:23:44.560 --> 02:23:45.760]   That's the key.
[02:23:45.760 --> 02:23:47.360]   John Nunn understands this whole...
[02:23:47.360 --> 02:23:48.000]   Yeah, I know that game.
[02:23:48.000 --> 02:23:49.040]   It's all dynamic.
[02:23:49.040 --> 02:23:50.080]   Say something outrageous.
[02:23:50.080 --> 02:23:52.160]   If you're right, people will go, "Whoa, he knew it.
[02:23:52.160 --> 02:23:53.440]   He was the only one."
[02:23:53.440 --> 02:23:54.480]   It works.
[02:23:54.480 --> 02:23:56.640]   And if you're wrong, it's like, "Well, just another..."
[02:23:56.640 --> 02:23:59.840]   I'm the guy, by the way, said two weeks ago, "Short Apple."
[02:23:59.840 --> 02:24:00.800]   Oh yeah, that was a good one.
[02:24:00.800 --> 02:24:01.360]   That was a good call.
[02:24:01.360 --> 02:24:01.600]   Yeah.
[02:24:01.600 --> 02:24:03.120]   Fantastic.
[02:24:03.120 --> 02:24:05.680]   I'm the guy who went, "Apple said, 'We're going Intel.'
[02:24:05.680 --> 02:24:06.880]   Said, 'What are you nuts?'"
[02:24:06.880 --> 02:24:08.560]   So, I'm...
[02:24:08.560 --> 02:24:09.360]   Don't listen to me.
[02:24:09.360 --> 02:24:10.240]   I just...
[02:24:10.240 --> 02:24:11.440]   So, Matthew, you agree with me, though.
[02:24:11.440 --> 02:24:12.000]   I like this theory.
[02:24:12.000 --> 02:24:12.400]   This is a bad...
[02:24:12.960 --> 02:24:14.000]   This is a bad...
[02:24:14.000 --> 02:24:15.520]   I'm a bad bellwether for Apple, I think.
[02:24:15.520 --> 02:24:17.520]   I do, because as soon as I heard about it,
[02:24:17.520 --> 02:24:20.080]   even though I've never used Beats headphones,
[02:24:20.080 --> 02:24:20.800]   I've never...
[02:24:20.800 --> 02:24:22.240]   You know, I haven't used the service.
[02:24:22.240 --> 02:24:22.880]   It made me...
[02:24:22.880 --> 02:24:26.880]   It troubled me that they would
[02:24:26.880 --> 02:24:28.480]   pay that much for this thing.
[02:24:28.480 --> 02:24:30.400]   That says to me, "We're out of ideas."
[02:24:30.400 --> 02:24:33.520]   It would be the largest acquisition in Apple's history
[02:24:33.520 --> 02:24:35.520]   by several orders.
[02:24:35.520 --> 02:24:37.920]   Yeah, so you remember the good old days when
[02:24:37.920 --> 02:24:40.080]   the biggest acquisition Microsoft ever made
[02:24:40.080 --> 02:24:42.560]   was the $600 million one of web...
[02:24:42.560 --> 02:24:44.160]   Web, whatever it was called as...
[02:24:44.160 --> 02:24:44.960]   Web TV.
[02:24:44.960 --> 02:24:45.600]   Web TV.
[02:24:45.600 --> 02:24:48.160]   And all the guy they were pushing themselves in,
[02:24:48.160 --> 02:24:49.680]   you know, in kind of an awkward position,
[02:24:49.680 --> 02:24:51.600]   and then they went up, and then went up,
[02:24:51.600 --> 02:24:53.360]   and now they're just throwing money away.
[02:24:53.360 --> 02:24:54.800]   So, I have to correct myself.
[02:24:54.800 --> 02:24:57.120]   The Dutch reach around you right is something else.
[02:24:57.120 --> 02:24:59.600]   What Apple used is a strategy known as
[02:24:59.600 --> 02:25:01.840]   the double Irish with a Dutch sandwich.
[02:25:01.840 --> 02:25:04.080]   That's worse.
[02:25:04.080 --> 02:25:04.720]   That's a thing.
[02:25:04.720 --> 02:25:05.520]   That's a thing.
[02:25:05.520 --> 02:25:07.920]   I think that's just another word for the dirty Sanchez.
[02:25:07.920 --> 02:25:12.080]   We're going down an F-E road.
[02:25:12.080 --> 02:25:14.400]   I think we just brought the urban dictionary down.
[02:25:14.400 --> 02:25:20.480]   But what you do with the double Irish with the Dutch sandwich
[02:25:20.480 --> 02:25:22.880]   is you root profits through Irish and Dutch subsidiaries,
[02:25:22.880 --> 02:25:24.240]   and then off to the Caribbean,
[02:25:24.240 --> 02:25:26.720]   and that's exactly what Apple's been doing for some time now.
[02:25:26.720 --> 02:25:31.040]   The problem with doing that is they now have a huge cash stake.
[02:25:31.040 --> 02:25:32.720]   Overseas, but they can't use it.
[02:25:32.720 --> 02:25:35.600]   Here's a question.
[02:25:35.600 --> 02:25:37.840]   The Supreme Court has been bringing this up,
[02:25:37.840 --> 02:25:39.360]   that the corporations are people.
[02:25:40.160 --> 02:25:41.920]   And if you're a person, an individual,
[02:25:41.920 --> 02:25:43.920]   and you try to move your money and hide it off,
[02:25:43.920 --> 02:25:45.600]   sure, the IRS goes after you.
[02:25:45.600 --> 02:25:47.360]   Why don't they just go after this money?
[02:25:47.360 --> 02:25:49.760]   It's legal, because it's well, and I agree with you,
[02:25:49.760 --> 02:25:50.720]   but it is legal.
[02:25:50.720 --> 02:25:52.560]   That's basically the story.
[02:25:52.560 --> 02:25:53.280]   So far.
[02:25:53.280 --> 02:25:53.760]   So far.
[02:25:53.760 --> 02:25:57.840]   Anyway, I think that's enough on Beats.
[02:25:57.840 --> 02:26:00.640]   If the deal goes through, it will go through early next week,
[02:26:00.640 --> 02:26:03.040]   you know what we should do?
[02:26:03.040 --> 02:26:05.120]   Let's make a recording of this show.
[02:26:05.120 --> 02:26:06.880]   And then--
[02:26:06.880 --> 02:26:08.160]   Are you doing that now?
[02:26:08.160 --> 02:26:09.920]   I'm one step ahead of you.
[02:26:09.920 --> 02:26:11.040]   I agree that you do that right here.
[02:26:11.040 --> 02:26:12.080]   I think you're doing that.
[02:26:12.080 --> 02:26:14.640]   And then we can play it back next Sunday.
[02:26:14.640 --> 02:26:16.880]   Leo was right.
[02:26:16.880 --> 02:26:21.840]   It was a rumor created by Dr. Dre and Jimmy Iovine,
[02:26:21.840 --> 02:26:24.960]   in an attempt to sell headphones and stock or whatever,
[02:26:24.960 --> 02:26:27.280]   and to drum up, gin up some interest in a company
[02:26:27.280 --> 02:26:29.040]   that is actually failing.
[02:26:29.040 --> 02:26:30.320]   That's what I think.
[02:26:30.320 --> 02:26:31.040]   Now you've gone out.
[02:26:31.040 --> 02:26:32.560]   You actually took it good.
[02:26:32.560 --> 02:26:33.200]   Wait too far?
[02:26:33.200 --> 02:26:33.760]   Yeah.
[02:26:33.760 --> 02:26:34.400]   Wait too far.
[02:26:34.400 --> 02:26:36.400]   You don't--
[02:26:36.400 --> 02:26:38.320]   When you break up a crackpot idea like this,
[02:26:38.320 --> 02:26:40.320]   you don't want to extrapolate to make it worse.
[02:26:40.320 --> 02:26:41.520]   Oh yeah, just kind of--
[02:26:41.520 --> 02:26:42.080]   Vague out.
[02:26:42.080 --> 02:26:42.560]   Vague out.
[02:26:42.560 --> 02:26:43.680]   Vague out like.
[02:26:43.680 --> 02:26:44.720]   Wrong again, Leo.
[02:26:44.720 --> 02:26:48.080]   I'll tell you one thing I know I'm right about,
[02:26:48.080 --> 02:26:49.840]   and that's personal capital.
[02:26:49.840 --> 02:26:52.240]   We'll have more of the best of this week and take in a moment.
[02:26:52.240 --> 02:26:54.800]   It is time to make those New Year's resolutions,
[02:26:54.800 --> 02:26:57.520]   mind to eat healthier, get more exercise.
[02:26:57.520 --> 02:27:00.640]   And to make my money work harder,
[02:27:00.640 --> 02:27:04.160]   personal capital is exactly designed to do that.
[02:27:04.160 --> 02:27:06.720]   With personal capital, you can--
[02:27:06.720 --> 02:27:09.760]   and by the way, you should put this on your to-do list for 2015.
[02:27:09.760 --> 02:27:12.400]   You can keep track of everything you've got,
[02:27:12.400 --> 02:27:15.840]   all the assets, all the investments,
[02:27:15.840 --> 02:27:17.760]   where your money's going on charge cards,
[02:27:17.760 --> 02:27:19.600]   where your money's going on mortgages,
[02:27:19.600 --> 02:27:21.280]   what's in your checking and savings.
[02:27:21.280 --> 02:27:23.760]   For the first time, I bet for the first time ever,
[02:27:23.760 --> 02:27:26.000]   you will have, maybe since you were five years old,
[02:27:26.000 --> 02:27:29.440]   you will have an idea of exactly what your net worth is
[02:27:29.440 --> 02:27:30.640]   and where your money is.
[02:27:30.640 --> 02:27:31.760]   And more importantly,
[02:27:32.400 --> 02:27:34.080]   and I hope you're investing for the future.
[02:27:34.080 --> 02:27:35.680]   I hope you're planning for retirement.
[02:27:35.680 --> 02:27:38.480]   You'll know how your retirement funds are doing.
[02:27:38.480 --> 02:27:40.640]   You'll know if you're frittering money away,
[02:27:40.640 --> 02:27:41.840]   paying excess fees,
[02:27:41.840 --> 02:27:43.920]   or maybe you're invested in the wrong things,
[02:27:43.920 --> 02:27:45.600]   or you haven't rebalanced lately,
[02:27:45.600 --> 02:27:47.520]   personal capital can help you.
[02:27:47.520 --> 02:27:51.360]   They're already helping more than 600,000 investors,
[02:27:51.360 --> 02:27:53.920]   just like you manage and grow their wealth,
[02:27:53.920 --> 02:27:55.040]   including me, by the way.
[02:27:55.040 --> 02:27:56.160]   I love personal capital.
[02:27:56.160 --> 02:27:58.000]   I've been using it for two years now.
[02:27:58.000 --> 02:27:59.600]   Personal capital is a complete,
[02:27:59.600 --> 02:28:01.680]   intuitive financial dashboard.
[02:28:01.680 --> 02:28:04.240]   All your accounts in one place on one page,
[02:28:04.240 --> 02:28:06.880]   on your computer, your laptop, your tablet,
[02:28:06.880 --> 02:28:09.520]   even your phone, even your Android Wear watch,
[02:28:09.520 --> 02:28:11.920]   I get alerts from personal capital.
[02:28:11.920 --> 02:28:13.120]   You can grow your wealth,
[02:28:13.120 --> 02:28:16.960]   you can find and eliminate high mutual fund and 401K fees,
[02:28:16.960 --> 02:28:18.960]   you can find other hidden brokerage fees,
[02:28:18.960 --> 02:28:20.640]   you may not even have known about.
[02:28:20.640 --> 02:28:22.880]   They may be costing you years off your retirement.
[02:28:22.880 --> 02:28:24.400]   I mean, you worked hard for this money.
[02:28:24.400 --> 02:28:26.720]   You sucked it away, you did the right thing.
[02:28:26.720 --> 02:28:30.000]   Make sure your money is continuing to work as hard as you did.
[02:28:30.000 --> 02:28:31.280]   You'll also get tailored advice
[02:28:31.280 --> 02:28:32.640]   in optimizing your investment.
[02:28:32.640 --> 02:28:36.640]   Don't wait, take control of your financial future in 2015.
[02:28:36.640 --> 02:28:39.520]   Make that your resolution, it's free, why not?
[02:28:39.520 --> 02:28:43.120]   I want you to visit personal capital.com/twit
[02:28:43.120 --> 02:28:44.000]   and sign up today.
[02:28:44.000 --> 02:28:46.320]   It's secure, trust me, it's safe,
[02:28:46.320 --> 02:28:49.520]   it's absolutely secure, it's easy to do.
[02:28:49.520 --> 02:28:52.640]   And I promise you, you're gonna get real value out of this.
[02:28:52.640 --> 02:28:55.120]   Personalcapital.com/twit.
[02:28:55.120 --> 02:28:57.520]   We thank them for their support all year long
[02:28:57.520 --> 02:28:59.040]   for this week in tech.
[02:28:59.040 --> 02:29:02.560]   People sometimes say, why is Devorak on twit?
[02:29:02.560 --> 02:29:05.760]   They also sometimes say, why is in Devorak on twit more?
[02:29:05.760 --> 02:29:11.040]   Your reaction to this next clip will tell you which camp you belong.
[02:29:11.040 --> 02:29:15.840]   I think, maybe it's because I'm badly nearsighted.
[02:29:15.840 --> 02:29:20.800]   Because when I take off my glasses and I hold the phone
[02:29:20.800 --> 02:29:24.080]   right here, right up to my face, it's like a giant screen TV.
[02:29:24.080 --> 02:29:25.280]   Yeah, I can't, this thing does nothing.
[02:29:25.280 --> 02:29:27.200]   You don't know how to use Windows phone.
[02:29:27.200 --> 02:29:30.160]   This is the Nokia 1520, it's a six inch.
[02:29:30.160 --> 02:29:32.240]   How did you get this thing to come up like that?
[02:29:32.240 --> 02:29:34.880]   There's a button on the side, you press it and push in buttons.
[02:29:34.880 --> 02:29:36.000]   Isn't that beautiful?
[02:29:36.000 --> 02:29:37.120]   I think it's gorgeous.
[02:29:37.120 --> 02:29:38.160]   And that's not even customized.
[02:29:38.160 --> 02:29:39.280]   I put Windows Phone 8.1.
[02:29:39.280 --> 02:29:40.640]   I do think Windows Phone 8.1.
[02:29:40.640 --> 02:29:43.120]   So why does it say me and there's a little picture of you on here
[02:29:43.120 --> 02:29:43.920]   and it's flat and flat.
[02:29:43.920 --> 02:29:44.960]   In case I forget.
[02:29:44.960 --> 02:29:49.120]   It's a phone for people your age.
[02:29:49.120 --> 02:29:49.520]   Look at this.
[02:29:49.520 --> 02:29:51.520]   Who am I?
[02:29:51.520 --> 02:29:52.560]   Oh, I know.
[02:29:52.560 --> 02:29:53.680]   I don't think so.
[02:29:53.680 --> 02:29:54.160]   I'm me.
[02:29:54.160 --> 02:29:56.960]   I don't have one of these phones you do.
[02:29:56.960 --> 02:30:00.000]   So let's get that straight.
[02:30:00.000 --> 02:30:01.040]   And what's this photos?
[02:30:01.040 --> 02:30:02.080]   What is this?
[02:30:02.080 --> 02:30:03.760]   It's showing different photos constantly.
[02:30:03.760 --> 02:30:05.760]   Oh, ask permission before you do that.
[02:30:05.760 --> 02:30:07.760]   Don't do that.
[02:30:07.760 --> 02:30:10.720]   Natalie, you have a problem with selfies and bell fees?
[02:30:10.720 --> 02:30:12.160]   What's a bell fee?
[02:30:12.160 --> 02:30:13.840]   I do not like it when people open.
[02:30:13.840 --> 02:30:15.840]   My sister does this to me and just like flip through.
[02:30:15.840 --> 02:30:16.720]   Start scrolling through it.
[02:30:16.720 --> 02:30:18.080]   My photos.
[02:30:18.080 --> 02:30:20.320]   This is how I get two photos in here.
[02:30:20.320 --> 02:30:21.680]   It's bad gadget etiquette.
[02:30:21.680 --> 02:30:22.800]   My son did that to me.
[02:30:22.800 --> 02:30:25.520]   I was visiting my son at school in Colorado
[02:30:25.520 --> 02:30:27.040]   and he started flipping through my pictures.
[02:30:27.040 --> 02:30:29.280]   He said, stop.
[02:30:29.280 --> 02:30:31.920]   Well, then don't carry him on a phone.
[02:30:31.920 --> 02:30:32.800]   It's kind of nutty.
[02:30:32.800 --> 02:30:34.400]   Well, you can't have it if you take the picture.
[02:30:34.400 --> 02:30:35.760]   It's a personal device.
[02:30:35.760 --> 02:30:36.240]   Thank you.
[02:30:36.240 --> 02:30:38.000]   Like you get to just go through my wallet.
[02:30:38.000 --> 02:30:38.800]   So bell not.
[02:30:38.800 --> 02:30:41.200]   Our butt selfies.
[02:30:41.200 --> 02:30:42.560]   Who takes such a thing?
[02:30:42.560 --> 02:30:47.040]   It's the evolution of when we used to do that on a copy machine.
[02:30:47.040 --> 02:30:47.840]   It's disgusting.
[02:30:47.840 --> 02:30:49.520]   And it's huge.
[02:30:49.520 --> 02:30:50.080]   I saw.
[02:30:50.080 --> 02:30:51.680]   Especially we got a big butt.
[02:30:51.680 --> 02:30:55.280]   I saw Kelly do it on live with Regis and
[02:30:55.280 --> 02:30:56.720]   live with Kelly and Michael.
[02:30:56.720 --> 02:30:57.600]   She did a bell fee.
[02:30:57.600 --> 02:31:00.960]   Did you ever do that on a copy machine?
[02:31:00.960 --> 02:31:03.120]   I mean, I didn't.
[02:31:03.120 --> 02:31:04.160]   Did you Natalie?
[02:31:04.160 --> 02:31:08.400]   Yeah, I've done that before.
[02:31:08.400 --> 02:31:08.880]   You have.
[02:31:08.880 --> 02:31:13.040]   Yes, on a copy machine with my sister.
[02:31:13.040 --> 02:31:13.280]   Yeah.
[02:31:13.280 --> 02:31:18.320]   Unfortunately, unlike bell fees, there was no
[02:31:18.320 --> 02:31:20.000]   Instagram for Xerox copies.
[02:31:20.000 --> 02:31:21.120]   What are you doing?
[02:31:21.120 --> 02:31:22.080]   You're making noise.
[02:31:22.080 --> 02:31:23.040]   Yeah.
[02:31:23.040 --> 02:31:23.600]   You're hearing the-
[02:31:23.600 --> 02:31:24.000]   Keep talking.
[02:31:24.000 --> 02:31:24.880]   I just did the background.
[02:31:25.360 --> 02:31:29.200]   Tim Cook explains, by the way, what?
[02:31:29.200 --> 02:31:32.560]   Go on.
[02:31:32.560 --> 02:31:40.560]   So when I started out doing this in 1991, I did a radio show with John C. Devorak.
[02:31:40.560 --> 02:31:41.120]   And he would.
[02:31:41.120 --> 02:31:42.560]   It's a three hour radio show.
[02:31:42.560 --> 02:31:43.840]   Remember that Devorak on computers?
[02:31:43.840 --> 02:31:44.320]   Oh, yeah.
[02:31:44.320 --> 02:31:45.760]   And he'd get bored.
[02:31:45.760 --> 02:31:47.200]   I was easily bored.
[02:31:47.200 --> 02:31:49.360]   So I gave him a bunch of sound effects.
[02:31:49.360 --> 02:31:51.440]   It was my idea.
[02:31:51.440 --> 02:31:54.960]   You did dig up all the classics.
[02:31:54.960 --> 02:31:56.240]   Thousands of sound effects.
[02:31:56.240 --> 02:31:59.440]   And he would interrupt the show constantly, just like this.
[02:31:59.440 --> 02:32:09.440]   So what does Tim Cook say about iPad sales?
[02:32:09.440 --> 02:32:11.360]   He says there are two factors behind this.
[02:32:11.360 --> 02:32:15.040]   In the same quarter of a year prior, Apple had increased-
[02:32:15.040 --> 02:32:17.440]   This is, by the way, a bogus explanation.
[02:32:17.440 --> 02:32:18.160]   Can you stop?
[02:32:18.160 --> 02:32:19.920]   Don't you think this makes the show better?
[02:32:19.920 --> 02:32:22.960]   [LAUGHTER]
[02:32:22.960 --> 02:32:24.480]   This is cheesy music.
[02:32:24.480 --> 02:32:25.600]   Wow.
[02:32:25.600 --> 02:32:26.960]   What a year this has been.
[02:32:26.960 --> 02:32:29.840]   There was so much news, so much to talk about.
[02:32:29.840 --> 02:32:33.440]   That's one of the great things about doing the show this weekend tech.
[02:32:33.440 --> 02:32:36.800]   I sit down with some of the most interesting people like Bruce Shaniah.
[02:32:36.800 --> 02:32:41.760]   Each and every week, John C. Devorak, Becky Worley, Jason Heiner,
[02:32:41.760 --> 02:32:42.960]   some of the brightest minds.
[02:32:42.960 --> 02:32:45.760]   And we get to really understand what it means.
[02:32:45.760 --> 02:32:47.120]   What these news stories-
[02:32:47.120 --> 02:32:48.480]   They're not just news stories for us.
[02:32:48.480 --> 02:32:51.200]   They're really a launching point for a great discussion.
[02:32:51.200 --> 02:32:55.280]   And I hope you can see from this show how great it's been all year long.
[02:32:55.280 --> 02:32:59.920]   I look forward to an amazing 2015, and I hope you'll be along for the right.
[02:32:59.920 --> 02:33:05.440]   We do tweet every Sunday afternoon, 3 p.m. Pacific, 6 p.m. Eastern Time, 2300 UTC.
[02:33:05.440 --> 02:33:06.720]   You can watch live.
[02:33:06.720 --> 02:33:10.720]   And the chatroom is a very much a part of the show live.twit.tv.
[02:33:10.720 --> 02:33:15.200]   But you can also download on-demand versions of all of our shows at Twit.tv.
[02:33:16.560 --> 02:33:21.760]   Watch after the fact. Audio and video always available just a few hours after the show ends.
[02:33:21.760 --> 02:33:26.080]   So Twit, for example, you can easily get it in time for your Monday morning commute.
[02:33:26.080 --> 02:33:27.600]   That's when a lot of people listen, I know.
[02:33:27.600 --> 02:33:33.360]   You can also subscribe. That way you'll get every week on iTunes, the Xbox Music Store,
[02:33:33.360 --> 02:33:36.960]   Stitcher, and the great Twit apps, which are available on most platforms.
[02:33:36.960 --> 02:33:39.040]   Thanks to our third party developers.
[02:33:39.040 --> 02:33:41.600]   We heart you guys. Thanks for working so hard for us.
[02:33:41.600 --> 02:33:43.600]   Thanks to all of you for watching.
[02:33:43.600 --> 02:33:46.320]   We love doing Twit. We love doing all of our shows.
[02:33:46.320 --> 02:33:53.040]   I have to tell you personally, I feel so fortunate to be able to bring you this each and every week.
[02:33:53.040 --> 02:33:57.120]   It's the best job in the world. And I thank you for watching and making it possible.
[02:33:57.120 --> 02:34:01.840]   Thanks to all of our sponsors too. Because of them, we can give this to you absolutely free.
[02:34:01.840 --> 02:34:09.600]   So that's that for this year in Twit. Don't forget, our big New Year's party starts 3 a.m. New
[02:34:09.600 --> 02:34:16.800]   Year's Eve and goes live all the way to 3 a.m. New Year's Day. This time we're doing it as a benefit
[02:34:16.800 --> 02:34:22.560]   for the United Nations Children's Fund. They're doing some great work to fight Ebola in Africa
[02:34:22.560 --> 02:34:25.680]   to help children all over the world. And we want to raise a lot of money.
[02:34:25.680 --> 02:34:30.320]   So with your help, we will please stop by sometime during the New Year's Eve celebration.
[02:34:30.320 --> 02:34:38.320]   Help us count down to 2015 all around the world, all 27 time zones, all 24 hours.
[02:34:38.320 --> 02:34:42.400]   It's going to be a whole lot of fun. We've got some great stuff, some real surprises planned for
[02:34:42.400 --> 02:34:48.400]   you. So please stop by. If I don't see you then, I'll see you next time on This Week in Tech.
[02:34:48.400 --> 02:34:54.400]   I'm Leo LaPorte. Thanks for being here. Happy holidays and all the best for 2015.
[02:34:54.400 --> 02:34:59.440]   We really appreciate your being here and being part of what we do. Thanks a lot. Take care.
[02:34:59.440 --> 02:35:06.160]   Well, you got us to close the show first? Leo has to go pee.
[02:35:06.160 --> 02:35:11.680]   Well, I can put the camera on me. I can say it as well as anybody else.
[02:35:11.680 --> 02:35:15.680]   That is the end. Leo is in the bathroom. We'll see you later. Thank you, John de Borac.
[02:35:15.680 --> 02:35:20.400]   They thank me, yes. For bringing the show and making it really happy.
[02:35:20.400 --> 02:35:23.200]   Well, don't forget yourself. And thanks to myself. Thank you very much.
[02:35:23.200 --> 02:35:26.400]   Let's thank each other for a while. And then I can outdo the...
[02:35:26.400 --> 02:35:29.200]   Oh, well, he's... Ben Thompson. Thank you. Ben. Ben. Ben. Ben.
[02:35:29.200 --> 02:35:32.240]   Ben, we actually got the close-up by Leo. So we can...
[02:35:32.240 --> 02:35:34.080]   You want to do it together? You want to do another...
[02:35:34.080 --> 02:35:36.080]   You take it, man. You're here one day.
[02:35:36.080 --> 02:35:39.600]   Okay, well, this is going to be it. This is another twist is in the can.
[02:35:39.600 --> 02:35:44.960]   Leo, what's in the can?
[02:35:44.960 --> 02:35:47.120]   Leo, let's go with the can. Yes.
[02:35:47.120 --> 02:35:50.800]   Do the twist. All right. Do the twist, baby.
[02:35:50.800 --> 02:35:52.240]   Do the twist. All right.

