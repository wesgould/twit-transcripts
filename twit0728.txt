
[00:00:00.000 --> 00:00:06.160]   It's time for Twit. This weekend tech. We've got a great panel, Seth Winetrop from Electric,
[00:00:06.160 --> 00:00:11.920]   Paris Martynaux from Wired, our friend Ian Thompson from the Register. Equifax finally gets its
[00:00:11.920 --> 00:00:20.480]   just desserts. TikTok takes over and Amazon sells like crazy. It's all coming up next on Twit.
[00:00:23.440 --> 00:00:32.080]   NetCasts you love. This is Twit.
[00:00:32.080 --> 00:00:47.680]   This is Twit. This weekend tech, episode 728, recorded Sunday, July 21, 2019.
[00:00:48.480 --> 00:00:54.640]   Facebook Faskif. This weekend tech is brought to you by Capterra. Buy the right tools to make
[00:00:54.640 --> 00:01:01.360]   an informed software decision for your business. Visit Capterra's free website at capterra.com/twit
[00:01:01.360 --> 00:01:07.680]   and buy ExpressVPN. Protect your online privacy with one click. It's that easy. For three extra
[00:01:07.680 --> 00:01:16.720]   months free with a one-year package go to expressvpn.com/twit and buy rocket mortgage from quick and
[00:01:16.720 --> 00:01:21.760]   loans. They make the home buying process work for you. Picking loans, award-winning client service
[00:01:21.760 --> 00:01:28.560]   and support will help you every step of the way. So get started online today at rocketmortgage.com/twit
[00:01:28.560 --> 00:01:36.320]   and buy DoorDash. DoorDash connects you to your favorite restaurants in your city. Get $5 off
[00:01:36.320 --> 00:01:42.080]   your first order or $15 or more when you download the DoorDash app and enter the promo code Twit.
[00:01:45.600 --> 00:01:50.800]   It's time for Twit this weekend tech. The show we cover the week's tech news. Paris Martino is
[00:01:50.800 --> 00:01:56.160]   here from Wired. Always a pleasure in the very hot confines of the Wired offices.
[00:01:56.160 --> 00:02:02.560]   It is actually Manhattan. It looks like it's actually steaming. I was about to say it's a
[00:02:02.560 --> 00:02:07.040]   steamy in here and that's all right. We're all going to hopefully get steamed over some tech news
[00:02:07.040 --> 00:02:12.400]   too so we'll go back and forth. You can barely see across the island there. I'm looking out your
[00:02:12.400 --> 00:02:17.440]   window. It's just like steamy. Oh yeah. No, I have the blinds down. So you have the front
[00:02:17.440 --> 00:02:23.280]   that are kind of through now but it's also steamy out there. Yes, it really is. Welcome. It's good
[00:02:23.280 --> 00:02:31.040]   to have you Paris. Also here from 9 to 5 Mac, 9 to 5 Google and Electric. It's the publisher and
[00:02:31.040 --> 00:02:36.000]   one of our favorite people, Seth One. Hi, Seth. How's it going, Leo? Are you burning up?
[00:02:37.280 --> 00:02:42.800]   It is actually hot. I'm not Manhattan hot but we're an hour north. Not Manhattan hot.
[00:02:42.800 --> 00:02:51.280]   He's up the river though. So that's great to have you. Also from the register.co.uk
[00:02:51.280 --> 00:02:57.280]   our favorite Ian Thompson. He's one and only Ian Thompson. I hope so. There are no others.
[00:02:57.280 --> 00:03:03.040]   Information is going to be a little easier. Yeah, no kidding. Actually, I'd speak
[00:03:03.040 --> 00:03:07.520]   in a Vietnamese theft. I was very thrilled to hear that it looks like there'll be a $700 million fine
[00:03:07.520 --> 00:03:13.360]   for Equifax in the works. This is a settlement of, I don't know how many states attorneys general are
[00:03:13.360 --> 00:03:21.120]   suing, probably all 50. The federal government, the Department of Justice, the Federal Trade
[00:03:21.120 --> 00:03:28.960]   Commission and they made a package deal. Looks like $700 million and a promise it'll never happen
[00:03:28.960 --> 00:03:34.240]   again. Pinkie swear promise. It sounds like a lot of money but when you look at what
[00:03:34.240 --> 00:03:37.760]   the stock price has done since, it's not really going to affect them that much. It's the same sort
[00:03:37.760 --> 00:03:42.560]   of thing with Facebook slap on the wrist. $5 billion for Facebook. Yeah, I mean, why not charge
[00:03:42.560 --> 00:03:46.880]   these people? Yeah, because there's $700 million. It's not that much. No, why not do what GDPR does
[00:03:46.880 --> 00:03:50.400]   and charge these people on a percentage of their revenues and not their problems? Wouldn't that
[00:03:50.400 --> 00:03:54.080]   be a great idea? That way you can get all this tech accounting out of the way and companies might
[00:03:54.080 --> 00:03:58.160]   actually take it seriously. I'm just glad there was some punishment. It felt like you've kind of
[00:03:58.160 --> 00:04:03.360]   gotten off scot-free. In fact, all the evidence was they'd made money on the breach selling
[00:04:03.360 --> 00:04:07.920]   services to monitor your revenue. Well, a couple of things actually are now facing prison time for
[00:04:07.920 --> 00:04:11.120]   trying to make money on the breach in a different way by selling their shares early.
[00:04:11.120 --> 00:04:16.880]   I think the senior execs are going to get away with that one because the proof just isn't there.
[00:04:16.880 --> 00:04:20.560]   But yeah, charge people on revenue, not just these arbitrary numbers.
[00:04:20.560 --> 00:04:26.720]   Part of the problem also was that Equifax didn't tell anybody for three months.
[00:04:26.720 --> 00:04:32.720]   And that's one thing GDPR fixes, 72 hours notice. But given the amount of time they had, it was
[00:04:32.720 --> 00:04:38.160]   an awfully amateurish attempt. Yeah. That website didn't work. They got Domain Highjacked.
[00:04:38.160 --> 00:04:43.280]   It was just three months to prove several executives as soon as they heard about the breach that
[00:04:43.280 --> 00:04:48.960]   don't tell anyone and sold their stock. So that wasn't cool. That wasn't cool. That wasn't nice.
[00:04:48.960 --> 00:04:53.520]   Yeah, now to this day, if you sign up to try and freeze your credit or do something else,
[00:04:53.520 --> 00:04:59.840]   you'll just be bombarded with spam emails asking you to sign up for super dark web safety search
[00:04:59.840 --> 00:05:07.200]   or whatever that means. You remember what happened. What is so Paris? If you find out
[00:05:07.200 --> 00:05:11.840]   that your email is on the dark web, what are you going to do about it?
[00:05:11.840 --> 00:05:19.760]   I mean, I think that's a loaded question because when people say the dark web, they're like,
[00:05:19.760 --> 00:05:25.360]   oh, wow, some scevie sketchy website where bad things will happen. But the dark web is a lot of
[00:05:25.360 --> 00:05:32.560]   things. It's just the non-indexed web. And I mean, if your email is on there, maybe it's on some
[00:05:32.560 --> 00:05:36.400]   sort of list that someone compiled. Maybe it's on a list that's bad. Maybe it's on a list that's
[00:05:36.400 --> 00:05:40.400]   neutral. Maybe it's on a list that's good. I mean, it's not like you're wearing a book.
[00:05:40.400 --> 00:05:45.840]   Yeah, it's meaningless. Nothing you can do about it. I guess if you knew that a password was out there,
[00:05:45.840 --> 00:05:50.640]   you could change your password. But if you only use one password on every site, you're kind of
[00:05:50.640 --> 00:05:56.000]   well, you screwed it. You're treated away. You're dead. But I mean, the most visited site on
[00:05:56.000 --> 00:06:01.680]   on tour is Facebook. Right. You know, this, you know, it's not Facebook runs its own tour node.
[00:06:01.680 --> 00:06:06.560]   Oh, yeah. So I mean, it's, I mean, it's not all, you know, wretched, high-fives, common villainy. I
[00:06:06.560 --> 00:06:11.120]   mean, there's a lot of legit stuff on there as well. Although how useful is tour now that we've
[00:06:11.120 --> 00:06:18.880]   learned that in fact, the Russians, the Russians were actively breaking tour for the last two or three
[00:06:18.880 --> 00:06:28.720]   years. This was actually a great story. Hackers got into a contractor for the Russian, for the FSB,
[00:06:28.720 --> 00:06:36.240]   the Russian intelligence operation, and they exfiltrated terabytes of data, 7.5 terabytes.
[00:06:36.240 --> 00:06:43.360]   They defaced the company's website with a Yaba face. That's the emoji that stands for trolling
[00:06:43.360 --> 00:06:48.160]   in, I guess, Russians. It's, we use this here too. Right, Paris, you see this around.
[00:06:48.160 --> 00:06:56.800]   Not as often, but I gotta say it fits. Yeah, it does. It's a language in the US as well.
[00:06:56.800 --> 00:07:00.880]   They gained access to the companies into the company, by the way, which is called Cytech,
[00:07:01.600 --> 00:07:06.560]   was a contractor, not FSB, but a contractor. They got access to their entire network,
[00:07:06.560 --> 00:07:11.280]   including their JIRA instance, so they could see what people were working on.
[00:07:11.280 --> 00:07:17.840]   They posted screenshots of the servers on Twitter, posted the data, the data they'd stolen
[00:07:17.840 --> 00:07:24.720]   with digital revolution and other hacking group. And after some investigation of the exfiltrated
[00:07:24.720 --> 00:07:30.480]   data, we learned some interesting things. There was a project called Nautilus-S for DM
[00:07:30.480 --> 00:07:34.960]   Nautilus-S for the Nautilus-S for the Nautilus-S for the Nautilus-S for the Nautilus-S for the Nautilus-S.
[00:07:34.960 --> 00:07:36.720]   And the way you do that is you create rogue-torque service, and if you create enough of them, it
[00:07:36.720 --> 00:07:41.760]   becomes part of the network and you're able to see what people are doing with Tor. BBC
[00:07:41.760 --> 00:07:47.200]   Russia pointed out that the work on Nautilus-S had started seven years ago in 2012, two years later,
[00:07:47.200 --> 00:07:53.200]   in 2014, academics from Carl Stodd, University in Sweden. So the FBI is accused of trying
[00:07:53.200 --> 00:08:01.040]   something similar as well about four years ago. So DM Nautilus-S is bad, certainly.
[00:08:01.040 --> 00:08:06.960]   It's probably a good thing to understand that Tor only works as long as you've trusted the
[00:08:06.960 --> 00:08:13.360]   sense of fear. And the exit note is always an issue. If the entrance note is compromised,
[00:08:13.360 --> 00:08:18.640]   researchers identified 25 malicious Tor servers, 18 of which were in Russia.
[00:08:20.960 --> 00:08:24.400]   In fact, running that same version of Tor that was in these leaked files, there was
[00:08:24.400 --> 00:08:29.280]   Nautilus, a project for collecting data about social media users. Including MySpace, bless.
[00:08:29.280 --> 00:08:37.520]   Well, it was an old project. Facebook and LinkedIn. Mentor, a project to monitor and search email
[00:08:37.520 --> 00:08:43.440]   communications on servers of Russian companies. There was a pretty old...
[00:08:43.440 --> 00:08:48.160]   The tank's three-wombe was nasty. A project for the creation of a closed intranet
[00:08:49.680 --> 00:08:56.000]   intended for Russian state figures, judges, and local administration officials. In other
[00:08:56.000 --> 00:09:03.280]   words, we want that on intranet that we will be safe on. They also, though, were working
[00:09:03.280 --> 00:09:08.000]   with Project Hope to investigate the topology of the Russian internet and how it connects to
[00:09:08.000 --> 00:09:14.320]   other countries networks. And that's kind of interesting because earlier this year, you may
[00:09:14.320 --> 00:09:20.000]   remember Russia ran tests to disconnect from the rest of the world. And so it's thought that this
[00:09:20.000 --> 00:09:27.200]   Project Hope might have been part of that, trying to figure out if we wished to sever ties.
[00:09:27.200 --> 00:09:31.680]   Where would we cut the cable? What would we do?
[00:09:31.680 --> 00:09:37.760]   Cytech, the company hacked, has taken down its website and refused media inquiries.
[00:09:37.760 --> 00:09:43.040]   Since the hack. Although, yeah, it just seemed like the shadowbroker's moment for the Russians on
[00:09:43.040 --> 00:09:49.440]   this one. Although, I have seen some talk online about this is a false slug operation by the NISA,
[00:09:49.440 --> 00:09:52.400]   which has got this information, is now putting it out to hacking groups.
[00:09:52.400 --> 00:09:55.760]   Start down that, everyone. You'll never end up. Once you start into that.
[00:09:55.760 --> 00:09:57.760]   Yeah. You want to see kids what I'd look like?
[00:09:57.760 --> 00:10:00.400]   Oh, no. You haven't done this to have you, Leo.
[00:10:00.400 --> 00:10:03.200]   This is face-up. No.
[00:10:03.200 --> 00:10:05.280]   So...
[00:10:05.280 --> 00:10:10.480]   What are you laughing at? Five years. Five years from now.
[00:10:11.520 --> 00:10:12.400]   Maybe...
[00:10:12.400 --> 00:10:13.520]   I was going to say a bit.
[00:10:13.520 --> 00:10:14.240]   Sun's real.
[00:10:14.240 --> 00:10:14.800]   Yeah.
[00:10:14.800 --> 00:10:18.880]   We're a hat when you're using your e-bike.
[00:10:18.880 --> 00:10:22.080]   That's... And I'm sure Paris, because you monitor this stuff.
[00:10:22.080 --> 00:10:28.400]   This you've seen face-up faces all over Instagram and various social networks, right?
[00:10:28.400 --> 00:10:29.280]   All the kids are doing it.
[00:10:29.280 --> 00:10:36.560]   Oh, yeah. They've been everywhere. Everybody is posting different filters and faces from face-up.
[00:10:36.560 --> 00:10:42.320]   And consequently, almost everybody is now talking about some sort of misinformation
[00:10:42.320 --> 00:10:50.960]   regarding who owns face-up or what it does. My younger sister, even, who is just like an 18-year-old
[00:10:50.960 --> 00:10:55.600]   college student that I always ask her, "Oh, if you find anything interesting, you think might be an
[00:10:55.600 --> 00:11:00.080]   interesting tech influencer story, because she's a ball in the world. Let me know. The one and only
[00:11:00.080 --> 00:11:04.560]   thinks that her message me is, "I heard that face-ass is owned by the rest of the
[00:11:04.560 --> 00:11:08.720]   world. I'm like, 'Oh, if you're owned by all of your data.' I'm like, 'Maybe that has to do.'
[00:11:08.720 --> 00:11:09.120]   Maybe that has to do...
[00:11:09.120 --> 00:11:12.480]   It's owned by a company in St. Petersburg and like every app.
[00:11:12.480 --> 00:11:15.120]   If you give it access to all of your data, it owns all of that.
[00:11:15.120 --> 00:11:16.160]   It owns all your data.
[00:11:16.160 --> 00:11:16.720]   Sure.
[00:11:16.720 --> 00:11:22.320]   Apparently, Senator Chuck Schumer, the Senate minority leader, had never heard of such a thing.
[00:11:22.320 --> 00:11:27.280]   I guess Chuck doesn't know about Facebook, Instagram, Twitter.
[00:11:27.280 --> 00:11:31.280]   That's half any other app online.
[00:11:31.280 --> 00:11:36.640]   So, a couple of points. First of all, yes, it's a company based in St. Petersburg, but the guy
[00:11:36.640 --> 00:11:41.120]   who started it actually was working at Microsoft when he thought of FaceApp in Seattle. You've heard
[00:11:41.120 --> 00:11:45.680]   of Washington State. He said, "Wait a minute. We don't send the photos to Russia. We do upload
[00:11:45.680 --> 00:11:52.640]   them to the server, but the server is on Amazon Web Services and Google code, which, as any sensible
[00:11:52.640 --> 00:11:59.280]   app, that makes sense. They did in the license agreement say, "We own your picture forever for
[00:11:59.280 --> 00:12:03.200]   all time in any media here too after, and we can share it with anybody and give it to anybody."
[00:12:03.200 --> 00:12:05.760]   But that's just lazy lawyer boilerplate. That's what... I mean...
[00:12:05.760 --> 00:12:10.480]   Yeah, I mean, if you look in the terms of service for basically any app you download that is going to
[00:12:10.480 --> 00:12:14.000]   be uploading content to or from, it's going to say the same thing.
[00:12:14.000 --> 00:12:14.480]   It's just a...
[00:12:14.480 --> 00:12:18.960]   Well, these kids signed in a waiver to get into our studio that gives us the right to use their
[00:12:18.960 --> 00:12:25.280]   image forever in perpetuity on all media now known or ever invented in this time of the universe.
[00:12:25.280 --> 00:12:26.400]   If you could just leave you possible.
[00:12:26.400 --> 00:12:27.760]   You all signed that, right?
[00:12:27.760 --> 00:12:28.320]   No.
[00:12:28.320 --> 00:12:30.240]   Okay. Good. Because we're showing your face right now.
[00:12:30.240 --> 00:12:37.440]   So on the one hand, obviously, this is kind of a crazy response from Senator Schumer,
[00:12:37.440 --> 00:12:39.440]   and he actually said we got to investigate.
[00:12:39.440 --> 00:12:42.320]   Oh, the amount of fear, I'm angry on this, has just been painful.
[00:12:42.320 --> 00:12:47.840]   But on the other hand, I like it because people are finally sitting up and paying attention to privacy,
[00:12:47.840 --> 00:12:48.080]   right?
[00:12:48.080 --> 00:12:53.360]   Well, in cases like this, yes, but this is kind of... I mean, they're not taking...
[00:12:53.360 --> 00:12:55.600]   They're not worried about Google or Facebook or anything else.
[00:12:55.600 --> 00:12:57.680]   It's just like the Russians are coming. The Russians are coming.
[00:12:57.680 --> 00:13:04.880]   I think we can be... We can get concerned about privacy and private information,
[00:13:04.880 --> 00:13:09.920]   but this... It doesn't seem like they're doing that much wrong compared to any other social media
[00:13:09.920 --> 00:13:11.840]   firm. I mean, apparently the expo on this, but...
[00:13:11.840 --> 00:13:19.840]   Yeah, I mean, it seems kind of frankly a xenophobic response. We've had this sort of outcry when
[00:13:19.840 --> 00:13:25.920]   it's related to face app because there is a Russian involvement. And similarly,
[00:13:25.920 --> 00:13:33.600]   there was a similar outcry in regards to TikTok because it has, I guess, similar policies and a
[00:13:33.600 --> 00:13:40.640]   Chinese company. Bloomberg, I believe, wrote a whole article being like, "Oh, what's up with TikTok?
[00:13:40.640 --> 00:13:45.440]   This scary Chinese app that's building something for your kids and going to take your data."
[00:13:45.440 --> 00:13:52.240]   It's like, listen, all apps are taking your data in some way or another probably,
[00:13:52.240 --> 00:13:54.960]   and especially many of the apps that are targeted at children.
[00:13:54.960 --> 00:14:02.000]   And it's good to be aware of these privacy violations, but not solely just for a xenophobic or
[00:14:02.000 --> 00:14:06.000]   ethnic-based fear. We should also point out face apps have been around for two years.
[00:14:06.000 --> 00:14:10.800]   It's just now gotten... It's a second viral 15 minutes. My favorite...
[00:14:10.800 --> 00:14:13.120]   What do they call that? The Streisand effect?
[00:14:13.120 --> 00:14:15.760]   Yeah. Well, now it's going to even be more fun.
[00:14:15.760 --> 00:14:19.840]   It's huge now. Everybody's sending me stuff. It's been around two years.
[00:14:19.840 --> 00:14:25.120]   Right. Two years. My favorite warning is from the Democratic National Committee,
[00:14:25.120 --> 00:14:30.960]   who warned 2020 campaigns not to use face app. Yeah. The Russians don't know what your candidate
[00:14:30.960 --> 00:14:36.160]   looks like. I think they know. I'm sorry. Elections, QoT is a joke, and this is what
[00:14:36.160 --> 00:14:39.520]   that's about. Nobody knows what Hickenlooper looks like, but everybody else, I think they know.
[00:14:41.840 --> 00:14:45.440]   But the reason I don't mind this is because it does raise awareness.
[00:14:45.440 --> 00:14:52.240]   Your face, your fingerprint, your iris, your DNA, these are all biometric identifiers that
[00:14:52.240 --> 00:14:57.840]   aren't easily readily changed. You can even change your social, but you can't really change
[00:14:57.840 --> 00:15:01.600]   how you look or how your fingerprint works, how your DNA is.
[00:15:01.600 --> 00:15:04.000]   I'm pretty sure the Kardashians would have known.
[00:15:04.000 --> 00:15:08.880]   It's... The Kardashians may have had their DNA altered with that. It's sensible to me that
[00:15:08.880 --> 00:15:17.120]   people should at least start thinking about this. I don't mind the idea. These warnings go out
[00:15:17.120 --> 00:15:21.280]   fairly regularly. Remember when Instagram, everybody's freaked out over Instagram saying,
[00:15:21.280 --> 00:15:25.280]   "Oh, we own your photos." All the professional photographers said, "Oh, I never put your photos
[00:15:25.280 --> 00:15:30.640]   on Instagram." Instagram changed it because it's default lawyer-ease. It's like, "Well,
[00:15:30.640 --> 00:15:37.040]   cover your ass." We'll just take everything until something. I don't know if face app is going
[00:15:37.040 --> 00:15:41.440]   to sell pictures of my 88-year-old self. It's not just in this sector. I mean,
[00:15:41.440 --> 00:15:45.760]   a friend of mine on a rival publication and they tried to get inside new contracts saying,
[00:15:45.760 --> 00:15:49.440]   "Yeah, we own all your content produced inside or outside the office." It's like,
[00:15:49.440 --> 00:15:54.720]   "No, you don't." They sent it back with crossed out and said, "Oh, yeah, hang on. That's a bit
[00:15:54.720 --> 00:16:00.080]   strong." But what is... Okay, so is there any legitimacy to concern at all?
[00:16:04.720 --> 00:16:09.840]   I can see why. It's never ever bad to be concerned over these sort of things. Like you said,
[00:16:09.840 --> 00:16:15.120]   it's a valid concern and something that people should be concerned about in all aspects of their
[00:16:15.120 --> 00:16:21.040]   lives and a variety of different apps. But I don't know, it just seems kind of like a flash in the
[00:16:21.040 --> 00:16:28.400]   pan response for reasons that are not the primary concern. If Russia or China is an adversary,
[00:16:28.400 --> 00:16:35.120]   and I think it's not too far-fetched to say they might be, is there value to them in having a
[00:16:35.120 --> 00:16:41.040]   database of every 16-year-olds in the United States? It seems like there might be some value to that.
[00:16:41.040 --> 00:16:45.120]   I don't know. It's information that you get from pretty much anywhere.
[00:16:45.120 --> 00:16:46.000]   Right. I mean...
[00:16:46.000 --> 00:16:50.320]   You could Google their Instagram account and get the same photos of their face. Probably the face
[00:16:50.320 --> 00:16:56.560]   app photos that they uploaded there. I know a lot of parents, though, who are very cautious about
[00:16:56.560 --> 00:17:00.240]   publishing pictures of their young children. Yeah. Is that reasonable?
[00:17:00.240 --> 00:17:07.920]   Yeah. Good for them. Yeah. I mean, you're building a database, like somebody's building databases,
[00:17:07.920 --> 00:17:12.000]   all these facial recognition companies are building databases of people.
[00:17:12.000 --> 00:17:19.440]   I personally don't want my kids' faces. I post pictures of my kids, but not their faces,
[00:17:19.440 --> 00:17:24.320]   or not publicly. How do you know your kids, Seth? Eight and ten.
[00:17:24.880 --> 00:17:30.640]   What age will you let them be on Facebook or Instagram or what's that?
[00:17:30.640 --> 00:17:34.160]   I don't even think they're allowed to be on Facebook or Instagram till 13.
[00:17:34.160 --> 00:17:34.880]   That's 13, yeah. Although...
[00:17:34.880 --> 00:17:39.040]   Okay. Wait a minute, though. I got to say, I know a lot of parents who sign their kids up
[00:17:39.040 --> 00:17:44.800]   on Facebook and Instagram are... Really? Are you guys on Facebook? Yeah, of course you are.
[00:17:44.800 --> 00:17:52.160]   No. Oh, look at the Italian students saying, "No, no, no." They're already aware. That's interesting.
[00:17:52.160 --> 00:17:56.080]   I imagine young people are a little more aware than... Are you guys not on Facebook?
[00:17:56.080 --> 00:17:59.200]   You're aware that it's bad or just because Facebook is lame, though.
[00:17:59.200 --> 00:18:03.920]   Is it because it's old people? How do you say lame in Italian? I bet there's a really good word for lame.
[00:18:03.920 --> 00:18:11.360]   Yes. Ski-fo. I see a Facebook is ski-fo. They know that word.
[00:18:11.360 --> 00:18:15.120]   I thought you described as something my parents were on by the younger generation.
[00:18:15.120 --> 00:18:17.360]   Yes. The olds use it. The olds.
[00:18:20.560 --> 00:18:26.640]   I... I don't know. I think it's good to be aware of it. Obviously, face app is no worse than...
[00:18:26.640 --> 00:18:32.160]   I mean, if you're already on any other platform, the Russians probably have long ago got your face.
[00:18:32.160 --> 00:18:39.040]   Yeah. Do they use TikTok in Italy? Yeah? You like TikTok? No. You don't like TikTok?
[00:18:39.040 --> 00:18:43.200]   Come on. You can lip sync. You can sing along. All right.
[00:18:43.200 --> 00:18:48.320]   TikTok is great. Oh, yeah. I forgot. Paris is a TikToker. Wow.
[00:18:48.320 --> 00:18:53.360]   Love TikTok. Don't make any TikTok videos just alert. It's great. So... Big fan.
[00:18:53.360 --> 00:18:59.120]   Paris, you can explain to me. This is exactly like Vine, right? Exactly.
[00:18:59.120 --> 00:19:06.240]   Kind of, but it has... It's Vine, but more options, more creativity, more flexibility.
[00:19:06.240 --> 00:19:13.680]   While Vine was the restriction that kind of made the app and the content interesting was
[00:19:13.680 --> 00:19:20.480]   the short length of the videos. TikTok can be any... can be a wide variety of length,
[00:19:20.480 --> 00:19:25.280]   wide variety of like music. They have a lot of really great like built-in effects.
[00:19:25.280 --> 00:19:30.880]   Because they acquired musically, a lot of it is now lip syncing, right? This is...
[00:19:30.880 --> 00:19:35.440]   Yeah, but I mean, a lot of it isn't lip syncing though. The interesting thing is that TikTok
[00:19:35.440 --> 00:19:41.600]   like memes or moments or things like that. You can search by sound. So if you find like a really
[00:19:41.600 --> 00:19:47.440]   good meme genre that you like and think is funny, you click the sound on that and then you show
[00:19:47.440 --> 00:19:55.040]   everybody else doing kind of spins on or reacting to that meme. Oh, interesting. I mean,
[00:19:55.040 --> 00:20:00.960]   there is normal stuff like this, but I'm a fan. It feels to me like the same people who loved Vine
[00:20:00.960 --> 00:20:07.200]   are now back to TikTok doing stuff. Oh, definitely. Our social media editor here at
[00:20:07.200 --> 00:20:14.000]   WiredCam, he just created a Instagram account that is called, I think, Big Vine Energy
[00:20:14.000 --> 00:20:18.800]   that is just TikToks that have Vine energy, which I'm very excited about.
[00:20:18.800 --> 00:20:25.120]   Well, Twitter's got a feeling in this going, "Oh, we saw screwed up. They bought Vine and killed it."
[00:20:25.120 --> 00:20:34.960]   Terrible mistake. Why did they ever say why they killed Vine? How does that make any sense?
[00:20:35.840 --> 00:20:39.520]   Vine was making celebrities. I'm told at VidCon last week,
[00:20:39.520 --> 00:20:44.480]   which was ostensibly created for YouTube and YouTube stars by the Greens.
[00:20:44.480 --> 00:20:50.320]   It was all TikTok stars. Like the TikTok celebrities, the TikTok party was the party to be at.
[00:20:50.320 --> 00:20:54.080]   Oh, yeah. The TikTokers are where it's at.
[00:20:54.080 --> 00:21:00.720]   Yeah. I hope this is a flash in the mail. I'm sorry, I'm just too old for this.
[00:21:01.520 --> 00:21:06.720]   There is a lot of creativity, though. I mean, look at this guy.
[00:21:06.720 --> 00:21:12.000]   The Washington Post's TikTok account is fantastic, actually.
[00:21:12.000 --> 00:21:17.200]   Oh, so if you're a brand, if you're a brand, you should be on TikTok.
[00:21:17.200 --> 00:21:22.080]   All of the brand accounts, well, most of the brand accounts suck, but the Washington Post's
[00:21:22.080 --> 00:21:27.200]   TikTok account is wonderful because it is, they just understand exactly how to use TikTok.
[00:21:27.200 --> 00:21:30.480]   Interesting. Interesting. So I should follow the Washington Post.
[00:21:30.480 --> 00:21:33.760]   Fitting older than mine. Yeah, actually, they've got some new ones.
[00:21:33.760 --> 00:21:35.920]   What's the maximum length of a TikTok video?
[00:21:35.920 --> 00:21:38.480]   I don't know, actually. It's a great question.
[00:21:38.480 --> 00:21:40.960]   So Vine was what? Eight seconds? Six or eight seconds?
[00:21:40.960 --> 00:21:44.160]   Yeah. It was short. Six maybe.
[00:21:44.160 --> 00:21:47.440]   Maximum length.
[00:21:47.440 --> 00:21:53.680]   Are you googling maximum length of Vine?
[00:21:53.680 --> 00:21:56.960]   You gave me six. Do you second?
[00:21:56.960 --> 00:21:57.840]   Six seconds, wasn't it?
[00:21:57.840 --> 00:22:00.720]   It was pretty short. TikTok is not that short.
[00:22:00.720 --> 00:22:04.320]   Although, I noticed that most of them are roughly that same. They're Vine length.
[00:22:04.320 --> 00:22:08.400]   Maybe that's just a natural length.
[00:22:08.400 --> 00:22:09.040]   That's true.
[00:22:09.040 --> 00:22:11.280]   15 seconds, somebody's saying. That's ticked, must be ticked.
[00:22:11.280 --> 00:22:13.920]   Yeah, maybe we'll hold out by minutes and say for instance.
[00:22:13.920 --> 00:22:18.000]   All right, let's take a break. Come back. There's lots more to talk about.
[00:22:18.000 --> 00:22:23.920]   Lots more to talk about. And as long as we're xenophobic, we'll talk about Google banning
[00:22:24.720 --> 00:22:30.960]   a Chinese app from the Play Store. We'll talk about the president saying he's going to take
[00:22:30.960 --> 00:22:37.520]   a look at Google for ties with China. It's the xenophobia edition of this weekend tech.
[00:22:37.520 --> 00:22:38.960]   Particularly ironic considering the audience.
[00:22:38.960 --> 00:22:50.560]   Well, I don't know. Is Italy a good country? Yeah. That's where we get pasta. Pizza.
[00:22:52.720 --> 00:22:56.480]   Great students to come watch. Great students who come watch the show.
[00:22:56.480 --> 00:23:03.360]   We have a Google screen, a group of coding, COD, ENG, coding and engineering students from
[00:23:03.360 --> 00:23:10.560]   Varese, italia. Is that right? In studio with us in there. Very nice bunch.
[00:23:10.560 --> 00:23:16.880]   But where's the pizza? There's no pizza. Our show today brought to you by Kaptera.
[00:23:16.880 --> 00:23:22.000]   There is software for every line of business on Kaptera. And I think this is great because so
[00:23:22.000 --> 00:23:26.160]   many businesses and I've worked for some of them are using old, out-of-date software.
[00:23:26.160 --> 00:23:31.520]   Why else would anybody be running Vista or Internet Explorer 8? Because you have to, right?
[00:23:31.520 --> 00:23:37.520]   Because the software that the boss's nephew, Joey, wrote when he was in college, still runs
[00:23:37.520 --> 00:23:44.000]   the entire business. Joey's long gone. The good news is there's better software out there.
[00:23:44.000 --> 00:23:49.760]   State-of-the-art business software. And if you need it, Kaptera can find it. Over 700 categories
[00:23:49.760 --> 00:23:56.720]   of software. CMS, email marketing, IT service, SEO, workflow management. We actually replaced
[00:23:56.720 --> 00:24:01.360]   Twit ads with a little CRM program you might have heard of called Salesforce.
[00:24:01.360 --> 00:24:08.960]   Yeah, works pretty well. I don't know why we suffered for so long. 700 categories,
[00:24:08.960 --> 00:24:15.040]   tens of thousands of apps in every category. Line of business software like yoga studio management,
[00:24:16.160 --> 00:24:19.600]   big software like video conferencing software and everything in between.
[00:24:19.600 --> 00:24:25.840]   And here's the best part. You can search for the category, drill it down. You can filter it by
[00:24:25.840 --> 00:24:31.360]   product rating by how many users it supports, how it's deployed on premises or in the cloud,
[00:24:31.360 --> 00:24:35.760]   the features you need, can you make appointments, can you do billing with it, that kind of thing.
[00:24:35.760 --> 00:24:40.160]   Then you can compare them side by side up to four at a time. They'll even show you lists of
[00:24:40.160 --> 00:24:45.200]   related categories. But the best part about Kaptera is the reviews. They're getting close
[00:24:45.200 --> 00:24:52.880]   now to a million actual users reviews, a thousand new reviews every single day. In fact, if you get
[00:24:52.880 --> 00:24:58.320]   software that Kaptera recommended, please leave a review yourself because that makes it so much
[00:24:58.320 --> 00:25:04.480]   more useful. Pay it forward. All of this is free. Free. You don't even have to leave a review,
[00:25:04.480 --> 00:25:11.040]   although it'd be nice if you wanted to leave a review. Kaptera, C-A-P-T-E-R-R-A.com/Twit.
[00:25:11.040 --> 00:25:15.040]   No matter what kind of software your business needs, Kaptera makes it easy to discover the
[00:25:15.040 --> 00:25:23.600]   right solution fast. Check out Kaptera and do it for free. C-A-P-T-E-R-A is software selection
[00:25:23.600 --> 00:25:29.120]   simplified. But if you would, go to Kaptera.com/Twit. That way they'll know you saw it here.
[00:25:29.120 --> 00:25:35.600]   You'll support us and we thank Kaptera for supporting us. Kaptera.com/Twit.
[00:25:39.840 --> 00:25:43.760]   I got to balance the heavy stories with the light stories. Should we talk about World
[00:25:43.760 --> 00:25:49.040]   Emoji Day and the new emojis? It's a crowd-pleaser. Everybody loves emojis.
[00:25:49.040 --> 00:25:56.960]   You don't love emojis? That's a sign you're old, Ian. I prefer what's wrong with just
[00:25:56.960 --> 00:26:01.120]   codon dash out of bracket. I bet Paris likes emojis.
[00:26:01.120 --> 00:26:07.520]   Not the biggest emoji fan. They're not fine. They do what they need to do.
[00:26:08.160 --> 00:26:14.320]   Don't really use them. How do you say emoji in Italian? Emoji. You got to use your hand,
[00:26:14.320 --> 00:26:22.000]   though. Emoji. Emoji. They added falafel. I love this article in The Verge from John Porter.
[00:26:22.000 --> 00:26:30.960]   Why does Apple hate falafel? On the left, Apple's falafel. On the right, Google's falafel.
[00:26:30.960 --> 00:26:34.800]   Actually, they both look disgusting. I was going to say that's not doing falafel justice.
[00:26:37.600 --> 00:26:42.640]   So where's the humus? It reminds me of the whole burger or controversy.
[00:26:42.640 --> 00:26:49.520]   Where they messed up the organization of the burger. Which butter would you prefer?
[00:26:49.520 --> 00:26:54.240]   Apples or Google's? Apple's on the left. Google's doing Apple's fanny.
[00:26:54.240 --> 00:26:59.200]   Apple's look real. That looks like you could rub that on yourself.
[00:26:59.200 --> 00:27:05.120]   That's like that's butter is creamy. Okay. Gorillas and skunks.
[00:27:05.760 --> 00:27:11.200]   Left is Apple. Right is Google. Apple's emoji is just look much more developed.
[00:27:11.200 --> 00:27:15.840]   Lately, Apple has made their emojis more 3D and more photo realistic. That's kind of the thing
[00:27:15.840 --> 00:27:20.960]   they've changed to. Google's gone more. Skewomorphic, maybe? Skewomorphic. Yeah. That's a skeuomorphic
[00:27:20.960 --> 00:27:26.400]   scum. I could practically smell it. Google's gone more cartoony. And I actually have to say
[00:27:26.400 --> 00:27:32.400]   the Google skunk is a little Pepe Le Pew. It's a little. It's Pranson. It's Pranson. Yeah.
[00:27:33.200 --> 00:27:37.280]   It's Pranson. The most important thing in the emoji is the thing we probably should mention.
[00:27:37.280 --> 00:27:43.120]   It's much more inclusive. People with disabilities are represented. There's a
[00:27:43.120 --> 00:27:50.800]   guy with a stick. There's a guy dog. There's a prosthetic limb. And there's a wheelchair. And
[00:27:50.800 --> 00:27:54.960]   of course you can have a variety of people in a wheelchair. As I remember, I don't
[00:27:54.960 --> 00:28:00.240]   want to make sure I give credit. And actually I should ask Jeremy Burge because he runs
[00:28:00.240 --> 00:28:03.760]   emoji PDA and we see him all the time. Oh, I think it's part of the show with him.
[00:28:03.760 --> 00:28:08.960]   This guy's got chief emoji officer on his business cards. And he's on the Unicode
[00:28:08.960 --> 00:28:12.000]   consortium. Yeah. That's right. No, we run some on the committee.
[00:28:12.000 --> 00:28:17.360]   And we should point out the companies have a big presence on the committee. But anybody can
[00:28:17.360 --> 00:28:21.440]   submit for emoji. I want to give credit to Apple because I think it was Apple that went for the
[00:28:21.440 --> 00:28:28.560]   inclusive people with disabilities emojis. And the year before Google was the one pushing for a
[00:28:28.560 --> 00:28:33.440]   variety of shades of skin color. And you've probably noticed that in your emojis, you can choose,
[00:28:33.440 --> 00:28:36.880]   you know, and in the hand emojis in the face emojis, you can choose
[00:28:36.880 --> 00:28:41.600]   other skin colors. One Google to the first one is to do same-sized couples. I'm not entirely
[00:28:41.600 --> 00:28:48.880]   sure. I think that probably was Google as well. So the new emojis will be appearing in the next
[00:28:48.880 --> 00:28:55.200]   version of your operating system. iOS 13 for Apple, Android. Where are we? We're at Q?
[00:28:56.480 --> 00:29:04.160]   We're at Q for the Android folks. But I bet Seth on nine to five sites, emojis are
[00:29:04.160 --> 00:29:11.440]   articles rank very high. It's funny you mention that because they do. It's like,
[00:29:11.440 --> 00:29:15.920]   it's kind of a joke in our Slack room like, Oh, good. There's an emoji story today. We're going to
[00:29:15.920 --> 00:29:21.200]   have a big day. It's world emoji day. They are our traffic drivers. What do you think I just did it
[00:29:21.200 --> 00:29:30.080]   for? Hi in the show. There you go. You see? I don't have any way of measuring the top of the charts.
[00:29:30.080 --> 00:29:37.120]   As long as we're talking about Apple, there's a new MacBook Air released
[00:29:37.120 --> 00:29:44.320]   ironically with a slower hard drive. I'm more, but it was less expensive. It was 100 bucks less
[00:29:44.320 --> 00:29:49.360]   expensive. Yeah, I know. And it's not a slow hard drive. Let's be clear. It's still an SSD. Apple
[00:29:49.360 --> 00:29:56.400]   actually uses raw memory and uses a T2 chip to control it. And it is still instead of two gigabytes,
[00:29:56.400 --> 00:30:01.920]   I bet it's bytes per second read. But that was last year's MacBook Air. It's 1.3 gigabytes per
[00:30:01.920 --> 00:30:08.880]   second. Now, yeah, that sounds like a lot. But 1.3 gigabytes a second is still plenty of data.
[00:30:08.880 --> 00:30:13.120]   Yeah, you're not reading more than that. And if you are, you just strung on the cloud anyway.
[00:30:13.120 --> 00:30:18.400]   That's right. I'm still frustrated. They got rid of all the MacBook Pros that don't have the touch
[00:30:18.400 --> 00:30:24.240]   bar thing. I agree with you. I don't want I'm upset because I was just planning on buying a new
[00:30:24.240 --> 00:30:29.120]   MacBook Pro. I looked at it. I think that Sunday I was like, Oh, you know, I'll order it on Monday
[00:30:29.120 --> 00:30:34.080]   because we work above the Apple store here. And I was like, I'll go in and pick it up at work.
[00:30:34.080 --> 00:30:38.480]   That day, all of them are gone from the store. Well, they don't even say you couldn't even get it.
[00:30:38.480 --> 00:30:43.440]   Now I have to get one with the touch bar if I want a new MacBook Pro. And it's awful. I don't
[00:30:43.440 --> 00:30:49.040]   want that. It is a lot faster. The new MacBook Pro. But I hate the touch bar. It gets in my way.
[00:30:49.040 --> 00:30:53.600]   I hit it all the time. I read is rant about it. I haven't come across a single person that goes,
[00:30:53.600 --> 00:30:58.960]   Yeah, that's a good idea. Who thinks that's a good idea besides Apple? And they're still using
[00:30:58.960 --> 00:31:03.600]   it. Also, wait, is the touch bar where the power button is? Is that part of the display or is it
[00:31:03.600 --> 00:31:09.120]   still physical? So that seems problematic. What is the computer freezes? And well, but it's not,
[00:31:09.120 --> 00:31:13.120]   it's a physical button. It still moves it goes in. It's your fingerprint reader too.
[00:31:13.120 --> 00:31:16.640]   So the one thing it gives you, which is good, and it's on the MacBook Airs, the air is still
[00:31:16.640 --> 00:31:20.560]   the right solution. No touch bar, but it does have the fingerprint reader. And that's the on off
[00:31:20.560 --> 00:31:25.600]   switch and fingerprint reader. And I think I'm pretty sure on the touch bar, I used to have one.
[00:31:25.600 --> 00:31:31.200]   I got rid of it. That button is a physical button. So you're right. That might be haptic,
[00:31:31.200 --> 00:31:35.200]   actually. Oh, no, they do those weird things. Yeah, where you think it's physical? Because
[00:31:35.760 --> 00:31:41.520]   the reason that I think that it is is because when my MacBook Pro is totally dead,
[00:31:41.520 --> 00:31:48.800]   and I push the power button, there's no feedback. Like I push the button until I power it up.
[00:31:48.800 --> 00:31:52.800]   Right. You know, with a so annoying. So, so I think it's haptic.
[00:31:52.800 --> 00:31:58.720]   That's frustrating because my one thing is I, I don't know, run way too many tabs or programs
[00:31:58.720 --> 00:32:03.920]   in my computer. And once in a while, it would just freeze and I got to shut it off forcefully.
[00:32:03.920 --> 00:32:12.400]   Paris, I have some very good news for you. If you go to the certified refurbished Apple store,
[00:32:12.400 --> 00:32:18.720]   actually might be doing that right after this. Do that now. I'll give you some time.
[00:32:18.720 --> 00:32:26.560]   You could still buy the MacBook Pro. We called it the escape. It's just the 2015 one. No, it's
[00:32:26.560 --> 00:32:33.040]   last years. Oh, okay. Oh, great. Yeah. That's what I'm on right now. I'm a computer. I just want
[00:32:33.040 --> 00:32:40.320]   the exact same thing. We call it the Macbook Escape because it has a escape key and then you escape
[00:32:40.320 --> 00:32:45.680]   from the touch bar. So, yeah, they have a quite a, actually this is 2017, but I think they have
[00:32:45.680 --> 00:32:50.880]   quite a big selection. Yeah, there's quite a big selection of MacBook Pros on there. And when you
[00:32:50.880 --> 00:32:57.120]   get Apple refurbished, usually that means it was, it was just never used. It was, you know, somebody
[00:32:57.120 --> 00:33:01.680]   bought it and they can't sell it as new because the box was open. I think originally,
[00:33:01.680 --> 00:33:07.760]   released 2017 is what all of them will say, but it's effectively new and cheap.
[00:33:07.760 --> 00:33:10.160]   Yeah, so much deeper.
[00:33:10.160 --> 00:33:13.120]   Apple standards. Huh? By Apple standards.
[00:33:13.120 --> 00:33:15.040]   Nothing. Yeah. Cheap and Apple don't go together.
[00:33:15.040 --> 00:33:24.640]   I think that's all the Apple news I have. We did the emoji. Well, there's one more story.
[00:33:24.640 --> 00:33:28.480]   I don't know if this matters to anybody. It kind of matters to me because I'm a podcaster.
[00:33:28.480 --> 00:33:34.880]   Apple has, according to a guy named Mark Gurman, I think that's his name, Mark Gurman.
[00:33:34.880 --> 00:33:40.720]   I'm teasing Seth because how old was Mark when you discovered him? 17?
[00:33:40.720 --> 00:33:41.440]   I think he's eight.
[00:33:41.440 --> 00:33:45.840]   It was at nine to five.
[00:33:45.840 --> 00:33:46.960]   I found him on Facebook.
[00:33:46.960 --> 00:33:47.760]   He's awesome.
[00:33:47.760 --> 00:33:53.760]   He's gone now to Bloomberg, but I presume taking his sources with him.
[00:33:53.760 --> 00:33:58.800]   According to Gurman and Lucas Shaw on Bloomberg, Apple plans to bankroll original podcasts
[00:33:58.800 --> 00:34:01.040]   to fend off rivals.
[00:34:01.040 --> 00:34:04.960]   What? Like Twit? What? What was it?
[00:34:04.960 --> 00:34:05.360]   What was it?
[00:34:05.360 --> 00:34:05.920]   Yeah.
[00:34:05.920 --> 00:34:06.720]   Do you know that?
[00:34:06.720 --> 00:34:06.880]   Yeah.
[00:34:06.880 --> 00:34:10.560]   Trying to become the Netflix, the Netflix, a podcast or something?
[00:34:10.560 --> 00:34:18.640]   According to Gurman, well, first of all, this is all part of the revival, the renaissance of
[00:34:18.640 --> 00:34:25.360]   podcasting. In fact, the New York Times today had an article that said podcasting his,
[00:34:25.360 --> 00:34:30.240]   what was the term they used? Have we hit peak podcasts?
[00:34:30.240 --> 00:34:36.160]   And they featured this woman who did a podcast for like six weeks and gave up.
[00:34:36.160 --> 00:34:38.160]   How did they find her? I want to know.
[00:34:38.160 --> 00:34:43.760]   How do you find someone who didn't, who has a podcast that didn't take off?
[00:34:43.760 --> 00:34:45.440]   Well, because I don't know.
[00:34:45.440 --> 00:34:49.440]   It must have been. Just sat in a conference room with her iPhone and talked to her friend.
[00:34:49.440 --> 00:34:51.680]   And it was shocked when it wasn't great.
[00:34:51.680 --> 00:34:52.240]   Yeah.
[00:34:52.240 --> 00:34:53.760]   It was called the advice podcast.
[00:34:53.760 --> 00:34:58.560]   But really, this entire article in the New York Times, have we hit peak podcasts,
[00:34:58.560 --> 00:35:02.080]   is basically an advertisement for this woman because she's starting a new podcast.
[00:35:02.080 --> 00:35:02.880]   Oh, good grief.
[00:35:02.880 --> 00:35:09.360]   Essentially, I mean, we started doing podcasts at my previous job in 2009,
[00:35:09.360 --> 00:35:11.520]   and nobody listened to them.
[00:35:11.520 --> 00:35:12.080]   Absolutely.
[00:35:12.080 --> 00:35:14.960]   If it, yeah, because you just couldn't get that traction.
[00:35:14.960 --> 00:35:17.040]   Now you've been doing this longer than pretty much any one.
[00:35:17.040 --> 00:35:18.000]   2005.
[00:35:18.000 --> 00:35:18.240]   Yeah.
[00:35:18.240 --> 00:35:22.640]   Actually, I had my first podcast, 2004, September, 2004, which was right when it began.
[00:35:22.640 --> 00:35:27.520]   I mean, people had done audio on the, I'd done an audio on the internet before that.
[00:35:27.520 --> 00:35:31.680]   But the whole idea of making an RSS feed with a show in it that people could subscribe to
[00:35:31.680 --> 00:35:37.760]   and it automatically download that started when Dave Weiner, Adam Curry convinced Dave
[00:35:37.760 --> 00:35:45.120]   Weiner to add binary enclosures to RSS saying, you know, that enclosure could be an audio file.
[00:35:45.120 --> 00:35:46.640]   And then people could subscribe to it.
[00:35:46.640 --> 00:35:47.760]   Dave did it.
[00:35:47.760 --> 00:35:54.000]   And if the fall of 2004, a number of people, including Dave and Adam and myself started doing
[00:35:54.000 --> 00:35:54.480]   podcasts.
[00:35:54.480 --> 00:35:57.280]   So I'm glad to see that it's back.
[00:35:57.280 --> 00:36:05.120]   Podcast listenership, according to Bloomberg, has more than doubled in the last, what is that,
[00:36:05.120 --> 00:36:05.920]   five years?
[00:36:07.520 --> 00:36:10.000]   And apparently they're worried about Spotify.
[00:36:10.000 --> 00:36:15.520]   Because remember, Spotify bought Gimlet for a hundred, but 210 million, 230 million dollars.
[00:36:15.520 --> 00:36:23.280]   And it's pretty clear Spotify's plan is to have exclusive podcasts produced by Glimlet,
[00:36:23.280 --> 00:36:26.480]   which will be available on both the paid and free tier.
[00:36:26.480 --> 00:36:30.720]   And so they'll make money in advertising on the free tier and they'll make money from people
[00:36:30.720 --> 00:36:32.480]   paying for it to hear these podcasts.
[00:36:32.480 --> 00:36:34.400]   Maybe they'll even be podcasts you have to pay for.
[00:36:35.600 --> 00:36:36.720]   This is a model to me.
[00:36:36.720 --> 00:36:39.120]   I mean, this is a little inside baseball, so I'll move on.
[00:36:39.120 --> 00:36:42.400]   But this is a model to me that I see a lot.
[00:36:42.400 --> 00:36:45.520]   I think Gimlet did this serial and all that stuff.
[00:36:45.520 --> 00:36:46.800]   It's the TV model.
[00:36:46.800 --> 00:36:49.360]   See, I think a podcast is radio shows.
[00:36:49.360 --> 00:36:49.920]   We're sitting around.
[00:36:49.920 --> 00:36:51.040]   We're doing a radio show.
[00:36:51.040 --> 00:36:51.360]   Yeah.
[00:36:51.360 --> 00:36:51.680]   Let's do it.
[00:36:51.680 --> 00:36:56.560]   But some podcast producers think of it as a TV series, an audio TV series.
[00:36:56.560 --> 00:36:58.400]   So it's going to have 13 episodes.
[00:36:58.400 --> 00:36:59.600]   It's going to have seasons.
[00:36:59.600 --> 00:37:04.240]   And I think this is exactly what Apple says, we're going to bankroll original podcasts.
[00:37:04.240 --> 00:37:09.920]   That sounds to me like the same model that they're using for their Apple TV plus shows.
[00:37:09.920 --> 00:37:12.000]   They're going to use for podcasts.
[00:37:12.000 --> 00:37:14.560]   It won't be as expensive as that of $15 million in episode.
[00:37:14.560 --> 00:37:16.480]   It'll be maybe $15 in episode.
[00:37:16.480 --> 00:37:19.360]   But they'll pay people to do exclusive podcasts.
[00:37:19.360 --> 00:37:22.880]   It'll only be available on Apple's whatever platform.
[00:37:22.880 --> 00:37:28.720]   I just wish they would spend some of this money making the Apple podcast app not terrible
[00:37:28.720 --> 00:37:30.080]   because it is bad.
[00:37:30.080 --> 00:37:33.840]   As a person who is used, I listen to so many podcasts every single day.
[00:37:33.840 --> 00:37:35.200]   It's honestly absurd.
[00:37:35.200 --> 00:37:40.720]   But I used to only exclusively use the Apple podcast app because I was like,
[00:37:40.720 --> 00:37:42.080]   oh, Spotify, a new player in this.
[00:37:42.080 --> 00:37:44.640]   I don't want to contribute to that.
[00:37:44.640 --> 00:37:46.960]   But the Apple podcast app is terrible.
[00:37:46.960 --> 00:37:51.440]   There's just no, it looks like it was designed by someone who isn't listening to podcasts
[00:37:51.440 --> 00:37:52.720]   at any sort of mass.
[00:37:52.720 --> 00:37:55.680]   And Spotify is just already leagues ahead.
[00:37:55.680 --> 00:38:01.440]   And I'm sure all the bespoke podcast listening apps are even leagues ahead of that.
[00:38:01.440 --> 00:38:02.240]   Well, that's what I'm.
[00:38:02.240 --> 00:38:03.440]   So I don't know.
[00:38:03.440 --> 00:38:04.800]   And I do know our stats.
[00:38:04.800 --> 00:38:11.600]   iTunes still is number one, but it used to be 80 or 90 percent of our downloads is less than 40
[00:38:11.600 --> 00:38:12.320]   percent now.
[00:38:12.320 --> 00:38:19.520]   Pocketcast, which is a bespoke, as you call it, a podcast app and a very good one,
[00:38:19.520 --> 00:38:23.120]   owned by public radio now, by the way, is number two.
[00:38:23.120 --> 00:38:27.840]   And then quite a few, there's Overcast, which is excellent.
[00:38:27.840 --> 00:38:31.280]   That's Marco Arment's audio only podcast program.
[00:38:31.280 --> 00:38:33.280]   And quite a few good podcast programs.
[00:38:33.280 --> 00:38:36.720]   I think a lot of podcast listeners honestly listen on their voice assistant.
[00:38:36.720 --> 00:38:41.840]   They say, "Echo, listen to this week in tech," or "Echo, listen to Joe Rogan," or whatever.
[00:38:41.840 --> 00:38:44.320]   And that's one way people listen to.
[00:38:44.320 --> 00:38:48.240]   Nothing hardware has had a massive role in this, because when podcasts first came out.
[00:38:48.240 --> 00:38:49.120]   Oh, it will change everything.
[00:38:49.120 --> 00:38:49.360]   Yeah.
[00:38:49.360 --> 00:38:51.360]   It was that they were a paint download and listened to.
[00:38:51.360 --> 00:38:53.040]   And now you can just stack it, string your phone.
[00:38:53.040 --> 00:38:55.200]   Well, you got to wonder why we still call them podcasts.
[00:38:55.200 --> 00:38:56.960]   They're barely as an iPod anymore.
[00:38:56.960 --> 00:38:58.080]   Right?
[00:38:58.080 --> 00:39:00.320]   The iPod name will live on in podcasts.
[00:39:00.320 --> 00:39:02.000]   Didn't they just release a new iPod?
[00:39:02.000 --> 00:39:04.000]   They have one last iPod, the iPod Touch.
[00:39:04.000 --> 00:39:06.320]   But the iPod to ruin them all.
[00:39:06.320 --> 00:39:06.880]   Roll them all.
[00:39:06.880 --> 00:39:07.840]   Yeah.
[00:39:07.840 --> 00:39:12.080]   It's not a, I mean, nobody listens to podcasts on their iPod.
[00:39:12.080 --> 00:39:15.040]   So...
[00:39:15.040 --> 00:39:16.400]   Sure, there's some purists out there.
[00:39:16.400 --> 00:39:16.800]   But yes.
[00:39:16.800 --> 00:39:22.720]   As a podcast listener, Paris, are you attracted by the notion of exclusive podcasts?
[00:39:22.720 --> 00:39:27.200]   You can only get on a platform like Spotify or Apple's podcast.
[00:39:27.200 --> 00:39:33.920]   No, honestly, I mean, whenever I hear exclusive content, whether it be like Spotify or Apple or
[00:39:33.920 --> 00:39:37.760]   something else, it kind of turns me off to it because I'm like, I don't want to be manipulated
[00:39:37.760 --> 00:39:40.320]   into using your service just to listen to this.
[00:39:40.320 --> 00:39:45.200]   It's the same way that this makes absolutely no sense because I don't act against my best interest.
[00:39:45.200 --> 00:39:51.040]   One podcast I like do that thing where it's Thursday, the day an episode comes out.
[00:39:51.040 --> 00:39:55.520]   But instead of an episode of the podcast, I get an episode of some other podcast in the network
[00:39:55.520 --> 00:39:56.880]   that they think will really like.
[00:39:56.880 --> 00:39:58.080]   I'm like, I'm not going to listen to that.
[00:39:58.080 --> 00:39:58.720]   I hate that.
[00:39:58.720 --> 00:40:03.200]   I'm not going to be fed content just so that I can be moved in to be an audience member
[00:40:03.200 --> 00:40:06.240]   of some other show, even though I probably would like it.
[00:40:06.240 --> 00:40:07.920]   I'm just...
[00:40:07.920 --> 00:40:10.560]   I will never do that to Paris, I promise.
[00:40:10.560 --> 00:40:11.120]   Thank you.
[00:40:11.120 --> 00:40:13.680]   Our feeds are...
[00:40:13.680 --> 00:40:15.600]   They're pure.
[00:40:15.600 --> 00:40:16.240]   They're pure.
[00:40:16.240 --> 00:40:17.200]   They're sacred.
[00:40:17.200 --> 00:40:19.520]   I think maybe Apple's thinking...
[00:40:19.520 --> 00:40:23.680]   Remember that satellite radio was about dead until Howard Stern went there.
[00:40:23.680 --> 00:40:26.720]   And in order to get Howard Stern, you had to subscribe to satellite radio.
[00:40:26.720 --> 00:40:28.160]   Maybe they're thinking that.
[00:40:28.160 --> 00:40:30.880]   Maybe they're thinking if we get somebody...
[00:40:30.880 --> 00:40:33.280]   I don't know who it is, Taylor Swift, Kim Kardashian.
[00:40:33.280 --> 00:40:34.000]   I don't know who it is.
[00:40:34.000 --> 00:40:39.680]   But if they got Joe Rogan, that would be interesting.
[00:40:39.680 --> 00:40:44.880]   And Joe said, you can't listen to my podcast unless you listen to it on Apple's platform.
[00:40:44.880 --> 00:40:45.680]   I don't think you do that.
[00:40:45.680 --> 00:40:47.600]   No, I mean, I think these things work.
[00:40:47.600 --> 00:40:49.200]   I'm now that I'm thinking about it.
[00:40:49.200 --> 00:40:49.760]   What is it?
[00:40:49.760 --> 00:40:52.320]   Some Gimlet podcast.
[00:40:52.320 --> 00:40:53.040]   Crime Town.
[00:40:53.040 --> 00:40:53.600]   Crime Town.
[00:40:53.600 --> 00:40:55.600]   The second fantastic podcast.
[00:40:55.600 --> 00:40:55.920]   Yes.
[00:40:55.920 --> 00:40:56.480]   Love it.
[00:40:56.480 --> 00:41:00.480]   I listened to the first season, didn't realize the second season was out.
[00:41:00.480 --> 00:41:03.120]   They were releasing episodes one by one on Apple podcast.
[00:41:03.120 --> 00:41:06.240]   And then I saw that all of them were available on Spotify.
[00:41:06.240 --> 00:41:07.120]   So I used it.
[00:41:07.120 --> 00:41:10.400]   And now I honestly use Spotify predominantly.
[00:41:10.400 --> 00:41:11.040]   Interesting.
[00:41:11.040 --> 00:41:12.400]   Because it's so much better.
[00:41:12.400 --> 00:41:13.760]   So that did work.
[00:41:13.760 --> 00:41:15.520]   They did get me in the end.
[00:41:15.520 --> 00:41:16.960]   So...
[00:41:16.960 --> 00:41:17.440]   I've never...
[00:41:17.440 --> 00:41:18.080]   It's a good stretch.
[00:41:18.080 --> 00:41:19.760]   So according to...
[00:41:19.760 --> 00:41:22.960]   I know industry executives, nobody asked me.
[00:41:22.960 --> 00:41:29.040]   According to industry executives, Spotify is the clear number two player in podcast.
[00:41:29.040 --> 00:41:29.600]   Enough for us.
[00:41:29.600 --> 00:41:31.040]   By any...
[00:41:31.040 --> 00:41:34.720]   I don't even know if Spotify shows up in our list.
[00:41:34.720 --> 00:41:36.960]   The company, according to this Bloomberg piece,
[00:41:36.960 --> 00:41:39.680]   is seized between 10 and 20 percent of listeners
[00:41:39.680 --> 00:41:42.240]   and accounts for half the audience on some shows.
[00:41:42.240 --> 00:41:44.640]   Other companies, iHeartMedia,
[00:41:44.640 --> 00:41:49.920]   which disclaimer I work for my radio shows on their premiere syndicated,
[00:41:49.920 --> 00:41:53.680]   Stitcher, Pandora, and Luminary have also devoted more resources.
[00:41:53.680 --> 00:41:54.880]   So maybe there is this now...
[00:41:54.880 --> 00:41:57.120]   That actually scares me.
[00:41:57.120 --> 00:42:02.640]   This rush by these big companies to take these over.
[00:42:02.640 --> 00:42:05.760]   I would hate to see exclusives because I think one of the best things about podcast
[00:42:05.760 --> 00:42:07.280]   is the democratic nature of it.
[00:42:07.280 --> 00:42:10.640]   And that you can listen however you want, wherever you want, whenever you want.
[00:42:10.640 --> 00:42:13.200]   That's always been kind of a mantra for me.
[00:42:13.200 --> 00:42:19.440]   If you had to have Stitcher to hear a certain show, I don't think that's good.
[00:42:20.000 --> 00:42:25.360]   I think that's taking this great new medium and stuffing it into the old way of doing things.
[00:42:25.360 --> 00:42:27.760]   Oh, it's on NBC.
[00:42:27.760 --> 00:42:29.920]   That's the only place you can listen to that podcast.
[00:42:29.920 --> 00:42:31.120]   Yeah.
[00:42:31.120 --> 00:42:32.480]   I hope that doesn't happen.
[00:42:32.480 --> 00:42:33.440]   All the gardens are just really...
[00:42:33.440 --> 00:42:35.600]   I understand why it's done.
[00:42:35.600 --> 00:42:36.160]   It's just really...
[00:42:36.160 --> 00:42:36.640]   It's been easy.
[00:42:36.640 --> 00:42:37.200]   It's been easy.
[00:42:37.200 --> 00:42:38.080]   It's really irritating.
[00:42:38.080 --> 00:42:38.960]   Yeah, it's good for business.
[00:42:38.960 --> 00:42:42.240]   All right.
[00:42:42.240 --> 00:42:45.520]   That really was all for me, so I apologize.
[00:42:48.640 --> 00:42:49.680]   The president says...
[00:42:49.680 --> 00:42:54.800]   By the way, anytime you start a sentence with the president says,
[00:42:54.800 --> 00:42:57.040]   "I think you pretty much ignore anything following that."
[00:42:57.040 --> 00:42:58.880]   Only because...
[00:42:58.880 --> 00:43:01.280]   It's not to diss him, but he says a lot of things.
[00:43:01.280 --> 00:43:03.840]   Very few of whichever kind of happen.
[00:43:03.840 --> 00:43:09.760]   But he's saying we should take a look at Google for its ties with China,
[00:43:09.760 --> 00:43:14.080]   which is kind of ironic because Google's one of the few big American companies that
[00:43:14.080 --> 00:43:16.240]   stopped doing business with China because they didn't like
[00:43:17.520 --> 00:43:18.960]   their repressive regime.
[00:43:18.960 --> 00:43:21.360]   In fact, Google had...
[00:43:21.360 --> 00:43:25.680]   There was rumored a secret skunk works to do a search engine for China.
[00:43:25.680 --> 00:43:29.440]   They've officially ended that now as if they said it a long time ago.
[00:43:29.440 --> 00:43:30.320]   They ended up now.
[00:43:30.320 --> 00:43:31.280]   It's official.
[00:43:31.280 --> 00:43:33.920]   They have kind of left the door open to take it up again at some
[00:43:33.920 --> 00:43:35.840]   future point, but yeah, at least they stopped first.
[00:43:35.840 --> 00:43:39.120]   Trump actually in this...
[00:43:39.120 --> 00:43:40.480]   And by the way, he said it in a tweet.
[00:43:40.480 --> 00:43:43.440]   She probably should make that clear as well.
[00:43:43.440 --> 00:43:47.200]   Trump actually credits tech investor Peter Thiel.
[00:43:48.080 --> 00:43:51.760]   He says billionaire tech investor Peter Thiel believes Google should be
[00:43:51.760 --> 00:43:53.280]   investigated for treason.
[00:43:53.280 --> 00:43:55.200]   He loves that T word, doesn't he?
[00:43:55.200 --> 00:43:55.920]   Yeah.
[00:43:55.920 --> 00:44:00.400]   He accuses Google of working with a Chinese government at Fox and Friends.
[00:44:00.400 --> 00:44:02.560]   Oh, well, now we know what he was watching.
[00:44:02.560 --> 00:44:05.760]   A great and brilliant guy who knows his subject better than anyone.
[00:44:05.760 --> 00:44:07.680]   The Trump administration will take a look.
[00:44:07.680 --> 00:44:10.240]   This is actually in many ways...
[00:44:10.240 --> 00:44:12.560]   It's the most cursed Venn diagram of content.
[00:44:12.560 --> 00:44:13.360]   I know!
[00:44:13.360 --> 00:44:15.360]   This is a classic Trump tweet.
[00:44:15.360 --> 00:44:17.520]   He refers himself in the third person.
[00:44:17.520 --> 00:44:18.720]   He calls somebody brilliant.
[00:44:18.720 --> 00:44:21.280]   He uses the T word, treason.
[00:44:21.280 --> 00:44:24.240]   And it's about Peter Thiel.
[00:44:24.240 --> 00:44:24.720]   Yeah.
[00:44:24.720 --> 00:44:25.920]   Who wants to face it?
[00:44:25.920 --> 00:44:27.280]   It has some fairly accurate...
[00:44:27.280 --> 00:44:28.240]   And Fox and Friends.
[00:44:28.240 --> 00:44:29.120]   And Fox and Friends.
[00:44:29.120 --> 00:44:31.600]   Ray...
[00:44:31.600 --> 00:44:33.440]   Or sorry, Riva Shuto.
[00:44:33.440 --> 00:44:35.520]   A Google spokeswoman said,
[00:44:35.520 --> 00:44:38.720]   "As we've said before, we do not work with the Chinese military."
[00:44:38.720 --> 00:44:39.680]   Well, that's interesting.
[00:44:39.680 --> 00:44:41.440]   Well, hang on.
[00:44:41.440 --> 00:44:42.160]   I mean, sorry.
[00:44:42.160 --> 00:44:45.280]   Cisco sold his China the hardware to build the initial Great Wall
[00:44:45.280 --> 00:44:46.320]   for a great farm.
[00:44:46.320 --> 00:44:47.040]   Firewall China.
[00:44:47.040 --> 00:44:47.840]   Yeah.
[00:44:47.840 --> 00:44:49.200]   You know, American companies have been selling...
[00:44:49.200 --> 00:44:52.240]   We do billions of dollars in business with the Chinese government.
[00:44:52.240 --> 00:44:56.480]   And, you know, a lot of tech firms are faced in their never-envelopes position.
[00:44:56.480 --> 00:45:01.040]   If they do take things up with the Chinese authorities, then China can just turn around to them.
[00:45:01.040 --> 00:45:04.080]   You know those manufacturing plants you had?
[00:45:04.080 --> 00:45:05.200]   What do you mean the ones we've got?
[00:45:05.200 --> 00:45:06.080]   No, the ones you had.
[00:45:06.080 --> 00:45:08.880]   And, you know, China has the Chinese government,
[00:45:08.880 --> 00:45:11.200]   has an awful lot of power in this situation.
[00:45:11.200 --> 00:45:13.760]   And just sending out the odd tweet or so.
[00:45:13.760 --> 00:45:16.960]   I'm unconvinced that the president's actually going to do anything on this one.
[00:45:16.960 --> 00:45:20.080]   Google's vice president for public policy was on Capitol Hill this week,
[00:45:20.080 --> 00:45:25.200]   testifying before the Senate Judiciary Subcommittee, Karen Batia.
[00:45:25.200 --> 00:45:31.280]   She said that Google had exited China in 2010 because the censorship regime was not
[00:45:31.280 --> 00:45:32.560]   compatible with our values.
[00:45:32.560 --> 00:45:35.120]   I'm sorry, he or not she.
[00:45:35.120 --> 00:45:38.160]   He denied there were any plans to reintroduce Google search engine in China.
[00:45:38.160 --> 00:45:42.400]   He also denied that Google had been, quote, "infilitated by Chinese intelligence
[00:45:42.960 --> 00:45:44.880]   operatives." That's what Piedlle Tyl claimed.
[00:45:44.880 --> 00:45:50.880]   And he said that also during an interview with Fox News on Monday, we see no evidence of that.
[00:45:50.880 --> 00:45:55.840]   Yeah, well, I got an absolutely bonkers press release through this week saying,
[00:45:55.840 --> 00:45:59.360]   apparently someone was trying to sue Google because they didn't have enough
[00:45:59.360 --> 00:46:00.560]   conservatives on their board.
[00:46:00.560 --> 00:46:06.880]   And it was just like, right now they've got Chinese spies and conservatives and no one
[00:46:06.880 --> 00:46:07.840]   knows what the hell's going on.
[00:46:08.720 --> 00:46:13.520]   Tyl said Google is working with the Chinese government, Chinese communist government,
[00:46:13.520 --> 00:46:15.200]   and not with the US military.
[00:46:15.200 --> 00:46:21.280]   Remember that was, of course, because engineers at Google went on strike when Google
[00:46:21.280 --> 00:46:27.280]   was working on a Pentagon contract for using AI.
[00:46:27.280 --> 00:46:28.640]   May project Maven, wasn't it?
[00:46:28.640 --> 00:46:29.360]   Maven, yeah.
[00:46:29.360 --> 00:46:35.680]   Yeah, and a lot of those engineers that struck have now moved on to other things.
[00:46:35.680 --> 00:46:40.560]   But honestly, it comes to the left, it comes to the right.
[00:46:40.560 --> 00:46:45.440]   There's this drumbeat that Silicon Valley has, we've got to do something about Silicon Valley
[00:46:45.440 --> 00:46:46.880]   for a variety of reasons.
[00:46:46.880 --> 00:46:53.680]   The social media summit last week was that the Silicon Valley's two left wing,
[00:46:53.680 --> 00:46:56.080]   and we got to do something, we got to do it because they're censoring us.
[00:46:56.080 --> 00:47:00.960]   And then the left says they're too powerful and they're spying on us.
[00:47:00.960 --> 00:47:02.000]   We've got to do something.
[00:47:02.000 --> 00:47:05.440]   So there's a drumbeat coming from both sides, which means maybe something will happen.
[00:47:06.400 --> 00:47:08.800]   It doesn't sound like anything good.
[00:47:08.800 --> 00:47:10.800]   Yeah.
[00:47:10.800 --> 00:47:13.360]   Yeah, it's just hard to say, because I mean, there's been so many
[00:47:13.360 --> 00:47:20.880]   hearings in this vein that, I mean, you watch them, which I have to do for my job,
[00:47:20.880 --> 00:47:25.600]   and there are a lot of things being said, but it's mostly just for,
[00:47:25.600 --> 00:47:32.880]   it seems, the senators to repeat talking points so that they can tell their fans and their base,
[00:47:32.880 --> 00:47:36.640]   oh, I repeated these talking points and everybody's shouting in a room, nothing is
[00:47:36.640 --> 00:47:39.440]   actually being said or heard and nothing comes of it.
[00:47:39.440 --> 00:47:42.080]   So you think it's all rhetorical, it's all grandstanding?
[00:47:42.080 --> 00:47:48.000]   I mean, it doesn't seem to have had any, none of these individual hearings have had any direct
[00:47:48.000 --> 00:47:54.800]   impact yet from a congressional perspective, which I think is kind of telling in and of itself.
[00:47:54.800 --> 00:47:58.400]   I mean, how many times are we just going to lock all these people in a room with a bunch of tech
[00:47:58.400 --> 00:48:01.600]   reporters and pretends like something's going to happen?
[00:48:02.160 --> 00:48:07.840]   Seth, what do you think is going on? Do you think that we are close to getting some sort
[00:48:07.840 --> 00:48:09.680]   of regulation of big tech?
[00:48:09.680 --> 00:48:16.480]   I think that would take quite a bit of work on behalf of Washington and I don't know if that
[00:48:16.480 --> 00:48:19.280]   they have the kind of bigger fish to fry.
[00:48:19.280 --> 00:48:23.600]   Yeah, they just don't have the, they have too much ADD to kind of deal with that.
[00:48:23.600 --> 00:48:27.760]   I mean, I will say about this thing. So Peter Keel said one thing and of course,
[00:48:27.760 --> 00:48:31.760]   he's a board member of Facebook and he's kind of throwing the dogs over to Google like,
[00:48:31.760 --> 00:48:36.800]   hey, look, you know, Google's doing bad stuff. Never mind that big $5 billion
[00:48:36.800 --> 00:48:41.840]   thing that we just got and our stock went up $6 billion because of it.
[00:48:41.840 --> 00:48:49.520]   So he's throwing them off. Fox and Friends quoted him incorrectly and made all these things about
[00:48:49.520 --> 00:48:56.800]   treason and all this other stuff. So Trump, of course, quotes Fox and Friends, which totally
[00:48:56.800 --> 00:49:02.080]   misquoting Peter Keel took off on that. Right. So, I mean, this is typical. This is typical
[00:49:02.080 --> 00:49:07.680]   of what happens now and this is our president. My feeling is that
[00:49:07.680 --> 00:49:17.040]   the Trump administration wants to send Google kind of a message that, hey, we have our crosshairs
[00:49:17.040 --> 00:49:24.240]   on you. Don't go liberal on us or don't, I feel like there's a lot of in conservative media.
[00:49:24.240 --> 00:49:30.080]   There was a lot of talk at the last election about how there was, you know, like in Breitbart or
[00:49:30.080 --> 00:49:37.200]   whatever that high ranking Googlers were very upset about the victory of Donald Trump. And I think
[00:49:37.200 --> 00:49:43.680]   the Trump administration wants to send them a message that, you know, hey, we're watching you.
[00:49:43.680 --> 00:49:47.360]   Yeah, we're not going to do anything, but we are watching. Right.
[00:49:48.400 --> 00:49:54.640]   There's also the issue that I feel like this is something there's a lot of
[00:49:54.640 --> 00:49:59.840]   roiling around on the surface. But let's not forget under the surface, there's a lot of tension
[00:49:59.840 --> 00:50:06.960]   between law enforcement and these companies on two fronts. One, at least publicly companies
[00:50:06.960 --> 00:50:10.560]   don't seem to be as cooperative with law enforcement as law enforcement would like. There's even
[00:50:10.560 --> 00:50:15.440]   been rumors that, you know, they'll be talking about encryption back doors and things like that.
[00:50:16.880 --> 00:50:20.800]   But on the other hand, I think actually these companies are highly cooperative law enforcement
[00:50:20.800 --> 00:50:25.120]   in ways, you know, in all sorts of ways in that a lot of the information
[00:50:25.120 --> 00:50:33.600]   that goes to Google, Facebook, Amazon, Apple, even Apple ends up in the hands of law enforcement
[00:50:33.600 --> 00:50:38.400]   anyway. I think I think law enforcement is reluctant to expose that relationship and doesn't
[00:50:38.400 --> 00:50:44.400]   really want to rock the apple cart. I think after covering a fair amount of the crime
[00:50:44.400 --> 00:50:49.680]   conferences on the crime reporting on this, Google, Facebook, et al, are happy to work with
[00:50:49.680 --> 00:50:53.200]   law enforcement as long as they get a proper warrant. And they get that warrant. Boom. Here you go.
[00:50:53.200 --> 00:50:58.240]   Then there it is. But it's when you start talking encryption back doors or with the San Bernardino
[00:50:58.240 --> 00:51:02.240]   case with Apple where they wanted a custom version of the operating system that could allow them to
[00:51:02.240 --> 00:51:07.600]   get around this, it was just, you know, that's too far. And if they break their own encryption
[00:51:07.600 --> 00:51:11.920]   to satisfy American law enforcement, they can't sell that encryption around the world anywhere else.
[00:51:11.920 --> 00:51:15.760]   Right. I mean, no one is going to trust their products if they're not actually
[00:51:15.760 --> 00:51:19.760]   sorted out that way. So there's a lot for the tech companies to lose.
[00:51:19.760 --> 00:51:24.560]   But yeah, if you turn up with the warrant, doors open.
[00:51:24.560 --> 00:51:28.640]   Yeah. I think I feel like law enforcement doesn't really want to jeopardize that either.
[00:51:28.640 --> 00:51:35.360]   No, let's just let's just the status quo is good. Google did ban a major Chinese app developer
[00:51:35.360 --> 00:51:40.640]   from the Play Store in its ad platforms. That's a that's pretty severe. That's a severe banning.
[00:51:41.520 --> 00:51:46.240]   The company was Kootec. Actually, here they are at the New York Stock Exchange where they are listed
[00:51:46.240 --> 00:51:49.040]   ringing the final bell.
[00:51:49.040 --> 00:51:50.160]   Stuck price.
[00:51:50.160 --> 00:51:57.680]   Buzzfeed News has a story, Craig Silverman that when Buzzfeed and a security company provided
[00:51:57.680 --> 00:52:04.080]   evidence that Kootec's apps were bombarding users with disruptive ads, even after the company told
[00:52:04.080 --> 00:52:10.320]   Google, no, no, we stopped doing that. Google investigated. There were hundreds of Android apps
[00:52:10.320 --> 00:52:16.560]   in the Play Store, including the TouchPal keyboard apps. 60 of those apps have now been removed
[00:52:16.560 --> 00:52:21.600]   from the Play Store. Kootec is completely banned from any Google ad platform buys.
[00:52:21.600 --> 00:52:28.560]   And Google says a Google spokesperson said more removals will follow. So that's malicious behavior.
[00:52:28.560 --> 00:52:35.680]   Kootec's response was, "Our apps have been temporarily disabled. We acknowledge that we have the
[00:52:35.680 --> 00:52:39.520]   ability to attract new users and generate revenue from Google AdMob, and that may be
[00:52:39.520 --> 00:52:44.960]   adversely affected. The actions taken by Google will not affect Kootec's existing users or their
[00:52:44.960 --> 00:52:49.760]   ability to use the app. How did it affect their stock price? Did you find a quick look?"
[00:52:49.760 --> 00:52:55.760]   This is the second major Chinese developer to receive a ban by Google this year.
[00:52:55.760 --> 00:53:00.240]   It went down a little bit. Just a little.
[00:53:00.240 --> 00:53:05.360]   All apps from Do Global are developed with half a billion installs.
[00:53:05.360 --> 00:53:10.160]   They're one month. Yeah. Pretty pretty. A fast downhill, the most Olympic skiing courses.
[00:53:10.160 --> 00:53:12.960]   Yeah. Bye-bye. Yeah.
[00:53:12.960 --> 00:53:20.400]   Do Global was Buzzfeed again revealed the company was committing ad fraud and violating other
[00:53:20.400 --> 00:53:26.240]   Google policies. It's a depressingly common refrain, but I'm not getting. Yeah. They're getting better at
[00:53:26.240 --> 00:53:29.120]   dealing with it, but it's still nowhere near there where it should be at the moment.
[00:53:30.080 --> 00:53:35.680]   You may remember that very famously Fortnite decided to sell itself outside the Play Store
[00:53:35.680 --> 00:53:43.920]   to keep Google from its 30% share. Now Tinder joins the revolt against App Store fees. Tinder is
[00:53:43.920 --> 00:53:52.160]   bypassing Google Play, asking you to re-up within the app. They launched a new default payment process
[00:53:52.160 --> 00:53:56.480]   that skips Google Play forces users to enter their credit card details straight in the app.
[00:53:57.040 --> 00:54:01.280]   Once a user has entered their payment information, the app not only remembers it, but removes the
[00:54:01.280 --> 00:54:06.960]   choice to go back to Google Play for future purchases. So bad, I'm not single anymore.
[00:54:06.960 --> 00:54:14.800]   I think both Apple and Google are under a lot of pressure to lower the cut or do something about
[00:54:14.800 --> 00:54:20.480]   the 30% of revenue that they take. Oh, sorry. A 30% is not so yeah. Rages cut. Is it? I feel like
[00:54:21.520 --> 00:54:27.520]   given that you get distribution, you get marketing. Well, but you also lose complete control. I mean,
[00:54:27.520 --> 00:54:31.760]   I've got a lot a bit more respect for Apple on this stuff because they do a decent job of
[00:54:31.760 --> 00:54:36.160]   actually checking all the softwares on their stores is relatively malware free. They've had a few
[00:54:36.160 --> 00:54:40.960]   slips over the years, but not money. But the Play Store, their automated checking system
[00:54:40.960 --> 00:54:46.960]   suck. And the amount of malware that's still in there is really painfully high for a 30% cut.
[00:54:48.240 --> 00:54:52.400]   Is that what the 30% goes to? Well, the 30% is supposed to be on maintenance and marketing and
[00:54:52.400 --> 00:54:57.920]   the rest of it. But as an end user, I do feel that if they're charging that much to the developer,
[00:54:57.920 --> 00:55:03.440]   then we should be getting some benefit from it. Right. All right. I'm going to ask you if you
[00:55:03.440 --> 00:55:10.720]   if anybody bought anything on Prime Day in a little bit. Prime Day was big, 175 million items,
[00:55:11.360 --> 00:55:18.320]   bigger than Black Friday and Cyber Monday. Combined. Combined. Our show today brought to you by
[00:55:18.320 --> 00:55:25.040]   ExpressVPN. Everybody knows a VPN protects your privacy, protects your security when you're an
[00:55:25.040 --> 00:55:30.240]   open Wi-Fi hotspot. Actually, I know people use VPNs at home too, because of course, your ISP
[00:55:30.240 --> 00:55:34.960]   is also kind of keeping an eye on what you're doing online. And we know ISPs will sell that data,
[00:55:34.960 --> 00:55:40.560]   in many cases, to marketers. A lot of people want to protect themselves online. They also
[00:55:40.560 --> 00:55:46.720]   like the idea of emerging in various geographic locations, eliminating geographic restrictions.
[00:55:46.720 --> 00:55:51.520]   I am always asked what's your recommendation? What's the best VPN? And I will tell you, it's
[00:55:51.520 --> 00:56:01.440]   ExpressVPN, our sponsor. ExpressVPN is easy, runs on any platform, Windows, Mac, iOS, Android.
[00:56:01.440 --> 00:56:07.600]   Download the app, put it on your device, click to connect and you're done. ExpressVPN is also
[00:56:07.600 --> 00:56:13.440]   fast. They have more servers than anybody all over the world. And they've just completed an
[00:56:13.440 --> 00:56:19.040]   audit, which I was really pleased to see, that says, "Yes, ExpressVPN's privacy policy is exactly
[00:56:19.040 --> 00:56:24.080]   as stated. They do no logging. They collect no information about you, except for the little they
[00:56:24.080 --> 00:56:29.360]   have to to charge you." They use a new cutting edge server technology called Trusted Server that
[00:56:29.360 --> 00:56:34.080]   prevents the operating system and apps from ever writing the hard drive too. It's like sandboxing.
[00:56:34.080 --> 00:56:38.640]   And that is an awesome standard of privacy and security. The audit also confirmed that's exactly
[00:56:38.640 --> 00:56:44.240]   how Trusted Server works. And it's very affordable. Less than $7 a month, you get a 30-day money
[00:56:44.240 --> 00:56:50.240]   back guarantee. So try it and see how you like it. Stop hackers, stock big brother, stop internet
[00:56:50.240 --> 00:56:55.600]   companies from grabbing your data, take back your online privacy, ExpressVPN. You can protect
[00:56:55.600 --> 00:56:59.840]   your online activity today and find out how you can get an extra three months free with a one-year
[00:56:59.840 --> 00:57:10.880]   package when you go to expressvpn.com/twit. Expr-e-dub-less vpn.com/twit. Express vpn.com/twit.
[00:57:10.880 --> 00:57:15.440]   Three extra months free when you buy a one-year package. Thank you, ExpressVPN.
[00:57:15.440 --> 00:57:21.120]   For supporting Twit, thank you, Paris Martynote, for being here from Wired Magazine,
[00:57:21.120 --> 00:57:28.480]   braving us sweltering hot, wired office where the AC has been turned off and Edward Snowden's
[00:57:28.480 --> 00:57:33.680]   photo is dripping off the wall. Yeah, where is he there? There he is. There he is. There he is.
[00:57:33.680 --> 00:57:36.640]   There he is. He's melting. It's a sawn in here. We're all purging.
[00:57:36.640 --> 00:57:43.200]   This is for your health, Paris. You're here for your health. Yeah, really. It's, I should be paying
[00:57:43.200 --> 00:57:47.120]   you guys for that. Seth Winetrap was up the river where it's just a little bit cooler.
[00:57:47.120 --> 00:57:52.240]   Publisher of 9 to 5 in Electric. It's always great to have you, Seth. Thank you for joining us today.
[00:57:52.240 --> 00:57:57.920]   Always fun to be here. And from the register.co.uk news editor Ian Thompson.
[00:57:58.800 --> 00:58:04.480]   I'm just registered. I love the register articles. Just read a good one.
[00:58:04.480 --> 00:58:08.720]   Oh, the headlines. Yeah, the headlines are so good. You should see the headlines that we
[00:58:08.720 --> 00:58:13.920]   don't publish. I mean, it was some of the stuff that would get a shot, but still fun.
[00:58:13.920 --> 00:58:22.480]   I have to do type the register.co.uk. I type register.co.uk and it said, it's for sale.
[00:58:25.120 --> 00:58:32.240]   It's for sale. Oakland has now, in fact, this is from a register story, become the third city
[00:58:32.240 --> 00:58:37.760]   in the United States to ban face recognition. San Francisco is the first Somerville, Massachusetts,
[00:58:37.760 --> 00:58:43.840]   the second. Now Oakland, what do you think of that? Is that, I mean, it's interesting,
[00:58:43.840 --> 00:58:51.120]   it's these liberal enclaves somewhat that are banning it. Is it a sensible privacy move to
[00:58:52.000 --> 00:58:56.640]   say the government? It's not banning face recognition. No, I mean, private companies.
[00:58:56.640 --> 00:59:01.200]   Well, what it's saying is if you want to set up, if law enforcement wants to set up a facial
[00:59:01.200 --> 00:59:06.800]   recognition system within our city, then they have to apply with permission, for permission to do so
[00:59:06.800 --> 00:59:11.360]   and explain exactly how it's going to work and how you're going to build privacy into that.
[00:59:11.360 --> 00:59:15.520]   That's certainly what they do with San Francisco. That's what they did. I think in Connecticut,
[00:59:17.120 --> 00:59:23.120]   you know, if you try and roll this stuff out too quickly, then things that they're going to cause
[00:59:23.120 --> 00:59:28.320]   problems. As we saw with the Orlando case this week, with Amazon getting kicked off their
[00:59:28.320 --> 00:59:32.640]   of their contract, it is incredibly difficult to make these facial recognition systems work.
[00:59:32.640 --> 00:59:38.160]   And because of problems with training them, they predominantly are accurate for white men
[00:59:38.160 --> 00:59:42.800]   and inaccurate for women and people of color, because that's just what the data sets were largely about.
[00:59:43.520 --> 00:59:49.200]   So I think putting a temporary ban on it is fine and asking people to justify their decisions.
[00:59:49.200 --> 00:59:54.160]   You can end up with fewer costly mistakes like we've seen in Florida. And frankly,
[00:59:54.160 --> 00:59:57.440]   I'm just not wild about the technology in the first place, but I don't know what
[00:59:57.440 --> 00:59:58.160]   are the rest of you think?
[00:59:58.160 --> 01:00:09.360]   Parents, I saw something at CES that really kind of scared me. And it was not only face
[01:00:09.360 --> 01:00:16.720]   recognition, but it was like calculating my age and like, wait, I can't even remember what other
[01:00:16.720 --> 01:00:23.040]   stuff. Yeah, like a guy at the carnival. Right, it was basically a carnival guy. But
[01:00:23.040 --> 01:00:34.080]   I don't think it's a big thing until you actually feel it. First hand, like that your data is being
[01:00:34.080 --> 01:00:37.840]   collected and you're being recognized and you come back later and it remembers that you were
[01:00:37.840 --> 01:00:47.120]   there before. And that kind of big brother situation is something that I think we're all
[01:00:47.120 --> 01:00:53.360]   inherently kind of afraid of. I can't decide if I'm more scared of government doing it or private
[01:00:53.360 --> 01:00:58.880]   industry doing it. Government, you've got a chance to stop a private industry. That's it.
[01:00:58.880 --> 01:01:06.000]   Has anybody used the Delta face recognition check in? It said Atlanta, they're going to add it to
[01:01:07.360 --> 01:01:12.480]   Minneapolis, St. Paul and Salt Lake City. This is actually a truly terrifying image.
[01:01:12.480 --> 01:01:20.880]   Yeah, that's not good. Delta expands optional. They underscore optional face recognition boarding.
[01:01:20.880 --> 01:01:25.680]   I've been seeing reports of people trying to opt out of this and they don't make it easy.
[01:01:25.680 --> 01:01:30.400]   Yeah, or you don't even know it's optional. And frankly, it's pretty easy. There's a
[01:01:30.400 --> 01:01:35.360]   list of terms and services that's on a billboard like next to it or a little board that is as tall as
[01:01:35.360 --> 01:01:41.440]   like a six foot person. Like, how do I have time to read by agreeing to your face scan? You agree
[01:01:41.440 --> 01:01:49.760]   all the boilerplate. Yeah, I mean, it's been like LGA the other week and they had a facial
[01:01:49.760 --> 01:01:55.360]   recognition, a private company kind of for TSA. You could, I mean, I do TSA. That's clear. I use
[01:01:55.360 --> 01:02:00.240]   clear. But yeah, I had never seen that before. Yeah, they're a sponsor and I actually use it.
[01:02:01.360 --> 01:02:06.800]   But because I've, and by the way, they have, they have my fingerprints, my iris.
[01:02:06.800 --> 01:02:11.040]   But I, you know, I check the privacy policy, make sure that they do, you know, they handle that
[01:02:11.040 --> 01:02:17.360]   responsibly. And actually in some ways, I prefer that they do it. Then, then somebody else, Delta's
[01:02:17.360 --> 01:02:23.680]   using CPB and I think DMV records as well, government records, they say, we don't get those
[01:02:23.680 --> 01:02:28.800]   pictures. We don't, we're just using their database. I don't know. This is, I just feel like this is
[01:02:28.800 --> 01:02:33.680]   moving very fast. Face app is the tip of a very big iceberg and it's all moving extremely quickly.
[01:02:33.680 --> 01:02:37.920]   You see, if you go to China, they're like 10, 15 years ahead of us on the social credit system.
[01:02:37.920 --> 01:02:42.960]   And the social credit system. And this is where this is going. And less enough people stand up
[01:02:42.960 --> 01:02:46.160]   and say, actually, this isn't the kind of future that I'm really looking forward to.
[01:02:46.160 --> 01:02:52.560]   Yeah. And it's, you know, given their drivers, tech companies and local government will,
[01:02:52.560 --> 01:02:57.280]   will love this. So if you want to actually stop it, it's really question of stepping up now.
[01:02:57.280 --> 01:03:01.120]   I can see people, it's so easy at the airport. You don't have to pull out your driver's license.
[01:03:01.120 --> 01:03:06.640]   You just walk right through there. Oh, yeah, we know you. I mean, it almost feels like friends.
[01:03:06.640 --> 01:03:11.360]   They just, they know you. Come on in, Neil, and we know you. Yeah. Friends who have a creepy
[01:03:11.360 --> 01:03:17.120]   and lots of matter, friends who are also stalkers is possible. I think it's, I think it's almost too
[01:03:17.120 --> 01:03:24.960]   late. I feel like it's happened. You may well be right. But yeah, I don't know. It does creep me
[01:03:24.960 --> 01:03:29.520]   out a bad bit. Okay. Anybody show hands anybody buy anything on Prime Day?
[01:03:29.520 --> 01:03:32.400]   Did you see any deals that you just couldn't resist? No.
[01:03:32.400 --> 01:03:35.680]   How about this day? My boycott on Prime Day.
[01:03:35.680 --> 01:03:40.800]   I didn't, I don't know if this is kind of a boycott. I know Prime members.
[01:03:40.800 --> 01:03:44.960]   So I'm a Prime member, but I just, I didn't, I didn't, I kind of stayed away from Amazon for those
[01:03:44.960 --> 01:03:51.040]   two days out of a feeling of support for the warehouse workers who probably hate Prime Day.
[01:03:51.040 --> 01:03:55.920]   A number of them walked out. Yeah, they had well cut strikes. Yeah.
[01:03:55.920 --> 01:04:04.080]   They didn't slow Amazon down. They sold 175 million items. It was the, it was bigger than Black
[01:04:04.080 --> 01:04:11.280]   Friday and Cyber Monday combined. So they managed to get around the, the walkouts if,
[01:04:11.280 --> 01:04:14.880]   I don't know how wide spread they were. I did rather like Bernie Sanders style.
[01:04:14.880 --> 01:04:19.120]   He was invited to a Washington Post event, which is owned by Amazon owner Jeff Bezos.
[01:04:19.760 --> 01:04:23.440]   And he was asked for his review on what they would do about the tech firms. He goes,
[01:04:23.440 --> 01:04:27.120]   Oh, well, I'm going to bring in an attorney general and break them up just like Teddy Roosevelt
[01:04:27.120 --> 01:04:31.520]   to stand in your house. So yeah, I'm going after your boss's biggest company.
[01:04:31.520 --> 01:04:35.840]   It's just like good for him. That's actually rather refreshing in a good for him. Yeah.
[01:04:35.840 --> 01:04:39.840]   Jeff will have plenty of money. It's not going to hurt Jeff's bottom line. Oh, no.
[01:04:39.840 --> 01:04:44.880]   He gave a really objectionable interview last year. He's like, I honestly, I've, I've learned so
[01:04:44.880 --> 01:04:49.200]   much money from, from Amazon that I'm just, I'm spending it on getting into space now.
[01:04:49.200 --> 01:04:53.120]   He calls himself a lottery winner. He's like, he erases over. I've got to go to the
[01:04:53.120 --> 01:04:57.200]   morning. Yeah, that's he said it again. Just the other day. I'm sorry. When your workers are having
[01:04:57.200 --> 01:05:02.000]   to urinate in bottles because they are so afraid to leave their posts, maybe you might want to,
[01:05:02.000 --> 01:05:07.200]   you know, deal with some issues on, on earth as well as in space. I'm not saying just one or the
[01:05:07.200 --> 01:05:14.800]   other, but you know, it's, um, multi-task. Yeah. Jeff wants to go to the moon first. It's
[01:05:14.800 --> 01:05:20.400]   Elon that wants to go straight to Mars. Yeah. This is almost a parody where you have these
[01:05:20.400 --> 01:05:28.240]   richest people in history fighting about going to moon or Mars. President Trump wants to go to Mars.
[01:05:28.240 --> 01:05:34.800]   Ah, yes. She says the moon is apart, which had some astronomers baffled on that one.
[01:05:34.800 --> 01:05:41.040]   He also asked a bunch of space scientists why we can't just go straight to Mars the other day.
[01:05:41.040 --> 01:05:44.800]   Let's just go straight. Let's just, you know, like the moon's a bad neighborhood.
[01:05:44.800 --> 01:05:48.800]   It's a bad neighborhood. It's one of those asshole, uh, uh, planetary bodies,
[01:05:48.800 --> 01:05:52.720]   which is just go straight to Mars. I mean, skip the moon. Technically you could, but we don't know
[01:05:52.720 --> 01:05:58.320]   enough about it and you're probably going to lose people. Um, Jeff says, Jeff Bezos is my buddy,
[01:05:58.320 --> 01:06:03.600]   Jeff. He says, focusing on reaching Mars before first establishing a presence on the moon is an
[01:06:03.600 --> 01:06:09.520]   illusion. It's not as smart as you'd, I mean, don't go into the moon first, getting something
[01:06:09.520 --> 01:06:14.160]   in orbit around the moon and then using that to get to Mars and makes a lot of logical sense.
[01:06:14.160 --> 01:06:18.640]   It's hard not to think that these guys have some economic incentive in all this. Like,
[01:06:18.640 --> 01:06:22.400]   it's the next big. I want to go to the moon because there's water on the poles and we could,
[01:06:22.400 --> 01:06:24.640]   I mean, there's reasons. I feel like there's this.
[01:06:24.640 --> 01:06:31.200]   The amount of natural resources floating within easy reach of the earth, we're starving in the,
[01:06:31.200 --> 01:06:35.040]   you know, in the midst of plenty here. You know, we could asteroid mining.
[01:06:35.040 --> 01:06:40.400]   Well, when planetary resources launched their pie in the sky idea to do asteroid mining,
[01:06:40.400 --> 01:06:45.680]   I looked in some of the NASA cases on this. There are, you know, strip mining one large asteroid
[01:06:45.680 --> 01:06:50.400]   would give you as much platinum as has been mined in the whole of earth's history.
[01:06:50.400 --> 01:06:54.880]   And yeah, it would totally disrupt the market. But if you're shifting onto that kind of scale of
[01:06:54.880 --> 01:07:01.600]   economics, then there's a lot to be said for it. And I think Musk and, and Bezos, they want to be
[01:07:01.600 --> 01:07:05.200]   in there at the start. They want to be providing the engines to get you to get you there.
[01:07:05.200 --> 01:07:08.240]   And eventually they want to be setting up the setting up the resource.
[01:07:08.240 --> 01:07:12.880]   Scaveny. Beatmaster says there's no sales tax on the moon.
[01:07:12.880 --> 01:07:17.280]   So you just put all the warehouses on the moon. Yeah. Yeah. Yeah. Well, there's a lovely
[01:07:17.280 --> 01:07:21.680]   Arthur C. Clark. Wayfare be South Dakota. It's not jurisdiction on the moon.
[01:07:21.680 --> 01:07:25.920]   There you go. There's a lovely Arthur C. Clark story from the late 1950s where he talking about a
[01:07:25.920 --> 01:07:31.040]   combined, this combined American British and Soviet trip to the moon. And the British astronauts
[01:07:31.040 --> 01:07:34.400]   decided to stay on there for an extra four months so they can avoid paying tax for the
[01:07:34.400 --> 01:07:40.640]   year on the salary. Top sellers on Prime Day, Echo Dot Fire TV Stick. Really?
[01:07:40.640 --> 01:07:46.560]   Yeah, the top selling devices. What a surprise Amazon. Yeah. What a surprise.
[01:07:46.560 --> 01:07:53.280]   I bought something, but I waited until Amazon got me because I skipped Prime Day. But then I got
[01:07:53.280 --> 01:08:00.640]   an email saying, Oh, we got a special on these little types. They suck you in. Type C USB connectors
[01:08:00.640 --> 01:08:04.960]   with little keychains on them. So I can't lose them. It's an adapter for type C to USB A.
[01:08:04.960 --> 01:08:10.400]   That's the thing that Amazon has you pegged for. They know what I want. Damn them.
[01:08:10.400 --> 01:08:18.960]   Chocolate rain. Some state dry will others feel the pain. Remember that? That one's got to stay
[01:08:18.960 --> 01:08:28.960]   forever. Okay. Members purchased millions of Alexa enabled devices, received tens of millions
[01:08:28.960 --> 01:08:32.640]   dollars in savings by shopping from Whole Foods. Wait a minute. Prime Day, I could have used my
[01:08:32.640 --> 01:08:39.360]   Whole Foods discount. Two billion dollars of products from third parties on Amazon.
[01:08:39.360 --> 01:08:45.200]   Also, hang on. Are they catching Whole Foods revenue in this as well? But I don't know what.
[01:08:45.200 --> 01:08:47.920]   I guess they had Prime Day at Whole Foods too. Yeah, I guess so.
[01:08:47.920 --> 01:08:57.360]   In the US, Prime members bought more than get ready 100,000 lunch boxes.
[01:08:58.720 --> 01:09:06.320]   100,000 laptops, 200,000 TVs, 300,000 headphones. This is this is a sad, sad
[01:09:06.320 --> 01:09:16.000]   commentary on American mercantilism. 350,000 luxury beauty products, 400,000 pet products,
[01:09:16.000 --> 01:09:20.480]   650,000 household cleaning supplies, and more than one million toys.
[01:09:20.480 --> 01:09:27.680]   They also bought more than 200,000 life straw personal water filters. Oh, for goodness sake.
[01:09:28.160 --> 01:09:34.240]   The water here is... Okay. I'm not going to go on a rant. I'm just calm down.
[01:09:34.240 --> 01:09:41.520]   Consumerism is good. Everything is fine. And our sponsor, 150,000 Crest 3D White Strips.
[01:09:41.520 --> 01:09:46.640]   That's a sponsor of ours. Okay. Yeah. I think I'm going to take credit for that.
[01:09:46.640 --> 01:09:51.760]   I'm going to take credit. They say, right? You all saw it on our shows, and then you went out and
[01:09:51.760 --> 01:09:56.800]   you bought it on Amazon during Prime Day. Thank you. They saved tens of millions of dollars by
[01:09:56.800 --> 01:10:02.800]   shopping and Whole Foods. Other top sellers, the Instant Pot. Who doesn't have an Instant Pot?
[01:10:02.800 --> 01:10:13.200]   And weirdly, 23 and me health and ancestry kits. Really? Yeah. That proves that nobody's paying
[01:10:13.200 --> 01:10:18.000]   any attention to privacy at all. No, because didn't they just sell their entire database to
[01:10:18.000 --> 01:10:22.640]   Bayer or something? Yeah, they sell the whole thing. No, they have a whole partnership with Glaxo,
[01:10:22.640 --> 01:10:26.640]   Smith, Klein. Glaxo, Smith, Klein. Oh, that other ethical. That's not a bad thing.
[01:10:26.640 --> 01:10:32.160]   Because as somebody whose genotype is stored at 23 and me, they've got my spit.
[01:10:32.160 --> 01:10:37.760]   I don't mind that being helpful in the development of... No, no, they actually,
[01:10:37.760 --> 01:10:43.440]   they collected. I don't mind that they share that with big pharma to help make better
[01:10:43.440 --> 01:10:48.880]   drugs. Well, if that's what... Yeah, I mean, isn't that good? Isn't that a social good?
[01:10:48.880 --> 01:10:53.840]   Well, I don't see how they actually use it to make better drugs because the test itself is
[01:10:53.840 --> 01:10:58.320]   fairly unreliable and it's anonymized data. So I'm curious to know what they wanted for.
[01:10:58.320 --> 01:11:02.640]   They want to offer some. You know why? Because they collect with... So you do... You send them
[01:11:02.640 --> 01:11:09.120]   your genotype and then 23 and me at least. Every time I go there, there's questions.
[01:11:09.120 --> 01:11:14.560]   And you can participate in studies. Oh, okay. So they're gathering a phenotype to go with
[01:11:14.560 --> 01:11:18.960]   the genotype and they do have the genetic information. I mean... You know, they're doing a similar thing
[01:11:18.960 --> 01:11:25.680]   now for pets. You can work out what proportion your dog is, or various different breeds. It's just...
[01:11:25.680 --> 01:11:30.000]   Who would have thought this sort of thing would become so popular, but...
[01:11:30.000 --> 01:11:37.600]   That's kind of interesting. I would do that. Millions of smart home devices, including the iRobot
[01:11:37.600 --> 01:11:47.680]   Roomba 690 Robot Vacuum, the MyQ Smart Garage Door Opener, and the Amazon Smart Plug. It doubled
[01:11:47.680 --> 01:11:52.080]   the sales of its video doorbell ring and other sponsor. Our sponsors did quite well.
[01:11:52.080 --> 01:12:00.720]   And Blink doubled the number of fire TV edition TVs. It sold six times the number of
[01:12:00.720 --> 01:12:07.920]   Euro devices, another sponsor. So I'm going to take credit for all of this. It's all me.
[01:12:07.920 --> 01:12:10.480]   It's all our advertising.
[01:12:13.040 --> 01:12:19.040]   Let's see. How do we feel about Facebook's Libra coin? Facebook was also on Capitol Hill
[01:12:19.040 --> 01:12:29.440]   testifying. David Marcus said that there's going to be better rules around it than banks for law
[01:12:29.440 --> 01:12:36.720]   enforcement. Yeah. I mean, I'm sure Facebook who's proven self utterly trustworthy with our data can
[01:12:36.720 --> 01:12:44.560]   be trusted not to abuse this. So yeah, I'll be staring clear of it. This is another one where
[01:12:44.560 --> 01:12:50.000]   it seems like a power grab from Facebook. They'd love... Well, they put on hold now. They would preempt.
[01:12:50.000 --> 01:12:55.120]   They did put it on hold. Yeah, because Munchin put out a statement saying basically that he believes
[01:12:55.120 --> 01:13:01.280]   this is like it's what we use to fund terrorism the rest of it. Well, the advantage of cryptocurrencies
[01:13:01.280 --> 01:13:04.880]   is that they are anonymous, right? They're good for money laundering. But yeah,
[01:13:05.840 --> 01:13:09.600]   then Facebook came out the next day and like, obviously, we'll put this on hold until the
[01:13:09.600 --> 01:13:17.840]   regulatory framework's done. I don't know what do you folks think, but I'm staring clear of this.
[01:13:17.840 --> 01:13:23.120]   It's like... I feel like Seth, you're all in on cryptocurrency. Do you have a big investment in
[01:13:23.120 --> 01:13:31.520]   cryptocurrency? No, actually I'm pretty anti. Oh. It just feels like it's all going to come
[01:13:31.520 --> 01:13:36.480]   crashing down at some point because there's like 300 different types of cryptos, obviously
[01:13:36.480 --> 01:13:44.800]   bitcoins that the first and biggest. But there's a lot of different types and very few are tied to
[01:13:44.800 --> 01:13:52.240]   real world value. It would be nice to have a currency that wasn't based on any nation state.
[01:13:52.240 --> 01:14:01.280]   But in particular, Facebook seems particularly troubling because the company behind it has
[01:14:01.280 --> 01:14:13.360]   been so lackadaisical about foreign actors, not just foreign actors, but not necessarily
[01:14:13.360 --> 01:14:20.160]   folks with the best intentions using their platform for bad things, electioneering, that kind of stuff.
[01:14:20.160 --> 01:14:28.720]   Obviously, Facebook, if a profits in the crosshairs isn't going to stand in the way of
[01:14:29.520 --> 01:14:33.680]   money laundering or terrorism or anything like that. We know that's how it's going to go down.
[01:14:33.680 --> 01:14:42.560]   On the other hand, Facebook is a multinational corporation. They can start this little small...
[01:14:42.560 --> 01:14:51.120]   the money thing as a small thing in other countries. All of a sudden, it's a global currency.
[01:14:51.120 --> 01:14:57.920]   I think it's a bad thing, but inevitable. The one thing I like about Facebook, and by the way,
[01:14:57.920 --> 01:15:04.560]   the whole idea behind the Libra coin is that it is a consortium of, I think as many as 100 other
[01:15:04.560 --> 01:15:08.960]   countries, companies, it's run out of Switzerland. It's not just Facebook. That may be a smokescreen
[01:15:08.960 --> 01:15:14.960]   to keep Facebook's involvement a little bit under the covers. I do, though. I can't say I hate
[01:15:14.960 --> 01:15:24.080]   the idea of undermining banks. The whole thing that happens with blockchain and crypto is that
[01:15:24.080 --> 01:15:31.280]   you don't need a centralized source of truth for who has what money. In Bitcoin, there is no central
[01:15:31.280 --> 01:15:37.600]   bank. It's completely decentralized. Everybody has the ledger, and you have a source of truth
[01:15:37.600 --> 01:15:43.040]   for who owns what. There have been some issues. Libra might solve some of those issues.
[01:15:43.040 --> 01:15:48.320]   And I can't think of a better group of people to be disseter-mediated than the global banking system.
[01:15:49.440 --> 01:15:54.080]   Am I wrong? I don't want to destabilize our economic future.
[01:15:54.080 --> 01:16:02.840]   Yeah, I mean, I think undercutting banks is never a terrible thing in the large-
[01:16:02.840 --> 01:16:09.600]   They seem pacious. It's not something that we all should be glorifying and defending with
[01:16:09.600 --> 01:16:18.240]   our last word, but I also think that, in this case, putting our trust in Facebook at a large
[01:16:18.240 --> 01:16:24.400]   group of cryptocurrency advocates at this stage probably isn't the wisest total alternative.
[01:16:24.400 --> 01:16:30.720]   Yeah, that's the real problem, isn't the Facebook's association with this. But it's the only reason
[01:16:30.720 --> 01:16:35.760]   it stands out because there's a hundred different, many more than a hundred different cryptocurrencies
[01:16:35.760 --> 01:16:41.680]   out there. And I don't know if Libra coin is in any respect better than any of the other ones.
[01:16:41.680 --> 01:16:45.280]   I don't know which is best, which is... I'm looking forward to DEF CON this year,
[01:16:45.280 --> 01:16:48.160]   whether they're going to be doing any depth look at what we know about it and what we don't.
[01:16:48.160 --> 01:16:50.320]   And I think that's going to be quite interesting.
[01:16:50.320 --> 01:16:56.080]   I have to say, I did feel like a failure in life because CNBC had a big profile today
[01:16:56.080 --> 01:17:03.680]   on the 26-year-old woman behind this, Morgan Beller. She is one of three people, all Facebook
[01:17:03.680 --> 01:17:09.520]   employees listed as co-creator of Libra, along with Vice Presidents David Marcus and Kevin Wiles,
[01:17:09.520 --> 01:17:12.240]   since they're Vice Presidents. I'm thinking she did all the work.
[01:17:14.480 --> 01:17:19.520]   This was her doing. She's 26. 26 new VP of Facebook.
[01:17:19.520 --> 01:17:26.160]   She's not a VP. She's apparently, according to CNBC, a rather new employee in Facebook's
[01:17:26.160 --> 01:17:32.800]   corporate development unit. But she, a couple of years ago, got very interested in the whole idea
[01:17:32.800 --> 01:17:39.760]   of cryptocurrency and blockchain and had been really pushing it at Facebook.
[01:17:41.200 --> 01:17:45.200]   Beller is known in the blockchain community as the original driving force behind Facebook's
[01:17:45.200 --> 01:17:51.200]   push into cryptocurrency. She's unlinked and listed as head of strategy for Calibra,
[01:17:51.200 --> 01:17:54.480]   which is the consortium, as well as co-creator of Libra.
[01:17:54.480 --> 01:18:02.160]   So I think that's kind of interesting. What's driving her apparently, at least according to CNBC,
[01:18:02.160 --> 01:18:10.320]   is this whole notion of getting rid of the existing financial system, which really
[01:18:10.880 --> 01:18:17.520]   doesn't work for a lot of people in the world and making a more democratic money system.
[01:18:17.520 --> 01:18:22.560]   Well, this was originally the promise of cryptocurrency, as it would get it out of the system.
[01:18:22.560 --> 01:18:29.120]   So much of the online currency seemed to just being held as investment tools. There's not much
[01:18:29.120 --> 01:18:36.720]   evidence that people are actually using them to buy anything other than illegal stuff and very
[01:18:36.720 --> 01:18:44.800]   low levels of others. Well, as it's Sarah Young, who said that she'd initially taken the first
[01:18:44.800 --> 01:18:49.680]   sushi restaurant off, allowed you to pay by Bitcoin and she took some people out and paid with
[01:18:49.680 --> 01:18:53.840]   Bitcoin. That's so dangerous. And then five years later, she just like, yeah, that dinner
[01:18:53.840 --> 01:19:01.040]   cost me about 55,000. Yes. There's the guy who bought the Bitcoin pizza, like two or three million
[01:19:01.040 --> 01:19:08.240]   dollars now of Bitcoin. By the way, there's a couple of significant problems with Bitcoin
[01:19:08.240 --> 01:19:13.760]   that presumably Libra, coin and others would solve. One is that the complete volatility of it. I mean,
[01:19:13.760 --> 01:19:18.160]   it goes up and down. It was as high as 20,000. For a while, it was back at 7,000. I think it just
[01:19:18.160 --> 01:19:23.440]   went down after this Libra coin kind of thing and went down again. The other problem is the
[01:19:23.440 --> 01:19:30.240]   blockchain itself. The Bitcoin wallet is more than 100 gigabytes massive. And every single
[01:19:30.240 --> 01:19:34.080]   person who uses Bitcoin, if they're using their own local wallet, has to store that
[01:19:34.080 --> 01:19:39.600]   because that's a distributed ledger. And then that I guess that really gives rise to the third
[01:19:39.600 --> 01:19:44.800]   problem, which is that transactions can take ridiculously long on Bitcoin because, well,
[01:19:44.800 --> 01:19:50.000]   just as kind of the nature of the way that the proof of the proofs are done, the Bitcoin miners,
[01:19:50.000 --> 01:19:54.080]   the amount of power it requires. Oh, that's another problem. I came up with four problems.
[01:19:54.800 --> 01:19:59.600]   It's using more energy than some countries. The Bitcoin miners.
[01:19:59.600 --> 01:20:05.680]   I mean, as you said, for the financial institutes, initially, they were just like,
[01:20:05.680 --> 01:20:09.680]   Bitcoin is fantastic. We can track everything. It's like, yeah, but the compute load to do that
[01:20:09.680 --> 01:20:15.520]   is such that it's going to slow down all your planning systems. So, yeah.
[01:20:15.520 --> 01:20:23.760]   There will be better. The Bitcoin ledgers. I'm sorry. It's not 100 gigabytes. How big is the
[01:20:23.760 --> 01:20:29.440]   blockchain today? Maybe it's only 20 gigabytes. It's going up. No, I'm sorry.
[01:20:29.440 --> 01:20:39.760]   It looks like 230 gigabytes. Yikes. That's so many. It's all the gigabytes.
[01:20:39.760 --> 01:20:48.320]   Somebody's saying you can zip it, but I don't know. But still, still, that's a lot of data.
[01:20:48.320 --> 01:20:53.680]   It has to be distributed. Yes. So, Bitcoin's up to 10,500 now.
[01:20:53.680 --> 01:20:56.480]   It is? Yeah. It's had a bit of a rally of late.
[01:20:56.480 --> 01:21:01.760]   Maybe because Libra is not the next thing. Yeah. I think when Libra was announced that it wasn't
[01:21:01.760 --> 01:21:05.440]   going to be coming out quite as quickly as then the market rally, it's slightly, but it's still.
[01:21:05.440 --> 01:21:12.080]   I got to figure out what my password is to my wallet. I got seven Bitcoins. At one point,
[01:21:12.080 --> 01:21:15.280]   it was worth $140,000. Now you're saying it's worth $70,000.
[01:21:16.640 --> 01:21:20.720]   I can't remember the password. It was a British IT administrator who had,
[01:21:20.720 --> 01:21:25.600]   this was back when he had really peaked. He had, it was $6 billion worth of Bitcoin
[01:21:25.600 --> 01:21:30.960]   on an old hard drive. Yeah. He threw out. Yeah. He threw out. So, he's trying to organize a
[01:21:30.960 --> 01:21:35.120]   Kickstarter campaign. To go through the dump. To go through the dump hand by hand to find this
[01:21:35.120 --> 01:21:39.600]   drive and hope that it worked again. But sadly, no, it didn't confine enough takers on that one.
[01:21:39.600 --> 01:21:44.160]   So, Steve, I don't know. It seems worth it for that amount of money. I would do it.
[01:21:44.160 --> 01:21:47.840]   I'd search through the dump. If the drive works, though, off the other side.
[01:21:47.840 --> 01:21:51.680]   Steve Gibson, when we did a piece on security now, when Bitcoin first came out,
[01:21:51.680 --> 01:21:54.800]   he talked about the process, how blockchain works, how Bitcoin works,
[01:21:54.800 --> 01:21:58.160]   Satoshi, paper and everything. And he thought, "Well, I'll just set up a miner.
[01:21:58.160 --> 01:22:03.200]   Set up a miner the next day." 50 Bitcoin come out. This was in the early days.
[01:22:03.200 --> 01:22:07.360]   Yeah. Yeah. He's a big deal. It's Bitcoin. He put it on the hard drive.
[01:22:07.360 --> 01:22:13.200]   It was at one point worth a million dollars. It turns out he never, he wouldn't admit this.
[01:22:13.200 --> 01:22:16.480]   He finally admitted to me. He had to race the hard drive. He'd back up his wall.
[01:22:16.480 --> 01:22:23.840]   Backup kids back up your wallet. Yeah. Yeah. That's all I can say. He'd erased a million dollars
[01:22:23.840 --> 01:22:32.560]   worth of Bitcoin just by erasing it. As he do. As one does, did you see this was a good one from
[01:22:32.560 --> 01:22:42.640]   Brian Krebs, Speaking of Security. Oh, wow. QuickBooks cloud hosting firm in sync.
[01:22:43.200 --> 01:22:47.920]   Hidden ransomware attack. This is just broke. Okay. That's not the one.
[01:22:47.920 --> 01:22:51.760]   That was just on this today. That's what I had is actually this was on Friday.
[01:22:51.760 --> 01:23:00.880]   Brian has become the king of ransomware. Now, this has some bad words in it.
[01:23:02.320 --> 01:23:14.400]   But this is an ad for a Russian credit card fraud shop. They make, they made an ad.
[01:23:14.400 --> 01:23:19.040]   All right. I'm just going to, I'm just going to play the ad and see if it makes you want to,
[01:23:19.040 --> 01:23:25.520]   want to notice by the way, an American flag hamburgers and a GOP elephant on this guy's bib.
[01:23:25.520 --> 01:23:39.360]   There's a coach, there's a fess. I'm confused. There's a guy going into the club. There's,
[01:23:39.360 --> 01:23:46.320]   they're grinding people up in a meat grinder. That's the president Donald Trump. I don't know
[01:23:46.320 --> 01:23:54.800]   what this is. He's making, oh, burgers out of it. And it looks like Homer Simpson, Barack Obama,
[01:23:54.800 --> 01:24:02.640]   Hillary Clinton. Okay. It's from, it's a party like a Russian, Robbie Williams, a song, or actually,
[01:24:02.640 --> 01:24:12.240]   you know, it's based on the video. It's a little disturbing. I apologize. But the fact that they
[01:24:12.240 --> 01:24:19.200]   have ads for credit card fraud shops was the thing that I found fascinating. I will stop it before we
[01:24:19.840 --> 01:24:25.200]   get to the actual, the actual ad. I got something that'll take the bad taste out of our mouth.
[01:24:25.200 --> 01:24:31.040]   We made a little video this week of all the fun things that we've done to it. Why don't we,
[01:24:31.040 --> 01:24:36.640]   why don't we watch that? Kids? Oh wait a minute. Hold on. Yes. Press the button. Is it ready to
[01:24:36.640 --> 01:24:41.920]   it? How many people going at the meat grinders does it feature? No, none. Zero zip. That was
[01:24:41.920 --> 01:24:49.040]   disgusting. Wasn't it? I apologize for that. I blame you, Brian. Do we have it?
[01:24:49.600 --> 01:24:56.160]   All right. Let's roll the tape. Previously on to it. This is what face app, which is a viral app.
[01:24:56.160 --> 01:25:01.680]   That's exactly what you're going to look like. That is what I think you're going to look like.
[01:25:01.680 --> 01:25:09.600]   It's ancient marinade. Mac break weekly. Originally came from digit times. Apple is killing its AR
[01:25:09.600 --> 01:25:15.280]   glasses. I am prejudiced to believe the report that Apple is backing away from immediate plans.
[01:25:15.280 --> 01:25:18.720]   Yeah, I just I don't think anybody will ever be a hold on a second. I just got a message.
[01:25:18.720 --> 01:25:25.680]   Windows weekly. This title, the show this title today is The Cats Away. I'm like,
[01:25:25.680 --> 01:25:31.920]   he can almost pet him. I'm going to get scratched his back. It's nice. This week in Google,
[01:25:31.920 --> 01:25:37.680]   my pick of the week I already told you about, which is start page, which gives you Google results
[01:25:37.680 --> 01:25:42.560]   without giving Google any information. And it's easy to install if you're using firefights.
[01:25:42.880 --> 01:25:48.480]   Security now quote. Their headline was malware attack on county computers,
[01:25:48.480 --> 01:25:54.960]   La Porte County website, government email servers out of operation. Someone by the name of the
[01:25:54.960 --> 01:26:01.280]   doctor. He's doing this to irk me, aren't you? No, just wait. Oh, Gibson Township goes down.
[01:26:01.280 --> 01:26:04.960]   That's right. Twit, the happiest place on earth.
[01:26:04.960 --> 01:26:11.920]   Our show today brought to you by Rocket Mortgage from quick and loans, finding the right
[01:26:11.920 --> 01:26:16.400]   houses and easy, but finding the right mortgage. That's a lot easier. Thanks to quick and loans
[01:26:16.400 --> 01:26:21.040]   and rocket mortgage. Rocket mortgage is doing more to help you understand the home buying process.
[01:26:21.040 --> 01:26:26.400]   So you can get exactly what you need. Because it's not just a mortgage, it's your mortgage.
[01:26:26.400 --> 01:26:30.800]   Quick and loans and rocket mortgage has a team of mortgage experts
[01:26:30.800 --> 01:26:34.800]   accessed with finding a better way, which means their number one goal is to make the home
[01:26:34.800 --> 01:26:40.640]   buying process smoother for you award winning client service and support every step of the way
[01:26:40.640 --> 01:26:45.840]   industry leading online lending technology. They've helped millions of Americans achieve their dream
[01:26:45.840 --> 01:26:51.840]   of home ownership. And you know, the proof is in the pudding, or should I say in the JD Power award,
[01:26:51.840 --> 01:26:58.480]   JD Power is ranked quick and loans highest in customer satisfaction for mortgage origination
[01:26:58.480 --> 01:27:04.720]   nine years in a row and highest in mortgage servicing five years in a row. If you want more
[01:27:04.720 --> 01:27:10.160]   information, go to JDpower.com when you work with Rocket Mortgage, you get more than just
[01:27:10.160 --> 01:27:14.480]   alone because Rocket Mortgage is a lot more than just the lender visit rocket mortgage.com
[01:27:14.480 --> 01:27:20.960]   slash twit to and take the first step toward the home of your dreams get started online today at
[01:27:20.960 --> 01:27:27.840]   rocket mortgage.com slash twit to their and equal housing lender, of course, licensed in all 50
[01:27:27.840 --> 01:27:35.680]   states and MLS consumer access.org number 30 30 rocket mortgage from quick and loans. Push button
[01:27:37.360 --> 01:27:47.840]   get mortgage. I do want to mention Apollo 11 because of course, this is the week 50th anniversary
[01:27:47.840 --> 01:27:53.200]   of Apollo 11. And a lot of times we talk about the space program and inevitably, I don't know if
[01:27:53.200 --> 01:27:58.800]   these people say this lately, but as as long as I've been around, they've said, Oh yeah, the space
[01:27:58.800 --> 01:28:05.760]   program, what do we get? We got Tang. We got Velcro. We got pens that could write upside down.
[01:28:06.640 --> 01:28:12.160]   And I never had a biting my tongue on this one. Why? Well, because Velcro existed before the
[01:28:12.160 --> 01:28:17.840]   space program because the pen thing was developed privately for NASA rather than. And by the right,
[01:28:17.840 --> 01:28:23.440]   Russian cosmonauts used pencils. Oh, it works in space. That's also an urban myth because they
[01:28:23.440 --> 01:28:27.680]   didn't use pencils. No, the graphite from the pencil would actually have short-step electronics.
[01:28:27.680 --> 01:28:32.960]   So they started using pencils and they found it works so good. They like the pencil. So what
[01:28:32.960 --> 01:28:38.240]   do they do? Well, laser eye surgery, for example, that was developed from software for getting
[01:28:38.240 --> 01:28:45.440]   ships to dock or birth with other ships. A whole host of new materials and ceramics.
[01:28:45.440 --> 01:28:51.280]   The kind of alloys needed to deal with these kind of things are now in produce everywhere. And of
[01:28:51.280 --> 01:28:58.880]   course, computers, you know, really important. The first use of semiconductors, microelectronics,
[01:28:59.840 --> 01:29:04.400]   really, it was the first embedded processor ever in the Apollo guidance computer that
[01:29:04.400 --> 01:29:10.240]   landed the men on the moon. You see, Arthur C. Clark was one of the great
[01:29:10.240 --> 01:29:17.120]   disappointments was the invention of microelectronics because he didn't visit if you were going to
[01:29:17.120 --> 01:29:20.640]   put satellites around space. You'd have to have people that constantly replacing the valves.
[01:29:20.640 --> 01:29:23.680]   The valves on them. We call them tubes here. Well, yes. But
[01:29:25.280 --> 01:29:29.840]   I mean, no, we got a lot out of this. Oh, yeah. The fact that we've dropped the ball ever since is
[01:29:29.840 --> 01:29:35.040]   great piece. Wall Street Journal did a really great job. And I want to give credit
[01:29:35.040 --> 01:29:43.520]   to the Wall Street Journal's, let me close the ad here so I can see his name. The Wall Street
[01:29:43.520 --> 01:29:48.640]   Journal science reporter Robert Lee Hots who did this video and narrated it. I'm guessing with his
[01:29:48.640 --> 01:29:54.000]   son, Alexander Hots. You're looking good for separation. You're a goal for separation. Columbia,
[01:29:54.000 --> 01:30:00.800]   over on July 20, a guy named Don Ailes just moments after the Apollo 11, who had never programmed a
[01:30:00.800 --> 01:30:08.880]   computer before, but was hired by MIT to help write the code that controlled Apollo's lunar
[01:30:08.880 --> 01:30:16.480]   modules descent to the moon. He was just a young guy straight out of college. And I guess at that
[01:30:16.480 --> 01:30:22.640]   time, where did you go to find computer programmers? Nowhere. So he was a smart guy. He was he applied
[01:30:22.640 --> 01:30:30.160]   to the instrumentation laboratory at MIT, 23 year old math major. And they said, well, math? Okay,
[01:30:30.160 --> 01:30:37.840]   come on in. And he ended up with the team writing the software for the first, you know,
[01:30:37.840 --> 01:30:43.440]   icy based interactive computer in space. If you look at the actual hardware, say it's just a
[01:30:43.440 --> 01:30:48.720]   masterpiece of right move this, this, I mean, makes the altar in 1976. Look, you know,
[01:30:49.680 --> 01:30:54.880]   so far advanced. But they just they did look at the source code and they found some
[01:30:54.880 --> 01:31:01.120]   some fun whimsy in it. Some of the routine names, for instance, the ignition sequence was
[01:31:01.120 --> 01:31:09.200]   named burn baby burn. And when the computer wanted to reposition the landing radar and 10 of the
[01:31:09.200 --> 01:31:17.280]   code said, I presume this is a comment astronaut, please crank the silly thing around. And then
[01:31:17.280 --> 01:31:21.440]   it performed a calculation to determine if the astronaut had moved it correctly, called
[01:31:21.440 --> 01:31:26.960]   see if he's lying. When the antenna was aimed and the landing could proceed, the code said off
[01:31:26.960 --> 01:31:33.440]   to see the wizard. Okay. Yeah, Easter eggs was still always been a thing that I also want to give
[01:31:33.440 --> 01:31:39.680]   credit to a woman named Margaret Hamilton. Yes. She's still alive. She's in her eighties.
[01:31:39.680 --> 01:31:44.320]   She got a word of the presidential matter of Obama. Yep. And you'll probably probably see in
[01:31:44.320 --> 01:31:50.960]   the picture of her with the with the source code printed out on the on the reams of paper as tall
[01:31:50.960 --> 01:31:57.200]   as she was. She she's now you may I don't know if you remember, but you'll if you listen to the
[01:31:57.200 --> 01:32:02.960]   landing, you'll hear at one point as the lunar modules trying to come down, Neil Armstrong say,
[01:32:02.960 --> 01:32:10.400]   we have a 1202 error. There's the picture of her with the the reams, the huge print out of all the
[01:32:10.400 --> 01:32:21.040]   code. Oh my goodness. What's a 1202 error? Armstrong asks. And nobody knew what the 1202 error is.
[01:32:21.040 --> 01:32:28.400]   She knew she was sitting along with other programmers and engineers because she wrote the alarm codes,
[01:32:28.400 --> 01:32:32.320]   including the 1202 code. She says they were this is also in the Wall Street Journal. They were
[01:32:32.320 --> 01:32:37.680]   never supposed to happen alarms. I was in a state of shock. I mean, they're literally minutes from
[01:32:37.680 --> 01:32:42.400]   landing on the moon. They're are in the lunar module. How could this be happening just before
[01:32:42.400 --> 01:32:49.600]   the landing? I'm thinking, Oh my God, this is not real. But to their credit, they had written the
[01:32:49.600 --> 01:32:56.480]   1202 in it was a signal that the computer had been overloaded. But and this is a this is such a
[01:32:56.480 --> 01:33:02.720]   great story. It had been designed if it if its ram was full to start dumping unimportant tasks in
[01:33:02.720 --> 01:33:08.320]   order to keep flying safely. And that's what 1202 was. And 1202 kept happening. And Armstrong
[01:33:08.320 --> 01:33:13.840]   said, what is going on? And eventually, and you can hear this on the recordings, the flight director
[01:33:13.840 --> 01:33:20.560]   Gene Krantz says to him, it's okay, you're go. Because they said, Oh no, this is this you're not
[01:33:20.560 --> 01:33:26.160]   supposed to see this error. There was there was something a switch had been flipped wrong at some
[01:33:26.160 --> 01:33:30.880]   point. And and data was being dumped into the computer. But the computer was handling it properly.
[01:33:31.440 --> 01:33:36.800]   That 1202 error reset the computer. They continued to land. They landed safely.
[01:33:36.800 --> 01:33:44.560]   And I think a lot of credit goes to Margaret Hamilton and the T and many, many, many people.
[01:33:44.560 --> 01:33:52.160]   Yeah. At MIT and NASA who who had written this code. So I there is absolutely a story to be told
[01:33:52.160 --> 01:33:56.640]   around this Apollo 11 landing. And if you use a computer today with microprocessors,
[01:33:56.640 --> 01:34:04.320]   you have all the debt. Yeah. Yeah. Thank you. Can thank Margaret Hamilton and and what an amazing team,
[01:34:04.320 --> 01:34:10.480]   including the young Don Ailes. Margaret Hamilton gave a lovely interview,
[01:34:10.480 --> 01:34:14.720]   which said she wouldn't be able to do this if her husband hadn't been quite so enlightened about,
[01:34:14.720 --> 01:34:18.080]   you know, women's abilities and that sort of thing, which is a proven is one of the reasons
[01:34:18.080 --> 01:34:24.480]   she married him. But yeah, it was women used to be the bulk of coders in some areas.
[01:34:24.480 --> 01:34:28.720]   And if only in the same region, that's what a computer meant. In the early days, a computer
[01:34:28.720 --> 01:34:32.880]   wasn't a machine. It was a human, a woman, in most cases. Yeah. So every time we have the James
[01:34:32.880 --> 01:34:37.680]   Danmels of this world, it's like what women are suited towards boat coating. It's just like,
[01:34:37.680 --> 01:34:45.520]   they've been doing it for the last 70 years. The 1202 is one of 29 alarms that could be displayed
[01:34:45.520 --> 01:34:54.160]   during the landing. Give us a reading on the 1202 program alarm strong radioed. They were 30,000
[01:34:54.160 --> 01:34:58.640]   feet and this above the moon, it is sending 27 seconds ticked off with no answer.
[01:34:58.640 --> 01:35:07.280]   As everybody scrambled to figure out what the hell? Finally, Grant said, we're go on that alarm.
[01:35:07.280 --> 01:35:14.880]   And his team said we're go. And he said, go. And they landed 17 seconds away from aborting.
[01:35:14.880 --> 01:35:20.560]   What was I think in many ways the most amazing thing humans have ever done.
[01:35:21.280 --> 01:35:25.200]   And thanks to Margaret Hamilton, here's another. Here's a picture of some of the other things.
[01:35:25.200 --> 01:35:28.480]   You get all the way there when you abort and you never would have lived that down in the
[01:35:28.480 --> 01:35:33.200]   astronaut bars afterwards. Yeah, we had to abort. No, we're landing. We're there, man.
[01:35:33.200 --> 01:35:42.800]   By the way, the final line of code as blows of lunar dust settled around the lander 50 years
[01:35:42.800 --> 01:35:47.360]   ago, it's onboard computer ticked through the instructions of its P68 lunar landing confirmation
[01:35:47.360 --> 01:35:53.040]   routine embedded in the final lines, writes, hots, where no outsider was ever likely to see it.
[01:35:53.040 --> 01:36:01.920]   The software said, astronaut, now look where you ended up on the moon. So that is a great,
[01:36:01.920 --> 01:36:07.280]   I really still get chills just thinking about it. Seth, you're not old enough to remember that.
[01:36:07.280 --> 01:36:14.000]   Nope. You and you're not either. I apparently did watch it. I was like,
[01:36:14.000 --> 01:36:20.000]   two. I was about two weeks old at the time. I was 12. I remember it very, very well.
[01:36:20.000 --> 01:36:25.440]   And I think it probably influenced me considerably. Apparently. Yeah, no, apparently,
[01:36:25.440 --> 01:36:29.280]   the local pub was showing it. So the family all decamped down there. And
[01:36:29.280 --> 01:36:37.360]   yeah, they allowed small screaming children in. I want to take one more break. And then I'm going
[01:36:37.360 --> 01:36:47.120]   to ask you Paris about, nope, not this one, about this New York Times article, which scared the
[01:36:47.120 --> 01:36:55.040]   hell out of me. Don't scoff at influencers. They're taking over the world. The next president of
[01:36:55.040 --> 01:36:59.760]   the United States will have been a social media influencer. Actually, I think the current president
[01:36:59.760 --> 01:37:04.560]   of the United States is a social media influencer. Come to think of it. We're already in that era.
[01:37:04.560 --> 01:37:09.600]   We're already in that era. But before that, I want to order some food. Can we get DoorDash
[01:37:09.600 --> 01:37:16.640]   on the line? I'm starving. Thank goodness DoorDash has connected us to our favorite restaurants.
[01:37:16.640 --> 01:37:24.400]   I love DoorDash, our sponsor for this portion of the Twitch show. How many times, it happens to me
[01:37:24.400 --> 01:37:29.360]   all the time. You go home, you're not in the mood to cook. You fire up your phone. DoorDash,
[01:37:29.360 --> 01:37:34.000]   DoorDash makes ordering easy. They connect you with all the restaurants in town. McDonald's is
[01:37:34.000 --> 01:37:39.280]   there, Chipotle, Wendy's, Chick-fil-A, the cheesecake factory. DoorDash connects you with Door to Door
[01:37:39.280 --> 01:37:45.440]   Delivery in over 3,300 cities in all 50 states and Canada. Don't worry about dinner. Let dinner
[01:37:45.440 --> 01:37:50.960]   come to you with DoorDash. I have to tell you, I love DoorDash for another reason. I've been using
[01:37:50.960 --> 01:37:57.360]   DoorDash for more than a year. My mom is 86. A couple of years ago, my whole life, she cooked me
[01:37:57.360 --> 01:38:01.360]   the best meals, right? Your mother's cooking is the best cooking. You've never tasted my mother's
[01:38:01.360 --> 01:38:07.440]   liver or I take it. My mother's cooking is the best cooking. She cooked Italian because my dad
[01:38:07.440 --> 01:38:14.080]   was Italian. She had to cook Italian. We had ravioli. She made her own pasta. She made her own
[01:38:14.080 --> 01:38:18.320]   French bread. I grew up on that. When she got to a certain age, a couple of years ago, she said,
[01:38:18.320 --> 01:38:25.360]   "I can't cook anymore. I don't want to do it anymore." I said, "Mom," I had given her an iPhone. I said,
[01:38:25.360 --> 01:38:31.200]   "Put DoorDash on your phone." I put my credit card number in the DoorDash. I said, "If you ever
[01:38:31.200 --> 01:38:36.880]   want something to eat, use this. It's on me." Even though she's all the way in Rhode Island,
[01:38:36.880 --> 01:38:42.560]   I get to give her a meal. It's a great way to pay mom back. Isn't that nice? In fact,
[01:38:42.560 --> 01:38:46.720]   it works so well. Lisa does it with her parents now, too. I'm just a little something you can do
[01:38:46.720 --> 01:38:53.200]   with your folks. DoorDash is fantastic. Of course, we use it all the time. You can have anything you
[01:38:53.200 --> 01:38:58.640]   want delivered right to your door by those great dashers. Right now, you'll get $5 off your first
[01:38:58.640 --> 01:39:03.840]   DoorDash order of $15 or more. If you download the DoorDash app, put it on your phone and use the
[01:39:03.840 --> 01:39:11.280]   promo code TWIT. I'm promising you. You will love it. Slice is on your sofa or derves on your
[01:39:11.280 --> 01:39:19.040]   ottoman. This is DoorDash, DoorDash promo code TWIT. Go to the App Store, download DoorDash,
[01:39:19.040 --> 01:39:24.560]   make an order, your first order of $15 or more. You get $5 off, but you have to use a promo code TWIT
[01:39:25.200 --> 01:39:32.320]   for that order. You can thank me later. What a great gift, by the way. A great gift for anybody.
[01:39:32.320 --> 01:39:36.560]   Thank you, DoorDash, for your support. Thank you for helping me be a better son.
[01:39:36.560 --> 01:39:41.840]   Somebody's saying in the chatroom that the BBC did a really good documentary called "13
[01:39:41.840 --> 01:39:46.480]   Minutes to Landing." Oh, yes. I've heard about this. I haven't seen it off to watch.
[01:39:46.480 --> 01:39:50.720]   I am not sick of it yet. I thought this week because it's been non-stop everybody,
[01:39:50.720 --> 01:39:54.640]   but I could watch it over and over. Hell, I haven't watched these seven minutes of hell,
[01:39:54.640 --> 01:39:59.200]   video this weekend with the Curiosity land at Lanigo Mars. NASA's done a brilliant video.
[01:39:59.200 --> 01:40:01.920]   Amazing. Well, yeah, pretty amazing.
[01:40:01.920 --> 01:40:09.920]   The shift, New York Times earlier this week. This is going to be interesting.
[01:40:09.920 --> 01:40:16.160]   I'm VidCon. When the first TikTok star is elected president writes Kevin Russe,
[01:40:16.160 --> 01:40:20.880]   who's great, "I hope she'll save some room in her cabinet for older and more conventional
[01:40:20.880 --> 01:40:25.200]   bureaucrats, even if they don't have millions of followers. Great hair or amazing dance moves."
[01:40:25.200 --> 01:40:29.360]   I say when, not if, because I just spent three days at VidCon,
[01:40:29.360 --> 01:40:33.360]   hanging out with a few thousand current and future internet celebrities,
[01:40:33.360 --> 01:40:37.760]   and it's becoming increasingly obvious to me, the teenagers and 20-somethings who have mastered
[01:40:37.760 --> 01:40:42.560]   these platforms and who are often dismissed as shallow, preening narcissists by adults who
[01:40:42.560 --> 01:40:47.760]   don't know any better are going to dominate, not just internet culture or the entertainment
[01:40:47.760 --> 01:40:51.680]   industry, but society as a whole. Paris, you live in this world, you agree?
[01:40:51.680 --> 01:40:57.920]   Yeah, I mean, I would say the one thing is that probably by the time someone who's TikTok
[01:40:57.920 --> 01:41:03.760]   to start today is of age to be elected president, TikTok will have been replaced by whatever
[01:41:03.760 --> 01:41:06.240]   the next big... Well, that's going to happen next month.
[01:41:06.240 --> 01:41:09.600]   ...but yeah, that'll probably happen. There'll be six other apps.
[01:41:10.560 --> 01:41:18.960]   So it won't be TikTok, but yeah, I mean, the influencer industry and world of culture that it
[01:41:18.960 --> 01:41:25.920]   creates is not just some small niche, and it's not relegated to, I don't know, one part of the
[01:41:25.920 --> 01:41:32.480]   world, be it like beauty or entertainment or even culture in generally, it is an all-encompassing
[01:41:32.480 --> 01:41:39.040]   way in which people interact with consumer and create content and interact with each other.
[01:41:39.040 --> 01:41:45.600]   I kind of blame myself because inevitably, when we talk about influencers, we talk about Logan
[01:41:45.600 --> 01:41:52.480]   Paul, we talk about Kim Kardashian, we talk about the outliers, the weirdos, the strange people,
[01:41:52.480 --> 01:41:58.240]   the dubious stunts, the extreme political commentary, things like that. But Roost points out,
[01:41:58.240 --> 01:42:06.080]   many of these people are entrepreneurs. They've set up businesses, they're hiring staff,
[01:42:06.080 --> 01:42:12.560]   they're managing budget. This is a business for a lot of these people, and the skills
[01:42:12.560 --> 01:42:20.640]   is completely transferable to running the world in 20 or 30 years. Is AOC, does she count as maybe
[01:42:20.640 --> 01:42:25.600]   she counts a little bit as one of the first influencers in Congress? She certainly knows how to use
[01:42:25.600 --> 01:42:31.120]   Twitter. In fact, she gave classes in Twitter to her older colleagues, as I remember.
[01:42:31.120 --> 01:42:37.360]   This is a definition I've been trying to figure out lately is how do we define influencer.
[01:42:37.360 --> 01:42:46.960]   I think the thing that separates influencers from celebrities or other mainstream figures in the
[01:42:46.960 --> 01:42:54.160]   Blind Light in society is that influencers come up through and gain notoriety through
[01:42:55.440 --> 01:43:03.280]   posting on some platform or creating content in some space originally for a non-
[01:43:03.280 --> 01:43:08.880]   originally in a way that is not monetizable. They have this kind of Arab authenticity.
[01:43:08.880 --> 01:43:14.720]   Meanwhile, celebrities, they get notoriety and gain fame because they are participating in more
[01:43:14.720 --> 01:43:19.920]   of an established industry. Celebrities can be influencers and influencers can be celebrity.
[01:43:19.920 --> 01:43:27.680]   For years, right? When you go to Japan, you see American movie stars who wouldn't
[01:43:27.680 --> 01:43:34.000]   dain to do TV ads or billboards in the US all over the place. They're clearly influencers.
[01:43:34.000 --> 01:43:39.440]   That's been a scam for a while now. That's not doing, do you're advertising in Japan and Korea
[01:43:39.440 --> 01:43:44.800]   because it'll never come back to you in the US? Who's the guy who was on Men in Black with Will Smith?
[01:43:45.600 --> 01:43:52.560]   Oh, treat Williams? Is that his name? No. Anyway, he's huge in Japan. You see him on
[01:43:52.560 --> 01:43:58.480]   vending machines everywhere. I took a picture of it because I couldn't believe it. He's riding
[01:43:58.480 --> 01:44:04.400]   an inner tube. His hair is swept back and he's holding canned coffee and it's an ad for canned
[01:44:04.400 --> 01:44:09.280]   coffee and it's everywhere when I was in Japan last year. It was Tommy Lee Jones. Thank you.
[01:44:09.280 --> 01:44:15.040]   That's it. He was everywhere. He's made up anyway. Actually, Bruce points this out. He said
[01:44:15.040 --> 01:44:19.040]   influencers have been running the world for years. Can you say President Ronald Reagan?
[01:44:19.040 --> 01:44:24.800]   We just haven't called him influencers. We call them movie stars or talk radio host or Davos
[01:44:24.800 --> 01:44:31.680]   attendees. Honestly, I think you could probably point out the president as there is the boss.
[01:44:31.680 --> 01:44:39.360]   Tommy Lee Jones. It's boss coffee, which by the way, the boss coffee logo. See if you can find the one
[01:44:39.360 --> 01:44:48.080]   where he's riding the inner tube. The boss coffee logo is like the guy with the pipe from the
[01:44:48.080 --> 01:44:55.920]   slack religion. The slack religion? Joe Bob, what's his name? J. Bob Dobbs. J. Robert Dobbs.
[01:44:55.920 --> 01:45:02.560]   It looks just like J. Robert Dobbs. I'm sorry. I'm Leo being an old influencer.
[01:45:04.000 --> 01:45:11.040]   President Trump is an influencer. He used Twitter to create a Facebook better than any candidate.
[01:45:11.040 --> 01:45:16.160]   You could really make the, I think, a very credible claim. He won not because of Russian
[01:45:16.160 --> 01:45:23.200]   influencer election fraud or electoral college, but because he used Facebook incredibly effectively.
[01:45:23.200 --> 01:45:28.080]   To spend a lot of my talks, he adds that spending has not actually sold, which is what makes me
[01:45:28.080 --> 01:45:34.640]   think he's going to win next time round as well. The Trump team really understood it the same
[01:45:34.640 --> 01:45:41.200]   with the Brexit crew in the UK. They really understood social media. I don't know. It's interesting
[01:45:41.200 --> 01:45:45.840]   point about the interchangeability that you made, Paris, on celebrities and influencers.
[01:45:45.840 --> 01:45:50.080]   I don't know how you feel about this, but we were talking in the office. We occasionally will
[01:45:50.080 --> 01:45:53.920]   get some, like, would you like to promote my product and in return? I'll give you a shout out on
[01:45:53.920 --> 01:45:59.120]   my Instagram thing. Those just come across as complete pillocks. But at what point does
[01:45:59.120 --> 01:46:05.120]   someone become an influencer? Is it reaching a certain regular number of social media heads per
[01:46:05.120 --> 01:46:11.040]   post or is it just the effect that they have? I think the term influencer, at least as we
[01:46:11.040 --> 01:46:19.920]   kind of have used it for the last couple of years, is intrinsically tied to capitalism and
[01:46:19.920 --> 01:46:26.640]   intrinsically tied to purchasing power and specifically the ability to influence or sway the buying
[01:46:26.640 --> 01:46:36.480]   habits or actions or beliefs and trends of others. Predominantly, when we're talking about influencers,
[01:46:36.480 --> 01:46:44.240]   these are people who are making money and a career and a life out of being able to produce
[01:46:44.240 --> 01:46:52.400]   content in some way and they generally finance that career by brand promotions or merch sales or
[01:46:52.400 --> 01:47:00.080]   any of these kind of entrepreneurial, I guess you could say, efforts in order to
[01:47:00.080 --> 01:47:08.880]   fund an unrelated, probably, channel or sort of content promotion, which is the one thing that does
[01:47:12.080 --> 01:47:20.720]   split influencers from political figures or people who have a general influencer political power in
[01:47:20.720 --> 01:47:33.040]   a more tangential sense. I mean, Bruce's piece ultimately says, "Don't dismiss influencers.
[01:47:33.040 --> 01:47:38.400]   That's just youth culture. That's the future. Is it youth culture? Is that where youth
[01:47:38.400 --> 01:47:42.880]   culture is gone?" Maybe that's why people like me don't recognize it because it used to be TV or
[01:47:42.880 --> 01:47:49.840]   it used to be movies or music. It's all been media, I guess. That's all media, but now it's
[01:47:49.840 --> 01:47:59.360]   Instagram. It's Snapchat. It's Instagram. You have to listen on the radio. Go to the movies or whatever.
[01:47:59.360 --> 01:48:03.760]   Now it's instantly into your pocket, onto your hand and the scale of it. It's so huge.
[01:48:05.600 --> 01:48:12.880]   Yeah. There are so many more niches. You can have an influencer who's a trusted expert or
[01:48:12.880 --> 01:48:20.400]   icon in any particular pocket of the world. If I want to find the best person to do strange,
[01:48:20.400 --> 01:48:25.040]   woodworking clocks, there's probably tens of thousands of influencers for that.
[01:48:25.040 --> 01:48:28.320]   That's a good point. That's one thing that's really changed is there are many, many, many niches.
[01:48:28.320 --> 01:48:33.440]   That's why brands love them so much. I guess from an advertising dollar perspective, it's much
[01:48:33.440 --> 01:48:40.080]   better for advertisers. Celebrity endorsements are meaningless in comparison to very specific
[01:48:40.080 --> 01:48:46.800]   influencer type advertising because if you're trying to target an audience, you can say, "Oh,
[01:48:46.800 --> 01:48:53.200]   have this celebrity promote my hair product." Some of their followers probably like this,
[01:48:53.200 --> 01:48:57.760]   you can be like, "Oh, I can go to this one hair product specific Instagram account where everyone
[01:48:57.760 --> 01:49:01.920]   here is talking about hair." I know I'm going to reach the people who matter the most. These are
[01:49:01.920 --> 01:49:08.320]   my customers. That's actually the same thing that people do with Facebook ads. A Facebook ad
[01:49:08.320 --> 01:49:15.440]   spend tends to be $100, $200, very small, but a great many of them because you're targeting very
[01:49:15.440 --> 01:49:22.080]   narrow slices. I would imagine this is the same thing with influencers. The problem with that,
[01:49:22.080 --> 01:49:26.560]   if you're a proctor and gamble and you want to spend $100 million on influencers,
[01:49:26.560 --> 01:49:33.040]   it's hard to spend at $100 at a time. Is there a burgeoning system for making this work?
[01:49:33.040 --> 01:49:37.840]   Is it agencies? Yeah, there are a lot of many markets and agencies
[01:49:37.840 --> 01:49:44.000]   for middle-tier influencers, not ones with tens of millions. Generally,
[01:49:44.000 --> 01:49:50.000]   on YouTube or Instagram, there are a bunch of different companies that exist where influencers
[01:49:50.000 --> 01:49:55.200]   can sign up. It operates a mini marketplace. They sign up, put their interests,
[01:49:56.240 --> 01:50:02.640]   things that they're interested in, and brands also will put their interests as well as put out
[01:50:02.640 --> 01:50:10.000]   campaign offers and the agency acts as a broker between the two and they form a campaign from that,
[01:50:10.000 --> 01:50:14.480]   which in some cases can happen on an automated scale if you want to do it more simply.
[01:50:14.480 --> 01:50:19.040]   In other cases, it can produce more bespoke form of advertising.
[01:50:19.040 --> 01:50:23.200]   So tech facilitates this too. Yeah, the one difference though,
[01:50:23.200 --> 01:50:28.480]   as far as influencer marketing versus something like Facebook is that most people don't,
[01:50:28.480 --> 01:50:35.440]   when you see what I guess would be an ad or sponsored product through an influencer,
[01:50:35.440 --> 01:50:39.680]   most people don't think of it as an advertisement in the same way that they would.
[01:50:39.680 --> 01:50:43.200]   If you see a Facebook ad, you're going to be like, "Oh, this is an ad. It's meaningless.
[01:50:43.200 --> 01:50:47.520]   I'm not going to look at it very purposefully if you notice it at all." But when it's your
[01:50:47.520 --> 01:50:51.440]   favorite influencer talking about how much you love this product, it's different.
[01:50:51.440 --> 01:50:57.440]   That's a big, to me, that's a big problem with banner ads is that you, I do the same thing.
[01:50:57.440 --> 01:51:01.920]   I intentionally ignore them. Like I avert my, I shouldn't admit this.
[01:51:01.920 --> 01:51:06.640]   That they can avert my eyes as I'm looking down the page. Don't tell Seth this.
[01:51:06.640 --> 01:51:12.400]   But as I'm going down the page, I avert my eyes. But for some reason, Instagram ads work against
[01:51:12.400 --> 01:51:17.760]   me. It's by the way, why I stopped using Instagram because every ninth post is not a post.
[01:51:18.640 --> 01:51:23.680]   It's an ad, but it's the same attention that you're giving to each a post. They win every time.
[01:51:23.680 --> 01:51:30.400]   I've spent so much stuff on Instagram crap I don't want all the time. It works so well.
[01:51:30.400 --> 01:51:34.800]   Coming from a magazine which is supported in part, what banner ads are there?
[01:51:34.800 --> 01:51:37.200]   I'm sorry to be, I apologize to you, Ann Cess.
[01:51:37.200 --> 01:51:39.760]   No, it's okay. But I would worry if I were you.
[01:51:39.760 --> 01:51:43.120]   But I'm worried for podcasts because Facebook is so efficient.
[01:51:43.120 --> 01:51:48.160]   As publications, if we try to put as much advertising on our site as Facebook puts on it,
[01:51:48.560 --> 01:51:52.480]   we wouldn't get any readers. Because if you look at the actual screen acreage of Facebook that
[01:51:52.480 --> 01:51:54.800]   isn't an advert, it's a very small property.
[01:51:54.800 --> 01:51:58.320]   Have you listened to American AM radio lately?
[01:51:58.320 --> 01:52:01.680]   No, no, no. Last time I did 19 minutes an hour.
[01:52:01.680 --> 01:52:04.480]   Well, I'm third. Oh my God.
[01:52:04.480 --> 01:52:07.200]   Third of all the time is is Edwards.
[01:52:07.200 --> 01:52:09.360]   But it's the same with the American football. I mean, I'm sorry.
[01:52:09.360 --> 01:52:11.920]   An American football game goes on for four hours.
[01:52:11.920 --> 01:52:15.040]   That's why your football is so good because you can't stop.
[01:52:15.040 --> 01:52:20.960]   You can't they can't run in red. No, they don't stop playing for crying out loud.
[01:52:20.960 --> 01:52:24.160]   If soccer ever wants to become a success, you're going to have to figure out a way to do that.
[01:52:24.160 --> 01:52:25.920]   Every minute or two, you guys.
[01:52:25.920 --> 01:52:29.280]   Actually, we kind of prefer that way even if America beats us and the women's
[01:52:29.280 --> 01:52:32.240]   football was designed for advertising.
[01:52:32.240 --> 01:52:36.640]   Oh, yeah. But I mean, there's 11 minutes of action in a standard American football game.
[01:52:36.640 --> 01:52:37.040]   Oh, yeah.
[01:52:37.040 --> 01:52:39.040]   11 minutes in a three hour game.
[01:52:39.040 --> 01:52:41.200]   Yeah, I can quite believe it.
[01:52:41.200 --> 01:52:45.280]   But what they've done with with soccer is or football as the rest of the world knows it
[01:52:45.280 --> 01:52:48.480]   because you kick the ball with your foot, not kicky, runny, shouting.
[01:52:48.480 --> 01:52:49.840]   I know it's handled. I know.
[01:52:49.840 --> 01:52:50.400]   I know.
[01:52:50.400 --> 01:52:53.200]   They've got billboards on the side of the pitch.
[01:52:53.200 --> 01:52:57.280]   Now, those can be electronically altered for the market that's watching it.
[01:52:57.280 --> 01:52:57.920]   Well, see, that's good.
[01:52:57.920 --> 01:52:59.120]   That's the way they do it.
[01:52:59.120 --> 01:52:59.440]   OK.
[01:52:59.440 --> 01:53:04.640]   Who here wants to have their brain stitched by a sewing machine?
[01:53:06.480 --> 01:53:14.480]   Carsten's volunteering. Carsten watched the neural link video.
[01:53:14.480 --> 01:53:15.360]   We read the paper.
[01:53:15.360 --> 01:53:16.720]   I thought it was interesting reading.
[01:53:16.720 --> 01:53:18.160]   Elon Musk's company.
[01:53:18.160 --> 01:53:20.160]   Elon, of course, reads a lot of science fiction.
[01:53:20.160 --> 01:53:21.120]   Takes a lot of drugs.
[01:53:21.120 --> 01:53:26.560]   So you combine the two and you're going to start a company that's designed to connect.
[01:53:26.560 --> 01:53:28.640]   Allegedly.
[01:53:28.640 --> 01:53:31.440]   No, no, he's done both in public.
[01:53:31.440 --> 01:53:32.800]   That's not even a lie.
[01:53:32.800 --> 01:53:39.600]   Unbroken. He has created a company called Neuralink.
[01:53:39.600 --> 01:53:43.520]   He's invested 100 million of his own money and they've raised considerably more.
[01:53:43.520 --> 01:53:50.640]   That will put a chip in your brain, a small processor, sits on the surface of the skull,
[01:53:50.640 --> 01:53:51.840]   and then here's the machine.
[01:53:51.840 --> 01:54:01.200]   A robotic, basically, sewing machine that inserts tiny threads smaller than the size of a hair.
[01:54:01.200 --> 01:54:02.640]   Over 3,000 of them.
[01:54:02.640 --> 01:54:05.360]   Into your brain.
[01:54:05.360 --> 01:54:09.360]   I had heard just looking at that.
[01:54:09.360 --> 01:54:13.440]   The problem is, how do they know where to put it?
[01:54:13.440 --> 01:54:14.160]   I think there's a...
[01:54:14.160 --> 01:54:19.280]   Well, we spoke to it because they published a scientific paper on this,
[01:54:19.280 --> 01:54:22.160]   which was the authors were just Elon Musk and Neuralink.
[01:54:22.160 --> 01:54:26.080]   So we called up some of the people who were cited in the research.
[01:54:26.080 --> 01:54:28.400]   And they're saying there's not anything particularly new about this.
[01:54:28.400 --> 01:54:30.320]   It's just the scale that they're going into it.
[01:54:30.320 --> 01:54:30.800]   Right.
[01:54:30.800 --> 01:54:32.560]   And they're talking about putting 3,000
[01:54:32.560 --> 01:54:37.280]   finding mapping out why the where the neurons they want to tap into are,
[01:54:37.280 --> 01:54:41.920]   putting 3,000 filaments into your head and running it all out through a USB-C cable.
[01:54:41.920 --> 01:54:42.960]   USB-C?
[01:54:42.960 --> 01:54:43.280]   I know.
[01:54:43.280 --> 01:54:46.160]   I hope we got something better in that by then.
[01:54:46.160 --> 01:54:46.640]   Yeah.
[01:54:46.640 --> 01:54:48.400]   So you can do this.
[01:54:48.400 --> 01:54:51.040]   What happened when USB-C becomes obsolete?
[01:54:51.040 --> 01:54:54.560]   I'm sorry. I have a firewire interface.
[01:54:54.560 --> 01:54:57.520]   Someone will be happy to sell your connector.
[01:54:57.520 --> 01:55:00.080]   Look at Apple's.
[01:55:00.080 --> 01:55:03.760]   I just want to have Dongle coming out of your head.
[01:55:03.760 --> 01:55:04.160]   Yeah.
[01:55:04.160 --> 01:55:07.120]   But isn't that every science fiction novel?
[01:55:07.120 --> 01:55:08.160]   I mean, remember the Matrix?
[01:55:08.160 --> 01:55:11.200]   It plugged a big cable into the back of your head in the Matrix.
[01:55:11.200 --> 01:55:14.000]   Imagine if I came to plug into three extra Dongles?
[01:55:14.000 --> 01:55:15.280]   That movie would be ridiculous.
[01:55:15.280 --> 01:55:22.160]   Oh, the Dongle life extends even to the brain.
[01:55:22.160 --> 01:55:24.080]   But yeah, I mean, they're saying they can power this
[01:55:24.080 --> 01:55:26.320]   from the electrical activity generated by the brain,
[01:55:26.320 --> 01:55:28.480]   which is still a very new area.
[01:55:28.480 --> 01:55:29.040]   ATP.
[01:55:29.040 --> 01:55:29.840]   It's very nice.
[01:55:29.840 --> 01:55:30.800]   Yeah, and...
[01:55:30.800 --> 01:55:32.800]   But it's just, these things are,
[01:55:32.800 --> 01:55:35.280]   yes, you've got to get them in exactly the right space.
[01:55:35.280 --> 01:55:37.600]   They're very fragile because they're so thin.
[01:55:37.600 --> 01:55:40.160]   And if they get much smaller, the conductive capacity
[01:55:40.160 --> 01:55:44.160]   that wires starts to degrade because of electronic interference.
[01:55:44.160 --> 01:55:46.880]   So aren't they looking for volunteers next year, Karsten?
[01:55:46.880 --> 01:55:49.600]   Do you want to take some time off to do that?
[01:55:49.600 --> 01:55:50.160]   Sure.
[01:55:50.160 --> 01:55:50.960]   Okay.
[01:55:50.960 --> 01:55:51.920]   It's like Hyperloop.
[01:55:51.920 --> 01:55:53.600]   That's a great idea in theory.
[01:55:53.600 --> 01:55:55.520]   But who's going to be the first one to do?
[01:55:56.400 --> 01:56:00.560]   Speaking of robots, the Verge,
[01:56:00.560 --> 01:56:03.680]   Boston Dynamics robots are preparing to leave the lab.
[01:56:03.680 --> 01:56:05.360]   Oh boy, is the world ready?
[01:56:05.360 --> 01:56:07.840]   You've got to, I think you've got a publicity problem here.
[01:56:07.840 --> 01:56:13.200]   Seth, are you going to buy Spot, the Boston Dynamic robot?
[01:56:13.200 --> 01:56:15.440]   I don't think so.
[01:56:15.440 --> 01:56:17.200]   I don't know what I would do with it.
[01:56:17.200 --> 01:56:18.480]   Besides scare everybody.
[01:56:18.480 --> 01:56:20.000]   Terrific.
[01:56:20.000 --> 01:56:20.880]   But that is something.
[01:56:20.880 --> 01:56:21.680]   Yeah.
[01:56:21.680 --> 01:56:25.120]   Spot will be the next influencer sensation.
[01:56:25.120 --> 01:56:26.000]   I'm calling it now.
[01:56:26.000 --> 01:56:28.960]   Here's a video of Spot.
[01:56:28.960 --> 01:56:33.200]   Well, I'll let you watch the video and figure out what Spot's up to.
[01:56:33.200 --> 01:56:40.160]   By the way, this sounds like the clone army coming for us.
[01:56:40.160 --> 01:56:44.160]   But this is actually a bunch of Spot robots.
[01:56:44.160 --> 01:56:48.320]   They're attached to a cable, a wire.
[01:56:48.320 --> 01:56:49.520]   It's a spot centipede.
[01:56:49.520 --> 01:56:51.040]   It's a Spot centipede.
[01:56:51.040 --> 01:56:52.560]   It's like a dog sled.
[01:56:52.560 --> 01:56:54.240]   It is actually, you're very close.
[01:56:54.800 --> 01:57:00.000]   Because they're attached to a giant truck, which they are pulling along.
[01:57:00.000 --> 01:57:06.480]   But hang on, it's surely for the price of one of those robots.
[01:57:06.480 --> 01:57:07.920]   You could buy about 10 trucks.
[01:57:07.920 --> 01:57:10.960]   Well, okay, Spot Mini.
[01:57:10.960 --> 01:57:16.400]   Last 90 minutes of charge, maximum payload of 14 kilograms.
[01:57:16.400 --> 01:57:18.000]   It's about 30 pounds.
[01:57:18.000 --> 01:57:19.040]   That's half its own weight.
[01:57:19.040 --> 01:57:24.320]   It can pull a truck.
[01:57:24.960 --> 01:57:27.760]   And what did they say the price was?
[01:57:27.760 --> 01:57:30.480]   It wasn't too awful, I think.
[01:57:30.480 --> 01:57:34.880]   Let me see if I can find a price on the Verge article.
[01:57:34.880 --> 01:57:38.720]   Originally, the article has got the kicking the Spot dog,
[01:57:38.720 --> 01:57:42.080]   which does look like the start of our new...
[01:57:42.080 --> 01:57:46.640]   Remember, the Boston Dynamics originally was doing this research for the military.
[01:57:46.640 --> 01:57:49.520]   Well, yeah, but then the military tried these out and discovered
[01:57:49.520 --> 01:57:51.680]   they were pretty much useless in the current incarnation.
[01:57:51.680 --> 01:57:55.200]   If I were a soldier and it came running towards me, I'd run the hell the other way.
[01:57:55.200 --> 01:57:57.520]   All you've got to do is run away for about half an hour, though,
[01:57:57.520 --> 01:57:58.800]   in the battery run.
[01:57:58.800 --> 01:58:00.080]   The battery runs out.
[01:58:00.080 --> 01:58:06.000]   I mean, the Marines tried a petrol version of these as a robot mule.
[01:58:06.000 --> 01:58:07.200]   Those were too noisy.
[01:58:07.200 --> 01:58:07.920]   Yeah, exactly.
[01:58:07.920 --> 01:58:12.400]   It was so noisy, you're going to get bombed out and back before you can get close to the enemy.
[01:58:12.400 --> 01:58:13.600]   And even Spot's quite loud.
[01:58:13.600 --> 01:58:16.080]   I mean, I love what they're doing, but it's...
[01:58:16.080 --> 01:58:20.000]   Well, no, it doesn't look like they have a price yet.
[01:58:20.560 --> 01:58:26.320]   But get ready because it is this year that Spot will hit the market mini-Spot.
[01:58:26.320 --> 01:58:28.720]   Seth, thank you for being here.
[01:58:28.720 --> 01:58:32.400]   Seth Wine-Trub Publisher at 9-5, 9-5 Mac, 9-5 Google.
[01:58:32.400 --> 01:58:33.440]   Are there other 9-5s?
[01:58:33.440 --> 01:58:34.240]   Am I going to get them all there?
[01:58:34.240 --> 01:58:36.080]   There's the 9-5 toys.
[01:58:36.080 --> 01:58:36.880]   Oh, yeah, I forgot.
[01:58:36.880 --> 01:58:38.160]   That was the new one you launched.
[01:58:38.160 --> 01:58:38.480]   Yeah.
[01:58:38.480 --> 01:58:44.240]   Oh, are they 9-5 toys for grownups or for kids?
[01:58:44.240 --> 01:58:49.200]   It's not adult toys, but it is toys for people who are
[01:58:49.200 --> 01:58:51.680]   of all ages.
[01:58:51.680 --> 01:58:53.040]   I got a new idea for you.
[01:58:53.040 --> 01:58:59.680]   9-5toys.com, not if I'm Mac, not if I'm Google, and of course,
[01:58:59.680 --> 01:59:02.720]   Electric, which I read religiously because I'm awesome.
[01:59:02.720 --> 01:59:04.480]   I'm all in on the electric vehicles.
[01:59:04.480 --> 01:59:06.400]   It's great to have you.
[01:59:06.400 --> 01:59:08.000]   Thank you so much for being here, Seth.
[01:59:08.000 --> 01:59:09.600]   Stay cool.
[01:59:09.600 --> 01:59:14.080]   As should you, Paris Martinov, Wired,
[01:59:14.080 --> 01:59:16.000]   staff writer, we love having you on Paris.
[01:59:16.000 --> 01:59:16.720]   I appreciate it.
[01:59:16.720 --> 01:59:17.280]   Thanks.
[01:59:17.280 --> 01:59:18.320]   Love being here.
[01:59:18.320 --> 01:59:22.480]   Thanks for coming into work and sweating it out with Mr. Snowden.
[01:59:22.480 --> 01:59:26.240]   I'm going to be free of all toxins by the end of this.
[01:59:26.240 --> 01:59:31.040]   Because as a spot, run me a bath spot.
[01:59:31.040 --> 01:59:31.920]   I'm coming home.
[01:59:31.920 --> 01:59:34.000]   Call DoorDash.
[01:59:34.000 --> 01:59:34.720]   I'm ready.
[01:59:34.720 --> 01:59:38.080]   And Ian Thompson, the news manager,
[01:59:38.080 --> 01:59:41.120]   news editor at theregister.co.uk always a pleasure to have you.
[01:59:41.120 --> 01:59:42.000]   Thank you for being here.
[01:59:42.000 --> 01:59:44.480]   You were in England for a few months for your mom's over.
[01:59:44.480 --> 01:59:45.680]   I just threw it two and a half weeks.
[01:59:45.680 --> 01:59:47.600]   Oh, it seems like it was forever, but he's too.
[01:59:47.600 --> 01:59:49.120]   It was Scottish Islands,
[01:59:49.120 --> 01:59:52.240]   or me, France, Spain, and then back home.
[01:59:52.240 --> 01:59:54.560]   So, yeah, two and a half weeks, six flights on.
[01:59:54.560 --> 01:59:56.400]   These are the whole day when I got back to get over it.
[01:59:56.400 --> 01:59:56.800]   Oh, wait, go.
[01:59:56.800 --> 01:59:57.200]   So, you know.
[01:59:57.200 --> 01:59:57.760]   Holy cow.
[01:59:57.760 --> 01:59:59.520]   Thank you for being here.
[01:59:59.520 --> 02:00:02.080]   We also thank the students from Vareze,
[02:00:02.080 --> 02:00:04.320]   Italia, the code engineering students.
[02:00:04.320 --> 02:00:05.680]   Great to have you once again.
[02:00:05.680 --> 02:00:07.200]   Thanks, Dervel, for bringing them along.
[02:00:07.200 --> 02:00:09.040]   We really appreciate it.
[02:00:09.040 --> 02:00:10.720]   Nice bunch of kids.
[02:00:10.720 --> 02:00:11.600]   Did you understand?
[02:00:11.600 --> 02:00:13.680]   Your English is better than mine, I think.
[02:00:13.680 --> 02:00:15.120]   You understood what this was all about.
[02:00:16.160 --> 02:00:18.640]   Would any of you like a giant robot dog?
[02:00:18.640 --> 02:00:21.520]   No, no.
[02:00:21.520 --> 02:00:23.360]   It's Potzo.
[02:00:23.360 --> 02:00:24.320]   It's crazy.
[02:00:24.320 --> 02:00:25.120]   No.
[02:00:25.120 --> 02:00:27.680]   We do.
[02:00:27.680 --> 02:00:29.600]   I love these guys.
[02:00:29.600 --> 02:00:31.200]   Thank you for being here.
[02:00:31.200 --> 02:00:32.800]   We do it every Sunday afternoon.
[02:00:32.800 --> 02:00:35.920]   Roundabout 230 Pacific 5.30 Eastern time.
[02:00:35.920 --> 02:00:37.360]   That'd be 2,130 UTC.
[02:00:37.360 --> 02:00:38.960]   If you want to watch live or listen live,
[02:00:38.960 --> 02:00:40.880]   you can't at twitter.tv/live.
[02:00:40.880 --> 02:00:43.520]   You can also participate in the chatroom
[02:00:43.520 --> 02:00:44.240]   if you're listening live,
[02:00:44.240 --> 02:00:46.080]   because they're doing the same thing at IRC.
[02:00:46.880 --> 02:00:48.720]   .tuit.tv.
[02:00:48.720 --> 02:00:50.640]   On-demand versions of all of our shows
[02:00:50.640 --> 02:00:52.400]   are available at our website,
[02:00:52.400 --> 02:00:53.840]   twit.tv.
[02:00:53.840 --> 02:00:56.320]   Of course, you can also subscribe
[02:00:56.320 --> 02:00:58.080]   in your favorite podcast application.
[02:00:58.080 --> 02:01:02.560]   Sure Spotify, but also Apple and Google and PocketCasts.
[02:01:02.560 --> 02:01:03.200]   Whatever you like,
[02:01:03.200 --> 02:01:04.480]   just subscribe that way you'll get it.
[02:01:04.480 --> 02:01:06.560]   The minute it's available on Sunday night.
[02:01:06.560 --> 02:01:07.120]   I apologize.
[02:01:07.120 --> 02:01:08.640]   We screwed up last week,
[02:01:08.640 --> 02:01:13.360]   and the feed didn't go out until about 7 or 8 in the morning.
[02:01:13.360 --> 02:01:16.960]   And so a lot of people from the east coast were angry at me.
[02:01:16.960 --> 02:01:18.080]   I apologize.
[02:01:18.080 --> 02:01:19.440]   It was a computer error,
[02:01:19.440 --> 02:01:21.600]   but it will not happen again.
[02:01:21.600 --> 02:01:22.880]   So do subscribe that way.
[02:01:22.880 --> 02:01:24.400]   You'll have it for your Monday morning commute.
[02:01:24.400 --> 02:01:26.000]   Thanks for being here everybody.
[02:01:26.000 --> 02:01:26.720]   We'll see you next time.
[02:01:26.720 --> 02:01:27.280]   Another Twitch.
[02:01:27.280 --> 02:01:28.800]   This is the can.
[02:01:28.800 --> 02:01:30.080]   Bye-bye.
[02:01:30.080 --> 02:01:39.200]   [Music]
[02:01:39.200 --> 02:01:41.700]   (buzzing)

