
[00:00:00.000 --> 00:00:02.360]   It's time for Twit this week in tech.
[00:00:02.360 --> 00:00:03.520]   Well, we got a great panel for you.
[00:00:03.520 --> 00:00:04.800]   Jeff Jarvis is here.
[00:00:04.800 --> 00:00:07.920]   He's visiting us from his home in New Jersey,
[00:00:07.920 --> 00:00:09.640]   also in studio.
[00:00:09.640 --> 00:00:11.400]   Mark Millian of Bloomberg Business Week
[00:00:11.400 --> 00:00:13.680]   and our old friend Nathan Oliveris Giles.
[00:00:13.680 --> 00:00:15.160]   We're gonna talk about Google I/O,
[00:00:15.160 --> 00:00:17.080]   all the things Google announced.
[00:00:17.080 --> 00:00:20.640]   Facebook's new rules for blocking abuse.
[00:00:20.640 --> 00:00:22.200]   It might blow you away.
[00:00:22.200 --> 00:00:25.640]   And what Theresa May has planned for the UK,
[00:00:25.640 --> 00:00:26.480]   that may scare you.
[00:00:26.480 --> 00:00:28.580]   It's all coming up next on Twit.
[00:00:28.580 --> 00:00:32.220]   [MUSIC PLAYING]
[00:00:32.220 --> 00:00:34.300]   Netcast, you love.
[00:00:34.300 --> 00:00:35.660]   From people you trust.
[00:00:35.660 --> 00:00:39.460]   [MUSIC PLAYING]
[00:00:39.460 --> 00:00:41.820]   This is Twit.
[00:00:41.820 --> 00:00:45.180]   Bandwidth for this week in tech is provided by cashfly
[00:00:45.180 --> 00:00:48.220]   at CACHEFLY.com.
[00:00:48.220 --> 00:00:53.700]   [MUSIC PLAYING]
[00:00:53.700 --> 00:00:57.660]   This is Twit, this week in tech, episode 615.
[00:00:57.660 --> 00:01:01.500]   Recorded Sunday, May 21, 2017.
[00:01:01.500 --> 00:01:04.300]   Biz-sized hole.
[00:01:04.300 --> 00:01:05.980]   This week in tech is brought to you
[00:01:05.980 --> 00:01:08.900]   by Rocket Mortgage from Quick and Loans.
[00:01:08.900 --> 00:01:11.180]   When it comes to the big decision of choosing a mortgage
[00:01:11.180 --> 00:01:14.580]   lender, work with one that has your best interest in mind.
[00:01:14.580 --> 00:01:17.420]   Use Rocket Mortgage for a transparent, trustworthy,
[00:01:17.420 --> 00:01:18.740]   home loan process.
[00:01:18.740 --> 00:01:24.540]   It's completely online at quickandlones.com/twit2.
[00:01:24.540 --> 00:01:29.580]   And by Betterment, a smart, easy-to-use, and less expensive
[00:01:29.580 --> 00:01:32.460]   way to invest for your financial future.
[00:01:32.460 --> 00:01:35.300]   Get one month managed free when you make an initial deposit
[00:01:35.300 --> 00:01:41.700]   of $10,000 or more at Betterment.com/twit.
[00:01:41.700 --> 00:01:43.660]   And by WordPress.
[00:01:43.660 --> 00:01:48.020]   WordPress powers 27% of all the websites in the world.
[00:01:48.020 --> 00:01:51.980]   Get 15% off your new website at wordpress.com/twit.
[00:01:51.980 --> 00:01:55.860]   And that's wordpress.com/twit.
[00:01:55.860 --> 00:01:58.180]   And by Carbonite.
[00:01:58.180 --> 00:01:59.940]   Keep your business safe this year.
[00:01:59.940 --> 00:02:01.580]   Protect your business from ransomware
[00:02:01.580 --> 00:02:05.700]   and hacker attacks with automatic cloud backup from Carbonite.
[00:02:05.700 --> 00:02:08.060]   Try it free at Carbonite.com.
[00:02:08.060 --> 00:02:10.780]   Use the offer code Twit to get two free bonus months
[00:02:10.780 --> 00:02:11.740]   if you decide to buy.
[00:02:11.740 --> 00:02:18.620]   It's time for Twit this week in tech, the show
[00:02:18.620 --> 00:02:21.420]   we cover the week's tech news.
[00:02:21.420 --> 00:02:25.260]   And as Jeff Jarvis said, there was a journal heavy panel today.
[00:02:25.260 --> 00:02:27.340]   Jeff Jarvis joins his class.
[00:02:27.340 --> 00:02:29.340]   I'm the heaviest journal in the oldest journal.
[00:02:29.340 --> 00:02:30.860]   And the old journal.
[00:02:30.860 --> 00:02:32.620]   Yeah, old.
[00:02:32.620 --> 00:02:34.380]   Buzzmachine.com is his blog.
[00:02:34.380 --> 00:02:37.620]   Of course, he's a professor of journalism, so he counts.
[00:02:37.620 --> 00:02:39.700]   That counts at the City University of New York.
[00:02:39.700 --> 00:02:43.380]   He's quite esteemed and respected professor of journalism.
[00:02:43.380 --> 00:02:44.540]   He's the author of many great books.
[00:02:44.540 --> 00:02:48.220]   And my booth mate.
[00:02:48.220 --> 00:02:49.820]   Yeah.
[00:02:49.820 --> 00:02:51.260]   We were in the VIP booth.
[00:02:51.260 --> 00:02:52.700]   In the VIP booth.
[00:02:52.700 --> 00:02:56.340]   We were just down the road a piece from some other VIPs
[00:02:56.340 --> 00:02:57.780]   I didn't recognize.
[00:02:57.780 --> 00:02:59.100]   So that was exciting.
[00:02:59.100 --> 00:03:00.580]   Hey, Jeff, you made it there.
[00:03:00.580 --> 00:03:00.940]   Are you?
[00:03:00.940 --> 00:03:04.060]   I just put up my favorite tweet I've ever done in my life
[00:03:04.060 --> 00:03:05.580]   of tweeting.
[00:03:05.580 --> 00:03:07.780]   Did you write it or use somebody else's?
[00:03:07.780 --> 00:03:08.780]   It's two pictures.
[00:03:08.780 --> 00:03:09.700]   You can go to it now.
[00:03:09.700 --> 00:03:10.700]   All right.
[00:03:10.700 --> 00:03:11.260]   Jeff Jarvis.
[00:03:11.260 --> 00:03:11.860]   One of the pictures.
[00:03:11.860 --> 00:03:14.900]   One of the last people still using Twitter.
[00:03:14.900 --> 00:03:17.300]   Twitter.
[00:03:17.300 --> 00:03:18.300]   Here it is.
[00:03:18.300 --> 00:03:19.300]   Pictures.
[00:03:19.300 --> 00:03:20.300]   Just call me.
[00:03:20.300 --> 00:03:21.300]   Pictures.
[00:03:21.300 --> 00:03:22.820]   There's the flying monkeys with the Wizard of Oz.
[00:03:22.820 --> 00:03:24.340]   You've got the Wicked Witch of the West.
[00:03:24.340 --> 00:03:25.340]   Dorothy and her.
[00:03:25.340 --> 00:03:26.700]   Click on the other photo.
[00:03:26.700 --> 00:03:27.700]   Oh, wow.
[00:03:27.700 --> 00:03:29.180]   [LAUGHTER]
[00:03:29.180 --> 00:03:32.220]   And this is President Trump in the Saudi Arabia.
[00:03:32.220 --> 00:03:34.220]   Is that the king that he's with there?
[00:03:34.220 --> 00:03:35.060]   I think so.
[00:03:35.060 --> 00:03:37.020]   And he's touching his orb.
[00:03:37.020 --> 00:03:38.020]   The orb?
[00:03:38.020 --> 00:03:41.580]   They have many rituals in Saudi Arabia that are odd.
[00:03:41.580 --> 00:03:43.500]   I don't think this is a historic ritual.
[00:03:43.500 --> 00:03:44.900]   I think this is something new.
[00:03:44.900 --> 00:03:46.500]   OK.
[00:03:46.500 --> 00:03:48.300]   Is he controlling something?
[00:03:48.300 --> 00:03:50.420]   I don't know.
[00:03:50.420 --> 00:03:52.300]   Seeing the eye of Sauron.
[00:03:52.300 --> 00:03:53.300]   Yes.
[00:03:53.300 --> 00:03:54.780]   Yes, exactly.
[00:03:54.780 --> 00:03:55.780]   It's a Palantir.
[00:03:55.780 --> 00:03:59.380]   There's going to be such great material this week for all the late night shows.
[00:03:59.380 --> 00:04:00.380]   Wow.
[00:04:00.380 --> 00:04:03.460]   It's an interesting image.
[00:04:03.460 --> 00:04:04.700]   Thank you, Jeff.
[00:04:04.700 --> 00:04:05.700]   [LAUGHTER]
[00:04:05.700 --> 00:04:10.660]   Also, with his Mark Millian from Blenberg Week, I have to say that, Bloomberg.com/tech.
[00:04:10.660 --> 00:04:11.660]   Yes.
[00:04:11.660 --> 00:04:12.660]   Great to see you again.
[00:04:12.660 --> 00:04:13.660]   It's great to be here.
[00:04:13.660 --> 00:04:15.140]   I love the new studio.
[00:04:15.140 --> 00:04:16.140]   I didn't realize I'd been so long.
[00:04:16.140 --> 00:04:18.300]   I knew at this point that you haven't seen this yet.
[00:04:18.300 --> 00:04:19.300]   Yeah, we've been a few months.
[00:04:19.300 --> 00:04:20.300]   Yeah, it's beautiful.
[00:04:20.300 --> 00:04:21.300]   Thank you.
[00:04:21.300 --> 00:04:22.300]   Thank you.
[00:04:22.300 --> 00:04:25.300]   And of course, Nathan Olivetter, this Giles.
[00:04:25.300 --> 00:04:26.300]   Yep.
[00:04:26.300 --> 00:04:27.300]   Happy to be here.
[00:04:27.300 --> 00:04:28.300]   Happy to be here.
[00:04:28.300 --> 00:04:30.260]   Our one of our most recent hires.
[00:04:30.260 --> 00:04:31.260]   Always welcome.
[00:04:31.260 --> 00:04:32.260]   Yeah.
[00:04:32.260 --> 00:04:37.100]   So you guys are all kind of like serious journalists and all that kind of thing.
[00:04:37.100 --> 00:04:38.100]   That's the rumor.
[00:04:38.100 --> 00:04:39.540]   That's what I hear.
[00:04:39.540 --> 00:04:40.540]   So what do you want to start?
[00:04:40.540 --> 00:04:41.540]   You want to start with Google?
[00:04:41.540 --> 00:04:42.540]   Google I/O?
[00:04:42.540 --> 00:04:45.100]   Well, Google I/O was kind of the-- it should have been the big deal.
[00:04:45.100 --> 00:04:46.100]   The biggest news of the week.
[00:04:46.100 --> 00:04:47.340]   And it wasn't.
[00:04:47.340 --> 00:04:51.260]   And it really kind of-- I think let a lot of people down.
[00:04:51.260 --> 00:04:53.100]   There's actually a lot of significant stuff.
[00:04:53.100 --> 00:04:57.260]   It just-- they didn't really explain why the stuff mattered that good.
[00:04:57.260 --> 00:04:59.460]   Well, and much of the stuff wasn't available yet.
[00:04:59.460 --> 00:05:02.020]   Well, that's part of Google's-- always Google's problem.
[00:05:02.020 --> 00:05:03.020]   Yeah.
[00:05:03.020 --> 00:05:04.020]   Yeah.
[00:05:04.020 --> 00:05:07.460]   I think because Moto was piece by Michael Nunez was the best that said that you just
[00:05:07.460 --> 00:05:10.020]   can't see that it's neater stuff, but you can't see it.
[00:05:10.020 --> 00:05:11.180]   You can't touch it.
[00:05:11.180 --> 00:05:12.180]   Wow.
[00:05:12.180 --> 00:05:15.340]   And in Google's defense, that's a good point.
[00:05:15.340 --> 00:05:22.420]   I mean, if you're making big strides in artificial intelligence, well, that just kind of slips
[00:05:22.420 --> 00:05:23.420]   away.
[00:05:23.420 --> 00:05:26.660]   If that's one of the things Sundar Pichai said, he says, we're moving from a mobile first
[00:05:26.660 --> 00:05:29.060]   world-- by the way, I'm just catching up with mobile first.
[00:05:29.060 --> 00:05:30.060]   Yeah.
[00:05:30.060 --> 00:05:31.580]   A lot of companies are.
[00:05:31.580 --> 00:05:37.780]   We're moving from a mobile first world to a AI first world.
[00:05:37.780 --> 00:05:40.260]   And that's kind of interesting.
[00:05:40.260 --> 00:05:42.860]   And well, that was kind of the sell last year for Google I/O, I think.
[00:05:42.860 --> 00:05:43.860]   I thought they said the same thing.
[00:05:43.860 --> 00:05:44.860]   Yeah, you're right.
[00:05:44.860 --> 00:05:49.220]   You know, one of the things that sticks out to me is if you look at the complaints before
[00:05:49.220 --> 00:05:55.460]   Sundar took over as CEO about a year ago now, a lot of it was that you go to Google I/O
[00:05:55.460 --> 00:06:00.260]   and you see all these really fun, gee whiz kind of ideas that aren't necessarily fully
[00:06:00.260 --> 00:06:02.420]   realized that are costing a lot of money.
[00:06:02.420 --> 00:06:06.260]   Sundar came in as CEO and kind of focused the company, got rid of a lot of that sort of
[00:06:06.260 --> 00:06:07.260]   thing.
[00:06:07.260 --> 00:06:08.980]   And this is really what the company is focused on.
[00:06:08.980 --> 00:06:14.260]   And so this is iterative stuff versus last year in this AI first idea.
[00:06:14.260 --> 00:06:15.660]   And it's good progress.
[00:06:15.660 --> 00:06:21.540]   Like the cloud TPU set up these basically these computer chips that will help their machine
[00:06:21.540 --> 00:06:22.540]   learning system--
[00:06:22.540 --> 00:06:24.540]   Tensor processing units.
[00:06:24.540 --> 00:06:26.340]   That's probably the biggest news of the event.
[00:06:26.340 --> 00:06:27.340]   This is exactly--
[00:06:27.340 --> 00:06:28.340]   Yeah.
[00:06:28.340 --> 00:06:29.340]   --is a huge business implications.
[00:06:29.340 --> 00:06:30.340]   Fascinating.
[00:06:30.340 --> 00:06:33.820]   So these are inexpensive-- almost they look like almost like Raspberry Pi.
[00:06:33.820 --> 00:06:36.500]   They got four processors on them.
[00:06:36.500 --> 00:06:38.140]   Big heavy duty GPU stuff.
[00:06:38.140 --> 00:06:41.780]   This is no Raspberry Pi 180 teraflops.
[00:06:41.780 --> 00:06:45.020]   And so this could give them an advantage in their cloud services versus Amazon.
[00:06:45.020 --> 00:06:47.060]   This could give them an advantage in building out their AI.
[00:06:47.060 --> 00:06:49.020]   They're also making available to third parties.
[00:06:49.020 --> 00:06:51.380]   So other than that, one of the Google Compute Cloud--
[00:06:51.380 --> 00:06:53.300]   --and the one of the AI software.
[00:06:53.300 --> 00:06:55.900]   So they've already open sourced TensorFlow, the software.
[00:06:55.900 --> 00:07:01.060]   And these are hardware devices designed to run TensorFlow at speed.
[00:07:01.060 --> 00:07:06.060]   And if you're impressed with 180 teraflops, that's really not the point because the idea
[00:07:06.060 --> 00:07:11.220]   is they massively parallelize them.
[00:07:11.220 --> 00:07:12.220]   Yeah.
[00:07:12.220 --> 00:07:21.420]   And these racks are multi-pedaflops per-- this is 11.5 petaflops of machine learning in this
[00:07:21.420 --> 00:07:22.420]   rack.
[00:07:22.420 --> 00:07:28.700]   And so what I think the missing piece really was Sundar or somebody else from Google saying,
[00:07:28.700 --> 00:07:34.820]   hey, this is what-- here are the cool things we'll be able to build with this technology.
[00:07:34.820 --> 00:07:38.220]   Here's the stuff that you developers should come and help us build together.
[00:07:38.220 --> 00:07:42.340]   Regular people watching this, consumers and enthusiasts, here's what the future is going
[00:07:42.340 --> 00:07:43.340]   to look like.
[00:07:43.340 --> 00:07:45.220]   And here's the vision, right?
[00:07:45.220 --> 00:07:51.380]   So Sundar's Google doesn't do as good of a job at illustrating that vision in these
[00:07:51.380 --> 00:07:54.780]   keynotes as--
[00:07:54.780 --> 00:07:55.780]   Let's face it.
[00:07:55.780 --> 00:07:56.780]   --the previous generation.
[00:07:56.780 --> 00:08:02.020]   --tech journalists would rather have Sergey Brin parachuting in with Google goggles on, even
[00:08:02.020 --> 00:08:03.020]   though--
[00:08:03.020 --> 00:08:04.020]   You've got on a better show.
[00:08:04.020 --> 00:08:05.020]   --but it's better showable.
[00:08:05.020 --> 00:08:06.020]   --it's better showable.
[00:08:06.020 --> 00:08:07.020]   --meaningless.
[00:08:07.020 --> 00:08:08.020]   Exactly.
[00:08:08.020 --> 00:08:09.020]   Well, not even equally.
[00:08:09.020 --> 00:08:10.020]   Much more so.
[00:08:10.020 --> 00:08:11.020]   Much more meaningless.
[00:08:11.020 --> 00:08:12.020]   Yeah, genuinely meaningless.
[00:08:12.020 --> 00:08:13.020]   Yeah.
[00:08:13.020 --> 00:08:15.820]   So it's less exciting, but this is probably one of the most significant things Google's
[00:08:15.820 --> 00:08:16.820]   announced.
[00:08:16.820 --> 00:08:17.820]   And I think that's really right.
[00:08:17.820 --> 00:08:18.820]   It's enabling.
[00:08:18.820 --> 00:08:19.820]   Right?
[00:08:19.820 --> 00:08:23.340]   It-- you know, we've heard the name of that guy.
[00:08:23.340 --> 00:08:26.900]   We talked about on the show for like an hour once was he a swisser, an Austrian, an AI
[00:08:26.900 --> 00:08:27.900]   genius.
[00:08:27.900 --> 00:08:28.900]   Yeah.
[00:08:28.900 --> 00:08:29.900]   I can't remember his name.
[00:08:29.900 --> 00:08:30.900]   I remember his name either.
[00:08:30.900 --> 00:08:31.900]   Yeah.
[00:08:31.900 --> 00:08:32.900]   You're against somebody.
[00:08:32.900 --> 00:08:36.380]   Now, the theory is so far ahead of the practice because it was not the way you just said Nate
[00:08:36.380 --> 00:08:39.620]   is that the power to do what they want to do isn't there.
[00:08:39.620 --> 00:08:41.860]   So their theory is way ahead.
[00:08:41.860 --> 00:08:42.860]   And this--
[00:08:42.860 --> 00:08:43.860]   Oh, you're against Schmittuber.
[00:08:43.860 --> 00:08:44.860]   You're talking about you're against Schmittuber.
[00:08:44.860 --> 00:08:45.860]   That's Middleover.
[00:08:45.860 --> 00:08:46.860]   Yes.
[00:08:46.860 --> 00:08:47.860]   Oh, yeah.
[00:08:47.860 --> 00:08:49.860]   Not the best website I've ever seen.
[00:08:49.860 --> 00:08:54.020]   See, I can't tell if this is like-- he hasn't updated his website since like 1996 or
[00:08:54.020 --> 00:08:55.020]   if it's like an ironic--
[00:08:55.020 --> 00:08:56.020]   --it's kind of in by the chains.
[00:08:56.020 --> 00:08:57.500]   --like I want it to look this way, like in kind of like a hipster.
[00:08:57.500 --> 00:08:59.340]   Oh, click on what's new.
[00:08:59.340 --> 00:09:00.340]   Yeah.
[00:09:00.340 --> 00:09:01.340]   What's new?
[00:09:01.340 --> 00:09:02.340]   2017.
[00:09:02.340 --> 00:09:05.860]   I've also probably zoomed this in.
[00:09:05.860 --> 00:09:07.500]   That's what it's supposed to look like.
[00:09:07.500 --> 00:09:08.500]   That's much better.
[00:09:08.500 --> 00:09:12.340]   I'm not going to zoom back in because I can't read it that size.
[00:09:12.340 --> 00:09:16.860]   But yeah, I mean, you know, like here's this opportunity.
[00:09:16.860 --> 00:09:18.060]   Sell us on the future.
[00:09:18.060 --> 00:09:23.580]   Like tell us where this is all going and why building this together with you is so much
[00:09:23.580 --> 00:09:28.980]   better than putting your energies as a developer or your dollars as a consumer towards Amazon
[00:09:28.980 --> 00:09:29.980]   and first base.
[00:09:29.980 --> 00:09:30.980]   Maybe not.
[00:09:30.980 --> 00:09:33.060]   Just to shut up.
[00:09:33.060 --> 00:09:35.740]   But see, this is what Google doesn't do.
[00:09:35.740 --> 00:09:36.740]   Google doesn't shut up.
[00:09:36.740 --> 00:09:37.740]   Apple shuts up.
[00:09:37.740 --> 00:09:38.740]   Exactly.
[00:09:38.740 --> 00:09:40.860]   Google builds their products in front of you.
[00:09:40.860 --> 00:09:45.300]   Sometimes they fail, but they always are basically-- you get to see how the sausage is
[00:09:45.300 --> 00:09:46.300]   made.
[00:09:46.300 --> 00:09:50.340]   Apple, they keep it secret and then when they have a fully realized product, usually, unless
[00:09:50.340 --> 00:09:55.220]   it's like a beta-like series or Apple Maps, then they'll bring it out to you.
[00:09:55.220 --> 00:09:58.580]   This is actually something that Mark and I have been talking about recently, just as
[00:09:58.580 --> 00:10:00.620]   friends, but also on our Buzzkill podcast.
[00:10:00.620 --> 00:10:05.020]   But it's like, this is a difference between those companies.
[00:10:05.020 --> 00:10:06.020]   Facebook's my plug buzzer.
[00:10:06.020 --> 00:10:10.980]   Yeah, Facebook also, you know, with their F8 developers' conference, they're further
[00:10:10.980 --> 00:10:14.340]   behind on the honest tech, but they showed some like, you know, camera apps and they
[00:10:14.340 --> 00:10:15.340]   got people excited.
[00:10:15.340 --> 00:10:18.780]   I kind of respect a company like Google where they're not going to do the flash.
[00:10:18.780 --> 00:10:22.220]   They're just going to do the-- and remember, it's a developers' conference and they're
[00:10:22.220 --> 00:10:23.220]   not going to try to impress.
[00:10:23.220 --> 00:10:24.220]   Yes.
[00:10:24.220 --> 00:10:27.820]   Well, it's a developers' conference, but these keynotes have been so filled with consumer
[00:10:27.820 --> 00:10:31.300]   news that the expectation these days is that you're going to have something flashy to
[00:10:31.300 --> 00:10:32.300]   show up.
[00:10:32.300 --> 00:10:34.380]   I was a little disappointed we didn't see anything about Chromebook.
[00:10:34.380 --> 00:10:36.220]   We didn't see anything about a lot of consumer products.
[00:10:36.220 --> 00:10:37.540]   They didn't mention the Pixel phones.
[00:10:37.540 --> 00:10:41.740]   They didn't mention-- they did mention Google Home and the Assistant and the Assistant now
[00:10:41.740 --> 00:10:47.340]   is on the iPhone, which is really a stealth introduction to Assistant to get iPhone users
[00:10:47.340 --> 00:10:51.180]   to understand, you know, that Siri you've got, that's crap.
[00:10:51.180 --> 00:10:53.420]   This is what a real Assistant can do.
[00:10:53.420 --> 00:10:57.540]   I think hoping to woo some people over to Android, but at least to get them to buy the
[00:10:57.540 --> 00:10:58.540]   Google Home.
[00:10:58.540 --> 00:11:02.700]   The other thing that-- maybe it's just me, I keep mentioning this, everybody's kind of
[00:11:02.700 --> 00:11:04.260]   ho-hum.
[00:11:04.260 --> 00:11:09.300]   I think the fact that you can make free calls to the-- any phone in the US and Canada on
[00:11:09.300 --> 00:11:11.860]   your Google Home is kind of impressive.
[00:11:11.860 --> 00:11:14.260]   I think I've got to mazes people our age.
[00:11:14.260 --> 00:11:15.260]   Maybe it's because we're old.
[00:11:15.260 --> 00:11:16.260]   Yeah.
[00:11:16.260 --> 00:11:20.060]   Yeah, as we're saying, we're there, you know, we're old enough fellow panelists.
[00:11:20.060 --> 00:11:22.540]   We're old enough that our parents would yell at us to get off the phone.
[00:11:22.540 --> 00:11:23.540]   Yeah.
[00:11:23.540 --> 00:11:25.540]   Because as long distance it's costing a lot of money.
[00:11:25.540 --> 00:11:26.540]   Right.
[00:11:26.540 --> 00:11:27.540]   And for me, that's not impressive at all.
[00:11:27.540 --> 00:11:28.540]   Because your cell phone does that.
[00:11:28.540 --> 00:11:29.540]   Yeah.
[00:11:29.540 --> 00:11:30.540]   You have unlimited minutes now.
[00:11:30.540 --> 00:11:31.540]   Exactly.
[00:11:31.540 --> 00:11:32.540]   It's like, it goes--
[00:11:32.540 --> 00:11:33.540]   Because they don't want to talk on the phone.
[00:11:33.540 --> 00:11:35.540]   Nobody wants to talk on the phone.
[00:11:35.540 --> 00:11:40.140]   If I have to go to my phone to set up my speaker, my speaker should know that my phone exists
[00:11:40.140 --> 00:11:43.100]   and it should be able to basically be a speaker phone.
[00:11:43.100 --> 00:11:44.100]   Like, that doesn't seem crazy.
[00:11:44.100 --> 00:11:45.100]   I just--
[00:11:45.100 --> 00:11:46.100]   I just--
[00:11:46.100 --> 00:11:47.100]   You millennials don't--
[00:11:47.100 --> 00:11:48.100]   You can call all the other Alexa's.
[00:11:48.100 --> 00:11:49.100]   You can only call other echoes.
[00:11:49.100 --> 00:11:50.100]   Yeah.
[00:11:50.100 --> 00:11:55.060]   This-- so in a couple of ways they scooped, I thought they sort of, you know, scooped Amazon's
[00:11:55.060 --> 00:11:58.620]   big announcement the last few weeks because that was one announcement is free echo to
[00:11:58.620 --> 00:12:00.260]   echo calling, big deal.
[00:12:00.260 --> 00:12:01.260]   Yeah.
[00:12:01.260 --> 00:12:04.780]   And they also have, by the way, some privacy issues because there's no way the block calls.
[00:12:04.780 --> 00:12:08.780]   So the fact that anybody who figures out how to get a hold of you on your echo can bug
[00:12:08.780 --> 00:12:11.180]   the hell out of you in your house is a problem.
[00:12:11.180 --> 00:12:12.180]   Yeah, no things.
[00:12:12.180 --> 00:12:13.180]   No things.
[00:12:13.180 --> 00:12:16.500]   But then remember Amazon has announced but not yet shipped this home.
[00:12:16.500 --> 00:12:17.500]   What do they call it?
[00:12:17.500 --> 00:12:18.500]   The show?
[00:12:18.500 --> 00:12:19.500]   Yeah, the show.
[00:12:19.500 --> 00:12:20.660]   The show has a screen on it.
[00:12:20.660 --> 00:12:23.460]   It's really just a tablet with an echo built into it.
[00:12:23.460 --> 00:12:27.820]   But Google says, well, we didn't do that because you got screens all over the house.
[00:12:27.820 --> 00:12:32.100]   So how about if you just can cast your calendar or your--
[00:12:32.100 --> 00:12:33.100]   To your TV.
[00:12:33.100 --> 00:12:37.220]   To your TV or any other, you know, cast-ready screen in your house.
[00:12:37.220 --> 00:12:40.340]   And of course, most people have cast-ready screens all over the place now.
[00:12:40.340 --> 00:12:41.340]   Yeah.
[00:12:41.340 --> 00:12:42.940]   So I thought that was impressive.
[00:12:42.940 --> 00:12:47.020]   It does make me wonder, though, if-- and this is something that Meghan Moroni brought up,
[00:12:47.020 --> 00:12:52.940]   actually, and we were talking about it earlier-- is whether or not this puts pressure on
[00:12:52.940 --> 00:12:55.820]   Amazon to come out with a phone again.
[00:12:55.820 --> 00:12:58.860]   Because even-- so Google has its apps on the iPhone.
[00:12:58.860 --> 00:13:01.180]   And they, of course, have Android.
[00:13:01.180 --> 00:13:05.180]   But basically, if you're using an iOS device or an Android device, they have a presence
[00:13:05.180 --> 00:13:06.940]   on your phone.
[00:13:06.940 --> 00:13:11.420]   And the reason why this might be a little bit of a jump ahead for them in this smart
[00:13:11.420 --> 00:13:15.620]   speaker phone calling thing is because they have access to your phone in ways that Amazon
[00:13:15.620 --> 00:13:16.620]   doesn't yet.
[00:13:16.620 --> 00:13:20.020]   Well, and that's the other thing Google has to kind of think about is the creepy line,
[00:13:20.020 --> 00:13:21.020]   right?
[00:13:21.020 --> 00:13:25.980]   Every time they announce something, there are going to be a group of people, privacy advocates,
[00:13:25.980 --> 00:13:28.180]   and say, oh, hell no.
[00:13:28.180 --> 00:13:29.180]   Yeah.
[00:13:29.180 --> 00:13:30.180]   I'm not putting that in a lot.
[00:13:30.180 --> 00:13:31.180]   Especially Europe.
[00:13:31.180 --> 00:13:32.180]   Yeah.
[00:13:32.180 --> 00:13:33.180]   Right.
[00:13:33.180 --> 00:13:34.860]   The Google lens is kind of funny.
[00:13:34.860 --> 00:13:41.140]   They announced-- this is an AI capability that reminds you a lot of Google goggles, which
[00:13:41.140 --> 00:13:42.140]   and Amazon's Firephone.
[00:13:42.140 --> 00:13:43.780]   It's seven years ago.
[00:13:43.780 --> 00:13:45.420]   Right.
[00:13:45.420 --> 00:13:52.260]   But I asked somebody at Google who was involved in integrating this into search and photos.
[00:13:52.260 --> 00:13:54.140]   She said, well, but this is AI.
[00:13:54.140 --> 00:13:55.860]   You know, goggles was kind of pre-populated.
[00:13:55.860 --> 00:13:57.500]   We had to teach it.
[00:13:57.500 --> 00:13:59.060]   This is learning all the time.
[00:13:59.060 --> 00:14:00.220]   So for instance, I love this.
[00:14:00.220 --> 00:14:02.420]   They took a picture of a flower.
[00:14:02.420 --> 00:14:03.420]   This happens to me all the time.
[00:14:03.420 --> 00:14:05.020]   Why does that flower?
[00:14:05.020 --> 00:14:08.020]   And it will actually say, oh, that's a milk and wine milli.
[00:14:08.020 --> 00:14:10.740]   And it will even give you nearby florists.
[00:14:10.740 --> 00:14:12.020]   You can order it and buy it.
[00:14:12.020 --> 00:14:13.660]   That is cool.
[00:14:13.660 --> 00:14:15.300]   That's a business proposition for Google.
[00:14:15.300 --> 00:14:16.460]   I think that's cool.
[00:14:16.460 --> 00:14:21.460]   If you have barcodes in the back of your router, it will automatically configure, you know,
[00:14:21.460 --> 00:14:24.220]   connect to it by just taking a picture of it.
[00:14:24.220 --> 00:14:25.260]   It'll get me to read it.
[00:14:25.260 --> 00:14:29.460]   And my favorite one was they showed, you know, you using your phone.
[00:14:29.460 --> 00:14:31.300]   And I'm not sure what app this is.
[00:14:31.300 --> 00:14:33.980]   Maybe it's just the camera app because that has lens built into it.
[00:14:33.980 --> 00:14:37.820]   You turn on lens and then you point at different storefronts and they'll tell you what the
[00:14:37.820 --> 00:14:41.140]   star rating is, you know, how much it costs.
[00:14:41.140 --> 00:14:42.460]   You can make a reservation.
[00:14:42.460 --> 00:14:43.460]   How many--
[00:14:43.460 --> 00:14:47.620]   What they are beyond what Facebook can do because Google has all that data.
[00:14:47.620 --> 00:14:52.300]   And, you know, I know Apple, at some point Apple is going to announce AR.
[00:14:52.300 --> 00:14:55.740]   This seems to me exactly what Apple might announce in the fall.
[00:14:55.740 --> 00:14:57.820]   And I think they've scooped them a little bit.
[00:14:57.820 --> 00:15:03.380]   Here's an example of-- it took a picture of a marquee at one of my favorite clubs in San
[00:15:03.380 --> 00:15:08.180]   Francisco, Bimbos 365 club of the Stone Foxes are playing May 17th.
[00:15:08.180 --> 00:15:12.020]   So the lens is smart enough to know that that's a Stone Foxes.
[00:15:12.020 --> 00:15:17.580]   It offers you Stone Foxes music, offers to add that to your calendar, which is pretty
[00:15:17.580 --> 00:15:22.020]   impressive, and shows you where you can buy tickets to that, all from taking a picture
[00:15:22.020 --> 00:15:23.460]   of the marquee.
[00:15:23.460 --> 00:15:27.740]   Those things seem like the kinds of things that would be useful over and above what goggles
[00:15:27.740 --> 00:15:28.740]   could--
[00:15:28.740 --> 00:15:32.300]   It's an entirely new user interface with a computer.
[00:15:32.300 --> 00:15:35.900]   They're typing, they have conversation, and now they have sight.
[00:15:35.900 --> 00:15:40.980]   And yet you do know that most people will never-- never even know that exists in the
[00:15:40.980 --> 00:15:41.980]   fall.
[00:15:41.980 --> 00:15:44.140]   Yeah, and does it even work outside of San Francisco, New York?
[00:15:44.140 --> 00:15:45.140]   I wonder.
[00:15:45.140 --> 00:15:47.180]   Well, that's a good question.
[00:15:47.180 --> 00:15:50.540]   I mean, that's the part of the problem with these keynotes is you don't know until you
[00:15:50.540 --> 00:15:51.540]   try it.
[00:15:51.540 --> 00:15:54.700]   And none of this is available yet.
[00:15:54.700 --> 00:16:01.860]   Not many other companies have, to just point, this data repository that Google has.
[00:16:01.860 --> 00:16:09.460]   I mean, basically, if their systems are sophisticated enough and can learn quick enough, and maybe
[00:16:09.460 --> 00:16:13.340]   someday even teach themselves, all the sort of images that people upload when they're
[00:16:13.340 --> 00:16:17.180]   at a place, and they're tagging them, and they're uploading them to Google Maps, or
[00:16:17.180 --> 00:16:21.940]   they're reviewing them, or they're using them on Google Image Search, all of that should
[00:16:21.940 --> 00:16:29.060]   be feeding data to say, hey, yeah, that small diner in Tucson, it might not be as popular
[00:16:29.060 --> 00:16:31.780]   as the place in San Francisco.
[00:16:31.780 --> 00:16:36.380]   But a couple dozen people have been there, and here are some photos, and let's put this
[00:16:36.380 --> 00:16:40.660]   together and help this camera recognize it if ever someone is there, right?
[00:16:40.660 --> 00:16:48.300]   So test towns and on recode argues that this is Google's future, that this is the Google
[00:16:48.300 --> 00:16:55.740]   Lands is an example of device independent computing, artificial intelligence.
[00:16:55.740 --> 00:16:59.420]   And she said, and I think she's probably, you know, I think there's something to be
[00:16:59.420 --> 00:17:06.140]   said for this, even though this is nothing new, it tells us something about where Google's
[00:17:06.140 --> 00:17:13.580]   growing, and that is part of a less device centric and more kind of user centric focus.
[00:17:13.580 --> 00:17:18.140]   I like that idea, and I think that that's, I mean, you still need a device, you still
[00:17:18.140 --> 00:17:19.140]   need a camera.
[00:17:19.140 --> 00:17:22.340]   Yeah, well, I think two or three things that Google's never cared about what the device
[00:17:22.340 --> 00:17:23.340]   you use.
[00:17:23.340 --> 00:17:25.300]   This is a new search, right?
[00:17:25.300 --> 00:17:30.420]   Isn't this a new, so instead of typing in a search, you just, this is a new way of search,
[00:17:30.420 --> 00:17:34.420]   and that's Google's core business, is search.
[00:17:34.420 --> 00:17:39.700]   And it pulls out all of Google's data, and it gathers more signals about the world, it
[00:17:39.700 --> 00:17:42.020]   understands more about the world.
[00:17:42.020 --> 00:17:43.020]   It's utilitarian.
[00:17:43.020 --> 00:17:48.900]   I mean, it's that or sharks swimming around your cereal bowl, which is a more useful for
[00:17:48.900 --> 00:17:49.900]   the...
[00:17:49.900 --> 00:17:51.340]   Yeah, that's a magically demo.
[00:17:51.340 --> 00:17:52.340]   Yeah.
[00:17:52.340 --> 00:17:53.340]   I agree with you.
[00:17:53.340 --> 00:17:57.300]   I think that maybe this all come into our lives in a more subtle fashion.
[00:17:57.300 --> 00:18:01.380]   And yes, it's not exciting when Google does a keynote about all these incremental improvements,
[00:18:01.380 --> 00:18:05.220]   but if, you know, by the way, none of these are available, we don't even know what they're
[00:18:05.220 --> 00:18:08.700]   going to be like, whether they'll live up to their promise, et cetera, et cetera, et cetera.
[00:18:08.700 --> 00:18:12.220]   Well, the other thing they showed was going into the Home Depot and getting right to that
[00:18:12.220 --> 00:18:13.220]   widget you need.
[00:18:13.220 --> 00:18:14.220]   Finally, because it's...
[00:18:14.220 --> 00:18:15.220]   It's a where...
[00:18:15.220 --> 00:18:16.220]   It's a tango.
[00:18:16.220 --> 00:18:20.420]   If you add tango into it, so you have this presence about your world that Google can add
[00:18:20.420 --> 00:18:22.540]   value to your world.
[00:18:22.540 --> 00:18:24.100]   That's a big deal.
[00:18:24.100 --> 00:18:25.100]   But the...
[00:18:25.100 --> 00:18:26.100]   But the...
[00:18:26.100 --> 00:18:27.100]   But the...
[00:18:27.100 --> 00:18:28.100]   But the...
[00:18:28.100 --> 00:18:29.100]   I said that about way to.
[00:18:29.100 --> 00:18:30.100]   Yeah, right.
[00:18:30.100 --> 00:18:34.100]   And it's very interesting or consumer friendly technology.
[00:18:34.100 --> 00:18:36.420]   First tango devices were big old tablets.
[00:18:36.420 --> 00:18:37.420]   Yep.
[00:18:37.420 --> 00:18:42.780]   And now I guess they're going to start making tango phones that are more normal, I think,
[00:18:42.780 --> 00:18:44.860]   whether they showed an LG phone that had tango enabled.
[00:18:44.860 --> 00:18:46.700]   Yeah, well, they still have like multiple cameras.
[00:18:46.700 --> 00:18:49.100]   It's a little bulkier than the average phone.
[00:18:49.100 --> 00:18:50.100]   Right.
[00:18:50.100 --> 00:18:51.100]   Yep.
[00:18:51.100 --> 00:18:52.100]   Yep.
[00:18:52.100 --> 00:18:53.100]   So I was unclear in the demo.
[00:18:53.100 --> 00:18:54.340]   They showed kind of two sides of it.
[00:18:54.340 --> 00:18:59.580]   They showed the gathering of data part where the computer is learning all these information
[00:18:59.580 --> 00:19:00.580]   points.
[00:19:00.580 --> 00:19:01.660]   Who does that?
[00:19:01.660 --> 00:19:04.100]   Is the storekeeper do that?
[00:19:04.100 --> 00:19:05.100]   Definitely not.
[00:19:05.100 --> 00:19:09.420]   Like, they've tried to do these in-store mapping things forever and they'll get like
[00:19:09.420 --> 00:19:13.340]   one or two retail partners that's willing to go through it and all their stores, all
[00:19:13.340 --> 00:19:14.340]   the other retailers.
[00:19:14.340 --> 00:19:15.500]   Like, we're just trying to stay alive.
[00:19:15.500 --> 00:19:16.500]   We have.
[00:19:16.500 --> 00:19:17.820]   And by the way, you can't do it just once.
[00:19:17.820 --> 00:19:19.340]   You've got to do it every week because it's...
[00:19:19.340 --> 00:19:21.820]   Stuff moves around and changes, right?
[00:19:21.820 --> 00:19:26.100]   So what are they going to drive a little tango card around and periodically map the store?
[00:19:26.100 --> 00:19:29.060]   Then they showed the consumer facing side, which is kind of neat.
[00:19:29.060 --> 00:19:30.780]   It's like Google Maps inside a store.
[00:19:30.780 --> 00:19:33.300]   You could say, "Where's the screwdrivers?"
[00:19:33.300 --> 00:19:39.660]   But I think most stores, that's why Home Depot has a guy there in a tool belt.
[00:19:39.660 --> 00:19:42.540]   So he could say, "Yeah, it's on aisle three."
[00:19:42.540 --> 00:19:44.780]   I don't know if that's not working yet.
[00:19:44.780 --> 00:19:47.620]   I think maybe it's solving a problem that doesn't exist yet.
[00:19:47.620 --> 00:19:51.860]   Tangos always felt to me like a technology in search of a...
[00:19:51.860 --> 00:19:52.860]   Yeah.
[00:19:52.860 --> 00:20:01.540]   But you added together with that data-backed AR, the image.
[00:20:01.540 --> 00:20:06.380]   Google will constantly know where you are, be able to take you to things as aware of your
[00:20:06.380 --> 00:20:07.380]   surroundings.
[00:20:07.380 --> 00:20:08.740]   Then that provides the context.
[00:20:08.740 --> 00:20:12.420]   Then you can ask questions about your surroundings, which is the best widget.
[00:20:12.420 --> 00:20:15.660]   But what did other people say about this omelet?
[00:20:15.660 --> 00:20:19.820]   All those things could start to come out because it is aware of context.
[00:20:19.820 --> 00:20:23.060]   Google is always looking for context so it can anticipate your needs.
[00:20:23.060 --> 00:20:24.620]   Now it will have more context.
[00:20:24.620 --> 00:20:26.340]   Here's what I think is going to happen.
[00:20:26.340 --> 00:20:31.300]   I think we don't really care about what they announced.
[00:20:31.300 --> 00:20:36.860]   If we don't, consumers even less doesn't matter because what is going to happen almost
[00:20:36.860 --> 00:20:41.500]   without anybody noticing it is the assistance is going to get better and better.
[00:20:41.500 --> 00:20:45.260]   These technologies are going to surface just because in the natural course of using your
[00:20:45.260 --> 00:20:48.380]   camera, it'll say, "Oh, you want to know what that flower is?"
[00:20:48.380 --> 00:20:53.180]   From what we will in a few years will happen as we'll look back and go, "Wow, we've really
[00:20:53.180 --> 00:20:54.740]   made considerable progress.
[00:20:54.740 --> 00:20:55.940]   Look at speech recognition.
[00:20:55.940 --> 00:20:58.860]   Their error rate is now under 5%.
[00:20:58.860 --> 00:20:59.860]   It was 8.5%.
[00:20:59.860 --> 00:21:02.260]   That's better than I would do at my age.
[00:21:02.260 --> 00:21:03.260]   Yeah.
[00:21:03.260 --> 00:21:04.620]   Well, they in fact said that.
[00:21:04.620 --> 00:21:05.620]   It's better than humans.
[00:21:05.620 --> 00:21:07.980]   No, they said that about the image recognition.
[00:21:07.980 --> 00:21:09.100]   Oh, image recognition is bad.
[00:21:09.100 --> 00:21:10.260]   I don't know how that could be.
[00:21:10.260 --> 00:21:12.540]   I don't understand that at all.
[00:21:12.540 --> 00:21:19.340]   So in a way, that's why I think Google should shut up because by announcing this, it's like,
[00:21:19.340 --> 00:21:22.100]   "Okay, 5% nice.
[00:21:22.100 --> 00:21:26.300]   It's not inspiring or exciting or even."
[00:21:26.300 --> 00:21:31.620]   But if they just shut up and let it get better and better and better and put it on Apple,
[00:21:31.620 --> 00:21:33.460]   give them a Google Assistant and they'll start to people.
[00:21:33.460 --> 00:21:40.140]   Apple users start to, "This assistant really does a pretty good job that gradually people
[00:21:40.140 --> 00:21:43.300]   start putting homes in their houses."
[00:21:43.300 --> 00:21:46.940]   I think that gradual is almost the best way to do this.
[00:21:46.940 --> 00:21:48.860]   Just surprise people.
[00:21:48.860 --> 00:21:49.860]   Surprise me.
[00:21:49.860 --> 00:21:50.860]   Maybe.
[00:21:50.860 --> 00:21:53.860]   Well, plus you have less problems of scary and regulators, but oh my God, they're digging
[00:21:53.860 --> 00:21:54.860]   over the world.
[00:21:54.860 --> 00:21:56.500]   Well, that's the big risk.
[00:21:56.500 --> 00:22:03.420]   Well, that's a genuine concern because if Google's approach is going to work here,
[00:22:03.420 --> 00:22:08.780]   it's going to rely on people uploading and sharing basically all of their photos.
[00:22:08.780 --> 00:22:13.140]   Unfortunately, every time you use Google Lens, you're sending that photo, that imagery,
[00:22:13.140 --> 00:22:18.980]   that video, whatever to Google, and that will leave a trail.
[00:22:18.980 --> 00:22:22.940]   That is a repository of all of the things you've been looking at through your phone being
[00:22:22.940 --> 00:22:23.940]   sent to Google.
[00:22:23.940 --> 00:22:27.340]   Now, it'll help off that context in a store, but it also like...
[00:22:27.340 --> 00:22:28.340]   Is it bad?
[00:22:28.340 --> 00:22:30.580]   Do you think that's a good thing?
[00:22:30.580 --> 00:22:35.460]   It's a privacy trade-off and I think it's a question that we all need to ask ourselves.
[00:22:35.460 --> 00:22:41.140]   But it could be a bad thing.
[00:22:41.140 --> 00:22:45.900]   There is a risk, of course, that because Apple does such a better job marketing that everybody
[00:22:45.900 --> 00:22:46.900]   else...
[00:22:46.900 --> 00:22:48.820]   I think people assume Siri is better than it is.
[00:22:48.820 --> 00:22:49.820]   Siri is terrible.
[00:22:49.820 --> 00:22:50.820]   Don't you think?
[00:22:50.820 --> 00:22:52.820]   I think people assume the opposite.
[00:22:52.820 --> 00:22:53.820]   It is.
[00:22:53.820 --> 00:22:54.820]   I think people...
[00:22:54.820 --> 00:22:55.820]   Don't you swear it?
[00:22:55.820 --> 00:22:57.140]   I mean, they're all pretty bad.
[00:22:57.140 --> 00:23:00.860]   Like being real about it, they're all very bad right now, but I think that's because the
[00:23:00.860 --> 00:23:03.060]   pop culture idea of what AI should be.
[00:23:03.060 --> 00:23:04.060]   They're not how many.
[00:23:04.060 --> 00:23:05.060]   Exactly.
[00:23:05.060 --> 00:23:06.620]   They're not the Star Trek computer yet.
[00:23:06.620 --> 00:23:08.980]   They're not Hell in a thousand, whatever.
[00:23:08.980 --> 00:23:14.220]   But I think they're where they're supposed to be at this point given the technology that
[00:23:14.220 --> 00:23:15.780]   AI is at.
[00:23:15.780 --> 00:23:20.580]   That's almost why I think it's just shut up and it'll gradually sneak up us on us that
[00:23:20.580 --> 00:23:21.580]   this is suddenly...
[00:23:21.580 --> 00:23:25.940]   Wow, I'm talking to Scarlett Johansson in my phone and she's got a lot of...
[00:23:25.940 --> 00:23:30.500]   But the only way it's going to improve is if people continue using the bad product and
[00:23:30.500 --> 00:23:31.500]   point it so that it gets better.
[00:23:31.500 --> 00:23:33.500]   That's why they need to keep it out.
[00:23:33.500 --> 00:23:39.740]   This is where Google has a huge advantage because they have this virtuous circle where
[00:23:39.740 --> 00:23:43.100]   people use it and it feeds into it and it gets better and you're right, they do need
[00:23:43.100 --> 00:23:45.660]   to get people to keep using it.
[00:23:45.660 --> 00:23:52.060]   Well, and for Google, even if people aren't using lens, even if people aren't talking
[00:23:52.060 --> 00:23:55.420]   through text and aloe, they're still using Google search, they're still using Google
[00:23:55.420 --> 00:23:56.420]   search.
[00:23:56.420 --> 00:23:57.420]   I think they're getting signals about it.
[00:23:57.420 --> 00:23:58.420]   They're using all these other products.
[00:23:58.420 --> 00:23:59.420]   Oh yeah.
[00:23:59.420 --> 00:24:03.460]   And all of those things inform their AI and they're able to tie all of that stuff together.
[00:24:03.460 --> 00:24:07.940]   So, yeah, I mean, they're going to...
[00:24:07.940 --> 00:24:10.260]   This company is set up and built for this problem.
[00:24:10.260 --> 00:24:12.500]   Don't you think people with the most stable wins?
[00:24:12.500 --> 00:24:18.780]   Don't you think people are starting to realize that photos is kind of remarkable?
[00:24:18.780 --> 00:24:23.300]   I mean, maybe it's just me, but I just put everything into photos now and I don't have
[00:24:23.300 --> 00:24:25.820]   to ever worry about categorizing it or anything.
[00:24:25.820 --> 00:24:27.620]   It just knows.
[00:24:27.620 --> 00:24:31.780]   And you're helping to feed their image recognition and all that stuff.
[00:24:31.780 --> 00:24:34.140]   And they offer it for free.
[00:24:34.140 --> 00:24:35.140]   It's a very...
[00:24:35.140 --> 00:24:36.140]   I think it's a compelling offering.
[00:24:36.140 --> 00:24:40.140]   It's free backup of your photos, automatic categorization.
[00:24:40.140 --> 00:24:45.460]   Now that you can make books kind of automatically without any effort on your part, which is
[00:24:45.460 --> 00:24:47.020]   kind of the holy grail.
[00:24:47.020 --> 00:24:48.220]   The new shared libraries.
[00:24:48.220 --> 00:24:49.220]   Sounds really cool.
[00:24:49.220 --> 00:24:50.220]   I haven't tried it yet.
[00:24:50.220 --> 00:24:52.460]   So they're giving us little bits of candy.
[00:24:52.460 --> 00:24:55.740]   They're giving us little...
[00:24:55.740 --> 00:25:00.380]   Hansel and Gretel breadcrumbs leading us into these technologies.
[00:25:00.380 --> 00:25:03.460]   And I think an appropriate way to get people to use it more and more so they can get better
[00:25:03.460 --> 00:25:04.460]   and better.
[00:25:04.460 --> 00:25:05.460]   Yeah.
[00:25:05.460 --> 00:25:10.540]   And you know, photos interestingly enough is a big advantage for Facebook because online
[00:25:10.540 --> 00:25:14.940]   the biggest place where most people upload photos is Facebook.
[00:25:14.940 --> 00:25:15.940]   Even more so than Flickr.
[00:25:15.940 --> 00:25:17.660]   Even more so than Google Photos.
[00:25:17.660 --> 00:25:21.580]   You're right, but they've never provided that kind of functionality where you can organize
[00:25:21.580 --> 00:25:24.820]   your family stuff and see all the photos of your kids and all that.
[00:25:24.820 --> 00:25:26.420]   They don't have that layer, the meta layer.
[00:25:26.420 --> 00:25:29.140]   They don't have that layer, but they have the facial recognition layer.
[00:25:29.140 --> 00:25:30.700]   They have location recognition.
[00:25:30.700 --> 00:25:31.700]   The social layers.
[00:25:31.700 --> 00:25:34.420]   Do you think that they're working as hard as Google on AI?
[00:25:34.420 --> 00:25:40.060]   I think they're maybe throwing as much money and resources at it, but they're so far behind
[00:25:40.060 --> 00:25:42.660]   because they don't have as many signals as possible.
[00:25:42.660 --> 00:25:46.900]   It's almost as if Google knew 10 years ago that this...
[00:25:46.900 --> 00:25:49.420]   I mean, do you think they kind of knew this was the end game that...
[00:25:49.420 --> 00:25:50.420]   I think...
[00:25:50.420 --> 00:25:51.420]   Larry, they're pretty forward thinking.
[00:25:51.420 --> 00:25:54.420]   I think Google was just trying to get all the data it could and then it would figure
[00:25:54.420 --> 00:25:56.100]   out what to do with it later.
[00:25:56.100 --> 00:25:58.300]   I mean, Google has been kind of... But they knew.
[00:25:58.300 --> 00:25:59.300]   But they knew.
[00:25:59.300 --> 00:26:00.300]   Organizing...
[00:26:00.300 --> 00:26:01.300]   What was it?
[00:26:01.300 --> 00:26:02.300]   What was it, Jeff?
[00:26:02.300 --> 00:26:03.300]   Organizing the world's data.
[00:26:03.300 --> 00:26:04.300]   Well, it's valid.
[00:26:04.300 --> 00:26:05.300]   Make it accessible.
[00:26:05.300 --> 00:26:06.300]   And make it accessible.
[00:26:06.300 --> 00:26:07.300]   That was from day one, their mission statement.
[00:26:07.300 --> 00:26:10.220]   Maybe they didn't know, but I think I...
[00:26:10.220 --> 00:26:16.620]   Even in 1975, when the key to artificial intelligence was data.
[00:26:16.620 --> 00:26:17.620]   Data was trending.
[00:26:17.620 --> 00:26:18.780]   Well, I remember what's his name?
[00:26:18.780 --> 00:26:23.460]   The brilliant Russian investor who does the physics prize and the computer prize.
[00:26:23.460 --> 00:26:24.460]   Yuri Miller.
[00:26:24.460 --> 00:26:29.100]   So, Yuri, when he started investing in Facebook and Twitter long ago, he said it was all because
[00:26:29.100 --> 00:26:31.100]   AI is coming and they have data.
[00:26:31.100 --> 00:26:32.100]   Yeah.
[00:26:32.100 --> 00:26:33.100]   Yeah.
[00:26:33.100 --> 00:26:34.100]   Big data.
[00:26:34.100 --> 00:26:38.260]   But nobody's done a better job, I think, of capturing it and capitalizing on the Google.
[00:26:38.260 --> 00:26:44.020]   I'm waiting to see Apple and Microsoft and Facebook and Amazon do the same.
[00:26:44.020 --> 00:26:47.260]   And it seems as if Google's got the handle on this, right?
[00:26:47.260 --> 00:26:49.260]   And just Google has never...
[00:26:49.260 --> 00:26:54.260]   Google has been one of the worst companies when it comes to respecting consumer privacy.
[00:26:54.260 --> 00:26:55.260]   Everything?
[00:26:55.260 --> 00:26:56.260]   Yeah.
[00:26:56.260 --> 00:27:00.060]   But that's allowed them to build that repository.
[00:27:00.060 --> 00:27:01.860]   Facebook is clearly the worst company.
[00:27:01.860 --> 00:27:03.500]   Facebook is a lot more crap.
[00:27:03.500 --> 00:27:07.060]   Facebook might care less and they might make more mistakes, but they...
[00:27:07.060 --> 00:27:08.860]   It feels like Google is very upfront.
[00:27:08.860 --> 00:27:10.780]   It feels like Google takes more.
[00:27:10.780 --> 00:27:14.100]   They take everything, but they tell you what they take in Dashboard.
[00:27:14.100 --> 00:27:15.100]   They let you.
[00:27:15.100 --> 00:27:16.100]   And you got value for it.
[00:27:16.100 --> 00:27:17.900]   Well, they all tell you in places where nobody looks.
[00:27:17.900 --> 00:27:19.620]   Most people don't go to Dashboard.
[00:27:19.620 --> 00:27:21.140]   Most people don't go to my account.
[00:27:21.140 --> 00:27:23.420]   Most people don't go into their user settings that way.
[00:27:23.420 --> 00:27:25.420]   So they're as transpare.
[00:27:25.420 --> 00:27:29.940]   Those are the two companies that default to "we're going to take and keep everything."
[00:27:29.940 --> 00:27:30.940]   Exactly.
[00:27:30.940 --> 00:27:33.420]   Whereas Apple and Amazon are somewhere on the other end of the...
[00:27:33.420 --> 00:27:37.300]   But I think in the long run, that's going to bite them in the butt because the company
[00:27:37.300 --> 00:27:38.300]   has the data.
[00:27:38.300 --> 00:27:39.580]   Apple's never really had that idea.
[00:27:39.580 --> 00:27:40.580]   Apple...
[00:27:40.580 --> 00:27:41.580]   Apple's...
[00:27:41.580 --> 00:27:42.580]   Apple's so far behind.
[00:27:42.580 --> 00:27:45.700]   Well, because they never had it, so they had to make it that positive.
[00:27:45.700 --> 00:27:47.300]   I think Google does it...
[00:27:47.300 --> 00:27:50.740]   Well, and maybe I'm prejudiced, but I think Google does it exactly right.
[00:27:50.740 --> 00:27:54.500]   They collect as much as they can, but they tell you.
[00:27:54.500 --> 00:27:55.500]   They do...
[00:27:55.500 --> 00:27:58.700]   I mean, admittedly, people don't care and look, but they give you all that.
[00:27:58.700 --> 00:28:00.220]   They don't hide it.
[00:28:00.220 --> 00:28:01.220]   And they even encourage you.
[00:28:01.220 --> 00:28:02.380]   Go review your settings.
[00:28:02.380 --> 00:28:03.740]   Go review your...
[00:28:03.740 --> 00:28:07.060]   And they say in their terms of service, I think, in fairly clear English what they're
[00:28:07.060 --> 00:28:08.540]   doing.
[00:28:08.540 --> 00:28:13.140]   And if you're going to win in AI, you've got to collect that data, don't you?
[00:28:13.140 --> 00:28:14.140]   Oh, yeah.
[00:28:14.140 --> 00:28:15.140]   You've got to have it.
[00:28:15.140 --> 00:28:19.740]   I'll tell you what you do see when you think of Facebook and Google is scale.
[00:28:19.740 --> 00:28:20.740]   Wow.
[00:28:20.740 --> 00:28:22.820]   Sundar Pachai gave out some numbers.
[00:28:22.820 --> 00:28:27.540]   2 billion monthly active Android devices.
[00:28:27.540 --> 00:28:28.540]   2 billion!
[00:28:28.540 --> 00:28:31.100]   That's how many people use Facebook.
[00:28:31.100 --> 00:28:34.900]   It's not quite 2 billion, but it's roughly the same order of magnitude, right?
[00:28:34.900 --> 00:28:36.820]   Yeah, it's the ballpark.
[00:28:36.820 --> 00:28:38.820]   That's...
[00:28:38.820 --> 00:28:41.420]   Microsoft has a 1.5 billion Windows machines.
[00:28:41.420 --> 00:28:42.420]   So...
[00:28:42.420 --> 00:28:43.420]   Yet...
[00:28:43.420 --> 00:28:44.420]   Yet...
[00:28:44.420 --> 00:28:47.540]   It's companies or personal services companies.
[00:28:47.540 --> 00:28:49.820]   We in media still treat everybody the same.
[00:28:49.820 --> 00:28:54.460]   We give them the same single product in Google and Facebook scale at a personal level.
[00:28:54.460 --> 00:28:56.460]   That's even more amazing than that.
[00:28:56.460 --> 00:28:57.460]   Yeah.
[00:28:57.460 --> 00:28:58.460]   And it's a big...
[00:28:58.460 --> 00:29:04.500]   And it's big growth from a year ago where they had 1.4 billion September 2015.
[00:29:04.500 --> 00:29:11.060]   800 million monthly active users on Google drive, Google Photos, 500 million monthly active
[00:29:11.060 --> 00:29:12.860]   users.
[00:29:12.860 --> 00:29:17.460]   I do wonder though, how many of those 2 billion Android devices are running LASEDOS?
[00:29:17.460 --> 00:29:18.460]   None of them.
[00:29:18.460 --> 00:29:19.460]   Okay.
[00:29:19.460 --> 00:29:24.460]   Only people are the pixel owners, the million pixel owners, that's probably about it.
[00:29:24.460 --> 00:29:28.380]   It kind of hurts to see all this cool new stuff in Google every year at ISO.
[00:29:28.380 --> 00:29:32.580]   And so few people have access to it because a lot of it usually comes out for the latest
[00:29:32.580 --> 00:29:33.580]   version of Android.
[00:29:33.580 --> 00:29:34.580]   Android, and...
[00:29:34.580 --> 00:29:38.420]   Android O looks really cool, even though people won't be able to use it for another
[00:29:38.420 --> 00:29:39.420]   couple years.
[00:29:39.420 --> 00:29:40.420]   Let's talk about it.
[00:29:40.420 --> 00:29:41.420]   I know Jeff's installed it immediately.
[00:29:41.420 --> 00:29:42.420]   I've got it.
[00:29:42.420 --> 00:29:43.420]   Now, and I didn't...
[00:29:43.420 --> 00:29:44.420]   But let's talk about it.
[00:29:44.420 --> 00:29:45.420]   I was.
[00:29:45.420 --> 00:29:46.420]   Second, you can.
[00:29:46.420 --> 00:29:48.020]   It's a public beta now and you can install it.
[00:29:48.020 --> 00:29:49.660]   If you have a...
[00:29:49.660 --> 00:29:51.860]   Probably have to have a Google phone and an X-issure pixel.
[00:29:51.860 --> 00:29:53.700]   I know you can install the pixels.
[00:29:53.700 --> 00:29:56.300]   Can we place our bets on what the O is going to be?
[00:29:56.300 --> 00:29:57.700]   Yeah, let's think about it.
[00:29:57.700 --> 00:30:00.020]   And when we come back, I want to take a break.
[00:30:00.020 --> 00:30:04.420]   Mark Millian is here from Bloomberg Businessweekbloomberg.com/tech.
[00:30:04.420 --> 00:30:08.140]   If you have any questions about the Bloomberg Tournament, all he knows how to operate it.
[00:30:08.140 --> 00:30:09.140]   Barely.
[00:30:09.140 --> 00:30:10.140]   Is it kind of...
[00:30:10.140 --> 00:30:12.300]   It looks like it's kind of complicated.
[00:30:12.300 --> 00:30:13.300]   We can do a lot of stuff.
[00:30:13.300 --> 00:30:14.700]   It's for traders.
[00:30:14.700 --> 00:30:15.700]   It's the traders love it.
[00:30:15.700 --> 00:30:17.180]   Yeah, the traders love it.
[00:30:17.180 --> 00:30:18.980]   @markmillian on Twitter.
[00:30:18.980 --> 00:30:21.060]   Nathan Oliveris-Jows, who I really...
[00:30:21.060 --> 00:30:26.540]   I think you should thank your mom and dad because Nate OG is the best Twitter handle ever.
[00:30:26.540 --> 00:30:31.100]   Yeah, that actually came from an elementary school teacher who couldn't say my last name.
[00:30:31.100 --> 00:30:32.860]   I don't think my best.
[00:30:32.860 --> 00:30:35.140]   We're anticipating that OG would be...
[00:30:35.140 --> 00:30:36.140]   OG.
[00:30:36.140 --> 00:30:37.140]   Yeah.
[00:30:37.140 --> 00:30:38.140]   Original gangsta.
[00:30:38.140 --> 00:30:39.140]   Is that right?
[00:30:39.140 --> 00:30:40.140]   Is that what that means?
[00:30:40.140 --> 00:30:41.140]   Yeah.
[00:30:41.140 --> 00:30:42.140]   Yeah, Leo.
[00:30:42.140 --> 00:30:43.140]   My...
[00:30:43.140 --> 00:30:44.140]   For Shizzle.
[00:30:44.140 --> 00:30:45.140]   My street reputation precedes me.
[00:30:45.140 --> 00:30:46.140]   I know that.
[00:30:46.140 --> 00:30:48.020]   I use the original gangsta.
[00:30:48.020 --> 00:30:51.820]   And we're proud to say our newest reporter, our newest journalist here.
[00:30:51.820 --> 00:30:53.180]   In fact, I'm looking for...
[00:30:53.180 --> 00:30:55.420]   We're working on working on Nate to do a car show.
[00:30:55.420 --> 00:30:56.420]   That's my new...
[00:30:56.420 --> 00:30:57.420]   Yeah, we were just...
[00:30:57.420 --> 00:31:00.300]   Actually, I was talking with Mark about it on the drive-up.
[00:31:00.300 --> 00:31:03.420]   You guys do a podcast together called Buzzkill.
[00:31:03.420 --> 00:31:04.420]   Yep.
[00:31:04.420 --> 00:31:05.420]   Which is...
[00:31:05.420 --> 00:31:06.420]   With Brian Chen from The New York Times as well.
[00:31:06.420 --> 00:31:07.420]   With Brian Eck.
[00:31:07.420 --> 00:31:08.420]   It's in it.
[00:31:08.420 --> 00:31:09.420]   Don't you have to say the X if you say Brian X Chen.
[00:31:09.420 --> 00:31:10.420]   Brian X Chen.
[00:31:10.420 --> 00:31:11.420]   Brian X Chen.
[00:31:11.420 --> 00:31:14.700]   Because they're other Brian Chen's, but he's the only Brian X.
[00:31:14.700 --> 00:31:15.700]   He's the only X.
[00:31:15.700 --> 00:31:17.140]   And what do you guys do on that show?
[00:31:17.140 --> 00:31:18.860]   I know you have the buzzer.
[00:31:18.860 --> 00:31:19.860]   Yes.
[00:31:19.860 --> 00:31:24.140]   We try to keep it under 30 minutes to save people's time.
[00:31:24.140 --> 00:31:25.140]   What a foolish idea.
[00:31:25.140 --> 00:31:27.140]   We've already gone past 30 minutes here.
[00:31:27.140 --> 00:31:28.140]   What's the daisy...
[00:31:28.140 --> 00:31:29.140]   What's daisy...
[00:31:29.140 --> 00:31:30.140]   No stamina.
[00:31:30.140 --> 00:31:31.140]   No stamina.
[00:31:31.140 --> 00:31:33.580]   We each pick a couple topics in advance.
[00:31:33.580 --> 00:31:34.820]   We have a pool of topics.
[00:31:34.820 --> 00:31:38.860]   And then over the course of the show, whenever any of us gets bored with one of the topics,
[00:31:38.860 --> 00:31:42.540]   we can hit a buzzer and that forces the conversation to move on to the next topic.
[00:31:42.540 --> 00:31:46.700]   So basically anytime we talk about sports, Brian just hits a note pretty quick.
[00:31:46.700 --> 00:31:48.220]   No sport ball on this show.
[00:31:48.220 --> 00:31:49.380]   We're both soccer nerds.
[00:31:49.380 --> 00:31:50.540]   But soccer, really.
[00:31:50.540 --> 00:31:51.540]   Yeah.
[00:31:51.540 --> 00:31:53.380]   I mean, we've talked about basketball today.
[00:31:53.380 --> 00:31:54.380]   What?
[00:31:54.380 --> 00:31:55.380]   Barcelona FC.
[00:31:55.380 --> 00:31:56.380]   Yeah.
[00:31:56.380 --> 00:31:57.380]   Lasky and the seasonals.
[00:31:57.380 --> 00:31:59.340]   Andraeos from Barcelona.
[00:31:59.340 --> 00:32:02.540]   He's usually wearing his Barcelona FC shirt.
[00:32:02.540 --> 00:32:03.540]   Are you not Barcelona?
[00:32:03.540 --> 00:32:05.820]   There's two clubs in Barcelona, aren't there?
[00:32:05.820 --> 00:32:07.580]   He's the other one.
[00:32:07.580 --> 00:32:08.580]   Shocking.
[00:32:08.580 --> 00:32:16.460]   Jason, I'm sorry, Jeff Jarvis is also here from City University of New York Buzzermachine.com.
[00:32:16.460 --> 00:32:17.740]   We're going to continue talking.
[00:32:17.740 --> 00:32:23.420]   Let's talk about, oh, in a second, and your picks for what dessert O stands for.
[00:32:23.420 --> 00:32:27.460]   Our show today brought to you by Rocket Mortgage from Quick and Lones, the best mortgage lender
[00:32:27.460 --> 00:32:30.900]   in the country because they're high tech, because they're transparent, because they do
[00:32:30.900 --> 00:32:36.740]   a great job because they're number one in customer satisfaction from JD Power year after
[00:32:36.740 --> 00:32:40.820]   year after year, both in loan origination and servicing.
[00:32:40.820 --> 00:32:42.100]   You got to love quick and loans.
[00:32:42.100 --> 00:32:47.860]   And now the geek in me loves them even more because they've created an entirely online
[00:32:47.860 --> 00:32:53.180]   mortgage process that happens fast because it's computers.
[00:32:53.180 --> 00:32:57.540]   Last time we bought a house, Lisa and I, three years ago, it took us a month, literally,
[00:32:57.540 --> 00:33:04.860]   from one of the big banks, you know the name, they're the, just like we gave them the normal
[00:33:04.860 --> 00:33:05.860]   stuff.
[00:33:05.860 --> 00:33:08.460]   And they kept asking for week after week.
[00:33:08.460 --> 00:33:11.540]   The more we went on vacation, we were faxing from a cruise ship.
[00:33:11.540 --> 00:33:14.380]   We were faxing this bank information before we got our mortgage.
[00:33:14.380 --> 00:33:16.740]   It was crazy.
[00:33:16.740 --> 00:33:23.620]   Next time Rocket Mortgage, you can do it all right there at the open house, secure, trustworthy.
[00:33:23.620 --> 00:33:28.900]   They even give you, you know, buttons to choose the term and the, and the rate of your loan,
[00:33:28.900 --> 00:33:31.260]   submit all the paperwork you need with a touch of a button.
[00:33:31.260 --> 00:33:34.580]   I mean, including pay stubs and check balance, everything, checking statements, everything
[00:33:34.580 --> 00:33:35.780]   you need.
[00:33:35.780 --> 00:33:36.980]   Just do right there.
[00:33:36.980 --> 00:33:39.500]   And because it's computers, they customize it just for you.
[00:33:39.500 --> 00:33:45.540]   And then they turn around literally not in months, weeks, not days, minutes, not hours,
[00:33:45.540 --> 00:33:47.940]   minutes.
[00:33:47.940 --> 00:33:54.580]   Rocket Mortgage, skip the bank, skip the waiting, go completely online, quickenloans.com/twit2.
[00:33:54.580 --> 00:33:57.820]   Get that address right, if you will, because that way they'll know you heard it here and
[00:33:57.820 --> 00:34:01.980]   not somewhere else, quickenloans.com/twit2.
[00:34:01.980 --> 00:34:05.380]   People housing lender, licensed in all 50 states and MLS consumer access.org, number
[00:34:05.380 --> 00:34:06.380]   3030.
[00:34:06.380 --> 00:34:09.860]   Rocket Mortgage from Quick and Loans, quickenloans.com/twit2.
[00:34:09.860 --> 00:34:12.380]   Do you have sponsors on the buskill?
[00:34:12.380 --> 00:34:14.380]   No, we have no sponsors.
[00:34:14.380 --> 00:34:17.380]   No one would pay to be.
[00:34:17.380 --> 00:34:21.460]   We get some like 800 listeners a week, which I think we're all kind of surprised by.
[00:34:21.460 --> 00:34:22.460]   Let's get it bigger.
[00:34:22.460 --> 00:34:23.460]   What's the website?
[00:34:23.460 --> 00:34:25.500]   Well, it's, we don't have a website.
[00:34:25.500 --> 00:34:26.500]   We don't have a website.
[00:34:26.500 --> 00:34:27.500]   Here's the problem right there.
[00:34:27.500 --> 00:34:29.780]   We're millennials, so we don't have a website.
[00:34:29.780 --> 00:34:31.780]   It actually comes on cassettes.
[00:34:31.780 --> 00:34:33.620]   Oh, it's on SoundCloud.
[00:34:33.620 --> 00:34:34.620]   That's where the kids go.
[00:34:34.620 --> 00:34:35.620]   It's on iTunes.
[00:34:35.620 --> 00:34:37.620]   It's on every podcast.
[00:34:37.620 --> 00:34:38.620]   Pocket bus.
[00:34:38.620 --> 00:34:40.620]   It's on Google Play, Kinca Titcher, Overcast.
[00:34:40.620 --> 00:34:41.620]   It's your right.
[00:34:41.620 --> 00:34:43.260]   You don't really need a website anymore.
[00:34:43.260 --> 00:34:47.860]   Just go to whatever podcast and if it's not on your podcast app, tweet us and we'll
[00:34:47.860 --> 00:34:48.860]   make app.
[00:34:48.860 --> 00:34:52.100]   I think of all the money I wasted over the years on websites.
[00:34:52.100 --> 00:34:54.020]   How about Squarespace hooking you up?
[00:34:54.020 --> 00:34:55.020]   No, no, no, no, no.
[00:34:55.020 --> 00:34:58.300]   We run our own sites, Drupal, Backend.
[00:34:58.300 --> 00:35:02.700]   It's a headless Drupal running Node.js.
[00:35:02.700 --> 00:35:03.700]   It's on Heroku.
[00:35:03.700 --> 00:35:04.900]   We use Redis.
[00:35:04.900 --> 00:35:06.220]   It's modern.
[00:35:06.220 --> 00:35:12.020]   It cost me $6,000 a month, quarter of a million dollars to design.
[00:35:12.020 --> 00:35:13.020]   But it's modern.
[00:35:13.020 --> 00:35:14.020]   But aren't you?
[00:35:14.020 --> 00:35:17.020]   I'm actually working on flapper stuff.
[00:35:17.020 --> 00:35:18.020]   I know, I know.
[00:35:18.020 --> 00:35:19.020]   You're flapper stuff.
[00:35:19.020 --> 00:35:20.020]   And I'm going with WordPress.
[00:35:20.020 --> 00:35:21.940]   I'm going with some more stuff.
[00:35:21.940 --> 00:35:22.940]   There are sponsors.
[00:35:22.940 --> 00:35:25.860]   If we'll talk about it, we might have a BuzzKiller website eventually.
[00:35:25.860 --> 00:35:27.700]   Actually, about a URL recently.
[00:35:27.700 --> 00:35:28.700]   We're going to do it on WordPress.
[00:35:28.700 --> 00:35:29.700]   WordPress is really good for podcast.
[00:35:29.700 --> 00:35:30.700]   Yeah.
[00:35:30.700 --> 00:35:32.260]   Actually, we have a podcast plug-ins.
[00:35:32.260 --> 00:35:33.260]   Yeah.
[00:35:33.260 --> 00:35:35.980]   Oh, so I took a picture.
[00:35:35.980 --> 00:35:39.100]   I was at Google I/O in the press area.
[00:35:39.100 --> 00:35:40.980]   And I took a picture.
[00:35:40.980 --> 00:35:47.660]   I don't know if this is indicative of anything, of a big basket of Oreo cookies.
[00:35:47.660 --> 00:35:50.460]   I so hope Android O is called Oreo.
[00:35:50.460 --> 00:35:51.980]   I love Oreos.
[00:35:51.980 --> 00:35:52.980]   Who doesn't?
[00:35:52.980 --> 00:35:55.380]   But is it an-- do you have Oreos in Barcelona?
[00:35:55.380 --> 00:35:56.380]   Of course.
[00:35:56.380 --> 00:35:59.060]   What do you think we are?
[00:35:59.060 --> 00:36:00.580]   Backward peasants?
[00:36:00.580 --> 00:36:02.420]   He says, of course.
[00:36:02.420 --> 00:36:03.420]   Okay.
[00:36:03.420 --> 00:36:04.660]   Because it has to be international.
[00:36:04.660 --> 00:36:07.500]   It can't be-- and that's part of the problem.
[00:36:07.500 --> 00:36:09.460]   You know, NuGet was sort of international.
[00:36:09.460 --> 00:36:12.140]   But I think Americans don't really know what NuGet is.
[00:36:12.140 --> 00:36:15.740]   Well, if you're like a hardcore Snickers person, then you know it's inside of Snickers.
[00:36:15.740 --> 00:36:16.740]   That's about it, right?
[00:36:16.740 --> 00:36:18.700]   I like what there's four of those people like.
[00:36:18.700 --> 00:36:21.740]   But remember, they named it KitKat and they got some flak for using a brand name.
[00:36:21.740 --> 00:36:22.740]   So maybe Oreos.
[00:36:22.740 --> 00:36:23.740]   I don't know.
[00:36:23.740 --> 00:36:25.740]   Maybe they have to make a deal with Nabisco or something like that.
[00:36:25.740 --> 00:36:27.340]   They do have to work at a trademark license.
[00:36:27.340 --> 00:36:28.340]   Yeah, because they don't own it.
[00:36:28.340 --> 00:36:29.340]   Hey, they didn't want to KitKat.
[00:36:29.340 --> 00:36:30.340]   They can do with Oreo.
[00:36:30.340 --> 00:36:31.340]   What about orange?
[00:36:31.340 --> 00:36:32.340]   Somebody says she'll be orange.
[00:36:32.340 --> 00:36:33.340]   I also--
[00:36:33.340 --> 00:36:34.340]   I was going to say--
[00:36:34.340 --> 00:36:35.340]   I was going to say--
[00:36:35.340 --> 00:36:36.340]   --that the event.
[00:36:36.340 --> 00:36:37.340]   Orange Julie's--
[00:36:37.340 --> 00:36:38.340]   Oh, the healthy?
[00:36:38.340 --> 00:36:39.340]   I don't think orange is a dessert.
[00:36:39.340 --> 00:36:40.340]   Orange Julie is not great.
[00:36:40.340 --> 00:36:42.340]   Orange Julie's are great.
[00:36:42.340 --> 00:36:45.180]   Orange slices are the healthy things they give out to kids after soccer games, right?
[00:36:45.180 --> 00:36:46.180]   It could be orange slices.
[00:36:46.180 --> 00:36:47.180]   Orange slice.
[00:36:47.180 --> 00:36:48.180]   Ooh.
[00:36:48.180 --> 00:36:49.180]   I like it.
[00:36:49.180 --> 00:36:50.180]   Oatmeal cookie?
[00:36:50.180 --> 00:36:51.180]   No.
[00:36:51.180 --> 00:36:52.180]   No.
[00:36:52.180 --> 00:36:53.980]   I think it's going to be-- I like Oreo.
[00:36:53.980 --> 00:36:56.780]   Remember, though, we thought it would be Nutella for N and N wasn't.
[00:36:56.780 --> 00:36:57.780]   We did.
[00:36:57.780 --> 00:36:58.940]   You know, let's be real.
[00:36:58.940 --> 00:37:00.420]   It's going to be Ozark pudding.
[00:37:00.420 --> 00:37:02.260]   Everybody loves.
[00:37:02.260 --> 00:37:03.260]   Everybody loves Ozark pudding.
[00:37:03.260 --> 00:37:04.500]   Who does it love?
[00:37:04.500 --> 00:37:06.460]   It's everyone's favorite nut cake, basically.
[00:37:06.460 --> 00:37:08.460]   So did you guys install orange?
[00:37:08.460 --> 00:37:09.460]   Orange.
[00:37:09.460 --> 00:37:11.580]   Sure, but not bad.
[00:37:11.580 --> 00:37:15.460]   Orange is too political because of the Dutch.
[00:37:15.460 --> 00:37:17.460]   And the president.
[00:37:17.460 --> 00:37:20.060]   [LAUGHTER]
[00:37:20.060 --> 00:37:22.060]   Emails to Jeff Jarvis.
[00:37:22.060 --> 00:37:24.340]   That's a bother me.
[00:37:24.340 --> 00:37:27.460]   I got enough email about Jeff.
[00:37:27.460 --> 00:37:30.180]   How about-- so Jeff's has tried it.
[00:37:30.180 --> 00:37:34.500]   Did you guys-- have you installed-- oh, I didn't install it on my Pixel.
[00:37:34.500 --> 00:37:39.100]   There are few interesting things about O, right?
[00:37:39.100 --> 00:37:40.100]   Jeff.
[00:37:40.100 --> 00:37:41.100]   All right.
[00:37:41.100 --> 00:37:42.100]   Right.
[00:37:42.100 --> 00:37:44.580]   Wait, you know, I didn't install it on this phone, but I've already got it.
[00:37:44.580 --> 00:37:45.580]   I just--
[00:37:45.580 --> 00:37:48.140]   Oh, you must have pushed that button.
[00:37:48.140 --> 00:37:50.060]   Are you on a beta channel or something?
[00:37:50.060 --> 00:37:51.060]   Yes.
[00:37:51.060 --> 00:37:52.020]   Maybe it was a beta.
[00:37:52.020 --> 00:38:00.780]   If you go to Android.com/beta or whatever it is, they'll show you the compatible phones.
[00:38:00.780 --> 00:38:06.020]   And then there's a button that you push that says, OK, sign me up.
[00:38:06.020 --> 00:38:09.820]   And then at that point, you get it over the air update.
[00:38:09.820 --> 00:38:11.820]   What's your favorite feature, Jeff?
[00:38:11.820 --> 00:38:12.820]   [LAUGHTER]
[00:38:12.820 --> 00:38:14.300]   I don't even-- that's the problem.
[00:38:14.300 --> 00:38:16.980]   I don't even know what features are on.
[00:38:16.980 --> 00:38:19.940]   It doesn't onboard you well, you know?
[00:38:19.940 --> 00:38:21.300]   So you see, I-- here it is.
[00:38:21.300 --> 00:38:23.060]   How does the Android O, beta program work?
[00:38:23.060 --> 00:38:24.060]   So there it is.
[00:38:24.060 --> 00:38:27.460]   Those are the two phones I own that are compatible, both Google pixels.
[00:38:27.460 --> 00:38:30.900]   So if I were to enroll device, then I would get it over the air.
[00:38:30.900 --> 00:38:32.660]   You don't have any Nexus devices?
[00:38:32.660 --> 00:38:34.660]   Or did you just-- did you give them away when you got the Pixel?
[00:38:34.660 --> 00:38:35.660]   I can't do.
[00:38:35.660 --> 00:38:38.020]   I don't know why I didn't show those, maybe.
[00:38:38.020 --> 00:38:41.100]   I have a Nexus 6, 6p.
[00:38:41.100 --> 00:38:42.100]   Maybe I gave away the 6p.
[00:38:42.100 --> 00:38:44.140]   I might have given away the 6p.
[00:38:44.140 --> 00:38:45.140]   So I kept the 6p.
[00:38:45.140 --> 00:38:49.940]   You know, by the way, looking at the phosphates to this list of O desserts for the O, there's
[00:38:49.940 --> 00:38:50.940]   not an obvious O.
[00:38:50.940 --> 00:38:51.940]   I know.
[00:38:51.940 --> 00:38:54.580]   I think Google wasn't thinking about this--
[00:38:54.580 --> 00:38:55.580]   What is--
[00:38:55.580 --> 00:38:57.060]   50 literation ago.
[00:38:57.060 --> 00:38:59.060]   Oly Bowl didn't jump out to you, Jeff.
[00:38:59.060 --> 00:39:00.620]   You're not a big Oly Bowl guy?
[00:39:00.620 --> 00:39:01.460]   No.
[00:39:01.460 --> 00:39:02.460]   No.
[00:39:02.460 --> 00:39:03.860]   That's a Dutch dessert.
[00:39:03.860 --> 00:39:05.180]   Yeah, it's good.
[00:39:05.180 --> 00:39:05.940]   Have you had it?
[00:39:05.940 --> 00:39:06.380]   Yeah.
[00:39:06.380 --> 00:39:07.140]   What is it?
[00:39:07.140 --> 00:39:08.620]   It's like--
[00:39:08.620 --> 00:39:10.500]   It's kind of like--
[00:39:10.500 --> 00:39:11.540]   It's like spry.
[00:39:11.540 --> 00:39:12.100]   It's powdered sugar and stuff.
[00:39:12.100 --> 00:39:18.420]   It's spelled so strangely that I can't imagine it would be a winner.
[00:39:18.420 --> 00:39:20.420]   I was thinking tepioca.
[00:39:20.420 --> 00:39:21.420]   Tepioca.
[00:39:21.420 --> 00:39:22.420]   Tepioca.
[00:39:22.420 --> 00:39:23.500]   That's a bit of a stretch.
[00:39:23.500 --> 00:39:24.500]   These do look good.
[00:39:24.500 --> 00:39:25.500]   They look like beignets kind of.
[00:39:25.500 --> 00:39:26.860]   They love to fry things now.
[00:39:26.860 --> 00:39:27.860]   They love to fry it and--
[00:39:27.860 --> 00:39:28.860]   Yeah.
[00:39:28.860 --> 00:39:29.860]   And they love to fry it.
[00:39:29.860 --> 00:39:30.860]   They're fantastic.
[00:39:30.860 --> 00:39:34.740]   They're with sugar to make them extra healthy.
[00:39:34.740 --> 00:39:40.340]   So when I went there for meetings and newspaper, their honor to you is to have a little beer
[00:39:40.340 --> 00:39:42.420]   in the afternoon and then they bring out the bitter bahlin.
[00:39:42.420 --> 00:39:44.140]   And it's just fried stuff.
[00:39:44.140 --> 00:39:45.940]   Just a whole bunch of fried stuff.
[00:39:45.940 --> 00:39:47.060]   It makes me happy.
[00:39:47.060 --> 00:39:51.940]   How does it happen that we in America are overweight and dying at younger and younger
[00:39:51.940 --> 00:39:56.620]   ages but that people in Holland are eating fried food like there's no tomorrow and they're
[00:39:56.620 --> 00:39:57.620]   healthy?
[00:39:57.620 --> 00:39:59.020]   What do we do wrong?
[00:39:59.020 --> 00:40:01.060]   I don't know.
[00:40:01.060 --> 00:40:02.220]   They ride their bikes.
[00:40:02.220 --> 00:40:04.620]   Yeah, they ride their bikes everywhere.
[00:40:04.620 --> 00:40:07.340]   So smart reply, that's not an O thing.
[00:40:07.340 --> 00:40:09.500]   That's just in Gmail where it answers you.
[00:40:09.500 --> 00:40:10.820]   So I want to quiz these guys.
[00:40:10.820 --> 00:40:12.900]   I said this on Twitter the other day.
[00:40:12.900 --> 00:40:19.300]   So have you used smart reply and do you feel guilty when you do?
[00:40:19.300 --> 00:40:21.580]   Anything to make my email faster, I don't care.
[00:40:21.580 --> 00:40:22.580]   I use it.
[00:40:22.580 --> 00:40:23.580]   I use it in the inbox.
[00:40:23.580 --> 00:40:24.580]   Yeah.
[00:40:24.580 --> 00:40:25.580]   It's pretty nice.
[00:40:25.580 --> 00:40:28.340]   So now it's in the inbox now but it'll be part of your regular Gmail soon.
[00:40:28.340 --> 00:40:30.100]   I usually ignore it.
[00:40:30.100 --> 00:40:31.940]   I almost never use it.
[00:40:31.940 --> 00:40:32.940]   I almost never use it.
[00:40:32.940 --> 00:40:35.420]   They didn't show the most felicitous example on the stage.
[00:40:35.420 --> 00:40:36.660]   It said it was a thing.
[00:40:36.660 --> 00:40:38.900]   You want to go to the Go Sea whoever is.
[00:40:38.900 --> 00:40:41.940]   Jane Smokers on Saturday or Sunday, which day.
[00:40:41.940 --> 00:40:44.380]   And then the three responses were Saturday.
[00:40:44.380 --> 00:40:46.900]   No, no, no, no, they were Saturday.
[00:40:46.900 --> 00:40:48.820]   I don't care Saturday.
[00:40:48.820 --> 00:40:50.900]   I don't care what day and whatever.
[00:40:50.900 --> 00:40:54.140]   There wasn't the most useful.
[00:40:54.140 --> 00:40:58.060]   The even Google which arguably has one of the best AI.
[00:40:58.060 --> 00:41:00.060]   And that was the example they chose.
[00:41:00.060 --> 00:41:02.060]   It's still bad.
[00:41:02.060 --> 00:41:03.060]   Yeah.
[00:41:03.060 --> 00:41:05.860]   My argument is that Google already knew you were busy on Sunday.
[00:41:05.860 --> 00:41:08.500]   Maybe he's looking at your yard.
[00:41:08.500 --> 00:41:09.500]   It could.
[00:41:09.500 --> 00:41:14.500]   Oh, we were talking about, oh, notification dots.
[00:41:14.500 --> 00:41:16.500]   So this is something that's what I have.
[00:41:16.500 --> 00:41:19.660]   The iPhone has had notification dots since it started.
[00:41:19.660 --> 00:41:22.260]   These are little badges that tell you you've got something.
[00:41:22.260 --> 00:41:26.940]   And if you press on them, if you press on like three days a bunch, yeah, you'll get a
[00:41:26.940 --> 00:41:34.140]   new set menu, which so you could argue because Google has had long press for a while, right?
[00:41:34.140 --> 00:41:35.140]   Or that came out in an end.
[00:41:35.140 --> 00:41:36.780]   Yeah, but there's not Jeff.
[00:41:36.780 --> 00:41:37.780]   Jeff's showing it.
[00:41:37.780 --> 00:41:38.780]   Not open.
[00:41:38.780 --> 00:41:39.780]   You can't see it.
[00:41:39.780 --> 00:41:41.620]   No, not on the app icon like this.
[00:41:41.620 --> 00:41:42.620]   I kind of like this.
[00:41:42.620 --> 00:41:44.020]   I would use that.
[00:41:44.020 --> 00:41:45.700]   Do you use it on your iPhone?
[00:41:45.700 --> 00:41:50.820]   No, because 3D touch is too weird on the iPhone.
[00:41:50.820 --> 00:41:54.140]   It's too finicky because it gives you the feedback and if it's finicky, it's like, do
[00:41:54.140 --> 00:41:55.140]   I press hard?
[00:41:55.140 --> 00:41:56.140]   Do I press light?
[00:41:56.140 --> 00:41:57.140]   Do I just touch and hold?
[00:41:57.140 --> 00:41:59.540]   You get a start soft and then you go hard.
[00:41:59.540 --> 00:42:00.540]   That's the vibe.
[00:42:00.540 --> 00:42:01.540]   I use it all the time.
[00:42:01.540 --> 00:42:02.540]   It's great.
[00:42:02.540 --> 00:42:03.540]   You like it.
[00:42:03.540 --> 00:42:04.540]   Yeah.
[00:42:04.540 --> 00:42:07.220]   It's a lot of double tapping the home button switch apps.
[00:42:07.220 --> 00:42:09.120]   You can press from the left side of the screen.
[00:42:09.120 --> 00:42:10.120]   Oh, yeah, that is nice.
[00:42:10.120 --> 00:42:11.120]   It gets the next app.
[00:42:11.120 --> 00:42:12.120]   It never works.
[00:42:12.120 --> 00:42:14.540]   It never does that for me unless I don't want it to do it.
[00:42:14.540 --> 00:42:16.140]   And then it does it.
[00:42:16.140 --> 00:42:17.980]   Drives me nuts.
[00:42:17.980 --> 00:42:19.060]   Okay.
[00:42:19.060 --> 00:42:20.880]   So you, but you know, do you like it?
[00:42:20.880 --> 00:42:21.880]   I like it.
[00:42:21.880 --> 00:42:24.380]   I think iPhone users generally like 3D touch.
[00:42:24.380 --> 00:42:29.660]   I just, I feel like it's to me, the long, this basically is the same, but it's long press,
[00:42:29.660 --> 00:42:30.660]   right?
[00:42:30.660 --> 00:42:31.660]   Yeah.
[00:42:31.660 --> 00:42:32.660]   Because there's no, you can't press harder or softer.
[00:42:32.660 --> 00:42:33.660]   Yep.
[00:42:33.660 --> 00:42:34.660]   And it makes sense.
[00:42:34.660 --> 00:42:38.220]   Long press pops up an extra menu of, of context sensitive things.
[00:42:38.220 --> 00:42:39.220]   I don't know.
[00:42:39.220 --> 00:42:41.180]   That just makes sense to me.
[00:42:41.180 --> 00:42:45.380]   But see, Google can do that because they don't have the jiggle jiggle jiggle.
[00:42:45.380 --> 00:42:46.820]   The iPhone has the jiggle jiggle jiggle.
[00:42:46.820 --> 00:42:47.820]   That was so good.
[00:42:47.820 --> 00:42:52.980]   Which I think is more confusing because then you've got like two actions that are roughly
[00:42:52.980 --> 00:42:53.980]   the same.
[00:42:53.980 --> 00:42:54.980]   That's why I get confused.
[00:42:54.980 --> 00:42:57.100]   So if you, you don't pray, you can't press.
[00:42:57.100 --> 00:43:02.140]   If you put your finger on an icon on the iPhone and hold it for a while, the icon goes like
[00:43:02.140 --> 00:43:04.340]   this and you can delete it or move it.
[00:43:04.340 --> 00:43:05.580]   You have to do that to delete or move it.
[00:43:05.580 --> 00:43:08.580]   On Google, you just drag it around.
[00:43:08.580 --> 00:43:09.580]   I don't know.
[00:43:09.580 --> 00:43:14.220]   Although I feel like one of the reasons why maybe Google doesn't have the same sort of
[00:43:14.220 --> 00:43:18.020]   3D touch thing is because they're going to have to always operating system out to devices
[00:43:18.020 --> 00:43:21.140]   that won't have that extra sense of the display, right?
[00:43:21.140 --> 00:43:22.140]   That's right.
[00:43:22.140 --> 00:43:23.140]   You can't count on that hardware.
[00:43:23.140 --> 00:43:26.580]   But if we ever get to a point where we have like no bezels, no buttons, you're going to
[00:43:26.580 --> 00:43:28.180]   want that's the advantage.
[00:43:28.180 --> 00:43:29.780]   Apple has to make all the hardware.
[00:43:29.780 --> 00:43:34.260]   They know their phones can have that capability, although, you know, iPhone 6s don't.
[00:43:34.260 --> 00:43:38.380]   But they know that they can, they can dictate the hardware platform in a way Google can.
[00:43:38.380 --> 00:43:46.180]   Notification dots is an example of the most incremental kind of not very exciting improvement.
[00:43:46.180 --> 00:43:48.260]   So what else is in O?
[00:43:48.260 --> 00:43:51.500]   Well, I mean, that's kind of where Android's been the last few years.
[00:43:51.500 --> 00:43:55.180]   For booster boot time, it's a really good operating system and they're just generating
[00:43:55.180 --> 00:43:56.180]   and making it better.
[00:43:56.180 --> 00:43:58.260]   Or peak, or peak operating system.
[00:43:58.260 --> 00:43:59.660]   It works in the peak.
[00:43:59.660 --> 00:44:00.860]   Well, it looks good.
[00:44:00.860 --> 00:44:01.860]   Yeah.
[00:44:01.860 --> 00:44:06.140]   What's the install base for iOS now?
[00:44:06.140 --> 00:44:09.060]   I can ask the Google.
[00:44:09.060 --> 00:44:12.900]   Okay, Google.
[00:44:12.900 --> 00:44:16.500]   How many iOS users are there?
[00:44:16.500 --> 00:44:17.500]   I think we...
[00:44:17.500 --> 00:44:24.020]   Android holds the largest number of install base devices with 1.9 billion in use in 2014
[00:44:24.020 --> 00:44:26.580]   compared with 682 million iOS.
[00:44:26.580 --> 00:44:27.580]   Mac OS is...
[00:44:27.580 --> 00:44:29.340]   That's a big difference.
[00:44:29.340 --> 00:44:30.340]   In 2014.
[00:44:30.340 --> 00:44:33.540]   Well, they don't have the newest.
[00:44:33.540 --> 00:44:34.980]   So here's the question.
[00:44:34.980 --> 00:44:39.500]   Is it still the case that developers do iOS first or is that starting to wear off now?
[00:44:39.500 --> 00:44:40.700]   I think that's still the case.
[00:44:40.700 --> 00:44:41.700]   Because you know why?
[00:44:41.700 --> 00:44:42.700]   It's money.
[00:44:42.700 --> 00:44:43.700]   Yeah.
[00:44:43.700 --> 00:44:44.860]   The iOS users are more...
[00:44:44.860 --> 00:44:49.860]   The problem with Android is that 2 billion number, as we said at the very beginning, is
[00:44:49.860 --> 00:44:55.140]   such a large number of people who own $50 phones who never buy apps that you can't really
[00:44:55.140 --> 00:44:57.780]   use that as informative.
[00:44:57.780 --> 00:45:02.940]   Yeah, one of the things I was looking for in the I/O keynote, which I never saw, was
[00:45:02.940 --> 00:45:07.420]   Google coming out and saying, "Hey, please kick an ass and here's how much money developers
[00:45:07.420 --> 00:45:09.420]   made and we paid out to developers this year."
[00:45:09.420 --> 00:45:10.780]   Apple tells you that very quickly.
[00:45:10.780 --> 00:45:12.340]   Apple will do that at I/O.
[00:45:12.340 --> 00:45:13.740]   And I was waiting for that at...
[00:45:13.740 --> 00:45:14.740]   I mean, at WWDC.
[00:45:14.740 --> 00:45:18.220]   I was waiting for that at I/O and it never came.
[00:45:18.220 --> 00:45:23.580]   Apple on the other hand, kind of does overstate the strength of the app store economy.
[00:45:23.580 --> 00:45:30.900]   They have a new page touting and I'm sure that this is really for the US government, for
[00:45:30.900 --> 00:45:32.620]   the benefit of...
[00:45:32.620 --> 00:45:37.300]   It's their 2 million page where it's apple.com/jobcreation.
[00:45:37.300 --> 00:45:44.660]   2 million US jobs and counting, which sounds good, right, until you look at the breakdown,
[00:45:44.660 --> 00:45:46.580]   which is 80,000 Apple employees.
[00:45:46.580 --> 00:45:48.620]   That includes retail.
[00:45:48.620 --> 00:45:49.620]   Then suppliers, 450,000.
[00:45:49.620 --> 00:45:53.980]   How many people work at UPS and FedEx to deliver the iPhones?
[00:45:53.980 --> 00:46:01.380]   Of the 2 million, more than three quarters, they attribute to the app store ecosystem.
[00:46:01.380 --> 00:46:02.380]   What?
[00:46:02.380 --> 00:46:03.740]   So, is that like developed?
[00:46:03.740 --> 00:46:08.220]   That's like some guy writing a calculator app who was making diddly do-do.
[00:46:08.220 --> 00:46:10.220]   Oh, that's BS.
[00:46:10.220 --> 00:46:11.220]   Well, but they made...
[00:46:11.220 --> 00:46:12.220]   That's like creating some club...
[00:46:12.220 --> 00:46:13.220]   That's like creating some club...
[00:46:13.220 --> 00:46:14.220]   That's like creating some club...
[00:46:14.220 --> 00:46:15.220]   That's like creating some club...
[00:46:15.220 --> 00:46:16.220]   The great.
[00:46:16.220 --> 00:46:18.500]   Well, it's clearly for the benefit of the Trump administration.
[00:46:18.500 --> 00:46:21.780]   So that, you know, I see we're creating jobs.
[00:46:21.780 --> 00:46:24.180]   I mean, they were doing this before.
[00:46:24.180 --> 00:46:28.020]   It just feels like a page that was designed by lobbyists.
[00:46:28.020 --> 00:46:37.820]   Yeah, Alaska, 74 Apple employees, 11 suppliers, but 1,000 app store ecosystem jobs.
[00:46:37.820 --> 00:46:39.060]   Yes.
[00:46:39.060 --> 00:46:44.660]   You know, we're making it safe to work in Alaska again.
[00:46:44.660 --> 00:46:47.580]   So anyway, I don't know how I got into this.
[00:46:47.580 --> 00:46:48.580]   I'm sorry.
[00:46:48.580 --> 00:46:49.580]   Let's see.
[00:46:49.580 --> 00:46:50.980]   Dip and dots.
[00:46:50.980 --> 00:46:52.460]   What else for Android O?
[00:46:52.460 --> 00:46:54.100]   Dip and dots.
[00:46:54.100 --> 00:46:59.220]   Can we go back and rename Android D?
[00:46:59.220 --> 00:47:00.220]   What was D?
[00:47:00.220 --> 00:47:01.220]   Donut.
[00:47:01.220 --> 00:47:03.180]   Let's call it dip and dots.
[00:47:03.180 --> 00:47:06.220]   They announced a VR headset that is standalone.
[00:47:06.220 --> 00:47:08.620]   They didn't announce a price or availability.
[00:47:08.620 --> 00:47:15.900]   They did say that it will be made by at least HTC, who makes the Vive, and Lenovo, who
[00:47:15.900 --> 00:47:19.180]   makes the Motorola phones.
[00:47:19.180 --> 00:47:25.460]   To me, this is an education play because I don't, you know, daydream, if you've got
[00:47:25.460 --> 00:47:31.260]   a smartphone is cheap, you just plop your smartphone in, but they pitched daydream at
[00:47:31.260 --> 00:47:34.940]   schools, but what they don't mention is that each and every one of you has to have an $800
[00:47:34.940 --> 00:47:35.940]   phone.
[00:47:35.940 --> 00:47:36.940]   Yeah.
[00:47:36.940 --> 00:47:40.260]   Meanwhile, schools that would like to use some, there's some very nice curriculum.
[00:47:40.260 --> 00:47:41.460]   There's the, what do they call it?
[00:47:41.460 --> 00:47:43.780]   Google expeditions where you can travel the world.
[00:47:43.780 --> 00:47:47.580]   There's some great daydream curriculum, but you know, a school can't assume that every
[00:47:47.580 --> 00:47:51.380]   kid's going to have a smartphone, let alone a tiny market.
[00:47:51.380 --> 00:47:52.380]   Tiny market.
[00:47:52.380 --> 00:47:55.340]   So I don't think this is a big market, but I think it, I think they figure, well, we
[00:47:55.340 --> 00:47:59.060]   can count on four or five units to, you know, many schools in the country.
[00:47:59.060 --> 00:48:01.100]   So we can have a little Google museums too.
[00:48:01.100 --> 00:48:02.100]   Museums?
[00:48:02.100 --> 00:48:03.100]   Sure.
[00:48:03.100 --> 00:48:08.220]   Well, it's also just kind of although do you want people walking around blind in your museum?
[00:48:08.220 --> 00:48:09.220]   Yeah.
[00:48:09.220 --> 00:48:15.060]   Going to compete in VR, whatever its future looks like, whether it's at home or in schools
[00:48:15.060 --> 00:48:19.620]   or in museums or whatever, you're going to have to have a wireless headset because Oculus
[00:48:19.620 --> 00:48:20.620]   is working on it.
[00:48:20.620 --> 00:48:21.620]   You know, everyone who's working on it.
[00:48:21.620 --> 00:48:22.820]   But Oculus doesn't have it.
[00:48:22.820 --> 00:48:24.540]   HTC doesn't have it.
[00:48:24.540 --> 00:48:26.940]   I mean, Oculus had a running demo.
[00:48:26.940 --> 00:48:27.940]   Microsoft doesn't have it.
[00:48:27.940 --> 00:48:32.460]   Oculus had a running demo at some of their previous developer conferences.
[00:48:32.460 --> 00:48:34.220]   So it isn't on sale yet.
[00:48:34.220 --> 00:48:35.220]   Right.
[00:48:35.220 --> 00:48:38.340]   But they actually showed one you could try out at Google I/O.
[00:48:38.340 --> 00:48:41.780]   They just said, well, it exists and we have the technology and we're working with hardware
[00:48:41.780 --> 00:48:44.140]   partners, but we're not going to show you what it looks like and you're not going to
[00:48:44.140 --> 00:48:45.260]   get to try one out yet.
[00:48:45.260 --> 00:48:46.260]   So, you know.
[00:48:46.260 --> 00:48:47.860]   But we got it, honest.
[00:48:47.860 --> 00:48:51.100]   Like, it wasn't a surprise at all that they announced it.
[00:48:51.100 --> 00:48:53.260]   It was kind of what they had to do.
[00:48:53.260 --> 00:48:54.500]   But I don't think it's a big market.
[00:48:54.500 --> 00:48:55.500]   No.
[00:48:55.500 --> 00:48:56.500]   Right.
[00:48:56.500 --> 00:48:57.500]   No.
[00:48:57.500 --> 00:48:58.500]   It's not end users.
[00:48:58.500 --> 00:49:00.620]   I think end users almost all have a smartphone that's daydream capable.
[00:49:00.620 --> 00:49:02.380]   The S8 will be daydream capable.
[00:49:02.380 --> 00:49:04.820]   LG is going to make daydream capable.
[00:49:04.820 --> 00:49:08.220]   It's next generation, the flagship.
[00:49:08.220 --> 00:49:11.380]   And if you don't have daydream, if you have Samsung, you can use the Gear VR.
[00:49:11.380 --> 00:49:13.620]   I don't know.
[00:49:13.620 --> 00:49:14.620]   Maybe there's a market.
[00:49:14.620 --> 00:49:15.620]   I don't see.
[00:49:15.620 --> 00:49:17.300]   I'm still skeptical about VR in general.
[00:49:17.300 --> 00:49:19.540]   I'm much more excited about AR.
[00:49:19.540 --> 00:49:21.540]   Mm-hmm.
[00:49:21.540 --> 00:49:22.540]   What else about O?
[00:49:22.540 --> 00:49:23.540]   Nothing else.
[00:49:23.540 --> 00:49:27.580]   Well, one of the cool things about the headset was that the sensors for this headset are
[00:49:27.580 --> 00:49:28.820]   built into the headset.
[00:49:28.820 --> 00:49:32.820]   So, unlike what Oculus is doing or what HTC is doing with their wireless headset.
[00:49:32.820 --> 00:49:35.020]   You have to have a camera out there.
[00:49:35.020 --> 00:49:36.020]   Exactly.
[00:49:36.020 --> 00:49:37.620]   You don't need the sensors in your living room.
[00:49:37.620 --> 00:49:38.620]   So I have in my living room-
[00:49:38.620 --> 00:49:39.620]   Oh, my God.
[00:49:39.620 --> 00:49:40.620]   I'm making more convenient.
[00:49:40.620 --> 00:49:43.420]   Two Vive sensors nailed to the wall.
[00:49:43.420 --> 00:49:44.420]   Ha!
[00:49:44.420 --> 00:49:45.420]   Ah!
[00:49:45.420 --> 00:49:46.420]   Yeah.
[00:49:46.420 --> 00:49:47.420]   It went to room.
[00:49:47.420 --> 00:49:48.420]   Well, where else?
[00:49:48.420 --> 00:49:49.420]   The VR room.
[00:49:49.420 --> 00:49:50.420]   Oh, no.
[00:49:50.420 --> 00:49:51.420]   Well, I just-
[00:49:51.420 --> 00:49:52.420]   Oh, no.
[00:49:52.420 --> 00:49:53.420]   It's a game room.
[00:49:53.420 --> 00:49:55.860]   But the problem with Vive is you need a lot of room.
[00:49:55.860 --> 00:49:59.060]   You need like a 6x9 space that's cleared.
[00:49:59.060 --> 00:50:01.620]   So we have to shove those chairs out of the way.
[00:50:01.620 --> 00:50:02.980]   And it's- you know what?
[00:50:02.980 --> 00:50:03.980]   I brought it in here.
[00:50:03.980 --> 00:50:04.980]   It's here.
[00:50:04.980 --> 00:50:05.980]   Yeah.
[00:50:05.980 --> 00:50:06.980]   I didn't bring the end.
[00:50:06.980 --> 00:50:12.500]   I still have them hanging on the wall just in case.
[00:50:12.500 --> 00:50:15.500]   Anything else about Google I/O we want to talk about before we move on to other-
[00:50:15.500 --> 00:50:16.500]   Well, I didn't know.
[00:50:16.500 --> 00:50:17.500]   So I saw a stripe.
[00:50:17.500 --> 00:50:18.500]   I don't know if this was Google I/O.
[00:50:18.500 --> 00:50:19.500]   We're not, but I just saw this.
[00:50:19.500 --> 00:50:20.500]   That they redesigned emojis.
[00:50:20.500 --> 00:50:21.500]   Did you see that one?
[00:50:21.500 --> 00:50:23.500]   Bottom of the Google session?
[00:50:23.500 --> 00:50:24.500]   Oh, yeah.
[00:50:24.500 --> 00:50:27.100]   It's part of Android O and they updated.
[00:50:27.100 --> 00:50:28.100]   So they had like-
[00:50:28.100 --> 00:50:29.100]   That's what I was.
[00:50:29.100 --> 00:50:30.100]   One of my last days.
[00:50:30.100 --> 00:50:31.580]   One of my last days was a little blob basically.
[00:50:31.580 --> 00:50:40.700]   And now an O or smiley face will be a circular kind of more apple-like face.
[00:50:40.700 --> 00:50:41.700]   So it won't-
[00:50:41.700 --> 00:50:43.900]   I think the burrito is much.
[00:50:43.900 --> 00:50:44.900]   Here's the burrito.
[00:50:44.900 --> 00:50:47.980]   I think the burritos is now wrapped in foil.
[00:50:47.980 --> 00:50:48.980]   Oh, that's a good idea.
[00:50:48.980 --> 00:50:49.980]   It has delicious toppings.
[00:50:49.980 --> 00:50:50.980]   Oh, cheese.
[00:50:50.980 --> 00:50:52.980]   Oh, it's a better color.
[00:50:52.980 --> 00:50:54.980]   Oh, it's a l'Oreal.
[00:50:54.980 --> 00:50:55.980]   A l'Oreal or whatever.
[00:50:55.980 --> 00:50:56.980]   Oh, it's like a l'Oreal.
[00:50:56.980 --> 00:50:57.980]   Oh, it's a l'Oreal.
[00:50:57.980 --> 00:51:02.700]   Oh, it's a l'Oreal or whatever an L'Oreal.
[00:51:02.700 --> 00:51:03.700]   I don't know.
[00:51:03.700 --> 00:51:04.700]   I'm making up names.
[00:51:04.700 --> 00:51:07.340]   They have a breastfeeding one now.
[00:51:07.340 --> 00:51:08.860]   Oh, they do.
[00:51:08.860 --> 00:51:09.860]   This was controversial.
[00:51:09.860 --> 00:51:16.700]   I remember we talked to the emoji guy from the Unicode emoji committee and he said,
[00:51:16.700 --> 00:51:21.980]   "Initially, we wanted the breastfeeding emoji to be gender neutral."
[00:51:21.980 --> 00:51:22.980]   And the only way they could think of-
[00:51:22.980 --> 00:51:23.980]   Well-
[00:51:23.980 --> 00:51:25.540]   To do that was cutting the head off.
[00:51:25.540 --> 00:51:28.220]   So you had a headless person feeding a baby.
[00:51:28.220 --> 00:51:29.580]   It didn't look good.
[00:51:29.580 --> 00:51:31.140]   Well, wait, wait, wait, wait, wait, wait.
[00:51:31.140 --> 00:51:36.020]   That makes no sense, Leo.
[00:51:36.020 --> 00:51:39.620]   I am not going to wade into this one at all.
[00:51:39.620 --> 00:51:41.620]   But I have been told that men can't-
[00:51:41.620 --> 00:51:42.620]   A man can't-
[00:51:42.620 --> 00:51:43.620]   A man can't feed.
[00:51:43.620 --> 00:51:44.620]   Do it.
[00:51:44.620 --> 00:51:45.620]   Some men.
[00:51:45.620 --> 00:51:47.780]   Let's talk about the panda emoji.
[00:51:47.780 --> 00:51:48.780]   [laughter]
[00:51:48.780 --> 00:51:49.780]   Please.
[00:51:49.780 --> 00:51:55.020]   Well, I think the breastfeeding emoji now does have a female head on it.
[00:51:55.020 --> 00:51:56.020]   Well, yeah.
[00:51:56.020 --> 00:51:57.020]   What's going on here?
[00:51:57.020 --> 00:51:58.020]   What do you think?
[00:51:58.020 --> 00:51:59.020]   What's-
[00:51:59.020 --> 00:52:00.020]   Oh, that's the massage emoji.
[00:52:00.020 --> 00:52:01.020]   That one's been around for quite a while.
[00:52:01.020 --> 00:52:02.020]   Oh, I see.
[00:52:02.020 --> 00:52:05.100]   You know, you kids today, you know this stuff.
[00:52:05.100 --> 00:52:07.020]   Is she making fried egg?
[00:52:07.020 --> 00:52:08.020]   Yep.
[00:52:08.020 --> 00:52:09.020]   She's looking.
[00:52:09.020 --> 00:52:10.940]   It's kind of sticky holding there right in the pan when she holds it up.
[00:52:10.940 --> 00:52:13.900]   They also animated them a lot down below in the story.
[00:52:13.900 --> 00:52:15.420]   Oh, there's some animated emojis?
[00:52:15.420 --> 00:52:16.420]   Yeah.
[00:52:16.420 --> 00:52:17.420]   Yeah.
[00:52:17.420 --> 00:52:18.420]   Nice ones.
[00:52:18.420 --> 00:52:21.180]   What does it say about the world that we're worried about this?
[00:52:21.180 --> 00:52:23.300]   I know.
[00:52:23.300 --> 00:52:27.980]   You know, Apple got a lot of press for iOS 9 and the redesigned emojis.
[00:52:27.980 --> 00:52:33.700]   In fact, the scandalously sexy dancing lady and the peach.
[00:52:33.700 --> 00:52:35.780]   Well, the peach went back and forth.
[00:52:35.780 --> 00:52:38.340]   Peach was some controversy.
[00:52:38.340 --> 00:52:40.340]   There was- Whoa.
[00:52:40.340 --> 00:52:41.340]   Whoa.
[00:52:41.340 --> 00:52:42.340]   Whoa.
[00:52:42.340 --> 00:52:43.340]   And is that me?
[00:52:43.340 --> 00:52:46.940]   Did I- Am I finally having acid flashbacks after?
[00:52:46.940 --> 00:52:47.940]   Because I've been waiting.
[00:52:47.940 --> 00:52:48.940]   Whoa, dude.
[00:52:48.940 --> 00:52:50.740]   They're just disappearing.
[00:52:50.740 --> 00:52:52.380]   Is that the animation or is that just me?
[00:52:52.380 --> 00:52:55.260]   Oh, so the previous one is the old style, the new ones.
[00:52:55.260 --> 00:52:56.780]   Oh, it's the change.
[00:52:56.780 --> 00:52:57.780]   Yeah.
[00:52:57.780 --> 00:52:58.780]   Oh, I get it.
[00:52:58.780 --> 00:53:01.420]   Yeah, these are more streamlined.
[00:53:01.420 --> 00:53:05.740]   So the gorilla doesn't look like it needs a haircut anymore.
[00:53:05.740 --> 00:53:08.020]   It looks like more of a- A clean cut gorilla.
[00:53:08.020 --> 00:53:09.580]   A clean cut gorilla.
[00:53:09.580 --> 00:53:11.940]   Not that just rolled out of bed gorilla.
[00:53:11.940 --> 00:53:12.940]   Yeah.
[00:53:12.940 --> 00:53:14.860]   Bedhead gorilla.
[00:53:14.860 --> 00:53:18.740]   You don't want a bedhead gorilla.
[00:53:18.740 --> 00:53:19.940]   Bye-bye blobs.
[00:53:19.940 --> 00:53:20.940]   Hello.
[00:53:20.940 --> 00:53:22.940]   Yeah, see, there's a squishy circles.
[00:53:22.940 --> 00:53:24.580]   There's the blobs all the time you guys about.
[00:53:24.580 --> 00:53:25.580]   Those are gone.
[00:53:25.580 --> 00:53:26.820]   I kind of like the blobs.
[00:53:26.820 --> 00:53:27.820]   They were unique.
[00:53:27.820 --> 00:53:28.820]   Nobody else.
[00:53:28.820 --> 00:53:29.820]   No other operating system.
[00:53:29.820 --> 00:53:30.820]   Oh, I didn't like them.
[00:53:30.820 --> 00:53:31.820]   That's right.
[00:53:31.820 --> 00:53:32.820]   Google, they looked like the tip of your thumb.
[00:53:32.820 --> 00:53:35.340]   They looked like you painted a face on the tip of your thumb.
[00:53:35.340 --> 00:53:36.340]   I hated those.
[00:53:36.340 --> 00:53:38.060]   So then they were- Or without really bad candy.
[00:53:38.060 --> 00:53:40.900]   Yeah, they're now back to the traditional round.
[00:53:40.900 --> 00:53:41.900]   Yeah.
[00:53:41.900 --> 00:53:42.900]   You didn't mind those?
[00:53:42.900 --> 00:53:43.900]   No.
[00:53:43.900 --> 00:53:45.820]   You ever paint a face on the tip of your thumb?
[00:53:45.820 --> 00:53:46.820]   Do a little puppet show?
[00:53:46.820 --> 00:53:47.820]   When I was like a kindergarten, I think.
[00:53:47.820 --> 00:53:48.820]   Yeah.
[00:53:48.820 --> 00:53:49.820]   Maybe.
[00:53:49.820 --> 00:53:53.220]   Wow, they spent a lot of time on this blog post.
[00:53:53.220 --> 00:53:54.220]   What?
[00:53:54.220 --> 00:53:55.220]   Thump puppet traumatic experience.
[00:53:55.220 --> 00:53:56.220]   You have it.
[00:53:56.220 --> 00:53:58.460]   It's a piece of blob so much.
[00:53:58.460 --> 00:53:59.460]   I don't like it.
[00:53:59.460 --> 00:54:01.380]   It looks back story- It's truncated.
[00:54:01.380 --> 00:54:02.380]   You're scary.
[00:54:02.380 --> 00:54:03.380]   It's like a chug.
[00:54:03.380 --> 00:54:05.380]   Oh, look.
[00:54:05.380 --> 00:54:07.180]   Reusable components.
[00:54:07.180 --> 00:54:09.060]   Oh.
[00:54:09.060 --> 00:54:13.020]   Which is something that we've seen in some iMessage apps actually.
[00:54:13.020 --> 00:54:14.020]   Are you kidding me?
[00:54:14.020 --> 00:54:15.020]   Yeah.
[00:54:15.020 --> 00:54:18.940]   Wow, you pay way too much attention to this.
[00:54:18.940 --> 00:54:24.500]   We've shared many of the i and mouse components between expression and animal emoji.
[00:54:24.500 --> 00:54:25.500]   Yeah.
[00:54:25.500 --> 00:54:29.860]   So one of our good friends, both Mark and I, makes an iMessage app that allows you to
[00:54:29.860 --> 00:54:31.980]   put on sunglasses and hats and all sorts of stuff.
[00:54:31.980 --> 00:54:32.980]   Oh, neat.
[00:54:32.980 --> 00:54:33.980]   What's that called?
[00:54:33.980 --> 00:54:34.980]   Stickerpals?
[00:54:34.980 --> 00:54:35.980]   Oh, yeah.
[00:54:35.980 --> 00:54:36.980]   Yeah.
[00:54:36.980 --> 00:54:37.980]   You told me about that.
[00:54:37.980 --> 00:54:38.980]   Yeah, yeah.
[00:54:38.980 --> 00:54:39.980]   Yeah.
[00:54:39.980 --> 00:54:40.980]   Yeah.
[00:54:40.980 --> 00:54:41.980]   I love Phil.
[00:54:41.980 --> 00:54:42.980]   Yeah, he's a huge fan of yours.
[00:54:42.980 --> 00:54:43.980]   Oh, we should have him on.
[00:54:43.980 --> 00:54:44.980]   He did the original camera plus.
[00:54:44.980 --> 00:54:45.980]   Yeah, he did camera plus.
[00:54:45.980 --> 00:54:46.980]   Yeah.
[00:54:46.980 --> 00:54:47.980]   And his team's also- Clear.
[00:54:47.980 --> 00:54:48.980]   That to- Do list?
[00:54:48.980 --> 00:54:49.980]   Yeah.
[00:54:49.980 --> 00:54:50.980]   I loved that.
[00:54:50.980 --> 00:54:53.020]   And they're working on Heads Up right now.
[00:54:53.020 --> 00:54:55.420]   So does he develop- He only iOS, right?
[00:54:55.420 --> 00:54:56.980]   I don't think he does any Android stuff.
[00:54:56.980 --> 00:54:58.620]   Heads Up is on Android now.
[00:54:58.620 --> 00:54:59.620]   Okay.
[00:54:59.620 --> 00:55:00.620]   It was a different team that worked on it.
[00:55:00.620 --> 00:55:01.620]   It was a different team?
[00:55:01.620 --> 00:55:02.620]   Okay.
[00:55:02.620 --> 00:55:04.940]   They don't like to mix Android and iOS types.
[00:55:04.940 --> 00:55:06.420]   They don't get all- Down across the stream.
[00:55:06.420 --> 00:55:07.420]   Down across the stream.
[00:55:07.420 --> 00:55:08.420]   Yes.
[00:55:08.420 --> 00:55:10.220]   Oh, here's the breastfeeding emoji.
[00:55:10.220 --> 00:55:11.220]   Yeah, that's nice.
[00:55:11.220 --> 00:55:12.220]   See, that's a lady.
[00:55:12.220 --> 00:55:13.220]   Nice, baby.
[00:55:13.220 --> 00:55:15.580]   She's got a peaceful smile.
[00:55:15.580 --> 00:55:19.980]   And there's the hedgehog, the zombie, the exploding head, the vampire.
[00:55:19.980 --> 00:55:20.980]   I like that one.
[00:55:20.980 --> 00:55:21.980]   Exploiting Ted.
[00:55:21.980 --> 00:55:22.980]   Yeah, that's you.
[00:55:22.980 --> 00:55:26.220]   I think they used you as the model for that.
[00:55:26.220 --> 00:55:27.220]   Hey, hey.
[00:55:27.220 --> 00:55:29.100]   That's a Jarvis rant emoji.
[00:55:29.100 --> 00:55:31.580]   All right.
[00:55:31.580 --> 00:55:34.940]   This is, for some reason, a medium post.
[00:55:34.940 --> 00:55:36.940]   You saw the New York Times article.
[00:55:36.940 --> 00:55:40.580]   Ev Williams says the internet's all screwed up, but he's going to save it?
[00:55:40.580 --> 00:55:42.540]   Well, it's also his fault that it's screwed up.
[00:55:42.540 --> 00:55:45.180]   I'd say that with all love and respect for Ev.
[00:55:45.180 --> 00:55:50.260]   But when he started Medium, I said that it was his penance for giving us Twitter and
[00:55:50.260 --> 00:55:51.260]   the blogger.
[00:55:51.260 --> 00:55:52.780]   And I think that's what he's saying there.
[00:55:52.780 --> 00:55:57.380]   The internet is broken at Ev is trying to salvage it.
[00:55:57.380 --> 00:55:58.860]   It's the question we've always asked.
[00:55:58.860 --> 00:56:01.460]   You give people more communication.
[00:56:01.460 --> 00:56:03.220]   What good or bad comes from that?
[00:56:03.220 --> 00:56:04.220]   That's what it was.
[00:56:04.220 --> 00:56:07.660]   Ev Williams, of course, founded Blogger, sold that to Google, stayed for a few years.
[00:56:07.660 --> 00:56:13.940]   Then he founded something called Odeo, which was a little remembered, much beloved, at
[00:56:13.940 --> 00:56:15.940]   least by me, podcast directory.
[00:56:15.940 --> 00:56:18.780]   Imagine how big that would be today.
[00:56:18.780 --> 00:56:22.060]   Odeo flopped because iTunes killed it.
[00:56:22.060 --> 00:56:27.100]   Ev famously gave the money back to the investors, which I think was a very good move.
[00:56:27.100 --> 00:56:33.060]   And one of his colleagues had this idea for a text.
[00:56:33.060 --> 00:56:36.900]   The reason I know this, I was just going back and listening to our interview with Ev back
[00:56:36.900 --> 00:56:40.100]   in 2007 when Twitter had just come out.
[00:56:40.100 --> 00:56:42.380]   And was it Jack or--
[00:56:42.380 --> 00:56:43.380]   I can't remember who--
[00:56:43.380 --> 00:56:44.380]   Jack came up with the idea.
[00:56:44.380 --> 00:56:45.380]   Was it Jack?
[00:56:45.380 --> 00:56:48.820]   Jack Dorsey had this idea for something TWTTR.
[00:56:48.820 --> 00:56:51.620]   And Ev said, well, you know, we got-- let's try it.
[00:56:51.620 --> 00:56:52.620]   And it was an Odeo.
[00:56:52.620 --> 00:56:55.660]   Obvious was the name of his company, Odeo, a production.
[00:56:55.660 --> 00:57:00.380]   And look at Lo and Behold, you know, 10 years later, Twitter is all that.
[00:57:00.380 --> 00:57:04.140]   But Ev says, "I think the internet is broken."
[00:57:04.140 --> 00:57:07.460]   He's believed this for a few years, actually, but things are getting worse, according to
[00:57:07.460 --> 00:57:08.460]   the Times.
[00:57:08.460 --> 00:57:14.100]   It's a lot more obvious, get it, to a lot of people, that it's broken.
[00:57:14.100 --> 00:57:17.780]   Why does he see-- he says it's broken because people are using Facebook to show suicides,
[00:57:17.780 --> 00:57:19.620]   beatings, and murder in real time.
[00:57:19.620 --> 00:57:24.860]   Twitter is a hive of trolling and abuse, fake news, whether created for ideology or profit
[00:57:24.860 --> 00:57:26.020]   runs rampant.
[00:57:26.020 --> 00:57:32.980]   Four out of 10 adult internet users told the Pew survey they've been harassed online.
[00:57:32.980 --> 00:57:36.980]   I thought, quote, "I thought once everybody could speak freely and exchange information
[00:57:36.980 --> 00:57:39.220]   and ideas, the world is automatically going to be a better place."
[00:57:39.220 --> 00:57:40.740]   We all thought that, didn't we?
[00:57:40.740 --> 00:57:41.740]   Yep, yep.
[00:57:41.740 --> 00:57:44.460]   I was wrong about that, says Ev Williams.
[00:57:44.460 --> 00:57:45.900]   So what's he doing to fix it?
[00:57:45.900 --> 00:57:46.900]   Medium?
[00:57:46.900 --> 00:57:49.300]   Well, he's trying to figure out the business model.
[00:57:49.300 --> 00:57:50.700]   Still, you know, I was thinking about this.
[00:57:50.700 --> 00:57:54.020]   The counterintuitive business model?
[00:57:54.020 --> 00:57:56.300]   He's trying to find a membership structure and all that.
[00:57:56.300 --> 00:58:00.540]   I actually think that the writers should pay.
[00:58:00.540 --> 00:58:01.980]   Now, look at me in trouble.
[00:58:01.980 --> 00:58:02.980]   There you go.
[00:58:02.980 --> 00:58:04.500]   Whoa, whoa, whoa.
[00:58:04.500 --> 00:58:06.500]   Every writer I know is broken.
[00:58:06.500 --> 00:58:09.420]   That's a business model.
[00:58:09.420 --> 00:58:17.460]   I would pay to be in an environment that was guaranteed to be quality.
[00:58:17.460 --> 00:58:20.540]   And now that means you can fire a meat.
[00:58:20.540 --> 00:58:22.220]   It means no, sorry, you're not let in.
[00:58:22.220 --> 00:58:24.300]   I'm going to judge who gets in.
[00:58:24.300 --> 00:58:25.820]   Oh, there are.
[00:58:25.820 --> 00:58:30.100]   But blog platforms, paid blog platforms like that.
[00:58:30.100 --> 00:58:31.820]   What makes medium unique?
[00:58:31.820 --> 00:58:36.460]   Why is medium different than WordPress or Squarespace or some other blogging platform?
[00:58:36.460 --> 00:58:37.460]   The social and planet.
[00:58:37.460 --> 00:58:42.780]   Well, you get WordPress.com has a very active front page social community.
[00:58:42.780 --> 00:58:45.140]   Well, but not the same way.
[00:58:45.140 --> 00:58:48.980]   I mean, my WordPress blog has no relation to any other WordPress blog, whereas my medium
[00:58:48.980 --> 00:58:52.540]   post does or doesn't get recommended on medium.
[00:58:52.540 --> 00:58:53.540]   Yeah.
[00:58:53.540 --> 00:59:00.540]   You and I talk to Stephen Levy, who of course his publication Back Channel is owned by Conde
[00:59:00.540 --> 00:59:03.660]   Nest, but they didn't make a website for it.
[00:59:03.660 --> 00:59:06.300]   They just posted on medium.
[00:59:06.300 --> 00:59:07.420]   I mean, what did I camera?
[00:59:07.420 --> 00:59:08.420]   I don't know.
[00:59:08.420 --> 00:59:10.140]   Should we consider that off the record, Jeff?
[00:59:10.140 --> 00:59:11.140]   You're the journalist.
[00:59:11.140 --> 00:59:12.900]   I guess so, yeah.
[00:59:12.900 --> 00:59:17.380]   But they were kind of, well, this way they asked, so what do you think of medium now?
[00:59:17.380 --> 00:59:18.380]   There is.
[00:59:18.380 --> 00:59:19.380]   Let's put it this way.
[00:59:19.380 --> 00:59:22.340]   There is baffled as everybody else about what the future medium is.
[00:59:22.340 --> 00:59:26.460]   Ev said when he launched medium, he was wanted to create quote, a beautiful space for reading
[00:59:26.460 --> 00:59:28.020]   and writing and little else.
[00:59:28.020 --> 00:59:29.740]   The words are central.
[00:59:29.740 --> 00:59:30.740]   Is it living up to that?
[00:59:30.740 --> 00:59:33.740]   I think so.
[00:59:33.740 --> 00:59:35.940]   I think so.
[00:59:35.940 --> 00:59:42.180]   I think Ev's central thesis of the internet making the world a worse place than it was
[00:59:42.180 --> 00:59:45.500]   before is wrong.
[00:59:45.500 --> 00:59:54.180]   So to me, the whole thing is a bit kind of just him thinking to himself, maybe getting
[00:59:54.180 --> 00:59:59.020]   a bit too heavy.
[00:59:59.020 --> 01:00:03.460]   Before the internet, in order to publish, in order to get your stuff out there, you had
[01:00:03.460 --> 01:00:05.340]   to be rich enough to own a printing press.
[01:00:05.340 --> 01:00:06.340]   Amen.
[01:00:06.340 --> 01:00:10.900]   And then if in the television station, well, you had to have the money known intelligence.
[01:00:10.900 --> 01:00:15.140]   Now, even if you don't own a computer, you could go into a library and you can have access
[01:00:15.140 --> 01:00:17.100]   to basically the same tools.
[01:00:17.100 --> 01:00:20.820]   For the most part, that we use as journalists to get stuff out there.
[01:00:20.820 --> 01:00:24.220]   Now, is there more noise and confusion than maybe ever before?
[01:00:24.220 --> 01:00:25.220]   Maybe.
[01:00:25.220 --> 01:00:26.700]   Fake news is propaganda.
[01:00:26.700 --> 01:00:29.180]   Well, there's always been that sort of thing out there.
[01:00:29.180 --> 01:00:33.740]   These aren't new problems that might be amplified because more people are participating than
[01:00:33.740 --> 01:00:35.220]   ever before.
[01:00:35.220 --> 01:00:43.700]   But upending old power structures of a select few people who had control of all the media,
[01:00:43.700 --> 01:00:45.380]   I think that's actually a good thing.
[01:00:45.380 --> 01:00:49.740]   Now, the problem for our industry is that we can't make as much money off as we used
[01:00:49.740 --> 01:00:50.740]   to.
[01:00:50.740 --> 01:00:52.820]   Hopefully, eventually, new business models will be found.
[01:00:52.820 --> 01:00:58.260]   But the central idea that the internet has made the world a worse place off the bat,
[01:00:58.260 --> 01:00:59.460]   I disagree with it.
[01:00:59.460 --> 01:01:01.940]   I absolutely agree with you.
[01:01:01.940 --> 01:01:06.340]   And I'm the optimist to a fault and I'll salute that flag.
[01:01:06.340 --> 01:01:11.060]   There's also two disturbing documents that are in the rundown this week.
[01:01:11.060 --> 01:01:19.460]   One is Data and Society released a report from two other researchers, a 106 page report
[01:01:19.460 --> 01:01:23.540]   about all the mechanisms and means of manipulation that occurs.
[01:01:23.540 --> 01:01:30.300]   And then there's also a guardian story about the reviewers of instructions that come out
[01:01:30.300 --> 01:01:31.300]   for Facebook.
[01:01:31.300 --> 01:01:36.740]   And it's depressing as hell to read what people do.
[01:01:36.740 --> 01:01:42.460]   And so this discussion on the long head is that the problem with Twitter is the openness
[01:01:42.460 --> 01:01:45.940]   probably necessarily breeds trolls and bad behavior.
[01:01:45.940 --> 01:01:50.860]   So I agree with absolutely everything you said, but there's a price that comes with it if
[01:01:50.860 --> 01:01:52.820]   we're going to be truly open.
[01:01:52.820 --> 01:01:57.780]   And even if you're a closed network, even if you're Facebook, to be big, what they feel
[01:01:57.780 --> 01:01:59.460]   they must tolerate and love with speech.
[01:01:59.460 --> 01:02:01.660]   And I love free speech.
[01:02:01.660 --> 01:02:06.420]   One of them is really obnoxious and really horrible and abusive animals and abuse even
[01:02:06.420 --> 01:02:07.420]   of children.
[01:02:07.420 --> 01:02:10.980]   As long as it's not celebratory, they leave it there to be aware and we have a little bit
[01:02:10.980 --> 01:02:13.460]   of ugly world and so that's part of the world.
[01:02:13.460 --> 01:02:17.500]   And so yeah, that's why I'm thinking that maybe what Ev really wants to do is to create
[01:02:17.500 --> 01:02:19.340]   a happy place.
[01:02:19.340 --> 01:02:20.340]   What does a happy place look like?
[01:02:20.340 --> 01:02:24.580]   He says he's always done the same thing that none of that all of his ideas are basically
[01:02:24.580 --> 01:02:25.580]   the same.
[01:02:25.580 --> 01:02:32.540]   Yeah, speak, but yeah, but if you create a great tool to let people speak, how are you
[01:02:32.540 --> 01:02:33.540]   going to speak?
[01:02:33.540 --> 01:02:34.540]   You're going to speak.
[01:02:34.540 --> 01:02:36.580]   How do you make sure it's only used for stuff you approve of?
[01:02:36.580 --> 01:02:37.580]   You can't.
[01:02:37.580 --> 01:02:39.900]   Well, too, so that's that's called, but it's called a magazine.
[01:02:39.900 --> 01:02:40.900]   Yeah, right.
[01:02:40.900 --> 01:02:44.980]   And you're then you're a publisher, not that you are a publisher on an entrepreneur, not
[01:02:44.980 --> 01:02:45.980]   a platform.
[01:02:45.980 --> 01:02:48.140]   That's where that's where it was headed.
[01:02:48.140 --> 01:02:49.140]   Yeah.
[01:02:49.140 --> 01:02:52.340]   But who says no to on medium?
[01:02:52.340 --> 01:02:55.220]   Well, what they're doing is they reject stuff.
[01:02:55.220 --> 01:03:00.420]   They're curating the publishers that publish on medium and the regular people.
[01:03:00.420 --> 01:03:03.140]   So if I wrote a hate to use, could I post it on medium?
[01:03:03.140 --> 01:03:05.300]   I think you can, but it won't rise.
[01:03:05.300 --> 01:03:08.380]   The argument is it won't rise that they will recommend all of the good stuff.
[01:03:08.380 --> 01:03:10.860]   But you know, that was a huge word.
[01:03:10.860 --> 01:03:18.140]   There are also some terms, both on Twitter and on Facebook and on medium.
[01:03:18.140 --> 01:03:20.300]   There are certain things that you can't get away without there.
[01:03:20.300 --> 01:03:24.740]   So you can definitely post something being hateful, you know, talking smack about somebody,
[01:03:24.740 --> 01:03:28.860]   but there are certain lines that can't be crossed.
[01:03:28.860 --> 01:03:34.020]   If does apologize for Twitter's role in electing the president.
[01:03:34.020 --> 01:03:35.740]   This is also from the article.
[01:03:35.740 --> 01:03:38.460]   President Trump says, I don't know why his name is turned orange.
[01:03:38.460 --> 01:03:40.500]   That might be some editorializing on the New York Times.
[01:03:40.500 --> 01:03:43.340]   Because you used a full F to find.
[01:03:43.340 --> 01:03:44.340]   Oh, okay.
[01:03:44.340 --> 01:03:48.340]   That says he believes Twitter put him in the White House recently.
[01:03:48.340 --> 01:03:52.580]   Mr. Williams heard the claim for the first time he molded over for a bit sitting in his
[01:03:52.580 --> 01:03:57.300]   medium office, which is noteworthy only for not having a desk.
[01:03:57.300 --> 01:03:59.020]   It's a very bad thing.
[01:03:59.020 --> 01:04:01.340]   He said, finally, Twitter's role in that.
[01:04:01.340 --> 01:04:05.500]   If it's true that he wouldn't be president, if it weren't for Twitter, then yeah, I'm sorry.
[01:04:05.500 --> 01:04:07.260]   I was kind of tepid.
[01:04:07.260 --> 01:04:12.220]   He spoke at the commencement in Nebraska.
[01:04:12.220 --> 01:04:18.820]   And I thought his quote from that, let me see if I can find it, is interesting.
[01:04:18.820 --> 01:04:24.060]   If a little bit classical, I'm going to have to do another search for promote Prometheus.
[01:04:24.060 --> 01:04:28.460]   In the commencement speech at University of Nebraska this month, Mr. Williams noted that
[01:04:28.460 --> 01:04:33.700]   Silicon Valley has a tendency to see itself as a Prometheus.
[01:04:33.700 --> 01:04:35.060]   He's just showing off now.
[01:04:35.060 --> 01:04:37.500]   Where'd he go to school?
[01:04:37.500 --> 01:04:41.740]   Getting fire from selfish gatekeeper gods and bestowing it on mere mortals.
[01:04:41.740 --> 01:04:42.740]   All right.
[01:04:42.740 --> 01:04:45.180]   So the ability to have a voice.
[01:04:45.180 --> 01:04:46.180]   Yeah.
[01:04:46.180 --> 01:04:49.860]   Quote, what we tend to forget is Zeus was so pissed at Prometheus.
[01:04:49.860 --> 01:04:51.060]   He chained him to a rock.
[01:04:51.060 --> 01:04:54.540]   So Eagles could pick out his guts for eternity.
[01:04:54.540 --> 01:04:56.620]   Mr. Williams told the crowd that's uplifting.
[01:04:56.620 --> 01:05:00.420]   If you're a college senior graduating, you hear that some would say that's what we deserve
[01:05:00.420 --> 01:05:03.020]   for giving the power of tweets to Donald Trump.
[01:05:03.020 --> 01:05:08.980]   I think he's maybe giving himself a little bit too much credit there.
[01:05:08.980 --> 01:05:09.980]   Yeah.
[01:05:09.980 --> 01:05:10.980]   Giving Twitter a little bit.
[01:05:10.980 --> 01:05:15.020]   You know, if Twitter had not existed, we would have had to invent it.
[01:05:15.020 --> 01:05:19.660]   I think there would be some way for him and all of us to speak.
[01:05:19.660 --> 01:05:21.380]   I mean, that's what you could blame YouTube.
[01:05:21.380 --> 01:05:22.380]   You could blame Facebook.
[01:05:22.380 --> 01:05:25.220]   There's plenty of other platforms.
[01:05:25.220 --> 01:05:29.340]   And you know, Trump's team is savvy at all of them.
[01:05:29.340 --> 01:05:30.340]   They're very savvy.
[01:05:30.340 --> 01:05:33.140]   They're savvy at all of them.
[01:05:33.140 --> 01:05:36.740]   And you know, he was elected because he won the electoral college.
[01:05:36.740 --> 01:05:37.740]   Yeah, he won.
[01:05:37.740 --> 01:05:39.860]   You know, can't deny that.
[01:05:39.860 --> 01:05:40.860]   Like it or not.
[01:05:40.860 --> 01:05:43.500]   It's a reflection of our electoral process.
[01:05:43.500 --> 01:05:47.700]   I don't think Twitter should take all of the congratulations or blame.
[01:05:47.700 --> 01:05:48.700]   Exactly.
[01:05:48.700 --> 01:05:50.100]   No, but there was a role here.
[01:05:50.100 --> 01:05:51.940]   We can never cut it up.
[01:05:51.940 --> 01:05:57.900]   But the data in society report goes through the levels of manipulation that occur.
[01:05:57.900 --> 01:06:02.700]   And they manipulate Google, they manipulate Facebook, they manipulate media very much so.
[01:06:02.700 --> 01:06:03.860]   That's the goal.
[01:06:03.860 --> 01:06:07.260]   The public advertisers.
[01:06:07.260 --> 01:06:11.380]   And these institutions are not being savvy enough to account for that.
[01:06:11.380 --> 01:06:14.620]   And it's a worthwhile report and it's all spun on.
[01:06:14.620 --> 01:06:15.620]   It's true.
[01:06:15.620 --> 01:06:20.060]   But as long as there have been things to manipulate, there have been people to manipulate them.
[01:06:20.060 --> 01:06:21.060]   Absolutely.
[01:06:21.060 --> 01:06:22.060]   Right.
[01:06:22.060 --> 01:06:23.060]   So again, these aren't necessarily new problems.
[01:06:23.060 --> 01:06:26.820]   But are we good at adjusting for that, right?
[01:06:26.820 --> 01:06:29.620]   So PR wasn't good at manipulating us in the press.
[01:06:29.620 --> 01:06:30.620]   Yeah.
[01:06:30.620 --> 01:06:32.580]   And so we try to account for that.
[01:06:32.580 --> 01:06:33.980]   Sometimes we do something as we do.
[01:06:33.980 --> 01:06:34.980]   Yeah.
[01:06:34.980 --> 01:06:38.540]   Well, maybe to the more to the point, this is something that Russia and Putin's government
[01:06:38.540 --> 01:06:45.300]   has used very effectively in manipulating its own people is this flood of news, a mix
[01:06:45.300 --> 01:06:51.220]   of truth and untruth, making it difficult to distinguish facts from lies.
[01:06:51.220 --> 01:06:57.860]   And intentionally overwhelming people with signals, they did that because they controlled
[01:06:57.860 --> 01:06:59.580]   the media in Russia.
[01:06:59.580 --> 01:07:01.860]   Well, you don't need to control the media in the West.
[01:07:01.860 --> 01:07:06.980]   You just need to be able to post on Facebook and Twitter and the rest follows.
[01:07:06.980 --> 01:07:12.860]   So in a way, maybe we gave a very useful tool to somebody who is very willing to misuse
[01:07:12.860 --> 01:07:14.380]   it and manipulate it.
[01:07:14.380 --> 01:07:16.740]   He was effective at manipulating the media to it.
[01:07:16.740 --> 01:07:17.740]   I think it was the point.
[01:07:17.740 --> 01:07:18.740]   Oh, yeah.
[01:07:18.740 --> 01:07:19.740]   CNN would air.
[01:07:19.740 --> 01:07:21.260]   They fell for it too.
[01:07:21.260 --> 01:07:22.260]   They fell for it too.
[01:07:22.260 --> 01:07:24.460]   Rallys in their entirety.
[01:07:24.460 --> 01:07:25.460]   You know what?
[01:07:25.460 --> 01:07:26.460]   It's still the best.
[01:07:26.460 --> 01:07:30.620]   It's it was at the United Nations was saying, there's people starving to death.
[01:07:30.620 --> 01:07:32.100]   Would you stop covering Trump?
[01:07:32.100 --> 01:07:33.100]   Yeah.
[01:07:33.100 --> 01:07:34.100]   And it is still the most.
[01:07:34.100 --> 01:07:39.620]   I mean, whatever you else you might say about the president, he is he and his team are
[01:07:39.620 --> 01:07:42.700]   very good at making entertainment.
[01:07:42.700 --> 01:07:44.180]   And you can't stop watching him.
[01:07:44.180 --> 01:07:47.100]   And media are built for the reward system.
[01:07:47.100 --> 01:07:49.820]   And the media is that how it works.
[01:07:49.820 --> 01:07:54.380]   As I said, when I interviewed David Kenny, the head of IBM Watson, and they had Watson
[01:07:54.380 --> 01:07:58.660]   right headlines and they fed the business model of the channel into it.
[01:07:58.660 --> 01:07:59.660]   And so guess what?
[01:07:59.660 --> 01:08:00.660]   It real clickbait.
[01:08:00.660 --> 01:08:01.660]   Right.
[01:08:01.660 --> 01:08:02.660]   Because that's what was going to work.
[01:08:02.660 --> 01:08:03.660]   Yeah.
[01:08:03.660 --> 01:08:06.260]   Ev says in this article concluding it, I think we'll fix these things.
[01:08:06.260 --> 01:08:07.260]   Just don't hold your breath.
[01:08:07.260 --> 01:08:08.420]   The work has barely begun.
[01:08:08.420 --> 01:08:12.460]   He says 20 years isn't very long to change how society works.
[01:08:12.460 --> 01:08:16.140]   So even Ev is in all that convinced that there's going to be able.
[01:08:16.140 --> 01:08:17.340]   We're going to be able to do much about it.
[01:08:17.340 --> 01:08:22.740]   I think the risks of stifling free speech are so great that it's really a difficult
[01:08:22.740 --> 01:08:23.740]   thing.
[01:08:23.740 --> 01:08:25.460]   It's a challenging thing to solve.
[01:08:25.460 --> 01:08:27.500]   If you were a what would you do with medium?
[01:08:27.500 --> 01:08:28.500]   Any of you.
[01:08:28.500 --> 01:08:32.500]   Well, I wouldn't have created medium in the first place, to be honest with you.
[01:08:32.500 --> 01:08:38.060]   I don't I don't I think that that's a little quixotic.
[01:08:38.060 --> 01:08:39.060]   Anybody?
[01:08:39.060 --> 01:08:42.660]   I mean, what do we need a centralized journalism platform for?
[01:08:42.660 --> 01:08:45.940]   Well, I think there's room for new publishers.
[01:08:45.940 --> 01:08:49.940]   And if he can look at it just as a new media publisher, then that could be.
[01:08:49.940 --> 01:08:53.740]   But like he's already had his big businesses that have made billions of dollars.
[01:08:53.740 --> 01:08:59.020]   It is kind of it does feel like a millionaire's hobby as opposed to tend to create a viable
[01:08:59.020 --> 01:09:00.020]   business.
[01:09:00.020 --> 01:09:06.500]   I mean, the one of the things that bothers me about it is is I think he means well, but
[01:09:06.500 --> 01:09:12.580]   and I throw this criticism at any media company, a legacy or or new like what Ev's doing
[01:09:12.580 --> 01:09:17.460]   in medium is they're not they're not necessarily doing anything that new.
[01:09:17.460 --> 01:09:19.500]   Like it's still as it's still revenue.
[01:09:19.500 --> 01:09:21.060]   It's kind of like blogger.
[01:09:21.060 --> 01:09:25.860]   It's exactly like it's it's revenue comes from ads and you're asking people to publish
[01:09:25.860 --> 01:09:28.500]   for free and they're saying we might promote your stuff.
[01:09:28.500 --> 01:09:30.300]   I feel like we have the worldwide web.
[01:09:30.300 --> 01:09:31.380]   We don't need the medium.
[01:09:31.380 --> 01:09:34.020]   We got we got public everybody can publish.
[01:09:34.020 --> 01:09:38.540]   Well, I think I think in this something that that that Jeff and you hit on earlier is the
[01:09:38.540 --> 01:09:42.220]   idea of curating what's there to find to create that happy place.
[01:09:42.220 --> 01:09:46.460]   I think that was kind of the goal with medium is there are a lot of great voices out there.
[01:09:46.460 --> 01:09:50.060]   Let's put them together in a in a more like minded place.
[01:09:50.060 --> 01:09:52.620]   I'm not I'm not knocking and I read medium all the time.
[01:09:52.620 --> 01:09:53.620]   I like it.
[01:09:53.620 --> 01:09:54.620]   It's beautiful.
[01:09:54.620 --> 01:09:57.660]   Yeah, but it's like being able to underline it and see what you guys underline things
[01:09:57.660 --> 01:09:58.660]   like that.
[01:09:58.660 --> 01:10:03.740]   But just like a like a magazine, it is a curation of like minded for the most part folks.
[01:10:03.740 --> 01:10:07.660]   Well, that's not a bad that's not bad, but you know, except that the advertising model
[01:10:07.660 --> 01:10:08.660]   failed.
[01:10:08.660 --> 01:10:11.220]   So now he's kind of in a rock between a rock and art advertising.
[01:10:11.220 --> 01:10:13.380]   Yeah, I'm not sure he tried enough on the advertising.
[01:10:13.380 --> 01:10:15.660]   I think if you look at courts is now profitable.
[01:10:15.660 --> 01:10:17.940]   Yes, it does native advertising, but it's well labeled.
[01:10:17.940 --> 01:10:18.940]   I like sports.
[01:10:18.940 --> 01:10:19.940]   In a company.
[01:10:19.940 --> 01:10:22.900]   It is it's probably a profitable full year.
[01:10:22.900 --> 01:10:26.780]   That's but see course is news courses and outright publication mediums.
[01:10:26.780 --> 01:10:31.940]   Yes, it is mediums more like the Huffington Post where or BuzzFeed where they let people
[01:10:31.940 --> 01:10:37.380]   go on there and write for free as in they don't pay them and they they benefit from
[01:10:37.380 --> 01:10:40.420]   this swell of content coming in that they don't pay for.
[01:10:40.420 --> 01:10:43.220]   And then they have their editorial teams over the top of it.
[01:10:43.220 --> 01:10:47.820]   And then they work with those who pay to get into get the extra promotion, which for medium,
[01:10:47.820 --> 01:10:53.180]   it's actual publications where for BuzzFeed, it's like tied or, you know, whatever brand.
[01:10:53.180 --> 01:10:56.180]   So again, it's not really a new model.
[01:10:56.180 --> 01:10:58.140]   It's not a new idea.
[01:10:58.140 --> 01:11:02.700]   It's just his his curation and it's it's great and I enjoy it.
[01:11:02.700 --> 01:11:06.580]   It's just, you know, if you really want to say you're going to do something new and groundbreaking
[01:11:06.580 --> 01:11:09.740]   for for journalism, well, this ain't it.
[01:11:09.740 --> 01:11:10.740]   Yeah.
[01:11:10.740 --> 01:11:15.340]   Quartz, by the I noticed has completely changed its look and feel.
[01:11:15.340 --> 01:11:16.340]   Yeah.
[01:11:16.340 --> 01:11:21.220]   It was the infinite scroll magazine before and now it's just a little bit, I guess it's
[01:11:21.220 --> 01:11:22.980]   still it had no homepage at the start.
[01:11:22.980 --> 01:11:23.980]   Right.
[01:11:23.980 --> 01:11:26.100]   Well, if you go into a specific story, you still get the infinite scroll.
[01:11:26.100 --> 01:11:27.100]   You still do.
[01:11:27.100 --> 01:11:31.660]   So yeah, I mean, what does a homepage mean in this day and age where the all the traffic
[01:11:31.660 --> 01:11:36.260]   comes from links from Twitter and it's a branding exercise.
[01:11:36.260 --> 01:11:39.660]   It helps as helps us set your design aesthetic.
[01:11:39.660 --> 01:11:42.140]   I go to, I mean, people go to Bloomberg.com, right?
[01:11:42.140 --> 01:11:43.140]   I mean, that's a.
[01:11:43.140 --> 01:11:44.860]   They do.
[01:11:44.860 --> 01:11:48.140]   It drives traffic still, not as much as it used to.
[01:11:48.140 --> 01:11:49.140]   Yeah.
[01:11:49.140 --> 01:11:51.820]   The New York Times homepage, a lot of people still go to.
[01:11:51.820 --> 01:11:52.820]   Yeah.
[01:11:52.820 --> 01:11:56.620]   But yeah, the homepage does not have the relevance that it once had.
[01:11:56.620 --> 01:12:00.660]   Actually, I think that's one of the things and I think I could say this one that I was
[01:12:00.660 --> 01:12:08.620]   asking Stephen Levy if people went to backchannel.com or and I think almost all the he said, we do
[01:12:08.620 --> 01:12:13.860]   get from page traffic as you are also saying, but I think deep links links into the articles
[01:12:13.860 --> 01:12:16.300]   directly is most traffic for everybody.
[01:12:16.300 --> 01:12:19.780]   But what I was talking about the homepage is a branding exercise.
[01:12:19.780 --> 01:12:22.140]   It's like, you know, Bloomberg is about data.
[01:12:22.140 --> 01:12:23.140]   So we present.
[01:12:23.140 --> 01:12:24.140]   You could see all the things.
[01:12:24.140 --> 01:12:25.140]   Mark gets data.
[01:12:25.140 --> 01:12:29.460]   That's what we wanted to do with our website too is if you didn't know what to it was,
[01:12:29.460 --> 01:12:33.740]   you could go to the front page and quickly grock what it was about.
[01:12:33.740 --> 01:12:36.180]   That's the best you can hope for with a homepage, right?
[01:12:36.180 --> 01:12:38.540]   And you're not going to get somebody going back again and again.
[01:12:38.540 --> 01:12:42.500]   You're going to get them the first time when they're researching you.
[01:12:42.500 --> 01:12:46.500]   So we have these big banners that say what we do and then right underneath it latest news
[01:12:46.500 --> 01:12:47.980]   helping out to reviews.
[01:12:47.980 --> 01:12:51.620]   So you understand that there are shows and there are shows in these categories.
[01:12:51.620 --> 01:12:54.700]   That's all we ever hoped to do, frankly, with the front page.
[01:12:54.700 --> 01:12:59.340]   I think it's that that in and of itself is reason enough to have a homepage.
[01:12:59.340 --> 01:13:00.340]   Right.
[01:13:00.340 --> 01:13:03.660]   And instead of just it's a it's a billboard.
[01:13:03.660 --> 01:13:04.660]   Let's take a break.
[01:13:04.660 --> 01:13:06.340]   The Bizstone has gone back to Twitter.
[01:13:06.340 --> 01:13:07.820]   I don't know if that's a big story or not.
[01:13:07.820 --> 01:13:08.820]   We can talk about that.
[01:13:08.820 --> 01:13:13.740]   Apple has some interesting ideas about tracking your blood sugar.
[01:13:13.740 --> 01:13:21.940]   In fact, Tim Cook seems to be wearing an unusual watch these days and Amazon.
[01:13:21.940 --> 01:13:27.780]   I don't know what the news is, but I'm just going to say the word Amazon, Facebook, Twitter
[01:13:27.780 --> 01:13:30.420]   and some stuff that'll just make you want to cry.
[01:13:30.420 --> 01:13:32.300]   It's all coming up.
[01:13:32.300 --> 01:13:36.220]   We've got a great panel today, Jeff Jarvis from Twig this week in Google and of course
[01:13:36.220 --> 01:13:39.140]   the city, University of New York, Buzzmachine.com.
[01:13:39.140 --> 01:13:40.140]   Always a pleasure.
[01:13:40.140 --> 01:13:41.140]   It was really nice to see you.
[01:13:41.140 --> 01:13:42.700]   I wish we'd had more time together.
[01:13:42.700 --> 01:13:43.700]   Yeah.
[01:13:43.700 --> 01:13:45.060]   But we got to see you in Lisa.
[01:13:45.060 --> 01:13:46.540]   I got to capture bubbles.
[01:13:46.540 --> 01:13:48.820]   We got Schwab.
[01:13:48.820 --> 01:13:49.820]   Not the chimp.
[01:13:49.820 --> 01:13:54.180]   It was the thing before the IO they were keeping us entertained with a really kind of the dopiest
[01:13:54.180 --> 01:13:55.180]   games ever.
[01:13:55.180 --> 01:13:59.980]   Mark Millian is here, Bloomberg Business Week, Bloomberg.com slash tech for his great tech
[01:13:59.980 --> 01:14:06.260]   coverage and of course our own Nathan Oliveira's Giles, NATOG.
[01:14:06.260 --> 01:14:13.220]   Our show today brought to you by Betterment, the easy, smart, best way to invest for your
[01:14:13.220 --> 01:14:15.540]   financial future.
[01:14:15.540 --> 01:14:20.500]   You've seen tech change so much, commerce, entertainment.
[01:14:20.500 --> 01:14:24.900]   I mean ride sharing, home security.
[01:14:24.900 --> 01:14:28.580]   Did you know that computers can help you invest better too?
[01:14:28.580 --> 01:14:33.580]   Betterment is the largest independent automated investing service and they've really changed
[01:14:33.580 --> 01:14:36.260]   the industry by making investing easier.
[01:14:36.260 --> 01:14:41.020]   And of course because computers are cheap, you pay a fraction of what you'd pay for traditional
[01:14:41.020 --> 01:14:42.340]   financial services.
[01:14:42.340 --> 01:14:46.420]   And I would argue you get a better, much better result.
[01:14:46.420 --> 01:14:50.740]   Betterment combines smart technology and they do have human advisors and I like that.
[01:14:50.740 --> 01:14:53.780]   So you can optimize your results at every level of investment.
[01:14:53.780 --> 01:14:59.620]   You'll get access to a team of certified financial professionals, licensed financial experts.
[01:14:59.620 --> 01:15:03.620]   They also along with the computers, monitor your accounts, they can answer questions.
[01:15:03.620 --> 01:15:08.140]   You can make planning calls and you can get notifications throughout the year.
[01:15:08.140 --> 01:15:15.180]   But the algorithms will also minute by minute, even second by second, keep track of your investment
[01:15:15.180 --> 01:15:22.580]   based on your interests in growth, in tolerance of risk, that kind of thing.
[01:15:22.580 --> 01:15:25.460]   You can also securely sync your outside investments with betterment.
[01:15:25.460 --> 01:15:28.980]   So you've got one dashboard that tells you your net worth and how everything's doing
[01:15:28.980 --> 01:15:30.300]   in one place.
[01:15:30.300 --> 01:15:34.580]   It's easy and I highly recommend you do this to use their smart deposits.
[01:15:34.580 --> 01:15:38.580]   So if you have a little excess cash in your account, it'll automatically invest and that's
[01:15:38.580 --> 01:15:41.060]   the best way to build your nest egg.
[01:15:41.060 --> 01:15:43.900]   When you're getting ready for retirement or even before then, you should probably start
[01:15:43.900 --> 01:15:45.660]   thinking about it sooner than later.
[01:15:45.660 --> 01:15:49.900]   They've got a great retirement guide that provides a consolidated view of where your
[01:15:49.900 --> 01:15:55.980]   investment stand calculates any gap that there might be, shows you how to close that gap.
[01:15:55.980 --> 01:16:01.340]   They do things, sophisticated things that only computers do like tax loss harvesting,
[01:16:01.340 --> 01:16:05.860]   that lowers your investment taxes and increases your after tax returns.
[01:16:05.860 --> 01:16:11.020]   And of course, it's very affordable, no trade, no transaction, no rebalancing fees.
[01:16:11.020 --> 01:16:12.900]   And I like this, it's easy to get started.
[01:16:12.900 --> 01:16:15.220]   There's no minimum to sign up.
[01:16:15.220 --> 01:16:17.220]   So you're going to get great diversification.
[01:16:17.220 --> 01:16:22.100]   You're going to get smart rebalancing, you're going to get tax loss harvesting, lower fees,
[01:16:22.100 --> 01:16:25.980]   and all that means you can expect higher returns in a typical DIY investor.
[01:16:25.980 --> 01:16:33.940]   Of course, as with everything investing involves risk, I got to say that, but you got to invest,
[01:16:33.940 --> 01:16:37.300]   you got to take a little risk if you're going to be ready to retire, if you're going to
[01:16:37.300 --> 01:16:40.580]   be ready to send your kids to college, if you're going to be ready to buy that house,
[01:16:40.580 --> 01:16:44.580]   if you're going to have that nest egg, get one month managed free when you're making
[01:16:44.580 --> 01:16:46.980]   an initial deposit of $10,000 or more.
[01:16:46.980 --> 01:16:51.700]   If you've got, if you've been managing your own IRAR, your 401k, get it right, get it over
[01:16:51.700 --> 01:16:58.500]   to betterment.com/twitbetterment.com/twitbetterment.
[01:16:58.500 --> 01:17:04.580]   The name says it all, it's investment made better.
[01:17:04.580 --> 01:17:10.340]   Does it mean anything that Biz is going back to Twitter or is it really mean just craziness
[01:17:10.340 --> 01:17:14.660]   ahead where you've got CEOs at each other's throats?
[01:17:14.660 --> 01:17:19.620]   I mean, if it's founders at each other's throats, a board that doesn't know what to do.
[01:17:19.620 --> 01:17:20.980]   He's filling a Biz-sized hole.
[01:17:20.980 --> 01:17:23.300]   Is that what he said?
[01:17:23.300 --> 01:17:24.660]   Yeah, that's his line.
[01:17:24.660 --> 01:17:31.540]   He's like, they haven't outlined an exact job for me, but you could say it's filling a
[01:17:31.540 --> 01:17:33.220]   Biz-sized hole.
[01:17:33.220 --> 01:17:35.620]   Is he going to, oh, it's on medium, of course.
[01:17:35.620 --> 01:17:40.900]   It sounds like he's going to go back to basically his death.
[01:17:40.900 --> 01:17:46.340]   Like, you know, rather the troops, like company culture, get people excited, and it'll probably
[01:17:46.340 --> 01:17:52.020]   be a little bit of a liaison between both the company and the press and then the company
[01:17:52.020 --> 01:17:53.380]   and it employs itself.
[01:17:53.380 --> 01:17:56.500]   Yeah, and that really day is a big part of his role as marketing and PR.
[01:18:00.020 --> 01:18:06.100]   I think they could use a little bit of help in that sphere, so it makes sense for them.
[01:18:06.100 --> 01:18:15.220]   But like for a company who's one of their biggest financial issues is that their compensation
[01:18:15.220 --> 01:18:21.220]   packages are so extreme that they pay out so much equity, which contributes to their losses,
[01:18:21.220 --> 01:18:25.860]   to hire somebody and not formalize a role for them is a little bit of a weird.
[01:18:25.860 --> 01:18:29.700]   Well, and that's one of the things that I would have loved to have seen that no stories out there
[01:18:30.180 --> 01:18:33.300]   that I saw answered was how much he's getting paid if he's getting paid at all.
[01:18:33.300 --> 01:18:37.620]   It would have been nice to see if he's just taking a dollar or something.
[01:18:37.620 --> 01:18:39.860]   So most of all he's getting paid.
[01:18:39.860 --> 01:18:40.820]   More than a dollar.
[01:18:40.820 --> 01:18:46.820]   But no disrespect to him in this role, but it seems like it's kind of like what
[01:18:46.820 --> 01:18:48.420]   Palmer Lucky used to do for Oculus.
[01:18:48.420 --> 01:18:51.460]   It seems like he's going to be kind of the face of the brand.
[01:18:51.460 --> 01:18:54.900]   He's the first player in the cosplaying and before the vision guy.
[01:18:54.900 --> 01:18:55.460]   When he's getting everybody off.
[01:18:55.460 --> 01:19:00.580]   He says in his media post, my top focus will be the guide the company culture, that energy,
[01:19:00.580 --> 01:19:01.300]   that feeling.
[01:19:01.300 --> 01:19:04.340]   I don't want to say he's going to be a mascot of sorts.
[01:19:04.340 --> 01:19:07.860]   He's going to be basically there to get everything happy enough off the books.
[01:19:07.860 --> 01:19:08.820]   That kind of feeling good.
[01:19:08.820 --> 01:19:10.580]   I'm not replacing anyone at Twitter.
[01:19:10.580 --> 01:19:13.700]   Somebody mentioned I'm just filling the biz shape hole I left.
[01:19:13.700 --> 01:19:17.780]   You might even say the job description includes being biz stone.
[01:19:17.780 --> 01:19:19.700]   Oh my God, I'm going to throw up.
[01:19:19.700 --> 01:19:23.940]   That's my job description being real report.
[01:19:24.660 --> 01:19:24.980]   Yeah.
[01:19:24.980 --> 01:19:31.300]   Well, I've said, and I think this is a, I don't know if there's a compliment,
[01:19:31.300 --> 01:19:33.940]   well, you're among the best in the world at being biz stone.
[01:19:33.940 --> 01:19:42.580]   If I were an investor in Twitter, this would not, to me, herald any big improvement.
[01:19:42.580 --> 01:19:44.020]   Well, the company that leads.
[01:19:44.020 --> 01:19:46.020]   And then it kind of calmed down after the announcement.
[01:19:46.020 --> 01:19:46.980]   It didn't seem too much.
[01:19:46.980 --> 01:19:50.180]   You think they put out a job posting just in case you see what other happens.
[01:19:50.180 --> 01:19:52.740]   Biz stone hole we'd like to fill.
[01:19:52.740 --> 01:19:54.420]   Anybody biz shaped out there.
[01:19:54.420 --> 01:19:59.220]   I, you know, I understand a company like Twitter needs to have,
[01:19:59.220 --> 01:20:02.740]   you know, kind of an overall feeling.
[01:20:02.740 --> 01:20:03.060]   Yeah.
[01:20:03.060 --> 01:20:05.380]   But at this point, Twitter is a utility.
[01:20:05.380 --> 01:20:10.180]   It just should be, I don't know what you just somebody should just say,
[01:20:10.180 --> 01:20:11.540]   we're not going to make any money at it.
[01:20:11.540 --> 01:20:13.780]   We're just going to buy it and let it run.
[01:20:13.780 --> 01:20:15.220]   Well, I guess I don't know.
[01:20:15.220 --> 01:20:16.660]   One of them know what to say.
[01:20:16.660 --> 01:20:19.860]   One of the maybe good things that could come from this is this is genuinely,
[01:20:19.860 --> 01:20:23.460]   like the most important thing Biz stone has ever been a part of in his life.
[01:20:23.460 --> 01:20:25.300]   So what did he do after he left Twitter?
[01:20:25.300 --> 01:20:26.420]   Jelly.
[01:20:26.420 --> 01:20:30.180]   He started jelly that like, like a question app that was.
[01:20:30.180 --> 01:20:31.540]   Oh, yeah, it was Quora.
[01:20:31.540 --> 01:20:31.860]   Yeah.
[01:20:31.860 --> 01:20:32.020]   Yeah.
[01:20:32.020 --> 01:20:32.980]   It was basically real table.
[01:20:32.980 --> 01:20:33.540]   We'll go and find out.
[01:20:33.540 --> 01:20:34.420]   They sold it, right?
[01:20:34.420 --> 01:20:36.420]   Yeah, they sold Pinterest.
[01:20:36.420 --> 01:20:38.180]   And he was at Pinterest for a short while.
[01:20:38.180 --> 01:20:40.100]   I think he's staying on as an advisor.
[01:20:40.100 --> 01:20:41.380]   I think Pinterest is funny.
[01:20:41.380 --> 01:20:43.620]   Because they had some kind of image recognition technology.
[01:20:43.620 --> 01:20:44.420]   They're working on something.
[01:20:44.420 --> 01:20:44.740]   All right.
[01:20:46.340 --> 01:20:50.340]   So it's this is a good country to be a former founder.
[01:20:50.340 --> 01:20:52.020]   There's a lot.
[01:20:52.020 --> 01:20:53.380]   It's a good country to be a billionaire.
[01:20:53.380 --> 01:20:55.060]   Yeah, it's good country to be a billionaire.
[01:20:55.060 --> 01:20:57.140]   Lot of opportunity out there for the billionaires.
[01:20:57.140 --> 01:20:59.380]   Somebody he said, Alex C in the chat room says,
[01:20:59.380 --> 01:21:02.500]   things not to bring up on a first date, your Biz shaped hole.
[01:21:02.500 --> 01:21:08.260]   It's business time.
[01:21:08.260 --> 01:21:12.020]   Let's talk about, I don't know.
[01:21:12.020 --> 01:21:13.380]   I don't care about anything anymore.
[01:21:15.940 --> 01:21:19.540]   I, it's just, it's all, you know, I'm just waiting for the
[01:21:19.540 --> 01:21:21.220]   artificial intelligence to kick in.
[01:21:21.220 --> 01:21:22.020]   And then I'm going to go.
[01:21:22.020 --> 01:21:22.740]   Just take over.
[01:21:22.740 --> 01:21:27.060]   Apple CEO Tim Cook has been wearing a weird watch.
[01:21:27.060 --> 01:21:30.660]   Apparently he's been test driving a glucose monitor.
[01:21:30.660 --> 01:21:38.020]   According to CNBC, Apple has a team dedicated to the holy grail in diabetes.
[01:21:38.020 --> 01:21:44.660]   Non-invasive, in other words, no pin prick, continuous glucose monitoring.
[01:21:44.660 --> 01:21:45.940]   That's huge if they do it.
[01:21:45.940 --> 01:21:47.220]   They find the way it's huge.
[01:21:47.220 --> 01:21:51.860]   He's been spotted at the campus wearing this watch.
[01:21:51.860 --> 01:21:55.140]   I don't, I don't know how they know that that's what that watch does.
[01:21:55.140 --> 01:21:57.780]   A source, I think it has a specialized band.
[01:21:57.780 --> 01:22:01.860]   A source said the cook was wearing a prototype glucose tracker on the Apple
[01:22:01.860 --> 01:22:05.460]   watch that points to future applications that would make it a device that must have
[01:22:05.460 --> 01:22:06.900]   for millions of people with diabetes.
[01:22:06.900 --> 01:22:09.460]   Now, of course, Apple could easily have this.
[01:22:09.460 --> 01:22:11.860]   The problem is to put it out as a product.
[01:22:11.860 --> 01:22:13.700]   You have to get FDA approval.
[01:22:13.700 --> 01:22:14.820]   This is non-trivial.
[01:22:14.820 --> 01:22:16.500]   This requires trials.
[01:22:16.500 --> 01:22:17.620]   I'm sure Apple will do it.
[01:22:17.620 --> 01:22:18.420]   They've got the money.
[01:22:18.420 --> 01:22:20.820]   Cardi is the company that's done something along this line.
[01:22:20.820 --> 01:22:22.100]   That's the conductor's company.
[01:22:22.100 --> 01:22:23.060]   The conductor's company.
[01:22:23.060 --> 01:22:26.820]   Yeah, I was going to say it's not quite clear that it's even an Apple-made
[01:22:26.820 --> 01:22:28.020]   product from the story.
[01:22:28.020 --> 01:22:29.540]   Like maybe it's a third party.
[01:22:29.540 --> 01:22:32.020]   Yeah, isn't a device that cooks in the Apple watch.
[01:22:32.020 --> 01:22:32.660]   Yeah, we don't know.
[01:22:32.660 --> 01:22:36.100]   Apparently he talks in February at the University of Glasgow to some students.
[01:22:36.100 --> 01:22:40.740]   And he didn't say if it was a medical device from Medtronic or Dexcom,
[01:22:40.740 --> 01:22:43.220]   some other company or an Apple prototype.
[01:22:43.220 --> 01:22:43.780]   He just said.
[01:22:43.780 --> 01:22:46.420]   Yeah, the other thing that's here is that it interests me.
[01:22:46.420 --> 01:22:48.820]   So my mother's a type one diabetic, has been since I was born.
[01:22:48.820 --> 01:22:50.420]   My fault.
[01:22:50.420 --> 01:22:54.180]   And there are other signals too.
[01:22:54.180 --> 01:22:56.980]   There are sets of signals that if you're going into an insulin reaction
[01:22:56.980 --> 01:23:02.100]   or if you're going in an acidosis, it's like going into an
[01:23:02.100 --> 01:23:04.100]   epileptic seizure or going into
[01:23:04.100 --> 01:23:10.740]   Tourette's outburst.
[01:23:10.740 --> 01:23:12.740]   There's things that may be predictive.
[01:23:13.300 --> 01:23:16.740]   Where they are, they go beyond single bedroom.
[01:23:16.740 --> 01:23:18.900]   Well, we see even the heart rate monitor on the Apple watch,
[01:23:18.900 --> 01:23:25.060]   we've seen evidence that it could be used to detect tachycardia or as you have for relation
[01:23:25.060 --> 01:23:33.140]   and warn the user, hey, your heart rate is on, heartbeat is on abnormal.
[01:23:33.140 --> 01:23:37.540]   You better maybe get one of those cardia out and do an EKG.
[01:23:37.540 --> 01:23:40.420]   These are hugely valuable things.
[01:23:40.420 --> 01:23:43.700]   And it would take something, a product that's kind of been languishing,
[01:23:43.700 --> 01:23:45.620]   looking for a niche to fill.
[01:23:45.620 --> 01:23:49.540]   It's been selling, I guess, okay, but isn't anything anybody needs.
[01:23:49.540 --> 01:23:52.980]   Man, if there's 11 million diabetics in the country,
[01:23:52.980 --> 01:23:55.300]   every one of them would buy something they didn't have to do.
[01:23:55.300 --> 01:23:55.940]   Oh, God, yes.
[01:23:55.940 --> 01:23:59.220]   By the way, a lot of people weren't diabetics.
[01:23:59.220 --> 01:24:00.580]   Tim Cook's not a diabetic.
[01:24:00.580 --> 01:24:01.860]   He said he lost 30 pounds.
[01:24:01.860 --> 01:24:05.620]   He's just been paying attention to how what he eats, affects his
[01:24:05.620 --> 01:24:10.500]   spikes of sugar, and he's been able to use that to his health advantage.
[01:24:10.500 --> 01:24:12.420]   So it's a really big market, frankly.
[01:24:12.420 --> 01:24:18.180]   And as far as wearables go, the Apple watches,
[01:24:18.180 --> 01:24:22.180]   really the only one outside Fitbit as a company as a whole.
[01:24:22.180 --> 01:24:26.100]   But it's kind of like the only smartwatch that you really do see a massive amount of
[01:24:26.100 --> 01:24:26.980]   people out there wearing.
[01:24:26.980 --> 01:24:31.700]   It might not be an iPhone size blockbuster, but a lot of people wear them,
[01:24:31.700 --> 01:24:37.540]   and they sell quite well if they do have a genuine advantage here on the health side,
[01:24:37.540 --> 01:24:41.540]   because Google's trying to invest in this, and Microsoft's been trying to invest in similar things.
[01:24:41.540 --> 01:24:44.660]   They aren't the first one to try and solve these problems,
[01:24:44.660 --> 01:24:47.060]   but that would be a big consequence of them.
[01:24:47.060 --> 01:24:49.940]   Huge, that's a massive business.
[01:24:49.940 --> 01:24:51.220]   Well, I could see other things too.
[01:24:51.220 --> 01:24:58.500]   Again, who knows what things like, a sensor here in eye dilation, Galvanik's skin response.
[01:24:58.500 --> 01:25:01.940]   And we know Google and they're fairly division, they're med science.
[01:25:01.940 --> 01:25:05.300]   This division is doing a contact lens that can also monitor glucose levels.
[01:25:05.300 --> 01:25:05.540]   Right.
[01:25:05.540 --> 01:25:13.380]   So there's a lot of, and if you put AI behind this, if you get enough data to recognize those signals,
[01:25:13.380 --> 01:25:17.540]   imagine God knows what all you can you can start to determine about somebody.
[01:25:17.540 --> 01:25:22.740]   Upcoming hard imagine if they can start getting any percentage of particular heart attack
[01:25:22.740 --> 01:25:24.900]   an hour before you happen.
[01:25:25.940 --> 01:25:28.740]   Well, we know that the sooner you get to the hospital after a heart attack,
[01:25:28.740 --> 01:25:31.140]   the better your chances of total recovery stroke too.
[01:25:31.140 --> 01:25:35.540]   Those things would be major life-saving technologies.
[01:25:35.540 --> 01:25:43.460]   Sad because available only in the first world to effectively wealthy individuals,
[01:25:43.460 --> 01:25:46.740]   but maybe Apple can solve that too.
[01:25:46.740 --> 01:25:53.380]   Your colleague Mark Gurman saw him at Google I/O, Smart Kid, has pretty good sources.
[01:25:53.380 --> 01:25:54.820]   Yes, he's a certain full force.
[01:25:54.820 --> 01:26:00.100]   Yeah, he says Apple plans a laptop upgrades that they will announce June 5th
[01:26:00.100 --> 01:26:01.860]   at WWDC.
[01:26:01.860 --> 01:26:03.540]   This is something we've been waiting for.
[01:26:03.540 --> 01:26:08.740]   Microsoft is having an event on the 23rd this week in Shanghai
[01:26:08.740 --> 01:26:12.420]   that they're also expected to announce laptops.
[01:26:12.420 --> 01:26:16.980]   This is the time of year, if believe it or not, for school, if you're going to do better,
[01:26:16.980 --> 01:26:20.740]   you announce these things in June, you want to get them in the stores so the kids can buy them
[01:26:20.740 --> 01:26:22.420]   for a September return to school.
[01:26:22.420 --> 01:26:23.780]   Yep, August, September, yeah.
[01:26:23.780 --> 01:26:27.620]   Yeah, so Apple's laptops have been kind of lagging.
[01:26:27.620 --> 01:26:29.060]   You're both using Apple laptops.
[01:26:29.060 --> 01:26:34.820]   You have a MacBook Pro with the toolbar and you get the MacBook minus the toolbar.
[01:26:34.820 --> 01:26:35.700]   No toolbar.
[01:26:35.700 --> 01:26:36.900]   No toolbar, but both.
[01:26:36.900 --> 01:26:40.980]   Yeah, you know when I kind of miss my MacBook, I gave it to my mom,
[01:26:40.980 --> 01:26:45.060]   which is great for her because it's very thin and light, but I kind of miss it.
[01:26:45.060 --> 01:26:46.980]   It was a hated the keyboard.
[01:26:46.980 --> 01:26:49.060]   The keyboard just off that keyboard I like.
[01:26:49.060 --> 01:26:50.020]   I love the keyboard.
[01:26:50.020 --> 01:26:51.780]   Yeah, I know it's kind of slow.
[01:26:51.780 --> 01:26:53.300]   The chip in it is not great.
[01:26:53.300 --> 01:26:54.980]   It's an M core M processor.
[01:26:54.980 --> 01:26:56.260]   Yeah, mobile chip.
[01:26:56.260 --> 01:27:00.820]   And of course, Microsoft did announce the Surface laptop, which is kind of their version of the
[01:27:00.820 --> 01:27:06.420]   MacBook, except with a la contra, a fine a la contra fabric on the keyboard.
[01:27:06.420 --> 01:27:07.780]   Their hardware has come a long way though.
[01:27:07.780 --> 01:27:10.340]   But I'm using the Surface Studio.
[01:27:10.340 --> 01:27:16.260]   I'm really like this and I ordered a Mac, rather a Surface isn't that interesting.
[01:27:16.260 --> 01:27:19.140]   I called it a Mac, but it's a Surface laptop, I ordered one.
[01:27:19.140 --> 01:27:20.900]   I think, and we were talking about this before the show.
[01:27:21.620 --> 01:27:24.980]   Nowadays, a lot of what people do isn't really on an operating system.
[01:27:24.980 --> 01:27:26.100]   It's in the Cloud.
[01:27:26.100 --> 01:27:28.100]   Most computing is done in the browser.
[01:27:28.100 --> 01:27:30.420]   So the operating system gets less and less important.
[01:27:30.420 --> 01:27:35.140]   The difference between a Mac and Windows 10 is so minor at this point, if mostly you do,
[01:27:35.140 --> 01:27:37.220]   you live in Chrome, it doesn't matter.
[01:27:37.220 --> 01:27:39.940]   So that's why I have my Chromebook, right?
[01:27:39.940 --> 01:27:46.100]   Well, in a Chromebook, boy, if you were running Windows 7, you probably wished you were running
[01:27:46.100 --> 01:27:47.300]   a Chromebook this week.
[01:27:47.300 --> 01:27:50.260]   WannaCry, what a nightmare.
[01:27:50.980 --> 01:27:54.500]   The biggest distinction between operating systems is security.
[01:27:54.500 --> 01:27:56.580]   It really seems that way.
[01:27:56.580 --> 01:28:01.860]   Although, don't patch yourself, you Mac users too much, because there are ransomware attacks.
[01:28:01.860 --> 01:28:02.340]   There are.
[01:28:02.340 --> 01:28:04.740]   Nowhere near, and there's no WannaCry.
[01:28:04.740 --> 01:28:10.100]   It's an interesting thing because WannaCry is just another kind of ransomware.
[01:28:10.100 --> 01:28:16.900]   It's spread rapidly because it was able to take advantage of an exploit in Windows SMB.
[01:28:16.900 --> 01:28:23.460]   There's a Samba messaging, which is, I call it Samba, there's something message block,
[01:28:23.460 --> 01:28:24.980]   a camera, single message block.
[01:28:24.980 --> 01:28:30.260]   They're networking technology that allowed it to spread as a worm throughout the entire land.
[01:28:30.260 --> 01:28:33.860]   So if you got it on a laptop, brought it into work, the whole place would go down.
[01:28:33.860 --> 01:28:40.820]   Unless they were running Windows 10 or they had patched Windows 7, we're seeing now that
[01:28:40.820 --> 01:28:43.780]   almost 98% of the infections are Windows 7.
[01:28:43.780 --> 01:28:48.580]   Very few XP people got bit because there aren't very many XP machines attached to the internet.
[01:28:48.580 --> 01:28:56.500]   Microsoft had patched it in March, but a lot of businesses don't update their patches.
[01:28:56.500 --> 01:28:58.580]   And now here's the kind of the double twist.
[01:28:58.580 --> 01:29:03.860]   Microsoft was really angry at the NSA saying, "It's your fault if you hadn't found this
[01:29:03.860 --> 01:29:09.300]   exploit. If you just told us, we wouldn't have had this problem.
[01:29:10.500 --> 01:29:17.620]   The only reason they patched it is because the NSA got hacked or leaked and the shadow brokers
[01:29:17.620 --> 01:29:22.580]   published gigabytes of data about NSA exploits, one of which was this SMB exploit.
[01:29:22.580 --> 01:29:26.340]   But now there's a guy who's created a fix for WannaCry.
[01:29:26.340 --> 01:29:33.540]   If you haven't rebooted, there is a fix for WannaCry that is, it's kind of Microsoft,
[01:29:33.540 --> 01:29:34.980]   give it the Microsoft, take it away.
[01:29:35.540 --> 01:29:42.100]   Another bug in Microsoft Windows that, so it turns out that the WannaCry guys were,
[01:29:42.100 --> 01:29:45.060]   you know, they were efficient.
[01:29:45.060 --> 01:29:48.740]   They used Microsoft's own encryption technology to encrypt the hard drive.
[01:29:48.740 --> 01:29:53.780]   It turns out there's a flaw in Microsoft's encryption technology.
[01:29:53.780 --> 01:29:58.100]   It keeps the two prime numbers, the factors in RAM.
[01:29:59.220 --> 01:30:06.820]   And so a guy has written a program that goes through RAM, finds that if you haven't rebooted,
[01:30:06.820 --> 01:30:11.460]   if you rebooted all bets are off, finds the key and it will unlock your hard drive.
[01:30:11.460 --> 01:30:17.940]   I mentioned that carefully. Dan Gouden writes about it and I trust Dan.
[01:30:17.940 --> 01:30:18.980]   It only works for XP?
[01:30:18.980 --> 01:30:23.460]   Yeah, yeah, it looks like it only works for XP.
[01:30:23.460 --> 01:30:24.820]   I'm not sure. I think that maybe...
[01:30:28.260 --> 01:30:32.020]   I don't know. This might be an older article and there might be more to say about it.
[01:30:32.020 --> 01:30:38.180]   In any event, I just find it ironic that it's something poorly written about Microsoft's
[01:30:38.180 --> 01:30:42.100]   cryptographic application programming interface or API.
[01:30:42.100 --> 01:30:46.260]   It keeps those keys in memory, which is of course a stupid thing to do.
[01:30:46.260 --> 01:30:52.100]   But maybe you can fix your Windows XP.
[01:30:52.100 --> 01:30:53.540]   Don't be fooled though.
[01:30:53.540 --> 01:30:58.820]   There are a lot of people out there who offer phony, ransomware decryption tools.
[01:30:58.820 --> 01:31:01.860]   There are some cases where they work, but in a lot of cases they don't.
[01:31:01.860 --> 01:31:12.500]   Eternal Blue was the NSA exploit that WannaCry took advantage of.
[01:31:12.500 --> 01:31:18.100]   And so how did the pizza... how did the guy who stopped to find...
[01:31:18.100 --> 01:31:20.020]   What did it take to find the kill switch?
[01:31:20.020 --> 01:31:22.260]   Oh, the kill switch is funny.
[01:31:22.260 --> 01:31:23.540]   So that's another story.
[01:31:23.540 --> 01:31:25.300]   This isn't the kill switch, but that's another story.
[01:31:25.300 --> 01:31:32.740]   I saw one or two reports that some intelligence officials think that WannaCry
[01:31:32.740 --> 01:31:37.300]   comes from North Korea, that it was actually a state-sponsored attack,
[01:31:37.300 --> 01:31:39.620]   which makes sense because they've made very little money.
[01:31:39.620 --> 01:31:42.100]   Most of these ransomware don't make a lot of money.
[01:31:42.100 --> 01:31:44.420]   And it was well written.
[01:31:44.420 --> 01:31:47.780]   It was translated into more than a dozen languages.
[01:31:47.780 --> 01:31:51.780]   It had a very helpful link of what is Bitcoin and how to buy Bitcoin.
[01:31:51.780 --> 01:31:56.660]   And it had a kill switch, which is not something the typical Macedonian hacker
[01:31:56.660 --> 01:31:58.980]   would build in.
[01:31:58.980 --> 01:32:04.340]   The kill switch worked that there was a very long obscure URL that didn't exist.
[01:32:04.340 --> 01:32:07.780]   It wasn't registered as a domain, but WannaCry would go out,
[01:32:07.780 --> 01:32:10.260]   would check the web to see if this domain existed.
[01:32:10.260 --> 01:32:13.620]   If it did, it would say, "Okay, I've been terminated and would not take
[01:32:13.620 --> 01:32:15.220]   your Scripture hard drive."
[01:32:15.220 --> 01:32:17.460]   So somebody was going through the code.
[01:32:17.460 --> 01:32:18.500]   He didn't even know what it would do.
[01:32:18.500 --> 01:32:20.580]   He just thought, "Well, I should register this domain name."
[01:32:20.580 --> 01:32:24.420]   He created a website there and it stopped WannaCry because WannaCry said,
[01:32:24.420 --> 01:32:25.300]   "Oh, there's a website.
[01:32:25.300 --> 01:32:26.660]   We've been turned off."
[01:32:26.660 --> 01:32:30.100]   Then people who wanted retroactively use WannaCry,
[01:32:30.100 --> 01:32:34.820]   probably not North Korea, but just random script kitties.
[01:32:34.820 --> 01:32:36.820]   A couple of them tried to overwrite.
[01:32:36.820 --> 01:32:41.620]   They took the WannaCry source code and they'd use a hex editor to overwrite a domain name.
[01:32:41.620 --> 01:32:45.780]   And then now there's a DDoS attack against the domain,
[01:32:45.780 --> 01:32:48.420]   hoping that that will react to free flight cry.
[01:32:48.420 --> 01:32:49.220]   Take it offline.
[01:32:49.220 --> 01:32:49.780]   Wow.
[01:32:49.780 --> 01:32:52.580]   It's just, it's what a world.
[01:32:52.580 --> 01:32:54.180]   I blame Ev with it.
[01:32:54.180 --> 01:32:55.060]   Williams and Twitter.
[01:32:55.060 --> 01:32:57.380]   Thanks, Ev.
[01:32:57.380 --> 01:33:02.340]   Yeah, the New York Times said actually the clues point to North Korea,
[01:33:02.340 --> 01:33:09.540]   partly because some of the code is very similar to the code used in the Sony exploit,
[01:33:09.540 --> 01:33:14.100]   which intelligence officials also believe came from North Korea.
[01:33:14.100 --> 01:33:18.660]   Also a Bangladesh bank attack last year in Polish banks in February.
[01:33:19.540 --> 01:33:22.500]   American officials said they'd seen the same similarities.
[01:33:22.500 --> 01:33:23.140]   I don't know.
[01:33:23.140 --> 01:33:26.500]   If when in debt blamed North Korea.
[01:33:26.500 --> 01:33:29.140]   Do you think that either could have been done for hire by somebody?
[01:33:29.140 --> 01:33:30.020]   Yeah.
[01:33:30.020 --> 01:33:32.500]   I mean, it's so hard to know where this stuff comes from.
[01:33:32.500 --> 01:33:36.660]   And of course, by now others are reusing WannaCry code.
[01:33:36.660 --> 01:33:41.460]   Although I feel like this does sort of help Microsoft's point that the
[01:33:41.460 --> 01:33:43.140]   NSA should have told them about it.
[01:33:43.140 --> 01:33:43.140]   Oh.
[01:33:43.140 --> 01:33:44.980]   If it were an orthogrion weapon.
[01:33:44.980 --> 01:33:45.220]   Yeah.
[01:33:45.220 --> 01:33:47.060]   Like, the NSA should have been like,
[01:33:47.060 --> 01:33:51.380]   oh, we found this thing, an enemy of the state plans to use.
[01:33:51.380 --> 01:33:52.580]   You might want to fix it.
[01:33:52.580 --> 01:33:52.820]   Yeah.
[01:33:52.820 --> 01:34:00.900]   Well, on the other hand, if you're the NSA, you've spent great time and effort to collect
[01:34:00.900 --> 01:34:04.820]   a bunch of exploits that will help you spy on Mark Millian.
[01:34:04.820 --> 01:34:07.460]   As soon as he starts contacting terrorist rings,
[01:34:07.460 --> 01:34:09.700]   I just use your name in vain.
[01:34:09.700 --> 01:34:10.180]   I shouldn't.
[01:34:10.180 --> 01:34:12.420]   I should use my own name, Leo Laport when he attacks.
[01:34:12.420 --> 01:34:14.500]   You know, when he starts to communicate.
[01:34:14.500 --> 01:34:15.540]   Now on the NSA watch list.
[01:34:15.540 --> 01:34:16.260]   Yeah. Well, I know.
[01:34:16.260 --> 01:34:17.940]   I just put you on the watch list.
[01:34:17.940 --> 01:34:18.820]   I'm so sorry.
[01:34:18.820 --> 01:34:21.140]   It's my last fault.
[01:34:21.140 --> 01:34:27.060]   Blame have that they would want to stockpile those and keep them now.
[01:34:27.060 --> 01:34:28.340]   You got to keep them guys.
[01:34:28.340 --> 01:34:30.980]   If you make them, make, you know, if you create these exploits,
[01:34:30.980 --> 01:34:32.820]   you better lock them up really tight.
[01:34:32.820 --> 01:34:34.900]   And they didn't somehow.
[01:34:34.900 --> 01:34:40.100]   We don't know how, but maybe a maybe a contractor like Edward Snowden leaked these out to
[01:34:40.100 --> 01:34:47.940]   WikiLeaks and, you know, Microsoft as soon as they found them patched them in March.
[01:34:47.940 --> 01:34:51.940]   But yeah, I mean, I think Microsoft goes a little overboard in blaming the NSA.
[01:34:51.940 --> 01:34:56.020]   I don't, I think that don't you think everybody's stockpiling these?
[01:34:56.020 --> 01:35:00.420]   It is unreasonable for a company to think that their government is going to
[01:35:00.420 --> 01:35:05.780]   clue them into a weapon that they basically that turns the NSA into a security outfit
[01:35:05.780 --> 01:35:06.820]   protecting Microsoft.
[01:35:06.820 --> 01:35:08.420]   That's maybe that's what they should do.
[01:35:08.420 --> 01:35:08.900]   I don't know.
[01:35:09.780 --> 01:35:10.260]   I don't know.
[01:35:10.260 --> 01:35:18.740]   Actually, I want to talk about Theresa May and the UK, because of course there's an election
[01:35:18.740 --> 01:35:23.780]   coming up for for a prime for actually it's whole primary.
[01:35:23.780 --> 01:35:29.700]   This whole system is confusing this parliamentary system, but there's an election coming up.
[01:35:29.700 --> 01:35:33.700]   There will be perhaps a new Prime Minister Theresa May would like to keep her job.
[01:35:33.700 --> 01:35:36.900]   And the platform is she's a Tory?
[01:35:39.060 --> 01:35:41.300]   She's like she should be wearing a wig if she's a Tory.
[01:35:41.300 --> 01:35:46.260]   The platform of the Tories has something that is notorious.
[01:35:46.260 --> 01:35:49.060]   We'll get to that in just a second.
[01:35:49.060 --> 01:35:53.700]   Mark Billian, Bloomberg Business Week, Bloomberg.com/tech always great.
[01:35:53.700 --> 01:35:54.660]   I haven't seen you in so long.
[01:35:54.660 --> 01:35:56.900]   I feel like we have much catching up to do.
[01:35:56.900 --> 01:35:58.980]   It's great to see you.
[01:35:58.980 --> 01:35:59.460]   Likewise.
[01:35:59.460 --> 01:36:00.500]   Is Goron yours?
[01:36:00.500 --> 01:36:01.620]   Goron's mine.
[01:36:01.620 --> 01:36:02.420]   Mine and my wife.
[01:36:02.420 --> 01:36:02.660]   Of course.
[01:36:02.660 --> 01:36:03.700]   What is Goron up to?
[01:36:03.700 --> 01:36:06.180]   I feel like I just saw something from Goron.
[01:36:06.180 --> 01:36:07.540]   I'm willing to bet he's sleeping.
[01:36:07.540 --> 01:36:08.660]   He's a French bulldog.
[01:36:08.660 --> 01:36:10.340]   Usually what he's doing.
[01:36:10.340 --> 01:36:12.660]   I follow him everywhere on Instagram on Twitter.
[01:36:12.660 --> 01:36:14.980]   Instagram.com/GoronSF.
[01:36:14.980 --> 01:36:16.820]   I'm a huge Goron fan.
[01:36:16.820 --> 01:36:20.340]   And I feel like something I just saw something about him.
[01:36:20.340 --> 01:36:21.940]   He's sleeping though.
[01:36:21.940 --> 01:36:23.460]   That's what Bulldog French bulldog's doing.
[01:36:23.460 --> 01:36:24.420]   We'll be doggsing him in a couple weeks.
[01:36:24.420 --> 01:36:25.620]   He's the cutest dog ever.
[01:36:25.620 --> 01:36:26.900]   Will you bring him in?
[01:36:26.900 --> 01:36:27.620]   I would love to.
[01:36:27.620 --> 01:36:28.900]   I'm actually glad you asked.
[01:36:28.900 --> 01:36:30.020]   I will bring Goron.
[01:36:30.020 --> 01:36:32.020]   Oh, I've never met Goron.
[01:36:32.020 --> 01:36:34.100]   There he is doing it.
[01:36:34.100 --> 01:36:36.580]   Oh, Mark's dog.
[01:36:36.580 --> 01:36:37.460]   What is Goron?
[01:36:37.460 --> 01:36:38.260]   What is that name?
[01:36:38.580 --> 01:36:40.020]   It's from the legend of Zelda.
[01:36:40.020 --> 01:36:41.620]   Of course it is.
[01:36:41.620 --> 01:36:42.180]   Should have known.
[01:36:42.180 --> 01:36:43.780]   The mountain creatures.
[01:36:43.780 --> 01:36:45.460]   I've been playing the new Zelda a lot.
[01:36:45.460 --> 01:36:46.420]   I love it.
[01:36:46.420 --> 01:36:47.460]   Excellent games.
[01:36:47.460 --> 01:36:50.660]   We actually just got tickets to the Symphony of the Goddess.
[01:36:50.660 --> 01:36:53.620]   Basically, Nintendo has an orchestra that travels around
[01:36:53.620 --> 01:36:55.060]   playing all the Zelda music.
[01:36:55.060 --> 01:36:55.780]   Oh, that'd be fun.
[01:36:55.780 --> 01:36:58.180]   And they play like parts of the game on screen.
[01:36:58.180 --> 01:37:00.020]   So we're going to go see that in August.
[01:37:00.020 --> 01:37:00.980]   That would be really fun.
[01:37:00.980 --> 01:37:02.100]   Maybe Symphony Hall in San Francisco.
[01:37:02.100 --> 01:37:04.740]   Is a whole bunch of people from Twitter doing that?
[01:37:04.740 --> 01:37:06.500]   Because I know they like to do that.
[01:37:06.500 --> 01:37:09.940]   They went to the, was it Star Wars concert?
[01:37:09.940 --> 01:37:10.900]   Yes, you come.
[01:37:10.900 --> 01:37:12.180]   No, it was a Star Trek concert.
[01:37:12.180 --> 01:37:12.740]   Yeah.
[01:37:12.740 --> 01:37:14.260]   We're going to have to ask.
[01:37:14.260 --> 01:37:15.140]   We're going to have to see what's up.
[01:37:15.140 --> 01:37:16.340]   That's Nathan Oliveras Giles.
[01:37:16.340 --> 01:37:18.740]   He is in charge of parties here at Twit.
[01:37:18.740 --> 01:37:21.940]   Just have our concert master.
[01:37:21.940 --> 01:37:24.900]   Also, of course, Jeff Jarvis.
[01:37:24.900 --> 01:37:25.940]   Great to have you all.
[01:37:25.940 --> 01:37:27.460]   Our show today brought to you by Guess What?
[01:37:27.460 --> 01:37:28.500]   WordPress.
[01:37:28.500 --> 01:37:28.820]   Yay!
[01:37:28.820 --> 01:37:31.700]   I just moved my site back to WordPress.
[01:37:31.700 --> 01:37:33.380]   I love you.
[01:37:33.380 --> 01:37:35.860]   You could take a look at leoleport.com.
[01:37:36.660 --> 01:37:39.940]   I love WordPress because I've used it for years.
[01:37:39.940 --> 01:37:43.700]   That's been my longest standing blogging platform.
[01:37:43.700 --> 01:37:47.700]   I just think it's gorgeous and it was so easy to move stuff over.
[01:37:47.700 --> 01:37:52.340]   And WordPress.com is a really great solution because WordPress
[01:37:52.340 --> 01:37:56.580]   does all of the upgrades, all the security patches.
[01:37:56.580 --> 01:37:58.980]   And that was the, I used to self-host, right?
[01:37:58.980 --> 01:38:01.460]   And it was so, you know, I was always patching.
[01:38:01.460 --> 01:38:03.300]   This way, they keep it up to date.
[01:38:03.300 --> 01:38:06.580]   They give you all the great templates you could ever want.
[01:38:06.580 --> 01:38:09.460]   They've got a great support team.
[01:38:09.460 --> 01:38:11.220]   I actually took advantage of their support team.
[01:38:11.220 --> 01:38:14.580]   I said, "I want a full bleed slideshow on my front page.
[01:38:14.580 --> 01:38:15.140]   How do I do it?"
[01:38:15.140 --> 01:38:19.220]   And they told me, "Oh, you'd like the 21st century template."
[01:38:19.220 --> 01:38:19.620]   I do.
[01:38:19.620 --> 01:38:21.220]   It's very nice.
[01:38:21.220 --> 01:38:24.180]   We use WordPress.com every day.
[01:38:24.180 --> 01:38:27.300]   In fact, you believe it or not use WordPress.com every day
[01:38:27.300 --> 01:38:31.300]   because WordPress runs 27% of all the websites in the world.
[01:38:32.420 --> 01:38:35.460]   So whether you're looking to create a personal blog or a business site or both,
[01:38:35.460 --> 01:38:39.220]   you're going to make a big impact when you build your business on WordPress.com.
[01:38:39.220 --> 01:38:40.500]   There's a community there too.
[01:38:40.500 --> 01:38:43.620]   I get a, there's a little follow button on my WordPress site.
[01:38:43.620 --> 01:38:47.300]   And I have, I didn't even know there's a huge number of followers.
[01:38:47.300 --> 01:38:53.220]   I have 593,898 followers at WordPress.com.
[01:38:53.220 --> 01:38:55.620]   That's just because I'm on WordPress.
[01:38:55.620 --> 01:38:56.420]   That's awesome.
[01:38:56.420 --> 01:38:58.980]   Hundreds of themes to get started.
[01:38:58.980 --> 01:39:00.340]   Pick a template, make it your own.
[01:39:00.340 --> 01:39:05.460]   Of course, the beauty of WordPress is that all the content is separate from the theme.
[01:39:05.460 --> 01:39:08.900]   So if you, you know, you say, "I want to change the content.
[01:39:08.900 --> 01:39:10.500]   I have to change the theme today."
[01:39:10.500 --> 01:39:11.380]   It's easy to do.
[01:39:11.380 --> 01:39:13.620]   Connect in all your social networks.
[01:39:13.620 --> 01:39:20.020]   I've got my Instagram updates, my Twitter updates, even my, you know, my indie web
[01:39:20.020 --> 01:39:23.380]   updates feed into my WordPress website.
[01:39:23.380 --> 01:39:24.180]   And I love that.
[01:39:24.180 --> 01:39:26.900]   And it supports there 24/7.
[01:39:28.020 --> 01:39:31.940]   More websites run on WordPress than any other platform, including many of the
[01:39:31.940 --> 01:39:34.340]   publications that you read every day.
[01:39:34.340 --> 01:39:36.340]   Paul Therat's site, WordPress.com.
[01:39:36.340 --> 01:39:38.580]   So many sites are on WordPress.
[01:39:38.580 --> 01:39:41.460]   It's a great content management system.
[01:39:41.460 --> 01:39:42.180]   Get started today.
[01:39:42.180 --> 01:39:45.620]   We're going to give you 15% off any new plan purchase.
[01:39:45.620 --> 01:39:50.180]   Go to WordPress.com/twit to create your website and find the membership plan
[01:39:50.180 --> 01:39:52.020]   that is right for you.
[01:39:52.020 --> 01:39:57.460]   WordPress.com/twit for 15% off.
[01:39:57.940 --> 01:40:01.700]   I'm actually very pleased to say, oh, I took off the archives link.
[01:40:01.700 --> 01:40:06.980]   I got to fix that, that I was able to get every blog post going back that I've made
[01:40:06.980 --> 01:40:10.100]   to 2000 or 2001 when I started blogging.
[01:40:10.100 --> 01:40:13.860]   And I was able to import that right back into WordPress.
[01:40:13.860 --> 01:40:15.380]   And that's really great, you know.
[01:40:15.380 --> 01:40:17.380]   And now I own it.
[01:40:17.380 --> 01:40:17.940]   It's mine.
[01:40:17.940 --> 01:40:18.420]   I got it.
[01:40:18.420 --> 01:40:21.940]   WordPress.com/twit.
[01:40:21.940 --> 01:40:23.380]   In fact, I'm looking at my tweets.
[01:40:23.380 --> 01:40:26.340]   And here's the story right there from BuzzFeed.
[01:40:26.340 --> 01:40:31.140]   Theresa May wants to irregular the internet.
[01:40:31.140 --> 01:40:37.540]   So the conservative platform, they call it their election manifesto,
[01:40:37.540 --> 01:40:41.300]   has a line at the very end.
[01:40:41.300 --> 01:40:43.700]   BuzzFeed found this that goes like this.
[01:40:43.700 --> 01:40:50.580]   Some people say that it is not for government to regulate when it comes to technology in the internet.
[01:40:50.580 --> 01:40:52.260]   We disagree.
[01:40:52.260 --> 01:40:54.580]   So polite.
[01:40:54.580 --> 01:40:55.300]   So nice.
[01:40:55.940 --> 01:41:03.300]   But what it really means is that the Tories who, Theresa May wrote the Snoopers Charter,
[01:41:03.300 --> 01:41:08.580]   she sponsored it when she was a member of parliament, got it forced through when she became PM.
[01:41:08.580 --> 01:41:15.780]   And now it looks like the conservatives, if they win the election and the polls say that
[01:41:15.780 --> 01:41:23.140]   May will win a majority in next month's election, they will have a mandate to significantly extend
[01:41:23.140 --> 01:41:29.140]   internet regulation, all based on the idea, I'm quoting BuzzFeed, that it's a government
[01:41:29.140 --> 01:41:33.780]   duty to protect citizens, just as much on the internet as it does in the real world.
[01:41:33.780 --> 01:41:41.940]   The proposals, which apparently are all over the manifesto, involve all kinds of things.
[01:41:41.940 --> 01:41:45.060]   Legislation would be introduced, for instance, to protect the public from abuse
[01:41:45.060 --> 01:41:47.620]   and offensive material online.
[01:41:47.620 --> 01:41:53.060]   Everyone would have a right to be forgotten, the right to white material that was posted
[01:41:53.300 --> 01:41:54.740]   when they were under 18.
[01:41:54.740 --> 01:41:59.620]   Internet companies would be asked to help promote counter extremism narratives.
[01:41:59.620 --> 01:42:06.500]   I don't know what that means at all, but that's scary.
[01:42:06.500 --> 01:42:10.260]   There'd be new rules requiring companies to make it ever harder for people to access
[01:42:10.260 --> 01:42:12.100]   pornography and violent images.
[01:42:12.100 --> 01:42:16.660]   Content creators would have to justify their policies to the government.
[01:42:16.660 --> 01:42:20.900]   And by the way, even if labor won, it ain't so very different.
[01:42:21.700 --> 01:42:28.580]   So this is my fear when we talk about fake news and we talk about, you know, how the
[01:42:28.580 --> 01:42:34.980]   democratization of the internet has brought us has brought a lot of negative voices to the
[01:42:34.980 --> 01:42:40.340]   fore. I really worry when we say let's control them that this is the end result of it.
[01:42:40.340 --> 01:42:41.540]   I agree.
[01:42:41.540 --> 01:42:44.660]   And if you look at the Guardian is not helping things, the Guardian had a story, I think we
[01:42:44.660 --> 01:42:51.860]   might have mentioned briefly before that that goes into the instructions for people who monitor
[01:42:51.860 --> 01:42:54.180]   complaints on Facebook.
[01:42:54.180 --> 01:42:57.620]   And it's not frightening about Facebook.
[01:42:57.620 --> 01:42:58.820]   It's afraid about mankind.
[01:42:58.820 --> 01:43:02.020]   What we do and what we do in public.
[01:43:02.020 --> 01:43:08.420]   And so you put this kind of stuff out there and the reflex is surely shut this down,
[01:43:08.420 --> 01:43:10.020]   package this, edit the world.
[01:43:10.020 --> 01:43:12.660]   But I don't want anybody to edit the world.
[01:43:12.660 --> 01:43:18.580]   Yeah, but at the same time, you know, one of the one of the guidelines is revenge porn.
[01:43:18.580 --> 01:43:20.740]   That's reprehensible.
[01:43:20.740 --> 01:43:21.540]   It's horrible.
[01:43:21.540 --> 01:43:25.460]   It's the victim has a miserable time stopping it.
[01:43:25.460 --> 01:43:31.940]   It's really, you know, something that the internet kind of makes very easy.
[01:43:31.940 --> 01:43:34.820]   And I just don't know what the what the answer is.
[01:43:34.820 --> 01:43:39.620]   Well, I think there should be a distinction too between Facebook versus, you know, the
[01:43:39.620 --> 01:43:42.740]   UK's government Facebook is a closed social network.
[01:43:42.740 --> 01:43:43.620]   It's a business.
[01:43:43.620 --> 01:43:47.860]   It's a place where you share things and they put ads next to those things and then they make
[01:43:47.860 --> 01:43:48.660]   money off of that, right?
[01:43:48.660 --> 01:43:56.900]   What the UK is talking about is kind of taking a censorship approach to the internet as a whole
[01:43:56.900 --> 01:43:59.300]   as it exists in its country.
[01:43:59.300 --> 01:44:01.140]   And that's those are two totally different things.
[01:44:01.140 --> 01:44:06.420]   I mean, now for many people, Facebook is where they get most of their news and they
[01:44:06.420 --> 01:44:11.140]   communicate with friends and families.
[01:44:11.140 --> 01:44:12.660]   So in some senses for those specific folks, it might be their internet because that's the
[01:44:12.660 --> 01:44:15.060]   only part of the internet they're hanging out on.
[01:44:15.060 --> 01:44:16.660]   But it's not the internet, right?
[01:44:16.660 --> 01:44:17.540]   It is a business.
[01:44:17.540 --> 01:44:19.620]   It is a closed space.
[01:44:19.620 --> 01:44:22.660]   You need a password to get in and all that stuff.
[01:44:22.660 --> 01:44:28.580]   It's not public versus the stuff that the UK is talking about.
[01:44:28.580 --> 01:44:32.740]   And like you as you mentioned, between the Tories or the labor party, there's not much
[01:44:32.740 --> 01:44:39.460]   difference in the way that they're trying to approach that regulation, which in this
[01:44:39.460 --> 01:44:41.460]   instance amounts to censorship.
[01:44:41.460 --> 01:44:45.380]   It's going to be a really interesting time in the UK because they had essentially
[01:44:45.380 --> 01:44:48.820]   seeded all of internet regulation to the EU when they were part of it.
[01:44:48.820 --> 01:44:51.060]   Now that they're breaking, they get to get something.
[01:44:51.060 --> 01:44:51.620]   Interesting.
[01:44:51.620 --> 01:44:52.100]   Interesting.
[01:44:52.100 --> 01:44:55.540]   The EU has been aggressive, but not this aggressive.
[01:44:55.540 --> 01:44:56.580]   Right.
[01:44:56.580 --> 01:45:02.100]   And in the discussions around internet regulation, when Britain was apart and they're still
[01:45:02.100 --> 01:45:08.660]   a part of the EU, but in those contexts, the UK would usually be more on the side of
[01:45:08.660 --> 01:45:13.220]   a leniency like where the US was and Germany would be on the far other end.
[01:45:13.220 --> 01:45:18.900]   So it's now we'll see, has the UK shifted a little bit?
[01:45:18.900 --> 01:45:19.460]   Are they swinging?
[01:45:19.460 --> 01:45:22.420]   Are they disassociating from the US mentality?
[01:45:22.420 --> 01:45:28.020]   And what will the US do now that Donald Trump seems to be a little more eager toward
[01:45:28.020 --> 01:45:28.980]   regulation?
[01:45:28.980 --> 01:45:34.500]   Well, even if we don't hear in the US, when a country like England, a big country like
[01:45:34.500 --> 01:45:37.460]   England does this, it affects every company that works in it.
[01:45:37.460 --> 01:45:38.260]   Oh, yeah, definitely.
[01:45:38.260 --> 01:45:38.500]   Yeah.
[01:45:38.500 --> 01:45:43.940]   And I mean, I guess Google could change its search results in England and not here.
[01:45:43.940 --> 01:45:46.340]   They do that with the right to be forgotten in the EU, right?
[01:45:46.340 --> 01:45:47.860]   Yep.
[01:45:47.860 --> 01:45:48.580]   Yep.
[01:45:48.580 --> 01:45:49.860]   Yeah, but it says the precedents.
[01:45:49.860 --> 01:45:51.780]   I think Marx really write it.
[01:45:51.780 --> 01:45:55.060]   Then it's a chase down.
[01:45:55.700 --> 01:45:59.380]   And part of the problem here is that we're concentrating, this is back to the end point.
[01:45:59.380 --> 01:46:01.060]   We're constantly concentrating on the bad.
[01:46:01.060 --> 01:46:03.460]   We're trying to play whack-a-mole with the bad.
[01:46:03.460 --> 01:46:07.540]   We're never going to get rid of Achan and Fordchan and the bad parts of Reddit.
[01:46:07.540 --> 01:46:10.900]   They're going to find a place to go.
[01:46:10.900 --> 01:46:15.220]   And if that's all we concentrate on, then we got a problem.
[01:46:15.220 --> 01:46:19.380]   Whereas if we find ways to support the good, and there's lots and lots of good,
[01:46:19.380 --> 01:46:23.620]   as Nate said earlier, then that's what we have to put our energy behind.
[01:46:23.620 --> 01:46:28.260]   And part of the problem is that the manipulation works so well,
[01:46:28.260 --> 01:46:30.100]   that you do the bad stuff.
[01:46:30.100 --> 01:46:37.220]   The reports, they're historical also as a report coming up Monday that we help fund at NII,
[01:46:37.220 --> 01:46:40.740]   the thing I'm running now, the News Integrity Initiative.
[01:46:40.740 --> 01:46:46.740]   And it's fascinating to see how quickly things rise from 8chan and 4chan up to bright part,
[01:46:46.740 --> 01:46:47.860]   up to the world.
[01:46:47.860 --> 01:46:52.580]   And media is still set up at a point where they swallow it,
[01:46:52.580 --> 01:46:53.940]   and they give it promotion.
[01:46:53.940 --> 01:46:54.900]   And that's the goal.
[01:46:54.900 --> 01:47:00.260]   And so that's the vision of the world that we see is a very tiny, small number of people who do
[01:47:00.260 --> 01:47:04.260]   crappy stuff get huge amplification in media.
[01:47:04.260 --> 01:47:06.260]   So it's not the fault of the internet.
[01:47:06.260 --> 01:47:08.660]   It's as much as fault of the media as anybody else.
[01:47:08.660 --> 01:47:09.620]   And that's what we have to fix.
[01:47:09.620 --> 01:47:16.180]   If you look at these rules at Facebook's, was this leaked to the Guardian?
[01:47:16.180 --> 01:47:16.980]   Yeah, it was leaked.
[01:47:16.980 --> 01:47:17.460]   Yeah.
[01:47:17.460 --> 01:47:17.620]   Yeah.
[01:47:17.620 --> 01:47:21.780]   For, well, in the slide deck, and I guess this is used for training,
[01:47:21.780 --> 01:47:28.260]   they call it the Facebook files, it says that moderators often have just 10 seconds
[01:47:28.260 --> 01:47:29.140]   to make a decision.
[01:47:29.140 --> 01:47:32.100]   There's so much content that they have to review.
[01:47:32.100 --> 01:47:36.020]   One document says Facebook reviews more than 6.5 million reports a week
[01:47:36.020 --> 01:47:38.500]   on fake accounts alone.
[01:47:38.500 --> 01:47:40.900]   Fake accounts alone.
[01:47:40.900 --> 01:47:46.260]   I would hate to be, this would be a tough job, and you'd have to work very quickly.
[01:47:46.260 --> 01:47:51.060]   And if you read the rules, you know, it's not immediately obvious.
[01:47:52.020 --> 01:47:52.260]   No.
[01:47:52.260 --> 01:47:59.140]   For instance, videos of violent death, while marked as disturbing, do not always have to be deleted,
[01:47:59.140 --> 01:48:03.220]   because they can help create awareness of issues such as mental illness.
[01:48:03.220 --> 01:48:08.180]   If they celebrate or encourage, they're taken down.
[01:48:08.180 --> 01:48:10.260]   But if they are there, this is a journalistic issue.
[01:48:10.260 --> 01:48:15.940]   If you have Ferguson, if Facebook took down, if Twitter took down the videos from Ferguson,
[01:48:16.500 --> 01:48:23.540]   we never would have seen the Black Lives Matter outcry that was able to gather around it.
[01:48:23.540 --> 01:48:26.100]   So pictures of death matter.
[01:48:26.100 --> 01:48:26.980]   It's difficult.
[01:48:26.980 --> 01:48:31.380]   Videos of abortions are allowed as long as there's no nudity.
[01:48:31.380 --> 01:48:33.620]   That's just weird.
[01:48:33.620 --> 01:48:39.460]   If you want to live stream attempts to self-harm, Facebook will allow it
[01:48:39.460 --> 01:48:42.980]   because, quote, "It doesn't want to censor or punish people into stress."
[01:48:45.060 --> 01:48:47.860]   These are hard, hard, hard decisions.
[01:48:47.860 --> 01:48:50.740]   The problem is you can read any of that stuff and say, "Oh my God, look what Facebook's doing
[01:48:50.740 --> 01:48:51.220]   in the world."
[01:48:51.220 --> 01:48:52.820]   No, look what the world is doing to itself.
[01:48:52.820 --> 01:48:57.140]   And Facebook is in this position of judging now.
[01:48:57.140 --> 01:49:00.340]   I'm not saying they do things right.
[01:49:00.340 --> 01:49:02.100]   They have the Vietnam-Nepam photo.
[01:49:02.100 --> 01:49:06.340]   They've screwed things up, but these are hard human decisions.
[01:49:06.340 --> 01:49:08.420]   And then an algorithm is not going to make them well.
[01:49:08.420 --> 01:49:09.940]   And I got bad news for all of you.
[01:49:09.940 --> 01:49:14.180]   Anyone with more than 100,000 followers is a public figure.
[01:49:14.900 --> 01:49:17.860]   Which means you don't have the same protections as a private individual.
[01:49:17.860 --> 01:49:19.460]   They've actually given it a numeric.
[01:49:19.460 --> 01:49:23.620]   Mark millions quickly checking how many followers he has.
[01:49:23.620 --> 01:49:28.420]   Well, you're already a public figure because the blue check mark next year.
[01:49:28.420 --> 01:49:30.340]   Oh God, you just missed.
[01:49:30.340 --> 01:49:31.940]   Yeah.
[01:49:31.940 --> 01:49:33.780]   I don't know what that means.
[01:49:33.780 --> 01:49:34.820]   You're going to get more abuse.
[01:49:34.820 --> 01:49:38.580]   But this Guardian article is interesting.
[01:49:39.860 --> 01:49:46.260]   I don't know if you're allowed to say, "Kick a person with red hair,"
[01:49:46.260 --> 01:49:49.380]   but you're not allowed to say someone, "Shoot the president."
[01:49:49.380 --> 01:49:53.140]   You're allowed to say, "I don't even want to read this."
[01:49:53.140 --> 01:49:58.420]   You're allowed to say, "Let's beat up fat kids."
[01:49:58.420 --> 01:50:02.580]   But you can't say, "I don't even want to read these."
[01:50:02.580 --> 01:50:04.500]   I go, "I just, you should read the article.
[01:50:04.500 --> 01:50:05.380]   It's ridiculous.
[01:50:05.380 --> 01:50:07.140]   It's ridiculous."
[01:50:08.100 --> 01:50:12.260]   As Jeff said, these are the questions that they have to wrestle with
[01:50:12.260 --> 01:50:14.500]   because of the position they put themselves in.
[01:50:14.500 --> 01:50:18.100]   They understand they have to be explicit and train people.
[01:50:18.100 --> 01:50:19.460]   Yeah, this is okay.
[01:50:19.460 --> 01:50:20.260]   This is not.
[01:50:20.260 --> 01:50:22.020]   This is the company they built themselves to be.
[01:50:22.020 --> 01:50:25.380]   These are also guidelines driven by advertisers.
[01:50:25.380 --> 01:50:27.220]   It's not what advertisers are willing to stomach.
[01:50:27.220 --> 01:50:29.940]   You look at what happened with YouTube when they were serving ads
[01:50:29.940 --> 01:50:32.100]   next to neo-Nazi videos.
[01:50:32.100 --> 01:50:32.420]   Yeah.
[01:50:32.420 --> 01:50:33.380]   Yep.
[01:50:33.380 --> 01:50:35.300]   You know, they were doing that for a long time.
[01:50:35.940 --> 01:50:37.940]   And so the advertising is going.
[01:50:37.940 --> 01:50:38.260]   Yes.
[01:50:38.260 --> 01:50:41.380]   Not like other media where there's a problem of adjacency.
[01:50:41.380 --> 01:50:42.100]   Oh my God.
[01:50:42.100 --> 01:50:45.940]   You put my ad on Breitbart or on a neo-Nazi site or on a porn site, right?
[01:50:45.940 --> 01:50:51.140]   And Facebook, there's never once is the ad next to the same content.
[01:50:51.140 --> 01:50:54.180]   Right?
[01:50:54.180 --> 01:50:55.620]   Oh, well, it's similar to YouTube.
[01:50:55.620 --> 01:50:58.420]   It's on the column on the right though, right?
[01:50:58.420 --> 01:50:58.740]   Yeah.
[01:50:58.740 --> 01:51:01.620]   Well, it's all somebody's page and you don't, there's no adjacency there.
[01:51:01.620 --> 01:51:03.540]   Now they're changing that around, it's an article.
[01:51:03.540 --> 01:51:05.140]   There's going to be adjacencies.
[01:51:05.140 --> 01:51:07.860]   Right now on Facebook, there's not an adjacency problem so much.
[01:51:07.860 --> 01:51:10.500]   So I'm not so sure that it's advertiser motivated
[01:51:10.500 --> 01:51:14.100]   as it is fear of regulation motivated and bad PR motivated.
[01:51:14.100 --> 01:51:19.700]   But if they look at this, there's no way that if you're a member of Congress,
[01:51:19.700 --> 01:51:21.380]   you're going to say, oh, that's fine.
[01:51:21.380 --> 01:51:25.220]   Graphic violence, you can generally image your eventable abuse can be shared.
[01:51:25.220 --> 01:51:27.620]   You might want to mark it as disturbing.
[01:51:27.620 --> 01:51:29.780]   Yeah.
[01:51:33.060 --> 01:51:34.900]   And I could see Congress looking at this thing.
[01:51:34.900 --> 01:51:37.780]   Well, no, but then you have then, then, okay,
[01:51:37.780 --> 01:51:40.740]   let's say the Philadelphia Inquirer does a story on what's his name,
[01:51:40.740 --> 01:51:44.180]   who plays for the Philadelphia Eagles now, who got in trouble for animal abuse.
[01:51:44.180 --> 01:51:45.220]   Mike Vick.
[01:51:45.220 --> 01:51:46.660]   Thank you.
[01:51:46.660 --> 01:51:47.860]   One real man amongst.
[01:51:47.860 --> 01:51:50.100]   He actually was retired now.
[01:51:50.100 --> 01:51:52.740]   He hasn't played for the Eagles in two real man amongst.
[01:51:52.740 --> 01:51:53.300]   I wouldn't notice.
[01:51:53.300 --> 01:51:53.460]   Yeah.
[01:51:53.460 --> 01:51:53.940]   Yeah.
[01:51:53.940 --> 01:51:53.940]   Yeah.
[01:51:53.940 --> 01:51:57.300]   But, but if you get a report on,
[01:51:57.300 --> 01:52:01.540]   on, you know, somebody, somebody who's stuck in and did annual,
[01:52:01.540 --> 01:52:06.740]   I don't want to say, says that he's doing this, then should the Philadelphia Inquirers report be killed?
[01:52:06.740 --> 01:52:07.540]   No.
[01:52:07.540 --> 01:52:07.860]   All right.
[01:52:07.860 --> 01:52:09.220]   That's news.
[01:52:09.220 --> 01:52:13.860]   So, so the problem is the context, it just sounds like it's some sicko showing animal abuse.
[01:52:13.860 --> 01:52:16.100]   Well, maybe it's an expose of animal abuse.
[01:52:16.100 --> 01:52:18.340]   Maybe it's like, it's a necessary thing to
[01:52:18.340 --> 01:52:18.900]   fill out the world.
[01:52:18.900 --> 01:52:19.860]   Know what's going on.
[01:52:19.860 --> 01:52:24.420]   And that's why there are the, these areas that are spelled out in Facebook's directions,
[01:52:24.420 --> 01:52:27.380]   where it might be okay to publish some of these things, right?
[01:52:27.380 --> 01:52:27.860]   Yes.
[01:52:27.860 --> 01:52:30.100]   But, but, but well, the other point is, which is quite right.
[01:52:30.100 --> 01:52:33.300]   Remember, Congress comes along and says, oh man, I got fresh meat.
[01:52:33.300 --> 01:52:33.540]   Yeah.
[01:52:33.540 --> 01:52:36.100]   I'm going to, these people allow pictures of animal abuse.
[01:52:36.100 --> 01:52:38.500]   How dare they, the speech writes itself.
[01:52:38.500 --> 01:52:38.740]   Yeah.
[01:52:38.740 --> 01:52:39.140]   Yep.
[01:52:39.140 --> 01:52:39.700]   Yep.
[01:52:39.700 --> 01:52:41.940]   And the FCC comes along.
[01:52:41.940 --> 01:52:43.060]   Oh, joy.
[01:52:43.060 --> 01:52:46.420]   Ajit Pai, he'll have fun with this.
[01:52:46.420 --> 01:52:49.620]   And the parents, the parents, what do you call it?
[01:52:49.620 --> 01:52:49.940]   Council?
[01:52:49.940 --> 01:52:51.780]   I used to hate when they went after Howard Stern.
[01:52:51.780 --> 01:52:53.380]   Oh, they'll have a field day.
[01:52:53.380 --> 01:52:55.620]   Ah.
[01:52:55.620 --> 01:52:59.700]   Well, it's good for Howard Stern, because Howard Stern seems quite tame now.
[01:53:00.660 --> 01:53:01.460]   Yeah.
[01:53:01.460 --> 01:53:01.860]   Yeah.
[01:53:01.860 --> 01:53:02.260]   Yeah.
[01:53:02.260 --> 01:53:04.980]   You know, times have changed.
[01:53:04.980 --> 01:53:10.020]   Uh, Russian hackers target Pentagon workers with malware laced Twitter messages.
[01:53:10.020 --> 01:53:11.140]   Yeah.
[01:53:11.140 --> 01:53:12.100]   Well, so what's new?
[01:53:12.100 --> 01:53:14.580]   That's our old now.
[01:53:14.580 --> 01:53:19.140]   Chelsea Manning, it's a beautiful picture of Chelsea Manning, who is now free.
[01:53:19.140 --> 01:53:20.740]   From prison.
[01:53:20.740 --> 01:53:26.740]   I didn't realize, I saw her report today on TV, that she, because she is going to appeal
[01:53:26.740 --> 01:53:28.500]   the verdict against her.
[01:53:28.500 --> 01:53:30.500]   She's still officially on active duty.
[01:53:30.500 --> 01:53:31.940]   No kidding.
[01:53:31.940 --> 01:53:34.020]   I had no idea of that.
[01:53:34.020 --> 01:53:36.100]   Is it was a military court that convicted her?
[01:53:36.100 --> 01:53:37.700]   Oh, yeah.
[01:53:37.700 --> 01:53:38.020]   Okay.
[01:53:38.020 --> 01:53:43.140]   Um, Zomato was hacked.
[01:53:43.140 --> 01:53:43.780]   He's Zomato.
[01:53:43.780 --> 01:53:44.660]   I don't know what Zomato.
[01:53:44.660 --> 01:53:46.340]   It's a restaurant search service.
[01:53:46.340 --> 01:53:49.220]   17 million customer email addresses and passwords stolen.
[01:53:49.220 --> 01:53:53.700]   The Swedes have dropped the rape case against Julian Assange.
[01:53:53.700 --> 01:53:56.020]   Not so much because, uh,
[01:53:56.820 --> 01:53:59.860]   they gave up, uh, you know, they don't think there's a case,
[01:53:59.860 --> 01:54:01.780]   but just because it's been going on and on and they don't,
[01:54:01.780 --> 01:54:06.180]   they're not really, they can't make any progress on it.
[01:54:06.180 --> 01:54:09.940]   He's staying, of course, in the Ecuadorian embassy in London.
[01:54:09.940 --> 01:54:11.380]   So here's a question for you.
[01:54:11.380 --> 01:54:14.180]   Does Donald Trump prosecute him or pardon him?
[01:54:14.180 --> 01:54:19.940]   I don't even think that would be, you know, I think his brain would explode if you
[01:54:19.940 --> 01:54:20.820]   asked him that question.
[01:54:20.820 --> 01:54:24.980]   I don't think that, because on the one hand, he praised WikiLeaks.
[01:54:24.980 --> 01:54:26.420]   Oh, did he ever?
[01:54:26.420 --> 01:54:28.580]   But on the other hand, now they're leaking about him.
[01:54:28.580 --> 01:54:29.620]   So it's not so good.
[01:54:29.620 --> 01:54:36.660]   Uh, let's take a little break, wrap this up.
[01:54:36.660 --> 01:54:39.700]   There's probably much more to talk about.
[01:54:39.700 --> 01:54:43.220]   Microsoft is being, is patching Minecraft,
[01:54:43.220 --> 01:54:45.460]   so kids won't poison their pet birds anymore.
[01:54:45.460 --> 01:54:46.980]   Oh, what?
[01:54:46.980 --> 01:54:53.140]   Um, apparently there was a big controversy in the Minecraft
[01:54:54.100 --> 01:54:56.660]   community when fans of the game pointed out the cookies,
[01:54:56.660 --> 01:55:00.420]   which you use in Minecraft to tame parrots.
[01:55:00.420 --> 01:55:01.380]   It killed the birds.
[01:55:01.380 --> 01:55:03.780]   Could actually be deadly to real life birds.
[01:55:03.780 --> 01:55:09.460]   In fact, it was the most upvoted post of all time on slash r slash Minecraft.
[01:55:09.460 --> 01:55:13.780]   Kids thought because they feed cookies to birds in the game and they can feed
[01:55:13.780 --> 01:55:14.980]   cookies to birds in real life.
[01:55:14.980 --> 01:55:17.860]   Do not feed your parrots, parrots, uh, cookies in the real life.
[01:55:17.860 --> 01:55:18.340]   I'm sad.
[01:55:18.340 --> 01:55:20.660]   Well, you know the controversy around the opening of Lou Grant.
[01:55:20.660 --> 01:55:22.340]   Leo, remember that?
[01:55:22.340 --> 01:55:23.140]   No.
[01:55:24.100 --> 01:55:28.420]   The opening of Lou Grant, my son, was a show about a newsroom.
[01:55:28.420 --> 01:55:30.100]   Well, we explained to you what a newsroom was.
[01:55:30.100 --> 01:55:34.020]   As time goes by, it was hitting harder and harder.
[01:55:34.020 --> 01:55:34.500]   Explain.
[01:55:34.500 --> 01:55:37.060]   So they go through the whole process of putting out the paper and all this
[01:55:37.060 --> 01:55:39.940]   wonderment that goes into it and the opening credits and then the paper ends up
[01:55:39.940 --> 01:55:44.740]   lining the, the cage of a bird cage, but that would poison the bird.
[01:55:44.740 --> 01:55:44.980]   Yeah.
[01:55:44.980 --> 01:55:48.740]   Oh, you, you don't put newspaper in the bird cage.
[01:55:48.740 --> 01:55:50.420]   No, no, no, the ink is bad for him.
[01:55:50.420 --> 01:55:52.820]   I had no idea.
[01:55:53.620 --> 01:55:54.500]   It's a good thing.
[01:55:54.500 --> 01:55:55.380]   I don't have any birds.
[01:55:55.380 --> 01:55:56.180]   I didn't know that either.
[01:55:56.180 --> 01:55:57.780]   Did he find it?
[01:55:57.780 --> 01:55:58.580]   Oh, yay.
[01:55:58.580 --> 01:55:59.460]   Oh, yes.
[01:55:59.460 --> 01:56:01.140]   All memories.
[01:56:01.140 --> 01:56:01.940]   Mason Adams.
[01:56:01.940 --> 01:56:02.580]   I loved him.
[01:56:02.580 --> 01:56:04.900]   Not really a problem these days.
[01:56:04.900 --> 01:56:06.980]   He subscribes to newspapers anymore, right?
[01:56:06.980 --> 01:56:09.220]   Nancy Moshan, that Mrs. Pincham.
[01:56:09.220 --> 01:56:11.940]   And, uh, there's the newspaper.
[01:56:11.940 --> 01:56:13.380]   That's called a printer, kids.
[01:56:13.380 --> 01:56:15.300]   Oh, that's, that's a bill.
[01:56:15.300 --> 01:56:18.980]   Mark and I have, there's newspapers for the record.
[01:56:18.980 --> 01:56:19.380]   We know.
[01:56:19.380 --> 01:56:21.620]   Did you deliver newspapers when you were kids?
[01:56:21.620 --> 01:56:22.100]   No.
[01:56:22.100 --> 01:56:22.660]   No.
[01:56:22.660 --> 01:56:25.940]   So the fellow goes, he reads the paper with his coffee,
[01:56:25.940 --> 01:56:27.620]   Los Angeles Tribune.
[01:56:27.620 --> 01:56:29.220]   Made to look like the LA Times.
[01:56:29.220 --> 01:56:31.220]   Cuts out a piece and then puts it.
[01:56:31.220 --> 01:56:34.500]   Oh, he's sort of in the bird cage and the canary johns.
[01:56:34.500 --> 01:56:34.980]   Bird is dead.
[01:56:34.980 --> 01:56:36.180]   It's so sad.
[01:56:36.180 --> 01:56:40.260]   On that note, we had a fun week this week.
[01:56:40.260 --> 01:56:42.980]   It was a really good week and we've made a little tiny movie,
[01:56:42.980 --> 01:56:45.460]   so you can see it and see everything you missed.
[01:56:45.460 --> 01:56:46.580]   Missed watch.
[01:56:46.580 --> 01:56:48.340]   Previously on Twitch.
[01:56:48.340 --> 01:56:50.900]   Jeff Jarvis is here unusually next to me,
[01:56:50.900 --> 01:56:51.860]   which means I can do.
[01:56:51.860 --> 01:56:53.700]   And that's great.
[01:56:53.700 --> 01:56:56.420]   This week in Google.
[01:56:56.420 --> 01:56:59.700]   So the reason he mentioned this image recognition improvement
[01:56:59.700 --> 01:57:02.820]   is to announce a new project called Google lens.
[01:57:02.820 --> 01:57:06.660]   I have been wanting this forever because I like constantly do things
[01:57:06.660 --> 01:57:08.500]   like walk through my yard and I'm like,
[01:57:08.500 --> 01:57:10.580]   Ooh, is this a weed or is it a plant?
[01:57:10.580 --> 01:57:11.220]   Can I eat this?
[01:57:11.220 --> 01:57:12.660]   Can I eat this?
[01:57:12.660 --> 01:57:15.700]   That's something that a human would be not like this, right?
[01:57:15.700 --> 01:57:17.700]   The new screensabers.
[01:57:17.700 --> 01:57:19.220]   The maker, Farron, Sam Mateo.
[01:57:19.220 --> 01:57:21.220]   This is the original, the 12th annual.
[01:57:21.220 --> 01:57:25.220]   We met a lot of fans, but also saw a lot of cool stuff.
[01:57:25.220 --> 01:57:27.140]   These are shadow boxes kids made.
[01:57:27.140 --> 01:57:31.220]   Maker fair is so fun because it just shows human creativity,
[01:57:31.220 --> 01:57:34.660]   creativity, ingenuity, and technology.
[01:57:34.660 --> 01:57:36.260]   Know how.
[01:57:36.260 --> 01:57:37.780]   This week we're going to do something a little bit different,
[01:57:37.780 --> 01:57:40.580]   which is dear liberally infecting your network.
[01:57:40.580 --> 01:57:41.860]   This is something you should not do.
[01:57:41.860 --> 01:57:42.100]   Where?
[01:57:42.100 --> 01:57:43.060]   Let's go ahead and run it.
[01:57:43.060 --> 01:57:44.740]   Twitch.
[01:57:44.740 --> 01:57:46.980]   Making the world safe for technology.
[01:57:47.620 --> 01:57:48.980]   So this is the screen.
[01:57:48.980 --> 01:57:53.060]   Wow, he installed one of Krypton R network.
[01:57:53.060 --> 01:57:53.620]   My computer.
[01:57:53.620 --> 01:57:56.100]   Oh, how dare you, Father Robert?
[01:57:56.100 --> 01:57:59.060]   Fortunately, he can also exorcise it.
[01:57:59.060 --> 01:57:59.700]   So it's good.
[01:57:59.700 --> 01:58:01.300]   Yeah, he does it both.
[01:58:01.300 --> 01:58:03.220]   You know Leo, you run a great company.
[01:58:03.220 --> 01:58:05.620]   That's great stuff that goes on in a week.
[01:58:05.620 --> 01:58:06.340]   Thank you, Jeff.
[01:58:06.340 --> 01:58:07.460]   I know it's always fun.
[01:58:07.460 --> 01:58:08.340]   We have a lot of fun.
[01:58:08.340 --> 01:58:08.820]   Yeah.
[01:58:08.820 --> 01:58:10.020]   Great team of people.
[01:58:10.020 --> 01:58:11.460]   And a great week coming up.
[01:58:11.460 --> 01:58:13.380]   I should point out, Megan Moroni, what's ahead?
[01:58:13.380 --> 01:58:16.740]   Here's a look at just a few of the stories we'll be watching
[01:58:16.740 --> 01:58:17.700]   in the week ahead.
[01:58:17.700 --> 01:58:20.580]   Microsoft is holding an event in Shanghai,
[01:58:20.580 --> 01:58:23.540]   where we expect to see an update to the Surface Pro.
[01:58:23.540 --> 01:58:26.260]   Rumors and leaks show not much of a redesign
[01:58:26.260 --> 01:58:27.620]   for the new Surface Pro,
[01:58:27.620 --> 01:58:30.180]   which will probably just be called the Surface Pro
[01:58:30.180 --> 01:58:32.100]   instead of the Surface Pro 5.
[01:58:32.100 --> 01:58:35.620]   Say goodbye to Hangouts, SMS messaging.
[01:58:35.620 --> 01:58:39.540]   Google is removing the option this week on May 24th.
[01:58:39.540 --> 01:58:42.580]   The Women in Engineering International Leadership Conference
[01:58:42.580 --> 01:58:45.140]   will be held in San Jose, California this week.
[01:58:45.140 --> 01:58:47.620]   Speakers included Lakshmi Puri,
[01:58:47.620 --> 01:58:50.500]   Deputy Executive Director of UN Women,
[01:58:50.500 --> 01:58:53.380]   and Maria Claw, President of Harvey Mudd College,
[01:58:53.380 --> 01:58:56.660]   where half of their current computer science majors are women.
[01:58:56.660 --> 01:59:00.420]   And finally, the IEEE Computer Society Technical Committee
[01:59:00.420 --> 01:59:04.580]   is holding its 38th annual symposium on security and privacy,
[01:59:04.580 --> 01:59:06.100]   also in San Jose.
[01:59:06.100 --> 01:59:08.420]   That's a look at a few of the things we'll be tracking
[01:59:08.420 --> 01:59:09.220]   in the coming week.
[01:59:09.220 --> 01:59:12.100]   Join Jason Howell and me on Tech News today,
[01:59:12.100 --> 01:59:14.980]   every weekday at 4 p.m. Pacific, 7 p.m. Eastern.
[01:59:14.980 --> 01:59:16.980]   Here on Twit.tv.
[01:59:16.980 --> 01:59:19.060]   Yep, keep up on your Tech News all week long.
[01:59:19.060 --> 01:59:21.540]   Nathan Offerson appears on that show as well.
[01:59:21.540 --> 01:59:29.140]   I don't know.
[01:59:29.140 --> 01:59:30.820]   I feel like we covered everything.
[01:59:30.820 --> 01:59:32.740]   I'm sorry you cut through a lot.
[01:59:32.740 --> 01:59:34.340]   Cut me off guard here,
[01:59:34.340 --> 01:59:37.940]   because I was trying to Pandora stock soaring,
[01:59:37.940 --> 01:59:41.380]   following a report that SiriusXM is in talks to buy it.
[01:59:41.380 --> 01:59:44.180]   That would be pretty interesting.
[01:59:44.180 --> 01:59:44.900]   Yeah.
[01:59:44.900 --> 01:59:47.700]   Uber starts charging what it thinks you're willing to pay.
[01:59:47.700 --> 01:59:48.820]   This is from Bloomberg.
[01:59:48.820 --> 01:59:49.540]   Yeah.
[01:59:49.540 --> 01:59:51.220]   Wait a minute.
[01:59:51.220 --> 01:59:52.340]   How we got a little scoop on this.
[01:59:52.340 --> 01:59:53.060]   Tell us about this.
[01:59:53.060 --> 01:59:55.060]   Is this one more reason to stop using Uber?
[01:59:55.060 --> 01:59:56.100]   Potentially.
[01:59:56.100 --> 01:59:57.700]   You know, I used Uber the other day.
[01:59:57.700 --> 01:59:58.340]   It's just easy.
[01:59:58.340 --> 01:59:58.900]   It's fun.
[01:59:58.900 --> 01:59:59.540]   It's natural.
[01:59:59.540 --> 02:00:00.740]   It just comes naturally.
[02:00:00.740 --> 02:00:01.780]   I probably shouldn't.
[02:00:01.780 --> 02:00:03.380]   But I mean, there is Lyft.
[02:00:03.380 --> 02:00:04.660]   A lot of people have gone over to Lyft.
[02:00:04.660 --> 02:00:06.820]   So since late last year,
[02:00:06.820 --> 02:00:10.580]   they've been quietly experimenting with this new pricing method.
[02:00:10.580 --> 02:00:11.780]   Route-based pricing.
[02:00:11.780 --> 02:00:13.300]   Route-based pricing.
[02:00:13.300 --> 02:00:14.420]   Route-based pricing.
[02:00:14.420 --> 02:00:14.900]   Yeah.
[02:00:14.900 --> 02:00:17.140]   And instead of the old model,
[02:00:17.140 --> 02:00:20.500]   which was some calculation of distance, time,
[02:00:20.500 --> 02:00:22.020]   like a cab and search pricing.
[02:00:22.020 --> 02:00:22.660]   Like a cab works, similar words.
[02:00:22.660 --> 02:00:23.220]   Yeah.
[02:00:23.220 --> 02:00:23.540]   Yep.
[02:00:23.540 --> 02:00:25.380]   They now use,
[02:00:25.380 --> 02:00:28.420]   they say they use AI to essentially estimate
[02:00:28.420 --> 02:00:30.260]   how much you're willing to pay.
[02:00:30.260 --> 02:00:32.500]   And they use signals such as,
[02:00:32.500 --> 02:00:35.140]   if you're coming from like an expensive neighborhood
[02:00:35.140 --> 02:00:36.740]   and going to another expensive neighborhood.
[02:00:36.740 --> 02:00:37.540]   Oh, no.
[02:00:37.540 --> 02:00:39.620]   They can estimate,
[02:00:39.620 --> 02:00:41.540]   well, this person might be willing to pay a little more.
[02:00:41.540 --> 02:00:43.140]   Or in verse red lining.
[02:00:43.140 --> 02:00:44.340]   Oh my gosh.
[02:00:44.340 --> 02:00:46.020]   Is this the worst AI that's out there?
[02:00:46.020 --> 02:00:47.220]   It's just like, you know what?
[02:00:47.220 --> 02:00:48.660]   Actually, that guy's rich.
[02:00:48.660 --> 02:00:49.780]   He should give me more.
[02:00:49.780 --> 02:00:51.460]   Charge him an extra five bucks.
[02:00:51.460 --> 02:00:52.900]   Charge them an extra two.
[02:00:52.900 --> 02:00:54.420]   Like, well, they're still losing money.
[02:00:54.420 --> 02:00:56.580]   They lost $2.8 billion last year.
[02:00:56.580 --> 02:00:57.540]   They're losing a lot of money.
[02:00:57.540 --> 02:01:00.420]   And so they finally come out and said,
[02:01:00.420 --> 02:01:01.620]   because drivers were complaining
[02:01:01.620 --> 02:01:02.820]   that they were saying,
[02:01:02.820 --> 02:01:05.700]   I'm finding out the passengers are paying a lot more
[02:01:05.700 --> 02:01:06.740]   than you're paying me.
[02:01:06.740 --> 02:01:07.540]   So what's going on?
[02:01:07.540 --> 02:01:08.740]   So they finally came out and said,
[02:01:08.740 --> 02:01:10.580]   okay, we've been doing this experiment.
[02:01:10.580 --> 02:01:12.420]   We're going to continue paying drivers
[02:01:12.420 --> 02:01:14.580]   based on the old model of distance and time.
[02:01:14.580 --> 02:01:18.180]   And we're going to charge riders based on this new category.
[02:01:18.180 --> 02:01:19.460]   Oh, that's worse.
[02:01:19.460 --> 02:01:21.460]   It's going to take everything that's in the middle.
[02:01:21.460 --> 02:01:24.260]   I wonder if they have an AI that's like,
[02:01:24.260 --> 02:01:25.220]   I wonder how much we can,
[02:01:25.220 --> 02:01:27.940]   I wonder how little we can pay that driver versus how little
[02:01:27.940 --> 02:01:29.140]   we can pay that driver.
[02:01:29.140 --> 02:01:30.660]   You know, he didn't shave today.
[02:01:30.660 --> 02:01:31.940]   He clearly needs the money.
[02:01:31.940 --> 02:01:33.620]   We're going to pay him half as much today.
[02:01:33.620 --> 02:01:34.260]   Yeah.
[02:01:34.260 --> 02:01:35.860]   It's as if they keep a lot of story.
[02:01:35.860 --> 02:01:37.380]   Google says, don't be evil.
[02:01:37.380 --> 02:01:39.620]   How can we make a company that makes money by being evil?
[02:01:39.620 --> 02:01:42.420]   How evil could we be and still have a business?
[02:01:42.420 --> 02:01:42.820]   Shise.
[02:01:42.820 --> 02:01:44.980]   Unbelievable.
[02:01:44.980 --> 02:01:46.740]   It's good scoop.
[02:01:46.740 --> 02:01:51.700]   FCC claims without any evidence that they've been de-dossed.
[02:01:51.700 --> 02:01:52.180]   Darn it.
[02:01:52.180 --> 02:01:54.340]   What was it?
[02:01:54.340 --> 02:01:57.140]   Go FCC yourself, the John Oliver psychos.
[02:01:57.140 --> 02:02:00.820]   Your self, John Oliver, sent so many comments,
[02:02:00.820 --> 02:02:06.100]   as he has before to the FCC over the net neutrality debate.
[02:02:06.100 --> 02:02:08.820]   So the FCC was advocating for people to tell the FCC
[02:02:08.820 --> 02:02:10.420]   to keep net neutrality rules in place
[02:02:10.420 --> 02:02:12.020]   instead of undoing them the way that
[02:02:12.020 --> 02:02:14.420]   Ajit Pai, the current chairman, wants to do.
[02:02:14.420 --> 02:02:16.580]   So he sent a lot of people there.
[02:02:16.580 --> 02:02:17.220]   I went there.
[02:02:17.220 --> 02:02:19.780]   I commented earlier this week on Tuesday.
[02:02:19.780 --> 02:02:24.900]   I said, you know, I run a TWIT as an internet-based streaming service.
[02:02:24.900 --> 02:02:28.580]   If internet service providers were allowed to discriminate against me,
[02:02:28.580 --> 02:02:30.900]   it would put me out of business.
[02:02:30.900 --> 02:02:33.460]   I feel that, you know, we exist.
[02:02:33.460 --> 02:02:34.100]   We innovate.
[02:02:34.100 --> 02:02:36.340]   We hire and pay 25 people.
[02:02:37.220 --> 02:02:40.420]   Full-time staffers and many dozens more contractors.
[02:02:40.420 --> 02:02:44.100]   Because we're able to make a living on the internet,
[02:02:44.100 --> 02:02:46.500]   we exist because the internet is open and free.
[02:02:46.500 --> 02:02:48.020]   I sent that in.
[02:02:48.020 --> 02:02:51.780]   I guess I got it in, but apparently because they were de-dossed.
[02:02:51.780 --> 02:02:54.180]   I think the de-doss was a lot of people commenting.
[02:02:54.180 --> 02:02:54.660]   Citizen.
[02:02:54.660 --> 02:02:55.140]   Citizen.
[02:02:55.140 --> 02:02:55.940]   That's what it was.
[02:02:55.940 --> 02:02:59.700]   They never demonstrated in any way that it was malicious de-dossing.
[02:02:59.700 --> 02:03:03.220]   Last time this came up, about 4 million people commented,
[02:03:04.100 --> 02:03:08.900]   which a couple years ago got us to the net neutrality rules we have now.
[02:03:08.900 --> 02:03:10.500]   That was under the Obama administration.
[02:03:10.500 --> 02:03:10.660]   Right.
[02:03:10.660 --> 02:03:12.660]   And it opened Tom Wheeler's eyes.
[02:03:12.660 --> 02:03:13.140]   Exactly.
[02:03:13.140 --> 02:03:15.780]   And a couple million people have commented so far.
[02:03:15.780 --> 02:03:20.180]   They say it's around, I think, like 2 million, so not as many as last time.
[02:03:20.180 --> 02:03:25.940]   But Ajit Pai so far has said that public polls and comments won't sway his opinions.
[02:03:25.940 --> 02:03:30.020]   No, because they're wrong, because net neutrality is bad for business.
[02:03:30.020 --> 02:03:32.340]   That's all the matters.
[02:03:32.340 --> 02:03:40.180]   So if you go to John Oliver's Go FCC yourself site, hello, because of her procedural quirk,
[02:03:40.180 --> 02:03:44.660]   the FCC will not be considering any comments on the issue of net neutrality.
[02:03:44.660 --> 02:03:46.580]   They're submitted over the next week or so.
[02:03:46.580 --> 02:03:50.740]   We'll update you when the comments are officially open again in the interim.
[02:03:50.740 --> 02:03:54.340]   You'll have to find something else to be mad about on the internet.
[02:03:54.340 --> 02:03:56.740]   Thank you, FCC.
[02:03:56.740 --> 02:03:57.620]   You'd almost think like that.
[02:03:57.620 --> 02:03:58.580]   Well, say you were all again.
[02:03:58.580 --> 02:04:01.140]   Go FCC yourself.
[02:04:01.700 --> 02:04:02.660]   I'll remember that.
[02:04:02.660 --> 02:04:08.580]   It almost as if they feel like the public shouldn't have any say in this.
[02:04:08.580 --> 02:04:11.620]   Why would they want to talk about that?
[02:04:11.620 --> 02:04:14.260]   This is between us and the internet service providers.
[02:04:14.260 --> 02:04:15.380]   We'll handle this.
[02:04:15.380 --> 02:04:18.660]   Don't worry your pretty little heads about a thing.
[02:04:18.660 --> 02:04:19.460]   We got this.
[02:04:19.460 --> 02:04:22.500]   Infuriating.
[02:04:22.500 --> 02:04:23.540]   Infuriating.
[02:04:23.540 --> 02:04:27.860]   Yeah, I mean, maybe they'll reopen it.
[02:04:27.860 --> 02:04:30.740]   They say we're not going to publish evidence of the DDoS.
[02:04:30.740 --> 02:04:32.820]   We're just going to have to take our word for it.
[02:04:32.820 --> 02:04:36.820]   Yeah, it smells like BS, honestly.
[02:04:36.820 --> 02:04:38.100]   There is so much of it.
[02:04:38.100 --> 02:04:39.060]   Ugh.
[02:04:39.060 --> 02:04:40.980]   So much of it.
[02:04:40.980 --> 02:04:46.980]   So I guess they voted to take the comments.
[02:04:46.980 --> 02:04:49.460]   What is the timeline now?
[02:04:49.460 --> 02:04:55.140]   I think it's a two-week period, which is normally shorter than usual.
[02:04:55.140 --> 02:04:57.380]   Yeah, I could be wrong, but I believe that's what it is.
[02:05:00.500 --> 02:05:00.900]   Okay.
[02:05:00.900 --> 02:05:02.580]   Yeah.
[02:05:02.580 --> 02:05:05.860]   I don't know what else to say.
[02:05:05.860 --> 02:05:09.140]   The, and this just goes right on the topic.
[02:05:09.140 --> 02:05:13.140]   A reporter, actually a very distinguished reporter, John M.
[02:05:13.140 --> 02:05:19.300]   Donally of the CQ Roll Call is also the chairman of the National Press Club's
[02:05:19.300 --> 02:05:24.420]   Press Freedom Team, president of the Military Reporters and Edders Association,
[02:05:24.420 --> 02:05:29.540]   was apparently asking too many questions at the FCC at a public hearing
[02:05:30.340 --> 02:05:35.540]   was forced to leave the premises by security guards.
[02:05:35.540 --> 02:05:39.380]   This comes after a reporter was arrested for asking questions of the,
[02:05:39.380 --> 02:05:42.020]   of the commerce secretary at what believe it was, it was Virginia.
[02:05:42.020 --> 02:05:44.980]   This, he was not confrontational.
[02:05:44.980 --> 02:05:48.660]   He was politely asking questions of the FCC commissioners,
[02:05:48.660 --> 02:05:54.340]   as is his role as a reporter representing us since we couldn't be there.
[02:05:55.780 --> 02:06:00.420]   Um, they forced him to leave the building under implied threat of force.
[02:06:00.420 --> 02:06:04.580]   These are plainclothes, private security personnel.
[02:06:04.580 --> 02:06:09.060]   Donally said, I could not have been less threatening or more polite.
[02:06:09.060 --> 02:06:13.620]   There's no justification for using force in such a situation.
[02:06:13.620 --> 02:06:18.340]   The National Press Club president, Jeff Belous,
[02:06:18.340 --> 02:06:21.620]   that Donally was doing his job doing it with his characteristic civility.
[02:06:22.420 --> 02:06:27.540]   Reporters can ask questions in any area of a public building that is not marked off as
[02:06:27.540 --> 02:06:28.740]   restricted to them.
[02:06:28.740 --> 02:06:32.180]   Officials who are fielding the questions are not required to answer,
[02:06:32.180 --> 02:06:37.140]   but is completely unacceptable to physically restrain a reporter who has done nothing
[02:06:37.140 --> 02:06:42.500]   wrong or forced him or her to leave a public, public building paid for by us,
[02:06:42.500 --> 02:06:47.460]   the taxpayers, as if a crime has been permitted.
[02:06:47.460 --> 02:06:49.940]   No comment from the FCC.
[02:06:49.940 --> 02:06:57.780]   Uh, Anthony Wiener played a guilty.
[02:06:57.780 --> 02:07:00.980]   I don't think, yeah.
[02:07:00.980 --> 02:07:05.460]   Oh, here's some good news, but I don't, I think it's a temporary respite.
[02:07:05.460 --> 02:07:09.460]   The, uh, you no longer have to register non-commercial drones with the FAA,
[02:07:09.460 --> 02:07:15.940]   the court threw the rule out because I'm fascinating that the, the, the drone companies are unhappy.
[02:07:15.940 --> 02:07:16.820]   Yeah, that's why.
[02:07:16.820 --> 02:07:17.220]   Healthy.
[02:07:17.220 --> 02:07:18.500]   Yeah, I like that.
[02:07:18.500 --> 02:07:24.020]   Um, so the, apparently there was a, a, a law passed by Congress in 2012,
[02:07:24.020 --> 02:07:28.980]   the FAA modernization reform act, which prohibited the FAA from passing rules on the
[02:07:28.980 --> 02:07:36.420]   operation of model aircraft, but the drone manufacturers kind of liked it that, you know,
[02:07:36.420 --> 02:07:37.700]   you had to register.
[02:07:37.700 --> 02:07:38.660]   Why did they like it?
[02:07:38.660 --> 02:07:45.540]   I think, I think that because the, the bad press for drones doing bad things,
[02:07:45.540 --> 02:07:47.460]   that for drones, they would kill the whole industry.
[02:07:47.460 --> 02:07:47.780]   Yeah.
[02:07:47.780 --> 02:07:52.580]   Well, I suspect in fact, there's already moves of foot in Congress to, you know,
[02:07:52.580 --> 02:07:55.540]   change the law and make it legal again.
[02:07:55.540 --> 02:07:57.940]   I think we could wrap it up.
[02:07:57.940 --> 02:07:59.060]   We've been here a long time.
[02:07:59.060 --> 02:08:03.700]   You've all been very, uh, informative, intelligent, entertaining.
[02:08:03.700 --> 02:08:05.380]   What?
[02:08:05.380 --> 02:08:08.340]   Oh, well, let me do an ad first.
[02:08:08.340 --> 02:08:11.380]   And then we'll have some final words.
[02:08:11.380 --> 02:08:11.860]   I forgot.
[02:08:11.860 --> 02:08:13.060]   Thank you, Carson.
[02:08:13.060 --> 02:08:15.220]   I meant to do that right after the week ahead.
[02:08:15.700 --> 02:08:18.660]   Our show today brought, this is important in the WannaCry world.
[02:08:18.660 --> 02:08:22.580]   Our show today brought to you by Carmonites.
[02:08:22.580 --> 02:08:27.860]   And I think, you know, if you're reading these stories about ransomware,
[02:08:27.860 --> 02:08:31.220]   ransomware, by the way, made more money last year than ever,
[02:08:31.220 --> 02:08:33.860]   it's expected we'll make a billion dollars this year.
[02:08:33.860 --> 02:08:37.140]   That's in just hard payments to ransomware authors.
[02:08:37.140 --> 02:08:42.740]   The actual productivity loss, it's estimated to be as high as 50 billion dollars this year.
[02:08:42.740 --> 02:08:44.260]   And that was before WannaCry.
[02:08:45.140 --> 02:08:46.740]   So ransomware is a real problem.
[02:08:46.740 --> 02:08:50.580]   And in business, if you have lost access to the data on your computers,
[02:08:50.580 --> 02:08:52.500]   that means you've lost everything.
[02:08:52.500 --> 02:08:56.980]   You've lost your customer list, your accounts receivable, your supplier list,
[02:08:56.980 --> 02:08:59.620]   your books, you can't, you can't do your taxes.
[02:08:59.620 --> 02:09:00.420]   You can't do anything.
[02:09:00.420 --> 02:09:01.460]   You can't go forward.
[02:09:01.460 --> 02:09:03.700]   Now you might say, well, I've got no problem.
[02:09:03.700 --> 02:09:04.500]   I've got a good backup.
[02:09:04.500 --> 02:09:05.060]   It's right there.
[02:09:05.060 --> 02:09:06.020]   Joey in the mail room.
[02:09:06.020 --> 02:09:06.980]   He does that every week.
[02:09:06.980 --> 02:09:09.780]   Yeah, that may be encrypted as well.
[02:09:09.780 --> 02:09:11.620]   You've got to have offsite backup.
[02:09:11.620 --> 02:09:13.540]   I want you to go to carbonite.com.
[02:09:13.540 --> 02:09:18.980]   Even if you don't become a customer, go to the carbonite for business.
[02:09:18.980 --> 02:09:20.980]   You know, they've got it for home and for office.
[02:09:20.980 --> 02:09:22.420]   They're the carbonite for office.
[02:09:22.420 --> 02:09:24.740]   You'll see right there in the menu resources.
[02:09:24.740 --> 02:09:27.860]   And they've got a number of white pages on ransomware,
[02:09:27.860 --> 02:09:32.420]   what to do to plan for it, what to do to remediate it.
[02:09:32.420 --> 02:09:33.940]   It's not a big ad for carbonite.
[02:09:33.940 --> 02:09:36.500]   It's very helpful, useful information.
[02:09:36.500 --> 02:09:39.300]   You want to create a disaster recovery plan.
[02:09:39.300 --> 02:09:41.860]   And no matter what, you want to have offsite backups.
[02:09:41.860 --> 02:09:43.460]   That's the safest.
[02:09:43.460 --> 02:09:47.140]   Carbonite has a lot of ways to solve that problem,
[02:09:47.140 --> 02:09:50.900]   including on-prem hard drives that backup to carbonite.
[02:09:50.900 --> 02:09:53.060]   They've got high availability solutions.
[02:09:53.060 --> 02:09:55.780]   Businesses love carbonite.
[02:09:55.780 --> 02:09:58.580]   And believe me, if you get, there you go, that's the E-Vault.
[02:09:58.580 --> 02:10:00.260]   That is a really nice solution.
[02:10:00.260 --> 02:10:04.980]   If you get hit by ransomware, you will love carbonite too,
[02:10:04.980 --> 02:10:09.780]   because you will be back to business instead of shutting the place down.
[02:10:09.780 --> 02:10:11.700]   Find out more about carbonite.
[02:10:11.700 --> 02:10:13.380]   Go to carbonite.com.
[02:10:13.380 --> 02:10:16.420]   They have free trials of the home version and the business versions.
[02:10:16.420 --> 02:10:18.500]   No credit card required.
[02:10:18.500 --> 02:10:20.580]   I would suggest the free trial.
[02:10:20.580 --> 02:10:23.700]   Do me a favor though, when you do the free trial, they'll ask you,
[02:10:23.700 --> 02:10:24.660]   they'll say, "What's the...?"
[02:10:24.660 --> 02:10:26.340]   You know, they see they offer code.
[02:10:26.340 --> 02:10:29.860]   Just put "twit" in there, so they know you heard it on this weekend tech.
[02:10:29.860 --> 02:10:32.180]   And by the way, when you do that, you'll get two free bonus months
[02:10:32.180 --> 02:10:33.700]   if you decide to sign up.
[02:10:33.700 --> 02:10:36.260]   It's the most affordable solution for home and office.
[02:10:36.260 --> 02:10:38.020]   It's the most effective solution.
[02:10:38.020 --> 02:10:39.620]   And if you haven't looked at carbonite lately,
[02:10:39.620 --> 02:10:41.540]   they've got more and more great solutions
[02:10:41.540 --> 02:10:43.780]   for small, medium, and large enterprises.
[02:10:43.780 --> 02:10:46.500]   carbonite.com.
[02:10:46.500 --> 02:10:48.740]   You got to back it up to get it back to it right.
[02:10:48.740 --> 02:10:54.420]   With carbonite, don't forget to use the word "twit" in the promo code.
[02:10:54.420 --> 02:10:57.860]   Actually, I do love this story.
[02:10:57.860 --> 02:11:03.140]   The kill switch guy, the guy who published, you know,
[02:11:03.140 --> 02:11:07.060]   registered the site, he gets a $10,000 bounty.
[02:11:07.060 --> 02:11:09.380]   And he's giving securities.
[02:11:09.380 --> 02:11:10.740]   And a year's free pizza.
[02:11:11.380 --> 02:11:12.340]   That I hope he's keeping.
[02:11:12.340 --> 02:11:18.900]   UK security researcher, Malware Tech, white hat hacker.
[02:11:18.900 --> 02:11:22.500]   That was the guy who just said, "You know, what if we registered this domain?"
[02:11:22.500 --> 02:11:27.380]   And hacker one, which is a bug bounty service, said,
[02:11:27.380 --> 02:11:29.220]   "Just for that, we're giving you a $10,000,000,
[02:11:29.220 --> 02:11:35.780]   which he's going to split among charities, and a year's worth..."
[02:11:35.780 --> 02:11:37.380]   Although it was British pizza, good pizza.
[02:11:37.380 --> 02:11:39.140]   Yeah, what kind of pizza I was going to ask you.
[02:11:39.140 --> 02:11:40.260]   There can be that.
[02:11:40.260 --> 02:11:42.100]   Pizza doesn't look so good, but it's free.
[02:11:42.100 --> 02:11:46.900]   It's just eat reward, global IT.
[02:11:46.900 --> 02:11:48.660]   So just eat is the name of the...
[02:11:48.660 --> 02:11:51.140]   That's a big delivery company.
[02:11:51.140 --> 02:11:51.700]   Just to eat.
[02:11:51.700 --> 02:11:52.260]   Oh, OK.
[02:11:52.260 --> 02:11:53.220]   Good.
[02:11:53.220 --> 02:11:53.860]   It comes to him.
[02:11:53.860 --> 02:11:54.260]   Yeah.
[02:11:54.260 --> 02:11:56.020]   Kind of like a horse mates here.
[02:11:56.020 --> 02:11:56.260]   Yeah.
[02:11:56.260 --> 02:11:58.260]   That's nice.
[02:11:58.260 --> 02:12:01.540]   And then the guy is ready for the next web.
[02:12:01.540 --> 02:12:04.100]   Says, "Malware Tech, allow me to add another offer to the list.
[02:12:04.100 --> 02:12:06.500]   If our pan's ever crossed, I'd love to buy you a pint."
[02:12:07.060 --> 02:12:08.420]   Several, actually.
[02:12:08.420 --> 02:12:09.220]   Isn't that nice?
[02:12:09.220 --> 02:12:10.100]   That's Matthew Hughes.
[02:12:10.100 --> 02:12:14.180]   Ladies and gentlemen, what a fun day today.
[02:12:14.180 --> 02:12:15.220]   Thank you, Nathan.
[02:12:15.220 --> 02:12:15.540]   Yeah.
[02:12:15.540 --> 02:12:16.740]   Coming in on your day off,
[02:12:16.740 --> 02:12:20.020]   spending some time for driving up with Mark Millian.
[02:12:20.020 --> 02:12:21.700]   He of Bloomberg, Beanyard.
[02:12:21.700 --> 02:12:22.820]   He always a pleasure.
[02:12:22.820 --> 02:12:24.260]   Always a pleasure to have you.
[02:12:24.260 --> 02:12:25.540]   Bring Goron.
[02:12:25.540 --> 02:12:26.580]   Oh, it's going to happen.
[02:12:26.580 --> 02:12:26.660]   It's coming.
[02:12:26.660 --> 02:12:27.220]   It's going to happen.
[02:12:27.220 --> 02:12:27.700]   Nice.
[02:12:27.700 --> 02:12:28.740]   I want to always...
[02:12:28.740 --> 02:12:30.820]   I heard very good things about French Bulldogs.
[02:12:30.820 --> 02:12:32.580]   If you show him the lease, I'm going to kill you,
[02:12:32.580 --> 02:12:33.700]   because she wants another dog.
[02:12:33.700 --> 02:12:35.060]   [Laughter]
[02:12:35.060 --> 02:12:36.260]   Wait, wait, wait.
[02:12:36.260 --> 02:12:37.700]   Lisa's always here.
[02:12:37.700 --> 02:12:39.540]   What day can I bring Goron?
[02:12:39.540 --> 02:12:40.340]   Lisa's not here yet.
[02:12:40.340 --> 02:12:40.660]   Right.
[02:12:40.660 --> 02:12:42.340]   Okay.
[02:12:42.340 --> 02:12:44.740]   I can just lie until it's a different kind of dog.
[02:12:44.740 --> 02:12:45.300]   What kind of dog?
[02:12:45.300 --> 02:12:47.540]   Can you be trained to bite people on command?
[02:12:47.540 --> 02:12:48.100]   We could do that.
[02:12:48.100 --> 02:12:48.980]   Okay, then we could.
[02:12:48.980 --> 02:12:49.780]   That'll solve.
[02:12:49.780 --> 02:12:50.820]   He's such a good dog.
[02:12:50.820 --> 02:12:51.700]   Oh, he's a sweetie.
[02:12:51.700 --> 02:12:52.900]   And I know what Lisa's going to do.
[02:12:52.900 --> 02:12:54.740]   She's been saying this for a while,
[02:12:54.740 --> 02:12:56.580]   but as he has passed away,
[02:12:56.580 --> 02:12:57.300]   we lost her.
[02:12:57.300 --> 02:12:57.700]   Yeah.
[02:12:57.700 --> 02:12:58.660]   Sweet, pappy on.
[02:12:58.660 --> 02:13:00.740]   And I'm still grieving,
[02:13:00.740 --> 02:13:02.740]   but she wants another dog.
[02:13:02.740 --> 02:13:03.860]   We're going to have three cats.
[02:13:04.580 --> 02:13:07.220]   We don't think another dog is in the mix.
[02:13:07.220 --> 02:13:08.340]   Does Goron like kitties?
[02:13:08.340 --> 02:13:11.700]   He has an empty interactions with cats.
[02:13:11.700 --> 02:13:12.660]   Yeah, maybe I'll bring a cat.
[02:13:12.660 --> 02:13:13.460]   That'll fix him.
[02:13:13.460 --> 02:13:14.660]   He's great with other dogs, though,
[02:13:14.660 --> 02:13:17.540]   because he thinks he's so much bigger than he actually is.
[02:13:17.540 --> 02:13:19.540]   So he'll play with anyone, big and small.
[02:13:19.540 --> 02:13:20.340]   Like, aww.
[02:13:20.340 --> 02:13:21.780]   Yeah, huge golden retriever.
[02:13:21.780 --> 02:13:22.900]   So I shouldn't be heading on.
[02:13:22.900 --> 02:13:23.380]   Either.
[02:13:23.380 --> 02:13:25.060]   Yeah.
[02:13:25.060 --> 02:13:26.980]   And there you go.
[02:13:26.980 --> 02:13:29.380]   Jeff Jarvis, always a pleasure too for joining us.
[02:13:29.380 --> 02:13:29.780]   Always.
[02:13:29.780 --> 02:13:31.860]   I'm so happy to be at the grown-ups table.
[02:13:31.860 --> 02:13:33.380]   I love being on the table.
[02:13:33.380 --> 02:13:36.420]   We'll be back at the kids table on Wednesday with this week in Google.
[02:13:36.420 --> 02:13:39.940]   Catch Jeff's work at buzzmachine.com and get his books.
[02:13:39.940 --> 02:13:41.540]   Just buy all his books, put them on the bookshelf.
[02:13:41.540 --> 02:13:43.220]   People will figure out an intellectual.
[02:13:43.220 --> 02:13:44.100]   It's a good thing to do.
[02:13:44.100 --> 02:13:47.700]   How have you measured how wide the shelf would it be?
[02:13:47.700 --> 02:13:50.020]   A seven-foot shelf if you got all of Jeff's books?
[02:13:50.020 --> 02:13:53.220]   Be about eight inches.
[02:13:53.220 --> 02:13:58.420]   I just leave it at that.
[02:13:58.420 --> 02:14:00.500]   Thank you for joining us.
[02:14:00.500 --> 02:14:02.820]   We do twin every Sunday afternoon at 3PM Pacific.
[02:14:02.820 --> 02:14:03.940]   It's 3PM Eastern.
[02:14:03.940 --> 02:14:05.060]   2200.
[02:14:05.060 --> 02:14:07.300]   Not eight inches.
[02:14:07.300 --> 02:14:08.660]   UTC.
[02:14:08.660 --> 02:14:13.380]   If you want to join us in studio, you can email tickets at twit.tv
[02:14:13.380 --> 02:14:16.580]   as some intrepid adventurers did from all over the world.
[02:14:16.580 --> 02:14:18.340]   We'll love to put a chair out for you.
[02:14:18.340 --> 02:14:19.140]   Have you join us?
[02:14:19.140 --> 02:14:23.460]   If you can't watch live, be in studio or be in the chatroom at IRC.twit.tv.
[02:14:23.460 --> 02:14:25.380]   Don't worry because everything's on demand.
[02:14:25.380 --> 02:14:29.940]   At the website twit.tv, yes, that expensive, expensive website.
[02:14:29.940 --> 02:14:30.740]   Please visit it.
[02:14:30.740 --> 02:14:31.780]   Just make me feel better.
[02:14:32.500 --> 02:14:36.100]   And by the way, while you're there, you can subscribe or just use your favorite podcast
[02:14:36.100 --> 02:14:39.380]   program and subscribe because we don't want you to miss an episode.
[02:14:39.380 --> 02:14:41.540]   Thanks for being here.
[02:14:41.540 --> 02:14:44.340]   Another twit is in the cat bubble.
[02:14:44.340 --> 02:14:45.300]   It's amazing.
[02:14:45.300 --> 02:14:55.460]   [Music]

