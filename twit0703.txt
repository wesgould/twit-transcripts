
[00:00:00.000 --> 00:00:02.120]   It's time for Twit this week in Tech.
[00:00:02.120 --> 00:00:03.400]   Man, we got a great show for you.
[00:00:03.400 --> 00:00:06.480]   Jason Heiner from the Tech Republic is here, Brian McCullough,
[00:00:06.480 --> 00:00:09.640]   from Tech Memes Ride Home, and then wild man himself,
[00:00:09.640 --> 00:00:12.360]   Greg Ferro from the Packet Pushers Network.
[00:00:12.360 --> 00:00:14.240]   We're gonna talk about predictions for 2019,
[00:00:14.240 --> 00:00:19.240]   foldable phones, the advent of gene editing.
[00:00:19.240 --> 00:00:21.920]   I mean, it is just a crazy, crazy show.
[00:00:21.920 --> 00:00:23.960]   Stand by, Twit is next.
[00:00:23.960 --> 00:00:28.160]   Netcast, you love.
[00:00:28.160 --> 00:00:30.160]   Different people you trust.
[00:00:30.160 --> 00:00:34.960]   This is Twit.
[00:00:34.960 --> 00:00:44.000]   This is Twit.
[00:00:44.000 --> 00:00:47.760]   This week in Tech, episode 703, recorded Sunday,
[00:00:47.760 --> 00:00:50.920]   January 27th, 2019.
[00:00:50.920 --> 00:00:53.520]   Algorithms are people too.
[00:00:53.520 --> 00:00:56.120]   This week in Tech is brought to you by Casper,
[00:00:56.120 --> 00:00:58.600]   the Sleep brand that continues to revolutionize
[00:00:58.600 --> 00:01:00.920]   its line of products to create an exceptionally
[00:01:00.920 --> 00:01:03.640]   comfortable sleep experience one night at a time.
[00:01:03.640 --> 00:01:06.360]   Get $50 towards select mattresses by visiting
[00:01:06.360 --> 00:01:11.120]   casper.com/twit and using the promo code TWIT at checker.
[00:01:11.120 --> 00:01:12.920]   And by CashFly.
[00:01:12.920 --> 00:01:16.560]   Give your users the seamless experience online that they want.
[00:01:16.560 --> 00:01:19.320]   Power your Cider app with CashFly's CDN
[00:01:19.320 --> 00:01:22.080]   and be 30% faster than the competition.
[00:01:22.080 --> 00:01:25.040]   Learn more at twit.cashfly.com.
[00:01:25.040 --> 00:01:27.040]   And by, Euro.
[00:01:27.040 --> 00:01:29.440]   Never think about Wi-Fi again when you can have
[00:01:29.440 --> 00:01:33.280]   brilliant hyper-fast, super simple Wi-Fi with Euro.
[00:01:33.280 --> 00:01:36.200]   And now, get Total Network Protection with Euro Plus.
[00:01:36.200 --> 00:01:40.480]   Visit Euro.com/twit and get $100 off the Euro base unit
[00:01:40.480 --> 00:01:44.360]   2Bkins package and one year of Euro Plus when you enter the code
[00:01:44.360 --> 00:01:46.320]   TWIT at checkout.
[00:01:46.320 --> 00:01:49.320]   And by was Sabi Hot Cloud Storage.
[00:01:49.320 --> 00:01:51.560]   From the founders of Carbonite comes the cloud storage
[00:01:51.560 --> 00:01:53.960]   technology that's disrupting the industry.
[00:01:53.960 --> 00:01:57.320]   See for yourself with free unlimited storage for a month.
[00:01:57.320 --> 00:01:59.720]   Go to wasabi.com, click free trial,
[00:01:59.720 --> 00:02:03.280]   and use the offer code TWIT.
[00:02:03.280 --> 00:02:04.760]   As time for TWIT this week in tech,
[00:02:04.760 --> 00:02:07.760]   the show we cover the week's tech news.
[00:02:07.760 --> 00:02:08.640]   Each week we assemble.
[00:02:08.640 --> 00:02:09.920]   This is a one-show we do where it's
[00:02:09.920 --> 00:02:12.400]   a different panel every week.
[00:02:12.400 --> 00:02:14.120]   But I like the variety.
[00:02:14.120 --> 00:02:17.760]   And what's good is we always bring back the people we like
[00:02:17.760 --> 00:02:20.280]   the most, and we've got some of them on right now,
[00:02:20.280 --> 00:02:22.600]   including the fabulous Greg Farrow
[00:02:22.600 --> 00:02:24.440]   from the Packet Pushers Network.
[00:02:24.440 --> 00:02:25.800]   Hello, Greg!
[00:02:25.800 --> 00:02:27.160]   How's it going, everybody?
[00:02:27.160 --> 00:02:30.800]   It's the real mind on the Twitter and in our chat today.
[00:02:30.800 --> 00:02:32.000]   Good to see you.
[00:02:32.000 --> 00:02:35.400]   You're in Oxford?
[00:02:35.400 --> 00:02:38.360]   I'm in the middle of England in a town called Cheltenham.
[00:02:38.360 --> 00:02:39.920]   Cheltenham, that's right.
[00:02:39.920 --> 00:02:41.000]   Just next to Gloucester.
[00:02:41.000 --> 00:02:41.640]   Lovely.
[00:02:41.640 --> 00:02:43.240]   Which nobody knows where either of those is.
[00:02:43.240 --> 00:02:46.280]   So I don't even know why I said that in truth.
[00:02:46.280 --> 00:02:46.800]   It's Cheltenham.
[00:02:46.800 --> 00:02:48.280]   It's right next to Gloucester.
[00:02:48.280 --> 00:02:50.600]   Yeah, we're the GCHQers.
[00:02:50.600 --> 00:02:51.760]   Yeah, we're in Petaluma.
[00:02:51.760 --> 00:02:53.960]   That's right next to Kottari.
[00:02:53.960 --> 00:02:54.320]   Yeah.
[00:02:54.320 --> 00:02:55.800]   Yeah.
[00:02:55.800 --> 00:02:57.880]   I stopped the ride from San Francisco.
[00:02:57.880 --> 00:02:59.120]   That's what I usually say.
[00:02:59.120 --> 00:03:01.160]   In fact, when we're traveling and people say where we're from,
[00:03:01.160 --> 00:03:03.800]   we almost always just say San Francisco or the Bay Area.
[00:03:03.800 --> 00:03:03.880]   Yes.
[00:03:03.880 --> 00:03:05.320]   Nobody knows Petaluma.
[00:03:05.320 --> 00:03:07.640]   Jason Heinrich, he's from a little town called Louisville,
[00:03:07.640 --> 00:03:08.200]   Kentucky.
[00:03:08.200 --> 00:03:09.440]   Hello, Jason.
[00:03:09.440 --> 00:03:09.880]   Right.
[00:03:09.880 --> 00:03:10.640]   Hey.
[00:03:10.640 --> 00:03:14.200]   Editor in chief of the Tech Republic, always a pleasure?
[00:03:14.200 --> 00:03:15.000]   My pleasure.
[00:03:15.000 --> 00:03:16.120]   Thanks for having me.
[00:03:16.120 --> 00:03:18.880]   It's always fun to come and chat.
[00:03:18.880 --> 00:03:21.440]   Watching a great documentary called "Seven Days--
[00:03:21.440 --> 00:03:24.080]   The Premises-- The Seven Days Before a Big Event,"
[00:03:24.080 --> 00:03:26.040]   and they did the Kentucky Derby, and we both said,
[00:03:26.040 --> 00:03:27.840]   "We got to call Jason.
[00:03:27.840 --> 00:03:29.960]   Got to go to Louisville for the Kentucky Derby."
[00:03:29.960 --> 00:03:31.160]   I would love to do that.
[00:03:31.160 --> 00:03:32.960]   You go every year, right?
[00:03:32.960 --> 00:03:37.400]   I don't go every year, but obviously I have been during the dot
[00:03:37.400 --> 00:03:37.920]   com boom.
[00:03:37.920 --> 00:03:41.880]   Tech Republic had one of the biggest booths on Millionaire's
[00:03:41.880 --> 00:03:46.040]   row when money was cheap in the dot com era.
[00:03:46.040 --> 00:03:47.880]   You mean you don't anymore?
[00:03:47.880 --> 00:03:49.480]   No, we haven't for years.
[00:03:49.480 --> 00:03:53.240]   I mean, now we might get one of those little scroungy boxes
[00:03:53.240 --> 00:03:53.800]   or something.
[00:03:53.800 --> 00:03:55.320]   You really do.
[00:03:55.320 --> 00:03:56.960]   Times have changed.
[00:03:56.960 --> 00:03:58.160]   Times have changed.
[00:03:58.160 --> 00:03:58.720]   Times have changed.
[00:03:58.720 --> 00:03:59.640]   Big time.
[00:03:59.640 --> 00:04:00.160]   I remember.
[00:04:00.160 --> 00:04:01.320]   And also, there's so many more people that
[00:04:01.320 --> 00:04:03.720]   want to be at the Kentucky Derby now, right?
[00:04:03.720 --> 00:04:06.480]   Like, it's everybody wants to be there.
[00:04:06.480 --> 00:04:09.640]   So you're competing with Tom Brady and with everybody else.
[00:04:09.640 --> 00:04:13.280]   Michael Jordan, all these people, they're buying out
[00:04:13.280 --> 00:04:15.480]   the big expensive boxes.
[00:04:15.480 --> 00:04:15.960]   Yeah.
[00:04:15.960 --> 00:04:17.240]   It's harder to get there.
[00:04:17.240 --> 00:04:18.360]   It's become famous.
[00:04:18.360 --> 00:04:20.680]   This is the way of the world, unfortunately.
[00:04:20.680 --> 00:04:23.400]   By the time I find out about it, it's too late.
[00:04:23.400 --> 00:04:27.200]   Anyway, great to have you, Jason, CBS Interactive.
[00:04:27.200 --> 00:04:30.480]   And all the way to my left, Brian McCullough.
[00:04:30.480 --> 00:04:34.920]   He is the host of the TechMeam Ride Home podcast.
[00:04:34.920 --> 00:04:38.360]   And an internet historian, your book is great, by the way.
[00:04:38.360 --> 00:04:39.120]   Thank you, sir.
[00:04:39.120 --> 00:04:40.960]   How's it doing?
[00:04:40.960 --> 00:04:41.600]   Quite well.
[00:04:41.600 --> 00:04:43.080]   And actually, it's funny.
[00:04:43.080 --> 00:04:44.400]   I was going to hit with some history.
[00:04:44.400 --> 00:04:45.680]   The only thing I know about Gloucester
[00:04:45.680 --> 00:04:46.840]   is Richard III, right?
[00:04:47.840 --> 00:04:50.840]   My horse, my kingdom for the horse, right, Greg?
[00:04:50.840 --> 00:04:51.840]   He doesn't know.
[00:04:51.840 --> 00:04:52.840]   I don't know.
[00:04:52.840 --> 00:04:53.840]   All right.
[00:04:53.840 --> 00:04:54.840]   All right.
[00:04:54.840 --> 00:04:55.840]   I don't know.
[00:04:55.840 --> 00:04:56.840]   I don't know.
[00:04:56.840 --> 00:04:57.840]   I don't know.
[00:04:57.840 --> 00:04:58.840]   I think I know about Gloucester as a member.
[00:04:58.840 --> 00:05:00.840]   The main thing is right.
[00:05:00.840 --> 00:05:01.840]   Yeah.
[00:05:01.840 --> 00:05:02.840]   Yeah.
[00:05:02.840 --> 00:05:03.840]   I don't know.
[00:05:03.840 --> 00:05:06.840]   I sort of, there's so much history around here where we left.
[00:05:06.840 --> 00:05:09.840]   This is the Midlands and it's, you know, cathedrals and castles
[00:05:09.840 --> 00:05:11.840]   and all that stuff that just becomes every day.
[00:05:11.840 --> 00:05:14.840]   And you kind of stop absorbing the facts.
[00:05:14.840 --> 00:05:20.640]   And I know that's kind of weird for people who are watching, but that's a realist.
[00:05:20.640 --> 00:05:21.640]   I would stop.
[00:05:21.640 --> 00:05:24.560]   I'd be hitting you with annoying facts every five seconds.
[00:05:24.560 --> 00:05:26.200]   Were you, were you, Brian?
[00:05:26.200 --> 00:05:30.640]   I know you're an internet historian, but were you a history major or history buff?
[00:05:30.640 --> 00:05:32.840]   I was actually a film major.
[00:05:32.840 --> 00:05:33.840]   Oh, no, Ken.
[00:05:33.840 --> 00:05:34.840]   No, yeah.
[00:05:34.840 --> 00:05:36.120]   But all I ever read are history.
[00:05:36.120 --> 00:05:41.240]   I'm, there's a great book I'm reading right now called Horse Wheel, Something About the
[00:05:41.240 --> 00:05:47.240]   History of the Indo-European language and how it's the root language of most of all
[00:05:47.240 --> 00:05:48.240]   Western languages.
[00:05:48.240 --> 00:05:49.240]   Nice.
[00:05:49.240 --> 00:05:55.280]   Brian was on our trangula, our triangulation show in November talking about how the internet
[00:05:55.280 --> 00:06:00.160]   happened from Netscape to the iPhone.
[00:06:00.160 --> 00:06:01.160]   Brand new.
[00:06:01.160 --> 00:06:02.880]   Get yourself a copy.
[00:06:02.880 --> 00:06:05.440]   Writing history like that is easy if you lived through it.
[00:06:05.440 --> 00:06:08.440]   Oh, and as long as we're plugging books, thank you.
[00:06:08.440 --> 00:06:11.920]   Carsten Bondi, follow the geeks, 10 digital innovators in the future of work.
[00:06:11.920 --> 00:06:13.840]   That's Jason Heiner's great book.
[00:06:13.840 --> 00:06:14.840]   Thank you.
[00:06:14.840 --> 00:06:16.920]   I am chapter nine.
[00:06:16.920 --> 00:06:17.920]   Chapter nine.
[00:06:17.920 --> 00:06:19.920]   Also the sample chapter on audible.
[00:06:19.920 --> 00:06:20.920]   Yeah.
[00:06:20.920 --> 00:06:23.800]   You go to audible and you hit sample chapter.
[00:06:23.800 --> 00:06:24.800]   You get the intro.
[00:06:24.800 --> 00:06:27.000]   You get the Leo's chapter.
[00:06:27.000 --> 00:06:28.000]   Yes.
[00:06:28.000 --> 00:06:35.000]   A scene from Leo in the desert realizing that there were hundreds of people coming to see
[00:06:35.000 --> 00:06:36.000]   him.
[00:06:36.000 --> 00:06:38.400]   Yeah, unless he had no idea what the heck was going on.
[00:06:38.400 --> 00:06:39.400]   He was wild, huh?
[00:06:39.400 --> 00:06:40.400]   Yeah.
[00:06:40.400 --> 00:06:41.400]   Well, let's see.
[00:06:41.400 --> 00:06:42.680]   I don't know where to begin.
[00:06:42.680 --> 00:06:46.720]   There's so many stories this week.
[00:06:46.720 --> 00:06:48.480]   I might start with this.
[00:06:48.480 --> 00:06:52.760]   This is Scott Galloway who wrote another book that we've talked about, the Big Four all
[00:06:52.760 --> 00:06:59.280]   about the Four Horsemen of the Tech Apocalypse.
[00:06:59.280 --> 00:07:03.000]   He has his predictions for 2019 for Big Tech and beyond.
[00:07:03.000 --> 00:07:04.440]   He did something very brave.
[00:07:04.440 --> 00:07:10.440]   He went back and looked at his predictions last year and graded them.
[00:07:10.440 --> 00:07:12.080]   That's what you do if you're a professor.
[00:07:12.080 --> 00:07:13.080]   That is brave.
[00:07:13.080 --> 00:07:14.160]   Very brave.
[00:07:14.160 --> 00:07:16.120]   He thought Wayfair would crash.
[00:07:16.120 --> 00:07:17.640]   He was wrong.
[00:07:17.640 --> 00:07:22.200]   He thought Twitter, Snap and Buzzfeed would be acquired.
[00:07:22.200 --> 00:07:24.680]   He was wrong.
[00:07:24.680 --> 00:07:26.760]   But he did a few things right.
[00:07:26.760 --> 00:07:28.920]   He said Amazon would surpass Apple in value.
[00:07:28.920 --> 00:07:30.800]   No one would have thought that.
[00:07:30.800 --> 00:07:35.760]   That was partly because of a stock market bust as opposed to the growth of Amazon.
[00:07:35.760 --> 00:07:37.360]   But maybe Amazon was.
[00:07:37.360 --> 00:07:42.720]   His point with the Amazon was that it's got much greater growth potential than Apple does
[00:07:42.720 --> 00:07:46.280]   because Apple has to top out when there's a phone in every pocket.
[00:07:46.280 --> 00:07:48.040]   They don't have a successor to that.
[00:07:48.040 --> 00:07:52.600]   Whereas Amazon has plenty of room to grow in e-commerce.
[00:07:52.600 --> 00:08:00.480]   In the US, Amazon's only reaching 5% of the total retail market.
[00:08:00.480 --> 00:08:05.160]   They might have 50% of online business, but that's still only 5% of the overall retail
[00:08:05.160 --> 00:08:06.360]   turnover in the US.
[00:08:06.360 --> 00:08:07.960]   They've got so much more room to grow.
[00:08:07.960 --> 00:08:11.480]   There's no way they're not going to be bigger than Apple eventually.
[00:08:11.480 --> 00:08:15.120]   That's not the reason why Amazon stock doubled last year.
[00:08:15.120 --> 00:08:16.120]   It's because of AWS.
[00:08:16.120 --> 00:08:20.440]   It has been doubled on exactly a second course.
[00:08:20.440 --> 00:08:22.440]   Completely accidentally.
[00:08:22.440 --> 00:08:24.920]   Hey, we've got some extra servers in the closet, Jeff.
[00:08:24.920 --> 00:08:26.680]   What should we do with those?
[00:08:26.680 --> 00:08:27.680]   Yeah.
[00:08:27.680 --> 00:08:31.200]   The second horse is going to be way bigger than the e-commerce business.
[00:08:31.200 --> 00:08:32.200]   Way bigger.
[00:08:32.200 --> 00:08:36.720]   Also, everyone's always talking about how they're getting into advertising and things
[00:08:36.720 --> 00:08:37.720]   like that.
[00:08:37.720 --> 00:08:43.600]   If you think about it, obviously I'm not saying anything anybody does know, but Amazon has
[00:08:43.600 --> 00:08:48.160]   their fingers in so many pies that everybody's doing a streaming thing.
[00:08:48.160 --> 00:08:50.880]   Amazon's head streaming video for forever.
[00:08:50.880 --> 00:08:56.840]   The insane advertising thing that they could do is if they release an ad support, I think
[00:08:56.840 --> 00:09:03.240]   they already do through Twitch or something, an ad supported streaming video play.
[00:09:03.240 --> 00:09:07.480]   The ads could be tailored to things that you've already bought in your Amazon history,
[00:09:07.480 --> 00:09:11.600]   to things that you've looked at but haven't bought yet.
[00:09:11.600 --> 00:09:16.800]   They have so many potential huge things that can tap.
[00:09:16.800 --> 00:09:22.120]   To that point, and again, this is talking about last year's predictions, he said Amazon
[00:09:22.120 --> 00:09:25.360]   Media Group would surpass the revenue of Twitter and oaths.
[00:09:25.360 --> 00:09:31.400]   What he didn't predict is that oath would be renamed Verizon Media Group, but he was right
[00:09:31.400 --> 00:09:33.200]   about revenue.
[00:09:33.200 --> 00:09:37.720]   He says at the beginning of the year, Morgan Stanley predicted Amazon's Media Group would
[00:09:37.720 --> 00:09:39.560]   have a revenue of 4.5 billion.
[00:09:39.560 --> 00:09:43.040]   It probably is closer to 11 billion.
[00:09:43.040 --> 00:09:46.120]   So yeah, even Media is doing well for Amazon.
[00:09:46.120 --> 00:09:50.960]   Let's look at his predictions though for 2019.
[00:09:50.960 --> 00:09:52.200]   Snap is the Walking Dead.
[00:09:52.200 --> 00:09:54.920]   I think that's pretty obvious or no.
[00:09:54.920 --> 00:09:56.800]   Think SnapChat will survive?
[00:09:56.800 --> 00:10:02.720]   I think Snap was the Walking Dead, but if Facebook merges, and this is another news article
[00:10:02.720 --> 00:10:05.960]   which maybe will cover, but they had an article in New York Times.
[00:10:05.960 --> 00:10:10.640]   They got a scoop, New York Times got a scoop on Facebook saying that Facebook wants to
[00:10:10.640 --> 00:10:16.000]   merge Instagram WhatsApp and the Facebook Messenger program into one.
[00:10:16.000 --> 00:10:21.040]   If that happens, then SnapChat will be very popular because Facebook will not screw that
[00:10:21.040 --> 00:10:23.840]   up and drive customers into the arms of SnapChat.
[00:10:23.840 --> 00:10:24.840]   Very interesting.
[00:10:24.840 --> 00:10:27.760]   Yeah, because Facebook is notorious for screwing stuff like that up.
[00:10:27.760 --> 00:10:30.360]   As soon as Zuckerberg gets involved in something, it gets screwed up.
[00:10:30.360 --> 00:10:31.360]   Yeah.
[00:10:31.360 --> 00:10:37.080]   Yeah, the theory there is- Google by Twitter, Google by Twitter and Snap.
[00:10:37.080 --> 00:10:40.160]   I've been saying that for the last five years.
[00:10:40.160 --> 00:10:41.160]   No.
[00:10:41.160 --> 00:10:42.160]   You think so?
[00:10:42.160 --> 00:10:45.520]   They've been waiting for Twitter to get cheap enough to buy.
[00:10:45.520 --> 00:10:49.520]   I think I said once Twitter is at 12, they're not even close to 12 right now.
[00:10:49.520 --> 00:10:51.360]   It's gone way up.
[00:10:51.360 --> 00:10:54.800]   Once it gets to 12, I think then I think Google pulls the trigger.
[00:10:54.800 --> 00:11:01.120]   Galloway predicts Twitter will be cut in half in 2019, mostly because of bots, foreign
[00:11:01.120 --> 00:11:05.080]   agents, all of the crap on Twitter.
[00:11:05.080 --> 00:11:08.680]   I think that's a fair prediction, but I've been saying that for years too.
[00:11:08.680 --> 00:11:09.680]   I don't know.
[00:11:09.680 --> 00:11:12.040]   Google doesn't do content.
[00:11:12.040 --> 00:11:16.840]   It doesn't- Google can't be a media company and Twitter, Facebook, Snap, they're all media
[00:11:16.840 --> 00:11:18.840]   companies, so Google can't buy them and want-
[00:11:18.840 --> 00:11:22.400]   It's Twitter really isn't a media company though.
[00:11:22.400 --> 00:11:24.800]   They're trying to be, but they're really a data company.
[00:11:24.800 --> 00:11:26.360]   They just don't know it yet.
[00:11:26.360 --> 00:11:27.360]   It doesn't matter.
[00:11:27.360 --> 00:11:28.360]   It doesn't matter.
[00:11:28.360 --> 00:11:34.720]   Google's getting nailed in the EU for antitrust, for screwing over the local press,
[00:11:34.720 --> 00:11:35.720]   all that stuff, right?
[00:11:35.720 --> 00:11:39.880]   If they were to buy Twitter, the European Union would be down on them so hard that it wouldn't
[00:11:39.880 --> 00:11:40.880]   matter.
[00:11:40.880 --> 00:11:44.200]   Twitter, Snap, Facebook, they're publishers.
[00:11:44.200 --> 00:11:45.920]   They're absolutely content creators.
[00:11:45.920 --> 00:11:50.080]   They cook their platforms are all about stealing content from other people and publishing it
[00:11:50.080 --> 00:11:53.440]   as repackaging it, as content that they produce.
[00:11:53.440 --> 00:11:55.120]   Google can't do that.
[00:11:55.120 --> 00:11:56.480]   If it does, it will die.
[00:11:56.480 --> 00:12:00.760]   It will instantly be a subject to an antitrust action in the EU and then shortly after that
[00:12:00.760 --> 00:12:01.760]   in the EU.
[00:12:01.760 --> 00:12:05.960]   Ultimately though, they're all in the same business which is collecting data for sales.
[00:12:05.960 --> 00:12:06.960]   That's really the business.
[00:12:06.960 --> 00:12:09.640]   It's just a matter of how you get that data.
[00:12:09.640 --> 00:12:10.640]   That's the business.
[00:12:10.640 --> 00:12:15.720]   Twitter, I do think Twitter is a real time data business.
[00:12:15.720 --> 00:12:20.520]   I do agree with you, Greg, though, in that most people don't understand that.
[00:12:20.520 --> 00:12:22.560]   I think Twitter barely understands it.
[00:12:22.560 --> 00:12:23.560]   That's the problem, frankly.
[00:12:23.560 --> 00:12:25.920]   Twitter's got the worst management ever.
[00:12:25.920 --> 00:12:31.760]   They don't seem to understand what to do with it, right?
[00:12:31.760 --> 00:12:33.200]   Or is it just hard?
[00:12:33.200 --> 00:12:37.840]   Did you read the article from Jack Dorsey that he published this week?
[00:12:37.840 --> 00:12:38.840]   Yeah, Jack.
[00:12:38.840 --> 00:12:40.760]   The guy is insane.
[00:12:40.760 --> 00:12:42.480]   The guy's a nutcase.
[00:12:42.480 --> 00:12:45.400]   He's going on about, "Oh, we've got to do this."
[00:12:45.400 --> 00:12:49.040]   I met Mark Zuckerberg and we killed a goat and then we ate it.
[00:12:49.040 --> 00:12:56.720]   Blobber, then you go like, "This is not how the CEO of a major company acts."
[00:12:56.720 --> 00:12:58.400]   We've seen Elon Musk come on hinge.
[00:12:58.400 --> 00:13:01.480]   Now we're watching Jack Dorsey turn into a fruit loop.
[00:13:01.480 --> 00:13:04.600]   Zuckerberg's clearly losing his control over at Facebook.
[00:13:04.600 --> 00:13:06.880]   He's just like, "Oh, I don't know what to do.
[00:13:06.880 --> 00:13:09.080]   I'm going to just say stuff and see what happens."
[00:13:09.080 --> 00:13:11.320]   It's all just going bananas, right?
[00:13:11.320 --> 00:13:15.720]   It's really funny watching these tech company CEOs all just blow up because they don't know
[00:13:15.720 --> 00:13:19.560]   what it's like to have a bad day.
[00:13:19.560 --> 00:13:21.840]   The world is changing around them so quickly.
[00:13:21.840 --> 00:13:22.840]   Sorry, go ahead.
[00:13:22.840 --> 00:13:23.840]   Oh, no, no, go ahead.
[00:13:23.840 --> 00:13:26.400]   Are you guys a super light?
[00:13:26.400 --> 00:13:27.400]   Just jump in.
[00:13:27.400 --> 00:13:28.640]   Go ahead, Jason.
[00:13:28.640 --> 00:13:30.640]   Go ahead, Jason.
[00:13:30.640 --> 00:13:36.760]   If you're Elon Musk, if you're Mark Zuckerberg, if you're Jack Dorsey, the world is changing
[00:13:36.760 --> 00:13:38.640]   around them so quickly.
[00:13:38.640 --> 00:13:44.000]   Their companies, when they get big, it's just hard to change big companies quickly.
[00:13:44.000 --> 00:13:47.080]   They are struggling really, really hard with it.
[00:13:47.080 --> 00:13:52.520]   Everything great has been created by small teams and usually gets eventually screwed
[00:13:52.520 --> 00:13:54.880]   up by big teams.
[00:13:54.880 --> 00:14:00.160]   Even the iPhone, I'm sure you guys have seen the stories and I've talked to people that
[00:14:00.160 --> 00:14:02.240]   were on the original iPhone team.
[00:14:02.240 --> 00:14:06.720]   It was about 20 people that made the iPhone.
[00:14:06.720 --> 00:14:12.800]   And you get in the position where when it's big enough, you play not to lose.
[00:14:12.800 --> 00:14:15.960]   And that's what we're seeing now is they're playing not to lose.
[00:14:15.960 --> 00:14:17.560]   It doesn't work at internet scale.
[00:14:17.560 --> 00:14:19.600]   It doesn't work at internet speed.
[00:14:19.600 --> 00:14:24.920]   And these are problems that are a little unique to the history of business.
[00:14:24.920 --> 00:14:25.920]   And it's not going well.
[00:14:25.920 --> 00:14:26.920]   And they're not?
[00:14:26.920 --> 00:14:27.920]   I mean, I will completely agree.
[00:14:27.920 --> 00:14:28.920]   That's complete, folks.
[00:14:28.920 --> 00:14:29.920]   Stop apologizing for them.
[00:14:29.920 --> 00:14:30.920]   Those people are all idiots.
[00:14:30.920 --> 00:14:31.920]   And idiots.
[00:14:31.920 --> 00:14:32.920]   Look, all the end.
[00:14:32.920 --> 00:14:34.720]   I'll say this, Greg.
[00:14:34.720 --> 00:14:35.920]   I'll say this.
[00:14:35.920 --> 00:14:38.960]   I think it's pretty clear Mark Zuckerberg was just incredibly lucky.
[00:14:38.960 --> 00:14:39.960]   Yeah.
[00:14:39.960 --> 00:14:40.960]   Right.
[00:14:40.960 --> 00:14:41.960]   He's not smart.
[00:14:41.960 --> 00:14:42.960]   He's not.
[00:14:42.960 --> 00:14:43.960]   He's not.
[00:14:43.960 --> 00:14:44.960]   Incredibly lucky.
[00:14:44.960 --> 00:14:45.960]   Jack Dorsey.
[00:14:45.960 --> 00:14:49.680]   Who knows why Jack Dorsey is running Twitter, mostly because Ev and company just said, "Ah,
[00:14:49.680 --> 00:14:50.680]   screw it.
[00:14:50.680 --> 00:14:52.680]   I got enough money."
[00:14:52.680 --> 00:14:54.320]   Look at it.
[00:14:54.320 --> 00:14:59.880]   And then Google, Larry and Sergey, incredibly lucky for a long time, didn't even know what
[00:14:59.880 --> 00:15:01.080]   they had.
[00:15:01.080 --> 00:15:05.900]   Some adult supervision came along, probably, Eric Schmidt, but somebody came along and
[00:15:05.900 --> 00:15:10.040]   said, "Dudes, you got this mountain of data.
[00:15:10.040 --> 00:15:11.760]   This is really valuable stuff."
[00:15:11.760 --> 00:15:12.760]   They went, "What?"
[00:15:12.760 --> 00:15:13.760]   Yeah.
[00:15:13.760 --> 00:15:14.760]   And this is a data business.
[00:15:14.760 --> 00:15:16.460]   That's, again, I think lucky.
[00:15:16.460 --> 00:15:19.960]   And I don't know who you'd point to to be the genius there.
[00:15:19.960 --> 00:15:25.400]   Actually, I have a theory, but I don't want to get too much in the weeds on that one.
[00:15:25.400 --> 00:15:27.800]   In most cases, these guys are like Mark Cuban.
[00:15:27.800 --> 00:15:29.740]   They just are lucky sons of guns.
[00:15:29.740 --> 00:15:31.700]   They got in the right place at the right time.
[00:15:31.700 --> 00:15:32.700]   And they cashed in.
[00:15:32.700 --> 00:15:37.600]   Because Mark Cuban was smart enough to cash in and get out and be a billionaire professionally.
[00:15:37.600 --> 00:15:39.160]   Yeah, that's right.
[00:15:39.160 --> 00:15:40.720]   His life is a lot easier, right?
[00:15:40.720 --> 00:15:44.080]   Because he didn't have this delusion that he was a genius.
[00:15:44.080 --> 00:15:49.560]   I've said that many times that Mark Cuban is quietly the most brilliant man ever to be
[00:15:49.560 --> 00:15:51.240]   in the tech industry because he got out.
[00:15:51.240 --> 00:15:52.720]   But the thing with...
[00:15:52.720 --> 00:15:59.280]   By the way, if I'd gotten somebody bought Twit from me, like Yahoo bought broadcast.com
[00:15:59.280 --> 00:16:02.000]   and I got a billion dollars, I would have gotten out too.
[00:16:02.000 --> 00:16:04.380]   So just give me some, I would have been just as brilliant.
[00:16:04.380 --> 00:16:09.140]   So the thing with Jack is in that article, because Jack's on a publicity tour again.
[00:16:09.140 --> 00:16:13.740]   And this happened the same, the last time I think it was, I was on the show.
[00:16:13.740 --> 00:16:16.900]   There was the Zuckerberg piece that got all the controversy.
[00:16:16.900 --> 00:16:22.700]   Like, I know PR people think that this is a good idea.
[00:16:22.700 --> 00:16:23.900]   We need to get him out there.
[00:16:23.900 --> 00:16:27.460]   He was on the Bill Simmons podcast.
[00:16:27.460 --> 00:16:29.620]   I'm a human like you fellow humans.
[00:16:29.620 --> 00:16:30.620]   Yeah.
[00:16:30.620 --> 00:16:33.100]   That's usually, that's Mark does that too.
[00:16:33.100 --> 00:16:35.320]   I am a human like you fellow.
[00:16:35.320 --> 00:16:36.320]   Exactly.
[00:16:36.320 --> 00:16:38.120]   So Jack's flavor of that is that he...
[00:16:38.120 --> 00:16:39.120]   I killed a goat.
[00:16:39.120 --> 00:16:40.120]   Sometimes...
[00:16:40.120 --> 00:16:41.960]   No, no, because actually he was trying to differentiate himself.
[00:16:41.960 --> 00:16:44.360]   He said he had a salad when Mark got the goat.
[00:16:44.360 --> 00:16:45.880]   He's like, "I thought that that was a little weird."
[00:16:45.880 --> 00:16:46.880]   But that's the thing.
[00:16:46.880 --> 00:16:54.020]   So Jack, he sometimes comes off as like almost the most Zen and like a evolved tech CEO out
[00:16:54.020 --> 00:16:55.020]   there.
[00:16:55.020 --> 00:16:59.900]   But then other times and most times it's like, "Well, or he's just a flake."
[00:16:59.900 --> 00:17:00.900]   And so like, you know, when he...
[00:17:00.900 --> 00:17:04.500]   I think there was a tweet this weekend about him talking about his three day fasts and things
[00:17:04.500 --> 00:17:05.500]   like that.
[00:17:05.500 --> 00:17:08.860]   And I can't remember because I'd give her a plot or a quote obviously.
[00:17:08.860 --> 00:17:12.220]   But as somebody on Twitter said, "Well, now I understand why Twitter is the way it is
[00:17:12.220 --> 00:17:15.380]   because the CEO is starving all the time."
[00:17:15.380 --> 00:17:21.320]   When you talk to people that work at Twitter, the thing that they always say is when they
[00:17:21.320 --> 00:17:28.060]   go to other companies, they can't believe that decisions actually get made in a logical,
[00:17:28.060 --> 00:17:29.500]   timely manner.
[00:17:29.500 --> 00:17:33.580]   Because at Twitter, the culture is just like, you know, it takes them three years to decide
[00:17:33.580 --> 00:17:36.460]   to go beyond the character limit on tweets.
[00:17:36.460 --> 00:17:42.260]   And it's just like, you can be Zen and you can be philosophical, but also you need to
[00:17:42.260 --> 00:17:43.260]   be decisive.
[00:17:43.260 --> 00:17:44.940]   I don't want to imply that these people are flawed.
[00:17:44.940 --> 00:17:45.940]   I'm not saying that.
[00:17:45.940 --> 00:17:48.220]   I'm saying they're normal.
[00:17:48.220 --> 00:17:50.820]   And unfortunately they got very lucky.
[00:17:50.820 --> 00:17:56.260]   And what happens when you become a billionaire is you think that you suddenly, your mind
[00:17:56.260 --> 00:18:01.940]   gets twisted and you think you did it and you are somehow God-like.
[00:18:01.940 --> 00:18:06.500]   And the problem is that the problems that these companies face are very difficult.
[00:18:06.500 --> 00:18:08.900]   Normal, it's not an easy thing to do.
[00:18:08.900 --> 00:18:13.700]   And we can see this is the history of technology companies from day one.
[00:18:13.700 --> 00:18:18.380]   The one person that I think might be a God, I'm not sure is Jeff Bezos.
[00:18:18.380 --> 00:18:19.380]   For sure.
[00:18:19.380 --> 00:18:23.340]   I think- No, mostly Jeff Bezos hired people under him.
[00:18:23.340 --> 00:18:28.620]   He set up a process so that the way that Amazon works is he created a management structure.
[00:18:28.620 --> 00:18:29.620]   But that was smart.
[00:18:29.620 --> 00:18:30.860]   But that was smart, right?
[00:18:30.860 --> 00:18:33.740]   I mean, the whole pizza principle of- Yeah, that's right.
[00:18:33.740 --> 00:18:37.020]   Don't have a meaning that you can't have feed with two pizzas.
[00:18:37.020 --> 00:18:41.340]   The whole idea of writing instead of making pitches for stuff writing the press release,
[00:18:41.340 --> 00:18:43.860]   I think he did some very, very smart things.
[00:18:43.860 --> 00:18:44.860]   That was a good one.
[00:18:44.860 --> 00:18:48.620]   The second one was he swindled the investors into convincing them not to take a profit.
[00:18:48.620 --> 00:18:50.780]   That only worked for a little while though.
[00:18:50.780 --> 00:18:56.100]   Remember, he could no longer go back to the capital markets around about 2000.
[00:18:56.100 --> 00:18:58.780]   And he had to start to turn that profit knob a little bit.
[00:18:58.780 --> 00:18:59.780]   Yeah.
[00:18:59.780 --> 00:19:01.060]   Those are the two innovations.
[00:19:01.060 --> 00:19:06.300]   Now, the challenge is I would never work for Amazon because those people are used like
[00:19:06.300 --> 00:19:07.300]   slaves.
[00:19:07.300 --> 00:19:09.900]   That's another bright thing that Jeff Bezos did.
[00:19:09.900 --> 00:19:12.660]   They're known for working them to the bone.
[00:19:12.660 --> 00:19:15.900]   You want to become the richest man in the world?
[00:19:15.900 --> 00:19:16.900]   Extraordinary from the slaves.
[00:19:16.900 --> 00:19:17.900]   How well?
[00:19:17.900 --> 00:19:18.900]   I mean, other workers.
[00:19:18.900 --> 00:19:19.900]   How well?
[00:19:19.900 --> 00:19:23.580]   The pyramids with nine to five workers.
[00:19:23.580 --> 00:19:26.700]   Let's ask the history guy about this.
[00:19:26.700 --> 00:19:30.940]   Well, I was going to use the pyramids analogy or whatever.
[00:19:30.940 --> 00:19:35.100]   But okay, so to bring it full circle though, and to say that Bezos is probably the closest
[00:19:35.100 --> 00:19:39.980]   to genius is so that, okay, even if he doesn't come up with AWS himself, like we're saying
[00:19:39.980 --> 00:19:44.660]   he put up, you know, look at what Google's been trying to do moonshots for how long now.
[00:19:44.660 --> 00:19:46.780]   They know they're a one trick advertising pony.
[00:19:46.780 --> 00:19:48.900]   They know that's not really changing the world.
[00:19:48.900 --> 00:19:49.900]   And they can't do it.
[00:19:49.900 --> 00:19:54.940]   And the same thing when you see Facebook training in the hardware and you see, you know, even
[00:19:54.940 --> 00:19:59.300]   how people try apples, apples like what's next.
[00:19:59.300 --> 00:20:00.300]   No idea.
[00:20:00.300 --> 00:20:01.300]   Okay.
[00:20:01.300 --> 00:20:06.020]   So Amazon has in place a system that, hey, you know, Jeff, this thing over here, you know,
[00:20:06.020 --> 00:20:08.540]   we've got this, these spare computer cycles and things like that.
[00:20:08.540 --> 00:20:11.540]   Do you think there's a business here and there's a mechanism in place for them to go
[00:20:11.540 --> 00:20:12.540]   explore it?
[00:20:12.540 --> 00:20:15.700]   And then when it works to then actually execute, that's actually the key.
[00:20:15.700 --> 00:20:19.780]   Anyone can come up with great other business ideas, but then to execute on turning that
[00:20:19.780 --> 00:20:21.500]   into your next great business.
[00:20:21.500 --> 00:20:22.500]   That's insane.
[00:20:22.500 --> 00:20:24.500]   I'm going to get credit by the way.
[00:20:24.500 --> 00:20:28.580]   Instead of getting paid taxes, he was able to use that to fund those things.
[00:20:28.580 --> 00:20:32.260]   But literally what he did was instead of paying a, you know, paying shareholders a dividend,
[00:20:32.260 --> 00:20:34.500]   he would punt on all these startups.
[00:20:34.500 --> 00:20:35.500]   Yeah.
[00:20:35.500 --> 00:20:37.180]   But what did he do that was genius?
[00:20:37.180 --> 00:20:42.100]   He got these investors, got them to give millions of dollars, plowed every penny of profit
[00:20:42.100 --> 00:20:44.340]   into what distribution said.
[00:20:44.340 --> 00:20:45.340]   Gross.
[00:20:45.340 --> 00:20:49.900]   And that was the right move of a gutsy move, right?
[00:20:49.900 --> 00:20:52.380]   Well, yes and no, there's two things they do.
[00:20:52.380 --> 00:20:56.700]   One is they, as we've already pointed out, as they continue to innovate and develop new
[00:20:56.700 --> 00:20:57.700]   business ideas.
[00:20:57.700 --> 00:21:01.180]   So they built distribution centers because the freight companies couldn't do it for them
[00:21:01.180 --> 00:21:04.260]   or the handling companies couldn't do it for them and getting the goods closer to the
[00:21:04.260 --> 00:21:05.260]   customer.
[00:21:05.260 --> 00:21:10.580]   And now they're buying planes and now they've looked at using drones to do home deliveries
[00:21:10.580 --> 00:21:13.580]   and they're doing robot cars.
[00:21:13.580 --> 00:21:18.100]   But with all of those warehouse and with all that distribution, they did the genius thing
[00:21:18.100 --> 00:21:20.460]   of allowing third parties onto that platform.
[00:21:20.460 --> 00:21:23.060]   Since hey, we already have this here anyway.
[00:21:23.060 --> 00:21:28.100]   There is more money made by Amazon from the third parties that are on the Amazon platform
[00:21:28.100 --> 00:21:29.100]   than Amazon.
[00:21:29.100 --> 00:21:31.780]   It's not even close, yes, day and age.
[00:21:31.780 --> 00:21:34.100]   But that's on that Amazon sells itself.
[00:21:34.100 --> 00:21:35.100]   Exactly.
[00:21:35.100 --> 00:21:40.180]   But the secret to that platform is that the people using the platform must get more profit
[00:21:40.180 --> 00:21:41.820]   than you get from it yourself.
[00:21:41.820 --> 00:21:42.820]   That's okay.
[00:21:42.820 --> 00:21:47.620]   If you get, that's the whole key.
[00:21:47.620 --> 00:21:49.180]   He comes from hedge funds, right?
[00:21:49.180 --> 00:21:52.980]   He understands that the key is to collect all the crumbs.
[00:21:52.980 --> 00:21:56.420]   It's fine if other people make money as long as you get a percentage of every financial
[00:21:56.420 --> 00:22:00.180]   transaction, you're going to be the wealthiest man in the world.
[00:22:00.180 --> 00:22:03.900]   The difference between Amazon and everybody else is they know what business they're in,
[00:22:03.900 --> 00:22:04.900]   right?
[00:22:04.900 --> 00:22:06.460]   We're talking about the problems with all these other companies.
[00:22:06.460 --> 00:22:08.860]   They don't really know what business they're in.
[00:22:08.860 --> 00:22:09.860]   And so they don't know what.
[00:22:09.860 --> 00:22:12.860]   That's a bunch of poor podcasters talking about.
[00:22:12.860 --> 00:22:15.300]   Let me come rich.
[00:22:15.300 --> 00:22:17.860]   There's a certain irony in all of this.
[00:22:17.860 --> 00:22:18.860]   There's a lot of lies.
[00:22:18.860 --> 00:22:19.860]   Here's a secret.
[00:22:19.860 --> 00:22:21.660]   We know we don't want to be them, right?
[00:22:21.660 --> 00:22:22.740]   I really look at it.
[00:22:22.740 --> 00:22:27.460]   I mean, I look at all those CEOs like Zuckerberg, founder CEOs particularly.
[00:22:27.460 --> 00:22:31.940]   It Musk, Zuckerberg, you know, Dorsey and all that.
[00:22:31.940 --> 00:22:32.940]   Was Musk lucky?
[00:22:32.940 --> 00:22:34.860]   I feel like Musk was pretty smart.
[00:22:34.860 --> 00:22:38.460]   Yeah, but at some point you've got to stick with his original businesses.
[00:22:38.460 --> 00:22:39.460]   He's pretty lucky.
[00:22:39.460 --> 00:22:40.460]   He has a visionary.
[00:22:40.460 --> 00:22:42.060]   Yeah, PayPal, maybe he was lucky.
[00:22:42.060 --> 00:22:43.500]   But I think he was a visionary.
[00:22:43.500 --> 00:22:45.340]   I think he's a visionary.
[00:22:45.340 --> 00:22:48.940]   You can be visionary, but at one point you have to stand back and let someone execute.
[00:22:48.940 --> 00:22:49.940]   So when we look at-
[00:22:49.940 --> 00:22:51.940]   Yeah, he has not been good at that.
[00:22:51.940 --> 00:22:55.660]   Yeah, if you look at more traditional companies, there are people running them at the top who
[00:22:55.660 --> 00:22:57.180]   are grown-ups that don't say so.
[00:22:57.180 --> 00:23:00.940]   So you look at Michael Dell, for example, still at the helm of Dell, but you don't see
[00:23:00.940 --> 00:23:06.340]   him going off a three-day meditation temple, you know, in a country which is that-
[00:23:06.340 --> 00:23:08.980]   Don't know what he wants to go to Myanmar.
[00:23:08.980 --> 00:23:10.980]   And sitting in a cave, that's fine.
[00:23:10.980 --> 00:23:13.380]   Yeah, but don't talk about it, right?
[00:23:13.380 --> 00:23:14.380]   Yeah, don't tell anybody.
[00:23:14.380 --> 00:23:15.380]   If you do that-
[00:23:15.380 --> 00:23:16.380]   Well, I don't want to know.
[00:23:16.380 --> 00:23:18.380]   That's the British in you right there.
[00:23:18.380 --> 00:23:19.380]   That's very British.
[00:23:19.380 --> 00:23:20.380]   It's so neat.
[00:23:20.380 --> 00:23:21.380]   Just don't tell anybody.
[00:23:21.380 --> 00:23:25.980]   It's so egotistical to tell people about your personal life and put it out there.
[00:23:25.980 --> 00:23:26.980]   Tell America.
[00:23:26.980 --> 00:23:29.220]   It cares about you.
[00:23:29.220 --> 00:23:34.140]   So I just want to, as a complete footnote, I do want to say that I think that the evil
[00:23:34.140 --> 00:23:38.820]   genius at Google was not Sergei, it was not Larry, it was not Eric Schmidt, it was
[00:23:38.820 --> 00:23:41.660]   this guy who probably most people don't know is Hal Varian.
[00:23:41.660 --> 00:23:45.420]   He is to this day, the chief economist at Google.
[00:23:45.420 --> 00:23:50.620]   He wrote the seminal papers at the end of the last century that said, "Here's where
[00:23:50.620 --> 00:23:52.120]   we have value.
[00:23:52.120 --> 00:23:53.780]   Here's how we can capitalize on this value."
[00:23:53.780 --> 00:23:58.780]   And if you want to know more about why Google took that pivot, because it's interesting.
[00:23:58.780 --> 00:24:02.700]   I interviewed Shoshana Zuboff about her book Surveillance Capitalism.
[00:24:02.700 --> 00:24:07.380]   In the book, she quotes Larry giving a speech in 1998 about Google saying, "We could never
[00:24:07.380 --> 00:24:12.460]   take advertising because that would taint the search product.
[00:24:12.460 --> 00:24:14.380]   We have to stay above that."
[00:24:14.380 --> 00:24:16.100]   That was Larry and Sergei did nothing.
[00:24:16.100 --> 00:24:17.100]   That's in their original paper.
[00:24:17.100 --> 00:24:18.100]   That's right.
[00:24:18.100 --> 00:24:19.100]   That's in the paper.
[00:24:19.100 --> 00:24:20.100]   That's in the paper.
[00:24:20.100 --> 00:24:24.900]   It was Hal Varian who came along and said, "Look, first of all, there's been a stock
[00:24:24.900 --> 00:24:25.900]   market crash.
[00:24:25.900 --> 00:24:29.540]   We better find a way to make money fast because the investors are getting itchy.
[00:24:29.540 --> 00:24:31.020]   And here's how we do it."
[00:24:31.020 --> 00:24:34.980]   So maybe Hal Varian deserves credit, not well known.
[00:24:34.980 --> 00:24:38.140]   That's where Greg, you're right.
[00:24:38.140 --> 00:24:40.420]   What does it hide your light under a bushel?
[00:24:40.420 --> 00:24:41.420]   Yeah.
[00:24:41.420 --> 00:24:42.420]   Yeah.
[00:24:42.420 --> 00:24:46.580]   If you're the leader of that sort of company, you'll suppose we expect you to be a grown
[00:24:46.580 --> 00:24:52.540]   up and say things that people expect you to say be reasonably well-behaved in public.
[00:24:52.540 --> 00:24:58.420]   And if you want to go and have a bunch of mistresses and do BDSM in your own time, don't go and
[00:24:58.420 --> 00:25:00.100]   make sure that that comes out in public.
[00:25:00.100 --> 00:25:01.780]   Just don't do that.
[00:25:01.780 --> 00:25:03.380]   Just keep it in your pants.
[00:25:03.380 --> 00:25:05.140]   Well, let's just go ahead.
[00:25:05.140 --> 00:25:06.140]   One more thing about Amazon.
[00:25:06.140 --> 00:25:07.780]   Sorry, last thing on Amazon.
[00:25:07.780 --> 00:25:10.260]   No one would business their in.
[00:25:10.260 --> 00:25:18.340]   They figured out over the last, especially five years, that their business of the future
[00:25:18.340 --> 00:25:25.060]   is delivering things to people, delivering goods and delivering bits, right?
[00:25:25.060 --> 00:25:33.340]   Even just electronic stuff and making micro-transactions off of every single one of them, right?
[00:25:33.340 --> 00:25:41.460]   And so that is why the future, they are already owning more and more of the future and where
[00:25:41.460 --> 00:25:42.780]   it's headed.
[00:25:42.780 --> 00:25:48.660]   And the thing that could hold them back is if they're going to run into some of these
[00:25:48.660 --> 00:25:52.940]   same problems that some of the other companies are, but they know what business they're in
[00:25:52.940 --> 00:25:56.020]   and they know use that to make the decisions.
[00:25:56.020 --> 00:26:00.820]   I think a lot of these other companies, Twitter, Facebook, to an extent Google, Google still
[00:26:00.820 --> 00:26:09.340]   sometimes is reaching and trying to figure things out is that they're still not quite
[00:26:09.340 --> 00:26:16.740]   sure what the future could be or how big they could get or what are the most important
[00:26:16.740 --> 00:26:20.580]   aspects of what they do for their customers.
[00:26:20.580 --> 00:26:21.580]   So that's the thing.
[00:26:21.580 --> 00:26:24.580]   Most companies though never have a second act, right?
[00:26:24.580 --> 00:26:25.580]   Yeah.
[00:26:25.580 --> 00:26:26.580]   It's really true.
[00:26:26.580 --> 00:26:27.580]   That's a hard thing to do.
[00:26:27.580 --> 00:26:33.140]   Well, not only do they not have a second act, 50% of acquisitions they make fail statistically,
[00:26:33.140 --> 00:26:34.140]   right?
[00:26:34.140 --> 00:26:38.380]   And for some companies, they do those acquisitions because they're trying to find a second act,
[00:26:38.380 --> 00:26:40.540]   but often that's a failure too.
[00:26:40.540 --> 00:26:43.980]   Interestingly the Galloway's predictions, a lot of them have to do with Amazon.
[00:26:43.980 --> 00:26:49.540]   He says Amazon will become one of the five largest media firms by the end of 2020.
[00:26:49.540 --> 00:26:56.740]   He says Amazon, this is an interesting prediction, will spin off AWS to reduce any trust concerns.
[00:26:56.740 --> 00:26:57.740]   Is it inevitable?
[00:26:57.740 --> 00:26:58.740]   Yeah.
[00:26:58.740 --> 00:26:59.740]   Yeah.
[00:26:59.740 --> 00:27:00.740]   He also says Amazon.
[00:27:00.740 --> 00:27:03.540]   That's been moved by most people.
[00:27:03.540 --> 00:27:08.140]   Begins their march toward becoming the most valuable healthcare company in the world.
[00:27:08.140 --> 00:27:13.020]   I talked to Christine Afar last week and not only that, they're about to get into health
[00:27:13.020 --> 00:27:19.700]   insurance, not just with the combination with Berkshire Hathaway and whoever the other third
[00:27:19.700 --> 00:27:20.700]   party.
[00:27:20.700 --> 00:27:21.700]   JP Morgan.
[00:27:21.700 --> 00:27:22.700]   Yeah.
[00:27:22.700 --> 00:27:23.700]   Yeah.
[00:27:23.700 --> 00:27:25.620]   It's going to be health insurance this year, she thinks.
[00:27:25.620 --> 00:27:27.660]   The spin off thing is not right though.
[00:27:27.660 --> 00:27:32.660]   The spin off thing, if you look at their actual earnings, their business, AWS is their business.
[00:27:32.660 --> 00:27:35.540]   Like it is the only really profit engine.
[00:27:35.540 --> 00:27:37.380]   Jeff gets to keep the stock business.
[00:27:37.380 --> 00:27:40.340]   It's absolutely going to happen.
[00:27:40.340 --> 00:27:44.660]   The simple fact is AWS is still only earning about six to eight billion a quarter.
[00:27:44.660 --> 00:27:48.420]   So it's still tiny, but it's got massive growth potential.
[00:27:48.420 --> 00:27:53.180]   So for example, Cisco makes 12 to 13 billion dollars a quarter and AWS is only half the
[00:27:53.180 --> 00:27:54.180]   size of Cisco.
[00:27:54.180 --> 00:27:59.940]   HPE does eight billion dollars a quarter and AWS is tiny, but AWS has mammoth growth potential
[00:27:59.940 --> 00:28:02.140]   and it's actually driving change in the market.
[00:28:02.140 --> 00:28:07.140]   So if they float that off, it could be as much as 60% of the value of Amazon today.
[00:28:07.140 --> 00:28:11.140]   And so you got to get that cash and then you could put it back into AWS and he can make
[00:28:11.140 --> 00:28:12.980]   AWS blow up like a nuclear bomb.
[00:28:12.980 --> 00:28:15.100]   It's like becoming critical mess.
[00:28:15.100 --> 00:28:18.580]   No, I think it's the only good business they have.
[00:28:18.580 --> 00:28:25.660]   These other businesses are so dependent on so many different things, fuel, margin, the
[00:28:25.660 --> 00:28:27.300]   margins are terrible.
[00:28:27.300 --> 00:28:30.540]   AWS is the only really great business they have.
[00:28:30.540 --> 00:28:35.380]   I think it's more likely they spin off the e-commerce business into some things that
[00:28:35.380 --> 00:28:36.700]   low margin business.
[00:28:36.700 --> 00:28:41.580]   But the future of that business is delivering electronic goods and all of it is through
[00:28:41.580 --> 00:28:42.580]   AWS.
[00:28:42.580 --> 00:28:43.580]   Yes.
[00:28:43.580 --> 00:28:44.900]   You can't disassemble the platform.
[00:28:44.900 --> 00:28:48.540]   You can't disassemble the shopping platform and the ad network.
[00:28:48.540 --> 00:28:49.540]   There is a synergy.
[00:28:49.540 --> 00:28:50.540]   There is a synergy.
[00:28:50.540 --> 00:28:51.540]   That's true.
[00:28:51.540 --> 00:28:55.460]   There is a synergy, but there's a real, but the real qualm.
[00:28:55.460 --> 00:28:58.860]   In fact, we're going to get to this after the break is regulation and everybody I think
[00:28:58.860 --> 00:29:01.100]   in Silicon Valley is terrified.
[00:29:01.100 --> 00:29:02.100]   That was the point.
[00:29:02.100 --> 00:29:05.460]   It's got Galloway's book was here comes the government.
[00:29:05.460 --> 00:29:06.460]   Yeah.
[00:29:06.460 --> 00:29:11.300]   His last prediction, I think a little tongue in cheek, Shell Sandberg will marry Mackenzie
[00:29:11.300 --> 00:29:12.300]   Bezos.
[00:29:12.300 --> 00:29:18.060]   They'll pull the $70 billion fortune and become the largest shareholders in alphabet.
[00:29:18.060 --> 00:29:22.860]   Ms. Sandberg reanimates Google plus Ms. Bezos takes over Google's voice group and they
[00:29:22.860 --> 00:29:24.660]   legally adopt Devin Spiegel.
[00:29:24.660 --> 00:29:29.660]   I think that's, I hope that happens.
[00:29:29.660 --> 00:29:34.780]   He is a funny guy, but he makes a very good point about Sheryl Sandberg.
[00:29:34.780 --> 00:29:38.060]   He says that unfortunately because she's a woman and so...
[00:29:38.060 --> 00:29:39.620]   She says she's going to leave.
[00:29:39.620 --> 00:29:41.220]   Well, she has to at this point.
[00:29:41.220 --> 00:29:45.820]   She has to be the shield that somebody has to take the fall, right?
[00:29:45.820 --> 00:29:51.020]   And for the George Soros stuff for all of that, she's going to take the fall for that.
[00:29:51.020 --> 00:29:55.460]   They need to make a show of we're getting new blood in here.
[00:29:55.460 --> 00:29:57.220]   We're doing generational turnover.
[00:29:57.220 --> 00:29:59.020]   By the way, there is a connection.
[00:29:59.020 --> 00:30:05.660]   Sheryl Sandberg learned about Google and the way they use data when she worked at Google
[00:30:05.660 --> 00:30:07.700]   and she brought it to Facebook.
[00:30:07.700 --> 00:30:12.860]   She brought the flame from Hal Varian and carried the flame across the street to Facebook
[00:30:12.860 --> 00:30:15.700]   and said, "Look, fire."
[00:30:15.700 --> 00:30:16.700]   It's fire.
[00:30:16.700 --> 00:30:17.700]   It's fire.
[00:30:17.700 --> 00:30:21.700]   I do think she's likely to leave for whatever reason, however they frame it.
[00:30:21.700 --> 00:30:22.700]   Wow.
[00:30:22.700 --> 00:30:26.380]   Well, let's take a break because I want to talk about Mark Zuckerberg's Wall Street Journal
[00:30:26.380 --> 00:30:27.220]   editorial.
[00:30:27.220 --> 00:30:31.180]   There's a lot more to talk about.
[00:30:31.180 --> 00:30:33.420]   As you can see, a fiery panel today.
[00:30:33.420 --> 00:30:35.380]   It's usually when Greg Farro is here.
[00:30:35.380 --> 00:30:36.700]   He fires them up.
[00:30:36.700 --> 00:30:40.980]   Greg Farro from the Packet Pushers Network, Jason Heiner from CBS Interactive, Tech Republic.
[00:30:40.980 --> 00:30:50.140]   EIC there and Brian McCullough from Tech Memes Ride Home Podcast, Internet Historian.
[00:30:50.140 --> 00:30:51.500]   Our show today brought to you by you.
[00:30:51.500 --> 00:30:53.500]   We're talking about mattresses.
[00:30:53.500 --> 00:30:55.620]   Casper, Casper.
[00:30:55.620 --> 00:30:56.620]   We love our Casper.
[00:30:56.620 --> 00:30:59.900]   Casper is an online premium mattress retailer.
[00:30:59.900 --> 00:31:04.940]   They invented this whole idea of, "Well, this is where Silicon Valley really is good."
[00:31:04.940 --> 00:31:08.980]   They look for inefficiencies in markets.
[00:31:08.980 --> 00:31:11.500]   The guys who founded Casper said, "Look, this is crazy.
[00:31:11.500 --> 00:31:13.540]   A company makes a mattress."
[00:31:13.540 --> 00:31:19.860]   Then they sell it through a showroom that marks it up 100 percent or more to an end-user.
[00:31:19.860 --> 00:31:21.300]   This is crazy.
[00:31:21.300 --> 00:31:27.380]   We could sell direct and cut out the middleman and sell great mattresses for much less money.
[00:31:27.380 --> 00:31:31.700]   But then good thinkers that they are, they said, "Well, there's one little problem with
[00:31:31.700 --> 00:31:32.700]   that.
[00:31:32.700 --> 00:31:34.700]   People want to go to a showroom and lie on a mattress."
[00:31:34.700 --> 00:31:36.460]   Not that that's a good way to test a mattress.
[00:31:36.460 --> 00:31:37.460]   I could tell you.
[00:31:37.460 --> 00:31:43.640]   Many a mattress I've got to show them, laying on it, lied on it.
[00:31:43.640 --> 00:31:44.640]   What is it?
[00:31:44.640 --> 00:31:45.860]   Carson, you went to Harvard.
[00:31:45.860 --> 00:31:46.860]   Lay on it.
[00:31:46.860 --> 00:31:47.860]   Light.
[00:31:47.860 --> 00:31:48.860]   Lane.
[00:31:48.860 --> 00:31:49.860]   Lane on it.
[00:31:49.860 --> 00:31:50.860]   You laid on it.
[00:31:50.860 --> 00:31:51.860]   I laid on it.
[00:31:51.860 --> 00:31:55.220]   Chickens lay an egg, but people lie on mattresses.
[00:31:55.220 --> 00:32:01.780]   Anyway, whatever it is, I've gotten the wrong mattress more than once by doing that.
[00:32:01.780 --> 00:32:06.060]   What Casper said is, we're going to give you 100 days, or maybe it's better to say 100
[00:32:06.060 --> 00:32:07.660]   nights with this mattress.
[00:32:07.660 --> 00:32:10.860]   Anytime in the first 100 days, if it's not perfect, we will come and get it.
[00:32:10.860 --> 00:32:11.860]   We will take it away.
[00:32:11.860 --> 00:32:13.140]   We'll refund you every penny.
[00:32:13.140 --> 00:32:14.300]   That solved the problem.
[00:32:14.300 --> 00:32:19.220]   The original Casper mattress combines multiple supportive memory foams for a sleep surface
[00:32:19.220 --> 00:32:22.340]   with just the right sink, but also bounce.
[00:32:22.340 --> 00:32:23.820]   It's hard to describe.
[00:32:23.820 --> 00:32:27.540]   That's why you have to lie on it, or lay on it, or do whatever you do with it.
[00:32:27.540 --> 00:32:31.140]   Actually, I do both.
[00:32:31.140 --> 00:32:36.020]   It gives to your knobbly parts, but it's firmly supporting your back.
[00:32:36.020 --> 00:32:37.020]   Is that a way to describe it?
[00:32:37.020 --> 00:32:38.020]   I don't know.
[00:32:38.020 --> 00:32:39.020]   You have to try it.
[00:32:39.020 --> 00:32:41.700]   I really have to say this is true.
[00:32:41.700 --> 00:32:43.940]   It's breathable, which means you sleep cool.
[00:32:43.940 --> 00:32:49.100]   We know from sleep experts, sleeping cool is the key to a great night's sleep.
[00:32:49.100 --> 00:32:52.900]   You're going to get long-lasting support, long-lasting comfort from your mattress.
[00:32:52.900 --> 00:32:55.260]   You buy a completely risk-free online.
[00:32:55.260 --> 00:32:57.660]   Here's our Casper.
[00:32:57.660 --> 00:33:00.820]   This is our second Casper.
[00:33:00.820 --> 00:33:01.820]   We love it.
[00:33:01.820 --> 00:33:04.260]   It is an incredible mattress.
[00:33:04.260 --> 00:33:06.580]   They uphold the highest environmental production standards.
[00:33:06.580 --> 00:33:08.180]   They're made in the USA.
[00:33:08.180 --> 00:33:11.020]   They come in a surprisingly compact box, which is really great.
[00:33:11.020 --> 00:33:14.460]   We got one for my son's dorm room because he didn't like the mattress that was in the
[00:33:14.460 --> 00:33:17.500]   dorm for obvious reasons.
[00:33:17.500 --> 00:33:19.060]   He was able to schlep it upstairs.
[00:33:19.060 --> 00:33:20.060]   It's great.
[00:33:20.060 --> 00:33:21.220]   It was so affordable after four years.
[00:33:21.220 --> 00:33:22.700]   We said, "You can leave it there."
[00:33:22.700 --> 00:33:25.500]   We'll give you a new one when you get your apartment.
[00:33:25.500 --> 00:33:26.500]   Casper.
[00:33:26.500 --> 00:33:33.380]   Doesn't that make you want to just get a Casper mattress today?
[00:33:33.380 --> 00:33:36.500]   You can save $50 towards select mattresses when you go to Casper.
[00:33:36.500 --> 00:33:43.580]   C-A-S-P-E-R.com/twit and use a promo code TWIT at checkout-casper.com/twit.
[00:33:43.580 --> 00:33:48.020]   Promo code TWIT to save $50 on select mattresses in terms and conditions apply.
[00:33:48.020 --> 00:33:49.180]   Thank you, Casper.
[00:33:49.180 --> 00:33:55.700]   If I am well-rested, you can thank Casper.
[00:33:55.700 --> 00:33:59.100]   I'm relaxed.
[00:33:59.100 --> 00:34:01.860]   Greg will fire me up.
[00:34:01.860 --> 00:34:04.860]   I do have one topic I want to raise reasonably early if I may.
[00:34:04.860 --> 00:34:06.620]   This DNS thing, right?
[00:34:06.620 --> 00:34:08.540]   Yeah, DNS flag day.
[00:34:08.540 --> 00:34:09.620]   Let me try and preface this.
[00:34:09.620 --> 00:34:11.340]   This is going to get a little bit nerdy.
[00:34:11.340 --> 00:34:12.340]   Strap yourself in.
[00:34:12.340 --> 00:34:15.260]   I'll try and keep it short for the people who aren't related to that.
[00:34:15.260 --> 00:34:17.300]   This is the Internet Society.
[00:34:17.300 --> 00:34:22.580]   That is the body that is responsible for parts of the Internet, making a fairly substantial
[00:34:22.580 --> 00:34:24.500]   change to the way that DNS works.
[00:34:24.500 --> 00:34:28.060]   First of all, what's wrong with DNS?
[00:34:28.060 --> 00:34:29.540]   There's nothing wrong with DNS.
[00:34:29.540 --> 00:34:33.100]   Over the years, we've changed the standards from DNS to a thing called enhanced DNS or
[00:34:33.100 --> 00:34:34.100]   EDNS.
[00:34:34.100 --> 00:34:38.460]   The standard was done 7493, I think, from memory.
[00:34:38.460 --> 00:34:40.940]   It was done like 10 years ago.
[00:34:40.940 --> 00:34:48.220]   What they did was the original DNS had a maximum query size of 512 bytes in the packet.
[00:34:48.220 --> 00:34:49.540]   That was no longer big enough.
[00:34:49.540 --> 00:34:54.060]   When we went to Unicode, the data that was being jammed in the packet oversized the packet.
[00:34:54.060 --> 00:34:58.420]   We created a thing called enhanced DNS or extended DNS and that allowed for a larger
[00:34:58.420 --> 00:34:59.420]   packet size.
[00:34:59.420 --> 00:35:03.860]   Now, that was fine, but all of the DNS servers on the Internet, if you got a query from somebody
[00:35:03.860 --> 00:35:10.060]   who is using legacy DNS, they would tolerate your non-EDNS query and respond back to you
[00:35:10.060 --> 00:35:13.380]   and say, "Okay, we'll give you some time to do the transition."
[00:35:13.380 --> 00:35:17.620]   Let me talk down to you because you have our server that's stupid.
[00:35:17.620 --> 00:35:18.620]   Yeah.
[00:35:18.620 --> 00:35:19.620]   You know, V1, kind of like V1, V2.
[00:35:19.620 --> 00:35:23.940]   Are there a lot of people not using EDNS now?
[00:35:23.940 --> 00:35:24.940]   It's a very small number.
[00:35:24.940 --> 00:35:27.660]   It's like 2 to 5 percent.
[00:35:27.660 --> 00:35:32.100]   They've sort of got to the point saying, "Look, we can't move the DNS infrastructure on.
[00:35:32.100 --> 00:35:35.220]   We need to make changes to DNS, like DNS over HTTPS.
[00:35:35.220 --> 00:35:41.220]   We need to make changes to increase the security, but we can't unless everybody's at least
[00:35:41.220 --> 00:35:43.740]   gotten away from the technology from 30 years ago."
[00:35:43.740 --> 00:35:49.540]   They put a flag down and said on the 1st of February is DNS flag day, "We're going to
[00:35:49.540 --> 00:35:55.420]   start the new version of bind, which is what most people use will no longer support DNS
[00:35:55.420 --> 00:35:56.420]   only.
[00:35:56.420 --> 00:36:01.180]   If you make a query and you don't flag that I do not, so you've got to be able to support
[00:36:01.180 --> 00:36:05.180]   at least enough of the extensions to say, "I don't understand EDNS.
[00:36:05.180 --> 00:36:06.580]   Give me a DNS response."
[00:36:06.580 --> 00:36:11.060]   If you make an invalid or a legacy query, these servers will no longer respond.
[00:36:11.060 --> 00:36:15.060]   It's going to be a bit like a link rot thing we used to have years ago.
[00:36:15.060 --> 00:36:19.020]   They used to worry about what happens when all of these shorteners used to disappear
[00:36:19.020 --> 00:36:21.540]   and then all these links would be dead.
[00:36:21.540 --> 00:36:25.180]   Some people are going to not be able to access some things.
[00:36:25.180 --> 00:36:28.300]   If you own a domain, get out there and start running a test.
[00:36:28.300 --> 00:36:31.900]   Go to dnsflagday.com and put your domain in and find out if it's going to pass the
[00:36:31.900 --> 00:36:33.540]   test.
[00:36:33.540 --> 00:36:34.700]   You don't have to rush it.
[00:36:34.700 --> 00:36:36.620]   It's not an apocalyptic thing.
[00:36:36.620 --> 00:36:40.220]   It's just something that's going to start having an impact as some users won't be able
[00:36:40.220 --> 00:36:41.220]   to work.
[00:36:41.220 --> 00:36:46.660]   It's mostly going to be companies who implement firewall appliances because a lot of the firewalls
[00:36:46.660 --> 00:36:50.780]   have these proxies and the DNS queries come in and then they go out.
[00:36:50.780 --> 00:36:54.980]   If those haven't been kept up to date, there's a fed bet that they're where the problem is.
[00:36:54.980 --> 00:36:57.700]   It's dnsflagday.net, by the way.
[00:36:57.700 --> 00:36:58.700]   Sorry.
[00:36:58.700 --> 00:37:00.460]   My apologies.
[00:37:00.460 --> 00:37:03.700]   This doesn't affect home users and users at all.
[00:37:03.700 --> 00:37:14.140]   If you have Twitter.tv, if you have a domain, you should make sure that it works.
[00:37:14.140 --> 00:37:15.140]   It does.
[00:37:15.140 --> 00:37:16.140]   I'm okay.
[00:37:16.140 --> 00:37:17.140]   I'm fine.
[00:37:17.140 --> 00:37:18.140]   Mine don't.
[00:37:18.140 --> 00:37:19.140]   I'm having a problem with hover.com.
[00:37:19.140 --> 00:37:20.140]   Really?
[00:37:20.140 --> 00:37:21.140]   They're updating.
[00:37:21.140 --> 00:37:28.460]   If you test gregfero.com, which is my personal blog site, all my others are hosted at CloudFlare.
[00:37:28.460 --> 00:37:29.460]   But hover.
[00:37:29.460 --> 00:37:30.460]   I do everything in hover.
[00:37:30.460 --> 00:37:31.460]   I'm going to try to.
[00:37:31.460 --> 00:37:36.500]   They're not compliant and they will be.
[00:37:36.500 --> 00:37:39.380]   So this is like yours.
[00:37:39.380 --> 00:37:40.140]   This is at hover.
[00:37:40.140 --> 00:37:41.140]   Leoloport.com.
[00:37:41.140 --> 00:37:43.100]   It's so this to be clear.
[00:37:43.100 --> 00:37:45.020]   It's hosted at WordPress.com.
[00:37:45.020 --> 00:37:47.820]   The DNS goes through hover.
[00:37:47.820 --> 00:37:48.820]   That's right.
[00:37:48.820 --> 00:37:55.420]   Now it's going to work because they do support the EDNS query and respond with legacy DNS
[00:37:55.420 --> 00:37:56.420]   answers.
[00:37:56.420 --> 00:37:58.380]   So they're not broken.
[00:37:58.380 --> 00:38:00.140]   As it says there, you're going to work.
[00:38:00.140 --> 00:38:02.940]   But hi, contact at hover and they said, "We're not going to fix it."
[00:38:02.940 --> 00:38:04.380]   And if you don't like it, leave.
[00:38:04.380 --> 00:38:05.380]   Why not?
[00:38:05.380 --> 00:38:07.500]   Hey, I don't know.
[00:38:07.500 --> 00:38:11.020]   I believe that hover might be in a rent extraction mode.
[00:38:11.020 --> 00:38:14.860]   So the original company that it was a couple of years ago, which was really innovative
[00:38:14.860 --> 00:38:16.380]   and really doing good things.
[00:38:16.380 --> 00:38:20.300]   It would seem that whoever's running the business now just wants to haul all the profit they
[00:38:20.300 --> 00:38:22.020]   can out of it and do nothing.
[00:38:22.020 --> 00:38:24.220]   It's here because all of our--
[00:38:24.220 --> 00:38:25.220]   Screw them.
[00:38:25.220 --> 00:38:27.100]   They were-- I don't know if there's still a sponsor.
[00:38:27.100 --> 00:38:28.100]   I think they might be.
[00:38:28.100 --> 00:38:35.780]   But regardless, all of my domains, all of our domains are through hover.
[00:38:35.780 --> 00:38:39.180]   I thought Twitter.tv is as well, I believe.
[00:38:39.180 --> 00:38:40.180]   Yeah.
[00:38:40.180 --> 00:38:43.940]   Just because if you're using them as a registrar, but you've got your DNS somewhere else.
[00:38:43.940 --> 00:38:44.940]   So for example--
[00:38:44.940 --> 00:38:45.940]   It must be we have the DNS somewhere else.
[00:38:45.940 --> 00:38:46.940]   Yes.
[00:38:46.940 --> 00:38:51.980]   I have all of my domains registered at-- or most of my domains at hover, but my DNS is
[00:38:51.980 --> 00:38:53.540]   most often hosted at Cloud Player.
[00:38:53.540 --> 00:38:59.020]   So I'll start migrating my domains away to Cloud Player in the next few weeks.
[00:38:59.020 --> 00:39:01.020]   Just because their response was so bad.
[00:39:01.020 --> 00:39:02.980]   It was basically like, "So what?
[00:39:02.980 --> 00:39:03.980]   We're not fixing it.
[00:39:03.980 --> 00:39:05.420]   And if you don't like it, go."
[00:39:05.420 --> 00:39:06.420]   Literally.
[00:39:06.420 --> 00:39:07.820]   That's the-- I can send you a screenshot.
[00:39:07.820 --> 00:39:08.820]   It's pretty amazing.
[00:39:08.820 --> 00:39:09.820]   Wow.
[00:39:09.820 --> 00:39:10.820]   Well, it's a good takeaway.
[00:39:10.820 --> 00:39:12.820]   You've got your domains there.
[00:39:12.820 --> 00:39:14.420]   Seriously, think about moving them.
[00:39:14.420 --> 00:39:15.940]   Well, hover is still a sponsor.
[00:39:15.940 --> 00:39:18.700]   So I'm going to-- I think I have maybe some in there.
[00:39:18.700 --> 00:39:21.820]   We'll try to get them to change that point of view.
[00:39:21.820 --> 00:39:22.820]   Sorry, I didn't mean to-- I got--
[00:39:22.820 --> 00:39:23.820]   No, that's terrible.
[00:39:23.820 --> 00:39:27.420]   --I was quite-- I was quite-- I was quite puffed with his support query.
[00:39:27.420 --> 00:39:28.420]   He was quite done.
[00:39:28.420 --> 00:39:31.500]   Well, maybe you got some-- maybe somebody had a bad day.
[00:39:31.500 --> 00:39:32.500]   And it just--
[00:39:32.500 --> 00:39:33.500]   Maybe.
[00:39:33.500 --> 00:39:34.500]   Yeah.
[00:39:34.500 --> 00:39:35.500]   I bet you.
[00:39:35.500 --> 00:39:37.300]   I'm going to make a promise to you that they're going to face that.
[00:39:37.300 --> 00:39:38.300]   [LAUGHTER]
[00:39:38.300 --> 00:39:40.500]   Now, this doesn't have anything to do with DNS security,
[00:39:40.500 --> 00:39:42.180]   which is another issue entirely, right?
[00:39:42.180 --> 00:39:43.460]   No, DNS sec is quite different.
[00:39:43.460 --> 00:39:46.900]   I think DNS sec will likely never get traction.
[00:39:46.900 --> 00:39:49.940]   So DNS security is where we actually encrypt the client
[00:39:49.940 --> 00:39:52.540]   and the server accessing cryptocessions between them
[00:39:52.540 --> 00:39:55.100]   using a form of public cryptography.
[00:39:55.100 --> 00:39:59.420]   I suspect that we'll see DNS over HTTPS before DNS sec ever
[00:39:59.420 --> 00:40:01.060]   gets traction.
[00:40:01.060 --> 00:40:04.100]   So the idea of using DNS--
[00:40:04.100 --> 00:40:07.260]   or UDP and having its own protocol will probably fade away.
[00:40:07.260 --> 00:40:11.300]   In fact, I actually use a thing on my iPhone.
[00:40:11.300 --> 00:40:15.500]   I use an app, which lets me use DNS over HTTPS.
[00:40:15.500 --> 00:40:16.940]   Quad1, send love it.
[00:40:16.940 --> 00:40:18.460]   1.1.1.1.1.1.
[00:40:18.460 --> 00:40:19.460]   Yeah.
[00:40:19.460 --> 00:40:24.460]   And this actually stops when you're at a cafe or something like that.
[00:40:24.460 --> 00:40:27.220]   People can't intercept your DNS queries
[00:40:27.220 --> 00:40:29.300]   and use those for data and analytics.
[00:40:29.300 --> 00:40:31.100]   And then you can't do that.
[00:40:31.100 --> 00:40:34.300]   Accept your DNS queries and use those for data and analytics.
[00:40:34.300 --> 00:40:37.100]   And I'm just-- I'm a bit privacy-free-keep myself.
[00:40:37.100 --> 00:40:39.300]   So that scratches my personal itch.
[00:40:39.300 --> 00:40:42.380]   In some cases, my DNS is--
[00:40:42.380 --> 00:40:45.060]   in fact, leo-report.com, I think does not
[00:40:45.060 --> 00:40:48.340]   go through Hover, it goes through Fastmail, my email
[00:40:48.340 --> 00:40:48.860]   providers.
[00:40:48.860 --> 00:40:51.460]   So I think maybe Fastmail needs to work on this too.
[00:40:51.460 --> 00:40:53.980]   In their defense, in both Hover's defense and Fastmail's
[00:40:53.980 --> 00:40:55.740]   defense, it's not that it doesn't work.
[00:40:55.740 --> 00:40:58.940]   It's just not fully compliant.
[00:40:58.940 --> 00:41:00.260]   So that needs to be fixed.
[00:41:00.260 --> 00:41:04.860]   Is there going to be a flag day for full compliance?
[00:41:04.860 --> 00:41:06.060]   It'll just be a rot thing.
[00:41:06.060 --> 00:41:08.940]   So over time, if the root servers stop responding
[00:41:08.940 --> 00:41:13.500]   to legacy queries, then eventually things just stop working.
[00:41:13.500 --> 00:41:15.060]   And that's the only way we can move forward.
[00:41:15.060 --> 00:41:17.580]   They've been agonizing over it for some years.
[00:41:17.580 --> 00:41:20.260]   And they've basically realized that there are things we have
[00:41:20.260 --> 00:41:22.860]   to do with DNS to move forward.
[00:41:22.860 --> 00:41:25.500]   And we have to get to the point where we say, right?
[00:41:25.500 --> 00:41:26.980]   And they've been carefully--
[00:41:26.980 --> 00:41:27.900]   this is all explained.
[00:41:27.900 --> 00:41:29.140]   If you go to the blog post, there's
[00:41:29.140 --> 00:41:32.100]   all the data is there, pointing you to source material,
[00:41:32.100 --> 00:41:33.620]   explaining the whole thing in detail.
[00:41:33.620 --> 00:41:36.020]   So we can just check your domains.
[00:41:36.020 --> 00:41:37.780]   You want to understand more, hit the blog post,
[00:41:37.780 --> 00:41:39.020]   go to DNS flagday.net.
[00:41:39.020 --> 00:41:41.020]   There's lots of information.
[00:41:41.020 --> 00:41:42.780]   And take some time to learn about it,
[00:41:42.780 --> 00:41:44.140]   if that's the thing that you need to know about it.
[00:41:44.140 --> 00:41:46.300]   Hover's primary business is as a registrar.
[00:41:46.300 --> 00:41:48.460]   So I don't know if I'll move off of Hover.
[00:41:48.460 --> 00:41:51.460]   I'll just move my DNS somewhere else, right?
[00:41:51.460 --> 00:41:53.460]   Yeah, I think the chat room is saying too, right?
[00:41:53.460 --> 00:41:55.780]   You could also-- because a lot of people's chat room
[00:41:55.780 --> 00:41:57.860]   said that they've actually had great experiences with--
[00:41:57.860 --> 00:41:59.300]   they're great registrar to do that.
[00:41:59.300 --> 00:42:00.740]   I've never used them.
[00:42:00.740 --> 00:42:05.260]   But they said yes, they keep their DNS other places.
[00:42:05.260 --> 00:42:09.460]   And as I said, Fastmail, which also can do DNS.
[00:42:09.460 --> 00:42:13.260]   And so some of my domains are DNS,
[00:42:13.260 --> 00:42:17.060]   including leoloport.com, for mail reasons, I think,
[00:42:17.060 --> 00:42:18.740]   are hosted at Hover.
[00:42:18.740 --> 00:42:21.260]   And they also show up as a problem.
[00:42:21.260 --> 00:42:24.820]   So I think-- let me try some other ones.
[00:42:24.820 --> 00:42:28.020]   So that's an interesting issue.
[00:42:28.020 --> 00:42:28.740]   Yeah.
[00:42:28.740 --> 00:42:30.100]   And it's not an apocalypse.
[00:42:30.100 --> 00:42:32.860]   So don't-- but it is something that will--
[00:42:32.860 --> 00:42:35.860]   Well, it would be if you were on such an old server
[00:42:35.860 --> 00:42:38.860]   that it didn't support at least some of those extensions,
[00:42:38.860 --> 00:42:40.100]   right?
[00:42:40.100 --> 00:42:42.020]   Yep.
[00:42:42.020 --> 00:42:45.260]   If people want a recommendation that I can recommend CloudFlare,
[00:42:45.260 --> 00:42:47.060]   they are actually charging you exactly what cost they are.
[00:42:47.060 --> 00:42:48.980]   They started doing domain service.
[00:42:48.980 --> 00:42:49.780]   Yeah.
[00:42:49.780 --> 00:42:52.020]   Can everybody-- I think you have to be a customer now.
[00:42:52.020 --> 00:42:54.780]   They're not yet open to the public, are they?
[00:42:54.780 --> 00:42:56.220]   I think you have to be a customer.
[00:42:56.220 --> 00:42:57.140]   No.
[00:42:57.140 --> 00:42:57.820]   No.
[00:42:57.820 --> 00:42:58.860]   I'm checking here now.
[00:42:58.860 --> 00:43:00.060]   And it's-- yes.
[00:43:00.060 --> 00:43:00.660]   OK.
[00:43:00.660 --> 00:43:04.100]   When they first announced their domain name service,
[00:43:04.100 --> 00:43:06.580]   they said it's going to be for-- now, by the way,
[00:43:06.580 --> 00:43:10.300]   you could be a customer for free.
[00:43:10.300 --> 00:43:12.060]   So OK, good.
[00:43:12.060 --> 00:43:15.500]   So now you don't even have to have a CloudFlare account.
[00:43:15.500 --> 00:43:17.300]   Yeah, it says early access.
[00:43:17.300 --> 00:43:19.420]   We'll be rolling out access to CloudFlare register
[00:43:19.420 --> 00:43:21.660]   on stages based on factors like how long
[00:43:21.660 --> 00:43:23.700]   you've been a CloudFlare customer.
[00:43:23.700 --> 00:43:25.660]   So it's not going to be available.
[00:43:25.660 --> 00:43:27.860]   This will be eventually a publicly available--
[00:43:27.860 --> 00:43:29.100]   It's super cheap, too.
[00:43:29.100 --> 00:43:31.380]   They're charging you the wholesale cost.
[00:43:31.380 --> 00:43:35.060]   So I'm looking at my etherealmind.com domain.
[00:43:35.060 --> 00:43:37.140]   What a chance to plug the hell out of that, hey?
[00:43:37.140 --> 00:43:38.700]   It's $7.85.
[00:43:38.700 --> 00:43:39.060]   That's great.
[00:43:39.060 --> 00:43:40.460]   That's half the price of hover.
[00:43:40.460 --> 00:43:45.660]   Yeah, domains are cheap, because they don't do anything else.
[00:43:45.660 --> 00:43:47.700]   Well, it's just a script.
[00:43:47.700 --> 00:43:52.540]   Speaking of bad guys, GoDaddy has had a little bit of a slap
[00:43:52.540 --> 00:43:53.180]   in the face.
[00:43:53.180 --> 00:43:56.620]   GoDaddy's poorly designed security.
[00:43:56.620 --> 00:43:58.420]   Actually, you're going to have to explain this.
[00:43:58.420 --> 00:44:01.460]   I think Greg, you could explain this to me.
[00:44:01.460 --> 00:44:06.940]   Has allowed Spammers to use well-known domains registered
[00:44:06.940 --> 00:44:12.580]   on GoDaddy to put out that as extortion spam.
[00:44:12.580 --> 00:44:13.380]   Did you get that one?
[00:44:13.380 --> 00:44:15.780]   Where you got an email saying, I know your password.
[00:44:15.780 --> 00:44:20.020]   It's-- and by the way, I've recorded you on a porn site.
[00:44:20.020 --> 00:44:21.380]   You might want to send me money, or I'm
[00:44:21.380 --> 00:44:22.740]   going to give this to all your friends.
[00:44:22.740 --> 00:44:23.260]   That's the one.
[00:44:23.260 --> 00:44:25.020]   I got those twice in the last month.
[00:44:25.020 --> 00:44:27.340]   Yeah, by the way, it scared me, because it was a password
[00:44:27.340 --> 00:44:28.500]   I had used many years ago.
[00:44:28.500 --> 00:44:29.020]   Oh, yeah.
[00:44:29.020 --> 00:44:30.260]   Oh, yeah.
[00:44:30.260 --> 00:44:32.260]   So that's due to a flaw in GoDaddy,
[00:44:32.260 --> 00:44:35.100]   and Brian Krebs discovered this one.
[00:44:35.100 --> 00:44:37.860]   I think the takeaway here is based on the evidence
[00:44:37.860 --> 00:44:39.700]   of the last five to 10 years, you
[00:44:39.700 --> 00:44:41.340]   shouldn't be doing business with GoDaddy.
[00:44:41.340 --> 00:44:43.540]   There are a bunch of hopeless losers.
[00:44:43.540 --> 00:44:45.460]   I mean, we've just seen them do everything wrong,
[00:44:45.460 --> 00:44:49.020]   consistently, repeatedly, over and over and over.
[00:44:49.020 --> 00:44:50.700]   At this point, why are they still in business?
[00:44:50.700 --> 00:44:51.780]   Are people stupid?
[00:44:51.780 --> 00:44:52.620]   Yeah.
[00:44:52.620 --> 00:44:57.060]   In fact, this flaw, this vulnerability,
[00:44:57.060 --> 00:45:02.620]   was first written about in 2016 by Matthew Bryant.
[00:45:02.620 --> 00:45:05.460]   And it basically allows somebody who
[00:45:05.460 --> 00:45:08.860]   has a GoDaddy account on the same domain name server
[00:45:08.860 --> 00:45:13.700]   as a big company to send email out
[00:45:13.700 --> 00:45:16.020]   from that big company's IP address,
[00:45:16.020 --> 00:45:18.820]   thereby bypassing a lot of spam filters, which look
[00:45:18.820 --> 00:45:21.260]   at IP addresses to see a large block.
[00:45:21.260 --> 00:45:22.060]   Bad stuff.
[00:45:22.060 --> 00:45:24.180]   Bad stuff.
[00:45:24.180 --> 00:45:26.340]   So I don't know if GoDaddy's fixed that,
[00:45:26.340 --> 00:45:27.580]   but that is--
[00:45:27.580 --> 00:45:30.300]   it first came to a light because somebody
[00:45:30.300 --> 00:45:34.180]   mailed a bomb threat from virtualfirefox.com, which
[00:45:34.180 --> 00:45:37.780]   is a Mozilla Foundation domain.
[00:45:37.780 --> 00:45:38.140]   Yeah.
[00:45:38.140 --> 00:45:41.580]   I just would strongly recommend that people do not ever
[00:45:41.580 --> 00:45:42.340]   use GoDaddy.
[00:45:42.340 --> 00:45:46.700]   They are proven to be the least reputable internet provider,
[00:45:46.700 --> 00:45:49.100]   probably, of any great size.
[00:45:49.100 --> 00:45:51.660]   And we've had so many stories with them over the years.
[00:45:51.660 --> 00:45:53.260]   Why are we still doing this?
[00:45:53.260 --> 00:46:03.540]   Confirmation that Dr. Hu, Hu Zhang Kui, did in fact--
[00:46:03.540 --> 00:46:07.020]   China has confirmed, used CRISPR to gene edit babies.
[00:46:07.020 --> 00:46:09.380]   Those babies were born.
[00:46:09.380 --> 00:46:14.780]   And China says he forged ethical review papers,
[00:46:14.780 --> 00:46:17.420]   recruited eight couples to participate in his experiment,
[00:46:17.420 --> 00:46:19.340]   resulting in two pregnancies.
[00:46:19.340 --> 00:46:22.420]   One of the mothers gave birth to twins nicknamed Lulu and Nana.
[00:46:22.420 --> 00:46:25.700]   These are the first, as far as we know, humans born
[00:46:25.700 --> 00:46:28.700]   with their genes CRISPR edited.
[00:46:28.700 --> 00:46:33.460]   He had removed a gene that supposedly would give these
[00:46:33.460 --> 00:46:39.340]   children better resistance to HIV and other diseases, smallpox,
[00:46:39.340 --> 00:46:41.020]   I think.
[00:46:41.020 --> 00:46:42.900]   But the problem with CRISPR gene editing
[00:46:42.900 --> 00:46:45.620]   is the side effects are unknown.
[00:46:45.620 --> 00:46:46.140]   Yeah.
[00:46:46.140 --> 00:46:48.740]   And while people have done this in the lab to rats and other things,
[00:46:48.740 --> 00:46:50.580]   this is the first time we know of this.
[00:46:50.580 --> 00:46:51.580]   And this was a big story.
[00:46:51.580 --> 00:46:53.500]   When we talked about this, it was unclear
[00:46:53.500 --> 00:46:54.780]   whether it really happened.
[00:46:54.780 --> 00:46:56.220]   But now that we know it's really happened,
[00:46:56.220 --> 00:46:59.060]   I think this is a watershed moment.
[00:46:59.060 --> 00:46:59.420]   Yeah.
[00:46:59.420 --> 00:47:03.580]   CRISPR is likely to be one of the biggest breakthrough
[00:47:03.580 --> 00:47:05.340]   technologies of this century.
[00:47:05.340 --> 00:47:07.620]   When we get to the end of the century, we look back.
[00:47:07.620 --> 00:47:11.980]   It is likely to be one of the big ones.
[00:47:11.980 --> 00:47:17.700]   Moving too fast in this area is fraught with all kinds of risks
[00:47:17.700 --> 00:47:23.380]   and dangers that it just doesn't feel like we should be moving
[00:47:23.380 --> 00:47:24.100]   that quickly.
[00:47:24.100 --> 00:47:26.860]   There should be a lot more research.
[00:47:26.860 --> 00:47:32.060]   There should be a lot more things done in labs before we
[00:47:32.060 --> 00:47:33.380]   put this in human beings.
[00:47:33.380 --> 00:47:35.020]   So that's the scary part.
[00:47:35.020 --> 00:47:38.580]   And that's why I think the scientific world is really
[00:47:38.580 --> 00:47:41.700]   cringing and has been cringing about this.
[00:47:41.700 --> 00:47:45.300]   And why they haven't supported, obviously, the work of--
[00:47:45.300 --> 00:47:48.660]   Every nation has laws against this.
[00:47:48.660 --> 00:47:50.700]   I mean, everybody agrees.
[00:47:50.700 --> 00:47:54.020]   This is not the time to start doing this, although once
[00:47:54.020 --> 00:47:56.180]   the genie's out of the bottle--
[00:47:56.180 --> 00:47:56.900]   Well, don't you think--
[00:47:56.900 --> 00:47:57.900]   Stop.
[00:47:57.900 --> 00:47:59.300]   --not to be too, too cynical about it.
[00:47:59.300 --> 00:48:02.420]   But part of it is, like some of the articles that I've read,
[00:48:02.420 --> 00:48:07.300]   like people are suggesting that this guy did this on his own,
[00:48:07.300 --> 00:48:08.940]   was going to promote himself.
[00:48:08.940 --> 00:48:11.620]   And so not to be overly cynical.
[00:48:11.620 --> 00:48:17.180]   But if China was the first to make some sort of CRISPR breakthrough,
[00:48:17.180 --> 00:48:19.380]   I feel like that they would have gotten behind it
[00:48:19.380 --> 00:48:22.900]   and look at how Chinese technology and medicine is--
[00:48:22.900 --> 00:48:25.380]   So I'm wondering if the problem here is
[00:48:25.380 --> 00:48:28.740]   that this guy was sort of a lone wolf that
[00:48:28.740 --> 00:48:30.620]   was trying to be a little too promotional.
[00:48:30.620 --> 00:48:35.380]   Because if he wasn't and there was real legitimate breakthroughs,
[00:48:35.380 --> 00:48:36.900]   I don't feel like China would be throwing him
[00:48:36.900 --> 00:48:37.860]   under the bus like this.
[00:48:37.860 --> 00:48:39.460]   Yeah.
[00:48:39.460 --> 00:48:40.460]   I'm not sure.
[00:48:40.460 --> 00:48:41.460]   I think there's two things--
[00:48:41.460 --> 00:48:43.020]   He's disappeared from sight.
[00:48:43.020 --> 00:48:45.660]   I think there's two things here that we aren't considering.
[00:48:45.660 --> 00:48:48.660]   One is that the current research indicates
[00:48:48.660 --> 00:48:50.580]   that the use of the CRISPR technology is actually
[00:48:50.580 --> 00:48:53.260]   incredibly damaging to the genes themselves.
[00:48:53.260 --> 00:48:58.460]   So not only are you using CRISPR to target specific genes,
[00:48:58.460 --> 00:48:59.940]   but what's coming out as the evidence
[00:48:59.940 --> 00:49:03.020]   is that CRISPR is actually damaging entire gene structures.
[00:49:03.020 --> 00:49:05.420]   So you may actually be causing more genetic defects
[00:49:05.420 --> 00:49:06.820]   than you're actually fixing.
[00:49:06.820 --> 00:49:09.940]   And so this is the reverse side of a breakthrough.
[00:49:09.940 --> 00:49:11.820]   The reality starts to set in that there
[00:49:11.820 --> 00:49:13.420]   might be some downsides.
[00:49:13.420 --> 00:49:16.140]   The children are not being identified by the Chinese government,
[00:49:16.140 --> 00:49:17.420]   but the Chinese government says we
[00:49:17.420 --> 00:49:19.420]   are going to monitor them because there
[00:49:19.420 --> 00:49:20.980]   is some concern about their long-term health.
[00:49:20.980 --> 00:49:21.980]   Well, it's a great feeling to be close.
[00:49:21.980 --> 00:49:25.060]   Remember when Dolly, the sheep was the first cloned animal,
[00:49:25.060 --> 00:49:27.300]   these cloned sheep died very quickly
[00:49:27.300 --> 00:49:29.460]   because it turned out not only were they cloning the sheep,
[00:49:29.460 --> 00:49:32.220]   they were cloning their biological clock.
[00:49:32.220 --> 00:49:33.220]   Yeah.
[00:49:33.220 --> 00:49:36.580]   So the senescence was actually cloned at the same time.
[00:49:36.580 --> 00:49:38.900]   I think the challenge here with the CRISPR stuff
[00:49:38.900 --> 00:49:41.020]   is they're actually attacking the germline.
[00:49:41.020 --> 00:49:43.860]   So what that means is if those children have genetic defects,
[00:49:43.860 --> 00:49:48.500]   they'll carry through into the children of those babies.
[00:49:48.500 --> 00:49:51.140]   And so they replicate down through the years.
[00:49:51.140 --> 00:49:54.500]   And we don't want a situation, perhaps,
[00:49:54.500 --> 00:49:58.620]   where uncontrolled use of CRISPR, that is actually
[00:49:58.620 --> 00:50:02.500]   damaging to the germline, then gets fed into the gene pill.
[00:50:02.500 --> 00:50:06.340]   That is theoretically the end of the world-type scenario.
[00:50:06.340 --> 00:50:08.940]   So science wants to be careful about this.
[00:50:08.940 --> 00:50:13.660]   On the other hand, if any country is going to do it,
[00:50:13.660 --> 00:50:16.020]   you'd think it'd be the first would be the Chinese.
[00:50:16.020 --> 00:50:17.620]   I guess that was your point, Jason, right?
[00:50:17.620 --> 00:50:18.540]   Is that--
[00:50:18.540 --> 00:50:22.900]   There's also so many issues.
[00:50:22.900 --> 00:50:24.700]   I mean, it's not even the side effects.
[00:50:24.700 --> 00:50:27.900]   Let's say you could do it effectively without side effects.
[00:50:27.900 --> 00:50:31.340]   Then that raises a whole slew of other problems.
[00:50:31.340 --> 00:50:34.340]   Will it only be available to those who can afford it?
[00:50:34.340 --> 00:50:35.940]   Will billionaires become--
[00:50:35.940 --> 00:50:37.940]   Yeah, well, billionaires become a new species
[00:50:37.940 --> 00:50:40.740]   because they can afford to have children that are smarter,
[00:50:40.740 --> 00:50:45.740]   faster, better, more good-looking than everybody else?
[00:50:45.740 --> 00:50:47.780]   It's amazing how much science fiction, of course,
[00:50:47.780 --> 00:50:49.620]   has dealt with it, has been dealing with these issues
[00:50:49.620 --> 00:50:51.460]   for so long.
[00:50:51.460 --> 00:50:56.460]   I remember in Deep Space Nine in "Stars Trek, Deep Space Nine,"
[00:50:56.460 --> 00:50:59.620]   where they remember the doctor.
[00:50:59.620 --> 00:51:01.940]   It came out about halfway through the series
[00:51:01.940 --> 00:51:04.380]   that he was genetically manipulated.
[00:51:04.380 --> 00:51:08.180]   He was an underperformer, and he had this genetic manipulation
[00:51:08.180 --> 00:51:11.380]   and turned him into this brainiac.
[00:51:11.380 --> 00:51:13.220]   And then, of course, Jurassic Park,
[00:51:13.220 --> 00:51:15.740]   it was like, you're so busy trying
[00:51:15.740 --> 00:51:17.540]   to figure out if you could that you didn't stop
[00:51:17.540 --> 00:51:19.340]   to think if you should, which, of course,
[00:51:19.340 --> 00:51:22.580]   that was all about gene manipulation and diet--
[00:51:22.580 --> 00:51:24.140]   On the other hand--
[00:51:24.140 --> 00:51:26.940]   I mean, if you could do it--
[00:51:26.940 --> 00:51:30.460]   I mean, if these kids were successfully CRISPR-edited
[00:51:30.460 --> 00:51:35.460]   to be resistant to diseases, that's a good thing, right?
[00:51:35.460 --> 00:51:39.140]   Oh, I mean, the potential of this is amazing.
[00:51:39.140 --> 00:51:42.460]   No, I don't think anybody would argue with the fact
[00:51:42.460 --> 00:51:47.740]   that being able to get rid of diseases,
[00:51:47.740 --> 00:51:49.340]   be able to protect against diseases,
[00:51:49.340 --> 00:51:55.500]   be able to do all kinds of things that are mind-blowing,
[00:51:55.500 --> 00:51:57.260]   really.
[00:51:57.260 --> 00:51:59.460]   The potential is fantastic.
[00:51:59.460 --> 00:52:02.100]   But moving too fast in something like this
[00:52:02.100 --> 00:52:04.580]   is fraught with so much risk and so much error.
[00:52:04.580 --> 00:52:06.980]   I don't know if there's any speed with which you can move,
[00:52:06.980 --> 00:52:11.340]   because we just don't have mechanisms to even think about this.
[00:52:11.340 --> 00:52:15.100]   Or to-- I mean, I'm not talking about the legitimate issues
[00:52:15.100 --> 00:52:17.060]   that you raised, Greg, of whether it works
[00:52:17.060 --> 00:52:19.580]   and whether it causes problems, but the ethical issues
[00:52:19.580 --> 00:52:24.980]   in just modifying genes, we don't have any mechanism for this.
[00:52:24.980 --> 00:52:25.980]   It's fine.
[00:52:25.980 --> 00:52:29.100]   Congress can't even figure out whether we should build a wall.
[00:52:29.100 --> 00:52:30.700]   Forget it.
[00:52:30.700 --> 00:52:33.860]   I mean, this seems so beyond our capabilities
[00:52:33.860 --> 00:52:35.500]   and our understanding.
[00:52:35.500 --> 00:52:37.420]   Like we have autonomous cars on the road,
[00:52:37.420 --> 00:52:41.980]   and the risk of coincidental death or accidental death exists.
[00:52:41.980 --> 00:52:44.820]   But imagine if you could put an autonomous car on the road
[00:52:44.820 --> 00:52:47.260]   that would run now for the next 500 years,
[00:52:47.260 --> 00:52:49.340]   and you couldn't take it off.
[00:52:49.340 --> 00:52:50.820]   That's the sort of thing that you--
[00:52:50.820 --> 00:52:51.740]   Huh?
[00:52:51.740 --> 00:52:52.900]   History hat.
[00:52:52.900 --> 00:52:54.100]   History hat.
[00:52:54.100 --> 00:52:58.460]   Do you want to know the only reason that atomic energy
[00:52:58.460 --> 00:53:01.260]   was able to be regulated by the US government
[00:53:01.260 --> 00:53:02.940]   was because when they developed the bomb,
[00:53:02.940 --> 00:53:04.460]   it was during wartime.
[00:53:04.460 --> 00:53:07.740]   And so the president had special wartime powers too.
[00:53:07.740 --> 00:53:09.820]   So the whole fact that the entire--
[00:53:09.820 --> 00:53:12.300]   like atomic energy is an entire industry,
[00:53:12.300 --> 00:53:15.260]   but it's entirely regulated and controlled by the US government
[00:53:15.260 --> 00:53:17.620]   because it was during wartime and the president had wartime
[00:53:17.620 --> 00:53:19.580]   powers to make that happen.
[00:53:19.580 --> 00:53:22.700]   Had it been developed by private industry
[00:53:22.700 --> 00:53:24.900]   to be a completely different issue?
[00:53:24.900 --> 00:53:25.220]   Yeah.
[00:53:25.220 --> 00:53:26.220]   Would you know--
[00:53:26.220 --> 00:53:26.700]   It's a related day.
[00:53:26.700 --> 00:53:27.380]   Probably not.
[00:53:27.380 --> 00:53:28.940]   Actually, I agree with you that you are--
[00:53:28.940 --> 00:53:32.540]   I think you're right, but if it wasn't at that point in time,
[00:53:32.540 --> 00:53:33.780]   all of the governments of the world
[00:53:33.780 --> 00:53:36.980]   united to agree that nuclear power had to be controlled
[00:53:36.980 --> 00:53:37.780]   because of the risk.
[00:53:37.780 --> 00:53:39.740]   So I used to work for--
[00:53:39.740 --> 00:53:40.580]   Here's the difference.
[00:53:40.580 --> 00:53:41.580]   The industry has to go forward.
[00:53:41.580 --> 00:53:42.180]   Here's the difference.
[00:53:42.180 --> 00:53:45.340]   It's still very hard, as Kim Jong Un will tell you,
[00:53:45.340 --> 00:53:46.900]   to create an atomic bomb.
[00:53:46.900 --> 00:53:49.220]   It takes a lot of skill, a lot of expertise,
[00:53:49.220 --> 00:53:51.340]   and a lot of tests.
[00:53:51.340 --> 00:53:54.140]   It turns out, CRISPR is something you could pretty much
[00:53:54.140 --> 00:53:55.780]   do in your basement.
[00:53:55.780 --> 00:53:56.700]   Yeah.
[00:53:56.700 --> 00:53:59.180]   It's not that hard.
[00:53:59.180 --> 00:53:59.620]   Yes.
[00:53:59.620 --> 00:54:01.980]   And that's the real problem here,
[00:54:01.980 --> 00:54:04.140]   is that this technology, whether it was developed
[00:54:04.140 --> 00:54:08.620]   by a government or private labs or whatever, it will get out.
[00:54:08.620 --> 00:54:11.180]   And unlike an atomic bomb, lots of people--
[00:54:11.180 --> 00:54:14.180]   Yeah, there is a lot of technology like that, isn't there?
[00:54:14.180 --> 00:54:14.700]   Yeah.
[00:54:14.700 --> 00:54:17.900]   We got the same problem with cocaine and heroin.
[00:54:17.900 --> 00:54:19.740]   People doing that at home and look at the damage
[00:54:19.740 --> 00:54:20.220]   that that's cool.
[00:54:20.220 --> 00:54:20.900]   Yeah.
[00:54:20.900 --> 00:54:24.060]   Look how easy it is to make meth.
[00:54:24.060 --> 00:54:25.940]   This food will be a thing.
[00:54:25.940 --> 00:54:27.540]   I'm confident CRISPR will be a thing.
[00:54:27.540 --> 00:54:28.820]   In our life time, I think.
[00:54:28.820 --> 00:54:29.300]   Yeah.
[00:54:29.300 --> 00:54:31.660]   Oh, yes, 100%.
[00:54:31.660 --> 00:54:34.540]   And ultimately, it has great potential
[00:54:34.540 --> 00:54:35.660]   to make things better.
[00:54:35.660 --> 00:54:41.780]   It's just humans and humanity is mature enough
[00:54:41.780 --> 00:54:46.060]   to actually deal with this in time.
[00:54:46.060 --> 00:54:48.180]   But the time is certainly not there yet.
[00:54:48.180 --> 00:54:48.900]   We're so not.
[00:54:48.900 --> 00:54:50.300]   Such early days.
[00:54:50.300 --> 00:54:51.860]   You know, one of the--
[00:54:51.860 --> 00:54:53.820]   I've mentioned this several times.
[00:54:53.820 --> 00:54:57.460]   I'm reading-- I love you all know our Harari, the philosopher
[00:54:57.460 --> 00:55:01.460]   from Israel who wrote Sam Bians and Homo Dias, his newest
[00:55:01.460 --> 00:55:03.660]   is 21 Lessons for the 21st Century.
[00:55:03.660 --> 00:55:05.260]   And one of the things he's pointing out
[00:55:05.260 --> 00:55:09.300]   is we're doing this kind of regression to nationalism.
[00:55:09.300 --> 00:55:12.180]   And it's happening in many countries worldwide,
[00:55:12.180 --> 00:55:16.740]   this kind of nostalgic desire to close in.
[00:55:16.740 --> 00:55:19.460]   It's happening in Britain, as you know, Greg.
[00:55:19.460 --> 00:55:21.100]   And it's happening in the United States.
[00:55:21.100 --> 00:55:23.700]   The problem with that is many of the problems
[00:55:23.700 --> 00:55:25.500]   that we have to deal with in the future
[00:55:25.500 --> 00:55:27.620]   are not national but global.
[00:55:27.620 --> 00:55:30.740]   You can't deal with climate change nationally.
[00:55:30.740 --> 00:55:33.660]   You can't deal with CRISPR nationally.
[00:55:33.660 --> 00:55:36.180]   It's going to take a global effort.
[00:55:36.180 --> 00:55:41.020]   And in many cases, countries are moving in the wrong direction.
[00:55:41.020 --> 00:55:43.660]   A country can't ban CRISPR and then expect it not
[00:55:43.660 --> 00:55:47.740]   to be used everywhere else.
[00:55:47.740 --> 00:55:52.100]   But in fact, nuclear weapons is a global issue,
[00:55:52.100 --> 00:55:54.340]   not a national issue.
[00:55:54.340 --> 00:55:56.260]   And the attempt to deal with it nationally
[00:55:56.260 --> 00:55:59.420]   is fraught with peril, as we well know.
[00:55:59.420 --> 00:56:02.140]   If they've got them, we have to have them.
[00:56:02.140 --> 00:56:04.980]   It's a global world and you can't turn back the clock on it.
[00:56:04.980 --> 00:56:07.540]   And the things that are happening,
[00:56:07.540 --> 00:56:10.740]   they're ultimately going to be blips in the radar.
[00:56:10.740 --> 00:56:14.660]   We know that this is the way that history moves, right?
[00:56:14.660 --> 00:56:17.540]   It's often two steps forward, one step back.
[00:56:17.540 --> 00:56:22.940]   And it's funny because one of the greatest examples of this
[00:56:22.940 --> 00:56:26.700]   is China and US and their trade relations and all of that.
[00:56:26.700 --> 00:56:32.140]   We are so intertwined and interdependent on each other
[00:56:32.140 --> 00:56:33.740]   commercially.
[00:56:33.740 --> 00:56:35.180]   It's ridiculous.
[00:56:35.180 --> 00:56:39.740]   A lot of this thing is so much posturing and so much
[00:56:39.740 --> 00:56:44.900]   really negotiation tactics in many ways from both sides.
[00:56:44.900 --> 00:56:49.620]   Because it would be catastrophic to both the US and China
[00:56:49.620 --> 00:56:53.780]   to not have a really strong trade relationship.
[00:56:53.780 --> 00:56:54.780]   Oh, yeah, we've got it.
[00:56:54.780 --> 00:56:56.260]   That's just one example, right?
[00:56:56.260 --> 00:56:57.500]   It's just one example.
[00:56:57.500 --> 00:56:58.540]   That promotes peace.
[00:56:58.540 --> 00:56:59.980]   I mean, that's--
[00:56:59.980 --> 00:57:00.500]   It does.
[00:57:00.500 --> 00:57:02.820]   One of the reasons we haven't had a nuclear war
[00:57:02.820 --> 00:57:05.580]   is because it would be catastrophic for both sides.
[00:57:05.580 --> 00:57:07.300]   And everybody knows that, right?
[00:57:07.300 --> 00:57:08.340]   Sorry, guys.
[00:57:08.340 --> 00:57:10.980]   Guns of August, guns of August, guns of August.
[00:57:10.980 --> 00:57:12.500]   You're talking about World War I.
[00:57:12.500 --> 00:57:14.060]   Yes.
[00:57:14.060 --> 00:57:15.060]   I know that.
[00:57:15.060 --> 00:57:16.420]   They said that there would never be a--
[00:57:16.420 --> 00:57:17.260]   The last war.
[00:57:17.260 --> 00:57:18.260]   The last war.
[00:57:18.260 --> 00:57:19.420]   Yeah, oh, no way.
[00:57:19.420 --> 00:57:20.420]   It's impossible.
[00:57:20.420 --> 00:57:22.060]   Our trade relations--
[00:57:22.060 --> 00:57:25.460]   They thought in 1914 that they had a global world where
[00:57:25.460 --> 00:57:27.060]   trade was so intertwined.
[00:57:27.060 --> 00:57:27.560]   Interesting.
[00:57:27.560 --> 00:57:28.780]   There's no way we would ever go to war.
[00:57:28.780 --> 00:57:29.900]   Yeah, interesting.
[00:57:29.900 --> 00:57:37.180]   Actually, January 18, just passed nine days ago,
[00:57:37.180 --> 00:57:40.940]   was the 100th anniversary of the Paris Treaty
[00:57:40.940 --> 00:57:43.460]   to an officially end World War I.
[00:57:43.460 --> 00:57:45.660]   So I've been re-in about this.
[00:57:45.660 --> 00:57:50.020]   So what I'm not saying is it's impossible that there won't be
[00:57:50.020 --> 00:57:54.500]   the humans aren't possible of going down that road again.
[00:57:54.500 --> 00:57:58.460]   I'm just saying, every day we are more interdependent.
[00:57:58.460 --> 00:58:02.300]   The best hope for a global world is globalism and global trade.
[00:58:02.300 --> 00:58:03.780]   That's the best hope for peace.
[00:58:03.780 --> 00:58:05.740]   It may not be sufficient.
[00:58:05.740 --> 00:58:06.260]   Yes.
[00:58:06.260 --> 00:58:08.980]   But we know nationalism is the wrong direction.
[00:58:08.980 --> 00:58:11.380]   Let's just point out the people who
[00:58:11.380 --> 00:58:12.860]   will be leading those decisions.
[00:58:12.860 --> 00:58:14.980]   We've got President Trump.
[00:58:14.980 --> 00:58:18.860]   We've got the Trump leader for life in--
[00:58:18.860 --> 00:58:19.860]   President Xi.
[00:58:19.860 --> 00:58:20.860]   Yeah.
[00:58:20.860 --> 00:58:23.500]   He's now been appointed for life.
[00:58:23.500 --> 00:58:25.500]   So he no longer has to face up to elections.
[00:58:25.500 --> 00:58:29.260]   So he now has absolute power over that particular part
[00:58:29.260 --> 00:58:30.500]   of the portfolio.
[00:58:30.500 --> 00:58:32.580]   Look at the collapse of Venezuela and Brazil.
[00:58:32.580 --> 00:58:35.260]   So now South America is in a great deal of trouble.
[00:58:35.260 --> 00:58:37.060]   You're just going to depress us if you keep going.
[00:58:37.060 --> 00:58:37.900]   Greg, can you stop?
[00:58:37.900 --> 00:58:39.420]   Yeah.
[00:58:39.420 --> 00:58:41.100]   Look at what's happening in Africa.
[00:58:41.100 --> 00:58:43.380]   I mean, there's various things happening in Africa
[00:58:43.380 --> 00:58:45.180]   which are quite concerning.
[00:58:45.180 --> 00:58:47.780]   The European Union is struggling to hold up
[00:58:47.780 --> 00:58:50.860]   its momentum around change because the members of the European
[00:58:50.860 --> 00:58:54.380]   Union are very weary of the change and the whole purpose
[00:58:54.380 --> 00:58:56.140]   of the EU was for peace, right?
[00:58:56.140 --> 00:58:58.140]   To stop another war from happening
[00:58:58.140 --> 00:59:00.340]   by unifying the states into one.
[00:59:00.340 --> 00:59:02.220]   So it's entirely realistic that we
[00:59:02.220 --> 00:59:07.060]   are looking at preconditions for a return to war.
[00:59:07.060 --> 00:59:08.980]   But I think we can also say this.
[00:59:08.980 --> 00:59:14.140]   The difference between the guns of August and its sequel,
[00:59:14.140 --> 00:59:19.020]   the guns of 1939, the difference is we have nuclear weapons now.
[00:59:19.020 --> 00:59:22.900]   And I think there's no question a global war
[00:59:22.900 --> 00:59:26.140]   would be disastrous in a way that World War I and II weren't
[00:59:26.140 --> 00:59:28.100]   as bad as they were.
[00:59:28.100 --> 00:59:28.420]   Yes.
[00:59:28.420 --> 00:59:30.420]   I mean, even Putin said that recently.
[00:59:30.420 --> 00:59:31.380]   Like even Putin said like--
[00:59:31.380 --> 00:59:32.500]   Everybody understands.
[00:59:32.500 --> 00:59:34.140]   This is getting stupid.
[00:59:34.140 --> 00:59:37.020]   And we're going to have a nuclear war if we don't do it.
[00:59:37.020 --> 00:59:41.980]   This is essentially a leader for life of Russia,
[00:59:41.980 --> 00:59:44.700]   not in the same way as Kim Jong--
[00:59:44.700 --> 00:59:46.420]   or sorry, as China.
[00:59:46.420 --> 00:59:47.940]   [INTERPOSING VOICES]
[00:59:47.940 --> 00:59:48.420]   As president--
[00:59:48.420 --> 00:59:51.820]   Hey, Leo, you got something sunny?
[00:59:51.820 --> 00:59:53.220]   Yeah, no kidding.
[00:59:53.220 --> 00:59:54.740]   No, this is depressing.
[00:59:54.740 --> 00:59:57.540]   Ah, yeah, yeah.
[00:59:57.540 --> 01:00:00.820]   How about the Amazon Scout, a small autonomous six-wheel delivery
[01:00:00.820 --> 01:00:04.300]   robot that's about to take over Snohomish County?
[01:00:04.300 --> 01:00:05.980]   These are cute.
[01:00:05.980 --> 01:00:08.340]   This is coming-- let me show you the video,
[01:00:08.340 --> 01:00:10.420]   because it's a really cute little video.
[01:00:10.420 --> 01:00:13.340]   I wonder, though, when I look at this,
[01:00:13.340 --> 01:00:15.700]   if this is the world we live in.
[01:00:15.700 --> 01:00:21.340]   This is a little bot that's driving down the sidewalk.
[01:00:21.340 --> 01:00:23.140]   Watch out, grandma.
[01:00:23.140 --> 01:00:26.340]   Here comes the Amazon delivery bot.
[01:00:26.340 --> 01:00:26.780]   Fortunately--
[01:00:26.780 --> 01:00:28.060]   There's been some of these--
[01:00:28.060 --> 01:00:28.660]   Sorry, go ahead, Leo.
[01:00:28.660 --> 01:00:30.420]   It's moving slowly, but I still
[01:00:30.420 --> 01:00:32.060]   make me a little nervous.
[01:00:32.060 --> 01:00:34.420]   This, clearly, by the way, is the Desperate Housewives
[01:00:34.420 --> 01:00:40.260]   neighborhood, a phony neighborhood in Hollywood.
[01:00:40.260 --> 01:00:41.940]   And then, look, she comes out.
[01:00:41.940 --> 01:00:44.020]   I don't know how she knew, but the little bot was out there
[01:00:44.020 --> 01:00:44.860]   waiting.
[01:00:44.860 --> 01:00:45.940]   It's lid comes open.
[01:00:45.940 --> 01:00:47.260]   She gets her package.
[01:00:47.260 --> 01:00:48.780]   It closes the lid very slowly.
[01:00:48.780 --> 01:00:51.380]   Watch your fur pinching, and then moves on.
[01:00:51.380 --> 01:00:54.540]   Is this-- I understand why Amazon wants to do this,
[01:00:54.540 --> 01:00:55.940]   and is promoting this.
[01:00:55.940 --> 01:00:58.460]   But is this at all viable?
[01:00:58.460 --> 01:00:59.060]   So Leo--
[01:00:59.060 --> 01:01:00.660]   Actually, there's--
[01:01:00.660 --> 01:01:02.060]   OK, we have it one at a time.
[01:01:02.060 --> 01:01:02.860]   Let's start with Brian.
[01:01:02.860 --> 01:01:03.740]   We'll go left to right.
[01:01:03.740 --> 01:01:04.740]   Brian, go ahead.
[01:01:04.740 --> 01:01:07.260]   And I'm apologizing for plugging my pod,
[01:01:07.260 --> 01:01:10.220]   but this was the episode we released literally today.
[01:01:10.220 --> 01:01:10.580]   Good.
[01:01:10.580 --> 01:01:13.220]   I talked to Christopher Mims of The Wall Street Journal
[01:01:13.220 --> 01:01:13.900]   about this--
[01:01:13.900 --> 01:01:14.420]   Love him.
[01:01:14.420 --> 01:01:16.180]   --about this exact thing.
[01:01:16.180 --> 01:01:18.020]   And the concept being that you're
[01:01:18.020 --> 01:01:21.100]   more likely to get a burrito delivered to you
[01:01:21.100 --> 01:01:23.260]   for lunch from an autonomous vehicle
[01:01:23.260 --> 01:01:26.740]   than you are to commute to work in an autonomous vehicle
[01:01:26.740 --> 01:01:27.660]   in the next five years.
[01:01:27.660 --> 01:01:31.260]   You're going to get stuff delivered to you by ABs sooner
[01:01:31.260 --> 01:01:32.380]   than you--
[01:01:32.380 --> 01:01:35.260]   Less likely cars, more likely these little babies.
[01:01:35.260 --> 01:01:36.300]   Yes, exactly.
[01:01:36.300 --> 01:01:38.860]   And so then, this is what we talked about.
[01:01:38.860 --> 01:01:41.100]   There's a whole ecosystem of startups
[01:01:41.100 --> 01:01:43.300]   that are doing these little things.
[01:01:43.300 --> 01:01:47.180]   And although also Waymo and everyone else,
[01:01:47.180 --> 01:01:49.820]   it's sort of everyone's playing both sides of the fence
[01:01:49.820 --> 01:01:51.820]   in case one thing takes off over the other.
[01:01:51.820 --> 01:01:54.780]   But so the concept is there's a couple of things.
[01:01:54.780 --> 01:01:56.580]   And one of them was super surprising to me.
[01:01:56.580 --> 01:01:57.780]   Like you're mentioning that that's
[01:01:57.780 --> 01:02:00.580]   the Desperate Housewives neighborhood,
[01:02:00.580 --> 01:02:02.500]   because I'm thinking I'm here in Dumbo in Brooklyn.
[01:02:02.500 --> 01:02:04.100]   And I'm like, well, listen, everyone's
[01:02:04.100 --> 01:02:06.780]   going to kick those things off the sidewalk here in New York.
[01:02:06.780 --> 01:02:07.620]   OK, but listen to that.
[01:02:07.620 --> 01:02:09.140]   You can't even charge your Tesla anymore,
[01:02:09.140 --> 01:02:10.300]   because people cut the cords.
[01:02:10.300 --> 01:02:12.820]   They parked their trucks in the Tesla charging.
[01:02:12.820 --> 01:02:14.460]   We don't like these things.
[01:02:14.460 --> 01:02:17.940]   This is the thing that surprised me.
[01:02:17.940 --> 01:02:19.300]   I don't have it in front of me.
[01:02:19.300 --> 01:02:21.140]   But in the article, he talks about the statistics
[01:02:21.140 --> 01:02:24.100]   point out that in suburban areas,
[01:02:24.100 --> 01:02:27.620]   the most underutilized resource in terms of land
[01:02:27.620 --> 01:02:28.580]   are sidewalks.
[01:02:28.580 --> 01:02:29.700]   Yeah, I know.
[01:02:29.700 --> 01:02:30.900]   And so that if you think--
[01:02:30.900 --> 01:02:32.140]   Because no one goes--
[01:02:32.140 --> 01:02:34.540]   No one walks anymore.
[01:02:34.540 --> 01:02:35.500]   Right, there's that.
[01:02:35.500 --> 01:02:36.100]   They're empty.
[01:02:36.100 --> 01:02:38.620]   But then also-- so then think of what Amazon is also doing
[01:02:38.620 --> 01:02:42.980]   is Whole Foods and these sort of ghost stores or whatever.
[01:02:42.980 --> 01:02:45.580]   So what if 10 years from now Amazon
[01:02:45.580 --> 01:02:48.740]   has your gas station just essentially
[01:02:48.740 --> 01:02:50.500]   becomes-- or your corner market or whatever--
[01:02:50.500 --> 01:02:54.820]   becomes this quasi-way station for these tiny bots that go out
[01:02:54.820 --> 01:02:55.700]   and make the deliveries.
[01:02:55.700 --> 01:02:56.540]   And not even that.
[01:02:56.540 --> 01:02:58.540]   It doesn't even have to be just that.
[01:02:58.540 --> 01:03:01.500]   You could think of what FedEx and UPS does.
[01:03:01.500 --> 01:03:03.140]   FedEx goes to a certain--
[01:03:03.140 --> 01:03:05.020]   like they have to go and the guy runs out
[01:03:05.020 --> 01:03:06.380]   and delivers the package, whatever.
[01:03:06.380 --> 01:03:09.500]   No, the FedEx truck could go to a certain location
[01:03:09.500 --> 01:03:11.060]   that the algorithms are--
[01:03:11.060 --> 01:03:12.900]   It'd be like a merve for--
[01:03:12.900 --> 01:03:14.220]   It would be like 30 different--
[01:03:14.220 --> 01:03:14.700]   Packages.
[01:03:14.700 --> 01:03:15.740]   --children going out.
[01:03:15.740 --> 01:03:18.500]   Yeah, exactly.
[01:03:18.500 --> 01:03:22.940]   George Mason University just took delivery on 25 food
[01:03:22.940 --> 01:03:25.260]   delivery robots.
[01:03:25.260 --> 01:03:27.740]   They're going to deliver pizza and--
[01:03:27.740 --> 01:03:28.580]   And that was the other thing.
[01:03:28.580 --> 01:03:31.460]   College campuses and retirement communities
[01:03:31.460 --> 01:03:34.780]   would be the first most obvious use for us.
[01:03:34.780 --> 01:03:37.420]   So actually, the funny thing is there's--
[01:03:37.420 --> 01:03:43.340]   one of these that's been in use for, I believe, since 2017.
[01:03:43.340 --> 01:03:46.020]   It's called Robbie, Robbie.io.
[01:03:46.020 --> 01:03:49.100]   I had a kung fu fight with one at CES last year.
[01:03:49.100 --> 01:03:52.340]   Sort of a funny-- there's a funny picture
[01:03:52.340 --> 01:03:56.260]   on my Instagram of me sort of joking around.
[01:03:56.260 --> 01:04:00.660]   Like I was going to sort of kick one of the one that
[01:04:00.660 --> 01:04:03.780]   was going around CES.
[01:04:03.780 --> 01:04:07.540]   And so the cool thing is, it looks--
[01:04:07.540 --> 01:04:09.420]   the new one, that was the Robbie 1.0.
[01:04:09.420 --> 01:04:10.780]   These look like the Robbies.
[01:04:10.780 --> 01:04:12.460]   I wonder if they're the same technology.
[01:04:12.460 --> 01:04:14.260]   Yeah, exactly.
[01:04:14.260 --> 01:04:17.740]   So I don't know, maybe Robbie's doing it for them or something.
[01:04:17.740 --> 01:04:18.860]   They're little six wheel--
[01:04:18.860 --> 01:04:19.860]   They look like a--
[01:04:19.860 --> 01:04:22.540]   --Eclu cooler on wheels, basically.
[01:04:22.540 --> 01:04:23.740]   Well, they all look like everything
[01:04:23.740 --> 01:04:25.900]   that's in the Death Star that's running into people's ankles
[01:04:25.900 --> 01:04:26.900]   and you're starting with.
[01:04:26.900 --> 01:04:27.740]   That's true.
[01:04:27.740 --> 01:04:28.940]   That's true.
[01:04:28.940 --> 01:04:30.900]   Exactly right.
[01:04:30.900 --> 01:04:36.220]   I think one of the questions was, what happens if just a couple
[01:04:36.220 --> 01:04:38.140]   of people come--
[01:04:38.140 --> 01:04:39.780]   you have one of these running around at night,
[01:04:39.780 --> 01:04:41.980]   and a couple thieves come, and they're like,
[01:04:41.980 --> 01:04:43.340]   hey, let's just pick this something up,
[01:04:43.340 --> 01:04:44.660]   though, in the back of our van.
[01:04:44.660 --> 01:04:45.980]   See what kind of packages are in there.
[01:04:45.980 --> 01:04:48.420]   I guess there's on the Amazon one,
[01:04:48.420 --> 01:04:51.340]   there's some kind of alarm that will go off
[01:04:51.340 --> 01:04:54.860]   if you try to pick it up or something.
[01:04:54.860 --> 01:04:56.900]   So it's pretty interesting to think about.
[01:04:56.900 --> 01:04:58.980]   But clearly, this is happening already.
[01:04:58.980 --> 01:05:02.780]   The Robbie, like I said, it was developed by these MIT
[01:05:02.780 --> 01:05:04.220]   scientists.
[01:05:04.220 --> 01:05:07.380]   It's been in use in the Bay Area for at least, I think,
[01:05:07.380 --> 01:05:10.220]   the last-- at least almost two years now.
[01:05:10.220 --> 01:05:14.620]   It's fascinating how science fiction completely informs us.
[01:05:14.620 --> 01:05:15.940]   It's not that they were right.
[01:05:15.940 --> 01:05:16.900]   They predicted it.
[01:05:16.900 --> 01:05:19.860]   It's that the people today who are developing this crap
[01:05:19.860 --> 01:05:21.100]   all watched this--
[01:05:21.100 --> 01:05:23.980]   here's the Star Wars clip on the Death Star,
[01:05:23.980 --> 01:05:26.180]   the little Robbie the Robot.
[01:05:26.180 --> 01:05:30.780]   And of course, Chewy goes, oh, and it runs away.
[01:05:30.780 --> 01:05:33.220]   Remember, who doesn't remember that?
[01:05:33.220 --> 01:05:35.660]   That's exactly what they invented.
[01:05:35.660 --> 01:05:36.740]   It's no way.
[01:05:36.740 --> 01:05:39.980]   I'm going to be a door downer on this,
[01:05:39.980 --> 01:05:41.740]   because I think it's the dumbest thing ever.
[01:05:41.740 --> 01:05:44.500]   Nice PR stunt, though.
[01:05:44.500 --> 01:05:46.740]   In realistically, if you put these in suburbia,
[01:05:46.740 --> 01:05:49.540]   the distances in American suburbs are so large,
[01:05:49.540 --> 01:05:52.220]   there's no way these things are going to have the battery life
[01:05:52.220 --> 01:05:53.060]   be pretty slow.
[01:05:53.060 --> 01:05:56.220]   It would take days to get across town.
[01:05:56.220 --> 01:05:57.820]   Your average American--
[01:05:57.820 --> 01:06:00.300]   Burrito will be cold.
[01:06:00.300 --> 01:06:02.860]   Yeah, American suburbs, everybody's on a quarter of an acre.
[01:06:02.860 --> 01:06:05.100]   You're talking five kilometers to 20 kilometers--
[01:06:05.100 --> 01:06:07.260]   Hey, it's mocking our McPlansions.
[01:06:07.260 --> 01:06:10.020]   Yeah, so your burrito, by the time it gets to you,
[01:06:10.020 --> 01:06:11.700]   isn't going to be in a fit state to eat.
[01:06:11.700 --> 01:06:14.540]   Well, that's why it makes sense to do it in a college, I guess,
[01:06:14.540 --> 01:06:15.060]   right?
[01:06:15.060 --> 01:06:17.340]   And then what happens when you start to get five to 10%
[01:06:17.340 --> 01:06:18.940]   loss around these things?
[01:06:18.940 --> 01:06:21.860]   What happens when they just trip over on the footpath
[01:06:21.860 --> 01:06:23.260]   or the conditions of the footpath change?
[01:06:23.260 --> 01:06:24.700]   I think people are going to beat them up.
[01:06:24.700 --> 01:06:26.060]   I honestly do.
[01:06:26.060 --> 01:06:27.780]   Yeah, well, they know people in Arizona
[01:06:27.780 --> 01:06:29.660]   are shooting at the Weimo vehicles.
[01:06:29.660 --> 01:06:32.260]   I mean, I think they're just going to beat the hell out of them.
[01:06:32.260 --> 01:06:34.100]   Yeah, and there will be some of that.
[01:06:34.100 --> 01:06:36.340]   But whether that reaches critical mass or not,
[01:06:36.340 --> 01:06:37.100]   or who knows.
[01:06:37.100 --> 01:06:39.140]   But my point is, is that the footpath can change.
[01:06:39.140 --> 01:06:41.140]   And then all of a sudden, it breaks down.
[01:06:41.140 --> 01:06:43.380]   So then they have to send somebody out to retrieve it
[01:06:43.380 --> 01:06:45.540]   and redo the patent because the foot cuts--
[01:06:45.540 --> 01:06:46.980]   There's a couple other things that--
[01:06:46.980 --> 01:06:49.380]   Most of America, you guys don't even pay enough taxes
[01:06:49.380 --> 01:06:51.740]   to put gutters on roads, much less have payments.
[01:06:51.740 --> 01:06:55.140]   There's a couple of things that Chris said that pointed out
[01:06:55.140 --> 01:06:59.300]   that because they are slower, it's cheaper to do the research
[01:06:59.300 --> 01:07:01.260]   and development because unlike cars,
[01:07:01.260 --> 01:07:03.580]   like if you keep it under 20 miles an hour, if you keep it up.
[01:07:03.580 --> 01:07:06.860]   So the reason that I'm saying-- and we can make a wager
[01:07:06.860 --> 01:07:08.260]   on here right now--
[01:07:08.260 --> 01:07:14.660]   If Leo gets a burrito before he commutes to do Twitch--
[01:07:14.660 --> 01:07:16.740]   Yeah, which would get there first.
[01:07:16.740 --> 01:07:19.540]   The thing is that, Leo, I live the kilometer for--
[01:07:19.540 --> 01:07:20.460]   I literally do.
[01:07:20.460 --> 01:07:21.020]   I live well.
[01:07:21.020 --> 01:07:22.020]   I live well.
[01:07:22.020 --> 01:07:25.020]   He's going to work because he lives right on top of a food court.
[01:07:25.020 --> 01:07:26.020]   Right?
[01:07:26.020 --> 01:07:29.020]   He could walk down for dinner and be back.
[01:07:29.020 --> 01:07:31.100]   They're probably specialized environments,
[01:07:31.100 --> 01:07:34.060]   especially university campuses where these would make a lot of sense.
[01:07:34.060 --> 01:07:35.060]   Right.
[01:07:35.060 --> 01:07:35.580]   Right.
[01:07:35.580 --> 01:07:36.420]   Specialized in more--
[01:07:36.420 --> 01:07:39.820]   So let's not conflate a limited use case
[01:07:39.820 --> 01:07:41.140]   in a highly controlled environment--
[01:07:41.140 --> 01:07:43.060]   What is Snohomish, Washington like?
[01:07:43.060 --> 01:07:45.740]   I mean, why are they testing it there besides the fact
[01:07:45.740 --> 01:07:47.660]   that it's near Amazon headquarters?
[01:07:47.660 --> 01:07:49.220]   Is Jeff Bezos live there?
[01:07:49.220 --> 01:07:50.020]   Does he waiting for his burrito?
[01:07:50.020 --> 01:07:53.060]   It's super suburban looking like desperate housewives.
[01:07:53.060 --> 01:07:54.060]   Neighborhoods.
[01:07:54.060 --> 01:07:55.060]   But Greg has a good point.
[01:07:55.060 --> 01:07:57.860]   For instance, in Petaluma, for a long time,
[01:07:57.860 --> 01:08:00.180]   they didn't require developments put in sidewalks.
[01:08:00.180 --> 01:08:02.140]   So even just outside of Twit, there
[01:08:02.140 --> 01:08:04.220]   are plenty of places where you'd be walking on the street
[01:08:04.220 --> 01:08:05.620]   where Robbie'd be going out in the street
[01:08:05.620 --> 01:08:06.780]   because there's no sidewalk.
[01:08:06.780 --> 01:08:08.260]   And he can't be on the street because it
[01:08:08.260 --> 01:08:09.380]   have to be a registered vehicle?
[01:08:09.380 --> 01:08:11.020]   And I know that because when I bicycle,
[01:08:11.020 --> 01:08:13.740]   the bicycle path will frequently just stop.
[01:08:13.740 --> 01:08:15.540]   And lots of bike lanes here in New York.
[01:08:15.540 --> 01:08:17.500]   You can't have a vehicle on a bike lane that
[01:08:17.500 --> 01:08:18.860]   goes over 20 miles an hour.
[01:08:18.860 --> 01:08:19.220]   There you go.
[01:08:19.220 --> 01:08:20.220]   That's why--
[01:08:20.220 --> 01:08:22.700]   Well, I'd say I won't-- so I'd say I won in 10 chance
[01:08:22.700 --> 01:08:24.900]   of success as a widespread.
[01:08:24.900 --> 01:08:25.420]   In terms of--
[01:08:25.420 --> 01:08:28.020]   I was trying to bring up a cheerful little--
[01:08:28.020 --> 01:08:29.660]   Robbie the robot subject.
[01:08:29.660 --> 01:08:31.580]   I think people in Silicon Valley are all stupid.
[01:08:31.580 --> 01:08:33.700]   They've got more money than since.
[01:08:33.700 --> 01:08:37.580]   We've definitely settled that question.
[01:08:37.580 --> 01:08:38.260]   Let's take a little break.
[01:08:38.260 --> 01:08:40.860]   More with our panel there wild today.
[01:08:40.860 --> 01:08:43.300]   They're on Fuego, our show today.
[01:08:43.300 --> 01:08:45.740]   Brought to you quite literally by Cashflow.
[01:08:45.740 --> 01:08:47.820]   When you download our podcasts, you
[01:08:47.820 --> 01:08:50.060]   are downloading it from our content distribution
[01:08:50.060 --> 01:08:51.980]   network from Cashflow.
[01:08:51.980 --> 01:08:54.220]   And man, it is the best.
[01:08:54.220 --> 01:08:55.100]   I just love it.
[01:08:55.100 --> 01:08:57.740]   We've been using Cashflow for I think 10 years.
[01:08:57.740 --> 01:09:01.820]   Every month, several petabytes of data
[01:09:01.820 --> 01:09:04.140]   are delivered to our listeners, our viewers,
[01:09:04.140 --> 01:09:07.180]   via Cashflow, audio and video both.
[01:09:07.180 --> 01:09:09.140]   I never get calls at three in the morning.
[01:09:09.140 --> 01:09:10.780]   The CD ends down.
[01:09:10.780 --> 01:09:12.300]   I don't have any problems.
[01:09:12.300 --> 01:09:14.660]   I've never had a problem with Cashflow.
[01:09:14.660 --> 01:09:17.540]   Cashflow delivers rich media content up to 10 times
[01:09:17.540 --> 01:09:20.100]   faster than traditional delivery methods
[01:09:20.100 --> 01:09:23.300]   because it has a server near your customer.
[01:09:23.300 --> 01:09:27.100]   And they're even faster than other major CD ends, up to 30%
[01:09:27.100 --> 01:09:28.140]   faster.
[01:09:28.140 --> 01:09:29.940]   And because they have so many servers,
[01:09:29.940 --> 01:09:33.900]   they can give you a 100% SLA.
[01:09:33.900 --> 01:09:35.700]   Cashflow guarantees the best experience
[01:09:35.700 --> 01:09:38.060]   for all your customers, no matter where they are,
[01:09:38.060 --> 01:09:39.740]   no matter what device they're on,
[01:09:39.740 --> 01:09:41.380]   we couldn't be happier with Cashflow.
[01:09:41.380 --> 01:09:42.740]   We're not alone though.
[01:09:42.740 --> 01:09:45.620]   Thousands of others trust Cashflow's reliable network,
[01:09:45.620 --> 01:09:50.620]   including LG, Microsoft, Adobe, R's, Technica.
[01:09:50.620 --> 01:09:54.980]   Petabytes of data, I'm telling you, it is, I love it.
[01:09:54.980 --> 01:09:56.340]   I love your Cashflow.
[01:09:56.340 --> 01:09:58.260]   Say goodbye to logging in several times a week
[01:09:58.260 --> 01:10:00.180]   just to make sure you haven't gone over your limits
[01:10:00.180 --> 01:10:03.420]   or even daily trying to track your CDN usage.
[01:10:03.420 --> 01:10:06.060]   Because when you call your Cashflow representative,
[01:10:06.060 --> 01:10:09.340]   you'll set up a custom plan tailored to your usage,
[01:10:09.340 --> 01:10:12.540]   your needs based on yearly usage trends.
[01:10:12.540 --> 01:10:14.020]   So you don't have to worry about those spikes.
[01:10:14.020 --> 01:10:18.420]   Most of us have spiky demand, but Cashflow handles it.
[01:10:18.420 --> 01:10:20.140]   In fact, on average, customers have switched
[01:10:20.140 --> 01:10:23.740]   to Cashflow, I save more than 20%.
[01:10:23.740 --> 01:10:25.620]   20%.
[01:10:25.620 --> 01:10:27.380]   Just for you, Cashflow is offering you
[01:10:27.380 --> 01:10:30.100]   a complimentary detail analysis, no hard sell
[01:10:30.100 --> 01:10:32.180]   of your current CDN bill and usage trends.
[01:10:32.180 --> 01:10:33.660]   Just see what you could save.
[01:10:33.660 --> 01:10:35.980]   Twit.cashflow.com.
[01:10:35.980 --> 01:10:40.060]   Twit.cashflow.com.
[01:10:40.060 --> 01:10:41.540]   We love them and I know you will too.
[01:10:41.540 --> 01:10:44.900]   Twit.cashflow.com.
[01:10:44.900 --> 01:10:48.740]   I don't think this is gonna calm anybody's blood here,
[01:10:48.740 --> 01:10:52.460]   but the first GDPR finds for Google
[01:10:52.460 --> 01:10:55.580]   or have come in $50 million, I'm sorry,
[01:10:55.580 --> 01:10:57.820]   50 million euros.
[01:10:57.820 --> 01:11:02.820]   France and Sinell, which is the French regulator,
[01:11:02.820 --> 01:11:07.380]   says that according to Sinell,
[01:11:07.380 --> 01:11:11.660]   Google is in breach of two provisions of the GDPR.
[01:11:11.660 --> 01:11:14.700]   First, by not making its data collection policies
[01:11:14.700 --> 01:11:16.820]   more easily accessible,
[01:11:16.820 --> 01:11:21.300]   second, by not obtaining specific user consent.
[01:11:21.300 --> 01:11:24.820]   They want Sinell wants you to say yes
[01:11:24.820 --> 01:11:27.060]   to each of Google's services each time,
[01:11:27.060 --> 01:11:29.900]   including YouTube, Google Maps and more.
[01:11:29.900 --> 01:11:32.820]   And the 50 million euros is just the beginning.
[01:11:32.820 --> 01:11:36.380]   - This was mainly with onboarding on a new Android phone.
[01:11:36.380 --> 01:11:37.820]   - Is it like the setup process?
[01:11:37.820 --> 01:11:38.660]   - Yeah.
[01:11:38.660 --> 01:11:41.620]   - Just think about how many times when you go to a website,
[01:11:41.620 --> 01:11:43.260]   you have to click now to say,
[01:11:43.260 --> 01:11:44.900]   "Yes, I know you use cookies.
[01:11:44.900 --> 01:11:46.380]   Okay, that's all right."
[01:11:46.380 --> 01:11:49.300]   Now, put that on your Android device,
[01:11:49.300 --> 01:11:51.260]   'cause that's what they're saying.
[01:11:51.260 --> 01:11:53.300]   They're not saying that that information isn't there,
[01:11:53.300 --> 01:11:54.540]   that you're not giving permission.
[01:11:54.540 --> 01:11:56.020]   They just want it to be more granular,
[01:11:56.020 --> 01:11:59.420]   they want you more, no better, make it more public.
[01:11:59.420 --> 01:12:01.060]   I'm not sure I'm against that.
[01:12:01.060 --> 01:12:03.420]   Google says they announced late last week
[01:12:03.420 --> 01:12:05.020]   that they will appeal.
[01:12:06.220 --> 01:12:08.980]   - Yeah, and there's a sequence of follow-ons from here.
[01:12:08.980 --> 01:12:10.620]   Germany's coming up with various--
[01:12:10.620 --> 01:12:12.100]   - Oh, it's just the beginning, kids.
[01:12:12.100 --> 01:12:13.380]   - Yeah, it's just the beginning.
[01:12:13.380 --> 01:12:15.740]   We're seeing other court cases come up right the way
[01:12:15.740 --> 01:12:17.700]   around the European Union.
[01:12:17.700 --> 01:12:20.020]   There's some going on here in the UK as well.
[01:12:20.020 --> 01:12:22.060]   I think one of the things that we're seeing here
[01:12:22.060 --> 01:12:24.260]   is sort of a general reaction to the move fast
[01:12:24.260 --> 01:12:25.380]   and break things.
[01:12:25.380 --> 01:12:27.620]   So if you go out and you break someone's business
[01:12:27.620 --> 01:12:29.260]   and then they start fighting back,
[01:12:29.260 --> 01:12:30.620]   you shouldn't be surprised and go,
[01:12:30.620 --> 01:12:32.740]   "Oh, I was just having some fun.
[01:12:32.740 --> 01:12:34.740]   I was just trying some things out."
[01:12:34.740 --> 01:12:36.780]   But, you know, and then the person the other side says,
[01:12:36.780 --> 01:12:38.100]   "Look at this, you broke my arm.
[01:12:38.100 --> 01:12:38.940]   You are that.
[01:12:38.940 --> 01:12:40.060]   I'm going to come after you."
[01:12:40.060 --> 01:12:40.900]   - Right.
[01:12:40.900 --> 01:12:43.460]   - So the motto of move fast and break things
[01:12:43.460 --> 01:12:44.940]   actually causes damage.
[01:12:44.940 --> 01:12:46.140]   And when people fight back,
[01:12:46.140 --> 01:12:47.700]   you shouldn't be surprised and go,
[01:12:47.700 --> 01:12:49.540]   "Oh, but I did nice things to you."
[01:12:49.540 --> 01:12:51.660]   - What damage, what damage are you talking about?
[01:12:51.660 --> 01:12:52.500]   - Yeah, what.
[01:12:52.500 --> 01:12:53.660]   - You're talking about the shopping decision.
[01:12:53.660 --> 01:12:54.740]   - The shopping decision.
[01:12:54.740 --> 01:12:55.580]   - So from the French point of you,
[01:12:55.580 --> 01:12:56.460]   no, I'm talking about the French,
[01:12:56.460 --> 01:12:59.180]   in the French culture,
[01:12:59.180 --> 01:13:02.380]   they're very passionate about defending the French language,
[01:13:02.380 --> 01:13:04.580]   the French media, the French way of life.
[01:13:04.580 --> 01:13:06.860]   And they, very many people in France,
[01:13:06.860 --> 01:13:10.300]   Google has destroyed their unique Frankophone lifestyle.
[01:13:10.300 --> 01:13:11.140]   - Oh, Lord.
[01:13:11.140 --> 01:13:11.980]   - Okay.
[01:13:11.980 --> 01:13:12.820]   - So this is an absolute culture.
[01:13:12.820 --> 01:13:14.900]   - If I were Google, I would say, fine, have fun.
[01:13:14.900 --> 01:13:16.660]   Go and show your croissants,
[01:13:16.660 --> 01:13:19.180]   read Le Mans, smoke you cigars and...
[01:13:19.180 --> 01:13:20.340]   - Yes.
[01:13:20.340 --> 01:13:21.340]   - We'll see you later.
[01:13:21.340 --> 01:13:22.860]   - We'll come to that because it's a platform.
[01:13:22.860 --> 01:13:23.700]   If it's not anywhere.
[01:13:23.700 --> 01:13:26.220]   - They can't because the internet is a global platform.
[01:13:26.220 --> 01:13:27.140]   It's international.
[01:13:27.140 --> 01:13:28.780]   You can't pick and choose.
[01:13:28.780 --> 01:13:31.020]   - And everyone, you know, everybody's tweets that day
[01:13:31.020 --> 01:13:34.300]   were like, "Oh, 50 million euros, that's nothing to Google."
[01:13:34.300 --> 01:13:37.620]   Which it isn't like, you know, like the FTC finds,
[01:13:37.620 --> 01:13:41.940]   the record FTC finds if Facebook or Google,
[01:13:41.940 --> 01:13:45.180]   Facebook was rumored to be facing the FTC's
[01:13:45.180 --> 01:13:46.260]   considering finding them,
[01:13:46.260 --> 01:13:49.460]   but the record FTC find was only $22 million.
[01:13:49.460 --> 01:13:50.900]   You can only do what the law does,
[01:13:50.900 --> 01:13:53.620]   but the law allows you to do.
[01:13:53.620 --> 01:13:56.380]   But the difference in Europe, as he was saying,
[01:13:56.380 --> 01:13:58.700]   like it's a death of a thousand cuts.
[01:13:58.700 --> 01:13:59.540]   - Right.
[01:13:59.540 --> 01:14:00.860]   - First it's France. - And it could at some point
[01:14:00.860 --> 01:14:03.020]   be more money because it could be up to 4%
[01:14:03.020 --> 01:14:04.980]   of your global revenue, which for Google,
[01:14:04.980 --> 01:14:09.980]   - Well, if they don't rectify things to the EU's satisfaction.
[01:14:09.980 --> 01:14:14.220]   - So in the UK, the Cambridge Analytica find on Facebook
[01:14:14.220 --> 01:14:17.180]   was two and a half million or a few million dollars.
[01:14:17.180 --> 01:14:19.460]   It's like petty cash down the back of the sofa.
[01:14:19.460 --> 01:14:21.820]   But there is legislation now moving through the government
[01:14:21.820 --> 01:14:23.100]   to turn it into billions.
[01:14:23.100 --> 01:14:26.300]   - How about this one?
[01:14:26.300 --> 01:14:27.860]   - How about foldable phones?
[01:14:27.860 --> 01:14:29.020]   (laughing)
[01:14:29.020 --> 01:14:30.260]   - Not yet.
[01:14:30.260 --> 01:14:32.740]   I want to keep your blood pressure a little higher
[01:14:32.740 --> 01:14:34.420]   for a little longer. - All right, all right.
[01:14:34.420 --> 01:14:36.140]   - And then we'll get to foldable phones
[01:14:36.140 --> 01:14:37.420]   'cause they are on the way.
[01:14:37.420 --> 01:14:39.820]   Thank you for trying, Jason, I really appreciate it.
[01:14:39.820 --> 01:14:41.300]   But I do have one more Google story,
[01:14:41.300 --> 01:14:44.860]   which is the Dutch surgeon
[01:14:44.860 --> 01:14:48.500]   who was formerly disciplined for medical negligence
[01:14:48.500 --> 01:14:51.540]   has wanted a legal action to have Google remove
[01:14:51.540 --> 01:14:54.560]   search results about her case.
[01:14:54.560 --> 01:14:58.900]   So her registration on the Register of Healthcare Professionals
[01:14:58.900 --> 01:15:01.320]   was suspended by a disciplinary panel.
[01:15:02.220 --> 01:15:05.220]   After appeal, it was changed to a conditional suspension.
[01:15:05.220 --> 01:15:08.220]   She is currently practicing as a result.
[01:15:08.220 --> 01:15:10.380]   But she says, when you search for my name,
[01:15:10.380 --> 01:15:13.780]   you find this a website
[01:15:13.780 --> 01:15:17.460]   which contains an unofficial blacklist, which mentions this.
[01:15:17.460 --> 01:15:19.620]   She says, it's a digital pillery
[01:15:19.620 --> 01:15:24.780]   and she wants that remove the Dutch data privacy watchdog
[01:15:24.780 --> 01:15:28.820]   agreed, initially they said no.
[01:15:28.820 --> 01:15:32.740]   But so she went to court and the court said, no.
[01:15:32.740 --> 01:15:34.460]   She has a surgeon, the surgeon has an interest
[01:15:34.460 --> 01:15:36.740]   in not indicating that every time somebody enters her name
[01:15:36.740 --> 01:15:39.500]   on a search engine that she appears
[01:15:39.500 --> 01:15:41.820]   on this blacklist of doctors appears,
[01:15:41.820 --> 01:15:45.140]   Google's claim that most people would have difficulty
[01:15:45.140 --> 01:15:47.220]   finding the relevant information on the medical board's
[01:15:47.220 --> 01:15:50.740]   big register where records are publicly held.
[01:15:50.740 --> 01:15:53.620]   Court didn't agree.
[01:15:53.620 --> 01:15:54.700]   What do you think?
[01:15:54.700 --> 01:15:57.660]   The right to be forgotten. - The kicker is in the final paragraph.
[01:15:57.660 --> 01:15:59.700]   It basically said that it's not up to Google
[01:15:59.700 --> 01:16:03.060]   to make the decision about whether or not this happens.
[01:16:03.060 --> 01:16:05.100]   It's a society's decision. - That's fair.
[01:16:05.100 --> 01:16:07.140]   - And in particular, it's the medical board.
[01:16:07.140 --> 01:16:09.980]   So if you'd go to the last paragraph, you'll see the kicker.
[01:16:09.980 --> 01:16:11.300]   - Yeah.
[01:16:11.300 --> 01:16:12.140]   - And that's the point.
[01:16:12.140 --> 01:16:13.820]   The point here is that Google's become the judge
[01:16:13.820 --> 01:16:17.060]   and executioner by putting this data online.
[01:16:17.060 --> 01:16:19.700]   - That's a very loaded way to put it.
[01:16:19.700 --> 01:16:21.540]   Google didn't put the data online.
[01:16:21.540 --> 01:16:23.300]   The data is online from somebody else.
[01:16:23.300 --> 01:16:27.060]   Google's merely a search index showing what's on the web.
[01:16:27.060 --> 01:16:29.660]   - Google loses a lawsuit 30 years ago
[01:16:29.660 --> 01:16:32.540]   and there's 30 different newspaper articles
[01:16:32.540 --> 01:16:35.340]   about her malfeasance or something.
[01:16:35.340 --> 01:16:37.220]   Allegedly, I don't know this lady.
[01:16:37.220 --> 01:16:41.860]   But who would think it would be fair to go to every library
[01:16:41.860 --> 01:16:45.740]   and rip all those newspapers out of the library?
[01:16:45.740 --> 01:16:49.220]   - So you're saying that Google's response.
[01:16:49.220 --> 01:16:52.260]   So the thing to do is to edit the search results
[01:16:52.260 --> 01:16:55.660]   as opposed to bring down this blacklist site, for instance.
[01:16:55.660 --> 01:16:58.660]   - Yeah, so the point is is that the medical board
[01:16:58.660 --> 01:17:02.180]   found her to be the initial case said that she was negligent.
[01:17:02.180 --> 01:17:04.140]   Medical board later ruled that she wasn't,
[01:17:04.140 --> 01:17:05.940]   but she still listed on the site.
[01:17:05.940 --> 01:17:08.500]   - Then go to the site.
[01:17:08.500 --> 01:17:09.340]   - She can't.
[01:17:09.340 --> 01:17:10.180]   - Why?
[01:17:10.180 --> 01:17:11.020]   - In outside the jurisdiction.
[01:17:11.020 --> 01:17:14.860]   - Well, sorry lady, but this Google's job is not to make up
[01:17:14.860 --> 01:17:16.540]   for an inability.
[01:17:16.540 --> 01:17:19.540]   There's good reasons why you can't go and pull that site down.
[01:17:19.540 --> 01:17:21.060]   It's in a different country.
[01:17:21.060 --> 01:17:23.100]   Why should they go to Google?
[01:17:23.100 --> 01:17:24.900]   - You can't treat algorithms
[01:17:24.900 --> 01:17:29.660]   as if they're extra judicial or outside of politics
[01:17:29.660 --> 01:17:30.700]   or outside of the media.
[01:17:30.700 --> 01:17:32.220]   - That's not what they're saying.
[01:17:32.220 --> 01:17:33.220]   That's not what they're saying.
[01:17:33.220 --> 01:17:36.380]   They're saying you have to modify the algorithm.
[01:17:36.380 --> 01:17:41.340]   They're saying that the algorithm has to be responsible
[01:17:41.340 --> 01:17:44.140]   as opposed to merely reflecting what's on the internet.
[01:17:44.140 --> 01:17:44.980]   - Absolutely.
[01:17:44.980 --> 01:17:45.820]   - That's not what you want.
[01:17:45.820 --> 01:17:48.100]   The minute you do that, then every nation in the world
[01:17:48.100 --> 01:17:49.940]   comes to Google and says, well, we want it
[01:17:49.940 --> 01:17:52.260]   to reflect our point of view, our point of view.
[01:17:52.260 --> 01:17:53.540]   - And that's exactly what should happen.
[01:17:53.540 --> 01:17:54.380]   - It's untenable.
[01:17:54.380 --> 01:17:55.820]   - Algorithms are people.
[01:17:55.820 --> 01:17:56.660]   - Oh, you're completely nuts.
[01:17:56.660 --> 01:17:57.980]   - If a company can be a person.
[01:17:57.980 --> 01:17:59.340]   - You're completely nuts, Greg.
[01:17:59.340 --> 01:18:02.260]   - The people at the company make the algorithms,
[01:18:02.260 --> 01:18:04.900]   the algorithms are people and have to be treated as people.
[01:18:04.900 --> 01:18:07.220]   They have to be culpable and legally liable
[01:18:07.220 --> 01:18:08.500]   for anything that they do.
[01:18:08.500 --> 01:18:10.260]   And that's the only way we're going to move forward
[01:18:10.260 --> 01:18:12.020]   because that's how in medical science,
[01:18:12.020 --> 01:18:14.300]   when they do an operation, they test it,
[01:18:14.300 --> 01:18:16.620]   they validate it, it goes through a very long
[01:18:16.620 --> 01:18:19.300]   development process, and then it's gradually released
[01:18:19.300 --> 01:18:21.460]   to make sure that it delivers the result you expect.
[01:18:21.460 --> 01:18:23.540]   And now we've got these jumped up young kids
[01:18:23.540 --> 01:18:25.220]   in Silicon Valley, releasing algorithms
[01:18:25.220 --> 01:18:27.300]   that have these massive societal impacts.
[01:18:27.300 --> 01:18:29.020]   And then-- - You want to go back
[01:18:29.020 --> 01:18:30.500]   to the middle ages. - What's in my thought?
[01:18:30.500 --> 01:18:32.780]   It's just the opposite of the middle ages.
[01:18:32.780 --> 01:18:35.060]   What good is the internet if without a search engine
[01:18:35.060 --> 01:18:36.260]   that accurately reflects it?
[01:18:36.260 --> 01:18:38.460]   - If I had a car and it rolled down the street
[01:18:38.460 --> 01:18:40.620]   and smashed into five vehicles causing damage
[01:18:40.620 --> 01:18:43.420]   and ran over a family of five, who's a liable?
[01:18:43.420 --> 01:18:45.540]   - It's a little inept analogy.
[01:18:45.540 --> 01:18:46.380]   It has the-- - No, it's not.
[01:18:46.380 --> 01:18:47.220]   It's the same.
[01:18:47.220 --> 01:18:49.100]   It's an algorithm that just runs down the road
[01:18:49.100 --> 01:18:50.820]   and smashes in the car and runs over people.
[01:18:50.820 --> 01:18:52.380]   It's the same thing. - In fact, I think you can make
[01:18:52.380 --> 01:18:54.220]   a strong argument, Google should be required
[01:18:54.220 --> 01:18:56.020]   to accurately reflect the internet,
[01:18:56.020 --> 01:18:58.300]   otherwise it's editorializing.
[01:18:58.300 --> 01:18:59.780]   - 'Cause then you're going into libraries
[01:18:59.780 --> 01:19:01.380]   and ripping out the newspapers.
[01:19:01.380 --> 01:19:04.660]   Like a newspaper only ever had to issue a retraction.
[01:19:04.660 --> 01:19:08.220]   They didn't have to go and find every erroneous copy
[01:19:08.220 --> 01:19:10.140]   of their newspaper and burn it to the ground.
[01:19:10.140 --> 01:19:11.820]   - Yeah. - Yeah.
[01:19:11.820 --> 01:19:13.580]   - But that was insane. - It's insane.
[01:19:13.580 --> 01:19:15.500]   - Because that was insane. - It's insane.
[01:19:15.500 --> 01:19:18.220]   - If you start piece milling search engines,
[01:19:18.220 --> 01:19:20.620]   you're never gonna have a search engine.
[01:19:20.620 --> 01:19:22.460]   What you're asking for, Greg, is insane.
[01:19:22.460 --> 01:19:24.180]   It's not even doable.
[01:19:24.180 --> 01:19:25.260]   - It is doable.
[01:19:25.260 --> 01:19:26.860]   - Well, it's not. - Because Google does it.
[01:19:26.860 --> 01:19:28.620]   - They take all the code out.
[01:19:28.620 --> 01:19:31.060]   They take all the child abuse out, they take out.
[01:19:31.060 --> 01:19:32.580]   - I would make the argument-- - Anybody that they feel
[01:19:32.580 --> 01:19:34.260]   like, funnily enough, there are algorithms
[01:19:34.260 --> 01:19:35.860]   to do it on YouTube and-- - Big mistake.
[01:19:35.860 --> 01:19:37.140]   They should have never done that.
[01:19:37.140 --> 01:19:39.820]   I agree that Google opened, unfortunately,
[01:19:39.820 --> 01:19:42.580]   a can of worms when they started doing that.
[01:19:42.580 --> 01:19:44.540]   They shouldn't editorialize at all.
[01:19:44.540 --> 01:19:47.380]   They should attempt to make their algorithm accurately
[01:19:47.380 --> 01:19:48.700]   reflect what's on the internet.
[01:19:48.700 --> 01:19:51.340]   Snapchat and Twitter are all media companies.
[01:19:51.340 --> 01:19:52.860]   They choose what they publish.
[01:19:52.860 --> 01:19:54.500]   Now, just because it isn't a person--
[01:19:54.500 --> 01:19:55.820]   - That's where they made the mistake.
[01:19:55.820 --> 01:19:56.660]   They should never have done that.
[01:19:56.660 --> 01:19:58.980]   - The algorithm is a person and it publishes
[01:19:58.980 --> 01:20:00.820]   and it must be responsible and liable
[01:20:00.820 --> 01:20:02.140]   for the decisions it makes.
[01:20:02.140 --> 01:20:04.420]   - So what you're saying is that what we're gonna have
[01:20:04.420 --> 01:20:08.580]   is a search engine that editorializes constantly.
[01:20:08.580 --> 01:20:10.140]   - And that's what it already does.
[01:20:10.140 --> 01:20:11.340]   - Well, I don't think it already does.
[01:20:11.340 --> 01:20:12.180]   And I think you're pushing in the other direction.
[01:20:12.180 --> 01:20:13.820]   - It does, it already decides-- - It does some of it,
[01:20:13.820 --> 01:20:15.700]   which they should not have done.
[01:20:15.700 --> 01:20:17.420]   But now you're saying they should do more of it,
[01:20:17.420 --> 01:20:19.140]   which is absolutely insane.
[01:20:19.140 --> 01:20:20.260]   You're not-- - You have to hold
[01:20:20.260 --> 01:20:24.260]   these companies liable for the decisions of its algorithm
[01:20:24.260 --> 01:20:27.620]   because people made the company as a legal person.
[01:20:27.620 --> 01:20:30.180]   The algorithms were created by people.
[01:20:30.180 --> 01:20:32.060]   The algorithms act like people.
[01:20:32.060 --> 01:20:32.980]   They work with people.
[01:20:32.980 --> 01:20:34.340]   The algorithms are people.
[01:20:34.340 --> 01:20:36.180]   And the companies who produce these algorithms
[01:20:36.180 --> 01:20:38.020]   have to take responsibility for them
[01:20:38.020 --> 01:20:39.620]   and the outcomes that they produce.
[01:20:39.620 --> 01:20:40.620]   - So what do you have, Greg?
[01:20:40.620 --> 01:20:41.460]   - They must be-- - They must be scared.
[01:20:41.460 --> 01:20:42.380]   - In a world-- - Go ahead.
[01:20:42.380 --> 01:20:44.620]   - L of human knowledge though is just way too,
[01:20:44.620 --> 01:20:47.940]   there's no, it's not even conceivable to do it.
[01:20:47.940 --> 01:20:50.340]   I mean, there are a few things where they've tried
[01:20:50.340 --> 01:20:52.980]   and many would argue have failed
[01:20:52.980 --> 01:20:55.180]   and where they do try to do it.
[01:20:55.180 --> 01:20:59.580]   And they try to do it in countries like Iran and China.
[01:20:59.580 --> 01:21:02.140]   And some would argue that they're successful,
[01:21:02.140 --> 01:21:05.660]   but look at the ramifications of that.
[01:21:05.660 --> 01:21:08.820]   It is the societal ramifications of those things
[01:21:08.820 --> 01:21:13.820]   are significant and they stifle human creativity
[01:21:14.820 --> 01:21:16.300]   they stifle innovation.
[01:21:16.300 --> 01:21:20.020]   And it's barely possible even in those countries,
[01:21:20.020 --> 01:21:22.660]   to keep it from happening.
[01:21:22.660 --> 01:21:24.340]   - It's not Google's job to take down
[01:21:24.340 --> 01:21:26.660]   the dictatorship in Iran, that's your job.
[01:21:26.660 --> 01:21:29.820]   - So in that case, you think Google should go ahead
[01:21:29.820 --> 01:21:32.900]   with its censored search engine in China?
[01:21:32.900 --> 01:21:33.740]   - Yeah, absolutely.
[01:21:33.740 --> 01:21:34.580]   China is China.
[01:21:34.580 --> 01:21:37.180]   The politics in China, you have to respect the government
[01:21:37.180 --> 01:21:39.660]   of any country in the same way that I have to respect
[01:21:39.660 --> 01:21:43.060]   President Trump as the leader of the US nation.
[01:21:43.060 --> 01:21:45.220]   And he represents you like it or not.
[01:21:45.220 --> 01:21:47.820]   And in the same case that any other country in the world,
[01:21:47.820 --> 01:21:48.980]   it is not for Google or Facebook.
[01:21:48.980 --> 01:21:51.300]   - Would you say it's Google's job to remove this mention
[01:21:51.300 --> 01:21:54.740]   in the French surgeon from just the French search results
[01:21:54.740 --> 01:21:56.940]   or should they do it from all search results globally?
[01:21:56.940 --> 01:21:59.020]   - They just won that case recently, by the way.
[01:21:59.020 --> 01:21:59.860]   - I know.
[01:21:59.860 --> 01:22:01.700]   I'm just asking what Greg thinks.
[01:22:01.700 --> 01:22:04.780]   - Yeah, I think if the source has proven
[01:22:04.780 --> 01:22:06.660]   that something's wrong, then it should be taken down
[01:22:06.660 --> 01:22:07.500]   everywhere.
[01:22:07.500 --> 01:22:08.340]   - Everywhere.
[01:22:08.340 --> 01:22:09.660]   - Because the information is now false.
[01:22:09.660 --> 01:22:11.820]   - Now, you just put Google out of business
[01:22:11.820 --> 01:22:14.940]   and doing so destroyed the public internet.
[01:22:14.940 --> 01:22:17.260]   - But the public internet is only a reflection.
[01:22:17.260 --> 01:22:19.900]   Like the only reason the papers issued a retraction
[01:22:19.900 --> 01:22:21.900]   was because it was physically impossible
[01:22:21.900 --> 01:22:24.860]   to go and retract every newspaper and bring it back, right?
[01:22:24.860 --> 01:22:26.340]   - It's not physically impossible to do what you ask.
[01:22:26.340 --> 01:22:27.220]   - It's not that we don't want it.
[01:22:27.220 --> 01:22:30.420]   - But the end result is that you have a bowdlerized internet,
[01:22:30.420 --> 01:22:32.220]   which is a bunch of holes.
[01:22:32.220 --> 01:22:34.940]   And the only thing that exists on this so-called
[01:22:34.940 --> 01:22:37.140]   search engine is stuff that's approved
[01:22:37.140 --> 01:22:38.820]   by every nation in the world.
[01:22:38.820 --> 01:22:40.620]   What would that be?
[01:22:40.620 --> 01:22:42.020]   - It would be back to where we were
[01:22:42.020 --> 01:22:44.380]   before the internet came along.
[01:22:44.380 --> 01:22:46.060]   - That's what you want?
[01:22:46.060 --> 01:22:46.900]   - Why not?
[01:22:46.900 --> 01:22:48.100]   - Okay, so we're done with Greg.
[01:22:48.100 --> 01:22:48.940]   - Why not, right?
[01:22:48.940 --> 01:22:49.780]   So why not?
[01:22:49.780 --> 01:22:50.620]   What would be so bad?
[01:22:50.620 --> 01:22:53.020]   - I think you just, that's called reductio ad absurdum.
[01:22:53.020 --> 01:22:54.380]   You don't want an internet.
[01:22:54.380 --> 01:22:56.580]   - We would still have advanced search engines,
[01:22:56.580 --> 01:22:58.020]   content available on demand.
[01:22:58.020 --> 01:22:58.860]   - Oh, he wouldn't.
[01:22:58.860 --> 01:22:59.700]   - But there would be--
[01:22:59.700 --> 01:23:00.540]   - We would have any of that.
[01:23:00.540 --> 01:23:03.740]   - We would go back to Vore for the internet, you just said.
[01:23:03.740 --> 01:23:05.660]   - We would go back to the idea of content
[01:23:05.660 --> 01:23:09.180]   before the internet where each country saw its own view, right?
[01:23:09.180 --> 01:23:10.940]   And that's not entirely impressive.
[01:23:10.940 --> 01:23:13.100]   - Greg, you just paint yourself into a completely
[01:23:13.100 --> 01:23:14.180]   untenable corner.
[01:23:14.180 --> 01:23:15.020]   You understand that, right?
[01:23:15.020 --> 01:23:15.820]   - It's gonna happen.
[01:23:15.820 --> 01:23:16.660]   It's gonna happen.
[01:23:16.660 --> 01:23:18.340]   The EU, the EU, the EU are starting to start
[01:23:18.340 --> 01:23:19.180]   at that process, right?
[01:23:19.180 --> 01:23:20.020]   - That's a terrible thing.
[01:23:20.020 --> 01:23:22.500]   - And it's why I believe Google was right to get out
[01:23:22.500 --> 01:23:24.980]   of China and if Google has to get out of Europe,
[01:23:24.980 --> 01:23:26.340]   then they should.
[01:23:26.340 --> 01:23:28.740]   - To do that, then the solution would be the algorithms
[01:23:28.740 --> 01:23:31.260]   again because how are you gonna ever do a different
[01:23:31.260 --> 01:23:33.500]   internet for every country and every polity in the world?
[01:23:33.500 --> 01:23:35.740]   You'd have to rely on the algorithms.
[01:23:35.740 --> 01:23:37.540]   - I think we should go back to Yahoo,
[01:23:37.540 --> 01:23:40.620]   a human curated directory.
[01:23:40.620 --> 01:23:42.820]   - These companies have to be liable for these algorithms.
[01:23:42.820 --> 01:23:44.220]   They can't walk up and say,
[01:23:44.220 --> 01:23:45.060]   - I agree with you there.
[01:23:45.060 --> 01:23:47.020]   - Wasn't there, was the algorithm, right?
[01:23:47.020 --> 01:23:50.860]   - Let's take a time out and then we're gonna talk
[01:23:50.860 --> 01:23:52.180]   about foldable phones.
[01:23:52.180 --> 01:23:55.100]   Actually, I still wanna talk about Facebook's plan.
[01:23:55.100 --> 01:23:56.540]   According to the New York Times,
[01:23:56.540 --> 01:23:58.940]   this hasn't been confirmed by Facebook to integrate
[01:23:58.940 --> 01:24:00.860]   what's happens to Graham and Messenger
[01:24:00.860 --> 01:24:04.540]   and Mark Zuckerberg's editorial in the World Wall Street
[01:24:04.540 --> 01:24:07.300]   Journal saying, hands off.
[01:24:07.300 --> 01:24:09.700]   We're okay, we're the good guys.
[01:24:09.700 --> 01:24:14.100]   But first, let's take a little trip down memory lane.
[01:24:14.100 --> 01:24:16.060]   It's been an amazing week this week on Twitch
[01:24:16.060 --> 01:24:18.300]   and we've got a video to demonstrate that.
[01:24:18.300 --> 01:24:20.740]   - Previously on Twitch.
[01:24:20.740 --> 01:24:21.860]   - People are talking about...
[01:24:21.860 --> 01:24:23.580]   - Oh my God!
[01:24:23.580 --> 01:24:25.820]   (laughing)
[01:24:25.820 --> 01:24:28.100]   I don't think Snake's yawn, I think they measure.
[01:24:28.100 --> 01:24:29.580]   - No, I just saw it.
[01:24:29.580 --> 01:24:31.460]   - Yeah, but I think she was measuring.
[01:24:31.460 --> 01:24:34.380]   She said, "Can I get his head in my mouth?"
[01:24:34.380 --> 01:24:35.500]   - Windows Weekly.
[01:24:35.500 --> 01:24:39.180]   Windows 10 mobile will no longer be supported
[01:24:39.180 --> 01:24:40.740]   the operating system for Windows Phone
[01:24:40.740 --> 01:24:42.820]   as of December 10th of this year.
[01:24:42.820 --> 01:24:44.420]   The state's been known for awhile.
[01:24:44.420 --> 01:24:47.380]   Microsoft updated a support page
[01:24:47.380 --> 01:24:49.060]   and actually said on it,
[01:24:49.060 --> 01:24:52.980]   Microsoft is recommending users go to Android or iOS.
[01:24:52.980 --> 01:24:54.740]   This is kind of the final word, guys.
[01:24:54.740 --> 01:24:57.300]   They're giving you explicit written instructions.
[01:24:57.300 --> 01:25:00.540]   Don't wait around go to iOS or Android.
[01:25:00.540 --> 01:25:02.380]   - Right, all about Android.
[01:25:02.380 --> 01:25:05.620]   The Motorola Razr might be forced to make a comeback,
[01:25:05.620 --> 01:25:06.940]   but with a price tag of,
[01:25:06.940 --> 01:25:09.660]   and I hope that's right down, $1,500.
[01:25:09.660 --> 01:25:10.700]   - What?
[01:25:10.700 --> 01:25:13.180]   - And now a newly discovered patent
[01:25:13.180 --> 01:25:15.300]   that was filed on December 17th
[01:25:15.300 --> 01:25:20.300]   shows that the design could be a foldable screen inside
[01:25:20.300 --> 01:25:22.460]   with a second screen on the outside.
[01:25:22.460 --> 01:25:24.860]   I guess it is nothing better than hanging up on someone
[01:25:24.860 --> 01:25:25.700]   with a flip-up.
[01:25:25.700 --> 01:25:26.540]   - Oh yeah.
[01:25:26.540 --> 01:25:27.380]   - That is completely gone.
[01:25:27.380 --> 01:25:29.140]   And now you just go, hmm,
[01:25:29.140 --> 01:25:31.060]   and you just tap your screen.
[01:25:31.060 --> 01:25:32.820]   And it's not the same.
[01:25:32.820 --> 01:25:33.660]   - To it.
[01:25:33.660 --> 01:25:35.780]   Now, where'd I put my Android?
[01:25:35.780 --> 01:25:37.460]   (laughing)
[01:25:37.460 --> 01:25:40.260]   - The snake changed the page to being homeless
[01:25:40.260 --> 01:25:42.260]   is better than working for Amazon.
[01:25:42.260 --> 01:25:44.020]   - Who snakes are capacitive?
[01:25:44.020 --> 01:25:44.900]   Look at that.
[01:25:44.900 --> 01:25:45.940]   - Snake is capacitive.
[01:25:45.940 --> 01:25:47.260]   - Oh.
[01:25:47.260 --> 01:25:48.860]   - That's really interesting.
[01:25:48.860 --> 01:25:50.780]   Are you trying to make a political statement snake
[01:25:50.780 --> 01:25:53.060]   about homelessness in Amazon?
[01:25:53.060 --> 01:25:54.060]   - Wow.
[01:25:54.060 --> 01:25:56.060]   That was a very woke snake.
[01:25:56.060 --> 01:26:00.100]   I showed it to you, bro.
[01:26:00.100 --> 01:26:04.020]   - Frought to you by Eero, my Wi-Fi router.
[01:26:04.020 --> 01:26:05.020]   I love it.
[01:26:05.020 --> 01:26:07.780]   I think we all know that the old days
[01:26:07.780 --> 01:26:11.180]   of a single router somewhere in the living room
[01:26:11.180 --> 01:26:14.860]   talking to the whole house, those days, long gone.
[01:26:14.860 --> 01:26:17.300]   We're all using too many internet devices.
[01:26:17.300 --> 01:26:19.740]   We're all consuming too much content.
[01:26:19.740 --> 01:26:22.500]   You've got the kids watching YouTube in the bedroom,
[01:26:22.500 --> 01:26:25.100]   mom and dad watching Netflix in the living room.
[01:26:25.100 --> 01:26:26.860]   You've got Aunt Sally in the kitchen.
[01:26:26.860 --> 01:26:28.580]   She's trying to download recipes.
[01:26:28.580 --> 01:26:29.580]   It's crazy.
[01:26:30.060 --> 01:26:32.860]   That's why you need an Eero Enterprise grade Wi-Fi system
[01:26:32.860 --> 01:26:35.700]   in your home in just a few minutes.
[01:26:35.700 --> 01:26:38.420]   You download the Eero app on your iOS or Android device.
[01:26:38.420 --> 01:26:39.700]   It walks you through the process.
[01:26:39.700 --> 01:26:41.740]   You set up the base station
[01:26:41.740 --> 01:26:43.620]   and then you add the beacons
[01:26:43.620 --> 01:26:45.740]   and the app will help you place them.
[01:26:45.740 --> 01:26:48.180]   The beacons just plug into the wall.
[01:26:48.180 --> 01:26:50.820]   What I love about the Eero app is I can see how my network's
[01:26:50.820 --> 01:26:52.660]   doing, I can see how it's doing right now from here.
[01:26:52.660 --> 01:26:54.220]   I can see what devices are on it.
[01:26:54.220 --> 01:26:56.660]   I can pause individual devices
[01:26:56.660 --> 01:26:59.460]   or I can even say all of these devices,
[01:26:59.460 --> 01:27:01.540]   that belong to our teenager.
[01:27:01.540 --> 01:27:02.820]   It's after 10 at night.
[01:27:02.820 --> 01:27:04.620]   Let's turn those off.
[01:27:04.620 --> 01:27:08.260]   I use Eero Plus 2, which filters all the bad stuff out.
[01:27:08.260 --> 01:27:11.700]   Catcher's malware before it gets onto the computer.
[01:27:11.700 --> 01:27:14.540]   State of the RWA2 protection, Eero's already announced.
[01:27:14.540 --> 01:27:17.660]   They'll be going to WPA3 and they say they can do it
[01:27:17.660 --> 01:27:18.820]   in software, which is awesome.
[01:27:18.820 --> 01:27:21.100]   That's why it's so cool to have an Eero
[01:27:21.100 --> 01:27:23.180]   because an Eero is upgraded constantly.
[01:27:23.180 --> 01:27:24.940]   It gets better all the time.
[01:27:24.940 --> 01:27:26.180]   It's always secure.
[01:27:26.180 --> 01:27:27.980]   You don't have to remember to update it.
[01:27:27.980 --> 01:27:29.220]   It updates automatically.
[01:27:29.220 --> 01:27:30.620]   Not only do you have the latest features,
[01:27:30.620 --> 01:27:33.340]   you have the latest security at all times.
[01:27:33.340 --> 01:27:36.140]   And I have to say, when I first got the Eero,
[01:27:36.140 --> 01:27:38.500]   I had some questions and I called them up
[01:27:38.500 --> 01:27:39.340]   and they were great.
[01:27:39.340 --> 01:27:40.500]   They stayed on the line with me
[01:27:40.500 --> 01:27:43.220]   until I got the port forwarding work and all the stuff.
[01:27:43.220 --> 01:27:45.860]   Eero's Eero Plus is actually the thing
[01:27:45.860 --> 01:27:46.780]   that put me over the top.
[01:27:46.780 --> 01:27:48.300]   So we've had the Eros for a while.
[01:27:48.300 --> 01:27:50.300]   In fact, I got the new Eero system when they came out
[01:27:50.300 --> 01:27:51.300]   and set my old system.
[01:27:51.300 --> 01:27:53.220]   I set it up for my mom.
[01:27:53.220 --> 01:27:55.300]   She's loving her Eros.
[01:27:55.300 --> 01:28:00.300]   Eero Plus is a simple reliable security layer
[01:28:00.300 --> 01:28:03.140]   that defends your home devices against malware,
[01:28:03.140 --> 01:28:07.140]   spyware, phishing attacks, and of course, unsuitable content.
[01:28:07.140 --> 01:28:09.820]   That's why Michael is not seeing anything adult
[01:28:09.820 --> 01:28:11.860]   because it's filtered off.
[01:28:11.860 --> 01:28:13.580]   The combination of Eero and Eero Plus
[01:28:13.580 --> 01:28:15.460]   gives you complete protection for your network,
[01:28:15.460 --> 01:28:18.220]   your devices for the people who use them.
[01:28:18.220 --> 01:28:20.460]   Eero Plus offers the ability to block malicious
[01:28:20.460 --> 01:28:22.660]   and unwanted content across the entire network.
[01:28:22.660 --> 01:28:23.500]   I do that.
[01:28:23.500 --> 01:28:24.860]   I have that turned on.
[01:28:24.860 --> 01:28:27.020]   By checking the sites you visit against a database
[01:28:27.020 --> 01:28:29.060]   of millions of known threats, Eero Plus prevents you
[01:28:29.060 --> 01:28:30.820]   from accidentally visiting malicious sites
[01:28:30.820 --> 01:28:32.220]   without slowing anything down.
[01:28:32.220 --> 01:28:35.100]   It automatically tags sites that contain
[01:28:35.100 --> 01:28:36.940]   violent illegal or adult content.
[01:28:36.940 --> 01:28:39.380]   You choose what your kids can and cannot visit
[01:28:39.380 --> 01:28:41.300]   right in the Eero app.
[01:28:41.300 --> 01:28:44.140]   I see everything I know everything from the Eero app.
[01:28:44.140 --> 01:28:46.380]   How much bandwidth each device uses?
[01:28:46.380 --> 01:28:47.420]   That's fascinating.
[01:28:47.420 --> 01:28:51.980]   I could do port forwarding, I could do reservations.
[01:28:51.980 --> 01:28:53.300]   I just think Eero's great.
[01:28:53.300 --> 01:28:56.020]   And man, no more dead spots, no more buffering.
[01:28:56.020 --> 01:28:58.060]   It really works.
[01:28:58.060 --> 01:28:59.500]   Never think about Wi-Fi again.
[01:28:59.500 --> 01:29:00.700]   You'll get $100.
[01:29:00.700 --> 01:29:01.780]   This is a great deal.
[01:29:01.780 --> 01:29:05.540]   $100 off the base unit two beacons package.
[01:29:05.540 --> 01:29:07.020]   That's the starting point.
[01:29:07.020 --> 01:29:09.260]   Plus a year of Eero Plus
[01:29:09.260 --> 01:29:11.940]   by visiting Eero.com/twit.
[01:29:11.940 --> 01:29:15.340]   E-E-R-O.com/twit for 100 bucks off the base package
[01:29:15.340 --> 01:29:16.620]   plus a year of Eero Plus.
[01:29:16.620 --> 01:29:19.620]   Eero.com/twit.
[01:29:19.620 --> 01:29:22.020]   E-E-R-O.com/twit.
[01:29:22.020 --> 01:29:23.660]   And don't forget to check out
[01:29:23.660 --> 01:29:26.340]   with the offer code twit to get that special offer.
[01:29:26.340 --> 01:29:28.420]   I know you've been suffering with your Wi-Fi
[01:29:28.420 --> 01:29:31.260]   suffer no longer with Eero.
[01:29:31.260 --> 01:29:32.500]   This is like the rest.
[01:29:32.500 --> 01:29:34.060]   Mesh with us.
[01:29:34.060 --> 01:29:38.940]   Dude, that story about the Razer phone,
[01:29:38.940 --> 01:29:41.220]   that would explain a $1,500 price tag
[01:29:41.220 --> 01:29:42.660]   if it had a foldable,
[01:29:42.660 --> 01:29:44.460]   this is not the phone they'd be talking about.
[01:29:44.460 --> 01:29:45.740]   This is the old Razer,
[01:29:45.740 --> 01:29:48.340]   which everybody had, I'm sure all you guys had these.
[01:29:48.340 --> 01:29:51.380]   I think it's kind of an interesting idea.
[01:29:51.380 --> 01:29:53.580]   So let's talk about foldable phones.
[01:29:53.580 --> 01:29:55.340]   There's one already available.
[01:29:55.340 --> 01:29:58.020]   They were at CES, the Royal.
[01:29:58.020 --> 01:29:58.860]   Yep.
[01:29:58.860 --> 01:30:00.500]   Did you see that at CES?
[01:30:00.500 --> 01:30:03.620]   Yeah, and seen it just published an article today
[01:30:03.620 --> 01:30:05.020]   called "Foldable Phones Are Real."
[01:30:05.020 --> 01:30:07.460]   Here's everyone we know about,
[01:30:07.460 --> 01:30:10.620]   which is a great look at everything that's there
[01:30:10.620 --> 01:30:15.340]   and coming the Royal FlexPay is the first one on the list.
[01:30:15.340 --> 01:30:16.300]   And then of course, you know,
[01:30:16.300 --> 01:30:20.100]   Samsung Galaxy Huawei this week, Xiaomi this week.
[01:30:20.100 --> 01:30:23.420]   We saw the Xiaomi CEO and a Twitter,
[01:30:23.420 --> 01:30:25.300]   now he said that was a concept phone,
[01:30:25.300 --> 01:30:26.420]   but that was a trip ticket,
[01:30:26.420 --> 01:30:30.100]   a tri-fold phone that the two wings folded back.
[01:30:30.100 --> 01:30:32.620]   Boy, that's wild.
[01:30:32.620 --> 01:30:33.780]   There it is, there's the video.
[01:30:33.780 --> 01:30:34.620]   Yeah.
[01:30:34.620 --> 01:30:37.460]   I mean, I love the concept on this.
[01:30:37.460 --> 01:30:38.300]   Do you want this?
[01:30:38.300 --> 01:30:40.020]   Do you think this is a good thing?
[01:30:40.020 --> 01:30:42.620]   No, this is partly why I wanted to talk about it.
[01:30:42.620 --> 01:30:44.300]   I'm not saying it's a bad thing,
[01:30:44.300 --> 01:30:48.020]   but I'm still trying to wrap my head around why I'd want it
[01:30:48.020 --> 01:30:49.860]   and not really why I'd want the ones
[01:30:49.860 --> 01:30:51.700]   that are probably gonna come out in 2018
[01:30:51.700 --> 01:30:54.980]   because those I don't think many of us really want.
[01:30:54.980 --> 01:30:58.140]   - I'm worried that they're gonna be janky.
[01:30:58.140 --> 01:30:59.060]   I mean, I-
[01:30:59.060 --> 01:30:59.900]   - Exactly.
[01:30:59.900 --> 01:31:01.020]   - How many times can you bend that screen
[01:31:01.020 --> 01:31:04.460]   before it starts showing where on the hinge, right?
[01:31:04.460 --> 01:31:07.260]   - It's also really thick and, you know,
[01:31:07.260 --> 01:31:09.220]   although we've liked bigger phones,
[01:31:09.220 --> 01:31:11.780]   it's sort of the bigger phone thing
[01:31:11.780 --> 01:31:13.420]   has been a little weird
[01:31:13.420 --> 01:31:17.700]   and counterintuitive over the past few years.
[01:31:17.700 --> 01:31:20.500]   I think thicker is not something people want,
[01:31:20.500 --> 01:31:22.780]   you know, that just try to stick in your pocket,
[01:31:22.780 --> 01:31:26.380]   something like that is not very practical.
[01:31:26.380 --> 01:31:29.020]   - No, when it's winter.
[01:31:29.020 --> 01:31:32.140]   - Yeah, when Samsung showed its foldable phone
[01:31:32.140 --> 01:31:33.780]   in the kind of the sneak peak,
[01:31:33.780 --> 01:31:35.860]   and of course we're gonna find out more on February 20th
[01:31:35.860 --> 01:31:37.220]   when they have their event,
[01:31:37.220 --> 01:31:38.740]   it looked pretty thick, but he said,
[01:31:38.740 --> 01:31:40.780]   oh, this is in a special case.
[01:31:40.780 --> 01:31:42.300]   So it's hard to say.
[01:31:42.300 --> 01:31:44.460]   Yeah, if thicker is not gonna solve anything.
[01:31:45.860 --> 01:31:50.540]   - No, but if I had a phone the size of my fablet today,
[01:31:50.540 --> 01:31:51.380]   - Right.
[01:31:51.380 --> 01:31:56.380]   - And then somehow it also could kind of like
[01:31:56.380 --> 01:32:01.980]   the Xiaomi prototype piece.
[01:32:01.980 --> 01:32:04.580]   If somehow it could, you know,
[01:32:04.580 --> 01:32:07.580]   the screen could essentially double itself.
[01:32:07.580 --> 01:32:10.220]   When I was ready to sit down and read something
[01:32:10.220 --> 01:32:13.460]   or do some work or do some bigger typing or whatever,
[01:32:13.460 --> 01:32:16.020]   I mean, they've been an insatiable appetite
[01:32:16.020 --> 01:32:17.820]   for big screen phones, right?
[01:32:17.820 --> 01:32:20.140]   'Cause they are more productive.
[01:32:20.140 --> 01:32:23.140]   You can do more things with them once you have more screen.
[01:32:23.140 --> 01:32:25.660]   And so this is like the fablet run amok
[01:32:25.660 --> 01:32:29.300]   that this whole idea of the folding phone
[01:32:29.300 --> 01:32:31.860]   is really an extension of the fablet phenomenon.
[01:32:31.860 --> 01:32:34.020]   And I'm just trying to wonder
[01:32:34.020 --> 01:32:37.020]   and this is why I'm sort of throwing it out to you all
[01:32:37.020 --> 01:32:39.460]   of like, what does that give me?
[01:32:39.460 --> 01:32:42.700]   Just assuming we get to that world where today's,
[01:32:42.700 --> 01:32:47.700]   you know, fablet, you know, this one or this one
[01:32:47.700 --> 01:32:50.860]   can double its screen size.
[01:32:50.860 --> 01:32:53.860]   How compelling is that?
[01:32:53.860 --> 01:32:57.500]   - It's obviously doubling the screen size
[01:32:57.500 --> 01:32:59.300]   when you need it or want it, right?
[01:32:59.300 --> 01:33:01.300]   And it almost goes back to the argument
[01:33:01.300 --> 01:33:03.500]   of iPod versus cell phones.
[01:33:03.500 --> 01:33:05.620]   So why not make them both the same?
[01:33:05.620 --> 01:33:10.220]   So why have a tablet and a smartphone?
[01:33:10.220 --> 01:33:11.420]   That's the most obvious thing.
[01:33:11.420 --> 01:33:13.500]   But you know what, here's the reality.
[01:33:13.500 --> 01:33:17.260]   Forget about what we would maybe have a use for it is.
[01:33:17.260 --> 01:33:19.940]   The reason these are coming is because no one's been able
[01:33:19.940 --> 01:33:22.900]   to differentiate a phone for at least five years now.
[01:33:22.900 --> 01:33:23.740]   - Right.
[01:33:23.740 --> 01:33:26.180]   - They all look exactly identical.
[01:33:26.180 --> 01:33:27.540]   And so guess what?
[01:33:27.540 --> 01:33:31.300]   I bet people are gonna have a reasonable amount of success
[01:33:31.300 --> 01:33:32.860]   because people are gonna be like, you know what?
[01:33:32.860 --> 01:33:36.700]   Look at me, I have the one phone in my friend circle
[01:33:36.700 --> 01:33:38.900]   that looks different than all y'all's phones.
[01:33:39.860 --> 01:33:41.620]   - Why don't they make it a triangular phone?
[01:33:41.620 --> 01:33:43.020]   - That's a fashion aspect.
[01:33:43.020 --> 01:33:44.940]   And I think that's very important,
[01:33:44.940 --> 01:33:46.660]   not necessarily in the US,
[01:33:46.660 --> 01:33:50.780]   but in some cultures phones are status items.
[01:33:50.780 --> 01:33:53.780]   And if you've got a unique item,
[01:33:53.780 --> 01:33:56.260]   that actually is part of a cultural status thing
[01:33:56.260 --> 01:33:58.540]   where you wanna be able to show off that you've got that.
[01:33:58.540 --> 01:34:01.100]   I believe that to be the case in certain parts of China
[01:34:01.100 --> 01:34:03.300]   and other places in Asia.
[01:34:03.300 --> 01:34:05.300]   - So maybe those are your status object
[01:34:05.300 --> 01:34:07.300]   as opposed to something useful.
[01:34:07.300 --> 01:34:08.140]   - That's right.
[01:34:08.140 --> 01:34:10.060]   - Something that only lasts for six to 12 months
[01:34:10.060 --> 01:34:12.660]   before you move on to something else,
[01:34:12.660 --> 01:34:14.700]   you know, fashion type item.
[01:34:14.700 --> 01:34:16.580]   And Apple's been trying to sell phones
[01:34:16.580 --> 01:34:19.060]   as fashion accessories for some time.
[01:34:19.060 --> 01:34:24.060]   - It's kind of the size of my paper planner, right?
[01:34:24.060 --> 01:34:25.300]   (laughs)
[01:34:25.300 --> 01:34:26.140]   - I think so.
[01:34:26.140 --> 01:34:27.780]   - It opens up and look, it's foldable,
[01:34:27.780 --> 01:34:28.980]   I got a big screen.
[01:34:28.980 --> 01:34:32.220]   - And the second part is that for some people,
[01:34:32.220 --> 01:34:33.780]   smartphones are their computers
[01:34:33.780 --> 01:34:36.980]   and indeed a television and a book.
[01:34:36.980 --> 01:34:40.340]   And if you want something that does all of those things,
[01:34:40.340 --> 01:34:41.780]   then perhaps there's a trade off there.
[01:34:41.780 --> 01:34:45.140]   So this is a case of, I think, testing the market
[01:34:45.140 --> 01:34:48.300]   to see if the idea can latch catch on.
[01:34:48.300 --> 01:34:50.500]   And if it does, they can then iterate around it.
[01:34:50.500 --> 01:34:52.140]   So again, I'm gonna make a prediction.
[01:34:52.140 --> 01:34:53.260]   - And we've seen those up.
[01:34:53.260 --> 01:34:55.380]   - We're not gonna see a single foldable phone
[01:34:55.380 --> 01:34:57.140]   at next year's CES, not one.
[01:34:57.140 --> 01:35:00.100]   - What's gonna be like 3D TV,
[01:35:00.100 --> 01:35:02.860]   it's just gonna disappear without a trace,
[01:35:02.860 --> 01:35:04.900]   maybe a few bubbles, that's it.
[01:35:04.900 --> 01:35:05.740]   Go ahead, Brian.
[01:35:05.740 --> 01:35:07.620]   - There's been a lot of wagers that going on here.
[01:35:07.620 --> 01:35:09.260]   So I don't know, Leo, I don't know
[01:35:09.260 --> 01:35:10.580]   that I like that one at all.
[01:35:10.580 --> 01:35:11.420]   - You like that one?
[01:35:11.420 --> 01:35:12.220]   - It's gonna be one of foldable,
[01:35:12.220 --> 01:35:13.620]   who here wants a foldable phone?
[01:35:13.620 --> 01:35:14.460]   - I don't.
[01:35:14.460 --> 01:35:15.300]   - No.
[01:35:15.300 --> 01:35:16.140]   - Have you seen those articles though,
[01:35:16.140 --> 01:35:21.060]   about how in the Indian cell phone market,
[01:35:21.060 --> 01:35:24.340]   that I can't remember, boy, you know.
[01:35:24.340 --> 01:35:26.500]   But the amount of hours that they spend on video,
[01:35:26.500 --> 01:35:29.200]   the point that Greg just made about how,
[01:35:29.200 --> 01:35:32.740]   like so if it's your entertainment devices,
[01:35:32.740 --> 01:35:35.060]   if this is how you are consuming
[01:35:35.060 --> 01:35:37.060]   all of your entertainment and your media,
[01:35:37.060 --> 01:35:39.460]   so that then it fits in your pocket
[01:35:39.460 --> 01:35:41.660]   and you do your daily business.
[01:35:41.660 --> 01:35:44.900]   And then at night, I'm not saying it replaces your TV,
[01:35:44.900 --> 01:35:46.220]   but you maybe live in a country
[01:35:46.220 --> 01:35:48.700]   where you don't have a big screen TV or whatever.
[01:35:48.700 --> 01:35:52.100]   Like so, why wouldn't you wanna unfold this thing
[01:35:52.100 --> 01:35:52.980]   and have a bigger screen?
[01:35:52.980 --> 01:35:53.820]   There's a lot of reasons.
[01:35:53.820 --> 01:35:56.820]   - What happens if your house is just a room?
[01:35:56.820 --> 01:35:57.660]   - Right.
[01:35:57.660 --> 01:35:58.500]   - Right.
[01:35:58.500 --> 01:36:00.460]   - Well, in fact, it's Japan,
[01:36:00.460 --> 01:36:03.900]   before smartphones even, they've had,
[01:36:03.900 --> 01:36:06.420]   because that's a big issue in Japan,
[01:36:06.420 --> 01:36:08.820]   larger phones that did a lot more, right?
[01:36:08.820 --> 01:36:09.860]   Am I wrong on that?
[01:36:09.860 --> 01:36:11.620]   That was a very popular,
[01:36:11.620 --> 01:36:14.940]   pre-smartphone product in Japan.
[01:36:14.940 --> 01:36:19.660]   - I think it's also to do with the use of emojis
[01:36:19.660 --> 01:36:23.500]   and the characters instead of using letters
[01:36:23.500 --> 01:36:25.740]   like we do the use spectograms.
[01:36:25.740 --> 01:36:28.420]   So the larger screens, as I understand it,
[01:36:28.420 --> 01:36:30.860]   and please, I don't wanna pretend that I'm an expert here,
[01:36:30.860 --> 01:36:33.300]   but from what I've researched and read
[01:36:33.300 --> 01:36:35.220]   is that they tend to go for the larger screens
[01:36:35.220 --> 01:36:39.340]   'cause it makes more sense for the local conditions.
[01:36:39.340 --> 01:36:42.980]   - Yeah, look at these images of cell phones from Japan
[01:36:42.980 --> 01:36:44.860]   and you'll get some idea.
[01:36:44.860 --> 01:36:50.500]   They all have extra display capabilities.
[01:36:50.500 --> 01:36:52.900]   - Those were the ones that for years we would see
[01:36:52.900 --> 01:36:55.180]   and everyone was trying to sell us on mobile computing
[01:36:55.180 --> 01:36:58.140]   and then all of us were like, we don't want that.
[01:36:58.140 --> 01:36:59.500]   - Right, yeah.
[01:36:59.500 --> 01:37:02.580]   - That's 'cause we were entering data with T19.
[01:37:02.580 --> 01:37:04.820]   - Right, the O2O, I remember that too, yeah.
[01:37:04.820 --> 01:37:07.380]   - Today you can do a lot more with voice.
[01:37:07.380 --> 01:37:08.820]   Some people are turning to voice
[01:37:08.820 --> 01:37:10.820]   as an alternative to the keyboard
[01:37:10.820 --> 01:37:12.700]   and a lot of people have gotten better
[01:37:12.700 --> 01:37:13.900]   with the alpha numerics,
[01:37:13.900 --> 01:37:16.420]   like that touch sensitive screens make more sense.
[01:37:16.420 --> 01:37:17.940]   So I think there is some transition there.
[01:37:17.940 --> 01:37:20.500]   There's no innovation as such, just a transition
[01:37:20.500 --> 01:37:22.900]   as we do make marginal improvements on them.
[01:37:22.900 --> 01:37:25.980]   - This is 2009, these phones were.
[01:37:25.980 --> 01:37:28.620]   - Leo, this could be innovation is what I'm saying.
[01:37:28.620 --> 01:37:30.900]   Like I'm with you in the sense that
[01:37:30.900 --> 01:37:33.140]   it's probably unreliable right now or whatever,
[01:37:33.140 --> 01:37:36.380]   but like are you saying that it wouldn't be innovation
[01:37:36.380 --> 01:37:39.060]   to have different screen sizes
[01:37:39.060 --> 01:37:42.340]   depending on when you needed it and your use case?
[01:37:42.340 --> 01:37:43.860]   - Let me think about that.
[01:37:43.860 --> 01:37:48.460]   So there's some conditions, obviously it can't be thick.
[01:37:48.460 --> 01:37:50.260]   So if it's not much bigger,
[01:37:50.260 --> 01:37:51.780]   if it's something like an existing phone.
[01:37:51.780 --> 01:37:53.860]   - First if we can get there, if we don't fold.
[01:37:53.860 --> 01:37:56.260]   - Yeah, yeah, yeah, yeah, I agree with that.
[01:37:56.260 --> 01:37:58.500]   So the first generation probably wonky.
[01:37:58.500 --> 01:38:00.820]   And this is based on AMOLED screens
[01:38:00.820 --> 01:38:03.460]   that can reliably bend and unbend
[01:38:03.460 --> 01:38:09.500]   without damage and showing wear of any kind, okay.
[01:38:09.500 --> 01:38:12.580]   - There's some ergonomics up.
[01:38:12.580 --> 01:38:14.900]   - I don't see myself opening it up to be honest with you.
[01:38:14.900 --> 01:38:19.900]   I feel like a Galaxy Note 9 or the iPhone XS Max,
[01:38:19.900 --> 01:38:22.940]   that's fine, that gets the job done.
[01:38:22.940 --> 01:38:26.260]   Maybe I'm just not open-minded enough.
[01:38:27.460 --> 01:38:32.460]   That's kind of, so there's also ergonomic issues with them too.
[01:38:32.460 --> 01:38:34.100]   I don't know if ergonomic is the right way to say it,
[01:38:34.100 --> 01:38:36.220]   but you know how with tablets.
[01:38:36.220 --> 01:38:37.220]   - Usability issues, yeah.
[01:38:37.220 --> 01:38:38.940]   - Yeah, usability, thank you.
[01:38:38.940 --> 01:38:41.860]   You know those tablets where you flip them over
[01:38:41.860 --> 01:38:44.620]   and when you have to hold them
[01:38:44.620 --> 01:38:47.020]   and you feel the keys on the back, I hate that.
[01:38:47.020 --> 01:38:47.860]   - I hate that too.
[01:38:47.860 --> 01:38:48.700]   - I hate that.
[01:38:48.700 --> 01:38:49.540]   - I hate that. - I hate that.
[01:38:49.540 --> 01:38:50.500]   - I have a yoga, I have a Lenovo Yoga,
[01:38:50.500 --> 01:38:53.060]   and I never do that for that reason.
[01:38:53.060 --> 01:38:56.540]   - I can either, I can't stand any ergonomics
[01:38:56.540 --> 01:38:57.780]   that you end up doing that.
[01:38:57.780 --> 01:39:01.260]   And I feel like that's my worry with these foldable phones.
[01:39:01.260 --> 01:39:03.780]   If this thing folded over and then okay,
[01:39:03.780 --> 01:39:07.260]   I'm always holding it where I've got the screen is on the back,
[01:39:07.260 --> 01:39:10.020]   but it's not on unless I flip it over.
[01:39:10.020 --> 01:39:11.260]   It's like I'm not gonna like that.
[01:39:11.260 --> 01:39:15.420]   I know because of the ways that these tablets do that.
[01:39:15.420 --> 01:39:18.420]   - I'm gonna stand by my prediction that this is,
[01:39:18.420 --> 01:39:22.100]   you're exactly right, this is an industry that's desperate
[01:39:22.100 --> 01:39:25.380]   for something new and different, some differentiator.
[01:39:25.380 --> 01:39:27.940]   And so they're gonna throw a lot of spaghetti against the wall.
[01:39:27.940 --> 01:39:32.060]   This is a noodle that's gonna flop back down.
[01:39:32.060 --> 01:39:35.420]   - Maybe they've spent so much money developing foldable screens
[01:39:35.420 --> 01:39:38.340]   that desperate to find a place to recover that money.
[01:39:38.340 --> 01:39:42.140]   Do you remember the curved screen?
[01:39:42.140 --> 01:39:45.060]   Did you see any curved screens at CES?
[01:39:45.060 --> 01:39:48.420]   I have a curved screen Samsung at home, it's dopey.
[01:39:48.420 --> 01:39:51.220]   - You have to sit in the exact middle of it, right?
[01:39:51.220 --> 01:39:54.500]   - All it succeeds in doing is making the reflections
[01:39:54.500 --> 01:39:56.300]   on the window go farther.
[01:39:56.300 --> 01:39:57.300]   (laughs)
[01:39:57.300 --> 01:39:59.020]   - Yeah, there's some curved screen monitors,
[01:39:59.020 --> 01:40:00.700]   like computer monitors, because you're always
[01:40:00.700 --> 01:40:01.540]   sitting in the middle of those.
[01:40:01.540 --> 01:40:02.380]   - That makes sense.
[01:40:02.380 --> 01:40:03.860]   Yeah, that makes sense. - Perfect sense, yep.
[01:40:03.860 --> 01:40:04.700]   - Perfect sense.
[01:40:04.700 --> 01:40:06.780]   On a TV, it makes no sense at all.
[01:40:06.780 --> 01:40:08.500]   - There were guys that were rarely sitting in the middle.
[01:40:08.500 --> 01:40:11.500]   - Do you guys have CESPTSD?
[01:40:11.500 --> 01:40:13.860]   - That may be, I did not go this year,
[01:40:13.860 --> 01:40:16.700]   but I was told there were no curved screens.
[01:40:16.700 --> 01:40:18.860]   Not, you're right for computer monitors,
[01:40:18.860 --> 01:40:20.420]   but there weren't any curved TVs.
[01:40:20.420 --> 01:40:21.500]   - That's right.
[01:40:21.500 --> 01:40:24.540]   That was a good example of a differentiator
[01:40:24.540 --> 01:40:26.500]   that didn't take off.
[01:40:26.500 --> 01:40:28.860]   - But yeah, but TVs, I mean, you know, like you said,
[01:40:28.860 --> 01:40:30.380]   3D TVs, all that stuff.
[01:40:30.380 --> 01:40:32.860]   TVs are a different kettle fish.
[01:40:32.860 --> 01:40:34.460]   And by the way, I'm not sold on this at all,
[01:40:34.460 --> 01:40:35.300]   and I don't want you to think
[01:40:35.300 --> 01:40:36.980]   that I'm arguing for this because I want one
[01:40:36.980 --> 01:40:40.420]   so desperately bad, but I can see that--
[01:40:40.420 --> 01:40:41.980]   - There might be some potential here, yeah.
[01:40:41.980 --> 01:40:43.740]   - Maybe it's just because I'm tired
[01:40:43.740 --> 01:40:46.100]   of seeing the same old dumb stuff for five years
[01:40:46.100 --> 01:40:49.020]   that I kind of want something new to happen
[01:40:49.020 --> 01:40:50.860]   in the smartphone space.
[01:40:50.860 --> 01:40:53.460]   - Actually, that's one of our stories is that
[01:40:53.460 --> 01:40:55.900]   we're kind of, we've reached peak phone.
[01:40:55.900 --> 01:40:57.540]   - Sure.
[01:40:57.540 --> 01:40:58.700]   - And that it's all gonna get weird now,
[01:40:58.700 --> 01:41:02.020]   as everybody desperately tries to find something.
[01:41:02.020 --> 01:41:04.980]   - 48 megapixels this week, that just came out, right?
[01:41:04.980 --> 01:41:07.140]   - Phone's become too boring.
[01:41:07.140 --> 01:41:08.460]   Well, they're about to get weird.
[01:41:08.460 --> 01:41:11.260]   I think, honestly, the phone's gonna stay the way it is
[01:41:11.260 --> 01:41:14.900]   and that wearables, and it's not around the corner.
[01:41:14.900 --> 01:41:18.780]   It's gonna be five years off, but wearables are the future.
[01:41:18.780 --> 01:41:21.060]   - Well, an internet of things, right?
[01:41:21.060 --> 01:41:23.300]   The internet of things is gonna take a lot of these things
[01:41:23.300 --> 01:41:27.700]   that are in the phone today and move it off of the phone
[01:41:27.700 --> 01:41:30.980]   to other parts of the ecosystem.
[01:41:30.980 --> 01:41:33.180]   - Does 5G change this the fact that we,
[01:41:33.180 --> 01:41:35.620]   if this ever, another thing that may or not happen,
[01:41:35.620 --> 01:41:36.460]   what do you think, Greg?
[01:41:36.460 --> 01:41:38.160]   Is 5G gonna happen next year?
[01:41:38.160 --> 01:41:40.900]   - No, it's gonna start.
[01:41:40.900 --> 01:41:43.340]   It'll be a slow, gradual rollout,
[01:41:43.340 --> 01:41:45.980]   probably five to 15 years.
[01:41:45.980 --> 01:41:47.220]   - What? - Depending on where you are
[01:41:47.220 --> 01:41:48.740]   in the world. - That long?
[01:41:49.420 --> 01:41:52.140]   - Oh, yes, they haven't even finished the 5G standard yet.
[01:41:52.140 --> 01:41:53.700]   - I'll be dead by then. - And so you won't see
[01:41:53.700 --> 01:41:54.540]   any perch it.
[01:41:54.540 --> 01:41:56.580]   (laughing)
[01:41:56.580 --> 01:41:58.500]   - Holy yeah. - And in terms of
[01:41:58.500 --> 01:42:00.260]   what 5G delivered. - Well, I mean,
[01:42:00.260 --> 01:42:03.100]   in my actuality, I probably will be, I'm just saying.
[01:42:03.100 --> 01:42:05.140]   - And really, the only thing 5G's gonna give you
[01:42:05.140 --> 01:42:06.860]   is more bandwidth.
[01:42:06.860 --> 01:42:08.140]   - So that's it. - That's it.
[01:42:08.140 --> 01:42:10.140]   But now don't dismiss that because--
[01:42:10.140 --> 01:42:11.900]   - Slowly, you see more things on the network.
[01:42:11.900 --> 01:42:13.620]   - More bandwidth is gonna give you, yeah.
[01:42:13.620 --> 01:42:16.220]   - Yeah, it does, it does can change things.
[01:42:16.220 --> 01:42:19.220]   You didn't have, until high speed internet
[01:42:19.220 --> 01:42:21.380]   was widely available in homes, you didn't have Netflix,
[01:42:21.380 --> 01:42:23.460]   you didn't have any of this, right?
[01:42:23.460 --> 01:42:25.620]   This is, it does change things.
[01:42:25.620 --> 01:42:28.060]   - Yes, bandwidth has, the key thing
[01:42:28.060 --> 01:42:29.900]   that people miss about bandwidth is it has
[01:42:29.900 --> 01:42:32.260]   two key scientific properties.
[01:42:32.260 --> 01:42:35.860]   One is volume, how much you can fit down the pipe.
[01:42:35.860 --> 01:42:37.660]   And the second one is speed.
[01:42:37.660 --> 01:42:40.220]   So yes, greater bandwidth, not only let you put
[01:42:40.220 --> 01:42:44.300]   more down the pipe, it also lets you put the traffic
[01:42:44.300 --> 01:42:45.900]   down the pipe faster, right?
[01:42:45.900 --> 01:42:49.140]   So yes, you do get improved speed, latency,
[01:42:49.140 --> 01:42:51.220]   you also get more capacity.
[01:42:51.220 --> 01:42:52.580]   So whenever you talk about bandwidth,
[01:42:52.580 --> 01:42:54.580]   two vector argument, not a single vector argument,
[01:42:54.580 --> 01:42:55.420]   which is-- - It's a good point,
[01:42:55.420 --> 01:42:56.260]   that's a good point.
[01:42:56.260 --> 01:42:57.100]   - We are often things-- - I don't know.
[01:42:57.100 --> 01:42:59.780]   I mean, in Europe, 4G was so mean to you guys in Europe,
[01:42:59.780 --> 01:43:02.180]   I think that maybe you're under as many as 5G.
[01:43:02.180 --> 01:43:04.300]   - He's bitter. - Yeah, yeah.
[01:43:04.300 --> 01:43:06.780]   - Well, one, a couple of old-- - I do think--
[01:43:06.780 --> 01:43:07.780]   - Go ahead.
[01:43:07.780 --> 01:43:10.060]   - So 5G, there are many things about 5G
[01:43:10.060 --> 01:43:11.500]   that the telcos want to have.
[01:43:11.500 --> 01:43:14.300]   They want to be able to take the idea of bandwidth
[01:43:14.300 --> 01:43:17.140]   and sell it as services and create more revenue
[01:43:17.140 --> 01:43:19.700]   for themselves or find a way to differentiate themselves.
[01:43:19.700 --> 01:43:22.020]   They don't want to become electricity companies.
[01:43:22.020 --> 01:43:24.700]   So a lot of what you read about this is telcos going,
[01:43:24.700 --> 01:43:26.860]   "Oh, if we could do this, we could build a service
[01:43:26.860 --> 01:43:27.860]   "that charges more money.
[01:43:27.860 --> 01:43:30.300]   "If we could do that, we could do that."
[01:43:30.300 --> 01:43:33.460]   Or we could-- and I think just like 4G,
[01:43:33.460 --> 01:43:35.300]   we saw all the things that they're doing now.
[01:43:35.300 --> 01:43:36.140]   - What actually is-- - Quibi.
[01:43:36.140 --> 01:43:36.980]   - Yeah. - Short form.
[01:43:36.980 --> 01:43:39.820]   - Sorry, I just went to the next story.
[01:43:39.820 --> 01:43:40.980]   - That's okay.
[01:43:40.980 --> 01:43:42.460]   - So actually it's creepy. - So actually it's creepy.
[01:43:42.460 --> 01:43:46.020]   - Ultimately, the real factor in the consumer market
[01:43:46.020 --> 01:43:48.860]   is just going to be more banned within more places
[01:43:48.860 --> 01:43:51.380]   at about the same price as we pay for it today.
[01:43:51.380 --> 01:43:52.820]   And there are some possibilities
[01:43:52.820 --> 01:43:54.620]   that we might see some differentiation elsewhere.
[01:43:54.620 --> 01:43:56.660]   - Self-driving vehicles. - And lower latency too.
[01:43:56.660 --> 01:43:58.100]   - 5G. - Lower latency.
[01:43:58.100 --> 01:44:00.540]   - Lower latency is important for if you're driving a car
[01:44:00.540 --> 01:44:02.380]   and cars are communicating to one another.
[01:44:02.380 --> 01:44:06.780]   - They won't do any of those things.
[01:44:06.780 --> 01:44:08.060]   Cars have to be autonomous.
[01:44:08.060 --> 01:44:09.460]   They can't communicate with each other.
[01:44:09.460 --> 01:44:11.460]   - They can't communicate with each other.
[01:44:11.460 --> 01:44:13.020]   - Well, they-- - That's one of the chief benefits
[01:44:13.020 --> 01:44:14.620]   of autonomous vehicles.
[01:44:14.620 --> 01:44:16.780]   - Yeah, but if they start to communicate with each other,
[01:44:16.780 --> 01:44:18.820]   you can't guarantee that you're going to get data
[01:44:18.820 --> 01:44:21.260]   from the neighboring car, so you can't rely on that.
[01:44:21.260 --> 01:44:22.900]   What if the neighboring car is not compatible
[01:44:22.900 --> 01:44:24.660]   with your standard or it's faulty in some way?
[01:44:24.660 --> 01:44:26.580]   - But it's not that what 5G is promising, right?
[01:44:26.580 --> 01:44:27.860]   That's what I've been sold.
[01:44:27.860 --> 01:44:31.540]   - That, and that is absolutely a load of bunk.
[01:44:31.540 --> 01:44:34.780]   There's not one autonomous car maker that cares about 5G.
[01:44:34.780 --> 01:44:38.380]   Only the 5G people care about autonomous cars
[01:44:38.380 --> 01:44:40.380]   because they think they can sell them
[01:44:40.380 --> 01:44:42.300]   at a premium enhanced service.
[01:44:42.300 --> 01:44:44.980]   And none of the car makers are talking to the 5G people
[01:44:44.980 --> 01:44:46.540]   about using that service.
[01:44:46.540 --> 01:44:49.100]   - I mean, it's not bunk, it's just one of those visions
[01:44:49.100 --> 01:44:54.100]   that has a lot of steps that have to be dealt with
[01:44:54.100 --> 01:44:58.740]   before the reality is there.
[01:44:58.740 --> 01:44:59.940]   But-- - It's a fault, it's a fault.
[01:44:59.940 --> 01:45:01.900]   - You know, the combination of edge computing.
[01:45:01.900 --> 01:45:05.060]   - A lot of people talk about the end of traffic congestion
[01:45:05.060 --> 01:45:07.580]   because you have cars that communicate with one another,
[01:45:07.580 --> 01:45:09.460]   you get to a four-way stop,
[01:45:09.460 --> 01:45:11.340]   the cars know which one should go first.
[01:45:11.340 --> 01:45:14.380]   You're saying a car needs to be a standalone,
[01:45:14.380 --> 01:45:16.580]   you know, an island,
[01:45:16.580 --> 01:45:18.820]   but I think there is a lot to be said for cars
[01:45:18.820 --> 01:45:20.540]   that communicate with one another, right?
[01:45:20.540 --> 01:45:21.540]   - One of the biggest-- - What's your intent?
[01:45:21.540 --> 01:45:24.180]   We don't, we have to infer what the intent of the guy ahead
[01:45:24.180 --> 01:45:25.380]   of us and the guy behind us is,
[01:45:25.380 --> 01:45:28.780]   but a car could theoretically query other vehicles, right?
[01:45:28.780 --> 01:45:30.660]   - So one of the biggest things that happened at CES
[01:45:30.660 --> 01:45:35.660]   and very quietly was Qualcomm has this technology
[01:45:35.660 --> 01:45:39.260]   called Vehicle to Everything.
[01:45:39.260 --> 01:45:42.140]   It's C2VX.
[01:45:42.140 --> 01:45:47.140]   It is a standard that combines vehicle to vehicle
[01:45:47.140 --> 01:45:51.900]   and vehicle to infrastructure technology.
[01:45:51.900 --> 01:45:54.140]   Ford came on stage and said,
[01:45:54.140 --> 01:45:56.700]   "We're gonna put this across our entire range of vehicles
[01:45:56.700 --> 01:45:58.660]   in 2022."
[01:45:58.660 --> 01:45:59.900]   Which means if Ford does it,
[01:45:59.900 --> 01:46:03.060]   the others are gonna follow and do the same.
[01:46:03.060 --> 01:46:08.060]   So this enables literally vehicles to see around corners, right?
[01:46:08.420 --> 01:46:13.420]   There are 1.3 million auto deaths globally every year still,
[01:46:13.420 --> 01:46:17.540]   which, you know, when we look back a long time from now,
[01:46:17.540 --> 01:46:19.220]   it's gonna be pretty fine to us.
[01:46:19.220 --> 01:46:20.660]   - Oh, terrible, yeah.
[01:46:20.660 --> 01:46:24.180]   - That we just, that we've lived with this every year.
[01:46:24.180 --> 01:46:27.340]   So this technology, the vehicles can talk to the roads,
[01:46:27.340 --> 01:46:28.660]   the vehicles can talk to buildings,
[01:46:28.660 --> 01:46:30.260]   the vehicles can talk to other vehicles,
[01:46:30.260 --> 01:46:31.180]   they can talk to lights,
[01:46:31.180 --> 01:46:33.380]   they can talk to stop signs, they can talk to all of it.
[01:46:33.380 --> 01:46:36.060]   So, you know, literally you can see around corner,
[01:46:36.060 --> 01:46:41.060]   about to go through a light or a stop sign that's green,
[01:46:41.060 --> 01:46:42.900]   sorry, a light that's green,
[01:46:42.900 --> 01:46:45.380]   somebody else has a red light coming,
[01:46:45.380 --> 01:46:47.340]   but you can't see 'em because of the building
[01:46:47.340 --> 01:46:48.820]   and they're about to run that red light
[01:46:48.820 --> 01:46:49.860]   and then they're gonna T-bone you
[01:46:49.860 --> 01:46:51.740]   and you know, those side impact accidents
[01:46:51.740 --> 01:46:53.820]   are the ones that are most fatal.
[01:46:53.820 --> 01:46:57.260]   Well, with the roads, you know, communicating with you
[01:46:57.260 --> 01:46:58.420]   with the building communicating,
[01:46:58.420 --> 01:47:00.580]   perhaps even the other car communicating,
[01:47:00.580 --> 01:47:05.340]   that is what enables that car to then stop
[01:47:05.340 --> 01:47:08.460]   and not get hit by that vehicle.
[01:47:08.460 --> 01:47:10.500]   - And imagine, I mean, isn't that kind of in a way,
[01:47:10.500 --> 01:47:12.540]   the promise of IOT in general is,
[01:47:12.540 --> 01:47:15.020]   as computing moves to the edge,
[01:47:15.020 --> 01:47:16.740]   communication's gonna be vital,
[01:47:16.740 --> 01:47:20.620]   the ability for all of these smart entities in our life
[01:47:20.620 --> 01:47:23.380]   to communicate rapidly and effectively with one another.
[01:47:23.380 --> 01:47:25.380]   I agree with you, Greg, we've gotta get a standard,
[01:47:25.380 --> 01:47:26.940]   but it looks like this is one stand.
[01:47:26.940 --> 01:47:28.300]   - Yeah, there's a lot of work.
[01:47:28.300 --> 01:47:30.100]   I'm not belittling what Greg's saying
[01:47:30.100 --> 01:47:32.260]   because there's a lot of work that needs to be done
[01:47:32.260 --> 01:47:34.180]   before any of these things happen.
[01:47:34.180 --> 01:47:39.180]   But I do think that the possibility
[01:47:39.180 --> 01:47:44.180]   is not pie in the sky or something that's not possible.
[01:47:44.180 --> 01:47:45.580]   - And there are, as you point out,
[01:47:45.580 --> 01:47:48.740]   very significant benefits, 1.3 million deaths.
[01:47:48.740 --> 01:47:50.500]   - So let me give you a hypothetical.
[01:47:50.500 --> 01:47:52.940]   You're in regional Australia,
[01:47:52.940 --> 01:47:55.280]   you're 500 kilometers from the nearest town.
[01:47:55.280 --> 01:47:57.860]   What's 5G gonna do for you?
[01:47:57.860 --> 01:48:02.580]   - Well, if you're in the Amazon jungle too,
[01:48:02.580 --> 01:48:05.540]   but given the fact that the vast majority of urban--
[01:48:05.540 --> 01:48:06.380]   - You're in a stuff that--
[01:48:06.380 --> 01:48:07.220]   - The vast majority of urban--
[01:48:07.220 --> 01:48:08.060]   - The 5G network suddenly--
[01:48:08.060 --> 01:48:10.420]   - You can bring up those kinds of goofy counter examples,
[01:48:10.420 --> 01:48:12.160]   but the majority of Earth's populations
[01:48:12.160 --> 01:48:15.740]   live in big urban centers where there's real value.
[01:48:15.740 --> 01:48:17.740]   - There's places where there's no electricity.
[01:48:17.740 --> 01:48:18.740]   - Right, right.
[01:48:18.740 --> 01:48:20.580]   - You're gonna use local Wi-Fi
[01:48:20.580 --> 01:48:22.220]   or local communication systems.
[01:48:22.220 --> 01:48:23.900]   They're gonna be a micro cell.
[01:48:23.900 --> 01:48:27.460]   And it's not gonna belong to the local traffic company
[01:48:27.460 --> 01:48:29.580]   or the local traffic agency or the town
[01:48:29.580 --> 01:48:31.660]   or whoever operates the traffic lights.
[01:48:31.660 --> 01:48:34.540]   It's not going to be part of the 5G network.
[01:48:34.540 --> 01:48:36.300]   Why would I pay a telco to run this?
[01:48:36.300 --> 01:48:38.260]   I can just do it in my traffic light
[01:48:38.260 --> 01:48:40.220]   with an antenna on top.
[01:48:40.220 --> 01:48:41.060]   - Sure.
[01:48:41.060 --> 01:48:42.580]   I mean, and the future networks
[01:48:42.580 --> 01:48:45.340]   are likely a combination of,
[01:48:45.340 --> 01:48:47.220]   5G's gonna cover a lot more places
[01:48:47.220 --> 01:48:48.860]   with a lot better bandwidth,
[01:48:48.860 --> 01:48:51.060]   much cheaper, much more cheaply.
[01:48:51.060 --> 01:48:54.580]   But, part of the future too
[01:48:54.580 --> 01:48:57.940]   is gonna be combinations of still things like white spaces
[01:48:57.940 --> 01:49:00.180]   and other types of technology
[01:49:00.180 --> 01:49:02.060]   where we still have a lot of work to do
[01:49:02.060 --> 01:49:04.300]   on some of this last mile.
[01:49:04.300 --> 01:49:06.180]   - All of these things that they're talking about in 5G,
[01:49:06.180 --> 01:49:08.700]   we have with 4G, they were gonna talk about small cells,
[01:49:08.700 --> 01:49:11.540]   they were gonna talk about mobile base stations
[01:49:11.540 --> 01:49:14.020]   and blah, blah, blah, and none of them turned up.
[01:49:14.020 --> 01:49:15.700]   So, and there's no reason to think
[01:49:15.700 --> 01:49:17.940]   that anything changed this time around.
[01:49:17.940 --> 01:49:19.580]   - I wouldn't say none of them changed.
[01:49:19.580 --> 01:49:24.460]   I think the 3G to 4G bump was, you know,
[01:49:24.460 --> 01:49:27.460]   3 to 5X speed bump that was meaningful,
[01:49:27.460 --> 01:49:30.940]   that led to new businesses that nobody ever anticipated
[01:49:30.940 --> 01:49:32.940]   before, you know, that jump happened.
[01:49:32.940 --> 01:49:34.980]   And, you know, with 4G to 5G,
[01:49:34.980 --> 01:49:37.940]   we're talking of 10X to 100X bump.
[01:49:37.940 --> 01:49:40.300]   And so, that's gonna enable all kinds of--
[01:49:40.300 --> 01:49:41.740]   - Yeah, no, no, I've already agreed with you
[01:49:41.740 --> 01:49:43.620]   that bandwidth gives us better speed
[01:49:43.620 --> 01:49:45.980]   and better volume and better latency, right?
[01:49:45.980 --> 01:49:49.100]   Because bandwidth is a function of speed and capacity.
[01:49:49.100 --> 01:49:50.740]   But, the point is, is that other people
[01:49:50.740 --> 01:49:52.660]   are trying to sell us network slicing
[01:49:52.660 --> 01:49:55.140]   or value added services around small cells
[01:49:55.140 --> 01:49:56.060]   or localized cells.
[01:49:56.060 --> 01:49:58.140]   Now, that's gonna give you greater coverage
[01:49:58.140 --> 01:50:00.460]   inside of a building and increase the bandwidth.
[01:50:00.460 --> 01:50:03.500]   But the only thing it all does is increases the bandwidth.
[01:50:03.500 --> 01:50:07.620]   It doesn't suddenly give the radio waves magical powers
[01:50:07.620 --> 01:50:10.020]   to read your mind or something like that.
[01:50:10.020 --> 01:50:13.100]   It's just-- - Great, one thing I will agree
[01:50:13.100 --> 01:50:16.540]   with you 100% on is I cannot imagine
[01:50:16.540 --> 01:50:18.500]   how much we've had to suffer
[01:50:18.500 --> 01:50:22.340]   because the telecos refuse, they rage, rage, rage
[01:50:22.340 --> 01:50:24.380]   against this idea that they're just dumb pipes.
[01:50:24.380 --> 01:50:25.780]   - Yeah, they don't wanna be a lie.
[01:50:25.780 --> 01:50:28.460]   Maybe we have to suffer before they learn that last year.
[01:50:28.460 --> 01:50:29.300]   - Yeah.
[01:50:29.300 --> 01:50:31.380]   - Well, hopefully, if you, as long as you guys
[01:50:31.380 --> 01:50:33.940]   stop boosting 5G, then that'll be where they go.
[01:50:33.940 --> 01:50:35.300]   (laughing)
[01:50:35.300 --> 01:50:36.540]   - Oh, it's our fault.
[01:50:36.540 --> 01:50:37.820]   Oh, you blame us too.
[01:50:37.820 --> 01:50:40.260]   - It's not pretending 5G is anything but electricity
[01:50:40.260 --> 01:50:41.900]   because that's what it is.
[01:50:41.900 --> 01:50:45.980]   - Zuckerberg, according to the Friday, New York Times,
[01:50:45.980 --> 01:50:50.060]   that's interesting how they give the credit to Zuckerberg.
[01:50:50.060 --> 01:50:52.780]   Zuckerberg plans to integrate WhatsApp, Instagram,
[01:50:52.780 --> 01:50:54.420]   and Facebook Messenger app.
[01:50:54.420 --> 01:50:56.340]   - I thought that was super interesting too.
[01:50:56.340 --> 01:50:59.140]   - Yeah, why don't they say Facebook?
[01:50:59.140 --> 01:51:00.740]   - Weird.
[01:51:00.740 --> 01:51:05.740]   - Anyway, this is Mike Isaac who's well sourced,
[01:51:05.740 --> 01:51:07.660]   San Francisco writer for other New York Times.
[01:51:07.660 --> 01:51:09.020]   - Even though that's weird, Leo.
[01:51:09.020 --> 01:51:09.820]   - Why?
[01:51:09.820 --> 01:51:13.900]   - Because, remember, the whole idea is this year,
[01:51:13.900 --> 01:51:17.180]   all of these founders left Facebook,
[01:51:17.180 --> 01:51:19.460]   Instagram, WhatsApp founders.
[01:51:19.460 --> 01:51:22.860]   And we always read that it was because there were clashes.
[01:51:22.860 --> 01:51:23.940]   - With Zuck.
[01:51:23.940 --> 01:51:27.740]   - And right, and they didn't want their products
[01:51:27.740 --> 01:51:28.900]   integrated in this way.
[01:51:28.900 --> 01:51:30.660]   They didn't want to join the Borg.
[01:51:30.660 --> 01:51:35.380]   And so either that's a leak from someone that's going
[01:51:35.380 --> 01:51:36.980]   after Zuck. - Ah, you're right.
[01:51:36.980 --> 01:51:41.820]   - Or, that's a ER that is, Zuck is, you know what?
[01:51:41.820 --> 01:51:43.780]   I'm gonna own this. - I'm in charge here.
[01:51:43.780 --> 01:51:44.620]   - Exactly.
[01:51:44.620 --> 01:51:45.460]   - Yeah.
[01:51:45.460 --> 01:51:47.220]   - The move has the potential to redefine how billions
[01:51:47.220 --> 01:51:48.940]   of people use the apps to connect with one another
[01:51:48.940 --> 01:51:52.420]   while strengthening Facebook's grip on users' rights, Mike,
[01:51:52.420 --> 01:51:54.620]   raising antitrust privacy and security questions.
[01:51:54.620 --> 01:51:56.980]   And also, this is the key sentence,
[01:51:56.980 --> 01:52:00.660]   underscores how Mr. Zuckerberg is imposing his authority
[01:52:00.660 --> 01:52:03.460]   over units he once vowed to leave alone.
[01:52:03.460 --> 01:52:04.820]   - So, like a brother.
[01:52:04.820 --> 01:52:05.660]   - Yeah.
[01:52:05.660 --> 01:52:06.500]   - Yeah.
[01:52:06.500 --> 01:52:07.700]   - I think that's a very powerful point,
[01:52:07.700 --> 01:52:10.140]   but the anti-trust is the big one.
[01:52:10.140 --> 01:52:12.100]   I think, yeah, Zuckerberg is moving
[01:52:12.100 --> 01:52:13.740]   so that he can't be broken up because--
[01:52:13.740 --> 01:52:15.060]   - Well, one member of Congress tweeted,
[01:52:15.060 --> 01:52:18.060]   "This is exactly why we should have paid closer attention
[01:52:18.060 --> 01:52:20.620]   to the WhatsApp and Instagram acquisitions
[01:52:20.620 --> 01:52:23.140]   because in fact, that's exactly what's gonna happen
[01:52:23.140 --> 01:52:27.580]   is this consolidation and Facebook's gonna be totally dominant."
[01:52:27.580 --> 01:52:29.580]   - There's no way Facebook could do an acquisition
[01:52:29.580 --> 01:52:31.740]   in the next 18 months, a major one.
[01:52:31.740 --> 01:52:34.140]   - I disagree 'cause I think it's a climate--
[01:52:34.140 --> 01:52:35.980]   I think we're in a climate now where,
[01:52:35.980 --> 01:52:38.540]   if you're gonna do it, do it now.
[01:52:38.540 --> 01:52:39.380]   - Oh, right.
[01:52:39.380 --> 01:52:42.820]   - The US government has other fish to fry, so to speak.
[01:52:42.820 --> 01:52:43.980]   - But what would they buy?
[01:52:43.980 --> 01:52:45.100]   What's worth buying?
[01:52:45.100 --> 01:52:46.340]   - Anything that's a threat.
[01:52:46.340 --> 01:52:48.700]   - Nothing at this point.
[01:52:48.700 --> 01:52:49.540]   - Nothing at this point.
[01:52:49.540 --> 01:52:50.660]   (laughing)
[01:52:50.660 --> 01:52:52.860]   - Maybe they're big enough they don't need to.
[01:52:52.860 --> 01:52:54.780]   - Yeah, pretty much, I think too much that they could buy.
[01:52:54.780 --> 01:52:56.740]   I mean, they could go and buy what's left of Yahoo
[01:52:56.740 --> 01:52:57.580]   from Verizon.
[01:52:57.580 --> 01:53:00.060]   - Tick tock, if something comes along that's,
[01:53:00.060 --> 01:53:01.420]   it poses a threat.
[01:53:01.420 --> 01:53:03.220]   If something's got a large user base,
[01:53:03.220 --> 01:53:04.420]   that's what they've done, basically.
[01:53:04.420 --> 01:53:07.020]   Each of these services has billions of users
[01:53:07.020 --> 01:53:07.900]   if you combine them.
[01:53:07.900 --> 01:53:10.900]   And by the way, this is not confirmed by Facebook.
[01:53:10.900 --> 01:53:14.900]   This is Mike's reporting, but if that happens,
[01:53:14.900 --> 01:53:17.540]   that you'd be have a behemoth now of users.
[01:53:17.540 --> 01:53:18.380]   - I think--
[01:53:18.380 --> 01:53:19.860]   - By the way, this is good for users.
[01:53:19.860 --> 01:53:22.460]   I would be thrilled if I could use WhatsApp
[01:53:22.460 --> 01:53:23.940]   to talk to Facebook Messenger
[01:53:23.940 --> 01:53:25.900]   and use Instagram to talk to WhatsApp.
[01:53:25.900 --> 01:53:26.740]   But that's a good thing.
[01:53:26.740 --> 01:53:29.420]   - We need to be clear, they're not combining the apps.
[01:53:29.420 --> 01:53:31.340]   - No, they're combining the infrastructure.
[01:53:31.340 --> 01:53:32.740]   - Right, exactly. - Talk to each other.
[01:53:32.740 --> 01:53:33.820]   - Yeah, fair enough.
[01:53:33.820 --> 01:53:36.540]   - And by the way, another good thing for end users,
[01:53:36.540 --> 01:53:38.020]   Zuck, according to this article,
[01:53:38.020 --> 01:53:40.740]   is gonna insist on end-to-end encryption for all three.
[01:53:40.740 --> 01:53:43.380]   That's a good thing. - Maybe.
[01:53:43.380 --> 01:53:45.300]   - Yeah, and that in face of Australia and others,
[01:53:45.300 --> 01:53:46.140]   you say you can't do it.
[01:53:46.140 --> 01:53:48.100]   - But he's also, so what you're saying there is,
[01:53:48.100 --> 01:53:49.820]   you gotta remember too, that Facebook Messenger
[01:53:49.820 --> 01:53:53.140]   has end-to-end encryption, but it's not safe
[01:53:53.140 --> 01:53:55.620]   or private encryption, it's just end-to-end encryption.
[01:53:55.620 --> 01:53:57.500]   - Yeah, Facebook still has access to the keys
[01:53:57.500 --> 01:53:59.900]   as does WhatsApp. - Yes, right.
[01:53:59.900 --> 01:54:01.500]   - Yeah, but WhatsApp is actually end-to-end,
[01:54:01.500 --> 01:54:03.860]   so that Facebook can't get into the message.
[01:54:03.860 --> 01:54:07.020]   - So Facebook doesn't have WhatsApp keys?
[01:54:07.020 --> 01:54:08.980]   - No, can't get into the data or WhatsApp.
[01:54:08.980 --> 01:54:10.460]   So that's why they can't monetize it
[01:54:10.460 --> 01:54:11.460]   and put ads against it.
[01:54:11.460 --> 01:54:14.940]   So the fear is, it's not that Facebook Messenger
[01:54:14.940 --> 01:54:17.620]   will come up to a better level of encryption.
[01:54:17.620 --> 01:54:18.460]   - Yeah, they're not. - More likely
[01:54:18.460 --> 01:54:19.340]   they're gonna take the WhatsApp
[01:54:19.340 --> 01:54:21.140]   and take it down to Facebook.
[01:54:21.140 --> 01:54:22.460]   And that also sells a few things,
[01:54:22.460 --> 01:54:24.700]   'cause the give to the governments might be,
[01:54:24.700 --> 01:54:26.620]   "Oh, Mr. Government, we're merging them together.
[01:54:26.620 --> 01:54:28.580]   "Please don't, Andy, trust us and break us up."
[01:54:28.580 --> 01:54:30.460]   - You'll have a better view inside the content.
[01:54:30.460 --> 01:54:32.020]   - Yeah. - We will give you legal
[01:54:32.020 --> 01:54:33.660]   intercept, legal and lawful intercept.
[01:54:33.660 --> 01:54:35.700]   - Sure, there you go. - And if they did that,
[01:54:35.700 --> 01:54:38.060]   then the governments are gonna be like, "Ooh."
[01:54:38.060 --> 01:54:39.860]   But as I, I told my daughters,
[01:54:39.860 --> 01:54:41.420]   I was talking to my daughters about this today,
[01:54:41.420 --> 01:54:44.940]   and they just went like, "We just stopped using Snapchat."
[01:54:44.940 --> 01:54:48.180]   Sorry, we just stopped using WhatsApp and Instagram
[01:54:48.180 --> 01:54:50.100]   and found something else.
[01:54:50.100 --> 01:54:53.660]   - Yeah, I think that this is a step toward them,
[01:54:53.660 --> 01:54:56.080]   trying to bring them together, clearly.
[01:54:56.080 --> 01:54:59.940]   And the number one reason behind it is likely
[01:54:59.940 --> 01:55:04.300]   because Facebook is just dead in the water
[01:55:04.300 --> 01:55:05.500]   with people under 30.
[01:55:05.500 --> 01:55:09.580]   And WhatsApp and Instagram are not.
[01:55:09.580 --> 01:55:14.300]   But Facebook, to all of those users,
[01:55:14.300 --> 01:55:15.820]   they're allergic to Facebook, right?
[01:55:15.820 --> 01:55:19.580]   Facebook is the network that my parents
[01:55:19.580 --> 01:55:22.340]   and my uncles and aunts and grandmas on, right?
[01:55:22.340 --> 01:55:25.220]   And so they don't want to be there,
[01:55:25.220 --> 01:55:28.660]   I think to the point that I think if you do,
[01:55:28.660 --> 01:55:31.380]   that the users will flee and go somewhere else.
[01:55:31.380 --> 01:55:36.380]   And that's what, you know, Facebook as a brand
[01:55:36.380 --> 01:55:38.980]   is essentially already a ticking time bomb
[01:55:38.980 --> 01:55:42.060]   because new users and young users.
[01:55:42.060 --> 01:55:45.660]   Which is why the time bomb, not just with its younger users,
[01:55:45.660 --> 01:55:47.420]   but also with government regulation,
[01:55:47.420 --> 01:55:49.300]   which is why Mark Zuckerberg wrote
[01:55:49.300 --> 01:55:51.980]   this Wall Street Journal opinion piece,
[01:55:51.980 --> 01:55:53.900]   the facts about Facebook.
[01:55:53.900 --> 01:55:55.980]   (all laughing)
[01:55:55.980 --> 01:55:59.500]   - Did you see Kara Swish's version of this?
[01:55:59.500 --> 01:56:00.620]   - No, what'd you say?
[01:56:00.620 --> 01:56:02.220]   - Oh, let me look it up.
[01:56:02.220 --> 01:56:04.580]   - We need your information for operation and security,
[01:56:04.580 --> 01:56:08.260]   but you control whether we use it for advertising.
[01:56:08.260 --> 01:56:10.660]   People consistently tell us, right, Mark,
[01:56:10.660 --> 01:56:11.820]   that if they're going to see ads,
[01:56:11.820 --> 01:56:13.700]   they want them to be relevant.
[01:56:13.700 --> 01:56:17.420]   That means we need to understand their interests.
[01:56:17.420 --> 01:56:20.540]   And you know, we don't sell that to anybody
[01:56:20.540 --> 01:56:23.220]   because well, that's how we make money.
[01:56:23.220 --> 01:56:26.060]   We have a strong incentive to protect people's information
[01:56:26.060 --> 01:56:28.500]   from being accessed by anyone else.
[01:56:28.500 --> 01:56:29.660]   They don't do a very good job of it,
[01:56:29.660 --> 01:56:31.540]   but we have a strong incentive of it.
[01:56:31.540 --> 01:56:35.220]   What do you think of, this is obviously aimed
[01:56:35.220 --> 01:56:39.820]   at both governmental regulators in the US and in Europe.
[01:56:39.820 --> 01:56:41.620]   - Right, because now number one,
[01:56:41.620 --> 01:56:43.820]   he's not going to publish this in the New York Times
[01:56:43.820 --> 01:56:45.660]   because he hates the New York Times now.
[01:56:45.660 --> 01:56:47.420]   But number two, everyone at Davos
[01:56:47.420 --> 01:56:49.420]   is more likely to read it in the Wall Street Journal.
[01:56:49.420 --> 01:56:51.260]   - Davos!
[01:56:51.260 --> 01:56:55.020]   - And then, so then this ties into what we were just talking
[01:56:55.020 --> 01:56:58.420]   about is because if he sees regulation coming
[01:56:58.420 --> 01:57:00.740]   and he's working the refs,
[01:57:00.740 --> 01:57:03.220]   and then you can do the old Microsoft thing of like,
[01:57:03.220 --> 01:57:05.340]   well, a year from now, if you try to have me
[01:57:05.340 --> 01:57:07.820]   break off Instagram or whatever, like as we're saying,
[01:57:07.820 --> 01:57:11.420]   oh no, they're all one code base.
[01:57:11.420 --> 01:57:13.940]   We can't do that, they're completely integral.
[01:57:13.940 --> 01:57:14.940]   But here's the other thing,
[01:57:14.940 --> 01:57:16.580]   and I'm gonna totally quote the person
[01:57:16.580 --> 01:57:18.460]   that turned me onto this.
[01:57:18.460 --> 01:57:20.780]   Sarah Fryer said that, remember,
[01:57:20.780 --> 01:57:25.260]   Zuck still likes the real identity part of social media.
[01:57:25.260 --> 01:57:27.700]   - Which I do too, be honest with you.
[01:57:27.700 --> 01:57:30.060]   - And well, but also if you're selling ads
[01:57:30.060 --> 01:57:31.220]   against someone's real life--
[01:57:31.220 --> 01:57:32.060]   - Yeah, it's a lot easier.
[01:57:32.060 --> 01:57:32.900]   - Yeah.
[01:57:32.900 --> 01:57:34.900]   Twitter doesn't know who the hell you are, right?
[01:57:34.900 --> 01:57:38.060]   - So, okay, number one, this solves a lot of problems, right?
[01:57:38.060 --> 01:57:42.020]   So, number one, governments were being nice
[01:57:42.020 --> 01:57:42.860]   and blah, blah, blah.
[01:57:42.860 --> 01:57:45.860]   And also, by the time you actually bring the hammer down
[01:57:45.860 --> 01:57:47.580]   on us, our code base is unified,
[01:57:47.580 --> 01:57:50.060]   and also it's easier for advertisers,
[01:57:50.060 --> 01:57:51.820]   they don't have to spend on several different platforms,
[01:57:51.820 --> 01:57:52.900]   it's one platform. - Right.
[01:57:52.900 --> 01:57:55.420]   - But then that's the bottom line,
[01:57:55.420 --> 01:57:59.780]   is that he's chopping off, as we know,
[01:57:59.780 --> 01:58:03.660]   he bought the threats to his business, okay?
[01:58:03.660 --> 01:58:05.820]   But it's still not the pure business.
[01:58:05.820 --> 01:58:08.540]   So, if Facebook, as was just being said,
[01:58:08.540 --> 01:58:11.740]   is not where the kids are at, or where the growth is at,
[01:58:11.740 --> 01:58:14.700]   or whatever, the problem that they still needed to solve
[01:58:14.700 --> 01:58:19.700]   was they had created their well-oiled business model.
[01:58:19.700 --> 01:58:23.020]   But these other arms of the business
[01:58:23.020 --> 01:58:24.980]   were not in that perfect business model.
[01:58:24.980 --> 01:58:26.620]   So, boom, chop that off,
[01:58:26.620 --> 01:58:28.380]   and now you're gonna be integrated
[01:58:28.380 --> 01:58:32.340]   into the sort of slicing and dicing,
[01:58:32.340 --> 01:58:34.260]   selling ads against every interest
[01:58:34.260 --> 01:58:35.740]   and thought that you ever had in your head,
[01:58:35.740 --> 01:58:37.220]   that Facebook has done.
[01:58:37.220 --> 01:58:38.780]   So, it doesn't matter if everyone leaves Facebook,
[01:58:38.780 --> 01:58:41.260]   because, boom, they're gonna fix that.
[01:58:41.260 --> 01:58:42.540]   - Yeah, well, if you're gonna leave Facebook,
[01:58:42.540 --> 01:58:44.660]   you have to leave WhatsApp and Instagram too,
[01:58:44.660 --> 01:58:47.180]   or you haven't left Facebook at all.
[01:58:47.180 --> 01:58:49.500]   What I learned when I deactivated my Facebook account
[01:58:49.500 --> 01:58:52.220]   is it doesn't deactivate Facebook Messenger.
[01:58:52.220 --> 01:58:54.860]   - Right, it's completely independent.
[01:58:54.860 --> 01:58:56.180]   - Completely independent.
[01:58:56.180 --> 01:58:59.140]   - Yeah, I think, I read the whole article,
[01:58:59.140 --> 01:59:01.260]   and I just saw somebody who's going like,
[01:59:01.260 --> 01:59:03.300]   what I've been doing is working really well,
[01:59:03.300 --> 01:59:04.780]   and just because you don't like it,
[01:59:04.780 --> 01:59:06.620]   you can just go and suck it up.
[01:59:06.620 --> 01:59:07.860]   And that's it.
[01:59:07.860 --> 01:59:09.740]   - No, no, he wasn't that.
[01:59:09.740 --> 01:59:11.420]   He was, no, it was quite the opposite.
[01:59:11.420 --> 01:59:13.860]   He was saying, really, this is the best for all of us.
[01:59:13.860 --> 01:59:16.620]   You just don't understand if you think there's anything
[01:59:16.620 --> 01:59:17.460]   wrong with what we're doing.
[01:59:17.460 --> 01:59:19.100]   - That's why he wants to do that Oprah show.
[01:59:19.100 --> 01:59:21.380]   Remember, that's his this year's resolution,
[01:59:21.380 --> 01:59:23.740]   is that he's gonna have Ted Talks or whatever.
[01:59:23.740 --> 01:59:24.820]   - He's gonna talk to everybody.
[01:59:24.820 --> 01:59:26.180]   - He's not gonna listen, but he's gonna trade.
[01:59:26.180 --> 01:59:28.860]   - If you only understood what I want,
[01:59:28.860 --> 01:59:30.740]   you'd agree. - Yeah, yeah.
[01:59:30.740 --> 01:59:31.820]   - Yeah, yeah, yeah.
[01:59:31.820 --> 01:59:33.380]   - I'm just gonna say that. - We should did a great job
[01:59:33.380 --> 01:59:34.220]   of taking it down.
[01:59:34.220 --> 01:59:35.620]   I put it into the show notes.
[01:59:35.620 --> 01:59:36.460]   You wanna have a look at it,
[01:59:36.460 --> 01:59:39.460]   but it's right at the bottom of the Facebook section,
[01:59:39.460 --> 01:59:40.860]   but it's just tremendous.
[01:59:40.860 --> 01:59:44.060]   He's basically saying, you know, you're an idiot.
[01:59:44.060 --> 01:59:44.980]   He's stopping childish,
[01:59:44.980 --> 01:59:47.500]   'cause it does read, the whole article reads incredibly childish.
[01:59:47.500 --> 01:59:51.580]   - She says, Mark Zuckerberg, let me fix that op-ed you wrote.
[01:59:51.580 --> 01:59:54.700]   I can tell the people what it is you're really trying to say.
[01:59:54.700 --> 01:59:55.900]   Oh boy.
[01:59:55.900 --> 01:59:58.900]   (both laughing)
[01:59:58.900 --> 01:59:59.900]   - So read that.
[01:59:59.900 --> 02:00:03.060]   - I think ultimately what's happening here is that
[02:00:03.060 --> 02:00:04.700]   they've decided to bunker up.
[02:00:04.700 --> 02:00:05.700]   They're pulling back.
[02:00:05.700 --> 02:00:07.700]   Now, the flip side of it here is,
[02:00:07.700 --> 02:00:09.060]   and I'll put a prediction out here,
[02:00:09.060 --> 02:00:11.420]   is how long is it before Facebook domiciles itself
[02:00:11.420 --> 02:00:13.300]   in Singapore or Indonesia,
[02:00:13.300 --> 02:00:14.860]   just to get away from the US government
[02:00:14.860 --> 02:00:16.620]   and being harassed all the time?
[02:00:16.620 --> 02:00:19.980]   So if I'm going to be harassed by the US government
[02:00:19.980 --> 02:00:22.060]   and it's gonna try and regulate me,
[02:00:22.060 --> 02:00:23.580]   and I find-- - Well that hasn't even started yet,
[02:00:23.580 --> 02:00:24.900]   though, by the way.
[02:00:24.900 --> 02:00:26.820]   - Kara, by the way, okay, first paragraph,
[02:00:26.820 --> 02:00:30.540]   when I started Facebook, I wasn't trying to build
[02:00:30.540 --> 02:00:32.860]   a global company, I just wanted to bring people together.
[02:00:32.860 --> 02:00:34.860]   Kara says, this is what he's really saying.
[02:00:34.860 --> 02:00:37.060]   We're old now, we big now.
[02:00:37.060 --> 02:00:39.060]   It came from my one really good idea.
[02:00:39.060 --> 02:00:41.580]   AOL sucked and I could do better and I did.
[02:00:41.580 --> 02:00:44.860]   Now the noise has reached me up on billionaire mountain,
[02:00:44.860 --> 02:00:46.900]   so I'm gonna have to pretend I care.
[02:00:46.900 --> 02:00:49.060]   - It's-- (laughing)
[02:00:49.060 --> 02:00:52.940]   - No rich person is going to pay too much
[02:00:52.940 --> 02:00:55.460]   for this muffler, social media service,
[02:00:55.460 --> 02:00:57.220]   and poor people aren't gonna pay us at all
[02:00:57.220 --> 02:00:58.980]   because they apparently don't have any money.
[02:00:58.980 --> 02:01:01.380]   So everyone will have to endure the ads we shovel out
[02:01:01.380 --> 02:01:04.460]   and stop griping, 'cause free ain't free people.
[02:01:04.460 --> 02:01:07.660]   People consistently tell me if they're gonna see ads,
[02:01:07.660 --> 02:01:08.740]   they want them to be relevant.
[02:01:08.740 --> 02:01:11.860]   Kara says, we have a lot of data, a lot, so much,
[02:01:11.860 --> 02:01:13.860]   especially about Spanish gardeners,
[02:01:13.860 --> 02:01:16.260]   which is by the way, for some reason.
[02:01:16.260 --> 02:01:20.060]   Mark brings up people who like pages about gardening
[02:01:20.060 --> 02:01:22.340]   and live in Spain as one of the categories.
[02:01:24.020 --> 02:01:26.700]   The internet also, Mark writes, allows us far greater
[02:01:26.700 --> 02:01:28.740]   transparency and control over what ads you see
[02:01:28.740 --> 02:01:31.060]   than TV, radio, or print.
[02:01:31.060 --> 02:01:33.540]   Kara says, sure, we give you tools to control the ads you see,
[02:01:33.540 --> 02:01:35.300]   but they're akin to the instructions you got
[02:01:35.300 --> 02:01:38.180]   to program your VCR back in the day.
[02:01:38.180 --> 02:01:40.420]   Thus, the modern day version of a blinking night,
[02:01:40.420 --> 02:01:41.660]   you never fix.
[02:01:41.660 --> 02:01:47.020]   Yeah, she's gotta take down all right, and a good one.
[02:01:47.020 --> 02:01:48.340]   - I mean, to be honest with you,
[02:01:48.340 --> 02:01:51.100]   when is somebody gonna put an adult in charge of Zuckerberg
[02:01:51.100 --> 02:01:53.020]   so that he can't write this stuff and get away with it?
[02:01:53.020 --> 02:01:54.860]   I mean, it's just so badly done.
[02:01:54.860 --> 02:01:55.700]   - Yeah, but--
[02:01:55.700 --> 02:01:56.540]   - And so out of touch.
[02:01:56.540 --> 02:01:57.940]   - Who's the adult?
[02:01:57.940 --> 02:02:01.060]   I mean, Cheryl Sandberg, who's the adult?
[02:02:01.060 --> 02:02:02.780]   - But she's obviously lost control of him.
[02:02:02.780 --> 02:02:04.980]   She's given up and backing out of the whole thing,
[02:02:04.980 --> 02:02:06.700]   I think she's just can't take the pressure
[02:02:06.700 --> 02:02:08.580]   and she knows she's gonna get burned,
[02:02:08.580 --> 02:02:09.820]   so maybe she's pulling back.
[02:02:09.820 --> 02:02:12.180]   - So Mark wrote, for us, technology has always been
[02:02:12.180 --> 02:02:16.020]   about putting power in the hands of as many people as possible.
[02:02:16.020 --> 02:02:19.260]   If you believe in a world where everyone gets an opportunity
[02:02:19.260 --> 02:02:22.500]   to use their voice and an equal chance to be heard,
[02:02:22.500 --> 02:02:24.820]   where anyone could start a business from scratch,
[02:02:24.820 --> 02:02:28.420]   then it's important to build technology that serves everyone.
[02:02:28.420 --> 02:02:31.380]   That's the world we're building for every day,
[02:02:31.380 --> 02:02:34.140]   and our business model makes it possible.
[02:02:34.140 --> 02:02:38.300]   Cara says, "The real power is in the hands of one person,
[02:02:38.300 --> 02:02:39.700]   which would be me.
[02:02:39.700 --> 02:02:41.620]   I am founder, I am chief executive,
[02:02:41.620 --> 02:02:43.700]   I control 60% of the stock that matters,
[02:02:43.700 --> 02:02:45.980]   I control the board, so stop complaining,
[02:02:45.980 --> 02:02:48.300]   especially you Spanish gardeners."
[02:02:48.300 --> 02:02:49.260]   (laughing)
[02:02:49.260 --> 02:02:50.660]   The end.
[02:02:50.660 --> 02:02:51.500]   - You're right.
[02:02:51.500 --> 02:02:53.700]   - I didn't read that, that must have been in today's paper,
[02:02:53.700 --> 02:02:55.380]   that's a good take down.
[02:02:55.380 --> 02:02:57.340]   - Yeah, she's doing a great job,
[02:02:57.340 --> 02:03:00.060]   and as she says, yes, let's not forget that,
[02:03:00.060 --> 02:03:01.300]   for all our criticism of Facebook,
[02:03:01.300 --> 02:03:03.580]   let's remember that Facebook has been a great,
[02:03:03.580 --> 02:03:05.540]   a force for good and a force for the thing,
[02:03:05.540 --> 02:03:08.780]   and just because it's failing in US and in Europe,
[02:03:08.780 --> 02:03:11.820]   because it's losing touch with what people really want,
[02:03:11.820 --> 02:03:14.500]   it's also absolutely huge in other parts of the world.
[02:03:14.500 --> 02:03:15.340]   - People need it.
[02:03:15.340 --> 02:03:16.180]   - In South America, Africa.
[02:03:16.180 --> 02:03:17.180]   - And people rely on it, I agree.
[02:03:17.180 --> 02:03:18.020]   - Asia, yeah.
[02:03:18.020 --> 02:03:20.700]   - So just remember, one of the things I wanna say
[02:03:20.700 --> 02:03:22.380]   to people who are watching is don't get bumped
[02:03:22.380 --> 02:03:25.820]   just because you're a European or you're a US citizen,
[02:03:25.820 --> 02:03:28.580]   start thinking globally instead of regionally,
[02:03:28.580 --> 02:03:32.700]   and just because you don't like it in terms of the context
[02:03:32.700 --> 02:03:34.540]   that you live in, in the US or in Europe,
[02:03:34.540 --> 02:03:36.700]   doesn't mean it's not huge somewhere else.
[02:03:36.700 --> 02:03:38.660]   So be aware of that, be sensitive to that.
[02:03:38.660 --> 02:03:40.780]   - Cara also points out that Mark's kind of stuck
[02:03:40.780 --> 02:03:41.980]   between a rock and a hard place,
[02:03:41.980 --> 02:03:45.100]   if he doesn't say anything, people get upset.
[02:03:45.100 --> 02:03:47.420]   And if he says anything, people get upset,
[02:03:47.420 --> 02:03:48.740]   so if he's not a Markman.
[02:03:48.740 --> 02:03:51.340]   - But he's earned that appropriate.
[02:03:51.340 --> 02:03:52.180]   - Yeah, I agree.
[02:03:52.180 --> 02:03:53.180]   - He's earned that appropriate.
[02:03:53.180 --> 02:03:56.100]   You know, he's consistently messed this up year in, year out.
[02:03:56.100 --> 02:03:56.940]   - Yeah.
[02:03:56.940 --> 02:03:58.660]   - You know, based on the evidence,
[02:03:58.660 --> 02:04:01.300]   every time he does something, he messes up.
[02:04:01.300 --> 02:04:04.340]   He needs, you know, it's time to put somebody else
[02:04:04.340 --> 02:04:07.700]   in charge of the business so that the company can
[02:04:07.700 --> 02:04:09.460]   sincerely embrace some change,
[02:04:09.460 --> 02:04:11.940]   'cause he just seems to keep being doing the same thing
[02:04:11.940 --> 02:04:13.660]   over and over and thinking,
[02:04:13.660 --> 02:04:15.900]   well, if I'm just gonna do it again until they get it,
[02:04:15.900 --> 02:04:17.860]   'cause I know best, I'm gonna take you all with,
[02:04:17.860 --> 02:04:19.540]   you know, tell you what you could need to do.
[02:04:19.540 --> 02:04:20.380]   - Let's take a little break.
[02:04:20.380 --> 02:04:25.140]   - And then we will wrap things up with our great panel,
[02:04:25.140 --> 02:04:28.220]   joining us from Tech Memes Ride Home podcast,
[02:04:28.220 --> 02:04:31.620]   Brian McCullough, his new book about the history
[02:04:31.620 --> 02:04:35.460]   of the internet is a must read and available everywhere.
[02:04:35.460 --> 02:04:38.460]   Is there an audible version of how the internet happened?
[02:04:38.460 --> 02:04:40.620]   - Yes, not read by me, thank God.
[02:04:40.620 --> 02:04:42.220]   - All right, well, look for that,
[02:04:42.220 --> 02:04:44.100]   'cause I know I like to listen.
[02:04:44.100 --> 02:04:47.100]   How the internet happened from Netscape to the iPhone.
[02:04:47.100 --> 02:04:48.380]   It's great to have you, Brian.
[02:04:48.380 --> 02:04:51.420]   Jason Heiner, editor in chief of Tech Republic.
[02:04:51.420 --> 02:04:53.300]   Always a pleasure to have you, Jason.
[02:04:53.300 --> 02:04:57.100]   You're one of my heroes, do a great job there
[02:04:57.100 --> 02:04:59.260]   and it's CBS Interactive.
[02:04:59.260 --> 02:05:00.860]   And Greg Fair-- - I know about that.
[02:05:00.860 --> 02:05:03.540]   - No, you are, you know, you got me elected president
[02:05:03.540 --> 02:05:05.180]   of the internet and for that I'm eternally,
[02:05:05.180 --> 02:05:09.900]   you're kind of like my Steve Bannon.
[02:05:09.900 --> 02:05:12.300]   (laughing)
[02:05:12.300 --> 02:05:14.900]   Only shaved or something.
[02:05:14.900 --> 02:05:17.660]   (laughing)
[02:05:17.660 --> 02:05:19.780]   - I do need my audio, but for the right.
[02:05:19.780 --> 02:05:21.460]   - Sorry. - Yes, and do a very good job,
[02:05:21.460 --> 02:05:22.620]   I mind that. - Oh, thank you.
[02:05:22.620 --> 02:05:25.900]   - And Greg Fair is also here from the Packet Pushers Network,
[02:05:25.900 --> 02:05:30.060]   a great podcast network for people who love the network,
[02:05:30.060 --> 02:05:32.860]   PacketPushers.net, add a theory of mine on the Twitter.
[02:05:32.860 --> 02:05:37.860]   I show today brought to you by Wasabe, hot cloud storage,
[02:05:37.860 --> 02:05:42.740]   being able to efficiently and affordably store data.
[02:05:42.740 --> 02:05:45.940]   And man data is crazy these days.
[02:05:45.940 --> 02:05:50.620]   There's an estimated 163 zettabytes of data by 2025.
[02:05:50.620 --> 02:05:52.340]   Being able to store that data efficiently
[02:05:52.340 --> 02:05:55.140]   and affordably is critical for businesses.
[02:05:55.140 --> 02:05:56.780]   Companies need to store it in the cloud,
[02:05:56.780 --> 02:05:58.620]   but of course there's concerns.
[02:05:58.620 --> 02:06:01.020]   Wasabe addresses this concerns because it has
[02:06:01.020 --> 02:06:05.420]   disruptive technology that's turning the industry on its ear.
[02:06:05.420 --> 02:06:08.100]   This revolutionary process lays data on disks
[02:06:08.100 --> 02:06:10.260]   sequentially as opposed to in blocks.
[02:06:10.260 --> 02:06:12.460]   That means their storage, Wasabe storage
[02:06:12.460 --> 02:06:17.460]   is 80% cheaper and six times faster than Amazon S3.
[02:06:17.460 --> 02:06:20.700]   It's incredibly simple, there's just one tier of service.
[02:06:20.700 --> 02:06:21.940]   And some of the things you get,
[02:06:21.940 --> 02:06:24.500]   things like unlimited free egress,
[02:06:24.500 --> 02:06:26.100]   no charge for API calls.
[02:06:26.100 --> 02:06:29.620]   And one of my favorite features, immutable storage,
[02:06:29.620 --> 02:06:31.740]   these are things I love.
[02:06:31.740 --> 02:06:33.900]   Immutable storage means you can say,
[02:06:33.900 --> 02:06:36.860]   hey that stuff I just put there, that can't be changed.
[02:06:36.860 --> 02:06:41.140]   No malware can change it, no fumble fingered employee
[02:06:41.140 --> 02:06:43.260]   can delete it, that's immutable.
[02:06:43.260 --> 02:06:48.100]   11, nine's data durability and up to six times faster
[02:06:48.100 --> 02:06:49.800]   than AWS, what?
[02:06:49.800 --> 02:06:52.980]   It's just as secure and in fact,
[02:06:52.980 --> 02:06:54.620]   I would say in most cases more secure
[02:06:54.620 --> 02:06:56.820]   than your on-prem storage.
[02:06:56.820 --> 02:07:00.540]   Hippo compliant, FINRA compliant, CJIS compliant.
[02:07:00.540 --> 02:07:03.140]   And if you do have a ton of data to migrate,
[02:07:03.140 --> 02:07:05.780]   get the Wasabe ball, you can just put it on the ball,
[02:07:05.780 --> 02:07:08.620]   send it to Wasabe, you can migrate petabytes of data
[02:07:08.620 --> 02:07:10.660]   simply quickly and securely.
[02:07:10.660 --> 02:07:12.460]   Look, I understand this is a new name
[02:07:12.460 --> 02:07:14.580]   and a new company, you don't know them.
[02:07:14.580 --> 02:07:16.380]   I just want you to put them on that list.
[02:07:16.380 --> 02:07:19.180]   If you're shopping for cloud storage
[02:07:19.180 --> 02:07:20.700]   and you got the big three on there
[02:07:20.700 --> 02:07:24.220]   and I know you do, just add one more.
[02:07:24.220 --> 02:07:25.340]   And I'll tell you what,
[02:07:25.340 --> 02:07:27.260]   the boss might really be thrilled when you say,
[02:07:27.260 --> 02:07:30.260]   hey boss, 80% cheaper and six times faster.
[02:07:30.260 --> 02:07:32.540]   You could try it right now free for 30 days.
[02:07:32.540 --> 02:07:35.260]   If you go to the website, you'll see it's a terabyte of data,
[02:07:35.260 --> 02:07:37.580]   but if you use the offer code TWIT, it's unlimited,
[02:07:37.580 --> 02:07:38.420]   there's no limit.
[02:07:38.420 --> 02:07:40.380]   Store it all up there, see how it works,
[02:07:40.380 --> 02:07:43.620]   see how fast it is, Wasabe.com.
[02:07:43.620 --> 02:07:45.940]   If you're a business and you need to put your stuff
[02:07:45.940 --> 02:07:48.380]   in the cloud, you need to do it fast, affordably,
[02:07:48.380 --> 02:07:49.220]   you gotta check them out.
[02:07:49.220 --> 02:07:54.220]   W-A-S-A-B-I, Wasabe.com, six times faster than S3.
[02:07:54.220 --> 02:07:59.500]   One fifth the price, you're gonna love it, Wasabe.com.
[02:07:59.500 --> 02:08:02.300]   Just add them to the list, check it out, that's all we ask.
[02:08:02.300 --> 02:08:05.380]   Use the offer code TWIT for free unlimited storage for a month.
[02:08:05.380 --> 02:08:07.340]   It was Wasabe, wasabe.
[02:08:07.340 --> 02:08:08.900]   Wasabe.com.
[02:08:09.860 --> 02:08:12.860]   Google is going to the Supreme Court,
[02:08:12.860 --> 02:08:14.180]   I think this is an important case,
[02:08:14.180 --> 02:08:16.420]   so I wanted to highlight it, you may remember,
[02:08:16.420 --> 02:08:20.500]   they lost the Oracle suit over Java.
[02:08:20.500 --> 02:08:25.500]   It wasn't about using Java, it was about whether an API
[02:08:25.500 --> 02:08:29.500]   can be copyrighted, whether somebody can take,
[02:08:29.500 --> 02:08:32.860]   for instance, the Java API and duplicate it,
[02:08:32.860 --> 02:08:34.620]   Google petitioned the Supreme Court saying,
[02:08:34.620 --> 02:08:36.660]   "You've gotta review this, here's their argument."
[02:08:36.660 --> 02:08:38.820]   Unless the Supreme Court corrects
[02:08:38.820 --> 02:08:42.060]   these twin reversals, this case will end developers'
[02:08:42.060 --> 02:08:44.660]   traditional ability to freely use
[02:08:44.660 --> 02:08:47.620]   existing software interfaces, APIs,
[02:08:47.620 --> 02:08:50.700]   to build new generations of computer programs for consumers.
[02:08:50.700 --> 02:08:53.740]   Did I just mention Wasabe uses the S3 API?
[02:08:53.740 --> 02:08:55.460]   Yeah, Amazon probably doesn't like it,
[02:08:55.460 --> 02:08:59.220]   but an API is public, that's the whole point of an API,
[02:08:59.220 --> 02:09:01.420]   and that's good for everybody.
[02:09:01.420 --> 02:09:03.700]   Just like we all learn to use Google rights,
[02:09:03.700 --> 02:09:05.300]   computer keyboard shortcuts,
[02:09:05.300 --> 02:09:07.900]   developers have learned to use the many standard interfaces.
[02:09:07.900 --> 02:09:11.140]   By the way, this is them explaining to justices
[02:09:11.140 --> 02:09:16.340]   that average 83 years old, what an API is.
[02:09:16.340 --> 02:09:19.580]   Developers learned to use the many standard interfaces
[02:09:19.580 --> 02:09:22.220]   associated with different programming languages.
[02:09:22.220 --> 02:09:24.220]   Letting these reversal stand would effectively
[02:09:24.220 --> 02:09:26.500]   lock developers into the platform
[02:09:26.500 --> 02:09:29.460]   of a single copyright holder, in this case, Oracle,
[02:09:29.460 --> 02:09:31.300]   akin to saying that keyboard shortcuts
[02:09:31.300 --> 02:09:33.380]   can only work with one type of computer.
[02:09:33.380 --> 02:09:37.860]   Is that an apt description, Greg Ferro, and are they right?
[02:09:37.860 --> 02:09:39.420]   I think so. I think in this case,
[02:09:39.420 --> 02:09:41.660]   Oracle's lawyers got one over Google's lawyers
[02:09:41.660 --> 02:09:43.500]   and managed to get away with it.
[02:09:43.500 --> 02:09:45.740]   Oracle, of course, was defending its Java
[02:09:45.740 --> 02:09:48.500]   and the control of the Java ecosystem at the time.
[02:09:48.500 --> 02:09:52.340]   Android was written in Java, and Oracle wanted to extract
[02:09:52.340 --> 02:09:54.860]   some money from Google.
[02:09:54.860 --> 02:09:57.140]   And Oracle knows how to play these games.
[02:09:57.140 --> 02:10:01.300]   They're incredibly smart about this and have really good lawyers.
[02:10:01.300 --> 02:10:04.980]   And in this case, I think that they got one over Google,
[02:10:04.980 --> 02:10:07.300]   and Google has to do this, I think.
[02:10:07.300 --> 02:10:09.820]   Not just for itself, but for the internet at large.
[02:10:09.820 --> 02:10:13.460]   Because if they lose this, then they can't actually
[02:10:13.460 --> 02:10:15.860]   read my website and scan for search data.
[02:10:15.860 --> 02:10:16.620]   Right.
[02:10:16.620 --> 02:10:18.980]   I remember we interviewed Jonathan Schwartz,
[02:10:18.980 --> 02:10:22.940]   the last CEO of Sun, on triangulation.
[02:10:22.940 --> 02:10:23.900]   You can go back and look at it.
[02:10:23.900 --> 02:10:28.860]   And he was talking about the day Sun was sold to Oracle.
[02:10:28.860 --> 02:10:31.260]   And at that time, Oracle acquired, of course,
[02:10:31.260 --> 02:10:33.700]   not only Sun's assets, but Java.
[02:10:33.700 --> 02:10:36.220]   And he said, I remember sitting in the room,
[02:10:36.220 --> 02:10:40.660]   and the lawyers, the Oracle lawyers, the Oracle negotiators,
[02:10:40.660 --> 02:10:43.700]   they were rubbing their hands with Glee,
[02:10:43.700 --> 02:10:46.860]   because they knew they were acquiring technologies
[02:10:46.860 --> 02:10:50.300]   that they could make a lot of money on in court.
[02:10:50.300 --> 02:10:52.780]   That was what they were excited about.
[02:10:52.780 --> 02:10:55.500]   They weren't excited about what Sun's technologies were.
[02:10:55.500 --> 02:10:57.260]   They were excited about the licenses.
[02:10:57.260 --> 02:10:59.820]   They were excited about the lawsuits.
[02:10:59.820 --> 02:11:02.340]   [LAUGHTER]
[02:11:02.340 --> 02:11:04.020]   And hey, they know how to make money.
[02:11:04.020 --> 02:11:07.460]   The day-- well, the trick here is that every website
[02:11:07.460 --> 02:11:08.660]   is fundamentally an API.
[02:11:08.660 --> 02:11:12.020]   When you request a HTTP request, you
[02:11:12.020 --> 02:11:16.060]   can make a case that pulling HTTP requests from a website
[02:11:16.060 --> 02:11:17.460]   is an API call.
[02:11:17.460 --> 02:11:19.460]   And the original idea behind HTTP
[02:11:19.460 --> 02:11:21.620]   was heading in that direction.
[02:11:21.620 --> 02:11:24.540]   And if you can patent that and take control
[02:11:24.540 --> 02:11:26.500]   of the whole idea that an API is controllable,
[02:11:26.500 --> 02:11:28.860]   then in theory, large parts of the web
[02:11:28.860 --> 02:11:29.900]   suddenly stop working.
[02:11:29.900 --> 02:11:33.700]   And it would be very bad for change.
[02:11:33.700 --> 02:11:34.820]   I wouldn't call innovation.
[02:11:34.820 --> 02:11:37.500]   Copying someone else's API is not an innovation.
[02:11:37.500 --> 02:11:39.540]   That's just copying somebody else's API
[02:11:39.540 --> 02:11:42.260]   and then putting your own technology underneath that API.
[02:11:42.260 --> 02:11:43.740]   We need that competitively.
[02:11:43.740 --> 02:11:46.060]   We don't want to have monopoly.
[02:11:46.060 --> 02:11:47.900]   So we know, for example, Facebook
[02:11:47.900 --> 02:11:50.300]   is a monopoly of that particular space.
[02:11:50.300 --> 02:11:52.660]   It's very difficult for anybody to compete with Facebook
[02:11:52.660 --> 02:11:54.460]   because of the network effect.
[02:11:54.460 --> 02:11:57.620]   If we have APIs dominated, then competitors
[02:11:57.620 --> 02:12:00.060]   will find it very difficult to enter the space.
[02:12:00.060 --> 02:12:02.100]   And capitalism and competition, which
[02:12:02.100 --> 02:12:05.460]   is part of a modern society, then get stifled.
[02:12:05.460 --> 02:12:07.860]   And that's why I think it's important.
[02:12:07.860 --> 02:12:10.940]   I think I overestimated the average age of the Supreme Court.
[02:12:10.940 --> 02:12:15.500]   I think it's actually thanks to Brett Kavanaugh replacing
[02:12:15.500 --> 02:12:18.900]   Justice Roberts, somewhere around 64 now.
[02:12:18.900 --> 02:12:20.860]   So it's a little better than it was.
[02:12:20.860 --> 02:12:23.220]   But imagine the difficulty--
[02:12:23.220 --> 02:12:24.820]   it's bad enough to explain in a lower court
[02:12:24.820 --> 02:12:26.860]   what an API is and why this is an issue.
[02:12:26.860 --> 02:12:30.620]   But imagine the difficulty explaining to the Supreme Court
[02:12:30.620 --> 02:12:32.020]   what this all means.
[02:12:32.020 --> 02:12:34.780]   Yes, you have to have some smart clerks
[02:12:34.780 --> 02:12:36.380]   that understand the technology world.
[02:12:36.380 --> 02:12:37.420]   That's a good point.
[02:12:37.420 --> 02:12:39.860]   I'm sure the clerks do.
[02:12:39.860 --> 02:12:41.540]   Yeah.
[02:12:41.540 --> 02:12:42.260]   We'll watch that.
[02:12:42.260 --> 02:12:44.260]   I think that's going to be an important case.
[02:12:44.260 --> 02:12:46.420]   I thank you for watching "Twit" this week.
[02:12:46.420 --> 02:12:47.940]   What a show.
[02:12:47.940 --> 02:12:50.500]   Greg Farrow, packet pushers, network.
[02:12:50.500 --> 02:12:51.700]   You're on fire.
[02:12:51.700 --> 02:12:52.500]   You always do that.
[02:12:52.500 --> 02:12:53.700]   You always light a fire on us.
[02:12:53.700 --> 02:12:55.300]   Make us think, which is important.
[02:12:55.300 --> 02:12:56.140]   That's important.
[02:12:56.140 --> 02:12:56.740]   Yes.
[02:12:56.740 --> 02:12:57.180]   That's important.
[02:12:57.180 --> 02:12:58.980]   Strong opinions loosely held.
[02:12:58.980 --> 02:12:59.860]   Change my mind.
[02:12:59.860 --> 02:13:00.660]   That's his motto.
[02:13:00.660 --> 02:13:03.620]   [LAUGHTER]
[02:13:03.620 --> 02:13:04.260]   Thank you, Greg.
[02:13:04.260 --> 02:13:04.940]   Always a pleasure.
[02:13:04.940 --> 02:13:06.180]   You stayed up late tonight.
[02:13:06.180 --> 02:13:08.100]   And we were very glad you did.
[02:13:08.100 --> 02:13:10.300]   As always, a privilege to be with you.
[02:13:10.300 --> 02:13:10.940]   Thank you.
[02:13:10.940 --> 02:13:11.700]   Thank you.
[02:13:11.700 --> 02:13:16.020]   Jason Heiner from the beautiful tech republic
[02:13:16.020 --> 02:13:17.940]   in Louisville, Kentucky.
[02:13:17.940 --> 02:13:20.260]   I'll see you in May.
[02:13:20.260 --> 02:13:21.100]   Excellent.
[02:13:21.100 --> 02:13:22.180]   I would love that.
[02:13:22.180 --> 02:13:22.740]   Oh, it'd be fun.
[02:13:22.740 --> 02:13:24.300]   Let me know if you come.
[02:13:24.300 --> 02:13:25.100]   Absolutely.
[02:13:25.100 --> 02:13:26.860]   I will first mint your lips on me.
[02:13:26.860 --> 02:13:30.180]   But you could buy the mud pie.
[02:13:30.180 --> 02:13:31.060]   That derby pie.
[02:13:31.060 --> 02:13:32.260]   That's good.
[02:13:32.260 --> 02:13:33.060]   That's good stuff.
[02:13:33.060 --> 02:13:33.580]   There we go.
[02:13:33.580 --> 02:13:35.740]   Mud derby pie.
[02:13:35.740 --> 02:13:37.860]   And it's Brian McCullough.
[02:13:37.860 --> 02:13:41.140]   He's the host of the Tech meme ride home.
[02:13:41.140 --> 02:13:42.620]   Our historian for the day.
[02:13:42.620 --> 02:13:45.260]   It was good to have a historian here.
[02:13:45.260 --> 02:13:46.060]   Well, thank you.
[02:13:46.060 --> 02:13:46.540]   Yeah.
[02:13:46.540 --> 02:13:48.260]   I put on the history hat now and again.
[02:13:48.260 --> 02:13:48.980]   I like that.
[02:13:48.980 --> 02:13:49.780]   Necessary.
[02:13:49.780 --> 02:13:52.060]   I think that's really helpful, actually.
[02:13:52.060 --> 02:13:55.580]   Because as I get older, I think it gets--
[02:13:55.580 --> 02:13:57.140]   I understand better the importance
[02:13:57.140 --> 02:13:58.380]   of context and all this stuff.
[02:13:58.380 --> 02:14:01.260]   Because we're like in the middle of it all.
[02:14:01.260 --> 02:14:04.620]   No, but that's the point, Leo, is that if you live long enough,
[02:14:04.620 --> 02:14:07.420]   all the stuff you remember is history
[02:14:07.420 --> 02:14:08.980]   that you got to tell the youngens about.
[02:14:08.980 --> 02:14:11.740]   Too bad I don't remember anything.
[02:14:11.740 --> 02:14:12.140]   Thank you.
[02:14:12.140 --> 02:14:13.500]   Great to have you, Brian.
[02:14:13.500 --> 02:14:15.620]   We do Twitter every Sunday afternoon, 3 p.m.
[02:14:15.620 --> 02:14:16.540]   Pacific, 6 p.m.
[02:14:16.540 --> 02:14:16.980]   Eastern.
[02:14:16.980 --> 02:14:20.700]   That's 2300 UTC late at night for Greg Ferro.
[02:14:20.700 --> 02:14:22.540]   But you can always watch wherever you are.
[02:14:22.540 --> 02:14:26.380]   If you watch the live stream, it's at twit.tv/live.
[02:14:26.380 --> 02:14:28.020]   Actually, it's audio and video.
[02:14:28.020 --> 02:14:29.620]   So you can watch or listen.
[02:14:29.620 --> 02:14:31.180]   If you do that, join us in the chat room.
[02:14:31.180 --> 02:14:33.700]   That's where everybody else watching and listening live is
[02:14:33.700 --> 02:14:36.420]   irc.twit.tv.
[02:14:36.420 --> 02:14:38.420]   There's always a great conversation going on there.
[02:14:38.420 --> 02:14:39.500]   And I appreciate the chat room.
[02:14:39.500 --> 02:14:40.900]   Thank you for being here.
[02:14:40.900 --> 02:14:43.500]   If you can't watch live-- and I know most of you can't--
[02:14:43.500 --> 02:14:44.100]   hey, no problem.
[02:14:44.100 --> 02:14:46.220]   We've got on-demand audio and video.
[02:14:46.220 --> 02:14:48.460]   No blinking 12, no VCR to set.
[02:14:48.460 --> 02:14:51.700]   We will provide you with an on-demand version of this show.
[02:14:51.700 --> 02:14:53.300]   Absolutely free.
[02:14:53.300 --> 02:14:55.300]   All you have to do is go to twit.tv.
[02:14:55.300 --> 02:14:56.580]   All our shows are there.
[02:14:56.580 --> 02:14:59.500]   You can download an episode audio or video.
[02:14:59.500 --> 02:15:04.260]   And you can also get it in your favorite podcast application.
[02:15:04.260 --> 02:15:05.620]   So that makes it really easy.
[02:15:05.620 --> 02:15:11.060]   All you have to do is look for this week in tech.
[02:15:11.060 --> 02:15:12.860]   Say, I want to subscribe.
[02:15:12.860 --> 02:15:14.460]   You'll get it the minute it's done.
[02:15:14.460 --> 02:15:15.140]   One more favor.
[02:15:15.140 --> 02:15:15.820]   I'd like to ask.
[02:15:15.820 --> 02:15:18.540]   It's time for our annual twit survey.
[02:15:18.540 --> 02:15:20.100]   We try to make these simple and easy,
[02:15:20.100 --> 02:15:22.420]   but it's very helpful for us in understanding better
[02:15:22.420 --> 02:15:25.260]   what you like, what you want, how you listen.
[02:15:25.260 --> 02:15:28.900]   And look, we don't collect any information about you.
[02:15:28.900 --> 02:15:30.540]   We do not spy on you.
[02:15:30.540 --> 02:15:34.020]   The survey is the only way we have of getting a better idea
[02:15:34.020 --> 02:15:38.540]   of who is there, not required.
[02:15:38.540 --> 02:15:40.580]   But if you would help us out, I'd appreciate it.
[02:15:40.580 --> 02:15:45.660]   Go to twit.to, twit.to-- that's our URL shortener--
[02:15:45.660 --> 02:15:47.620]   slash survey 19.
[02:15:47.620 --> 02:15:49.580]   If you go to twit.tv, there's a link right there
[02:15:49.580 --> 02:15:54.700]   on the front page to twit.to/survey19.
[02:15:54.700 --> 02:15:58.260]   We really appreciate your help in better understanding you.
[02:15:58.260 --> 02:16:00.980]   It helps us sell ads, but it also helps us understand
[02:16:00.980 --> 02:16:02.780]   what it is you need from us.
[02:16:02.780 --> 02:16:05.500]   So we thank you very much for helping us out there.
[02:16:05.500 --> 02:16:07.380]   Thank you for watching Twit.
[02:16:07.380 --> 02:16:08.380]   We'll see you next time.
[02:16:08.380 --> 02:16:09.940]   Meanwhile, another twit.
[02:16:09.940 --> 02:16:11.020]   It's amazing.
[02:16:11.020 --> 02:16:13.020]   Bye bye.
[02:16:13.020 --> 02:16:14.780]   [MUSIC PLAYING]
[02:16:14.780 --> 02:16:15.280]   Twit.
[02:16:15.280 --> 02:16:16.280]   All right.
[02:16:16.280 --> 02:16:18.020]   Do it on the twit, baby.
[02:16:18.020 --> 02:16:18.820]   Do it on the twit.
[02:16:18.820 --> 02:16:19.860]   All right.

